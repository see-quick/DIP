[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Build Order:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift                 [pom]
[[1;34mINFO[m] test                                                               [jar]
[[1;34mINFO[m] crd-annotations                                                    [jar]
[[1;34mINFO[m] crd-generator                                                      [jar]
[[1;34mINFO[m] api                                                                [jar]
[[1;34mINFO[m] mockkube                                                           [jar]
[[1;34mINFO[m] config-model                                                       [jar]
[[1;34mINFO[m] certificate-manager                                                [jar]
[[1;34mINFO[m] operator-common                                                    [jar]
[[1;34mINFO[m] systemtest                                                         [jar]
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------------< [0;36mio.strimzi:strimzi[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT [1/10][m
[[1;34mINFO[m] [1m--------------------------------[ pom ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;33mWARNING[m] The artifact xml-apis:xml-apis:jar:2.0.2 has been relocated to xml-apis:xml-apis:jar:1.0.b2
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mstrimzi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mstrimzi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping pom project
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--------------------------< [0;36mio.strimzi:test[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding test 0.29.0-SNAPSHOT                                     [2/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/test/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/test/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No sources to compile
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/test/target/test-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:crd-annotations[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding crd-annotations 0.29.0-SNAPSHOT                          [3/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/crd-annotations/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/crd-annotations/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/crd-annotations/target/crd-annotations-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:crd-generator[0;1m >----------------------[m
[[1;34mINFO[m] [1mBuilding crd-generator 0.29.0-SNAPSHOT                            [4/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/crd-generator/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 7 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-shade-plugin:3.1.0:shade[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Including io.strimzi:crd-annotations:jar:0.29.0-SNAPSHOT in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-core:jar:2.11.3 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-databind:jar:2.11.3 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.10.5 in the shaded jar.
[[1;34mINFO[m] Including org.yaml:snakeyaml:jar:1.26 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-client:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-rbac:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-admissionregistration:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apps:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-autoscaling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apiextensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-batch:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-certificates:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-coordination:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-discovery:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-events:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-extensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-flowcontrol:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-networking:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-metrics:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-policy:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-scheduling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-storageclass:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-node:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:okhttp:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okio:okio:jar:1.15.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:logging-interceptor:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including org.slf4j:slf4j-api:jar:1.7.25 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.datatype:jackson-datatype-jsr310:jar:2.13.1 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:zjsonpatch:jar:0.3.0 in the shaded jar.
[[1;34mINFO[m] Including com.github.mifmif:generex:jar:1.0.2 in the shaded jar.
[[1;34mINFO[m] Including dk.brics.automaton:automaton:jar:1.11-8 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-core:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-common:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-annotations:jar:2.11.3 in the shaded jar.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] kubernetes-model-coordination-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 18 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluent
[[1;33mWARNING[m]   - 8 more...
[[1;33mWARNING[m] logging-interceptor-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger$1
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$Factory
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Level
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor
[[1;33mWARNING[m]   - okhttp3.logging.package-info
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$1
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger
[[1;33mWARNING[m] kubernetes-client-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 536 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.CertUtils
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.CustomResource
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.osgi.ManagedKubernetesClient
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.V1beta1ApiextensionAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.PatchUtils$SingletonHolder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.VersionInfo$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.utils.ReplaceValueStream
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.CreateFromServerGettable
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.ApiextensionsAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.Containerable
[[1;33mWARNING[m]   - 526 more...
[[1;33mWARNING[m] kubernetes-model-events-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$SeriesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$RegardingNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventSeriesFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, automaton-1.11-8.jar define 25 overlapping classes: 
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonMatcher
[[1;33mWARNING[m]   - dk.brics.automaton.ShuffleOperations$ShuffleConfiguration
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$Kind
[[1;33mWARNING[m]   - dk.brics.automaton.RunAutomaton
[[1;33mWARNING[m]   - dk.brics.automaton.Automaton
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonProvider
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$1
[[1;33mWARNING[m]   - dk.brics.automaton.MinimizationOperations$StateListNode
[[1;33mWARNING[m]   - dk.brics.automaton.State
[[1;33mWARNING[m]   - 15 more...
[[1;33mWARNING[m] kubernetes-model-metrics-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 30 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.ContainerMetricsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetrics
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl$ContainersNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListBuilder
[[1;33mWARNING[m]   - 20 more...
[[1;33mWARNING[m] kubernetes-model-networking-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 234 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressServiceBackend
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressClassFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressRuleFluentImpl$HttpNestedImpl
[[1;33mWARNING[m]   - 224 more...
[[1;33mWARNING[m] jackson-dataformat-yaml-2.10.5.jar, crd-generator-0.29.0-SNAPSHOT.jar define 15 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLMapper$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.snakeyaml.error.Mark
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.UTF8Reader
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.JacksonYAMLParseException
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.PackageVersion
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.snakeyaml.error.YAMLException
[[1;33mWARNING[m]   - 5 more...
[[1;33mWARNING[m] kubernetes-model-apiextensions-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrBoolBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionSpecFluent$ValidationNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionFluentImpl$SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrStringArraySerDe$Deserializer$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceValidationFluentImpl$OpenAPIV3SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsFluentImpl$NotNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.WebhookClientConfigFluentImpl$ServiceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrArrayFluent$SchemaNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1.JSONSchemaPropsOrBoolSerDe
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] generex-1.0.2.jar, crd-generator-0.29.0-SNAPSHOT.jar define 7 overlapping classes: 
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator
[[1;33mWARNING[m]   - com.mifmif.common.regex.Generex
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator$Step
[[1;33mWARNING[m]   - com.mifmif.common.regex.Node
[[1;33mWARNING[m]   - com.mifmif.common.regex.Main
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterable
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterator
[[1;33mWARNING[m] kubernetes-model-autoscaling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricSpecFluentImpl$ObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.CrossVersionObjectReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.ContainerResourceMetricStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricStatusFluent$ObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpecFluent$ScaleTargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, zjsonpatch-0.3.0.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.InsertCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Operation
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.CommandVisitor
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.guava.Strings
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.EditCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonDiff$EncodePathFunction
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.SequencesComparator
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Diff
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.ListUtils
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonPatch
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-admissionregistration-5.12.0.jar define 362 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluent$ObjectSelectorNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1.SubjectAccessReviewSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SubjectRulesReviewStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.ValidatingWebhookConfigurationBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authentication.TokenReviewFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectRulesReviewSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluentImpl$NamespaceSelectorNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookConfigurationFluentImpl$WebhooksNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectAccessReviewFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.MutatingWebhookFluent$ClientConfigNested
[[1;33mWARNING[m]   - 352 more...
[[1;33mWARNING[m] kubernetes-model-rbac-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 80 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.AggregationRuleFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.PolicyRuleFluent
[[1;33mWARNING[m]   - 70 more...
[[1;33mWARNING[m] kubernetes-model-certificates-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 60 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestConditionFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl
[[1;33mWARNING[m]   - 50 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-policy-5.12.0.jar define 162 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1.PodDisruptionBudgetList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.HostPortRangeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.EvictionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$AllowedCSIDriversNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.AllowedFlexVolumeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.IDRangeFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.SELinuxStrategyOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$FsGroupNestedImpl
[[1;33mWARNING[m]   - 152 more...
[[1;33mWARNING[m] jackson-datatype-jsr310-2.13.1.jar, crd-generator-0.29.0-SNAPSHOT.jar define 59 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.Jsr310KeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.PackageVersion
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.YearDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.key.Jsr310NullKeySerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.LocalDateTimeKeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.util.DurationUnitConverter
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.InstantSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.OffsetDateTimeSerializer
[[1;33mWARNING[m]   - 49 more...
[[1;33mWARNING[m] kubernetes-model-flowcontrol-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 132 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowSchemaConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowDistinguisherMethodBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfigurationFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReference
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PolicyRulesWithSubjects
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationListFluent$ItemsNested
[[1;33mWARNING[m]   - 122 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, crd-annotations-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$Stability
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$1
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedType
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedProperty
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange$VersionParser
[[1;33mWARNING[m]   - io.strimzi.api.annotations.KubeVersion
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, okio-1.15.0.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - okio.ByteString
[[1;33mWARNING[m]   - okio.Source
[[1;33mWARNING[m]   - okio.ForwardingSink
[[1;33mWARNING[m]   - okio.BufferedSource
[[1;33mWARNING[m]   - okio.Util
[[1;33mWARNING[m]   - okio.AsyncTimeout$1
[[1;33mWARNING[m]   - okio.HashingSource
[[1;33mWARNING[m]   - okio.GzipSink
[[1;33mWARNING[m]   - okio.Okio$1
[[1;33mWARNING[m]   - okio.Pipe$PipeSink
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] kubernetes-model-discovery-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 88 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.ForZoneBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointFluent$TargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluentImpl$ConditionsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointConditionsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 78 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-annotations-2.11.3.jar define 68 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonAutoDetect
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonInclude
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.ObjectIdGenerators
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Features
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonIgnore
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSetter
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonTypeInfo$None
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Shape
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSubTypes
[[1;33mWARNING[m]   - 58 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-extensions-5.12.0.jar define 264 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetConditionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DeploymentStrategyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicySpecFluent$IngressNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressSpecFluent$RulesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyPeerBuilder
[[1;33mWARNING[m]   - 254 more...
[[1;33mWARNING[m] kubernetes-model-node-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 78 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.OverheadBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.Scheduling
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.SchedulingFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.RuntimeClassSpecFluent$OverheadNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - 68 more...
[[1;33mWARNING[m] kubernetes-model-core-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 2394 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.BaseKubernetesListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.StatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.KubeSchemaFluentImpl$APIResourceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.NodeListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ResourceQuotaListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluentImpl$APIServiceStatusObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluent$VsphereVirtualDiskVolumeSourceObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ProbeFluentImpl$HttpGetNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.PatchOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ServerAddressByClientCIDRFluentImpl
[[1;33mWARNING[m]   - 2384 more...
[[1;33mWARNING[m] slf4j-api-1.7.25.jar, crd-generator-0.29.0-SNAPSHOT.jar define 34 overlapping classes: 
[[1;33mWARNING[m]   - org.slf4j.helpers.SubstituteLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.NamedLoggerBase
[[1;33mWARNING[m]   - org.slf4j.helpers.NOPMDCAdapter
[[1;33mWARNING[m]   - org.slf4j.MarkerFactory
[[1;33mWARNING[m]   - org.slf4j.helpers.BasicMarker
[[1;33mWARNING[m]   - org.slf4j.spi.LoggerFactoryBinder
[[1;33mWARNING[m]   - org.slf4j.MDC$MDCCloseable
[[1;33mWARNING[m]   - org.slf4j.spi.LocationAwareLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.MessageFormatter
[[1;33mWARNING[m]   - org.slf4j.helpers.Util$ClassContextSecurityManager
[[1;33mWARNING[m]   - 24 more...
[[1;33mWARNING[m] kubernetes-model-apps-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 212 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentStrategyFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluent$DeploymentDataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluentImpl$PersistentVolumeClaimDataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetCondition
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - 202 more...
[[1;33mWARNING[m] kubernetes-model-scheduling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassFluent$MetadataNested
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-core-2.11.3.jar define 117 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.JsonGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.json.JsonReadFeature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.ThreadLocalBufferManager$ThreadLocalBufferManagerHolder
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.Separators
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.io.SegmentedStringWriter
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.TreeNode
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.sym.Name
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.RequestPayload
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.JsonGeneratorDelegate
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.async.NonBlockingInputFeeder
[[1;33mWARNING[m]   - 107 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-common-5.12.0.jar define 16 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Plural
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Group
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer$CancelUnwrapped
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.PrinterColumn
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.UnwrappedTypeResolverBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Singular
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.StatusReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.SpecReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Version
[[1;33mWARNING[m]   - 6 more...
[[1;33mWARNING[m] snakeyaml-1.26.jar, crd-generator-0.29.0-SNAPSHOT.jar define 216 overlapping classes: 
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockNode
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingSimpleValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectDocumentEnd
[[1;33mWARNING[m]   - org.yaml.snakeyaml.Yaml$3
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockSequenceItem
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockSequenceEntry
[[1;33mWARNING[m]   - org.yaml.snakeyaml.util.ArrayUtils
[[1;33mWARNING[m]   - org.yaml.snakeyaml.tokens.Token$ID
[[1;33mWARNING[m]   - org.yaml.snakeyaml.reader.StreamReader
[[1;33mWARNING[m]   - 206 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-batch-5.12.0.jar define 112 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobStatusFluentImpl$ActiveNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluent$TemplateNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluentImpl$TemplateNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.Job
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobListFluent
[[1;33mWARNING[m]   - 102 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-storageclass-5.12.0.jar define 172 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIStorageCapacityListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeDriverFluentImpl$AllocatableNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.StorageClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.TokenRequestFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSINodeDriverFluent$AllocatableNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIDriverSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSpecFluent
[[1;33mWARNING[m]   - 162 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-databind-2.11.3.jar define 657 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$NoAnnotations
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.jsontype.BasicPolymorphicTypeValidator$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.BeanDescription
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.deser.impl.BeanAsArrayBuilderDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotatedMethodMap
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.SerializerProvider
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$OneAnnotation
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.StaticListSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.NumberSerializers$ShortSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.BeanSerializerFactory
[[1;33mWARNING[m]   - 647 more...
[[1;33mWARNING[m] okhttp-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 208 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.WebSocket
[[1;33mWARNING[m]   - okhttp3.Cookie$Builder
[[1;33mWARNING[m]   - okhttp3.internal.http.HttpHeaders
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$ReaderRunnable
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Reader$ContinuationSource
[[1;33mWARNING[m]   - okhttp3.internal.tls.OkHostnameVerifier
[[1;33mWARNING[m]   - okhttp3.Cache$Entry
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$3
[[1;33mWARNING[m]   - okhttp3.internal.ws.RealWebSocket$Streams
[[1;33mWARNING[m]   - okhttp3.CacheControl$Builder
[[1;33mWARNING[m]   - 198 more...
[[1;33mWARNING[m] maven-shade-plugin has detected that some class files are
[[1;33mWARNING[m] present in two or more JARs. When this happens, only one
[[1;33mWARNING[m] single version of the class is copied to the uber jar.
[[1;33mWARNING[m] Usually this is not harmful and you can skip these warnings,
[[1;33mWARNING[m] otherwise try to manually exclude artifacts based on
[[1;33mWARNING[m] mvn dependency:tree -Ddetail=true and the above output.
[[1;33mWARNING[m] See http://maven.apache.org/plugins/maven-shade-plugin/
[[1;34mINFO[m] Replacing original artifact with shaded artifact.
[[1;34mINFO[m] Replacing /home/cloud-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT.jar with /home/cloud-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-shaded.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------------< [0;36mio.strimzi:api[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding api 0.29.0-SNAPSHOT                                      [5/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/api/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1-eo)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-doc)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 99 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-test-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mapi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mapi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m------------------------< [0;36mio.strimzi:mockkube[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding mockkube 0.29.0-SNAPSHOT                                 [6/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/mockkube/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mmockkube[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mmockkube[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/mockkube/target/mockkube-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:config-model[0;1m >-----------------------[m
[[1;34mINFO[m] [1mBuilding config-model 0.29.0-SNAPSHOT                             [7/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/config-model/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/config-model/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mconfig-model[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mconfig-model[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/config-model/target/config-model-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------< [0;36mio.strimzi:certificate-manager[0;1m >-------------------[m
[[1;34mINFO[m] [1mBuilding certificate-manager 0.29.0-SNAPSHOT                      [8/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/certificate-manager/target/certificate-manager-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:operator-common[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding operator-common 0.29.0-SNAPSHOT                          [9/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/operator-common/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 9 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36moperator-common[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36moperator-common[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/operator-common/target/operator-common-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-----------------------< [0;36mio.strimzi:systemtest[0;1m >------------------------[m
[[1;34mINFO[m] [1mBuilding systemtest 0.29.0-SNAPSHOT                              [10/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 3 resources
[[1;34mINFO[m] Copying 2 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 32 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;33mWARNING[m] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file /home/cloud-user/strimzi-kafka-operator/systemtest/target/surefire-reports/2022-03-10T04-22-42_191-jvmRun1.dumpstream
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36msystemtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36msystemtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeTlsST
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlST
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.MultipleListenersST
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.ListenersST
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.metrics.MetricsIsolatedST
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.connect.ConnectIsolatedST
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-03-10 09:23:11 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeTlsST
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:220] Used environment variables:
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:221] CONFIG: /home/cloud-user/strimzi-kafka-operator/systemtest/config.json
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] STRIMZI_RBAC_SCOPE: CLUSTER
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OLM_APP_BUNDLE_PREFIX: strimzi-cluster-operator
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_CLIENTS_VERSION: 0.2.0
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OLM_SOURCE_NAMESPACE: openshift-marketplace
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] CLUSTER_OPERATOR_INSTALL_TYPE: BUNDLE
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] STRIMZI_COMPONENTS_LOG_LEVEL: INFO
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] SKIP_TEARDOWN: false
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] LB_FINALIZERS: false
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OLM_OPERATOR_DEPLOYMENT_NAME: strimzi-cluster-operator
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] DOCKER_ORG: strimzi
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_LOG_DIR: /home/cloud-user/strimzi-kafka-operator/systemtest/../systemtest/target/logs/
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] COMPONENTS_IMAGE_PULL_POLICY: IfNotPresent
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] DOCKER_REGISTRY: quay.io
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_CLIENT_IMAGE: quay.io/strimzi/test-client:latest-kafka-3.1.0
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] SYSTEM_TEST_STRIMZI_IMAGE_PULL_SECRET: 
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_ADMIN_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-admin:0.2.0-kafka-3.1.0
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_HTTP_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-http-producer:0.2.0
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OLM_OPERATOR_NAME: strimzi-kafka-operator
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] DOCKER_TAG: latest
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OLM_SOURCE_NAME: community-operators
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] STRIMZI_FEATURE_GATES: 
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] CLIENTS_KAFKA_VERSION: 3.1.0
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_HTTP_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-http-consumer:0.2.0
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] STRIMZI_LOG_LEVEL: DEBUG
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] ST_KAFKA_VERSION: 3.1.0
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OPERATOR_IMAGE_PULL_POLICY: Always
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] DEFAULT_TO_DENY_NETWORK_POLICIES: true
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-producer:0.2.0-kafka-3.1.0
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] BRIDGE_IMAGE: latest-released
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_STREAMS_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-streams:0.2.0-kafka-3.1.0
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-consumer:0.2.0-kafka-3.1.0
2022-03-10 09:23:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OLM_OPERATOR_VERSION: 0.26.1
2022-03-10 09:23:13 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeCluster:87] Using cluster: minikube
2022-03-10 09:23:13 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:60] Cluster default namespace is 'default'
2022-03-10 09:23:13 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:196] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@586734d4
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-03-10 09:23:13 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:260] Install ClusterOperator via Yaml bundle
2022-03-10 09:23:14 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-03-10 09:23:15 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-03-10 09:23:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 09:23:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 09:23:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 09:23:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 09:23:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 09:23:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 09:23:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 09:23:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 09:23:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 09:23:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 09:23:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 09:23:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 09:23:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 09:23:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 09:23:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 09:23:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 09:23:17 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-03-10 09:23:36 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-03-10 09:23:36 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-03-10 09:23:46 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-03-10 09:23:46 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: http-bridge-tls-st
2022-03-10 09:23:46 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: http-bridge-tls-st
2022-03-10 09:23:46 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: http-bridge-tls-st
2022-03-10 09:23:46 [ForkJoinPool-1-worker-3] [32mINFO [m [HttpBridgeTlsST:122] Deploy Kafka and KafkaBridge before tests
2022-03-10 09:23:46 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-03-10 09:23:46 [ForkJoinPool-1-worker-3] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkas' with unstable version 'v1beta2'
2022-03-10 09:23:46 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-tls-cluster-name will have desired state: Ready
2022-03-10 09:25:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-tls-cluster-name is in desired state: Ready
2022-03-10 09:25:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1464991083-1320148847 in namespace http-bridge-tls-st
2022-03-10 09:25:12 [ForkJoinPool-1-worker-3] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkausers' with unstable version 'v1beta2'
2022-03-10 09:25:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1464991083-1320148847 will have desired state: Ready
2022-03-10 09:25:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1464991083-1320148847 is in desired state: Ready
2022-03-10 09:25:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment http-bridge-tls-st-kafka-clients in namespace http-bridge-tls-st
2022-03-10 09:25:13 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: http-bridge-tls-st-kafka-clients will be ready
2022-03-10 09:25:16 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: http-bridge-tls-st-kafka-clients is ready
2022-03-10 09:25:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-03-10 09:25:17 [ForkJoinPool-1-worker-3] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkabridges' with unstable version 'v1beta2'
2022-03-10 09:25:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-tls-cluster-name will have desired state: Ready
2022-03-10 09:25:43 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-tls-cluster-name is in desired state: Ready
2022-03-10 09:25:43 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaClients:86] Consumer group were not specified going to create the random one.
2022-03-10 09:25:43 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 09:25:43 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testReceiveSimpleMessageTls-STARTED
2022-03-10 09:25:43 [ForkJoinPool-1-worker-7] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 09:25:43 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 09:25:43 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testSendSimpleMessageTls-STARTED
2022-03-10 09:25:43 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 09:25:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1316173636-1330503652 in namespace http-bridge-tls-st
2022-03-10 09:25:43 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-934342832-270911184 in namespace http-bridge-tls-st
2022-03-10 09:25:43 [ForkJoinPool-1-worker-7] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkatopics' with unstable version 'v1beta2'
2022-03-10 09:25:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1316173636-1330503652 will have desired state: Ready
2022-03-10 09:25:43 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-934342832-270911184 will have desired state: Ready
2022-03-10 09:25:44 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1316173636-1330503652 is in desired state: Ready
2022-03-10 09:25:44 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-934342832-270911184 is in desired state: Ready
2022-03-10 09:25:44 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-251174372 in namespace http-bridge-tls-st
2022-03-10 09:25:44 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:155] Create/Update Job producer-283057708 in namespace http-bridge-tls-st
2022-03-10 09:25:44 [ForkJoinPool-1-worker-7] [32mINFO [m [JobUtils:70] Waiting for job: consumer-251174372 will be in active state
2022-03-10 09:25:44 [ForkJoinPool-1-worker-5] [32mINFO [m [JobUtils:70] Waiting for job: producer-283057708 will be in active state
2022-03-10 09:25:44 [ForkJoinPool-1-worker-5] [32mINFO [m [ClientUtils:62] Waiting for producer/consumer:producer-283057708 to finished
2022-03-10 09:25:45 [ForkJoinPool-1-worker-7] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 09:25:45 [ForkJoinPool-1-worker-7] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@330da50d, messages=[], arguments=[--topic, my-topic-934342832-270911184, --max-messages, 100, --bootstrap-server, http-bridge-tls-cluster-name-kafka-bootstrap.http-bridge-tls-st.svc:9093, USER=my_user_1464991083_1320148847], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='http-bridge-tls-st-kafka-clients-8459b55c55-st4gc', podNamespace='http-bridge-tls-st', bootstrapServer='http-bridge-tls-cluster-name-kafka-bootstrap.http-bridge-tls-st.svc:9093', topicName='my-topic-934342832-270911184', maxMessages=100, kafkaUsername='my-user-1464991083-1320148847', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7fe16770}
2022-03-10 09:25:45 [ForkJoinPool-1-worker-7] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to http-bridge-tls-cluster-name-kafka-bootstrap.http-bridge-tls-st.svc:9093:my-topic-934342832-270911184 from pod http-bridge-tls-st-kafka-clients-8459b55c55-st4gc
2022-03-10 09:25:45 [ForkJoinPool-1-worker-7] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec http-bridge-tls-st-kafka-clients-8459b55c55-st4gc -n http-bridge-tls-st -- /opt/kafka/producer.sh --topic my-topic-934342832-270911184 --max-messages 100 --bootstrap-server http-bridge-tls-cluster-name-kafka-bootstrap.http-bridge-tls-st.svc:9093 USER=my_user_1464991083_1320148847
2022-03-10 09:25:52 [ForkJoinPool-1-worker-7] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-03-10 09:25:52 [ForkJoinPool-1-worker-7] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-03-10 09:25:52 [ForkJoinPool-1-worker-7] [32mINFO [m [ClientUtils:62] Waiting for producer/consumer:consumer-251174372 to finished
2022-03-10 09:25:53 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 09:25:53 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessageTls
2022-03-10 09:25:53 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job consumer-251174372 in namespace http-bridge-tls-st
2022-03-10 09:25:53 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-934342832-270911184 in namespace http-bridge-tls-st
2022-03-10 09:25:54 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 09:25:54 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5d127f75, messages=[], arguments=[--topic, my-topic-1316173636-1330503652, --max-messages, 100, --bootstrap-server, http-bridge-tls-cluster-name-kafka-bootstrap.http-bridge-tls-st.svc:9093, --group-id, my-consumer-group-1117658226, USER=my_user_1464991083_1320148847, --group-instance-id, instance1265288647], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='http-bridge-tls-st-kafka-clients-8459b55c55-st4gc', podNamespace='http-bridge-tls-st', bootstrapServer='http-bridge-tls-cluster-name-kafka-bootstrap.http-bridge-tls-st.svc:9093', topicName='my-topic-1316173636-1330503652', maxMessages=100, kafkaUsername='my-user-1464991083-1320148847', consumerGroupName='my-consumer-group-1117658226', consumerInstanceId='instance1265288647', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6cb3c828}
2022-03-10 09:25:54 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from http-bridge-tls-cluster-name-kafka-bootstrap.http-bridge-tls-st.svc:9093:my-topic-1316173636-1330503652 from pod http-bridge-tls-st-kafka-clients-8459b55c55-st4gc
2022-03-10 09:25:54 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec http-bridge-tls-st-kafka-clients-8459b55c55-st4gc -n http-bridge-tls-st -- /opt/kafka/consumer.sh --topic my-topic-1316173636-1330503652 --max-messages 100 --bootstrap-server http-bridge-tls-cluster-name-kafka-bootstrap.http-bridge-tls-st.svc:9093 --group-id my-consumer-group-1117658226 USER=my_user_1464991083_1320148847 --group-instance-id instance1265288647
2022-03-10 09:26:03 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 09:26:03 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testReceiveSimpleMessageTls-FINISHED
2022-03-10 09:26:03 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 09:26:04 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-03-10 09:26:04 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-03-10 09:26:04 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 09:26:04 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessageTls
2022-03-10 09:26:04 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job producer-283057708 in namespace http-bridge-tls-st
2022-03-10 09:26:04 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1316173636-1330503652 in namespace http-bridge-tls-st
2022-03-10 09:26:14 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 09:26:14 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testSendSimpleMessageTls-FINISHED
2022-03-10 09:26:14 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 09:26:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 09:26:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeTlsST
2022-03-10 09:26:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment http-bridge-tls-st-kafka-clients in namespace http-bridge-tls-st
2022-03-10 09:26:14 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1464991083-1320148847 in namespace http-bridge-tls-st
2022-03-10 09:26:14 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-03-10 09:26:24 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-03-10 09:26:54 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 229.929 s - in io.strimzi.systemtest.bridge.HttpBridgeTlsST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlST
2022-03-10 09:27:01 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-st
2022-03-10 09:27:01 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-st
2022-03-10 09:27:01 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-st
2022-03-10 09:27:01 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 09:27:01 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithRebalanceResourceAndRefreshAnnotation-STARTED
2022-03-10 09:27:01 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 09:27:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-35756d8b in namespace cruise-control-st
2022-03-10 09:27:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-35756d8b will have desired state: Ready
2022-03-10 09:30:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-35756d8b is in desired state: Ready
2022-03-10 09:30:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-35756d8b in namespace cruise-control-st
2022-03-10 09:30:35 [ForkJoinPool-1-worker-3] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkarebalances' with unstable version 'v1beta2'
2022-03-10 09:30:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-35756d8b will have desired state: PendingProposal
2022-03-10 09:30:36 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-35756d8b is in desired state: PendingProposal
2022-03-10 09:30:36 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #1(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): ============================================================================
2022-03-10 09:30:36 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #1(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): PendingProposal
2022-03-10 09:30:36 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #1(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): ============================================================================
2022-03-10 09:30:36 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:81] Reconciliation #1(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): Verifying that KafkaRebalance resource is in PendingProposal state
2022-03-10 09:30:36 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-35756d8b will have desired state: PendingProposal
2022-03-10 09:30:36 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-35756d8b is in desired state: PendingProposal
2022-03-10 09:30:36 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:85] Reconciliation #1(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): Verifying that KafkaRebalance resource is in ProposalReady state
2022-03-10 09:30:36 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-35756d8b will have desired state: ProposalReady
2022-03-10 09:35:32 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-35756d8b is in desired state: ProposalReady
2022-03-10 09:35:32 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #1(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): ============================================================================
2022-03-10 09:35:32 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #1(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): ProposalReady
2022-03-10 09:35:32 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #1(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): ============================================================================
2022-03-10 09:35:32 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #1(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-03-10 09:35:32 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #1(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): Annotating KafkaRebalance:my-cluster-35756d8b with annotation approve
2022-03-10 09:35:33 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #1(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-35756d8b annotated
2022-03-10 09:35:33 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #1(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): Verifying that annotation triggers the Rebalancing state
2022-03-10 09:35:33 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-35756d8b will have desired state: Rebalancing
2022-03-10 09:35:34 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-35756d8b is in desired state: Rebalancing
2022-03-10 09:35:34 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #1(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): Verifying that KafkaRebalance is in the Ready state
2022-03-10 09:35:34 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-35756d8b will have desired state: Ready
2022-03-10 09:36:40 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-35756d8b is in desired state: Ready
2022-03-10 09:36:40 [ForkJoinPool-1-worker-3] [32mINFO [m [CruiseControlST:154] Annotating KafkaRebalance: my-cluster-35756d8b with 'refresh' anno
2022-03-10 09:36:40 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #2(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): Annotating KafkaRebalance:my-cluster-35756d8b with annotation refresh
2022-03-10 09:36:40 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-35756d8b will have desired state: ProposalReady
2022-03-10 09:36:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-35756d8b is in desired state: ProposalReady
2022-03-10 09:36:41 [ForkJoinPool-1-worker-3] [32mINFO [m [CruiseControlST:158] Trying rebalancing process again
2022-03-10 09:36:41 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #3(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): ============================================================================
2022-03-10 09:36:41 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #3(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): ProposalReady
2022-03-10 09:36:41 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #3(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): ============================================================================
2022-03-10 09:36:41 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #3(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): ============================================================================
2022-03-10 09:36:41 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #3(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): ProposalReady
2022-03-10 09:36:41 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #3(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): ============================================================================
2022-03-10 09:36:41 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #3(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-03-10 09:36:41 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #3(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): Annotating KafkaRebalance:my-cluster-35756d8b with annotation approve
2022-03-10 09:36:41 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #3(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-35756d8b annotated
2022-03-10 09:36:41 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #3(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): Verifying that annotation triggers the Rebalancing state
2022-03-10 09:36:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-35756d8b will have desired state: Rebalancing
2022-03-10 09:36:42 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-35756d8b is in desired state: Rebalancing
2022-03-10 09:36:42 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #3(test) KafkaRebalance(cruise-control-st/my-cluster-35756d8b): Verifying that KafkaRebalance is in the Ready state
2022-03-10 09:36:42 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-35756d8b will have desired state: Ready
2022-03-10 09:36:47 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-35756d8b is in desired state: Ready
2022-03-10 09:36:47 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 09:36:47 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithRebalanceResourceAndRefreshAnnotation
2022-03-10 09:36:47 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-35756d8b in namespace cruise-control-st
2022-03-10 09:36:47 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-35756d8b in namespace cruise-control-st
2022-03-10 09:36:47 [ForkJoinPool-1-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-35756d8b
2022-03-10 09:36:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 09:36:57 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithRebalanceResourceAndRefreshAnnotation-FINISHED
2022-03-10 09:36:57 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 09:36:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 09:36:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:346] In context CruiseControlST is everything deleted.
2022-03-10 09:36:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 641.302 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
2022-03-10 09:37:42 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-api-st
2022-03-10 09:37:42 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-api-st
2022-03-10 09:37:42 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-api-st
2022-03-10 09:37:42 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 09:37:42 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequestsWithSecurityDisabled-STARTED
2022-03-10 09:37:42 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 09:37:42 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 09:37:42 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequests-STARTED
2022-03-10 09:37:42 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-0 for test case:testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-03-10 09:37:42 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-0
2022-03-10 09:37:43 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-0
2022-03-10 09:37:43 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-0
2022-03-10 09:37:43 [ForkJoinPool-1-worker-7] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 09:37:43 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-1 for test case:testCruiseControlBasicAPIRequests
2022-03-10 09:37:43 [ForkJoinPool-1-worker-7] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-1
2022-03-10 09:37:43 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka cruise-control-api-cluster-name in namespace namespace-0
2022-03-10 09:37:43 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-0
2022-03-10 09:37:43 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: cruise-control-api-cluster-name will have desired state: Ready
2022-03-10 09:37:43 [ForkJoinPool-1-worker-7] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-1
2022-03-10 09:37:43 [ForkJoinPool-1-worker-7] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-1
2022-03-10 09:37:43 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-04420cf2 in namespace namespace-1
2022-03-10 09:37:43 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-03-10 09:37:43 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-04420cf2 will have desired state: Ready
2022-03-10 09:47:47 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] Kafka: cruise-control-api-cluster-name is in desired state: Ready
2022-03-10 09:47:47 [ForkJoinPool-1-worker-3] [32mINFO [m [CruiseControlApiST:153] ----> CRUISE CONTROL DEPLOYMENT STATE ENDPOINT <----
2022-03-10 09:47:48 [ForkJoinPool-1-worker-3] [32mINFO [m [CruiseControlApiST:157] Verifying that Cruise Control REST API is available using HTTP request without credentials
2022-03-10 09:47:48 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 09:47:48 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-03-10 09:47:48 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka cruise-control-api-cluster-name in namespace namespace-0
2022-03-10 09:47:48 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-0, for cruise control Kafka cluster cruise-control-api-cluster-name
2022-03-10 09:47:58 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 09:47:58 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-0 for test case:testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-03-10 09:48:44 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequestsWithSecurityDisabled-FINISHED
2022-03-10 09:48:44 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 09:52:02 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-04420cf2 is in desired state: Ready
2022-03-10 09:52:02 [ForkJoinPool-1-worker-7] [32mINFO [m [CruiseControlApiST:48] ----> CRUISE CONTROL DEPLOYMENT STATE ENDPOINT <----
2022-03-10 09:52:03 [ForkJoinPool-1-worker-7] [32mINFO [m [CruiseControlApiST:58] Verifying that Cruise Control REST API is available
2022-03-10 09:53:23 [ForkJoinPool-1-worker-7] [32mINFO [m [CruiseControlApiST:66] ----> KAFKA REBALANCE <----
2022-03-10 09:53:24 [ForkJoinPool-1-worker-7] [32mINFO [m [CruiseControlApiST:73] Waiting for CC will have for enough metrics to be recorded to make a proposal 
2022-03-10 09:55:55 [ForkJoinPool-1-worker-7] [32mINFO [m [CruiseControlApiST:97] ----> EXECUTION OF STOP PROPOSAL <----
2022-03-10 09:55:56 [ForkJoinPool-1-worker-7] [32mINFO [m [CruiseControlApiST:108] ----> USER TASKS <----
2022-03-10 09:55:57 [ForkJoinPool-1-worker-7] [32mINFO [m [CruiseControlApiST:126] Verifying that Cruise Control REST API doesn't allow HTTP requests
2022-03-10 09:55:57 [ForkJoinPool-1-worker-7] [32mINFO [m [CruiseControlApiST:132] Verifying that Cruise Control REST API doesn't allow unauthenticated requests
2022-03-10 09:55:58 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 09:55:58 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlBasicAPIRequests
2022-03-10 09:55:58 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-04420cf2 in namespace namespace-1
2022-03-10 09:55:58 [ForkJoinPool-1-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-1, for cruise control Kafka cluster my-cluster-04420cf2
2022-03-10 09:56:08 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 09:56:08 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-1 for test case:testCruiseControlBasicAPIRequests
2022-03-10 09:56:53 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequests-FINISHED
2022-03-10 09:56:53 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 09:56:53 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 09:56:53 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:346] In context CruiseControlApiST is everything deleted.
2022-03-10 09:56:53 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,156.573 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.MultipleListenersST
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:294] Starting to generate test cases for multiple listeners
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:300] Generating INTERNAL listener
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:363] Generating listeners with type INTERNAL -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@8a201548, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@cb780164]
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:300] Generating ROUTE listener
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:363] Generating listeners with type ROUTE -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@ad3f1eb4]
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:300] Generating LOADBALANCER listener
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:363] Generating listeners with type LOADBALANCER -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@9e9edd65, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@ecf6eb73]
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:300] Generating NODEPORT listener
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:363] Generating listeners with type NODEPORT -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@4e69435b, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@8fc12f77, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@d1191b93, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@127107af]
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:300] Generating INGRESS listener
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:363] Generating listeners with type INGRESS -> []
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:367] Finished with generation of test cases for multiple listeners
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-listeners-st
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-listeners-st
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-listeners-st
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.MultipleListenersST.testCombinationOfInternalAndExternalListeners-STARTED
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:163] This is listeners [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@8a201548, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@cb780164, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@4e69435b, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@8fc12f77, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@d1191b93, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@127107af], which will verified.
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b0b6e3c2 in namespace multiple-listeners-st
2022-03-10 09:56:59 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b0b6e3c2 will have desired state: Ready
2022-03-10 10:04:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b0b6e3c2 is in desired state: Ready
2022-03-10 10:04:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-595015125-141725054 in namespace multiple-listeners-st
2022-03-10 10:04:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-595015125-141725054 will have desired state: Ready
2022-03-10 10:04:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-595015125-141725054 is in desired state: Ready
2022-03-10 10:04:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1387535948-1066115583 in namespace multiple-listeners-st
2022-03-10 10:04:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1387535948-1066115583 will have desired state: Ready
2022-03-10 10:04:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1387535948-1066115583 is in desired state: Ready
2022-03-10 10:04:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b0b6e3c2-kafka-clients-tls in namespace multiple-listeners-st
2022-03-10 10:04:12 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b0b6e3c2-kafka-clients-tls will be ready
2022-03-10 10:04:14 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b0b6e3c2-kafka-clients-tls is ready
2022-03-10 10:04:14 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 10:04:14 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:252] Checking produced and consumed messages to pod:my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw
2022-03-10 10:04:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1982119087-1299112184 in namespace multiple-listeners-st
2022-03-10 10:04:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1982119087-1299112184 will have desired state: Ready
2022-03-10 10:04:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1982119087-1299112184 is in desired state: Ready
2022-03-10 10:04:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ClientUtils:109] Sending messages to - topic my-topic-1387535948-1066115583, cluster my-cluster-b0b6e3c2 and message count of 100
2022-03-10 10:04:15 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@24ccde7a, messages=[], arguments=[--topic, my-topic-1982119087-1299112184, --max-messages, 100, --bootstrap-server, my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13900, USER=my_user_595015125_141725054], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13900', topicName='my-topic-1982119087-1299112184', maxMessages=100, kafkaUsername='my-user-595015125-141725054', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@e830cc4}
2022-03-10 10:04:15 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13900:my-topic-1982119087-1299112184 from pod my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw
2022-03-10 10:04:15 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw -n multiple-listeners-st -- /opt/kafka/producer.sh --topic my-topic-1982119087-1299112184 --max-messages 100 --bootstrap-server my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13900 USER=my_user_595015125_141725054
2022-03-10 10:04:21 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-03-10 10:04:21 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-03-10 10:04:21 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6ed27dc1, messages=[], arguments=[--topic, my-topic-1982119087-1299112184, --max-messages, 100, --bootstrap-server, my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13900, --group-id, my-consumer-group-2059179589, USER=my_user_595015125_141725054, --group-instance-id, instance982681831], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13900', topicName='my-topic-1982119087-1299112184', maxMessages=100, kafkaUsername='my-user-595015125-141725054', consumerGroupName='my-consumer-group-2059179589', consumerInstanceId='instance982681831', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@78a1ab3d}
2022-03-10 10:04:21 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13900:my-topic-1982119087-1299112184 from pod my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw
2022-03-10 10:04:21 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw -n multiple-listeners-st -- /opt/kafka/consumer.sh --topic my-topic-1982119087-1299112184 --max-messages 100 --bootstrap-server my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13900 --group-id my-consumer-group-2059179589 USER=my_user_595015125_141725054 --group-instance-id instance982681831
2022-03-10 10:04:32 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-03-10 10:04:32 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-03-10 10:04:32 [ForkJoinPool-1-worker-3] [32mINFO [m [ClientUtils:115] Sent 100 and received 100
2022-03-10 10:04:32 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-367119790-1843221624 in namespace multiple-listeners-st
2022-03-10 10:04:32 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-367119790-1843221624 will have desired state: Ready
2022-03-10 10:04:33 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-367119790-1843221624 is in desired state: Ready
2022-03-10 10:04:33 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b0b6e3c2-kafka-clients-tls in namespace multiple-listeners-st
2022-03-10 10:04:33 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b0b6e3c2-kafka-clients-tls will be ready
2022-03-10 10:04:33 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b0b6e3c2-kafka-clients-tls is ready
2022-03-10 10:04:33 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 10:04:33 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:252] Checking produced and consumed messages to pod:my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw
2022-03-10 10:04:33 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-556678297-2079465542 in namespace multiple-listeners-st
2022-03-10 10:04:33 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-556678297-2079465542 will have desired state: Ready
2022-03-10 10:04:34 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-556678297-2079465542 is in desired state: Ready
2022-03-10 10:04:34 [ForkJoinPool-1-worker-3] [32mINFO [m [ClientUtils:109] Sending messages to - topic my-topic-367119790-1843221624, cluster my-cluster-b0b6e3c2 and message count of 100
2022-03-10 10:04:34 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@329744b2, messages=[], arguments=[--topic, my-topic-556678297-2079465542, --max-messages, 100, --bootstrap-server, my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13901, USER=my_user_595015125_141725054], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13901', topicName='my-topic-556678297-2079465542', maxMessages=100, kafkaUsername='my-user-595015125-141725054', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@311e6d3d}
2022-03-10 10:04:34 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13901:my-topic-556678297-2079465542 from pod my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw
2022-03-10 10:04:34 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw -n multiple-listeners-st -- /opt/kafka/producer.sh --topic my-topic-556678297-2079465542 --max-messages 100 --bootstrap-server my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13901 USER=my_user_595015125_141725054
2022-03-10 10:04:41 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-03-10 10:04:41 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-03-10 10:04:41 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@612b271b, messages=[], arguments=[--topic, my-topic-556678297-2079465542, --max-messages, 100, --bootstrap-server, my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13901, --group-id, my-consumer-group-1799484225, USER=my_user_595015125_141725054, --group-instance-id, instance527509773], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13901', topicName='my-topic-556678297-2079465542', maxMessages=100, kafkaUsername='my-user-595015125-141725054', consumerGroupName='my-consumer-group-1799484225', consumerInstanceId='instance527509773', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@21ca436b}
2022-03-10 10:04:41 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13901:my-topic-556678297-2079465542 from pod my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw
2022-03-10 10:04:41 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b0b6e3c2-kafka-clients-tls-59998668db-j28fw -n multiple-listeners-st -- /opt/kafka/consumer.sh --topic my-topic-556678297-2079465542 --max-messages 100 --bootstrap-server my-cluster-b0b6e3c2-kafka-bootstrap.multiple-listeners-st.svc:13901 --group-id my-consumer-group-1799484225 USER=my_user_595015125_141725054 --group-instance-id instance527509773
2022-03-10 10:04:52 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-03-10 10:04:52 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-03-10 10:04:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ClientUtils:115] Sent 100 and received 100
2022-03-10 10:04:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1106698702-246518612 in namespace multiple-listeners-st
2022-03-10 10:04:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1106698702-246518612 will have desired state: Ready
2022-03-10 10:04:53 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1106698702-246518612 is in desired state: Ready
2022-03-10 10:04:53 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 10:04:53 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:204] Verifying tls listener
2022-03-10 10:04:53 [ForkJoinPool-1-worker-3] [32mINFO [m [ProducerConfig:376] ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.49.2:31098]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-160427302
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 6000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties8690905414941062304.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties4968870822473673476.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-03-10 10:04:54 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-03-10 10:04:54 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-03-10 10:04:54 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1646906693988
2022-03-10 10:04:54 [kafka-producer-network-thread | producer-160427302] [32mINFO [m [Metadata:402] [Producer clientId=producer-160427302] Resetting the last seen epoch of partition my-topic-1106698702-246518612-0 to 0 since the associated topicId changed from null to DBZHvWAOSECp0S3w5f4ugw
2022-03-10 10:04:54 [kafka-producer-network-thread | producer-160427302] [32mINFO [m [Metadata:287] [Producer clientId=producer-160427302] Cluster ID: BpQYqIr8TJa50e6ap-LTQg
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ExternalKafkaClient:182] Sent 100 messages.
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaProducer:1228] [Producer clientId=producer-160427302] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:83] App info kafka.producer for producer-160427302 unregistered
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerConfig:376] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.49.2:31098]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-759519030
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-1349492495
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties16821956437134610372.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties14966729796412928566.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1646906696715
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaConsumer:966] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Subscribed to topic(s): my-topic-1106698702-246518612
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [Metadata:402] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Resetting the last seen epoch of partition my-topic-1106698702-246518612-0 to 0 since the associated topicId changed from null to DBZHvWAOSECp0S3w5f4ugw
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [Metadata:287] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Cluster ID: BpQYqIr8TJa50e6ap-LTQg
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:853] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Discovered group coordinator 192.168.49.2:31862 (id: 2147483645 rack: null)
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:535] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] (Re-)joining group
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1000] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Request joining group due to: need to re-join with the given member-id
2022-03-10 10:04:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:535] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] (Re-)joining group
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:595] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Successfully joined group with generation Generation{generationId=1, memberId='consumer-759519030-4a662167-9c93-44cb-aec5-1c2f46fa7180', protocol='range'}
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:652] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Finished assignment for group at generation 1: {consumer-759519030-4a662167-9c93-44cb-aec5-1c2f46fa7180=Assignment(partitions=[my-topic-1106698702-246518612-0])}
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:761] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Successfully synced group in generation Generation{generationId=1, memberId='consumer-759519030-4a662167-9c93-44cb-aec5-1c2f46fa7180', protocol='range'}
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:279] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Notifying assignor about the new Assignment(partitions=[my-topic-1106698702-246518612-0])
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:291] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Adding newly assigned partitions: my-topic-1106698702-246518612-0
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1388] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Found no committed offset for partition my-topic-1106698702-246518612-0
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [SubscriptionState:398] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Resetting offset for partition my-topic-1106698702-246518612-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.49.2:31862 (id: 2 rack: null)], epoch=0}}.
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ExternalKafkaClient:224] Received 100 messages.
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:310] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Revoke previously assigned partitions my-topic-1106698702-246518612-0
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1060] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Member consumer-759519030-4a662167-9c93-44cb-aec5-1c2f46fa7180 sending LeaveGroup request to coordinator 192.168.49.2:31862 (id: 2147483645 rack: null) due to the consumer is being closed
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:972] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Resetting generation due to: consumer pro-actively leaving the group
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1000] [Consumer clientId=consumer-759519030, groupId=my-consumer-group-1349492495] Request joining group due to: consumer pro-actively leaving the group
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:83] App info kafka.consumer for consumer-759519030 unregistered
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1594629411-647631182 in namespace multiple-listeners-st
2022-03-10 10:05:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1594629411-647631182 will have desired state: Ready
2022-03-10 10:05:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1594629411-647631182 is in desired state: Ready
2022-03-10 10:05:01 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 10:05:01 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:204] Verifying tls listener
2022-03-10 10:05:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ProducerConfig:376] ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.49.2:31424]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-79264087
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 6000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties11140794203314630249.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties7397406641199853541.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-03-10 10:05:01 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-03-10 10:05:01 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-03-10 10:05:01 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1646906701826
2022-03-10 10:05:01 [kafka-producer-network-thread | producer-79264087] [32mINFO [m [Metadata:402] [Producer clientId=producer-79264087] Resetting the last seen epoch of partition my-topic-1594629411-647631182-0 to 0 since the associated topicId changed from null to kIh8qUrnTQOhMuOEw7q8Rw
2022-03-10 10:05:01 [kafka-producer-network-thread | producer-79264087] [32mINFO [m [Metadata:287] [Producer clientId=producer-79264087] Cluster ID: BpQYqIr8TJa50e6ap-LTQg
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [ExternalKafkaClient:182] Sent 100 messages.
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaProducer:1228] [Producer clientId=producer-79264087] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:83] App info kafka.producer for producer-79264087 unregistered
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerConfig:376] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.49.2:31424]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-127879153
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-1777302877
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties12932666720107179636.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties2984095513607435691.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1646906703316
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaConsumer:966] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Subscribed to topic(s): my-topic-1594629411-647631182
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [Metadata:402] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Resetting the last seen epoch of partition my-topic-1594629411-647631182-0 to 0 since the associated topicId changed from null to kIh8qUrnTQOhMuOEw7q8Rw
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [Metadata:287] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Cluster ID: BpQYqIr8TJa50e6ap-LTQg
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:853] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Discovered group coordinator 192.168.49.2:30958 (id: 2147483646 rack: null)
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:535] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] (Re-)joining group
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1000] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Request joining group due to: need to re-join with the given member-id
2022-03-10 10:05:03 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:535] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] (Re-)joining group
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:595] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Successfully joined group with generation Generation{generationId=1, memberId='consumer-127879153-b38e434d-7d4c-460b-91f9-9e4edc65c1e1', protocol='range'}
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:652] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Finished assignment for group at generation 1: {consumer-127879153-b38e434d-7d4c-460b-91f9-9e4edc65c1e1=Assignment(partitions=[my-topic-1594629411-647631182-0])}
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:761] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Successfully synced group in generation Generation{generationId=1, memberId='consumer-127879153-b38e434d-7d4c-460b-91f9-9e4edc65c1e1', protocol='range'}
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:279] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Notifying assignor about the new Assignment(partitions=[my-topic-1594629411-647631182-0])
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:291] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Adding newly assigned partitions: my-topic-1594629411-647631182-0
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1388] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Found no committed offset for partition my-topic-1594629411-647631182-0
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [SubscriptionState:398] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Resetting offset for partition my-topic-1594629411-647631182-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.49.2:30413 (id: 0 rack: null)], epoch=0}}.
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ExternalKafkaClient:224] Received 100 messages.
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:310] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Revoke previously assigned partitions my-topic-1594629411-647631182-0
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1060] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Member consumer-127879153-b38e434d-7d4c-460b-91f9-9e4edc65c1e1 sending LeaveGroup request to coordinator 192.168.49.2:30958 (id: 2147483646 rack: null) due to the consumer is being closed
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:972] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Resetting generation due to: consumer pro-actively leaving the group
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1000] [Consumer clientId=consumer-127879153, groupId=my-consumer-group-1777302877] Request joining group due to: consumer pro-actively leaving the group
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:83] App info kafka.consumer for consumer-127879153 unregistered
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-575167757-484018616 in namespace multiple-listeners-st
2022-03-10 10:05:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-575167757-484018616 will have desired state: Ready
2022-03-10 10:05:07 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-575167757-484018616 is in desired state: Ready
2022-03-10 10:05:07 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 10:05:07 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:204] Verifying tls listener
2022-03-10 10:05:07 [ForkJoinPool-1-worker-3] [32mINFO [m [ProducerConfig:376] ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.49.2:30538]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1816634435
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 6000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties17264635405912744638.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties11369081400621178802.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-03-10 10:05:07 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-03-10 10:05:07 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-03-10 10:05:07 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1646906707817
2022-03-10 10:05:07 [kafka-producer-network-thread | producer-1816634435] [32mINFO [m [Metadata:402] [Producer clientId=producer-1816634435] Resetting the last seen epoch of partition my-topic-575167757-484018616-0 to 0 since the associated topicId changed from null to u_QTfnVPTDCD5UYAJn3niw
2022-03-10 10:05:07 [kafka-producer-network-thread | producer-1816634435] [32mINFO [m [Metadata:287] [Producer clientId=producer-1816634435] Cluster ID: BpQYqIr8TJa50e6ap-LTQg
2022-03-10 10:05:08 [ForkJoinPool-1-worker-3] [32mINFO [m [ExternalKafkaClient:182] Sent 100 messages.
2022-03-10 10:05:08 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaProducer:1228] [Producer clientId=producer-1816634435] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-03-10 10:05:08 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-03-10 10:05:08 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-03-10 10:05:08 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-03-10 10:05:08 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:83] App info kafka.producer for producer-1816634435 unregistered
2022-03-10 10:05:08 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerConfig:376] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.49.2:30538]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-1450449494
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-1190097953
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties15577925873624861053.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties13335444526576982425.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-03-10 10:05:08 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-03-10 10:05:08 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-03-10 10:05:08 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1646906708741
2022-03-10 10:05:08 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaConsumer:966] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Subscribed to topic(s): my-topic-575167757-484018616
2022-03-10 10:05:08 [ForkJoinPool-1-worker-3] [32mINFO [m [Metadata:402] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Resetting the last seen epoch of partition my-topic-575167757-484018616-0 to 0 since the associated topicId changed from null to u_QTfnVPTDCD5UYAJn3niw
2022-03-10 10:05:08 [ForkJoinPool-1-worker-3] [32mINFO [m [Metadata:287] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Cluster ID: BpQYqIr8TJa50e6ap-LTQg
2022-03-10 10:05:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:853] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Discovered group coordinator 192.168.49.2:31057 (id: 2147483647 rack: null)
2022-03-10 10:05:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:535] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] (Re-)joining group
2022-03-10 10:05:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1000] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Request joining group due to: need to re-join with the given member-id
2022-03-10 10:05:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:535] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] (Re-)joining group
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:595] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Successfully joined group with generation Generation{generationId=1, memberId='consumer-1450449494-4c39609a-b2e1-4d14-bcd9-c47fd6efd3a8', protocol='range'}
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:652] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Finished assignment for group at generation 1: {consumer-1450449494-4c39609a-b2e1-4d14-bcd9-c47fd6efd3a8=Assignment(partitions=[my-topic-575167757-484018616-0])}
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:761] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Successfully synced group in generation Generation{generationId=1, memberId='consumer-1450449494-4c39609a-b2e1-4d14-bcd9-c47fd6efd3a8', protocol='range'}
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:279] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Notifying assignor about the new Assignment(partitions=[my-topic-575167757-484018616-0])
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:291] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Adding newly assigned partitions: my-topic-575167757-484018616-0
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1388] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Found no committed offset for partition my-topic-575167757-484018616-0
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [SubscriptionState:398] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Resetting offset for partition my-topic-575167757-484018616-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.49.2:31057 (id: 0 rack: null)], epoch=0}}.
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ExternalKafkaClient:224] Received 100 messages.
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:310] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Revoke previously assigned partitions my-topic-575167757-484018616-0
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1060] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Member consumer-1450449494-4c39609a-b2e1-4d14-bcd9-c47fd6efd3a8 sending LeaveGroup request to coordinator 192.168.49.2:31057 (id: 2147483647 rack: null) due to the consumer is being closed
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:972] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Resetting generation due to: consumer pro-actively leaving the group
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1000] [Consumer clientId=consumer-1450449494, groupId=my-consumer-group-1190097953] Request joining group due to: consumer pro-actively leaving the group
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:83] App info kafka.consumer for consumer-1450449494 unregistered
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1532162670-871927687 in namespace multiple-listeners-st
2022-03-10 10:05:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1532162670-871927687 will have desired state: Ready
2022-03-10 10:05:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1532162670-871927687 is in desired state: Ready
2022-03-10 10:05:13 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 10:05:13 [ForkJoinPool-1-worker-3] [32mINFO [m [MultipleListenersST:204] Verifying tls listener
2022-03-10 10:05:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ProducerConfig:376] ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.49.2:31994]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1351538254
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 6000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties5701223962797640987.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties14844941228415695104.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-03-10 10:05:13 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-03-10 10:05:13 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-03-10 10:05:13 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1646906713545
2022-03-10 10:05:13 [kafka-producer-network-thread | producer-1351538254] [32mINFO [m [Metadata:402] [Producer clientId=producer-1351538254] Resetting the last seen epoch of partition my-topic-1532162670-871927687-0 to 0 since the associated topicId changed from null to dcqFUCiKRKiU6LsLXRrFVw
2022-03-10 10:05:13 [kafka-producer-network-thread | producer-1351538254] [32mINFO [m [Metadata:287] [Producer clientId=producer-1351538254] Cluster ID: BpQYqIr8TJa50e6ap-LTQg
2022-03-10 10:05:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ExternalKafkaClient:182] Sent 100 messages.
2022-03-10 10:05:14 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaProducer:1228] [Producer clientId=producer-1351538254] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-03-10 10:05:14 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-03-10 10:05:14 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-03-10 10:05:14 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-03-10 10:05:14 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:83] App info kafka.producer for producer-1351538254 unregistered
2022-03-10 10:05:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerConfig:376] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.49.2:31994]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-917174568
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-108948723
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties5041480676007112823.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties17853929666343823965.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-03-10 10:05:14 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-03-10 10:05:14 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-03-10 10:05:14 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1646906714731
2022-03-10 10:05:14 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaConsumer:966] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Subscribed to topic(s): my-topic-1532162670-871927687
2022-03-10 10:05:14 [ForkJoinPool-1-worker-3] [32mINFO [m [Metadata:402] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Resetting the last seen epoch of partition my-topic-1532162670-871927687-0 to 0 since the associated topicId changed from null to dcqFUCiKRKiU6LsLXRrFVw
2022-03-10 10:05:14 [ForkJoinPool-1-worker-3] [32mINFO [m [Metadata:287] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Cluster ID: BpQYqIr8TJa50e6ap-LTQg
2022-03-10 10:05:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:853] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Discovered group coordinator 192.168.49.2:31822 (id: 2147483647 rack: null)
2022-03-10 10:05:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:535] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] (Re-)joining group
2022-03-10 10:05:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1000] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Request joining group due to: need to re-join with the given member-id
2022-03-10 10:05:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:535] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] (Re-)joining group
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:595] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Successfully joined group with generation Generation{generationId=1, memberId='consumer-917174568-b4706643-95b6-40a2-b649-a94e01c4568d', protocol='range'}
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:652] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Finished assignment for group at generation 1: {consumer-917174568-b4706643-95b6-40a2-b649-a94e01c4568d=Assignment(partitions=[my-topic-1532162670-871927687-0])}
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:761] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Successfully synced group in generation Generation{generationId=1, memberId='consumer-917174568-b4706643-95b6-40a2-b649-a94e01c4568d', protocol='range'}
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:279] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Notifying assignor about the new Assignment(partitions=[my-topic-1532162670-871927687-0])
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:291] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Adding newly assigned partitions: my-topic-1532162670-871927687-0
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1388] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Found no committed offset for partition my-topic-1532162670-871927687-0
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [SubscriptionState:398] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Resetting offset for partition my-topic-1532162670-871927687-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.49.2:31822 (id: 0 rack: null)], epoch=0}}.
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ExternalKafkaClient:224] Received 100 messages.
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:310] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Revoke previously assigned partitions my-topic-1532162670-871927687-0
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1060] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Member consumer-917174568-b4706643-95b6-40a2-b649-a94e01c4568d sending LeaveGroup request to coordinator 192.168.49.2:31822 (id: 2147483647 rack: null) due to the consumer is being closed
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:972] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Resetting generation due to: consumer pro-actively leaving the group
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ConsumerCoordinator:1000] [Consumer clientId=consumer-917174568, groupId=my-consumer-group-108948723] Request joining group due to: consumer pro-actively leaving the group
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [AppInfoParser:83] App info kafka.consumer for consumer-917174568 unregistered
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for testCombinationOfInternalAndExternalListeners
2022-03-10 10:05:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-556678297-2079465542 in namespace multiple-listeners-st
2022-03-10 10:05:18 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b0b6e3c2-kafka-clients-tls in namespace multiple-listeners-st
2022-03-10 10:05:18 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-595015125-141725054 in namespace multiple-listeners-st
2022-03-10 10:05:28 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1387535948-1066115583 in namespace multiple-listeners-st
2022-03-10 10:05:28 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1106698702-246518612 in namespace multiple-listeners-st
2022-03-10 10:05:38 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b0b6e3c2-kafka-clients-tls in namespace multiple-listeners-st
2022-03-10 10:05:38 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b0b6e3c2 in namespace multiple-listeners-st
2022-03-10 10:05:48 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-367119790-1843221624 in namespace multiple-listeners-st
2022-03-10 10:05:58 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1982119087-1299112184 in namespace multiple-listeners-st
2022-03-10 10:06:08 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-575167757-484018616 in namespace multiple-listeners-st
2022-03-10 10:06:08 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1594629411-647631182 in namespace multiple-listeners-st
2022-03-10 10:06:08 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1532162670-871927687 in namespace multiple-listeners-st
2022-03-10 10:06:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:06:18 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.MultipleListenersST.testCombinationOfInternalAndExternalListeners-FINISHED
2022-03-10 10:06:18 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:06:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:06:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:346] In context MultipleListenersST is everything deleted.
2022-03-10 10:06:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 566.733 s - in io.strimzi.systemtest.kafka.listeners.MultipleListenersST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.ListenersST
2022-03-10 10:06:30 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: listeners-st
2022-03-10 10:06:30 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: listeners-st
2022-03-10 10:06:30 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: listeners-st
2022-03-10 10:06:30 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:06:30 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-STARTED
2022-03-10 10:06:30 [ForkJoinPool-1-worker-7] [32mINFO [m [OpenShiftOnlyCondition:25] testCustomSoloCertificatesForRoute is @OpenShiftOnly, but the running cluster is not OpenShift: Ignoring testCustomSoloCertificatesForRoute
2022-03-10 10:06:30 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:06:30 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-2 for test case:testSendMessagesCustomListenerTlsScramSha
2022-03-10 10:06:30 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:06:30 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-STARTED
2022-03-10 10:06:30 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-2
2022-03-10 10:06:30 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-2
2022-03-10 10:06:30 [ForkJoinPool-1-worker-1] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-2
2022-03-10 10:06:30 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:06:30 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-3 for test case:testSendMessagesTlsScramSha
2022-03-10 10:06:30 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-3
2022-03-10 10:06:30 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-69d81b71 in namespace namespace-2
2022-03-10 10:06:30 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-03-10 10:06:30 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-69d81b71 will have desired state: Ready
2022-03-10 10:06:30 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-3
2022-03-10 10:06:30 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-3
2022-03-10 10:06:30 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-eef994b8 in namespace namespace-3
2022-03-10 10:06:30 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-03-10 10:06:30 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-eef994b8 will have desired state: Ready
2022-03-10 10:20:30 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:414] Kafka status:

Conditions:
	Type: NotReady
	Message: Exceeded timeout of 300000ms while waiting for StatefulSet resource my-cluster-69d81b71-kafka in namespace namespace-2 to be ready

Pods with conditions and messages:

my-cluster-69d81b71-kafka-0:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-69d81b71-kafka-1:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: Ready
	Message: containers with unready status: [kafka]

	Type: ContainersReady
	Message: containers with unready status: [kafka]

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-69d81b71-kafka-2:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: Ready
	Message: containers with unready status: [kafka]

	Type: ContainersReady
	Message: containers with unready status: [kafka]

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-69d81b71-zookeeper-0:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-69d81b71-zookeeper-1:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-69d81b71-zookeeper-2:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>
2022-03-10 10:20:30 [ForkJoinPool-1-worker-1] [1;31mERROR[m [TestExecutionWatcher:28] ListenersST - Exception Timeout after 840000 ms waiting for Resource condition: readiness is fulfilled for resource Kafka:my-cluster-69d81b71 has been thrown in @Test. Going to collect logs from components.
2022-03-10 10:20:30 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-03-10 10:20:30 [ForkJoinPool-1-worker-3] [1;31mERROR[m [TestUtils:162] Exception waiting for Kafka: my-cluster-eef994b8 will have desired state: Ready, null
2022-03-10 10:20:30 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:414] Kafka status:

Conditions:
	Type: NotReady
	Message: Exceeded timeout of 300000ms while waiting for StatefulSet resource my-cluster-eef994b8-kafka in namespace namespace-3 to be ready

Pods with conditions and messages:

my-cluster-eef994b8-kafka-0:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: Ready
	Message: containers with unready status: [kafka]

	Type: ContainersReady
	Message: containers with unready status: [kafka]

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-eef994b8-kafka-1:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-eef994b8-kafka-2:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-eef994b8-zookeeper-0:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-eef994b8-zookeeper-1:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-eef994b8-zookeeper-2:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>
2022-03-10 10:20:30 [ForkJoinPool-1-worker-3] [1;31mERROR[m [TestExecutionWatcher:28] ListenersST - Exception Timeout after 840000 ms waiting for Resource condition: readiness is fulfilled for resource Kafka:my-cluster-eef994b8 has been thrown in @Test. Going to collect logs from components.
2022-03-10 10:20:31 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-03-10 10:20:31 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-03-10 10:20:32 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-03-10 10:20:32 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-03-10 10:20:32 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-03-10 10:20:32 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-03-10 10:20:33 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-03-10 10:20:33 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:252] Collecting events in Namespace namespace-2
2022-03-10 10:20:33 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace namespace-2
2022-03-10 10:20:33 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace namespace-2
2022-03-10 10:20:35 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace namespace-2
2022-03-10 10:20:36 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace namespace-2
2022-03-10 10:20:36 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace namespace-2
2022-03-10 10:20:36 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace namespace-2
2022-03-10 10:20:37 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-03-10 10:20:37 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:252] Collecting events in Namespace listeners-st
2022-03-10 10:20:37 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace listeners-st
2022-03-10 10:20:37 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace listeners-st
2022-03-10 10:20:37 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace listeners-st
2022-03-10 10:20:37 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace listeners-st
2022-03-10 10:20:38 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace listeners-st
2022-03-10 10:20:38 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace listeners-st
2022-03-10 10:20:39 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-03-10 10:20:39 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-03-10 10:20:39 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:20:39 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesCustomListenerTlsScramSha
2022-03-10 10:20:39 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-69d81b71 in namespace namespace-2
2022-03-10 10:20:39 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-03-10 10:20:39 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-03-10 10:20:40 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-03-10 10:20:41 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-03-10 10:20:41 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-03-10 10:20:41 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-03-10 10:20:42 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-03-10 10:20:42 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:252] Collecting events in Namespace namespace-3
2022-03-10 10:20:42 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace namespace-3
2022-03-10 10:20:42 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace namespace-3
2022-03-10 10:20:44 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace namespace-3
2022-03-10 10:20:44 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace namespace-3
2022-03-10 10:20:45 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace namespace-3
2022-03-10 10:20:45 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace namespace-3
2022-03-10 10:20:45 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-03-10 10:20:45 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:252] Collecting events in Namespace listeners-st
2022-03-10 10:20:45 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace listeners-st
2022-03-10 10:20:46 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace listeners-st
2022-03-10 10:20:46 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace listeners-st
2022-03-10 10:20:46 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace listeners-st
2022-03-10 10:20:46 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace listeners-st
2022-03-10 10:20:46 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace listeners-st
2022-03-10 10:20:47 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-03-10 10:20:47 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:20:47 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesTlsScramSha
2022-03-10 10:20:47 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-eef994b8 in namespace namespace-3
2022-03-10 10:20:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:20:49 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-2 for test case:testSendMessagesCustomListenerTlsScramSha
2022-03-10 10:20:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:20:57 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-3 for test case:testSendMessagesTlsScramSha
2022-03-10 10:21:09 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-FINISHED
2022-03-10 10:21:09 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:21:16 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-FINISHED
2022-03-10 10:21:16 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:21:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:21:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:346] In context ListenersST is everything deleted.
2022-03-10 10:21:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 3, Failures: 0, Errors: 2, Skipped: 1, Time elapsed: 895.836 s <<< FAILURE! - in io.strimzi.systemtest.kafka.listeners.ListenersST
[[1;31mERROR[m] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha(ExtensionContext)  Time elapsed: 878.671 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 840000 ms waiting for Resource condition: readiness is fulfilled for resource Kafka:my-cluster-eef994b8
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha(ListenersST.java:322)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:396)
	at java.base/java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:721)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.joinConcurrentTasksInReverseOrderToEnableWorkStealing(ForkJoinPoolHierarchicalTestExecutorService.java:162)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.invokeAll(ForkJoinPoolHierarchicalTestExecutorService.java:136)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.executeNonConcurrentTasks(ForkJoinPoolHierarchicalTestExecutorService.java:155)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.invokeAll(ForkJoinPoolHierarchicalTestExecutorService.java:135)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)

[[1;31mERROR[m] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha(ExtensionContext)  Time elapsed: 885.727 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 840000 ms waiting for Resource condition: readiness is fulfilled for resource Kafka:my-cluster-69d81b71
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha(ListenersST.java:401)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)

[[1;34mINFO[m] Running io.strimzi.systemtest.metrics.MetricsIsolatedST
2022-03-10 10:21:21 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-03-10 10:21:46 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:594] ============================================================================
2022-03-10 10:21:46 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:595] Un-installing cluster operator from infra-namespace namespace
2022-03-10 10:21:46 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:596] ============================================================================
2022-03-10 10:21:46 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:21:46 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-03-10 10:21:46 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 10:21:46 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 10:21:46 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 10:21:47 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 10:21:47 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-03-10 10:21:47 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:21:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:21:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 10:21:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 10:21:57 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 10:21:57 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 10:21:57 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:21:57 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 10:21:57 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:07 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:07 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:07 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 10:22:07 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 10:22:07 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 10:22:07 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 10:22:07 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 10:22:07 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:22:07 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:17 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:18 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:28 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:22:33 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:196] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@586734d4
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace,second-metrics-cluster-test
bindingsNamespaces=[infra-namespace, second-metrics-cluster-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-03-10 10:22:33 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:260] Install ClusterOperator via Yaml bundle
2022-03-10 10:22:33 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-03-10 10:22:33 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-metrics-cluster-test
2022-03-10 10:22:33 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-03-10 10:22:33 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:22:33 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 10:22:33 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 10:22:33 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 10:22:33 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 10:22:33 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 10:22:34 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:34 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:34 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 10:22:34 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:34 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:34 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-metrics-cluster-test
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-metrics-cluster-test
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-metrics-cluster-test
2022-03-10 10:22:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:22:36 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-03-10 10:23:11 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-03-10 10:23:11 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-03-10 10:23:21 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-03-10 10:23:21 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-03-10 10:23:21 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka metrics-cluster-name in namespace infra-namespace
2022-03-10 10:23:21 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka second-kafka-cluster in namespace second-metrics-cluster-test
2022-03-10 10:23:21 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-kafka-clients in namespace infra-namespace
2022-03-10 10:23:21 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-metrics-cluster-test-kafka-clients in namespace second-metrics-cluster-test
2022-03-10 10:23:21 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: metrics-cluster-name will have desired state: Ready
2022-03-10 10:35:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] Kafka: metrics-cluster-name is in desired state: Ready
2022-03-10 10:35:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: second-kafka-cluster will have desired state: Ready
2022-03-10 10:35:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] Kafka: second-kafka-cluster is in desired state: Ready
2022-03-10 10:35:17 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-kafka-clients will be ready
2022-03-10 10:35:17 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-kafka-clients is ready
2022-03-10 10:35:17 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-metrics-cluster-test-kafka-clients will be ready
2022-03-10 10:35:17 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: second-metrics-cluster-test-kafka-clients is ready
2022-03-10 10:35:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-bridge in namespace infra-namespace
2022-03-10 10:35:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-bridge will have desired state: Ready
2022-03-10 10:35:42 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaBridge: my-bridge is in desired state: Ready
2022-03-10 10:35:42 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 mm2-cluster in namespace infra-namespace
2022-03-10 10:35:42 [ForkJoinPool-1-worker-3] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkamirrormaker2s' with unstable version 'v1beta2'
2022-03-10 10:35:42 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: mm2-cluster will have desired state: Ready
2022-03-10 10:36:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: mm2-cluster is in desired state: Ready
2022-03-10 10:36:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-346885214-1565180398 in namespace infra-namespace
2022-03-10 10:36:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-346885214-1565180398 will have desired state: Ready
2022-03-10 10:36:54 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-346885214-1565180398 is in desired state: Ready
2022-03-10 10:36:54 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1098814858-1484970824 in namespace infra-namespace
2022-03-10 10:36:54 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1098814858-1484970824 will have desired state: Ready
2022-03-10 10:36:55 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1098814858-1484970824 is in desired state: Ready
2022-03-10 10:36:55 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-184723579-1847670732 in namespace infra-namespace
2022-03-10 10:36:55 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-184723579-1847670732 will have desired state: Ready
2022-03-10 10:36:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-184723579-1847670732 is in desired state: Ready
2022-03-10 10:36:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1859828938-987165425 in namespace infra-namespace
2022-03-10 10:36:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1859828938-987165425 will have desired state: Ready
2022-03-10 10:36:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1859828938-987165425 is in desired state: Ready
2022-03-10 10:36:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1431662579-819461059 in namespace infra-namespace
2022-03-10 10:36:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1431662579-819461059 will have desired state: Ready
2022-03-10 10:36:58 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1431662579-819461059 is in desired state: Ready
2022-03-10 10:36:58 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect metrics-cluster-name in namespace infra-namespace
2022-03-10 10:36:58 [ForkJoinPool-1-worker-3] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkaconnects' with unstable version 'v1beta2'
2022-03-10 10:36:58 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: metrics-cluster-name will have desired state: Ready
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaConnect: metrics-cluster-name is in desired state: Ready
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:72] Apply NetworkPolicy access to cluster-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy cluster-operator-allow in namespace infra-namespace
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:90] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:104] Apply NetworkPolicy access to metrics-cluster-name-entity-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy metrics-cluster-name-entity-operator-allow in namespace infra-namespace
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:128] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:104] Apply NetworkPolicy access to second-kafka-cluster-entity-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy second-kafka-cluster-entity-operator-allow in namespace second-metrics-cluster-test
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:128] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:141] Apply NetworkPolicy access to metrics-cluster-name-kafka-exporter from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy metrics-cluster-name-kafka-exporter-allow in namespace infra-namespace
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:161] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:141] Apply NetworkPolicy access to second-kafka-cluster-kafka-exporter from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy second-kafka-cluster-kafka-exporter-allow in namespace second-metrics-cluster-test
2022-03-10 10:38:05 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:161] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-03-10 10:39:30 [ForkJoinPool-1-worker-3] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:34 [ForkJoinPool-1-worker-3] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.16 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:38 [ForkJoinPool-1-worker-3] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.15 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:40 [ForkJoinPool-1-worker-3] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:41 [ForkJoinPool-1-worker-3] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:42 [ForkJoinPool-1-worker-3] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:44 [ForkJoinPool-1-worker-3] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:47 [ForkJoinPool-1-worker-3] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.21 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:47 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:39:47 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testUserOperatorMetrics-STARTED
2022-03-10 10:39:47 [ForkJoinPool-1-worker-7] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:39:47 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:39:47 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperQuorumSize-STARTED
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBrokersCount-STARTED
2022-03-10 10:39:47 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:39:47 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:39:47 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:346] In context testZookeeperQuorumSize is everything deleted.
2022-03-10 10:39:47 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:39:47 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperQuorumSize-FINISHED
2022-03-10 10:39:47 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:39:47 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:39:47 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testMirrorMaker2Metrics-STARTED
2022-03-10 10:39:47 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:346] In context testKafkaBrokersCount is everything deleted.
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBrokersCount-FINISHED
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBridgeMetrics-STARTED
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [KafkaClients:86] Consumer group were not specified going to create the random one.
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer in namespace infra-namespace
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [JobUtils:70] Waiting for job: bridge-producer will be in active state
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-consumer in namespace infra-namespace
2022-03-10 10:39:47 [ForkJoinPool-1-worker-5] [32mINFO [m [JobUtils:70] Waiting for job: bridge-consumer will be in active state
2022-03-10 10:39:48 [ForkJoinPool-1-worker-7] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.19 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:48 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:39:48 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:346] In context testUserOperatorMetrics is everything deleted.
2022-03-10 10:39:48 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:39:48 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testUserOperatorMetrics-FINISHED
2022-03-10 10:39:48 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:39:48 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:39:48 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testClusterOperatorMetrics-STARTED
2022-03-10 10:39:48 [ForkJoinPool-1-worker-7] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:39:48 [ForkJoinPool-1-worker-5] [32mINFO [m [MetricsIsolatedST:425] Looking for 'strimzi_bridge_kafka_producer_count' in bridge metrics
2022-03-10 10:39:49 [ForkJoinPool-1-worker-7] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.5 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:49 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:39:49 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:346] In context testClusterOperatorMetrics is everything deleted.
2022-03-10 10:39:49 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:39:49 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testClusterOperatorMetrics-FINISHED
2022-03-10 10:39:49 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:39:49 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:39:49 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testCruiseControlMetrics-STARTED
2022-03-10 10:39:49 [ForkJoinPool-1-worker-7] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:39:50 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.23 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:50 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:39:50 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:346] In context testMirrorMaker2Metrics is everything deleted.
2022-03-10 10:39:50 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:39:50 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testMirrorMaker2Metrics-FINISHED
2022-03-10 10:39:50 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:39:50 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:39:50 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testTopicOperatorMetrics-STARTED
2022-03-10 10:39:50 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:39:50 [ForkJoinPool-1-worker-5] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.19 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: consumer-offsets---84e7a678d08f4bd226872e5cdd4eb527fadc1c6a
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: heartbeats
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: metrics-cluster-name-connect-config
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: metrics-cluster-name-connect-offsets
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: metrics-cluster-name-connect-status
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: mirrormaker2-cluster-configs
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: mirrormaker2-cluster-offsets
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: mirrormaker2-cluster-status
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: my-topic-1098814858-1484970824
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: my-topic-184723579-1847670732
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: my-topic-346885214-1565180398
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: second-kafka-cluster.checkpoints.internal
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: strimzi-store-topic---effb8e3e057afce1ecf67c3f5d8e4e3ff177fc55
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: strimzi-topic-operator-kstreams-topic-store-changelog---b75e702040b99be8a9263134de3507fc0cc4017b
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: strimzi.cruisecontrol.metrics
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsIsolatedST:371] KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:346] In context testTopicOperatorMetrics is everything deleted.
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testTopicOperatorMetrics-FINISHED
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectRequests-STARTED
2022-03-10 10:39:51 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:39:51 [ForkJoinPool-1-worker-5] [32mINFO [m [MetricsIsolatedST:425] Looking for 'strimzi_bridge_kafka_producer_count' in bridge metrics
2022-03-10 10:39:52 [ForkJoinPool-1-worker-7] [32mINFO [m [MetricsIsolatedST:456] Verifying that we have more than 0 groups
2022-03-10 10:39:52 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:39:52 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:346] In context testCruiseControlMetrics is everything deleted.
2022-03-10 10:39:52 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:39:52 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testCruiseControlMetrics-FINISHED
2022-03-10 10:39:52 [ForkJoinPool-1-worker-7] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:39:53 [ForkJoinPool-1-worker-5] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:53 [ForkJoinPool-1-worker-1] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:53 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:39:53 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:346] In context testKafkaConnectRequests is everything deleted.
2022-03-10 10:39:53 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:39:53 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectRequests-FINISHED
2022-03-10 10:39:53 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:39:54 [ForkJoinPool-1-worker-5] [32mINFO [m [MetricsIsolatedST:425] Looking for 'strimzi_bridge_kafka_producer_count' in bridge metrics
2022-03-10 10:39:54 [ForkJoinPool-1-worker-5] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:55 [ForkJoinPool-1-worker-5] [32mINFO [m [MetricsIsolatedST:425] Looking for 'strimzi_bridge_kafka_producer_count' in bridge metrics
2022-03-10 10:39:56 [ForkJoinPool-1-worker-5] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:56 [ForkJoinPool-1-worker-5] [32mINFO [m [MetricsIsolatedST:433] Looking for 'strimzi_bridge_kafka_consumer_connection_count' in bridge metrics
2022-03-10 10:39:57 [ForkJoinPool-1-worker-5] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:39:57 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:39:57 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeMetrics
2022-03-10 10:39:57 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job bridge-consumer in namespace infra-namespace
2022-03-10 10:39:57 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer in namespace infra-namespace
2022-03-10 10:39:57 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:39:57 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBridgeMetrics-FINISHED
2022-03-10 10:39:57 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:39:57 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:39:57 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDataAfterExchange-STARTED
2022-03-10 10:39:57 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:39:57 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 10:39:57 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@23ff7f4, messages=[], arguments=[--topic, my-topic-1098814858-1484970824, --max-messages, 5000, --bootstrap-server, metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='infra-namespace-kafka-clients-748578f786-lsr2f', podNamespace='infra-namespace', bootstrapServer='metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-1098814858-1484970824', maxMessages=5000, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@437a765a}
2022-03-10 10:39:57 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:94] Producing 5000 messages to metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092:my-topic-1098814858-1484970824 from pod infra-namespace-kafka-clients-748578f786-lsr2f
2022-03-10 10:39:57 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec infra-namespace-kafka-clients-748578f786-lsr2f -n infra-namespace -- /opt/kafka/producer.sh --topic my-topic-1098814858-1484970824 --max-messages 5000 --bootstrap-server metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092
2022-03-10 10:40:03 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-03-10 10:40:03 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:101] Producer produced 5000 messages
2022-03-10 10:40:03 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5c3bfa89, messages=[], arguments=[--topic, my-topic-1098814858-1484970824, --max-messages, 5000, --bootstrap-server, metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092, --group-id, my-consumer-group-2124367940, --group-instance-id, instance780662947], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='infra-namespace-kafka-clients-748578f786-lsr2f', podNamespace='infra-namespace', bootstrapServer='metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-1098814858-1484970824', maxMessages=5000, kafkaUsername='null', consumerGroupName='my-consumer-group-2124367940', consumerInstanceId='instance780662947', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@69b51a24}
2022-03-10 10:40:03 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:157] Consuming 5000 messages from metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092#my-topic-1098814858-1484970824 from pod infra-namespace-kafka-clients-748578f786-lsr2f
2022-03-10 10:40:03 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec infra-namespace-kafka-clients-748578f786-lsr2f -n infra-namespace -- /opt/kafka/consumer.sh --topic my-topic-1098814858-1484970824 --max-messages 5000 --bootstrap-server metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092 --group-id my-consumer-group-2124367940 --group-instance-id instance780662947
2022-03-10 10:40:14 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-03-10 10:40:14 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 5000 messages
2022-03-10 10:40:16 [ForkJoinPool-1-worker-3] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.21 from Pod infra-namespace-kafka-clients-748578f786-lsr2f finished with return code: 0
2022-03-10 10:40:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:40:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:346] In context testKafkaExporterDataAfterExchange is everything deleted.
2022-03-10 10:40:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:40:16 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDataAfterExchange-FINISHED
2022-03-10 10:40:16 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:40:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:40:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for MetricsIsolatedST
2022-03-10 10:40:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1431662579-819461059 in namespace infra-namespace
2022-03-10 10:40:16 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 mm2-cluster in namespace infra-namespace
2022-03-10 10:40:16 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy second-kafka-cluster-entity-operator-allow in namespace second-metrics-cluster-test
2022-03-10 10:40:16 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy second-kafka-cluster-kafka-exporter-allow in namespace second-metrics-cluster-test
2022-03-10 10:40:17 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy metrics-cluster-name-kafka-exporter-allow in namespace infra-namespace
2022-03-10 10:40:17 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy metrics-cluster-name-entity-operator-allow in namespace infra-namespace
2022-03-10 10:40:17 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy cluster-operator-allow in namespace infra-namespace
2022-03-10 10:40:17 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1859828938-987165425 in namespace infra-namespace
2022-03-10 10:40:26 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect metrics-cluster-name in namespace infra-namespace
2022-03-10 10:40:26 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-bridge in namespace infra-namespace
2022-03-10 10:40:27 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-184723579-1847670732 in namespace infra-namespace
2022-03-10 10:40:36 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-kafka-clients in namespace infra-namespace
2022-03-10 10:40:37 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1098814858-1484970824 in namespace infra-namespace
2022-03-10 10:40:37 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka second-kafka-cluster in namespace second-metrics-cluster-test
2022-03-10 10:40:47 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-346885214-1565180398 in namespace infra-namespace
2022-03-10 10:40:47 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka metrics-cluster-name in namespace infra-namespace
2022-03-10 10:40:47 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace infra-namespace, for cruise control Kafka cluster metrics-cluster-name
2022-03-10 10:40:57 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment second-metrics-cluster-test-kafka-clients in namespace second-metrics-cluster-test
2022-03-10 10:41:47 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,225.449 s - in io.strimzi.systemtest.metrics.MetricsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.connect.ConnectIsolatedST
2022-03-10 10:41:47 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-03-10 10:42:12 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:594] ============================================================================
2022-03-10 10:42:12 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:595] Un-installing cluster operator from infra-namespace namespace
2022-03-10 10:42:12 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:596] ============================================================================
2022-03-10 10:42:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:42:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-03-10 10:42:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 10:42:12 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 10:42:12 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 10:42:12 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-metrics-cluster-test
2022-03-10 10:42:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 10:42:12 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-metrics-cluster-test
2022-03-10 10:42:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 10:42:12 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:42:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:42:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 10:42:22 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 10:42:22 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:42:22 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 10:42:32 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 10:42:32 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 10:42:32 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 10:42:32 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 10:42:32 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 10:42:32 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 10:42:32 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 10:42:32 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 10:42:32 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 10:42:42 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 10:42:43 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 10:42:43 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 10:42:43 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 10:42:43 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:42:52 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 10:43:02 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:43:27 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:254] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@19ea31bb, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@586734d4, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='*', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-03-10 10:43:27 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:260] Install ClusterOperator via Yaml bundle
2022-03-10 10:43:27 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-03-10 10:43:27 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-03-10 10:43:27 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:43:27 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 10:43:27 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 10:43:27 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 10:43:27 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 10:43:27 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 10:43:27 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 10:43:28 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 10:43:28 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 10:43:28 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 10:43:28 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 10:43:28 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 10:43:28 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 10:43:28 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 10:43:28 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:43:29 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-03-10 10:44:03 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-03-10 10:44:03 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-03-10 10:44:13 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-03-10 10:44:13 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:44:13 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testMultiNodeKafkaConnectWithConnectorCreation-STARTED
2022-03-10 10:44:13 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:44:13 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-4 for test case:testMultiNodeKafkaConnectWithConnectorCreation
2022-03-10 10:44:13 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-4
2022-03-10 10:44:13 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-4
2022-03-10 10:44:13 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-4
2022-03-10 10:44:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c4f356ae-kafka-clients in namespace namespace-4
2022-03-10 10:44:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-03-10 10:44:13 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c4f356ae-kafka-clients will be ready
2022-03-10 10:44:16 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c4f356ae-kafka-clients is ready
2022-03-10 10:44:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c4f356ae in namespace namespace-4
2022-03-10 10:44:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-03-10 10:44:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c4f356ae will have desired state: Ready
2022-03-10 10:48:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c4f356ae is in desired state: Ready
2022-03-10 10:48:00 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-c4f356ae-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-03-10 10:48:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-c4f356ae-allow in namespace namespace-4
2022-03-10 10:48:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-03-10 10:48:00 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-03-10 10:48:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-c4f356ae in namespace namespace-4
2022-03-10 10:48:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-03-10 10:48:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-c4f356ae will have desired state: Ready
2022-03-10 10:49:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-c4f356ae is in desired state: Ready
2022-03-10 10:49:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-c4f356ae in namespace namespace-4
2022-03-10 10:49:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-03-10 10:49:09 [ForkJoinPool-1-worker-3] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkaconnectors' with unstable version 'v1beta2'
2022-03-10 10:49:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-c4f356ae will have desired state: Ready
2022-03-10 10:49:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-c4f356ae is in desired state: Ready
2022-03-10 10:49:12 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 10:49:13 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-c4f356ae-connect-65b6bd6555-h47bq -- curl -X GET http://localhost:8083/connectors/my-cluster-c4f356ae/status
2022-03-10 10:49:13 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-03-10 10:49:13 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4eb9a47e, messages=[], arguments=[--topic, my-topic-1653770483-593677852, --max-messages, 100, --bootstrap-server, my-cluster-c4f356ae-kafka-bootstrap.namespace-4.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-c4f356ae-kafka-clients-78dfd475c-z4mb7', podNamespace='namespace-4', bootstrapServer='my-cluster-c4f356ae-kafka-bootstrap.namespace-4.svc:9092', topicName='my-topic-1653770483-593677852', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@f5ee1ab}
2022-03-10 10:49:13 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-c4f356ae-kafka-bootstrap.namespace-4.svc:9092:my-topic-1653770483-593677852 from pod my-cluster-c4f356ae-kafka-clients-78dfd475c-z4mb7
2022-03-10 10:49:13 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c4f356ae-kafka-clients-78dfd475c-z4mb7 -n namespace-4 -- /opt/kafka/producer.sh --topic my-topic-1653770483-593677852 --max-messages 100 --bootstrap-server my-cluster-c4f356ae-kafka-bootstrap.namespace-4.svc:9092
2022-03-10 10:49:20 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-03-10 10:49:20 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-03-10 10:49:20 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@19a9533c, messages=[], arguments=[--topic, my-topic-1653770483-593677852, --max-messages, 100, --bootstrap-server, my-cluster-c4f356ae-kafka-bootstrap.namespace-4.svc:9092, --group-id, my-consumer-group-1500211308, --group-instance-id, instance551537822], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c4f356ae-kafka-clients-78dfd475c-z4mb7', podNamespace='namespace-4', bootstrapServer='my-cluster-c4f356ae-kafka-bootstrap.namespace-4.svc:9092', topicName='my-topic-1653770483-593677852', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1500211308', consumerInstanceId='instance551537822', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2e1cdb93}
2022-03-10 10:49:20 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-c4f356ae-kafka-bootstrap.namespace-4.svc:9092#my-topic-1653770483-593677852 from pod my-cluster-c4f356ae-kafka-clients-78dfd475c-z4mb7
2022-03-10 10:49:20 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c4f356ae-kafka-clients-78dfd475c-z4mb7 -n namespace-4 -- /opt/kafka/consumer.sh --topic my-topic-1653770483-593677852 --max-messages 100 --bootstrap-server my-cluster-c4f356ae-kafka-bootstrap.namespace-4.svc:9092 --group-id my-consumer-group-1500211308 --group-instance-id instance551537822
2022-03-10 10:49:29 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-03-10 10:49:29 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-03-10 10:49:29 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-c4f356ae-connect-65b6bd6555-kzm87
2022-03-10 10:49:30 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-c4f356ae-connect-65b6bd6555-kzm87
2022-03-10 10:49:30 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:49:30 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for testMultiNodeKafkaConnectWithConnectorCreation
2022-03-10 10:49:30 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-c4f356ae-allow in namespace namespace-4
2022-03-10 10:49:30 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c4f356ae in namespace namespace-4
2022-03-10 10:49:30 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c4f356ae-kafka-clients in namespace namespace-4
2022-03-10 10:49:30 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-c4f356ae in namespace namespace-4
2022-03-10 10:49:40 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-c4f356ae in namespace namespace-4
2022-03-10 10:50:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:50:11 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-4 for test case:testMultiNodeKafkaConnectWithConnectorCreation
2022-03-10 10:50:18 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testMultiNodeKafkaConnectWithConnectorCreation-FINISHED
2022-03-10 10:50:18 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:50:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:50:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:346] In context ConnectIsolatedST is everything deleted.
2022-03-10 10:50:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 510.965 s - in io.strimzi.systemtest.connect.ConnectIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
2022-03-10 10:50:18 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-03-10 10:50:43 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:594] ============================================================================
2022-03-10 10:50:43 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:595] Un-installing cluster operator from infra-namespace namespace
2022-03-10 10:50:43 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:596] ============================================================================
2022-03-10 10:50:43 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:50:43 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-03-10 10:50:43 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 10:50:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 10:50:43 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 10:50:43 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 10:50:43 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-03-10 10:50:43 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:50:53 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:50:53 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 10:50:53 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 10:50:53 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 10:51:03 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:03 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:03 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 10:51:03 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:51:04 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 10:51:04 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 10:51:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:14 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 10:51:14 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 10:51:14 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:51:14 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 10:51:14 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:14 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 10:51:23 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:34 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:51:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:196] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@586734d4
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=120000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-03-10 10:51:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:260] Install ClusterOperator via Yaml bundle
2022-03-10 10:51:39 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-03-10 10:51:39 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-03-10 10:51:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:51:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 10:51:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 10:51:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 10:51:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 10:51:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 10:51:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:40 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:40 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 10:51:40 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:40 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:40 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:40 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:40 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 10:51:41 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-03-10 10:52:20 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-03-10 10:52:20 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-03-10 10:52:30 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-03-10 10:52:30 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 10:52:30 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsAuthenticated-STARTED
2022-03-10 10:52:30 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 10:52:30 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-5 for test case:testMirrorMakerTlsAuthenticated
2022-03-10 10:52:30 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-5
2022-03-10 10:52:30 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-5
2022-03-10 10:52:30 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-5
2022-03-10 10:52:30 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4e999fd5-source in namespace namespace-5
2022-03-10 10:52:30 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-03-10 10:52:30 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4e999fd5-source will have desired state: Ready
2022-03-10 10:53:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4e999fd5-source is in desired state: Ready
2022-03-10 10:53:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4e999fd5-target in namespace namespace-5
2022-03-10 10:53:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-03-10 10:53:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4e999fd5-target will have desired state: Ready
2022-03-10 10:56:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4e999fd5-target is in desired state: Ready
2022-03-10 10:56:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-43782029-743602071-source-553408007 in namespace namespace-5
2022-03-10 10:56:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-03-10 10:56:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-43782029-743602071-source-553408007 will have desired state: Ready
2022-03-10 10:56:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-43782029-743602071-source-553408007 is in desired state: Ready
2022-03-10 10:56:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-4e999fd5-my-user-source in namespace namespace-5
2022-03-10 10:56:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-03-10 10:56:06 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-4e999fd5-my-user-source will have desired state: Ready
2022-03-10 10:56:08 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-4e999fd5-my-user-source is in desired state: Ready
2022-03-10 10:56:08 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-4e999fd5-my-user-target in namespace namespace-5
2022-03-10 10:56:08 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-03-10 10:56:08 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-4e999fd5-my-user-target will have desired state: Ready
2022-03-10 10:56:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-4e999fd5-my-user-target is in desired state: Ready
2022-03-10 10:56:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4e999fd5-kafka-clients in namespace namespace-5
2022-03-10 10:56:09 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-03-10 10:56:10 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4e999fd5-kafka-clients will be ready
2022-03-10 10:56:13 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4e999fd5-kafka-clients is ready
2022-03-10 10:56:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-91101192-2042271656-test-1 in namespace namespace-5
2022-03-10 10:56:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-03-10 10:56:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-91101192-2042271656-test-1 will have desired state: Ready
2022-03-10 10:56:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-91101192-2042271656-test-1 is in desired state: Ready
2022-03-10 10:56:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-91101192-2042271656-test-2 in namespace namespace-5
2022-03-10 10:56:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-03-10 10:56:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-91101192-2042271656-test-2 will have desired state: Ready
2022-03-10 10:56:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-91101192-2042271656-test-2 is in desired state: Ready
2022-03-10 10:56:15 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 10:56:15 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@42352115, messages=[], arguments=[--topic, my-topic-91101192-2042271656-test-1, --max-messages, 200, --bootstrap-server, my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093, USER=my_cluster_4e999fd5_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j', podNamespace='namespace-5', bootstrapServer='my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093', topicName='my-topic-91101192-2042271656-test-1', maxMessages=200, kafkaUsername='my-cluster-4e999fd5-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@390967b9}
2022-03-10 10:56:15 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093:my-topic-91101192-2042271656-test-1 from pod my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j
2022-03-10 10:56:15 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j -n namespace-5 -- /opt/kafka/producer.sh --topic my-topic-91101192-2042271656-test-1 --max-messages 200 --bootstrap-server my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093 USER=my_cluster_4e999fd5_my_user_source
2022-03-10 10:56:22 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-03-10 10:56:22 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-03-10 10:56:22 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@340a68e7, messages=[], arguments=[--topic, my-topic-91101192-2042271656-test-1, --max-messages, 200, --bootstrap-server, my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093, --group-id, my-consumer-group-517839741, USER=my_cluster_4e999fd5_my_user_source, --group-instance-id, instance321559094], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j', podNamespace='namespace-5', bootstrapServer='my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093', topicName='my-topic-91101192-2042271656-test-1', maxMessages=200, kafkaUsername='my-cluster-4e999fd5-my-user-source', consumerGroupName='my-consumer-group-517839741', consumerInstanceId='instance321559094', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@464cfb38}
2022-03-10 10:56:22 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093:my-topic-91101192-2042271656-test-1 from pod my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j
2022-03-10 10:56:22 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j -n namespace-5 -- /opt/kafka/consumer.sh --topic my-topic-91101192-2042271656-test-1 --max-messages 200 --bootstrap-server my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093 --group-id my-consumer-group-517839741 USER=my_cluster_4e999fd5_my_user_source --group-instance-id instance321559094
2022-03-10 10:56:34 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-03-10 10:56:34 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-03-10 10:56:34 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6dc3a5ed, messages=[], arguments=[--topic, my-topic-91101192-2042271656-test-2, --max-messages, 200, --bootstrap-server, my-cluster-4e999fd5-target-kafka-bootstrap.namespace-5.svc:9093, USER=my_cluster_4e999fd5_my_user_target], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j', podNamespace='namespace-5', bootstrapServer='my-cluster-4e999fd5-target-kafka-bootstrap.namespace-5.svc:9093', topicName='my-topic-91101192-2042271656-test-2', maxMessages=200, kafkaUsername='my-cluster-4e999fd5-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5f5cdafa}
2022-03-10 10:56:34 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-4e999fd5-target-kafka-bootstrap.namespace-5.svc:9093:my-topic-91101192-2042271656-test-2 from pod my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j
2022-03-10 10:56:34 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j -n namespace-5 -- /opt/kafka/producer.sh --topic my-topic-91101192-2042271656-test-2 --max-messages 200 --bootstrap-server my-cluster-4e999fd5-target-kafka-bootstrap.namespace-5.svc:9093 USER=my_cluster_4e999fd5_my_user_target
2022-03-10 10:56:43 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-03-10 10:56:43 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-03-10 10:56:43 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2b5d126f, messages=[], arguments=[--topic, my-topic-91101192-2042271656-test-2, --max-messages, 200, --bootstrap-server, my-cluster-4e999fd5-target-kafka-bootstrap.namespace-5.svc:9093, --group-id, my-consumer-group-678833083, USER=my_cluster_4e999fd5_my_user_target, --group-instance-id, instance1095750712], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j', podNamespace='namespace-5', bootstrapServer='my-cluster-4e999fd5-target-kafka-bootstrap.namespace-5.svc:9093', topicName='my-topic-91101192-2042271656-test-2', maxMessages=200, kafkaUsername='my-cluster-4e999fd5-my-user-target', consumerGroupName='my-consumer-group-678833083', consumerInstanceId='instance1095750712', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4c770656}
2022-03-10 10:56:43 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-4e999fd5-target-kafka-bootstrap.namespace-5.svc:9093:my-topic-91101192-2042271656-test-2 from pod my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j
2022-03-10 10:56:43 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j -n namespace-5 -- /opt/kafka/consumer.sh --topic my-topic-91101192-2042271656-test-2 --max-messages 200 --bootstrap-server my-cluster-4e999fd5-target-kafka-bootstrap.namespace-5.svc:9093 --group-id my-consumer-group-678833083 USER=my_cluster_4e999fd5_my_user_target --group-instance-id instance1095750712
2022-03-10 10:56:56 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-03-10 10:56:56 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-03-10 10:56:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-4e999fd5 in namespace namespace-5
2022-03-10 10:56:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-03-10 10:56:56 [ForkJoinPool-1-worker-3] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkamirrormakers' with unstable version 'v1beta2'
2022-03-10 10:56:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-4e999fd5 will have desired state: Ready
2022-03-10 10:58:08 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-4e999fd5 is in desired state: Ready
2022-03-10 10:58:08 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1c1bdf7, messages=[], arguments=[--topic, my-topic-43782029-743602071-source-553408007, --max-messages, 200, --bootstrap-server, my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093, USER=my_cluster_4e999fd5_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j', podNamespace='namespace-5', bootstrapServer='my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093', topicName='my-topic-43782029-743602071-source-553408007', maxMessages=200, kafkaUsername='my-cluster-4e999fd5-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7b32963a}
2022-03-10 10:58:08 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093:my-topic-43782029-743602071-source-553408007 from pod my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j
2022-03-10 10:58:08 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j -n namespace-5 -- /opt/kafka/producer.sh --topic my-topic-43782029-743602071-source-553408007 --max-messages 200 --bootstrap-server my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093 USER=my_cluster_4e999fd5_my_user_source
2022-03-10 10:58:17 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-03-10 10:58:17 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-03-10 10:58:17 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@32f8409d, messages=[], arguments=[--topic, my-topic-43782029-743602071-source-553408007, --max-messages, 200, --bootstrap-server, my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093, --group-id, my-consumer-group-790559324, USER=my_cluster_4e999fd5_my_user_source, --group-instance-id, instance1039114705], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j', podNamespace='namespace-5', bootstrapServer='my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093', topicName='my-topic-43782029-743602071-source-553408007', maxMessages=200, kafkaUsername='my-cluster-4e999fd5-my-user-source', consumerGroupName='my-consumer-group-790559324', consumerInstanceId='instance1039114705', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5d949e53}
2022-03-10 10:58:17 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093:my-topic-43782029-743602071-source-553408007 from pod my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j
2022-03-10 10:58:17 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j -n namespace-5 -- /opt/kafka/consumer.sh --topic my-topic-43782029-743602071-source-553408007 --max-messages 200 --bootstrap-server my-cluster-4e999fd5-source-kafka-bootstrap.namespace-5.svc:9093 --group-id my-consumer-group-790559324 USER=my_cluster_4e999fd5_my_user_source --group-instance-id instance1039114705
2022-03-10 10:58:29 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-03-10 10:58:29 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-03-10 10:58:29 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@47450b34, messages=[], arguments=[--topic, my-topic-43782029-743602071-source-553408007, --max-messages, 200, --bootstrap-server, my-cluster-4e999fd5-target-kafka-bootstrap.namespace-5.svc:9093, --group-id, my-consumer-group-1644799245, USER=my_cluster_4e999fd5_my_user_target, --group-instance-id, instance971787294], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j', podNamespace='namespace-5', bootstrapServer='my-cluster-4e999fd5-target-kafka-bootstrap.namespace-5.svc:9093', topicName='my-topic-43782029-743602071-source-553408007', maxMessages=200, kafkaUsername='my-cluster-4e999fd5-my-user-target', consumerGroupName='my-consumer-group-1644799245', consumerInstanceId='instance971787294', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3e5a7caa}
2022-03-10 10:58:29 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-4e999fd5-target-kafka-bootstrap.namespace-5.svc:9093:my-topic-43782029-743602071-source-553408007 from pod my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j
2022-03-10 10:58:29 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4e999fd5-kafka-clients-5fc8474b7d-w6h4j -n namespace-5 -- /opt/kafka/consumer.sh --topic my-topic-43782029-743602071-source-553408007 --max-messages 200 --bootstrap-server my-cluster-4e999fd5-target-kafka-bootstrap.namespace-5.svc:9093 --group-id my-consumer-group-1644799245 USER=my_cluster_4e999fd5_my_user_target --group-instance-id instance971787294
2022-03-10 10:58:41 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-03-10 10:58:41 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-03-10 10:58:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:58:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerTlsAuthenticated
2022-03-10 10:58:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4e999fd5-kafka-clients in namespace namespace-5
2022-03-10 10:58:41 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-43782029-743602071-source-553408007 in namespace namespace-5
2022-03-10 10:58:41 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4e999fd5-target in namespace namespace-5
2022-03-10 10:58:51 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4e999fd5-source in namespace namespace-5
2022-03-10 10:58:51 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-4e999fd5-my-user-source in namespace namespace-5
2022-03-10 10:59:01 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-91101192-2042271656-test-2 in namespace namespace-5
2022-03-10 10:59:01 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-4e999fd5-my-user-target in namespace namespace-5
2022-03-10 10:59:11 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-4e999fd5 in namespace namespace-5
2022-03-10 10:59:11 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-91101192-2042271656-test-1 in namespace namespace-5
2022-03-10 10:59:31 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 10:59:31 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-5 for test case:testMirrorMakerTlsAuthenticated
2022-03-10 10:59:59 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsAuthenticated-FINISHED
2022-03-10 10:59:59 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 10:59:59 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 10:59:59 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:346] In context MirrorMakerIsolatedST is everything deleted.
2022-03-10 10:59:59 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 581.568 s - in io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
2022-03-10 10:59:59 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-03-10 11:00:24 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:594] ============================================================================
2022-03-10 11:00:24 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:595] Un-installing cluster operator from infra-namespace namespace
2022-03-10 11:00:24 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:596] ============================================================================
2022-03-10 11:00:24 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 11:00:24 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-03-10 11:00:24 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 11:00:24 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 11:00:24 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 11:00:25 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:00:25 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-03-10 11:00:25 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:00:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:00:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 11:00:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 11:00:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 11:00:35 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 11:00:35 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 11:00:35 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:00:35 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 11:00:35 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 11:00:45 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 11:00:45 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:00:45 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 11:00:45 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:00:45 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 11:00:45 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:00:46 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 11:00:46 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 11:00:46 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 11:00:55 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:01:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 11:01:11 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:196] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@586734d4
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-03-10 11:01:11 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:260] Install ClusterOperator via Yaml bundle
2022-03-10 11:01:11 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-03-10 11:01:11 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-03-10 11:01:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:01:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:01:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 11:01:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 11:01:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 11:01:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 11:01:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 11:01:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 11:01:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 11:01:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 11:01:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:01:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:01:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 11:01:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 11:01:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 11:01:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 11:01:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:01:12 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-03-10 11:01:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 11:01:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 11:01:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-03-10 11:01:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 11:01:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-03-10 11:01:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 11:01:13 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 11:01:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:01:13 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-03-10 11:01:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 11:01:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-03-10 11:01:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-03-10 11:01:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:01:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-03-10 11:01:13 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:01:13 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-03-10 11:01:43 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-03-10 11:01:43 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-03-10 11:01:53 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-03-10 11:01:53 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 11:01:53 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndTlsClientAuth-STARTED
2022-03-10 11:01:53 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 11:01:53 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-6 for test case:testMirrorMaker2TlsAndTlsClientAuth
2022-03-10 11:01:53 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-6
2022-03-10 11:01:53 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-6
2022-03-10 11:01:53 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-6
2022-03-10 11:01:53 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-781edd8d-source in namespace namespace-6
2022-03-10 11:01:53 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-03-10 11:01:53 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-781edd8d-source will have desired state: Ready
2022-03-10 11:04:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-781edd8d-source is in desired state: Ready
2022-03-10 11:04:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-781edd8d-target in namespace namespace-6
2022-03-10 11:04:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-03-10 11:04:02 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-781edd8d-target will have desired state: Ready
2022-03-10 11:06:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-781edd8d-target is in desired state: Ready
2022-03-10 11:06:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-1841892356 in namespace namespace-6
2022-03-10 11:06:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-03-10 11:06:14 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-1841892356 will have desired state: Ready
2022-03-10 11:06:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-1841892356 is in desired state: Ready
2022-03-10 11:06:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-781edd8d-my-user-source in namespace namespace-6
2022-03-10 11:06:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-03-10 11:06:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-781edd8d-my-user-source will have desired state: Ready
2022-03-10 11:06:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-781edd8d-my-user-source is in desired state: Ready
2022-03-10 11:06:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-781edd8d-my-user-target in namespace namespace-6
2022-03-10 11:06:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-03-10 11:06:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-781edd8d-my-user-target will have desired state: Ready
2022-03-10 11:06:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-781edd8d-my-user-target is in desired state: Ready
2022-03-10 11:06:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-781edd8d-kafka-clients in namespace namespace-6
2022-03-10 11:06:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-03-10 11:06:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-288583187-1931769582-test-1 in namespace namespace-6
2022-03-10 11:06:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-03-10 11:06:18 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-288583187-1931769582-test-1 will have desired state: Ready
2022-03-10 11:06:19 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-288583187-1931769582-test-1 is in desired state: Ready
2022-03-10 11:06:19 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-288583187-1931769582-test-2 in namespace namespace-6
2022-03-10 11:06:19 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-03-10 11:06:19 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-288583187-1931769582-test-2 will have desired state: Ready
2022-03-10 11:06:20 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-288583187-1931769582-test-2 is in desired state: Ready
2022-03-10 11:06:20 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 11:06:20 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-274532383-2126852027 in namespace namespace-6
2022-03-10 11:06:20 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-03-10 11:06:20 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-274532383-2126852027 will have desired state: Ready
2022-03-10 11:06:22 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-274532383-2126852027 is in desired state: Ready
2022-03-10 11:06:22 [ForkJoinPool-1-worker-3] [32mINFO [m [ClientUtils:109] Sending messages to - topic my-topic-288583187-1931769582-test-1, cluster my-cluster-781edd8d-source and message count of 200
2022-03-10 11:06:22 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2982a30a, messages=[], arguments=[--topic, my-topic-274532383-2126852027, --max-messages, 200, --bootstrap-server, my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093, USER=my_cluster_781edd8d_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l', podNamespace='namespace-6', bootstrapServer='my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093', topicName='my-topic-274532383-2126852027', maxMessages=200, kafkaUsername='my-cluster-781edd8d-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@61e9f196}
2022-03-10 11:06:22 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093:my-topic-274532383-2126852027 from pod my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l
2022-03-10 11:06:22 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l -n namespace-6 -- /opt/kafka/producer.sh --topic my-topic-274532383-2126852027 --max-messages 200 --bootstrap-server my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093 USER=my_cluster_781edd8d_my_user_source
2022-03-10 11:06:29 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-03-10 11:06:29 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-03-10 11:06:29 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@17166b10, messages=[], arguments=[--topic, my-topic-274532383-2126852027, --max-messages, 200, --bootstrap-server, my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093, --group-id, my-consumer-group-1275816942, USER=my_cluster_781edd8d_my_user_source, --group-instance-id, instance2041606950], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l', podNamespace='namespace-6', bootstrapServer='my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093', topicName='my-topic-274532383-2126852027', maxMessages=200, kafkaUsername='my-cluster-781edd8d-my-user-source', consumerGroupName='my-consumer-group-1275816942', consumerInstanceId='instance2041606950', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@395d48ec}
2022-03-10 11:06:29 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093:my-topic-274532383-2126852027 from pod my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l
2022-03-10 11:06:29 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l -n namespace-6 -- /opt/kafka/consumer.sh --topic my-topic-274532383-2126852027 --max-messages 200 --bootstrap-server my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093 --group-id my-consumer-group-1275816942 USER=my_cluster_781edd8d_my_user_source --group-instance-id instance2041606950
2022-03-10 11:06:39 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-03-10 11:06:39 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-03-10 11:06:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ClientUtils:115] Sent 200 and received 200
2022-03-10 11:06:39 [ForkJoinPool-1-worker-3] [32mINFO [m [MirrorMaker2IsolatedST:329] Setting topic to my-topic-288583187-1931769582-test-2, cluster to my-cluster-781edd8d-target and changing user to my-cluster-781edd8d-my-user-target
2022-03-10 11:06:39 [ForkJoinPool-1-worker-3] [32mINFO [m [MirrorMaker2IsolatedST:338] Sending messages to - topic my-topic-288583187-1931769582-test-2, cluster my-cluster-781edd8d-target and message count of 200
2022-03-10 11:06:39 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2db907ac, messages=[], arguments=[--topic, my-topic-288583187-1931769582-test-2, --max-messages, 200, --bootstrap-server, my-cluster-781edd8d-target-kafka-bootstrap.namespace-6.svc:9093, USER=my_cluster_781edd8d_my_user_target], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l', podNamespace='namespace-6', bootstrapServer='my-cluster-781edd8d-target-kafka-bootstrap.namespace-6.svc:9093', topicName='my-topic-288583187-1931769582-test-2', maxMessages=200, kafkaUsername='my-cluster-781edd8d-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2b30000b}
2022-03-10 11:06:39 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-781edd8d-target-kafka-bootstrap.namespace-6.svc:9093:my-topic-288583187-1931769582-test-2 from pod my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l
2022-03-10 11:06:39 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l -n namespace-6 -- /opt/kafka/producer.sh --topic my-topic-288583187-1931769582-test-2 --max-messages 200 --bootstrap-server my-cluster-781edd8d-target-kafka-bootstrap.namespace-6.svc:9093 USER=my_cluster_781edd8d_my_user_target
2022-03-10 11:06:46 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-03-10 11:06:46 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-03-10 11:06:46 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5a9a8aea, messages=[], arguments=[--topic, my-topic-288583187-1931769582-test-2, --max-messages, 200, --bootstrap-server, my-cluster-781edd8d-target-kafka-bootstrap.namespace-6.svc:9093, --group-id, my-consumer-group-1008188110, USER=my_cluster_781edd8d_my_user_target, --group-instance-id, instance1478317813], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l', podNamespace='namespace-6', bootstrapServer='my-cluster-781edd8d-target-kafka-bootstrap.namespace-6.svc:9093', topicName='my-topic-288583187-1931769582-test-2', maxMessages=200, kafkaUsername='my-cluster-781edd8d-my-user-target', consumerGroupName='my-consumer-group-1008188110', consumerInstanceId='instance1478317813', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7e7030df}
2022-03-10 11:06:46 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-781edd8d-target-kafka-bootstrap.namespace-6.svc:9093:my-topic-288583187-1931769582-test-2 from pod my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l
2022-03-10 11:06:46 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l -n namespace-6 -- /opt/kafka/consumer.sh --topic my-topic-288583187-1931769582-test-2 --max-messages 200 --bootstrap-server my-cluster-781edd8d-target-kafka-bootstrap.namespace-6.svc:9093 --group-id my-consumer-group-1008188110 USER=my_cluster_781edd8d_my_user_target --group-instance-id instance1478317813
2022-03-10 11:06:57 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-03-10 11:06:57 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-03-10 11:06:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-781edd8d in namespace namespace-6
2022-03-10 11:06:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-03-10 11:06:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-781edd8d will have desired state: Ready
2022-03-10 11:08:12 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-781edd8d is in desired state: Ready
2022-03-10 11:08:12 [ForkJoinPool-1-worker-3] [32mINFO [m [MirrorMaker2IsolatedST:398] Setting topic to mirrormaker2-topic-example-1841892356, cluster to my-cluster-781edd8d-source and changing user to my-cluster-781edd8d-my-user-source
2022-03-10 11:08:12 [ForkJoinPool-1-worker-3] [32mINFO [m [MirrorMaker2IsolatedST:408] Sending messages to - topic mirrormaker2-topic-example-1841892356, cluster my-cluster-781edd8d-source and message count of 200
2022-03-10 11:08:12 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@164df296, messages=[], arguments=[--topic, mirrormaker2-topic-example-1841892356, --max-messages, 200, --bootstrap-server, my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093, USER=my_cluster_781edd8d_my_user_source], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l', podNamespace='namespace-6', bootstrapServer='my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093', topicName='mirrormaker2-topic-example-1841892356', maxMessages=200, kafkaUsername='my-cluster-781edd8d-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@56d7addd}
2022-03-10 11:08:12 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093:mirrormaker2-topic-example-1841892356 from pod my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l
2022-03-10 11:08:12 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l -n namespace-6 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-1841892356 --max-messages 200 --bootstrap-server my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093 USER=my_cluster_781edd8d_my_user_source
2022-03-10 11:08:19 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-03-10 11:08:19 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-03-10 11:08:19 [ForkJoinPool-1-worker-3] [32mINFO [m [MirrorMaker2IsolatedST:412] Receiving messages from - topic mirrormaker2-topic-example-1841892356, cluster my-cluster-781edd8d-source and message count of 200
2022-03-10 11:08:19 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3212e239, messages=[], arguments=[--topic, mirrormaker2-topic-example-1841892356, --max-messages, 200, --bootstrap-server, my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093, --group-id, my-consumer-group-1008188110, USER=my_cluster_781edd8d_my_user_source, --group-instance-id, instance2007860512], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l', podNamespace='namespace-6', bootstrapServer='my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093', topicName='mirrormaker2-topic-example-1841892356', maxMessages=200, kafkaUsername='my-cluster-781edd8d-my-user-source', consumerGroupName='my-consumer-group-1008188110', consumerInstanceId='instance2007860512', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@59c00599}
2022-03-10 11:08:19 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093:mirrormaker2-topic-example-1841892356 from pod my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l
2022-03-10 11:08:19 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l -n namespace-6 -- /opt/kafka/consumer.sh --topic mirrormaker2-topic-example-1841892356 --max-messages 200 --bootstrap-server my-cluster-781edd8d-source-kafka-bootstrap.namespace-6.svc:9093 --group-id my-consumer-group-1008188110 USER=my_cluster_781edd8d_my_user_source --group-instance-id instance2007860512
2022-03-10 11:08:30 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-03-10 11:08:30 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-03-10 11:08:30 [ForkJoinPool-1-worker-3] [32mINFO [m [MirrorMaker2IsolatedST:419] Now setting topic to my-cluster-781edd8d-source.mirrormaker2-topic-example-1841892356, cluster to my-cluster-781edd8d-target and user to my-cluster-781edd8d-my-user-target - the messages should be mirrored
2022-03-10 11:08:30 [ForkJoinPool-1-worker-3] [32mINFO [m [MirrorMaker2IsolatedST:428] Consumer in target cluster and topic should receive 200 messages
2022-03-10 11:08:30 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5749da78, messages=[], arguments=[--topic, my-cluster-781edd8d-source.mirrormaker2-topic-example-1841892356, --max-messages, 200, --bootstrap-server, my-cluster-781edd8d-target-kafka-bootstrap.namespace-6.svc:9093, --group-id, my-consumer-group-1008188110, USER=my_cluster_781edd8d_my_user_target, --group-instance-id, instance1299122226], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l', podNamespace='namespace-6', bootstrapServer='my-cluster-781edd8d-target-kafka-bootstrap.namespace-6.svc:9093', topicName='my-cluster-781edd8d-source.mirrormaker2-topic-example-1841892356', maxMessages=200, kafkaUsername='my-cluster-781edd8d-my-user-target', consumerGroupName='my-consumer-group-1008188110', consumerInstanceId='instance1299122226', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4b326faf}
2022-03-10 11:08:30 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-781edd8d-target-kafka-bootstrap.namespace-6.svc:9093:my-cluster-781edd8d-source.mirrormaker2-topic-example-1841892356 from pod my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l
2022-03-10 11:08:30 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-781edd8d-kafka-clients-769d984d6b-dld5l -n namespace-6 -- /opt/kafka/consumer.sh --topic my-cluster-781edd8d-source.mirrormaker2-topic-example-1841892356 --max-messages 200 --bootstrap-server my-cluster-781edd8d-target-kafka-bootstrap.namespace-6.svc:9093 --group-id my-consumer-group-1008188110 USER=my_cluster_781edd8d_my_user_target --group-instance-id instance1299122226
2022-03-10 11:08:42 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-03-10 11:08:42 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-03-10 11:08:42 [ForkJoinPool-1-worker-3] [32mINFO [m [MirrorMaker2IsolatedST:433] Messages successfully mirrored
2022-03-10 11:08:42 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 11:08:42 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2TlsAndTlsClientAuth
2022-03-10 11:08:42 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-288583187-1931769582-test-1 in namespace namespace-6
2022-03-10 11:08:42 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-1841892356 in namespace namespace-6
2022-03-10 11:08:42 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-274532383-2126852027 in namespace namespace-6
2022-03-10 11:08:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-781edd8d-kafka-clients in namespace namespace-6
2022-03-10 11:08:52 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-781edd8d in namespace namespace-6
2022-03-10 11:09:02 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-288583187-1931769582-test-2 in namespace namespace-6
2022-03-10 11:09:12 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-781edd8d-my-user-target in namespace namespace-6
2022-03-10 11:09:12 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-781edd8d-target in namespace namespace-6
2022-03-10 11:09:22 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-781edd8d-my-user-source in namespace namespace-6
2022-03-10 11:09:22 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-781edd8d-source in namespace namespace-6
2022-03-10 11:09:42 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 11:09:42 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-6 for test case:testMirrorMaker2TlsAndTlsClientAuth
2022-03-10 11:09:54 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndTlsClientAuth-FINISHED
2022-03-10 11:09:54 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 11:09:54 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 11:09:54 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:346] In context MirrorMaker2IsolatedST is everything deleted.
2022-03-10 11:09:54 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 594.958 s - in io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
2022-03-10 11:09:54 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:594] ============================================================================
2022-03-10 11:09:54 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:595] Un-installing cluster operator from infra-namespace namespace
2022-03-10 11:09:54 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:596] ============================================================================
2022-03-10 11:09:54 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 11:09:54 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-03-10 11:09:54 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 11:09:54 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 11:09:54 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 11:09:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:09:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-03-10 11:09:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:09:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 11:09:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:09:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 11:09:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 11:10:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:10:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 11:10:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 11:10:05 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 11:10:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:10:05 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 11:10:15 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 11:10:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:10:15 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 11:10:25 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:10:25 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 11:10:25 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:10:25 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 11:10:25 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 11:10:25 [ForkJoinPool-1-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 11:10:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.ListenersST
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-03-10 11:11:02 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.ListenersST
2022-03-10 11:11:02 [ForkJoinPool-2-worker-3] [32mINFO [m [SetupClusterOperator:196] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@13a23e06
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-03-10 11:11:02 [ForkJoinPool-2-worker-3] [32mINFO [m [SetupClusterOperator:260] Install ClusterOperator via Yaml bundle
2022-03-10 11:11:02 [ForkJoinPool-2-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-03-10 11:11:02 [ForkJoinPool-2-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-03-10 11:11:02 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:11:02 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:11:02 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 11:11:02 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 11:11:02 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 11:11:02 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 11:11:02 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 11:11:03 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 11:11:03 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 11:11:03 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 11:11:03 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:11:03 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:11:03 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 11:11:03 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:11:04 [ForkJoinPool-2-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-03-10 11:11:22 [ForkJoinPool-2-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-03-10 11:11:22 [ForkJoinPool-2-worker-3] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: listeners-st
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: listeners-st
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: listeners-st
2022-03-10 11:11:33 [ForkJoinPool-2-worker-5] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 11:11:33 [ForkJoinPool-2-worker-5] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-STARTED
2022-03-10 11:11:33 [ForkJoinPool-2-worker-5] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 11:11:33 [ForkJoinPool-2-worker-5] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-7 for test case:testSendMessagesTlsScramSha
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-STARTED
2022-03-10 11:11:33 [ForkJoinPool-2-worker-5] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-7
2022-03-10 11:11:33 [ForkJoinPool-2-worker-5] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-7
2022-03-10 11:11:33 [ForkJoinPool-2-worker-5] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-7
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-8 for test case:testSendMessagesCustomListenerTlsScramSha
2022-03-10 11:11:33 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-11c372ba in namespace namespace-7
2022-03-10 11:11:33 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-8
2022-03-10 11:11:33 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-11c372ba will have desired state: Ready
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-8
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-8
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-135b1795 in namespace namespace-8
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-03-10 11:11:33 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-135b1795 will have desired state: Ready
2022-03-10 11:23:59 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-11c372ba is in desired state: Ready
2022-03-10 11:23:59 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-81597468-801387921 in namespace namespace-8
2022-03-10 11:23:59 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-03-10 11:23:59 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-81597468-801387921 will have desired state: Ready
2022-03-10 11:24:00 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-81597468-801387921 is in desired state: Ready
2022-03-10 11:24:00 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-540017880-1652671483 in namespace namespace-8
2022-03-10 11:24:00 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-03-10 11:24:00 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-540017880-1652671483 will have desired state: Ready
2022-03-10 11:24:01 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-540017880-1652671483 is in desired state: Ready
2022-03-10 11:24:01 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-11c372ba-kafka-clients in namespace namespace-7
2022-03-10 11:24:01 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-03-10 11:24:01 [ForkJoinPool-2-worker-5] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-11c372ba-kafka-clients will be ready
2022-03-10 11:24:04 [ForkJoinPool-2-worker-5] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-11c372ba-kafka-clients is ready
2022-03-10 11:24:04 [ForkJoinPool-2-worker-5] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 11:24:04 [ForkJoinPool-2-worker-5] [32mINFO [m [ListenersST:369] Checking produced and consumed messages to pod:my-cluster-11c372ba-kafka-clients-5fff74fd9d-pwvb7
2022-03-10 11:24:04 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@89f73cc, messages=[], arguments=[--topic, my-topic-81597468-801387921, --max-messages, 100, --bootstrap-server, my-cluster-11c372ba-kafka-bootstrap.namespace-7.svc:9096, USER=my_user_540017880_1652671483], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-11c372ba-kafka-clients-5fff74fd9d-pwvb7', podNamespace='namespace-7', bootstrapServer='my-cluster-11c372ba-kafka-bootstrap.namespace-7.svc:9096', topicName='my-topic-81597468-801387921', maxMessages=100, kafkaUsername='my-user-540017880-1652671483', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@37f83b3f}
2022-03-10 11:24:04 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-11c372ba-kafka-bootstrap.namespace-7.svc:9096:my-topic-81597468-801387921 from pod my-cluster-11c372ba-kafka-clients-5fff74fd9d-pwvb7
2022-03-10 11:24:04 [ForkJoinPool-2-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-11c372ba-kafka-clients-5fff74fd9d-pwvb7 -n namespace-7 -- /opt/kafka/producer.sh --topic my-topic-81597468-801387921 --max-messages 100 --bootstrap-server my-cluster-11c372ba-kafka-bootstrap.namespace-7.svc:9096 USER=my_user_540017880_1652671483
2022-03-10 11:24:11 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-03-10 11:24:11 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-03-10 11:24:11 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@779cbbb7, messages=[], arguments=[--topic, my-topic-81597468-801387921, --max-messages, 100, --bootstrap-server, my-cluster-11c372ba-kafka-bootstrap.namespace-7.svc:9096, --group-id, my-consumer-group-562923320, USER=my_user_540017880_1652671483, --group-instance-id, instance1972461196], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-11c372ba-kafka-clients-5fff74fd9d-pwvb7', podNamespace='namespace-7', bootstrapServer='my-cluster-11c372ba-kafka-bootstrap.namespace-7.svc:9096', topicName='my-topic-81597468-801387921', maxMessages=100, kafkaUsername='my-user-540017880-1652671483', consumerGroupName='my-consumer-group-562923320', consumerInstanceId='instance1972461196', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@14b5962}
2022-03-10 11:24:11 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-11c372ba-kafka-bootstrap.namespace-7.svc:9096:my-topic-81597468-801387921 from pod my-cluster-11c372ba-kafka-clients-5fff74fd9d-pwvb7
2022-03-10 11:24:11 [ForkJoinPool-2-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-11c372ba-kafka-clients-5fff74fd9d-pwvb7 -n namespace-7 -- /opt/kafka/consumer.sh --topic my-topic-81597468-801387921 --max-messages 100 --bootstrap-server my-cluster-11c372ba-kafka-bootstrap.namespace-7.svc:9096 --group-id my-consumer-group-562923320 USER=my_user_540017880_1652671483 --group-instance-id instance1972461196
2022-03-10 11:24:22 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-03-10 11:24:22 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-03-10 11:24:22 [ForkJoinPool-2-worker-5] [32mINFO [m [ListenersST:376] Checking if generated password has 25 characters
2022-03-10 11:24:22 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 11:24:22 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesTlsScramSha
2022-03-10 11:24:22 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-540017880-1652671483 in namespace namespace-7
2022-03-10 11:24:22 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-81597468-801387921 in namespace namespace-7
2022-03-10 11:24:32 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-11c372ba-kafka-clients in namespace namespace-7
2022-03-10 11:24:32 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-11c372ba in namespace namespace-7
2022-03-10 11:25:12 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 11:25:12 [ForkJoinPool-2-worker-5] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-7 for test case:testSendMessagesTlsScramSha
2022-03-10 11:25:18 [ForkJoinPool-2-worker-5] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-FINISHED
2022-03-10 11:25:18 [ForkJoinPool-2-worker-5] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 11:25:33 [ForkJoinPool-2-worker-3] [1;31mERROR[m [TestUtils:162] Exception waiting for Kafka: my-cluster-135b1795 will have desired state: Ready, null
2022-03-10 11:25:33 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:414] Kafka status:

Conditions:
	Type: NotReady
	Message: Exceeded timeout of 300000ms while waiting for StatefulSet resource my-cluster-135b1795-kafka in namespace namespace-8 to be ready

Pods with conditions and messages:

my-cluster-135b1795-kafka-0:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-135b1795-kafka-1:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-135b1795-kafka-2:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: Ready
	Message: containers with unready status: [kafka]

	Type: ContainersReady
	Message: containers with unready status: [kafka]

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-135b1795-zookeeper-0:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-135b1795-zookeeper-1:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-135b1795-zookeeper-2:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>
2022-03-10 11:25:33 [ForkJoinPool-2-worker-3] [1;31mERROR[m [TestExecutionWatcher:28] ListenersST - Exception Timeout after 840000 ms waiting for Resource condition: readiness is fulfilled for resource Kafka:my-cluster-135b1795 has been thrown in @Test. Going to collect logs from components.
2022-03-10 11:25:33 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-03-10 11:25:34 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-03-10 11:25:34 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-03-10 11:25:34 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-03-10 11:25:34 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-03-10 11:25:34 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-03-10 11:25:34 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-03-10 11:25:34 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-03-10 11:25:35 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:252] Collecting events in Namespace namespace-8
2022-03-10 11:25:35 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace namespace-8
2022-03-10 11:25:35 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace namespace-8
2022-03-10 11:25:36 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace namespace-8
2022-03-10 11:25:36 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace namespace-8
2022-03-10 11:25:36 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace namespace-8
2022-03-10 11:25:36 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace namespace-8
2022-03-10 11:25:37 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-03-10 11:25:37 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:252] Collecting events in Namespace listeners-st
2022-03-10 11:25:37 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace listeners-st
2022-03-10 11:25:37 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace listeners-st
2022-03-10 11:25:37 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace listeners-st
2022-03-10 11:25:37 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace listeners-st
2022-03-10 11:25:37 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace listeners-st
2022-03-10 11:25:37 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace listeners-st
2022-03-10 11:25:38 [ForkJoinPool-2-worker-3] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-03-10 11:25:38 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 11:25:38 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesCustomListenerTlsScramSha
2022-03-10 11:25:38 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-135b1795 in namespace namespace-8
2022-03-10 11:25:48 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 11:25:48 [ForkJoinPool-2-worker-3] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-8 for test case:testSendMessagesCustomListenerTlsScramSha
2022-03-10 11:26:31 [ForkJoinPool-2-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-FINISHED
2022-03-10 11:26:31 [ForkJoinPool-2-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 11:26:31 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 11:26:31 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:346] In context ListenersST is everything deleted.
2022-03-10 11:26:31 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 934.961 s <<< FAILURE! - in io.strimzi.systemtest.kafka.listeners.ListenersST
[[1;31mERROR[m] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha(ExtensionContext)  Time elapsed: 898.687 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 840000 ms waiting for Resource condition: readiness is fulfilled for resource Kafka:my-cluster-135b1795
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha(ListenersST.java:401)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:396)
	at java.base/java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:721)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.joinConcurrentTasksInReverseOrderToEnableWorkStealing(ForkJoinPoolHierarchicalTestExecutorService.java:162)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.invokeAll(ForkJoinPoolHierarchicalTestExecutorService.java:136)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.invokeAll(ForkJoinPoolHierarchicalTestExecutorService.java:129)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)

2022-03-10 11:26:37 [ForkJoinPool-2-worker-3] [32mINFO [m [SetupClusterOperator:594] ============================================================================
2022-03-10 11:26:37 [ForkJoinPool-2-worker-3] [32mINFO [m [SetupClusterOperator:595] Un-installing cluster operator from infra-namespace namespace
2022-03-10 11:26:37 [ForkJoinPool-2-worker-3] [32mINFO [m [SetupClusterOperator:596] ============================================================================
2022-03-10 11:26:37 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 11:26:37 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-03-10 11:26:37 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 11:26:37 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 11:26:37 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 11:26:37 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:26:37 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-03-10 11:26:37 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:26:37 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 11:26:37 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:26:37 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 11:26:37 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 11:26:47 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:26:47 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 11:26:47 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 11:26:47 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:26:47 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:26:47 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 11:26:47 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 11:26:57 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 11:26:57 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 11:26:58 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:26:58 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 11:26:58 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:26:58 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 11:26:58 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 11:26:58 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 11:27:08 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.ListenersST
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-03-10 11:27:34 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.ListenersST
2022-03-10 11:27:34 [ForkJoinPool-3-worker-3] [32mINFO [m [SetupClusterOperator:196] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@19c87063
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-03-10 11:27:34 [ForkJoinPool-3-worker-3] [32mINFO [m [SetupClusterOperator:260] Install ClusterOperator via Yaml bundle
2022-03-10 11:27:34 [ForkJoinPool-3-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-03-10 11:27:34 [ForkJoinPool-3-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-03-10 11:27:34 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-03-10 11:27:35 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 11:27:36 [ForkJoinPool-3-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-03-10 11:27:36 [ForkJoinPool-3-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-03-10 11:27:36 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:27:36 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-03-10 11:27:36 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:27:36 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-03-10 11:28:04 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-03-10 11:28:04 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: listeners-st
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: listeners-st
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: listeners-st
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-STARTED
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-9 for test case:testSendMessagesCustomListenerTlsScramSha
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-9
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-9
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-9
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-64abaefd in namespace namespace-9
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-9
2022-03-10 11:28:14 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-64abaefd will have desired state: Ready
2022-03-10 11:36:56 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-64abaefd is in desired state: Ready
2022-03-10 11:36:56 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1870998130-621250927 in namespace namespace-9
2022-03-10 11:36:56 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-9
2022-03-10 11:36:56 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1870998130-621250927 will have desired state: Ready
2022-03-10 11:36:57 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1870998130-621250927 is in desired state: Ready
2022-03-10 11:36:57 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-86884224-366789529 in namespace namespace-9
2022-03-10 11:36:57 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-9
2022-03-10 11:36:57 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-86884224-366789529 will have desired state: Ready
2022-03-10 11:36:58 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-86884224-366789529 is in desired state: Ready
2022-03-10 11:36:58 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-64abaefd-kafka-clients in namespace namespace-9
2022-03-10 11:36:58 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-9
2022-03-10 11:36:58 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-64abaefd-kafka-clients will be ready
2022-03-10 11:37:01 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-64abaefd-kafka-clients is ready
2022-03-10 11:37:01 [ForkJoinPool-3-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-03-10 11:37:01 [ForkJoinPool-3-worker-3] [32mINFO [m [ListenersST:441] Checking produced and consumed messages to pod:my-cluster-64abaefd-kafka-clients-7dcc4d87df-mw59b
2022-03-10 11:37:01 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2f2ac994, messages=[], arguments=[--topic, my-topic-1870998130-621250927, --max-messages, 100, --bootstrap-server, my-cluster-64abaefd-kafka-bootstrap.namespace-9.svc:9122, USER=my_user_86884224_366789529], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-64abaefd-kafka-clients-7dcc4d87df-mw59b', podNamespace='namespace-9', bootstrapServer='my-cluster-64abaefd-kafka-bootstrap.namespace-9.svc:9122', topicName='my-topic-1870998130-621250927', maxMessages=100, kafkaUsername='my-user-86884224-366789529', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4bd5cb2c}
2022-03-10 11:37:01 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-64abaefd-kafka-bootstrap.namespace-9.svc:9122:my-topic-1870998130-621250927 from pod my-cluster-64abaefd-kafka-clients-7dcc4d87df-mw59b
2022-03-10 11:37:01 [ForkJoinPool-3-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-64abaefd-kafka-clients-7dcc4d87df-mw59b -n namespace-9 -- /opt/kafka/producer.sh --topic my-topic-1870998130-621250927 --max-messages 100 --bootstrap-server my-cluster-64abaefd-kafka-bootstrap.namespace-9.svc:9122 USER=my_user_86884224_366789529
2022-03-10 11:37:07 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-03-10 11:37:07 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-03-10 11:37:07 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@838753, messages=[], arguments=[--topic, my-topic-1870998130-621250927, --max-messages, 100, --bootstrap-server, my-cluster-64abaefd-kafka-bootstrap.namespace-9.svc:9122, --group-id, my-consumer-group-1029660467, USER=my_user_86884224_366789529, --group-instance-id, instance1226764122], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-64abaefd-kafka-clients-7dcc4d87df-mw59b', podNamespace='namespace-9', bootstrapServer='my-cluster-64abaefd-kafka-bootstrap.namespace-9.svc:9122', topicName='my-topic-1870998130-621250927', maxMessages=100, kafkaUsername='my-user-86884224-366789529', consumerGroupName='my-consumer-group-1029660467', consumerInstanceId='instance1226764122', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@65eaac69}
2022-03-10 11:37:07 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-64abaefd-kafka-bootstrap.namespace-9.svc:9122:my-topic-1870998130-621250927 from pod my-cluster-64abaefd-kafka-clients-7dcc4d87df-mw59b
2022-03-10 11:37:07 [ForkJoinPool-3-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-64abaefd-kafka-clients-7dcc4d87df-mw59b -n namespace-9 -- /opt/kafka/consumer.sh --topic my-topic-1870998130-621250927 --max-messages 100 --bootstrap-server my-cluster-64abaefd-kafka-bootstrap.namespace-9.svc:9122 --group-id my-consumer-group-1029660467 USER=my_user_86884224_366789529 --group-instance-id instance1226764122
2022-03-10 11:37:16 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-03-10 11:37:16 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-03-10 11:37:16 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 11:37:16 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesCustomListenerTlsScramSha
2022-03-10 11:37:16 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1870998130-621250927 in namespace namespace-9
2022-03-10 11:37:16 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-86884224-366789529 in namespace namespace-9
2022-03-10 11:37:16 [ForkJoinPool-3-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-64abaefd-kafka-clients in namespace namespace-9
2022-03-10 11:37:26 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-64abaefd in namespace namespace-9
2022-03-10 11:37:56 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 11:37:56 [ForkJoinPool-3-worker-3] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-9 for test case:testSendMessagesCustomListenerTlsScramSha
2022-03-10 11:38:23 [ForkJoinPool-3-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-FINISHED
2022-03-10 11:38:23 [ForkJoinPool-3-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-03-10 11:38:23 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 11:38:23 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:346] In context ListenersST is everything deleted.
2022-03-10 11:38:23 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 654.785 s - in io.strimzi.systemtest.kafka.listeners.ListenersST
2022-03-10 11:38:29 [ForkJoinPool-3-worker-3] [32mINFO [m [SetupClusterOperator:594] ============================================================================
2022-03-10 11:38:29 [ForkJoinPool-3-worker-3] [32mINFO [m [SetupClusterOperator:595] Un-installing cluster operator from infra-namespace namespace
2022-03-10 11:38:29 [ForkJoinPool-3-worker-3] [32mINFO [m [SetupClusterOperator:596] ============================================================================
2022-03-10 11:38:29 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:344] ############################################################################
2022-03-10 11:38:29 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-03-10 11:38:29 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-03-10 11:38:29 [ForkJoinPool-3-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-03-10 11:38:29 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-03-10 11:38:29 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:38:29 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-03-10 11:38:29 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:38:29 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-03-10 11:38:29 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:38:29 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-03-10 11:38:29 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-03-10 11:38:29 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-03-10 11:38:39 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:38:39 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-03-10 11:38:39 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-03-10 11:38:39 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:38:39 [ForkJoinPool-3-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-03-10 11:38:40 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-03-10 11:38:49 [ForkJoinPool-3-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-03-10 11:38:49 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-03-10 11:38:50 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-03-10 11:38:50 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-03-10 11:38:50 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-03-10 11:38:50 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-03-10 11:38:50 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-03-10 11:38:50 [ForkJoinPool-3-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-03-10 11:39:00 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:369] ############################################################################
2022-03-10 11:39:11 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-03-10 11:39:11 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-03-10 11:39:11 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-03-10 11:39:11 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-03-10 11:39:11 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;33mWARNING[m] Flakes: 
[[1;33mWARNING[m] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha(ExtensionContext)
[[1;31mERROR[m]   Run 1: ListenersST.testSendMessagesCustomListenerTlsScramSha:401 ? Wait Timeout after...
[[1;31mERROR[m]   Run 2: ListenersST.testSendMessagesCustomListenerTlsScramSha:401 ? Wait Timeout after...
[[1;34mINFO[m]   Run 3: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha(ExtensionContext)
[[1;31mERROR[m]   Run 1: ListenersST.testSendMessagesTlsScramSha:322 ? Wait Timeout after 840000 ms wai...
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;33mWARNING[m] Tests run: 22, Failures: 0, Errors: 0, Skipped: 1, Flakes: 2
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Summary for Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift . [1;32mSUCCESS[m [  4.829 s]
[[1;34mINFO[m] test ............................................... [1;32mSUCCESS[m [  1.963 s]
[[1;34mINFO[m] crd-annotations .................................... [1;32mSUCCESS[m [  1.785 s]
[[1;34mINFO[m] crd-generator ...................................... [1;32mSUCCESS[m [  3.805 s]
[[1;34mINFO[m] api ................................................ [1;32mSUCCESS[m [  9.650 s]
[[1;34mINFO[m] mockkube ........................................... [1;32mSUCCESS[m [  1.921 s]
[[1;34mINFO[m] config-model ....................................... [1;32mSUCCESS[m [  1.385 s]
[[1;34mINFO[m] certificate-manager ................................ [1;32mSUCCESS[m [  1.664 s]
[[1;34mINFO[m] operator-common .................................... [1;32mSUCCESS[m [  2.747 s]
[[1;34mINFO[m] systemtest ......................................... [1;32mSUCCESS[m [  02:16 h]
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1;32mBUILD SUCCESS[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] Total time:  02:16 h
[[1;34mINFO[m] Finished at: 2022-03-10T06:39:11-05:00
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
