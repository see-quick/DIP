[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Build Order:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift                 [pom]
[[1;34mINFO[m] test                                                               [jar]
[[1;34mINFO[m] crd-annotations                                                    [jar]
[[1;34mINFO[m] crd-generator                                                      [jar]
[[1;34mINFO[m] api                                                                [jar]
[[1;34mINFO[m] mockkube                                                           [jar]
[[1;34mINFO[m] config-model                                                       [jar]
[[1;34mINFO[m] certificate-manager                                                [jar]
[[1;34mINFO[m] operator-common                                                    [jar]
[[1;34mINFO[m] systemtest                                                         [jar]
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------------< [0;36mio.strimzi:strimzi[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT [1/10][m
[[1;34mINFO[m] [1m--------------------------------[ pom ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;33mWARNING[m] The artifact xml-apis:xml-apis:jar:2.0.2 has been relocated to xml-apis:xml-apis:jar:1.0.b2
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mstrimzi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mstrimzi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping pom project
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--------------------------< [0;36mio.strimzi:test[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding test 0.29.0-SNAPSHOT                                     [2/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/test/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/test/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No sources to compile
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/test/target/test-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:crd-annotations[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding crd-annotations 0.29.0-SNAPSHOT                          [3/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/crd-annotations/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/crd-annotations/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/crd-annotations/target/crd-annotations-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:crd-generator[0;1m >----------------------[m
[[1;34mINFO[m] [1mBuilding crd-generator 0.29.0-SNAPSHOT                            [4/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/crd-generator/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 7 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-shade-plugin:3.1.0:shade[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Including io.strimzi:crd-annotations:jar:0.29.0-SNAPSHOT in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-core:jar:2.11.3 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-databind:jar:2.11.3 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.10.5 in the shaded jar.
[[1;34mINFO[m] Including org.yaml:snakeyaml:jar:1.26 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-client:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-rbac:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-admissionregistration:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apps:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-autoscaling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apiextensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-batch:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-certificates:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-coordination:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-discovery:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-events:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-extensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-flowcontrol:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-networking:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-metrics:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-policy:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-scheduling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-storageclass:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-node:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:okhttp:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okio:okio:jar:1.15.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:logging-interceptor:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including org.slf4j:slf4j-api:jar:1.7.25 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.datatype:jackson-datatype-jsr310:jar:2.13.1 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:zjsonpatch:jar:0.3.0 in the shaded jar.
[[1;34mINFO[m] Including com.github.mifmif:generex:jar:1.0.2 in the shaded jar.
[[1;34mINFO[m] Including dk.brics.automaton:automaton:jar:1.11-8 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-core:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-common:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-annotations:jar:2.11.3 in the shaded jar.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] kubernetes-model-coordination-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 18 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluent
[[1;33mWARNING[m]   - 8 more...
[[1;33mWARNING[m] logging-interceptor-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger$1
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$Factory
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Level
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor
[[1;33mWARNING[m]   - okhttp3.logging.package-info
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$1
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger
[[1;33mWARNING[m] kubernetes-client-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 536 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.CertUtils
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.CustomResource
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.osgi.ManagedKubernetesClient
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.V1beta1ApiextensionAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.PatchUtils$SingletonHolder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.VersionInfo$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.utils.ReplaceValueStream
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.CreateFromServerGettable
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.ApiextensionsAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.Containerable
[[1;33mWARNING[m]   - 526 more...
[[1;33mWARNING[m] kubernetes-model-events-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$SeriesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$RegardingNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventSeriesFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, automaton-1.11-8.jar define 25 overlapping classes: 
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonMatcher
[[1;33mWARNING[m]   - dk.brics.automaton.ShuffleOperations$ShuffleConfiguration
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$Kind
[[1;33mWARNING[m]   - dk.brics.automaton.RunAutomaton
[[1;33mWARNING[m]   - dk.brics.automaton.Automaton
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonProvider
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$1
[[1;33mWARNING[m]   - dk.brics.automaton.MinimizationOperations$StateListNode
[[1;33mWARNING[m]   - dk.brics.automaton.State
[[1;33mWARNING[m]   - 15 more...
[[1;33mWARNING[m] kubernetes-model-metrics-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 30 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.ContainerMetricsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetrics
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl$ContainersNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListBuilder
[[1;33mWARNING[m]   - 20 more...
[[1;33mWARNING[m] kubernetes-model-networking-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 234 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressServiceBackend
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressClassFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressRuleFluentImpl$HttpNestedImpl
[[1;33mWARNING[m]   - 224 more...
[[1;33mWARNING[m] jackson-dataformat-yaml-2.10.5.jar, crd-generator-0.29.0-SNAPSHOT.jar define 15 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLMapper$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.snakeyaml.error.Mark
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.UTF8Reader
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.JacksonYAMLParseException
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.PackageVersion
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.snakeyaml.error.YAMLException
[[1;33mWARNING[m]   - 5 more...
[[1;33mWARNING[m] kubernetes-model-apiextensions-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrBoolBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionSpecFluent$ValidationNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionFluentImpl$SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrStringArraySerDe$Deserializer$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceValidationFluentImpl$OpenAPIV3SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsFluentImpl$NotNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.WebhookClientConfigFluentImpl$ServiceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrArrayFluent$SchemaNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1.JSONSchemaPropsOrBoolSerDe
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] generex-1.0.2.jar, crd-generator-0.29.0-SNAPSHOT.jar define 7 overlapping classes: 
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator
[[1;33mWARNING[m]   - com.mifmif.common.regex.Generex
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator$Step
[[1;33mWARNING[m]   - com.mifmif.common.regex.Node
[[1;33mWARNING[m]   - com.mifmif.common.regex.Main
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterable
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterator
[[1;33mWARNING[m] kubernetes-model-autoscaling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricSpecFluentImpl$ObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.CrossVersionObjectReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.ContainerResourceMetricStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricStatusFluent$ObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpecFluent$ScaleTargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, zjsonpatch-0.3.0.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.InsertCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Operation
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.CommandVisitor
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.guava.Strings
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.EditCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonDiff$EncodePathFunction
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.SequencesComparator
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Diff
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.ListUtils
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonPatch
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-admissionregistration-5.12.0.jar define 362 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluent$ObjectSelectorNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1.SubjectAccessReviewSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SubjectRulesReviewStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.ValidatingWebhookConfigurationBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authentication.TokenReviewFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectRulesReviewSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluentImpl$NamespaceSelectorNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookConfigurationFluentImpl$WebhooksNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectAccessReviewFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.MutatingWebhookFluent$ClientConfigNested
[[1;33mWARNING[m]   - 352 more...
[[1;33mWARNING[m] kubernetes-model-rbac-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 80 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.AggregationRuleFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.PolicyRuleFluent
[[1;33mWARNING[m]   - 70 more...
[[1;33mWARNING[m] kubernetes-model-certificates-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 60 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestConditionFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl
[[1;33mWARNING[m]   - 50 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-policy-5.12.0.jar define 162 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1.PodDisruptionBudgetList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.HostPortRangeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.EvictionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$AllowedCSIDriversNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.AllowedFlexVolumeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.IDRangeFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.SELinuxStrategyOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$FsGroupNestedImpl
[[1;33mWARNING[m]   - 152 more...
[[1;33mWARNING[m] jackson-datatype-jsr310-2.13.1.jar, crd-generator-0.29.0-SNAPSHOT.jar define 59 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.Jsr310KeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.PackageVersion
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.YearDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.key.Jsr310NullKeySerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.LocalDateTimeKeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.util.DurationUnitConverter
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.InstantSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.OffsetDateTimeSerializer
[[1;33mWARNING[m]   - 49 more...
[[1;33mWARNING[m] kubernetes-model-flowcontrol-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 132 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowSchemaConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowDistinguisherMethodBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfigurationFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReference
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PolicyRulesWithSubjects
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationListFluent$ItemsNested
[[1;33mWARNING[m]   - 122 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, crd-annotations-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$Stability
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$1
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedType
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedProperty
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange$VersionParser
[[1;33mWARNING[m]   - io.strimzi.api.annotations.KubeVersion
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, okio-1.15.0.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - okio.ByteString
[[1;33mWARNING[m]   - okio.Source
[[1;33mWARNING[m]   - okio.ForwardingSink
[[1;33mWARNING[m]   - okio.BufferedSource
[[1;33mWARNING[m]   - okio.Util
[[1;33mWARNING[m]   - okio.AsyncTimeout$1
[[1;33mWARNING[m]   - okio.HashingSource
[[1;33mWARNING[m]   - okio.GzipSink
[[1;33mWARNING[m]   - okio.Okio$1
[[1;33mWARNING[m]   - okio.Pipe$PipeSink
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] kubernetes-model-discovery-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 88 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.ForZoneBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointFluent$TargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluentImpl$ConditionsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointConditionsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 78 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-annotations-2.11.3.jar define 68 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonAutoDetect
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonInclude
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.ObjectIdGenerators
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Features
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonIgnore
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSetter
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonTypeInfo$None
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Shape
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSubTypes
[[1;33mWARNING[m]   - 58 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-extensions-5.12.0.jar define 264 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetConditionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DeploymentStrategyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicySpecFluent$IngressNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressSpecFluent$RulesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyPeerBuilder
[[1;33mWARNING[m]   - 254 more...
[[1;33mWARNING[m] kubernetes-model-node-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 78 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.OverheadBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.Scheduling
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.SchedulingFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.RuntimeClassSpecFluent$OverheadNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - 68 more...
[[1;33mWARNING[m] kubernetes-model-core-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 2394 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.BaseKubernetesListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.StatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.KubeSchemaFluentImpl$APIResourceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.NodeListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ResourceQuotaListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluentImpl$APIServiceStatusObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluent$VsphereVirtualDiskVolumeSourceObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ProbeFluentImpl$HttpGetNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.PatchOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ServerAddressByClientCIDRFluentImpl
[[1;33mWARNING[m]   - 2384 more...
[[1;33mWARNING[m] slf4j-api-1.7.25.jar, crd-generator-0.29.0-SNAPSHOT.jar define 34 overlapping classes: 
[[1;33mWARNING[m]   - org.slf4j.helpers.SubstituteLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.NamedLoggerBase
[[1;33mWARNING[m]   - org.slf4j.helpers.NOPMDCAdapter
[[1;33mWARNING[m]   - org.slf4j.MarkerFactory
[[1;33mWARNING[m]   - org.slf4j.helpers.BasicMarker
[[1;33mWARNING[m]   - org.slf4j.spi.LoggerFactoryBinder
[[1;33mWARNING[m]   - org.slf4j.MDC$MDCCloseable
[[1;33mWARNING[m]   - org.slf4j.spi.LocationAwareLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.MessageFormatter
[[1;33mWARNING[m]   - org.slf4j.helpers.Util$ClassContextSecurityManager
[[1;33mWARNING[m]   - 24 more...
[[1;33mWARNING[m] kubernetes-model-apps-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 212 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentStrategyFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluent$DeploymentDataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluentImpl$PersistentVolumeClaimDataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetCondition
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - 202 more...
[[1;33mWARNING[m] kubernetes-model-scheduling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassFluent$MetadataNested
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-core-2.11.3.jar define 117 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.JsonGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.json.JsonReadFeature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.ThreadLocalBufferManager$ThreadLocalBufferManagerHolder
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.Separators
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.io.SegmentedStringWriter
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.TreeNode
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.sym.Name
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.RequestPayload
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.JsonGeneratorDelegate
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.async.NonBlockingInputFeeder
[[1;33mWARNING[m]   - 107 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-common-5.12.0.jar define 16 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Plural
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Group
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer$CancelUnwrapped
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.PrinterColumn
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.UnwrappedTypeResolverBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Singular
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.StatusReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.SpecReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Version
[[1;33mWARNING[m]   - 6 more...
[[1;33mWARNING[m] snakeyaml-1.26.jar, crd-generator-0.29.0-SNAPSHOT.jar define 216 overlapping classes: 
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockNode
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingSimpleValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectDocumentEnd
[[1;33mWARNING[m]   - org.yaml.snakeyaml.Yaml$3
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockSequenceItem
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockSequenceEntry
[[1;33mWARNING[m]   - org.yaml.snakeyaml.util.ArrayUtils
[[1;33mWARNING[m]   - org.yaml.snakeyaml.tokens.Token$ID
[[1;33mWARNING[m]   - org.yaml.snakeyaml.reader.StreamReader
[[1;33mWARNING[m]   - 206 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-batch-5.12.0.jar define 112 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobStatusFluentImpl$ActiveNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluent$TemplateNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluentImpl$TemplateNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.Job
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobListFluent
[[1;33mWARNING[m]   - 102 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-storageclass-5.12.0.jar define 172 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIStorageCapacityListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeDriverFluentImpl$AllocatableNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.StorageClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.TokenRequestFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSINodeDriverFluent$AllocatableNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIDriverSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSpecFluent
[[1;33mWARNING[m]   - 162 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-databind-2.11.3.jar define 657 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$NoAnnotations
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.jsontype.BasicPolymorphicTypeValidator$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.BeanDescription
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.deser.impl.BeanAsArrayBuilderDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotatedMethodMap
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.SerializerProvider
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$OneAnnotation
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.StaticListSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.NumberSerializers$ShortSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.BeanSerializerFactory
[[1;33mWARNING[m]   - 647 more...
[[1;33mWARNING[m] okhttp-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 208 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.WebSocket
[[1;33mWARNING[m]   - okhttp3.Cookie$Builder
[[1;33mWARNING[m]   - okhttp3.internal.http.HttpHeaders
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$ReaderRunnable
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Reader$ContinuationSource
[[1;33mWARNING[m]   - okhttp3.internal.tls.OkHostnameVerifier
[[1;33mWARNING[m]   - okhttp3.Cache$Entry
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$3
[[1;33mWARNING[m]   - okhttp3.internal.ws.RealWebSocket$Streams
[[1;33mWARNING[m]   - okhttp3.CacheControl$Builder
[[1;33mWARNING[m]   - 198 more...
[[1;33mWARNING[m] maven-shade-plugin has detected that some class files are
[[1;33mWARNING[m] present in two or more JARs. When this happens, only one
[[1;33mWARNING[m] single version of the class is copied to the uber jar.
[[1;33mWARNING[m] Usually this is not harmful and you can skip these warnings,
[[1;33mWARNING[m] otherwise try to manually exclude artifacts based on
[[1;33mWARNING[m] mvn dependency:tree -Ddetail=true and the above output.
[[1;33mWARNING[m] See http://maven.apache.org/plugins/maven-shade-plugin/
[[1;34mINFO[m] Replacing original artifact with shaded artifact.
[[1;34mINFO[m] Replacing /home/cloud-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT.jar with /home/cloud-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-shaded.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------------< [0;36mio.strimzi:api[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding api 0.29.0-SNAPSHOT                                      [5/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/api/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1-eo)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-doc)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 99 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-test-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mapi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mapi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m------------------------< [0;36mio.strimzi:mockkube[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding mockkube 0.29.0-SNAPSHOT                                 [6/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/mockkube/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mmockkube[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mmockkube[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/mockkube/target/mockkube-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:config-model[0;1m >-----------------------[m
[[1;34mINFO[m] [1mBuilding config-model 0.29.0-SNAPSHOT                             [7/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/config-model/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/config-model/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mconfig-model[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mconfig-model[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/config-model/target/config-model-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------< [0;36mio.strimzi:certificate-manager[0;1m >-------------------[m
[[1;34mINFO[m] [1mBuilding certificate-manager 0.29.0-SNAPSHOT                      [8/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/certificate-manager/target/certificate-manager-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:operator-common[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding operator-common 0.29.0-SNAPSHOT                          [9/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/cloud-user/strimzi-kafka-operator/operator-common/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 9 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36moperator-common[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36moperator-common[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/cloud-user/strimzi-kafka-operator/operator-common/target/operator-common-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-----------------------< [0;36mio.strimzi:systemtest[0;1m >------------------------[m
[[1;34mINFO[m] [1mBuilding systemtest 0.29.0-SNAPSHOT                              [10/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 3 resources
[[1;34mINFO[m] Copying 2 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 31 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;31mERROR[m] Feb 23, 2022 3:31:52 AM org.junit.platform.launcher.core.LauncherConfigurationParameters loadClasspathResource
[[1;31mERROR[m] INFO: Loading JUnit Platform configuration parameters from classpath resource [file:/home/cloud-user/strimzi-kafka-operator/systemtest/target/test-classes/junit-platform.properties].
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;33mWARNING[m] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file /home/cloud-user/strimzi-kafka-operator/systemtest/target/surefire-reports/2022-02-23T03-31-40_928-jvmRun1.dumpstream
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36msystemtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/cloud-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/cloud-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36msystemtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
2022-02-23 08:31:54 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-02-23 08:31:54 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-02-23 08:31:54 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-02-23 08:31:54 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-02-23 08:31:54 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-02-23 08:31:54 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-02-23 08:31:54 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.SecurityST
2022-02-23 08:31:54 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-02-23 08:31:54 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.security.SecurityST
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:220] Used environment variables:
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:221] CONFIG: /home/cloud-user/strimzi-kafka-operator/systemtest/config.json
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] STRIMZI_RBAC_SCOPE: CLUSTER
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OLM_APP_BUNDLE_PREFIX: strimzi-cluster-operator
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_CLIENTS_VERSION: 0.2.0
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OLM_SOURCE_NAMESPACE: openshift-marketplace
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] CLUSTER_OPERATOR_INSTALL_TYPE: BUNDLE
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] STRIMZI_COMPONENTS_LOG_LEVEL: INFO
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] SKIP_TEARDOWN: false
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] LB_FINALIZERS: false
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OLM_OPERATOR_DEPLOYMENT_NAME: strimzi-cluster-operator
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] DOCKER_ORG: strimzi
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_LOG_DIR: /home/cloud-user/strimzi-kafka-operator/systemtest/../systemtest/target/logs/
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] COMPONENTS_IMAGE_PULL_POLICY: IfNotPresent
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] DOCKER_REGISTRY: quay.io
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_CLIENT_IMAGE: quay.io/strimzi/test-client:latest-kafka-3.1.0
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] SYSTEM_TEST_STRIMZI_IMAGE_PULL_SECRET: 
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_ADMIN_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-admin:0.2.0-kafka-3.1.0
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_HTTP_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-http-producer:0.2.0
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OLM_OPERATOR_NAME: strimzi-kafka-operator
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] DOCKER_TAG: latest
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OLM_SOURCE_NAME: community-operators
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] STRIMZI_FEATURE_GATES: 
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] CLIENTS_KAFKA_VERSION: 3.1.0
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_HTTP_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-http-consumer:0.2.0
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] STRIMZI_LOG_LEVEL: DEBUG
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] ST_KAFKA_VERSION: 3.1.0
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OPERATOR_IMAGE_PULL_POLICY: Always
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] DEFAULT_TO_DENY_NETWORK_POLICIES: true
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-producer:0.2.0-kafka-3.1.0
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] BRIDGE_IMAGE: latest-released
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_STREAMS_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-streams:0.2.0-kafka-3.1.0
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] TEST_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-consumer:0.2.0-kafka-3.1.0
2022-02-23 08:31:54 [ForkJoinPool-1-worker-3] [32mINFO [m [Environment:222] OLM_OPERATOR_VERSION: 0.26.1
2022-02-23 08:31:55 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeCluster:87] Using cluster: minikube
2022-02-23 08:31:55 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:60] Cluster default namespace is 'default'
2022-02-23 08:31:55 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:195] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@66c82f13
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-02-23 08:31:55 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:252] Install ClusterOperator via Yaml bundle
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-02-23 08:31:56 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-02-23 08:31:57 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-02-23 08:32:27 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-02-23 08:32:27 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-02-23 08:32:37 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-02-23 08:32:37 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: security-st
2022-02-23 08:32:37 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: security-st
2022-02-23 08:32:37 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: security-st
2022-02-23 08:32:37 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 08:32:37 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 08:32:37 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCustomClusterCACertRenew-STARTED
2022-02-23 08:32:37 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-STARTED
2022-02-23 08:32:37 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 08:32:37 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-0 for test case:testCustomClusterCACertRenew
2022-02-23 08:32:37 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-0
2022-02-23 08:32:37 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-0
2022-02-23 08:32:37 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-0
2022-02-23 08:32:37 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 08:32:37 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-1 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-02-23 08:32:37 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1828] Generating custom RootCA, IntermediateCA, and ClusterCA, ClientsCA for Strimzi and PEM bundles.
2022-02-23 08:32:37 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-1
2022-02-23 08:32:37 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-1
2022-02-23 08:32:37 [ForkJoinPool-1-worker-1] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-1
2022-02-23 08:32:37 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:70] Creating secret my-cluster-864956373-cluster-ca-cert
2022-02-23 08:32:37 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:601] Creating a cluster
2022-02-23 08:32:38 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-864956373 in namespace namespace-1
2022-02-23 08:32:38 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-1
2022-02-23 08:32:38 [ForkJoinPool-1-worker-1] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkas' with unstable version 'v1beta2'
2022-02-23 08:32:38 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-864956373 will have desired state: Ready
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1844] Deploy all certificates and keys as secrets.
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:150] Waiting for Secret: my-cluster-544503089-cluster-ca-cert to be deleted
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:154] Secret: my-cluster-544503089-cluster-ca-cert successfully deleted
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-544503089-cluster-ca-cert
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:50] Secret my-cluster-544503089-cluster-ca-cert created
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:150] Waiting for Secret: my-cluster-544503089-cluster-ca to be deleted
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:154] Secret: my-cluster-544503089-cluster-ca successfully deleted
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:150] Waiting for Secret: my-cluster-544503089-clients-ca-cert to be deleted
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:154] Secret: my-cluster-544503089-clients-ca-cert successfully deleted
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-544503089-clients-ca-cert
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:50] Secret my-cluster-544503089-clients-ca-cert created
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:150] Waiting for Secret: my-cluster-544503089-clients-ca to be deleted
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:154] Secret: my-cluster-544503089-clients-ca successfully deleted
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1805] Check ClusterCA and ClientsCA certificates.
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-544503089 in namespace namespace-1
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-0
2022-02-23 08:32:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-544503089 will have desired state: Ready
2022-02-23 08:34:47 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-864956373 is in desired state: Ready
2022-02-23 08:34:47 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-565311866-258341322 in namespace namespace-1
2022-02-23 08:34:47 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-1
2022-02-23 08:34:47 [ForkJoinPool-1-worker-1] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkausers' with unstable version 'v1beta2'
2022-02-23 08:34:47 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-565311866-258341322 will have desired state: Ready
2022-02-23 08:34:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-565311866-258341322 is in desired state: Ready
2022-02-23 08:34:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-725554750-388286007 in namespace namespace-1
2022-02-23 08:34:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-1
2022-02-23 08:34:48 [ForkJoinPool-1-worker-1] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkatopics' with unstable version 'v1beta2'
2022-02-23 08:34:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-725554750-388286007 will have desired state: Ready
2022-02-23 08:34:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-725554750-388286007 is in desired state: Ready
2022-02-23 08:34:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-864956373-kafka-clients in namespace namespace-1
2022-02-23 08:34:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-1
2022-02-23 08:34:49 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-864956373-kafka-clients will be ready
2022-02-23 08:34:52 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-864956373-kafka-clients is ready
2022-02-23 08:34:52 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 08:34:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:674] Checking produced and consumed messages to pod:my-cluster-864956373-kafka-clients-67d9958d9c-5dns6
2022-02-23 08:34:52 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@19bcbc25, messages=[], arguments=[--bootstrap-server, my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092, --max-messages, 100, --topic, my-topic-725554750-388286007], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-864956373-kafka-clients-67d9958d9c-5dns6', podNamespace='namespace-1', bootstrapServer='my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-725554750-388286007', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7b569b16}
2022-02-23 08:34:52 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092:my-topic-725554750-388286007 from pod my-cluster-864956373-kafka-clients-67d9958d9c-5dns6
2022-02-23 08:34:52 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-864956373-kafka-clients-67d9958d9c-5dns6 -n namespace-1 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092 --max-messages 100 --topic my-topic-725554750-388286007
2022-02-23 08:34:54 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-02-23 08:34:54 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-02-23 08:34:54 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@673d5d41, messages=[], arguments=[--group-instance-id, instance117143843, --bootstrap-server, my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092, --max-messages, 100, --topic, my-topic-725554750-388286007, --group-id, my-consumer-group-839638911], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-864956373-kafka-clients-67d9958d9c-5dns6', podNamespace='namespace-1', bootstrapServer='my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-725554750-388286007', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-839638911', consumerInstanceId='instance117143843', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5c747c22}
2022-02-23 08:34:54 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092#my-topic-725554750-388286007 from pod my-cluster-864956373-kafka-clients-67d9958d9c-5dns6
2022-02-23 08:34:54 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-864956373-kafka-clients-67d9958d9c-5dns6 -n namespace-1 -- /opt/kafka/consumer.sh --group-instance-id instance117143843 --bootstrap-server my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092 --max-messages 100 --topic my-topic-725554750-388286007 --group-id my-consumer-group-839638911
2022-02-23 08:35:00 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 08:35:00 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 08:35:00 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:131] Waiting for Secret my-cluster-864956373-cluster-ca-cert certificate change
2022-02-23 08:35:00 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:138] Certificate in Secret my-cluster-864956373-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUbTjhR7CEnTH6yinLJkDWsMY5mUYwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjAyMjMwODMyMzhaFw0yMzAyMjMwODMyMzhaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQC6GtzTlSwKtTru5zyufkYXsb6BzHdfJv7Z+OxoFg5d
rJ2y+1anK4TIW0gLVJg243uixXkY1tnBoQoRWy0mL/GOPi6vber/8sdj2If1jro+
Jor1UcOgqWh4OT26ZqUEe0G5hXRNYHTy1X7uYvyKO1vnWdVtfginLMsfD4SrZtQd
SKZpYB1HRkULv3ecfkFzGhJI/YZKZccQXWLUXeYaaz83s6CZ6C8kCH+u4Db27Cwl
lq0VHTJOkPnKlmb93fn3KOFiZqL5bnqigtxixv1YVmS38DO5vFVHL91JgvyJec/Q
mZHjdWPVP+NynfwWz5cxWJcFiKLVXW9H2HrnT7jUXZfrQ0RZLubLx3QhyxNRtn+b
Hg6oiBoAk8V5+W4k79tb9HN0JFdwlbvBAdixuk2NkiDYBW7WFMEr66dtKmnubfIv
F3YqkYWWwsl/zNkhjbDRPdnoiO3vzWaLOQHZDa6UCnygUFVU0yX50+j/inR2GWtu
kn2v745V/fvKYNSkDdrMsQ25BAE49CgZKx1/TaXWGXLSG/QbQ+mHNMBl6X9rt1vg
4ZnqIfbCd0Q28OtQVLCvJWVrG4NbccRvaDXe0qrG420M3Q5L043l5SgXJuwphUkP
HimxsQNxC1PMygj2xOAGFjrlP40q/flgOIK0Q4nHgcLGZKXCcJWQX1GAkxRqyGy4
AQIDAQABo0UwQzAdBgNVHQ4EFgQUfeZ2gRnlnUMoiq54IWq4QjNDznIwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AGfeL/JOXzgKg5Fg/PUa/GD3Au2L1fH/eVFjMj4w00ncr9AO4z30nNUopHB/d0HC
ORJxN823L/XHne/4dvuZwW17kQDX2pP/P6a629vXqZqXUB80LXC9ZAQDsu3IajI0
bAYj2W4TtccVG/6StvKbSh7ob+YWmDzcg6NQejYao0nkB/fUWfqsW1900sf2NhBP
j2WGuVPT+G4bAPUq4pimXd4aRHJwuyNtfvtwgk/W+jizrlQxeS9HyOzeMWRwNgt9
cNtleoNqCwv/A8TqTBdpqx7hVwH36faGcn4zzCxhyuLToykprjc8gOMsZN6bxUq2
Hm8/MBTvkR8lg0UNLVB90VqWq8lC8D898MqXMUWCfYNFdDDXQ7VDqckXs+9gwa57
tbCBIY5RMVF6HB73+hAThQiaBWBombXPTCME+d0G3xXzn5p2X1W/nwJ6oKyj3Vkn
dRH40O/6Defq3uh0ufZueNf0umrG0yMG8NmCo2pojbETCUoh0aLprs282lfQTVz1
qmSiDzUKfQtYOuLcbi6dUvqSj/DvOHRbjZXSyTnlSH5Cp1rVJvMFwhUDVWnD2shZ
kbkDFahP8r7Mx1gbsMvwZLGZ/FA8ObXgSu0XWoHtvXjlCKPNRp/Ta+AnpLLynVWb
lWOpj2d4x1TaCQMxIJiz9apmNmgTLRUbgr76v6yxpt2v
-----END CERTIFICATE-----

2022-02-23 08:35:00 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaUtils:178] Waiting for cluster stability
2022-02-23 08:36:02 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaUtils:206] Kafka cluster is stable after 61 polls.
2022-02-23 08:36:02 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:686] Checking produced and consumed messages to pod:my-cluster-864956373-kafka-clients-67d9958d9c-5dns6
2022-02-23 08:36:02 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@33a92c67, messages=[], arguments=[--bootstrap-server, my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092, --max-messages, 100, --topic, my-topic-725554750-388286007], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-864956373-kafka-clients-67d9958d9c-5dns6', podNamespace='namespace-1', bootstrapServer='my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-725554750-388286007', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5b2d5009}
2022-02-23 08:36:02 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092:my-topic-725554750-388286007 from pod my-cluster-864956373-kafka-clients-67d9958d9c-5dns6
2022-02-23 08:36:02 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-864956373-kafka-clients-67d9958d9c-5dns6 -n namespace-1 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092 --max-messages 100 --topic my-topic-725554750-388286007
2022-02-23 08:36:04 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-02-23 08:36:04 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-02-23 08:36:04 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5ffd966c, messages=[], arguments=[--group-instance-id, instance2124205505, --bootstrap-server, my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092, --max-messages, 100, --topic, my-topic-725554750-388286007, --group-id, my-consumer-group-839638911], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-864956373-kafka-clients-67d9958d9c-5dns6', podNamespace='namespace-1', bootstrapServer='my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-725554750-388286007', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-839638911', consumerInstanceId='instance2124205505', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6ee13ea1}
2022-02-23 08:36:04 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092#my-topic-725554750-388286007 from pod my-cluster-864956373-kafka-clients-67d9958d9c-5dns6
2022-02-23 08:36:04 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-864956373-kafka-clients-67d9958d9c-5dns6 -n namespace-1 -- /opt/kafka/consumer.sh --group-instance-id instance2124205505 --bootstrap-server my-cluster-864956373-kafka-bootstrap.namespace-1.svc:9092 --max-messages 100 --topic my-topic-725554750-388286007 --group-id my-consumer-group-839638911
2022-02-23 08:36:05 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-544503089 is in desired state: Ready
2022-02-23 08:36:05 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1562] Change of kafka validity and renewal days - reconciliation should start.
2022-02-23 08:36:05 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-544503089-kafka rolling update
2022-02-23 08:36:09 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 08:36:09 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 08:36:09 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 08:36:09 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:309] Delete all resources for testAutoRenewCaCertsTriggerByExpiredCertificate
2022-02-23 08:36:09 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-725554750-388286007 in namespace namespace-1
2022-02-23 08:36:19 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-864956373-kafka-clients in namespace namespace-1
2022-02-23 08:36:59 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-565311866-258341322 in namespace namespace-1
2022-02-23 08:37:09 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-864956373 in namespace namespace-1
2022-02-23 08:37:09 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-1, for cruise control Kafka cluster my-cluster-864956373
2022-02-23 08:37:19 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 08:37:19 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-1 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-02-23 08:37:51 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 08:37:51 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-STARTED
2022-02-23 08:38:02 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-FINISHED
2022-02-23 08:38:02 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 08:38:02 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 08:38:02 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAclWithSuperUser-STARTED
2022-02-23 08:38:06 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 08:38:06 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-2 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-02-23 08:38:06 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-2
2022-02-23 08:38:06 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-2
2022-02-23 08:38:06 [ForkJoinPool-1-worker-5] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-2
2022-02-23 08:38:06 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:601] Creating a cluster
2022-02-23 08:38:06 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-36262540 in namespace namespace-2
2022-02-23 08:38:06 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-2
2022-02-23 08:38:06 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-36262540 will have desired state: Ready
2022-02-23 08:39:25 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-544503089-kafka has been successfully rolled
2022-02-23 08:39:25 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-544503089-kafka to be ready
2022-02-23 08:39:51 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-544503089 will have desired state: Ready
2022-02-23 08:39:51 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-544503089 is in desired state: Ready
2022-02-23 08:39:51 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-544503089 is ready
2022-02-23 08:39:51 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1592] Initial ClusterCA cert dates: Tue Feb 22 03:32:38 EST 2022 --> Thu Mar 24 04:32:38 EDT 2022
2022-02-23 08:39:51 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1593] Changed ClusterCA cert dates: Tue Feb 22 03:32:38 EST 2022 --> Thu Mar 24 04:32:38 EDT 2022
2022-02-23 08:39:51 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1594] KafkaBroker cert creation dates: Wed Feb 23 03:33:49 EST 2022 --> Tue Mar 15 04:33:49 EDT 2022
2022-02-23 08:39:51 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1595] KafkaBroker cert changed dates:  Wed Feb 23 03:37:27 EST 2022 --> Sun Sep 11 04:37:27 EDT 2022
2022-02-23 08:39:51 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1596] Zookeeper cert creation dates: Wed Feb 23 03:32:41 EST 2022 --> Tue Mar 15 04:32:41 EDT 2022
2022-02-23 08:39:51 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1597] Zookeeper cert changed dates:  Wed Feb 23 03:36:07 EST 2022 --> Sun Sep 11 04:36:07 EDT 2022
2022-02-23 08:39:51 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 08:39:51 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:309] Delete all resources for testCustomClusterCACertRenew
2022-02-23 08:39:51 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-544503089 in namespace namespace-0
2022-02-23 08:40:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 08:40:01 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-0 for test case:testCustomClusterCACertRenew
2022-02-23 08:40:28 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCustomClusterCACertRenew-FINISHED
2022-02-23 08:40:28 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 08:40:28 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 08:40:28 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertificates-STARTED
2022-02-23 08:40:32 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 08:40:32 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-3 for test case:testAclWithSuperUser
2022-02-23 08:40:32 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-3
2022-02-23 08:40:32 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-3
2022-02-23 08:40:32 [ForkJoinPool-1-worker-1] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-3
2022-02-23 08:40:32 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-2061679835 in namespace namespace-3
2022-02-23 08:40:32 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-3
2022-02-23 08:40:32 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-2061679835 will have desired state: Ready
2022-02-23 08:40:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-36262540 is in desired state: Ready
2022-02-23 08:40:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-1835957211-1006556617 in namespace namespace-3
2022-02-23 08:40:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-2
2022-02-23 08:40:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-1835957211-1006556617 will have desired state: Ready
2022-02-23 08:40:49 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-1835957211-1006556617 is in desired state: Ready
2022-02-23 08:40:49 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-752966107-636718435 in namespace namespace-3
2022-02-23 08:40:49 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-2
2022-02-23 08:40:49 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-752966107-636718435 will have desired state: Ready
2022-02-23 08:40:50 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-752966107-636718435 is in desired state: Ready
2022-02-23 08:40:50 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-36262540-kafka-clients in namespace namespace-3
2022-02-23 08:40:50 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-2
2022-02-23 08:40:50 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-36262540-kafka-clients will be ready
2022-02-23 08:40:52 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-36262540-kafka-clients is ready
2022-02-23 08:40:52 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 08:40:52 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:467] Checking produced and consumed messages to pod:my-cluster-36262540-kafka-clients-5c7bb5b45b-nzmzq
2022-02-23 08:40:52 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5d3a5c3e, messages=[], arguments=[--bootstrap-server, my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092, --max-messages, 100, --topic, my-topic-752966107-636718435], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-36262540-kafka-clients-5c7bb5b45b-nzmzq', podNamespace='namespace-2', bootstrapServer='my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092', topicName='my-topic-752966107-636718435', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1f8d1f78}
2022-02-23 08:40:52 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092:my-topic-752966107-636718435 from pod my-cluster-36262540-kafka-clients-5c7bb5b45b-nzmzq
2022-02-23 08:40:52 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-36262540-kafka-clients-5c7bb5b45b-nzmzq -n namespace-2 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092 --max-messages 100 --topic my-topic-752966107-636718435
2022-02-23 08:40:55 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-02-23 08:40:55 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-02-23 08:40:55 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7f7698ef, messages=[], arguments=[--group-instance-id, instance1333322797, --bootstrap-server, my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092, --max-messages, 100, --topic, my-topic-752966107-636718435, --group-id, my-consumer-group-1698015033], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-36262540-kafka-clients-5c7bb5b45b-nzmzq', podNamespace='namespace-2', bootstrapServer='my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092', topicName='my-topic-752966107-636718435', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1698015033', consumerInstanceId='instance1333322797', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@33bd07bc}
2022-02-23 08:40:55 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092#my-topic-752966107-636718435 from pod my-cluster-36262540-kafka-clients-5c7bb5b45b-nzmzq
2022-02-23 08:40:55 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-36262540-kafka-clients-5c7bb5b45b-nzmzq -n namespace-2 -- /opt/kafka/consumer.sh --group-instance-id instance1333322797 --bootstrap-server my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092 --max-messages 100 --topic my-topic-752966107-636718435 --group-id my-consumer-group-1698015033
2022-02-23 08:41:00 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 08:41:00 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 08:41:00 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:481] Triggering CA cert renewal by adding the annotation
2022-02-23 08:41:00 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:493] Patching secret my-cluster-36262540-clients-ca with strimzi.io/force-replace
2022-02-23 08:41:00 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:503] Wait for kafka to rolling restart (1)...
2022-02-23 08:41:00 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-36262540-kafka rolling update
2022-02-23 08:41:42 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-2061679835 is in desired state: Ready
2022-02-23 08:41:42 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-744500066-743083133 in namespace namespace-3
2022-02-23 08:41:42 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-3
2022-02-23 08:41:42 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-744500066-743083133 will have desired state: Ready
2022-02-23 08:41:43 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-744500066-743083133 is in desired state: Ready
2022-02-23 08:41:43 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-523376528-1853355493 in namespace namespace-3
2022-02-23 08:41:43 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-3
2022-02-23 08:41:43 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-523376528-1853355493 will have desired state: Ready
2022-02-23 08:41:44 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-523376528-1853355493 is in desired state: Ready
2022-02-23 08:41:44 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1108] Checking kafka super user:my-user-523376528-1853355493 that is able to send messages to topic:my-topic-744500066-743083133
2022-02-23 08:41:44 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 08:41:44 [ForkJoinPool-1-worker-1] [32mINFO [m [ProducerConfig:376] ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.49.2:31485]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2044649307
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 6000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties9707532253973873890.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties7547966356203214063.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-02-23 08:41:44 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-02-23 08:41:44 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-23 08:41:44 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1645605704498
2022-02-23 08:41:44 [kafka-producer-network-thread | producer-2044649307] [32mINFO [m [Metadata:402] [Producer clientId=producer-2044649307] Resetting the last seen epoch of partition my-topic-744500066-743083133-0 to 0 since the associated topicId changed from null to VqgAazmwSAOweGkXi0hR1A
2022-02-23 08:41:44 [kafka-producer-network-thread | producer-2044649307] [32mINFO [m [Metadata:287] [Producer clientId=producer-2044649307] Cluster ID: syHbhoqYTieMX4gI5g46fg
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [ExternalKafkaClient:182] Sent 100 messages.
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaProducer:1228] [Producer clientId=producer-2044649307] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:83] App info kafka.producer for producer-2044649307 unregistered
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1122] Checking kafka super user:my-user-523376528-1853355493 that is able to read messages to topic:my-topic-744500066-743083133 regardless that we configured Acls with only write operation
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerConfig:376] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.49.2:31485]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-992431420
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-379818635
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties7227431749405515548.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties458304690850431514.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1645605705281
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaConsumer:966] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Subscribed to topic(s): my-topic-744500066-743083133
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [Metadata:402] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Resetting the last seen epoch of partition my-topic-744500066-743083133-0 to 0 since the associated topicId changed from null to VqgAazmwSAOweGkXi0hR1A
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [Metadata:287] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Cluster ID: syHbhoqYTieMX4gI5g46fg
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:853] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Discovered group coordinator 192.168.49.2:31551 (id: 2147483645 rack: null)
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:535] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] (Re-)joining group
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:1000] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Request joining group due to: need to re-join with the given member-id
2022-02-23 08:41:45 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:535] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] (Re-)joining group
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:595] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Successfully joined group with generation Generation{generationId=1, memberId='consumer-992431420-de03c6c4-e68d-4e99-97ea-eeb2cd910348', protocol='range'}
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:652] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Finished assignment for group at generation 1: {consumer-992431420-de03c6c4-e68d-4e99-97ea-eeb2cd910348=Assignment(partitions=[my-topic-744500066-743083133-0])}
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:761] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Successfully synced group in generation Generation{generationId=1, memberId='consumer-992431420-de03c6c4-e68d-4e99-97ea-eeb2cd910348', protocol='range'}
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:279] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Notifying assignor about the new Assignment(partitions=[my-topic-744500066-743083133-0])
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:291] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Adding newly assigned partitions: my-topic-744500066-743083133-0
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:1388] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Found no committed offset for partition my-topic-744500066-743083133-0
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [SubscriptionState:398] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Resetting offset for partition my-topic-744500066-743083133-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.49.2:32049 (id: 0 rack: null)], epoch=0}}.
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ExternalKafkaClient:224] Received 100 messages.
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:310] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Revoke previously assigned partitions my-topic-744500066-743083133-0
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:1060] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Member consumer-992431420-de03c6c4-e68d-4e99-97ea-eeb2cd910348 sending LeaveGroup request to coordinator 192.168.49.2:31551 (id: 2147483645 rack: null) due to the consumer is being closed
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:972] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Resetting generation due to: consumer pro-actively leaving the group
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:1000] [Consumer clientId=consumer-992431420, groupId=my-consumer-group-379818635] Request joining group due to: consumer pro-actively leaving the group
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:83] App info kafka.consumer for consumer-992431420 unregistered
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-523376528-1853355493-non-super-user in namespace namespace-3
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-3
2022-02-23 08:41:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-523376528-1853355493-non-super-user will have desired state: Ready
2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-523376528-1853355493-non-super-user is in desired state: Ready
2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1148] Checking kafka super user:my-user-523376528-1853355493-non-super-user that is able to send messages to topic:my-topic-744500066-743083133
2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ProducerConfig:376] ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.49.2:31485]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-442302890
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 6000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties13325345994168549388.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties13568573798699181595.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1645605709643
2022-02-23 08:41:49 [kafka-producer-network-thread | producer-442302890] [32mINFO [m [Metadata:402] [Producer clientId=producer-442302890] Resetting the last seen epoch of partition my-topic-744500066-743083133-0 to 0 since the associated topicId changed from null to VqgAazmwSAOweGkXi0hR1A
2022-02-23 08:41:49 [kafka-producer-network-thread | producer-442302890] [32mINFO [m [Metadata:287] [Producer clientId=producer-442302890] Cluster ID: syHbhoqYTieMX4gI5g46fg
2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ExternalKafkaClient:182] Sent 100 messages.
2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaProducer:1228] [Producer clientId=producer-442302890] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:83] App info kafka.producer for producer-442302890 unregistered
2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1156] Checking kafka super user:my-user-523376528-1853355493-non-super-user that is not able to read messages to topic:my-topic-744500066-743083133 because of defined ACLs on only write operation
2022-02-23 08:41:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerConfig:376] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.49.2:31485]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-1187815637
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-27316472
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties16721440939321315409.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties9036080763397920807.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-02-23 08:41:50 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-02-23 08:41:50 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-23 08:41:50 [ForkJoinPool-1-worker-1] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1645605710033
2022-02-23 08:41:50 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaConsumer:966] [Consumer clientId=consumer-1187815637, groupId=my-consumer-group-27316472] Subscribed to topic(s): my-topic-744500066-743083133
2022-02-23 08:41:50 [ForkJoinPool-1-worker-1] [32mINFO [m [Metadata:402] [Consumer clientId=consumer-1187815637, groupId=my-consumer-group-27316472] Resetting the last seen epoch of partition my-topic-744500066-743083133-0 to 0 since the associated topicId changed from null to VqgAazmwSAOweGkXi0hR1A
2022-02-23 08:41:50 [ForkJoinPool-1-worker-1] [32mINFO [m [Metadata:287] [Consumer clientId=consumer-1187815637, groupId=my-consumer-group-27316472] Cluster ID: syHbhoqYTieMX4gI5g46fg
2022-02-23 08:41:50 [ForkJoinPool-1-worker-1] [32mINFO [m [ConsumerCoordinator:261] [Consumer clientId=consumer-1187815637, groupId=my-consumer-group-27316472] FindCoordinator request hit fatal exception
org.apache.kafka.common.errors.GroupAuthorizationException: Not authorized to access group: my-consumer-group-27316472
2022-02-23 08:41:50 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 08:41:50 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:309] Delete all resources for testAclWithSuperUser
2022-02-23 08:41:50 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-523376528-1853355493 in namespace namespace-3
2022-02-23 08:42:00 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-523376528-1853355493-non-super-user in namespace namespace-3
2022-02-23 08:42:10 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-744500066-743083133 in namespace namespace-3
2022-02-23 08:42:10 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-2061679835 in namespace namespace-3
2022-02-23 08:42:20 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 08:42:20 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-3 for test case:testAclWithSuperUser
2022-02-23 08:42:25 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-36262540-kafka has been successfully rolled
2022-02-23 08:42:25 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:524] Wait for kafka to rolling restart (2)...
2022-02-23 08:42:25 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-36262540-kafka rolling update
2022-02-23 08:42:47 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAclWithSuperUser-FINISHED
2022-02-23 08:42:47 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 08:42:47 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 08:42:47 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCustomClientsCACertRenew-STARTED
2022-02-23 08:42:48 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 08:42:48 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-4 for test case:testCertificates
2022-02-23 08:42:48 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-4
2022-02-23 08:42:48 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-4
2022-02-23 08:42:48 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-4
2022-02-23 08:42:48 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:127] Running testCertificates my-cluster-1308139980
2022-02-23 08:42:48 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-1308139980 in namespace namespace-4
2022-02-23 08:42:48 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-4
2022-02-23 08:42:48 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-1308139980 will have desired state: Ready
2022-02-23 08:48:10 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-36262540-kafka has been successfully rolled
2022-02-23 08:48:10 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-36262540-kafka to be ready
2022-02-23 08:48:34 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-1308139980 is in desired state: Ready
2022-02-23 08:48:34 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:137] Check Kafka bootstrap certificate
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1308139980-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1308139980-kafka-bootstrap:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1308139980-kafka-bootstrap
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:140] OPENSSL OUTPUT: 

CONNECTED(00000003)
---
Certificate chain
 0 s:O = io.strimzi, CN = my-cluster-1308139980-kafka
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----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-----END CERTIFICATE-----
 1 s:O = io.strimzi, CN = cluster-ca v0
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUJGAI2nWmzsns01svaqaPb21/FZQwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjAyMjMwODQyNDlaFw0yMzAyMjMwODQyNDlaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQC1yGRlYwu0nQzuVaw1BFUfH8/MgRzAcF9nzwXgmMhZ
gXFc9TRv1Cga5o+Wi762w51Af+BqP5mnZwXW01bNeqGDbfDxuCrIkg2DAdJKkRd/
iZLCUWj3j8INiPSxX3oCiZDWaPZF246BPFovAb/ods0syyXU5upsVNpMnCv+UirA
rIGPcwZpMmeRyQO5VPISl13G5PYcUGJxNgwaD5gWUufhKQ+o3tcv5bfZHEO0+eaz
+xrsM6PNOSxQ/oQQOhdlZpAR0wIbTcedV7ABP7c7IwUCxYbV2qT7fJqPYFuix/iz
TICsmAJkOyF0U7P8L17TUyTf6xdZsDmjK4yIIpi1BgUXCZ5Mfv1UTNEey2UNfaJR
FCVm5cCSyGtCqUSTVsBbZHRsnlhfD66/AQbgqFr7/4Cq7CDo/BTurwz7taaWF47E
e6mIIMKS3i0G6IJBEq2Ui6rjV5ADa0dgldH0eUXfM7qz7x1/dLYaOz2TVK+zIT9U
gRKT0yTFPYZizDdQ9KzWM8GvDU2f73dZTjsQkO8BC7FGE6aj4rYPvISG/iN/xzUJ
qJk3IcI9L5C9Ey9jawc5pFAeYGEh4BCUA8HvRvKJA8Pj1Kzoq5LtfU7gjDEcl+m9
tU/RuthuDuFuomKP8ZvmRqSISCRMd057IXzO/voqwkHGHQ6QvdHSMgjeXsPmEoXV
aQIDAQABo0UwQzAdBgNVHQ4EFgQUNx0ejfUnzuCfqQ6FqBfp7nS9v5cwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
ABigwuOgv+6y8b7aI53sGMnCIFi/0H0BxtHrZyDMxr/K3HGGbAhfXXmranIZAkrJ
ywfjQy37htvZoWVoJSj31N+zX6B/WoLAT04jvyAFZXEiA/fX+GdsWeOXP99+R544
ofg92oINe84H04+XLr8aIGslPRKjerNigcOp9GjFJvi54c/THuatlSF/lb/39Cpg
K8J1DvnVeSuWv2ZPEO5NOhbIOuGCv63+Ld6dMEqmiSGvQQtit77zDg4sswmPnYYj
czRhlc+hVUfkWZpM/7PZ0nFIBZ3x8WcpUfSMhG2uwoYvjsp+n+rbZ34MGL+nMfJ7
ODEBwA4qNKmdaL3ZazmtAoCfcCZwhFaPsvhIsGuL4HjCUGRBU975x/dKIU8USUkr
lGjte6riSQmYXLU+fpLOJpJevl+IZFLjuALvMz+5WA36X2yUcFrYWs3FNlytdVa2
tN8l76JnHtuqb5O7ir1a0YLHkdXgU2FeAMCkmYrQQK0vtnUHjvYhIMF0WcBheezs
OardRebzYhMIwiTNhjJLy0qwUL4wt3MpGDb8ua/hi16KnlvT9npBUYSPesCRjXTS
f15m9fDVSqpaKUSItq0qOJBciIsqwsunEGC576xYo4HWrprwN1u0WYqQcGJjjfSm
rU/dH5g1D2fRsW8zkoaMt/pZ8PQ2W9+YcokMvxO7nFpL
-----END CERTIFICATE-----
---
Server certificate
subject=O = io.strimzi, CN = my-cluster-1308139980-kafka

issuer=O = io.strimzi, CN = cluster-ca v0

---
No client certificate CA names sent
Peer signing digest: SHA256
Peer signature type: RSA-PSS
Server Temp Key: X25519, 253 bits
---
SSL handshake has read 3507 bytes and written 369 bytes
Verification: OK
Verified peername: my-cluster-1308139980-kafka-bootstrap
---
New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384
Server public key is 2048 bit
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
Early data was not sent
Verify return code: 0 (ok)
---



2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:143] Check zookeeper client certificate
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1308139980-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1308139980-zookeeper-client:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1308139980-zookeeper-client -cert /opt/kafka/broker-certs/my-cluster-1308139980-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-1308139980-kafka-0.key
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:154] Checking certificates for podId 0
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:156] Check kafka certificate for port 9091
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1308139980-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1308139980-kafka-0.my-cluster-1308139980-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1308139980-kafka-0.my-cluster-1308139980-kafka-brokers.namespace-4.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-1308139980-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-1308139980-kafka-0.key
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:156] Check kafka certificate for port 9093
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1308139980-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1308139980-kafka-0.my-cluster-1308139980-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1308139980-kafka-0.my-cluster-1308139980-kafka-brokers.namespace-4.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-1308139980-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-1308139980-kafka-0.key
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:163] Check zookeeper certificate for port 2181
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1308139980-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1308139980-zookeeper-0.my-cluster-1308139980-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1308139980-zookeeper-0.my-cluster-1308139980-zookeeper-nodes.namespace-4.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-1308139980-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-1308139980-zookeeper-0.key
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:163] Check zookeeper certificate for port 3888
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1308139980-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1308139980-zookeeper-0.my-cluster-1308139980-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1308139980-zookeeper-0.my-cluster-1308139980-zookeeper-nodes.namespace-4.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-1308139980-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-1308139980-zookeeper-0.key
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:154] Checking certificates for podId 1
2022-02-23 08:48:35 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:156] Check kafka certificate for port 9091
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1308139980-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1308139980-kafka-1.my-cluster-1308139980-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1308139980-kafka-1.my-cluster-1308139980-kafka-brokers.namespace-4.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-1308139980-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-1308139980-kafka-1.key
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:156] Check kafka certificate for port 9093
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1308139980-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1308139980-kafka-1.my-cluster-1308139980-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1308139980-kafka-1.my-cluster-1308139980-kafka-brokers.namespace-4.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-1308139980-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-1308139980-kafka-1.key
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:163] Check zookeeper certificate for port 2181
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1308139980-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1308139980-zookeeper-1.my-cluster-1308139980-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1308139980-zookeeper-1.my-cluster-1308139980-zookeeper-nodes.namespace-4.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-1308139980-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-1308139980-zookeeper-1.key
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:163] Check zookeeper certificate for port 3888
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-1308139980-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1308139980-zookeeper-1.my-cluster-1308139980-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1308139980-zookeeper-1.my-cluster-1308139980-zookeeper-nodes.namespace-4.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-1308139980-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-1308139980-zookeeper-1.key
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:309] Delete all resources for testCertificates
2022-02-23 08:48:36 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-1308139980 in namespace namespace-4
2022-02-23 08:48:46 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 08:48:46 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-4 for test case:testCertificates
2022-02-23 08:49:02 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:539] Checking the certificates have been replaced
2022-02-23 08:49:02 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:550] Checking consumed messages to pod:my-cluster-36262540-kafka-clients-5c7bb5b45b-nzmzq
2022-02-23 08:49:02 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@49e97e64, messages=[], arguments=[--group-instance-id, instance1889222261, --bootstrap-server, my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092, --max-messages, 100, --topic, my-topic-752966107-636718435, --group-id, my-consumer-group-259998929], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-36262540-kafka-clients-5c7bb5b45b-nzmzq', podNamespace='namespace-2', bootstrapServer='my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092', topicName='my-topic-752966107-636718435', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-259998929', consumerInstanceId='instance1889222261', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3755a016}
2022-02-23 08:49:02 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092#my-topic-752966107-636718435 from pod my-cluster-36262540-kafka-clients-5c7bb5b45b-nzmzq
2022-02-23 08:49:02 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-36262540-kafka-clients-5c7bb5b45b-nzmzq -n namespace-2 -- /opt/kafka/consumer.sh --group-instance-id instance1889222261 --bootstrap-server my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092 --max-messages 100 --topic my-topic-752966107-636718435 --group-id my-consumer-group-259998929
2022-02-23 08:49:07 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 08:49:07 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 08:49:07 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-954879525-2011191630 in namespace namespace-4
2022-02-23 08:49:07 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-2
2022-02-23 08:49:07 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-954879525-2011191630 will have desired state: Ready
2022-02-23 08:49:08 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-954879525-2011191630 is in desired state: Ready
2022-02-23 08:49:08 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-36262540-kafka-clients-tls in namespace namespace-4
2022-02-23 08:49:08 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-2
2022-02-23 08:49:08 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-36262540-kafka-clients-tls will be ready
2022-02-23 08:49:10 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-36262540-kafka-clients-tls is ready
2022-02-23 08:49:10 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:575] Checking consumed messages to pod:my-cluster-36262540-kafka-clients-tls-8497fcfdb5-bg4km
2022-02-23 08:49:10 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@31455bb5, messages=[], arguments=[--group-instance-id, instance129634065, --bootstrap-server, my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092, --max-messages, 100, --topic, my-topic-752966107-636718435, --group-id, my-consumer-group-1755703856], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-36262540-kafka-clients-tls-8497fcfdb5-bg4km', podNamespace='namespace-2', bootstrapServer='my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092', topicName='my-topic-752966107-636718435', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1755703856', consumerInstanceId='instance129634065', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@228098a4}
2022-02-23 08:49:10 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092#my-topic-752966107-636718435 from pod my-cluster-36262540-kafka-clients-tls-8497fcfdb5-bg4km
2022-02-23 08:49:10 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-36262540-kafka-clients-tls-8497fcfdb5-bg4km -n namespace-2 -- /opt/kafka/consumer.sh --group-instance-id instance129634065 --bootstrap-server my-cluster-36262540-kafka-bootstrap.namespace-2.svc:9092 --max-messages 100 --topic my-topic-752966107-636718435 --group-id my-consumer-group-1755703856
2022-02-23 08:49:15 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 08:49:15 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 08:49:15 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 08:49:15 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:309] Delete all resources for testAutoReplaceClientsCaKeysTriggeredByAnno
2022-02-23 08:49:15 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-36262540-kafka-clients in namespace namespace-2
2022-02-23 08:49:29 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertificates-FINISHED
2022-02-23 08:49:29 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 08:49:29 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 08:49:29 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-STARTED
2022-02-23 08:49:32 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 08:49:32 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-5 for test case:testCustomClientsCACertRenew
2022-02-23 08:49:32 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-5
2022-02-23 08:49:32 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-5
2022-02-23 08:49:32 [ForkJoinPool-1-worker-1] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-5
2022-02-23 08:49:32 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1828] Generating custom RootCA, IntermediateCA, and ClusterCA, ClientsCA for Strimzi and PEM bundles.
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1844] Deploy all certificates and keys as secrets.
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:150] Waiting for Secret: my-cluster-502937537-cluster-ca-cert to be deleted
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:154] Secret: my-cluster-502937537-cluster-ca-cert successfully deleted
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-502937537-cluster-ca-cert
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:50] Secret my-cluster-502937537-cluster-ca-cert created
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:150] Waiting for Secret: my-cluster-502937537-cluster-ca to be deleted
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:154] Secret: my-cluster-502937537-cluster-ca successfully deleted
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:150] Waiting for Secret: my-cluster-502937537-clients-ca-cert to be deleted
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:154] Secret: my-cluster-502937537-clients-ca-cert successfully deleted
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-502937537-clients-ca-cert
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:50] Secret my-cluster-502937537-clients-ca-cert created
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:150] Waiting for Secret: my-cluster-502937537-clients-ca to be deleted
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecretUtils:154] Secret: my-cluster-502937537-clients-ca successfully deleted
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1805] Check ClusterCA and ClientsCA certificates.
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-502937537 in namespace namespace-5
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-5
2022-02-23 08:49:33 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-502937537 will have desired state: Ready
2022-02-23 08:50:35 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-36262540-kafka-clients-tls in namespace namespace-2
2022-02-23 08:50:35 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-954879525-2011191630 in namespace namespace-2
2022-02-23 08:50:45 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-1835957211-1006556617 in namespace namespace-2
2022-02-23 08:50:56 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-752966107-636718435 in namespace namespace-2
2022-02-23 08:51:06 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-36262540 in namespace namespace-2
2022-02-23 08:51:06 [ForkJoinPool-1-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-2, for cruise control Kafka cluster my-cluster-36262540
2022-02-23 08:51:16 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 08:51:16 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-2 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-02-23 08:51:59 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-FINISHED
2022-02-23 08:51:59 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 08:51:59 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 08:51:59 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-STARTED
2022-02-23 08:51:59 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 08:51:59 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-6 for test case:testClientsCACertRenew
2022-02-23 08:51:59 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-6
2022-02-23 08:51:59 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-6
2022-02-23 08:51:59 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-6
2022-02-23 08:51:59 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-1913101644 in namespace namespace-6
2022-02-23 08:51:59 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-6
2022-02-23 08:51:59 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-1913101644 will have desired state: Ready
2022-02-23 08:56:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-1913101644 is in desired state: Ready
2022-02-23 08:56:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser strimzi-tls-user-1783948331 in namespace namespace-6
2022-02-23 08:56:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-6
2022-02-23 08:56:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: strimzi-tls-user-1783948331 will have desired state: Ready
2022-02-23 08:56:16 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] KafkaUser: strimzi-tls-user-1783948331 is in desired state: Ready
2022-02-23 08:56:16 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1669] Change of kafka validity and renewal days - reconciliation should start.
2022-02-23 08:56:16 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1913101644-entity-operator rolling update
2022-02-23 09:01:16 [ForkJoinPool-1-worker-3] [1;31mERROR[m [TestExecutionWatcher:28] SecurityST - Exception Timeout after 300000 ms waiting for Deployment my-cluster-1913101644-entity-operator rolling update in namespace:namespace-6 has been thrown in @Test. Going to collect logs from components.
2022-02-23 09:01:16 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-02-23 09:01:16 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-02-23 09:01:16 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-02-23 09:01:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-02-23 09:01:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-02-23 09:01:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-02-23 09:01:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-02-23 09:01:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 09:01:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:252] Collecting events in Namespace namespace-6
2022-02-23 09:01:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace namespace-6
2022-02-23 09:01:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace namespace-6
2022-02-23 09:01:18 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace namespace-6
2022-02-23 09:01:18 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace namespace-6
2022-02-23 09:01:18 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace namespace-6
2022-02-23 09:01:18 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace namespace-6
2022-02-23 09:01:19 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 09:01:19 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:252] Collecting events in Namespace security-st
2022-02-23 09:01:19 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace security-st
2022-02-23 09:01:19 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace security-st
2022-02-23 09:01:19 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace security-st
2022-02-23 09:01:19 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace security-st
2022-02-23 09:01:19 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace security-st
2022-02-23 09:01:19 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace security-st
2022-02-23 09:01:19 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 09:01:19 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 09:01:19 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:309] Delete all resources for testClientsCACertRenew
2022-02-23 09:01:19 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of KafkaUser strimzi-tls-user-1783948331 in namespace namespace-6
2022-02-23 09:01:29 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-1913101644 in namespace namespace-6
2022-02-23 09:01:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 09:01:39 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-6 for test case:testClientsCACertRenew
2022-02-23 09:02:06 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-FINISHED
2022-02-23 09:02:06 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 09:02:06 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 09:02:06 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCustomClusterCAClientsCA-STARTED
2022-02-23 09:02:09 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 09:02:09 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-7 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-02-23 09:02:09 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-7
2022-02-23 09:02:09 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-7
2022-02-23 09:02:09 [ForkJoinPool-1-worker-5] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-7
2022-02-23 09:02:09 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-606719141-source in namespace namespace-7
2022-02-23 09:02:09 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-7
2022-02-23 09:02:09 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-606719141-source will have desired state: Ready
2022-02-23 09:02:24 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-502937537 is in desired state: Ready
2022-02-23 09:02:24 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser strimzi-tls-user-1984116703 in namespace namespace-7
2022-02-23 09:02:24 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-5
2022-02-23 09:02:24 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: strimzi-tls-user-1984116703 will have desired state: Ready
2022-02-23 09:02:25 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaUser: strimzi-tls-user-1984116703 is in desired state: Ready
2022-02-23 09:02:25 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1669] Change of kafka validity and renewal days - reconciliation should start.
2022-02-23 09:02:25 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-502937537-entity-operator rolling update
2022-02-23 09:02:35 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-502937537-entity-operator will be ready
2022-02-23 09:03:21 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-502937537-entity-operator is ready
2022-02-23 09:03:31 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-502937537-entity-operator rolling update finished
2022-02-23 09:03:31 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1691] Initial ClientsCA cert dates: Tue Feb 22 03:49:33 EST 2022 --> Thu Mar 24 04:49:33 EDT 2022
2022-02-23 09:03:31 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1692] Changed ClientsCA cert dates: Tue Feb 22 03:49:33 EST 2022 --> Thu Mar 24 04:49:33 EDT 2022
2022-02-23 09:03:31 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1693] Initial userCert dates: Wed Feb 23 04:02:24 EST 2022 --> Tue Mar 15 05:02:24 EDT 2022
2022-02-23 09:03:31 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1694] Changed userCert dates: Wed Feb 23 04:02:38 EST 2022 --> Sun Sep 11 05:02:38 EDT 2022
2022-02-23 09:03:31 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 09:03:31 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:309] Delete all resources for testCustomClientsCACertRenew
2022-02-23 09:03:31 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaUser strimzi-tls-user-1984116703 in namespace namespace-5
2022-02-23 09:03:32 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-606719141-source is in desired state: Ready
2022-02-23 09:03:32 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-606719141-target in namespace namespace-7
2022-02-23 09:03:32 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-7
2022-02-23 09:03:32 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-606719141-target will have desired state: Ready
2022-02-23 09:03:41 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-502937537 in namespace namespace-5
2022-02-23 09:03:51 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 09:03:51 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-5 for test case:testCustomClientsCACertRenew
2022-02-23 09:04:35 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCustomClientsCACertRenew-FINISHED
2022-02-23 09:04:35 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 09:04:35 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 09:04:35 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-STARTED
2022-02-23 09:04:36 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 09:04:36 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-8 for test case:testCustomClusterCAClientsCA
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-8
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-8
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-8
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1828] Generating custom RootCA, IntermediateCA, and ClusterCA, ClientsCA for Strimzi and PEM bundles.
2022-02-23 09:04:37 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-606719141-target is in desired state: Ready
2022-02-23 09:04:37 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:905] Getting IP of the source bootstrap service for consumer
2022-02-23 09:04:37 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:908] Getting IP of the target bootstrap service for producer
2022-02-23 09:04:37 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:911] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to consumer with address 10.99.57.30:9093
2022-02-23 09:04:37 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:912] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to producer with address 10.104.63.199:9093
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1844] Deploy all certificates and keys as secrets.
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:150] Waiting for Secret: my-cluster-848903979-cluster-ca-cert to be deleted
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:154] Secret: my-cluster-848903979-cluster-ca-cert successfully deleted
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-848903979-cluster-ca-cert
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:50] Secret my-cluster-848903979-cluster-ca-cert created
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:150] Waiting for Secret: my-cluster-848903979-cluster-ca to be deleted
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:154] Secret: my-cluster-848903979-cluster-ca successfully deleted
2022-02-23 09:04:37 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaMirrorMaker my-cluster-606719141 in namespace namespace-8
2022-02-23 09:04:37 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-7
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:150] Waiting for Secret: my-cluster-848903979-clients-ca-cert to be deleted
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:154] Secret: my-cluster-848903979-clients-ca-cert successfully deleted
2022-02-23 09:04:37 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-848903979-clients-ca-cert
2022-02-23 09:04:37 [ForkJoinPool-1-worker-5] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkamirrormakers' with unstable version 'v1beta2'
2022-02-23 09:04:38 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:50] Secret my-cluster-848903979-clients-ca-cert created
2022-02-23 09:04:38 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:245] Wait until Pod my-cluster-606719141-mirror-maker is present
2022-02-23 09:04:38 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:150] Waiting for Secret: my-cluster-848903979-clients-ca to be deleted
2022-02-23 09:04:38 [ForkJoinPool-1-worker-3] [32mINFO [m [SecretUtils:154] Secret: my-cluster-848903979-clients-ca successfully deleted
2022-02-23 09:04:38 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1805] Check ClusterCA and ClientsCA certificates.
2022-02-23 09:04:38 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1720]  Deploy kafka with new certs/secrets.
2022-02-23 09:04:38 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-848903979 in namespace namespace-8
2022-02-23 09:04:38 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-8
2022-02-23 09:04:38 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-848903979 will have desired state: Ready
2022-02-23 09:04:39 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:249] Pod my-cluster-606719141-mirror-maker is present
2022-02-23 09:04:39 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:236] Wait until Pod my-cluster-606719141-mirror-maker-7696695dd7-qnv7c is in CrashLoopBackOff state
2022-02-23 09:04:51 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:241] Pod my-cluster-606719141-mirror-maker-7696695dd7-qnv7c is in CrashLoopBackOff state
2022-02-23 09:04:51 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:947] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to consumer with address 10.99.57.30:9093
2022-02-23 09:04:51 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:948] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to producer with address 10.104.63.199:9093
2022-02-23 09:04:51 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:950] Adding configuration ssl.endpoint.identification.algorithm to the mirror maker...
2022-02-23 09:04:51 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaMirrorMaker: my-cluster-606719141 will have desired state: Ready
2022-02-23 09:08:48 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-848903979 is in desired state: Ready
2022-02-23 09:08:48 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1748] Check Kafka(s) and Zookeeper(s) certificates.
2022-02-23 09:08:48 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-1217573092-612577570 in namespace namespace-8
2022-02-23 09:08:48 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-8
2022-02-23 09:08:48 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-1217573092-612577570 will have desired state: Ready
2022-02-23 09:08:49 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-1217573092-612577570 is in desired state: Ready
2022-02-23 09:08:49 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1759] Check KafkaUser certificate.
2022-02-23 09:08:49 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-93024173-1052115229 in namespace namespace-8
2022-02-23 09:08:49 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-8
2022-02-23 09:08:49 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-93024173-1052115229 will have desired state: Ready
2022-02-23 09:08:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-93024173-1052115229 is in desired state: Ready
2022-02-23 09:08:50 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1766] Send and receive messages over TLS.
2022-02-23 09:08:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-848903979-kafka-clients in namespace namespace-8
2022-02-23 09:08:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-8
2022-02-23 09:08:50 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-848903979-kafka-clients will be ready
2022-02-23 09:08:51 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-848903979-kafka-clients is ready
2022-02-23 09:08:51 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 09:08:51 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1780] Check for certificates used within kafka pod internal clients (producer/consumer)
2022-02-23 09:08:51 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-848903979-kafka-clients-84db759fc5-xz2x9 -- /bin/bash -c openssl x509 -in /opt/kafka/user-secret-my-user-93024173-1052115229/ca.crt -noout -nameopt RFC2253 -issuer
2022-02-23 09:08:51 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 09:08:52 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-848903979-kafka-clients-84db759fc5-xz2x9 -- /bin/bash -c openssl x509 -in /opt/kafka/user-secret-my-user-93024173-1052115229/ca.crt -noout -nameopt RFC2253 -subject
2022-02-23 09:08:52 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 09:08:52 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-848903979-kafka-clients-84db759fc5-xz2x9 -- /bin/bash -c openssl x509 -in /opt/kafka/cluster-ca-my-user-93024173-1052115229/ca.crt -noout -nameopt RFC2253 -issuer
2022-02-23 09:08:52 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 09:08:52 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-848903979-kafka-clients-84db759fc5-xz2x9 -- /bin/bash -c openssl x509 -in /opt/kafka/cluster-ca-my-user-93024173-1052115229/ca.crt -noout -nameopt RFC2253 -subject
2022-02-23 09:08:52 [ForkJoinPool-1-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-02-23 09:08:52 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1797] Checking produced and consumed messages via TLS to pod:my-cluster-848903979-kafka-clients-84db759fc5-xz2x9
2022-02-23 09:08:52 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@65ee584c, messages=[], arguments=[USER=my_user_93024173_1052115229, --bootstrap-server, my-cluster-848903979-kafka-bootstrap.namespace-8.svc:9093, --max-messages, 100, --topic, my-topic-1217573092-612577570], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-848903979-kafka-clients-84db759fc5-xz2x9', podNamespace='namespace-8', bootstrapServer='my-cluster-848903979-kafka-bootstrap.namespace-8.svc:9093', topicName='my-topic-1217573092-612577570', maxMessages=100, kafkaUsername='my-user-93024173-1052115229', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@27654a2}
2022-02-23 09:08:52 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-848903979-kafka-bootstrap.namespace-8.svc:9093:my-topic-1217573092-612577570 from pod my-cluster-848903979-kafka-clients-84db759fc5-xz2x9
2022-02-23 09:08:52 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-848903979-kafka-clients-84db759fc5-xz2x9 -n namespace-8 -- /opt/kafka/producer.sh USER=my_user_93024173_1052115229 --bootstrap-server my-cluster-848903979-kafka-bootstrap.namespace-8.svc:9093 --max-messages 100 --topic my-topic-1217573092-612577570
2022-02-23 09:08:55 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-02-23 09:08:55 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-02-23 09:08:55 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@16c37f81, messages=[], arguments=[--group-instance-id, instance1073396336, USER=my_user_93024173_1052115229, --bootstrap-server, my-cluster-848903979-kafka-bootstrap.namespace-8.svc:9093, --max-messages, 100, --topic, my-topic-1217573092-612577570, --group-id, my-consumer-group-813225351], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-848903979-kafka-clients-84db759fc5-xz2x9', podNamespace='namespace-8', bootstrapServer='my-cluster-848903979-kafka-bootstrap.namespace-8.svc:9093', topicName='my-topic-1217573092-612577570', maxMessages=100, kafkaUsername='my-user-93024173-1052115229', consumerGroupName='my-consumer-group-813225351', consumerInstanceId='instance1073396336', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@613b1fd7}
2022-02-23 09:08:55 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-848903979-kafka-bootstrap.namespace-8.svc:9093:my-topic-1217573092-612577570 from pod my-cluster-848903979-kafka-clients-84db759fc5-xz2x9
2022-02-23 09:08:55 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-848903979-kafka-clients-84db759fc5-xz2x9 -n namespace-8 -- /opt/kafka/consumer.sh --group-instance-id instance1073396336 USER=my_user_93024173_1052115229 --bootstrap-server my-cluster-848903979-kafka-bootstrap.namespace-8.svc:9093 --max-messages 100 --topic my-topic-1217573092-612577570 --group-id my-consumer-group-813225351
2022-02-23 09:09:01 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-23 09:09:01 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-23 09:09:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 09:09:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:309] Delete all resources for testCustomClusterCAClientsCA
2022-02-23 09:09:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-93024173-1052115229 in namespace namespace-8
2022-02-23 09:09:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-848903979-kafka-clients in namespace namespace-8
2022-02-23 09:09:51 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-1217573092-612577570 in namespace namespace-8
2022-02-23 09:10:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-848903979 in namespace namespace-8
2022-02-23 09:10:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 09:10:11 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-8 for test case:testCustomClusterCAClientsCA
2022-02-23 09:10:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaMirrorMaker: my-cluster-606719141 is in desired state: Ready
2022-02-23 09:10:43 [ForkJoinPool-1-worker-5] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-606719141-mirror-maker is not deleted yet! Triggering force delete by cmd client!
2022-02-23 09:10:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 09:10:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:309] Delete all resources for testTlsHostnameVerificationWithMirrorMaker
2022-02-23 09:10:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-606719141-target in namespace namespace-7
2022-02-23 09:10:54 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCustomClusterCAClientsCA-FINISHED
2022-02-23 09:10:54 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 09:10:54 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 09:10:54 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-STARTED
2022-02-23 09:10:55 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 09:10:55 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-9 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-02-23 09:10:55 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-9
2022-02-23 09:10:55 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-9
2022-02-23 09:10:55 [ForkJoinPool-1-worker-1] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-9
2022-02-23 09:10:55 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:601] Creating a cluster
2022-02-23 09:10:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-222145770 in namespace namespace-9
2022-02-23 09:10:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-9
2022-02-23 09:10:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-222145770 will have desired state: Ready
2022-02-23 09:10:58 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaMirrorMaker my-cluster-606719141 in namespace namespace-7
2022-02-23 09:10:58 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-606719141-source in namespace namespace-7
2022-02-23 09:11:08 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 09:11:08 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-7 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-02-23 09:11:18 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-FINISHED
2022-02-23 09:11:18 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 09:11:18 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 09:11:18 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-STARTED
2022-02-23 09:11:19 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 09:11:19 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-10 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-02-23 09:11:19 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-10
2022-02-23 09:11:19 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-10
2022-02-23 09:11:19 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-10
2022-02-23 09:11:19 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-798410260 in namespace namespace-10
2022-02-23 09:11:19 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-10
2022-02-23 09:11:19 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-798410260 will have desired state: Ready
2022-02-23 09:14:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-798410260 is in desired state: Ready
2022-02-23 09:14:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:852] Getting IP of the bootstrap service
2022-02-23 09:14:39 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:856] KafkaConnect without config ssl.endpoint.identification.algorithm will not connect to 10.110.1.1:9093
2022-02-23 09:14:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-798410260-kafka-clients in namespace namespace-10
2022-02-23 09:14:39 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-10
2022-02-23 09:14:39 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-798410260-kafka-clients will be ready
2022-02-23 09:14:41 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-798410260-kafka-clients is ready
2022-02-23 09:14:41 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-798410260-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-02-23 09:14:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update NetworkPolicy my-cluster-798410260-allow in namespace namespace-10
2022-02-23 09:14:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-10
2022-02-23 09:14:41 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-02-23 09:14:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update KafkaConnect my-cluster-798410260 in namespace namespace-10
2022-02-23 09:14:41 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-10
2022-02-23 09:14:41 [ForkJoinPool-1-worker-3] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkaconnects' with unstable version 'v1beta2'
2022-02-23 09:14:41 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:245] Wait until Pod my-cluster-798410260-connect is present
2022-02-23 09:14:42 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:249] Pod my-cluster-798410260-connect is present
2022-02-23 09:14:42 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:236] Wait until Pod my-cluster-798410260-connect-558698db97-w9tf7 is in CrashLoopBackOff state
2022-02-23 09:15:00 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:241] Pod my-cluster-798410260-connect-558698db97-w9tf7 is in CrashLoopBackOff state
2022-02-23 09:15:00 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:886] KafkaConnect with config ssl.endpoint.identification.algorithm will connect to 10.110.1.1:9093
2022-02-23 09:15:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for KafkaConnect: my-cluster-798410260 will have desired state: Ready
2022-02-23 09:20:24 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-222145770 is in desired state: Ready
2022-02-23 09:20:24 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-1284852901-1222563690 in namespace namespace-10
2022-02-23 09:20:24 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-9
2022-02-23 09:20:24 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-1284852901-1222563690 will have desired state: Ready
2022-02-23 09:20:25 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-1284852901-1222563690 is in desired state: Ready
2022-02-23 09:20:25 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-643378916-972178187 in namespace namespace-10
2022-02-23 09:20:25 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-9
2022-02-23 09:20:25 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-643378916-972178187 will have desired state: Ready
2022-02-23 09:20:26 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-643378916-972178187 is in desired state: Ready
2022-02-23 09:20:26 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-222145770-kafka-clients in namespace namespace-10
2022-02-23 09:20:26 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-9
2022-02-23 09:20:26 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-222145770-kafka-clients will be ready
2022-02-23 09:20:28 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-222145770-kafka-clients is ready
2022-02-23 09:20:28 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 09:20:28 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:274] Checking produced and consumed messages to pod:my-cluster-222145770-kafka-clients-db8bb47dd-f7l5v
2022-02-23 09:20:28 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@39f68b64, messages=[], arguments=[--bootstrap-server, my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9092, --max-messages, 100, --topic, my-topic-643378916-972178187], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-222145770-kafka-clients-db8bb47dd-f7l5v', podNamespace='namespace-9', bootstrapServer='my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9092', topicName='my-topic-643378916-972178187', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5e3eaba4}
2022-02-23 09:20:28 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9092:my-topic-643378916-972178187 from pod my-cluster-222145770-kafka-clients-db8bb47dd-f7l5v
2022-02-23 09:20:28 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-222145770-kafka-clients-db8bb47dd-f7l5v -n namespace-9 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9092 --max-messages 100 --topic my-topic-643378916-972178187
2022-02-23 09:20:30 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-02-23 09:20:30 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-02-23 09:20:30 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@420c40e4, messages=[], arguments=[--group-instance-id, instance621533201, --bootstrap-server, my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9092, --max-messages, 100, --topic, my-topic-643378916-972178187, --group-id, my-consumer-group-1436399261], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-222145770-kafka-clients-db8bb47dd-f7l5v', podNamespace='namespace-9', bootstrapServer='my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9092', topicName='my-topic-643378916-972178187', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1436399261', consumerInstanceId='instance621533201', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@69c4b5f3}
2022-02-23 09:20:30 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9092#my-topic-643378916-972178187 from pod my-cluster-222145770-kafka-clients-db8bb47dd-f7l5v
2022-02-23 09:20:30 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-222145770-kafka-clients-db8bb47dd-f7l5v -n namespace-9 -- /opt/kafka/consumer.sh --group-instance-id instance621533201 --bootstrap-server my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9092 --max-messages 100 --topic my-topic-643378916-972178187 --group-id my-consumer-group-1436399261
2022-02-23 09:20:35 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 09:20:35 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 09:20:36 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:288] Triggering CA cert renewal by adding the annotation
2022-02-23 09:20:36 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:300] Patching secret my-cluster-222145770-cluster-ca-cert with strimzi.io/force-renew
2022-02-23 09:20:36 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:305] Wait for zk to rolling restart ...
2022-02-23 09:20:36 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-222145770-zookeeper rolling update
2022-02-23 09:20:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] KafkaConnect: my-cluster-798410260 is in desired state: Ready
2022-02-23 09:20:52 [ForkJoinPool-1-worker-3] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-798410260-connect is not deleted yet! Triggering force delete by cmd client!
2022-02-23 09:20:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 09:20:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:309] Delete all resources for testTlsHostnameVerificationWithKafkaConnect
2022-02-23 09:20:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of NetworkPolicy my-cluster-798410260-allow in namespace namespace-10
2022-02-23 09:20:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of KafkaConnect my-cluster-798410260 in namespace namespace-10
2022-02-23 09:21:07 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-798410260-kafka-clients in namespace namespace-10
2022-02-23 09:21:46 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-222145770-zookeeper has been successfully rolled
2022-02-23 09:21:46 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-222145770-zookeeper to be ready
2022-02-23 09:21:47 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-798410260 in namespace namespace-10
2022-02-23 09:21:57 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 09:21:57 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-10 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-02-23 09:22:19 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:309] Wait for kafka to rolling restart ...
2022-02-23 09:22:19 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-222145770-kafka rolling update
2022-02-23 09:22:40 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-FINISHED
2022-02-23 09:22:40 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 09:22:40 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 09:22:40 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-STARTED
2022-02-23 09:22:43 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 09:22:43 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-11 for test case:testCaRenewalBreakInMiddle
2022-02-23 09:22:43 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-11
2022-02-23 09:22:43 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-11
2022-02-23 09:22:43 [ForkJoinPool-1-worker-5] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-11
2022-02-23 09:22:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-1510668978 in namespace namespace-11
2022-02-23 09:22:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-11
2022-02-23 09:22:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-1510668978 will have desired state: Ready
2022-02-23 09:23:49 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-222145770-kafka has been successfully rolled
2022-02-23 09:23:49 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-222145770-kafka to be ready
2022-02-23 09:24:14 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:313] Wait for EO to rolling restart ...
2022-02-23 09:24:14 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-222145770-entity-operator rolling update
2022-02-23 09:24:14 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-222145770-entity-operator will be ready
2022-02-23 09:25:36 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-222145770-entity-operator is ready
2022-02-23 09:25:46 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-222145770-entity-operator rolling update finished
2022-02-23 09:25:46 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:317] Wait for CC and KE to rolling restart ...
2022-02-23 09:25:46 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-222145770-kafka-exporter rolling update
2022-02-23 09:26:41 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-222145770-kafka-exporter will be ready
2022-02-23 09:26:41 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-222145770-kafka-exporter is ready
2022-02-23 09:26:51 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-222145770-kafka-exporter rolling update finished
2022-02-23 09:26:51 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-222145770-cruise-control rolling update
2022-02-23 09:26:51 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-222145770-cruise-control will be ready
2022-02-23 09:26:51 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-222145770-cruise-control is ready
2022-02-23 09:27:01 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-222145770-cruise-control rolling update finished
2022-02-23 09:27:01 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:322] Checking the certificates have been replaced
2022-02-23 09:27:01 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:336] Checking consumed messages to pod:my-cluster-222145770-kafka-clients-db8bb47dd-f7l5v
2022-02-23 09:27:01 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7a36aef7, messages=[], arguments=[--group-instance-id, instance1549617480, --bootstrap-server, my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9092, --max-messages, 100, --topic, my-topic-643378916-972178187, --group-id, my-consumer-group-2058872890], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-222145770-kafka-clients-db8bb47dd-f7l5v', podNamespace='namespace-9', bootstrapServer='my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9092', topicName='my-topic-643378916-972178187', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2058872890', consumerInstanceId='instance1549617480', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7595dff1}
2022-02-23 09:27:01 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9092#my-topic-643378916-972178187 from pod my-cluster-222145770-kafka-clients-db8bb47dd-f7l5v
2022-02-23 09:27:01 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-222145770-kafka-clients-db8bb47dd-f7l5v -n namespace-9 -- /opt/kafka/consumer.sh --group-instance-id instance1549617480 --bootstrap-server my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9092 --max-messages 100 --topic my-topic-643378916-972178187 --group-id my-consumer-group-2058872890
2022-02-23 09:27:07 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 09:27:07 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 09:27:07 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser bob-my-cluster-222145770 in namespace namespace-11
2022-02-23 09:27:07 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-9
2022-02-23 09:27:07 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: bob-my-cluster-222145770 will have desired state: Ready
2022-02-23 09:27:08 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaUser: bob-my-cluster-222145770 is in desired state: Ready
2022-02-23 09:27:08 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-222145770-kafka-clients-tls in namespace namespace-9
2022-02-23 09:27:08 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-9
2022-02-23 09:27:08 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-222145770-kafka-clients-tls will be ready
2022-02-23 09:27:10 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-222145770-kafka-clients-tls is ready
2022-02-23 09:27:10 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:360] Checking consumed messages to pod:my-cluster-222145770-kafka-clients-tls-db554c975-z2f4v
2022-02-23 09:27:10 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1f820b77, messages=[], arguments=[--group-instance-id, instance381315827, USER=bob_my_cluster_222145770, --bootstrap-server, my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9093, --max-messages, 100, --topic, my-topic-643378916-972178187, --group-id, my-consumer-group-1491699013], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-222145770-kafka-clients-tls-db554c975-z2f4v', podNamespace='namespace-9', bootstrapServer='my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9093', topicName='my-topic-643378916-972178187', maxMessages=100, kafkaUsername='bob-my-cluster-222145770', consumerGroupName='my-consumer-group-1491699013', consumerInstanceId='instance381315827', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@68a0ab03}
2022-02-23 09:27:10 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9093#my-topic-643378916-972178187 from pod my-cluster-222145770-kafka-clients-tls-db554c975-z2f4v
2022-02-23 09:27:10 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-222145770-kafka-clients-tls-db554c975-z2f4v -n namespace-9 -- /opt/kafka/consumer.sh --group-instance-id instance381315827 USER=bob_my_cluster_222145770 --bootstrap-server my-cluster-222145770-kafka-bootstrap.namespace-9.svc:9093 --max-messages 100 --topic my-topic-643378916-972178187 --group-id my-consumer-group-1491699013
2022-02-23 09:27:16 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 09:27:16 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 09:27:16 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 09:27:16 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:309] Delete all resources for testAutoRenewClusterCaCertsTriggeredByAnno
2022-02-23 09:27:16 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-222145770-kafka-clients in namespace namespace-9
2022-02-23 09:27:53 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-1510668978 is in desired state: Ready
2022-02-23 09:27:53 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-30836801-605059559 in namespace namespace-11
2022-02-23 09:27:53 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-11
2022-02-23 09:27:53 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-30836801-605059559 will have desired state: Ready
2022-02-23 09:27:54 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-30836801-605059559 is in desired state: Ready
2022-02-23 09:27:54 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-1125566246-335969055 in namespace namespace-11
2022-02-23 09:27:54 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-11
2022-02-23 09:27:54 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-1125566246-335969055 will have desired state: Ready
2022-02-23 09:27:55 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-1125566246-335969055 is in desired state: Ready
2022-02-23 09:27:55 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-1510668978-kafka-clients in namespace namespace-11
2022-02-23 09:27:55 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-11
2022-02-23 09:27:55 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1510668978-kafka-clients will be ready
2022-02-23 09:27:56 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1510668978-kafka-clients is ready
2022-02-23 09:27:56 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 09:27:56 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2d51055e, messages=[], arguments=[USER=my_user_30836801_605059559, --bootstrap-server, my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093, --max-messages, 100, --topic, my-topic-1125566246-335969055], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf', podNamespace='namespace-11', bootstrapServer='my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093', topicName='my-topic-1125566246-335969055', maxMessages=100, kafkaUsername='my-user-30836801-605059559', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2ea0a99a}
2022-02-23 09:27:56 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093:my-topic-1125566246-335969055 from pod my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf
2022-02-23 09:27:56 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf -n namespace-11 -- /opt/kafka/producer.sh USER=my_user_30836801_605059559 --bootstrap-server my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093 --max-messages 100 --topic my-topic-1125566246-335969055
2022-02-23 09:27:59 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-02-23 09:27:59 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-02-23 09:27:59 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3e7a139a, messages=[], arguments=[--group-instance-id, instance169300761, USER=my_user_30836801_605059559, --bootstrap-server, my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093, --max-messages, 100, --topic, my-topic-1125566246-335969055, --group-id, my-consumer-group-1625559592], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf', podNamespace='namespace-11', bootstrapServer='my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093', topicName='my-topic-1125566246-335969055', maxMessages=100, kafkaUsername='my-user-30836801-605059559', consumerGroupName='my-consumer-group-1625559592', consumerInstanceId='instance169300761', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5eef20fc}
2022-02-23 09:27:59 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093:my-topic-1125566246-335969055 from pod my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf
2022-02-23 09:27:59 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf -n namespace-11 -- /opt/kafka/consumer.sh --group-instance-id instance169300761 USER=my_user_30836801_605059559 --bootstrap-server my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093 --max-messages 100 --topic my-topic-1125566246-335969055 --group-id my-consumer-group-1625559592
2022-02-23 09:28:06 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-23 09:28:06 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-23 09:28:06 [ForkJoinPool-1-worker-5] [32mINFO [m [SecretUtils:70] Creating secret my-cluster-1510668978-cluster-ca-cert
2022-02-23 09:28:06 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:1238] No pods of my-cluster-1510668978-zookeeper are in desired state
2022-02-23 09:28:07 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:1238] No pods of my-cluster-1510668978-zookeeper are in desired state
2022-02-23 09:28:08 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:1238] No pods of my-cluster-1510668978-zookeeper are in desired state
2022-02-23 09:28:09 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:1238] No pods of my-cluster-1510668978-zookeeper are in desired state
2022-02-23 09:28:10 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:1241] Pod in 'Pending' state: my-cluster-1510668978-zookeeper-0
2022-02-23 09:28:10 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3d8bf776, messages=[], arguments=[--group-instance-id, instance122915433, USER=my_user_30836801_605059559, --bootstrap-server, my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093, --max-messages, 100, --topic, my-topic-1125566246-335969055, --group-id, my-consumer-group-932674828], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf', podNamespace='namespace-11', bootstrapServer='my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093', topicName='my-topic-1125566246-335969055', maxMessages=100, kafkaUsername='my-user-30836801-605059559', consumerGroupName='my-consumer-group-932674828', consumerInstanceId='instance122915433', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@100480cb}
2022-02-23 09:28:10 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093:my-topic-1125566246-335969055 from pod my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf
2022-02-23 09:28:10 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf -n namespace-11 -- /opt/kafka/consumer.sh --group-instance-id instance122915433 USER=my_user_30836801_605059559 --bootstrap-server my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093 --max-messages 100 --topic my-topic-1125566246-335969055 --group-id my-consumer-group-932674828
2022-02-23 09:28:16 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-23 09:28:16 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-23 09:28:16 [ForkJoinPool-1-worker-5] [32mINFO [m [SecretUtils:131] Waiting for Secret my-cluster-1510668978-cluster-ca-cert certificate change
2022-02-23 09:28:16 [ForkJoinPool-1-worker-5] [32mINFO [m [SecretUtils:138] Certificate in Secret my-cluster-1510668978-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUf3Xv9b5WKaBY3jOwX/43caoG4KQwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjAyMjMwOTI4MDZaFw0yMjAzMDIwOTI4MDZaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQC+zxhtdm+JKKy31ilEpiB327qR1KrYC6DRwO36o4fC
d3Vn0DLtgcyO/iumP+MWf0TtaixTUfIDaScdUglM0QKjotN4pCHnZUuskZbVHhaH
NOkh6w1C9kaq0UTpYSHmOA5Eh8cKGXFf2u8ZDzh0n9qD6t+yekguUbnKQmA0I3q1
FAIMxRLZ3nCnUnSkgtPVBmZAB1RiFuXp4EhtGGJE/7K8FFHcpF5GHfl7hd3l7u0z
XI+FuflvF3gNr2ZQZcrBnHnLF7iXYX55esnCmaKkDRsMDURCCy3vQ56s2RMpbkHH
UIOLmSv/taiy2dGnwovIfN2WLYEc2+PiHcRyqQvgljP5fFj7dArFYSDu/xZnZkgk
3Po1n9PbxXIk02IEB+8Hf3BqhDpLP8Gq1N2C1g8sjyiSIt50z15rC8z0Z3RAxL8q
bd8oJpT81P3aq9X48IMzuqclOQvV5ZLS2m7b34g9/xWekC8EKaDVaNRUZR/6S5cP
4fe6/3y0bdy0M65OHpNbvAolqwLHYOPWZUHXcB1Vdxzki9nYNt/ZVC4uvNW+RHUK
PMj2BW/6r5fMtkhWklzJ4KakJoGCjohCfNXX4TzXJJ6HvuXQjy1dVpqMAz9G9vKy
p7I1zwR37kU79osT+Aw878zOuvo3Jkl4NLEA2TZkJLon3YECTzbzngk3HnrEh95u
5wIDAQABo0UwQzAdBgNVHQ4EFgQU3tC6hJBw7MiDaEtcoraXNrm4PbswEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AFNoVG+3RRjZmQ3ZHyvOrG8Ry12cgtXo4Y55gy7B/AD7rOtUL4IjqNH4Yo6wR6DO
AxEn3CM6P4CbX31UvvIJEpghj9LAzsfoXCE4QTOHoiJldWuCtlgr3a0r+ZgrQpr1
in8ZOrSBr+xA9uV4jZIZqWNaGYZdwLKVL1mvttNpZsFAH6BEf3bya25NNKekp9d2
NEZe6XWFHo9WiHb/N3XlsouWNbQF5jVMdomKr25OejGBHcv9E7kKj4EfiVEJOLPA
Alyqm/W42GTS9P27RDq+UCd+yjYt3nA0yFfzoQFj4idF/NDcLiqwZ1G11aAp1Tij
L3DPjWDqPsyn9y+HkvmYkPKFpfDTsnQ8UB2L1ESz5jKgmgQXeXtpjW5vJQuVSoHK
csrSDPjOLKKOZ6UBjGPaU/kzQ0uLYfZmqTaVe+WPFsIdQd5a/WLTyxVTYC2HBtlW
yjS6n3LcfnhAV+daJv7sXcmTaNNPy+Qv1AJINyir58tyDxbeTgqNJTK0PIvbkZ97
WtnYuwUjgQlMr59QtT4CnIwwt/0YSPqJB3OP1maC46fUgfLCQu4Pad/ounGpmvF5
/s5SwuQr7nTZkH31yqtsXXASTFw7FQaWk6enT7JeVklFeqXh4TqD1Exj4+O1FjE6
Yu8MCiXno5oE4YdgGEBSke6rxudEDcqz9yOIrlnI8PC9
-----END CERTIFICATE-----

2022-02-23 09:28:16 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1510668978-zookeeper rolling update
2022-02-23 09:28:36 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-222145770-kafka-clients-tls in namespace namespace-9
2022-02-23 09:28:36 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaUser bob-my-cluster-222145770 in namespace namespace-9
2022-02-23 09:28:46 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-1284852901-1222563690 in namespace namespace-9
2022-02-23 09:28:56 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-643378916-972178187 in namespace namespace-9
2022-02-23 09:29:06 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-222145770 in namespace namespace-9
2022-02-23 09:29:06 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-9, for cruise control Kafka cluster my-cluster-222145770
2022-02-23 09:29:16 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 09:29:16 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-9 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-02-23 09:29:59 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-FINISHED
2022-02-23 09:29:59 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 09:29:59 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 09:29:59 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-STARTED
2022-02-23 09:30:00 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 09:30:00 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-12 for test case:testKafkaAndKafkaConnectTlsVersion
2022-02-23 09:30:00 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-12
2022-02-23 09:30:01 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-12
2022-02-23 09:30:01 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-12
2022-02-23 09:30:01 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1307] Deploying Kafka cluster with the support TLSv1.2 TLS
2022-02-23 09:30:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-1984086228 in namespace namespace-12
2022-02-23 09:30:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-12
2022-02-23 09:30:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-1984086228 will have desired state: Ready
2022-02-23 09:33:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-1984086228 is in desired state: Ready
2022-02-23 09:33:35 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1319] Verifying that Kafka cluster has the accepted configuration:
ssl.enabled.protocols -> TLSv1.2
ssl.protocol -> TLSv1.3
2022-02-23 09:33:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-1984086228-kafka-clients in namespace namespace-12
2022-02-23 09:33:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-12
2022-02-23 09:33:35 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1984086228-kafka-clients will be ready
2022-02-23 09:33:36 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1984086228-kafka-clients is ready
2022-02-23 09:33:36 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-1984086228-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-02-23 09:33:36 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update NetworkPolicy my-cluster-1984086228-allow in namespace namespace-12
2022-02-23 09:33:36 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-12
2022-02-23 09:33:36 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-02-23 09:33:36 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update KafkaConnect my-cluster-1984086228 in namespace namespace-12
2022-02-23 09:33:36 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-12
2022-02-23 09:33:36 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1342] Verifying that Kafka Connect status is NotReady because of different TLS version
2022-02-23 09:33:36 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for KafkaConnect: my-cluster-1984086228 will have desired state: NotReady
2022-02-23 09:35:06 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1510668978-zookeeper has been successfully rolled
2022-02-23 09:35:06 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-1510668978-zookeeper to be ready
2022-02-23 09:35:27 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1510668978-kafka rolling update
2022-02-23 09:36:57 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1510668978-kafka has been successfully rolled
2022-02-23 09:36:57 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-1510668978-kafka to be ready
2022-02-23 09:38:38 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] KafkaConnect: my-cluster-1984086228 is in desired state: NotReady
2022-02-23 09:38:38 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1346] Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.
2022-02-23 09:38:38 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1350] Verifying that Kafka Connect has the accepted configuration:
 ssl.enabled.protocols -> TLSv1.2
 ssl.protocol -> TLSv1.3
2022-02-23 09:38:38 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-02-23 09:38:38 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-02-23 09:38:38 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-02-23 09:38:38 [ForkJoinPool-1-worker-3] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-02-23 09:38:38 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1359] Verifying that Kafka Connect is stable
2022-02-23 09:38:38 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-1984086228-connect are stable
2022-02-23 09:38:38 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 50
2022-02-23 09:38:39 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 49
2022-02-23 09:38:40 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 48
2022-02-23 09:38:41 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 47
2022-02-23 09:38:42 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 46
2022-02-23 09:38:43 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 45
2022-02-23 09:38:44 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 44
2022-02-23 09:38:45 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 43
2022-02-23 09:38:46 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 42
2022-02-23 09:38:47 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 41
2022-02-23 09:38:48 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1510668978-entity-operator rolling update
2022-02-23 09:38:48 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1510668978-entity-operator will be ready
2022-02-23 09:38:48 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 40
2022-02-23 09:38:49 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 39
2022-02-23 09:38:50 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 38
2022-02-23 09:38:51 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 37
2022-02-23 09:38:52 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 36
2022-02-23 09:38:53 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 35
2022-02-23 09:38:54 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 34
2022-02-23 09:38:55 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 33
2022-02-23 09:38:56 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 32
2022-02-23 09:38:57 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 31
2022-02-23 09:38:58 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 30
2022-02-23 09:38:59 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 29
2022-02-23 09:39:00 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 28
2022-02-23 09:39:01 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 27
2022-02-23 09:39:02 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 26
2022-02-23 09:39:03 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 25
2022-02-23 09:39:04 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 24
2022-02-23 09:39:05 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 23
2022-02-23 09:39:06 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 22
2022-02-23 09:39:07 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 21
2022-02-23 09:39:08 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 20
2022-02-23 09:39:09 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 19
2022-02-23 09:39:10 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 18
2022-02-23 09:39:11 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 17
2022-02-23 09:39:12 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 16
2022-02-23 09:39:13 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 15
2022-02-23 09:39:14 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 14
2022-02-23 09:39:15 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 13
2022-02-23 09:39:16 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 12
2022-02-23 09:39:17 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 11
2022-02-23 09:39:18 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 10
2022-02-23 09:39:19 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 9
2022-02-23 09:39:20 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 8
2022-02-23 09:39:21 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 7
2022-02-23 09:39:22 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 6
2022-02-23 09:39:23 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 5
2022-02-23 09:39:24 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 4
2022-02-23 09:39:25 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 3
2022-02-23 09:39:26 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 2
2022-02-23 09:39:27 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:322] Pod my-cluster-1984086228-connect-846db5547f-q5chm is in the Running state. Remaining seconds pod to be stable 1
2022-02-23 09:39:27 [ForkJoinPool-1-worker-3] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-1984086228-connect-846db5547f-q5chm
2022-02-23 09:39:27 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1363] Verifying that Kafka Connect status is Ready because of same TLS version
2022-02-23 09:39:27 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for KafkaConnect: my-cluster-1984086228 will have desired state: Ready
2022-02-23 09:41:01 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1510668978-entity-operator is ready
2022-02-23 09:41:11 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1510668978-entity-operator rolling update finished
2022-02-23 09:41:11 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:1272] Checking produced and consumed messages to pod:my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf
2022-02-23 09:41:11 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@590d4bbb, messages=[], arguments=[--group-instance-id, instance822406420, USER=my_user_30836801_605059559, --bootstrap-server, my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093, --max-messages, 100, --topic, my-topic-1125566246-335969055, --group-id, my-consumer-group-1855961336], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf', podNamespace='namespace-11', bootstrapServer='my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093', topicName='my-topic-1125566246-335969055', maxMessages=100, kafkaUsername='my-user-30836801-605059559', consumerGroupName='my-consumer-group-1855961336', consumerInstanceId='instance822406420', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5dc1b4b3}
2022-02-23 09:41:11 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093:my-topic-1125566246-335969055 from pod my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf
2022-02-23 09:41:11 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf -n namespace-11 -- /opt/kafka/consumer.sh --group-instance-id instance822406420 USER=my_user_30836801_605059559 --bootstrap-server my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093 --max-messages 100 --topic my-topic-1125566246-335969055 --group-id my-consumer-group-1855961336
2022-02-23 09:41:18 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-23 09:41:18 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-23 09:41:18 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-2004832078-1944839026 in namespace namespace-12
2022-02-23 09:41:18 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-11
2022-02-23 09:41:18 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-2004832078-1944839026 will have desired state: Ready
2022-02-23 09:42:55 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-2004832078-1944839026 is in desired state: Ready
2022-02-23 09:42:55 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@27c3c984, messages=[], arguments=[USER=my_user_30836801_605059559, --bootstrap-server, my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093, --max-messages, 100, --topic, my-topic-2004832078-1944839026], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf', podNamespace='namespace-11', bootstrapServer='my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093', topicName='my-topic-2004832078-1944839026', maxMessages=100, kafkaUsername='my-user-30836801-605059559', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@77f78fe5}
2022-02-23 09:42:55 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093:my-topic-2004832078-1944839026 from pod my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf
2022-02-23 09:42:55 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf -n namespace-11 -- /opt/kafka/producer.sh USER=my_user_30836801_605059559 --bootstrap-server my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093 --max-messages 100 --topic my-topic-2004832078-1944839026
2022-02-23 09:42:58 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-02-23 09:42:58 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-02-23 09:42:58 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@df1dfa2, messages=[], arguments=[--group-instance-id, instance1387974959, USER=my_user_30836801_605059559, --bootstrap-server, my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093, --max-messages, 100, --topic, my-topic-2004832078-1944839026, --group-id, my-consumer-group-619709673], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf', podNamespace='namespace-11', bootstrapServer='my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093', topicName='my-topic-2004832078-1944839026', maxMessages=100, kafkaUsername='my-user-30836801-605059559', consumerGroupName='my-consumer-group-619709673', consumerInstanceId='instance1387974959', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@46b2f836}
2022-02-23 09:42:58 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093:my-topic-2004832078-1944839026 from pod my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf
2022-02-23 09:42:58 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1510668978-kafka-clients-5489d5dbb5-s57cf -n namespace-11 -- /opt/kafka/consumer.sh --group-instance-id instance1387974959 USER=my_user_30836801_605059559 --bootstrap-server my-cluster-1510668978-kafka-bootstrap.namespace-11.svc:9093 --max-messages 100 --topic my-topic-2004832078-1944839026 --group-id my-consumer-group-619709673
2022-02-23 09:43:04 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-23 09:43:04 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-23 09:43:04 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 09:43:04 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:309] Delete all resources for testCaRenewalBreakInMiddle
2022-02-23 09:43:04 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-1125566246-335969055 in namespace namespace-11
2022-02-23 09:43:14 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-2004832078-1944839026 in namespace namespace-11
2022-02-23 09:43:24 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-1510668978-kafka-clients in namespace namespace-11
2022-02-23 09:44:04 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-30836801-605059559 in namespace namespace-11
2022-02-23 09:44:14 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-1510668978 in namespace namespace-11
2022-02-23 09:44:24 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 09:44:24 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-11 for test case:testCaRenewalBreakInMiddle
2022-02-23 09:44:47 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] KafkaConnect: my-cluster-1984086228 is in desired state: Ready
2022-02-23 09:44:47 [ForkJoinPool-1-worker-3] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-1984086228-connect is not deleted yet! Triggering force delete by cmd client!
2022-02-23 09:44:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 09:44:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:309] Delete all resources for testKafkaAndKafkaConnectTlsVersion
2022-02-23 09:44:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of NetworkPolicy my-cluster-1984086228-allow in namespace namespace-12
2022-02-23 09:44:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of KafkaConnect my-cluster-1984086228 in namespace namespace-12
2022-02-23 09:44:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-1984086228-kafka-clients in namespace namespace-12
2022-02-23 09:45:07 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-FINISHED
2022-02-23 09:45:07 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 09:45:07 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 09:45:07 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-STARTED
2022-02-23 09:45:09 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 09:45:09 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-13 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-02-23 09:45:09 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-13
2022-02-23 09:45:09 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-13
2022-02-23 09:45:09 [ForkJoinPool-1-worker-1] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-13
2022-02-23 09:45:09 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:601] Creating a cluster
2022-02-23 09:45:09 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-1120773431 in namespace namespace-13
2022-02-23 09:45:09 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-13
2022-02-23 09:45:09 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-1120773431 will have desired state: Ready
2022-02-23 09:45:42 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-1984086228 in namespace namespace-12
2022-02-23 09:45:52 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 09:45:52 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-12 for test case:testKafkaAndKafkaConnectTlsVersion
2022-02-23 09:46:35 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-FINISHED
2022-02-23 09:46:35 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 09:46:35 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 09:46:35 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-STARTED
2022-02-23 09:46:37 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 09:46:37 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-14 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-02-23 09:46:37 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-14
2022-02-23 09:46:37 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-14
2022-02-23 09:46:37 [ForkJoinPool-1-worker-5] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-14
2022-02-23 09:46:37 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-419333991 in namespace namespace-14
2022-02-23 09:46:37 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-14
2022-02-23 09:46:37 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-419333991 will have desired state: Ready
2022-02-23 09:48:19 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-1120773431 is in desired state: Ready
2022-02-23 09:48:19 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-1372108601-2095190637 in namespace namespace-14
2022-02-23 09:48:19 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-13
2022-02-23 09:48:19 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-1372108601-2095190637 will have desired state: Ready
2022-02-23 09:48:20 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-1372108601-2095190637 is in desired state: Ready
2022-02-23 09:48:20 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-1238414940-1976308583 in namespace namespace-14
2022-02-23 09:48:20 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-13
2022-02-23 09:48:20 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-1238414940-1976308583 will have desired state: Ready
2022-02-23 09:48:21 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-1238414940-1976308583 is in desired state: Ready
2022-02-23 09:48:21 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-1120773431-kafka-clients in namespace namespace-14
2022-02-23 09:48:21 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-13
2022-02-23 09:48:21 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1120773431-kafka-clients will be ready
2022-02-23 09:48:23 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1120773431-kafka-clients is ready
2022-02-23 09:48:23 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 09:48:23 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:274] Checking produced and consumed messages to pod:my-cluster-1120773431-kafka-clients-786fb569f6-g9hfq
2022-02-23 09:48:23 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@aba786, messages=[], arguments=[--bootstrap-server, my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9092, --max-messages, 100, --topic, my-topic-1238414940-1976308583], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1120773431-kafka-clients-786fb569f6-g9hfq', podNamespace='namespace-13', bootstrapServer='my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9092', topicName='my-topic-1238414940-1976308583', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7b4e8a0d}
2022-02-23 09:48:23 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9092:my-topic-1238414940-1976308583 from pod my-cluster-1120773431-kafka-clients-786fb569f6-g9hfq
2022-02-23 09:48:23 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1120773431-kafka-clients-786fb569f6-g9hfq -n namespace-13 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9092 --max-messages 100 --topic my-topic-1238414940-1976308583
2022-02-23 09:48:25 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-02-23 09:48:25 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-02-23 09:48:25 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7ab91fa0, messages=[], arguments=[--group-instance-id, instance1821480373, --bootstrap-server, my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9092, --max-messages, 100, --topic, my-topic-1238414940-1976308583, --group-id, my-consumer-group-584858571], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1120773431-kafka-clients-786fb569f6-g9hfq', podNamespace='namespace-13', bootstrapServer='my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9092', topicName='my-topic-1238414940-1976308583', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-584858571', consumerInstanceId='instance1821480373', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7528fdea}
2022-02-23 09:48:25 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9092#my-topic-1238414940-1976308583 from pod my-cluster-1120773431-kafka-clients-786fb569f6-g9hfq
2022-02-23 09:48:25 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1120773431-kafka-clients-786fb569f6-g9hfq -n namespace-13 -- /opt/kafka/consumer.sh --group-instance-id instance1821480373 --bootstrap-server my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9092 --max-messages 100 --topic my-topic-1238414940-1976308583 --group-id my-consumer-group-584858571
2022-02-23 09:48:30 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 09:48:30 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 09:48:30 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:288] Triggering CA cert renewal by adding the annotation
2022-02-23 09:48:30 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:300] Patching secret my-cluster-1120773431-cluster-ca-cert with strimzi.io/force-renew
2022-02-23 09:48:30 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:300] Patching secret my-cluster-1120773431-clients-ca-cert with strimzi.io/force-renew
2022-02-23 09:48:30 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:305] Wait for zk to rolling restart ...
2022-02-23 09:48:30 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1120773431-zookeeper rolling update
2022-02-23 09:49:25 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1120773431-zookeeper has been successfully rolled
2022-02-23 09:49:25 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-1120773431-zookeeper to be ready
2022-02-23 09:49:54 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:309] Wait for kafka to rolling restart ...
2022-02-23 09:49:54 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1120773431-kafka rolling update
2022-02-23 09:51:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-419333991 is in desired state: Ready
2022-02-23 09:51:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-619741671-1072542000 in namespace namespace-14
2022-02-23 09:51:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-14
2022-02-23 09:51:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-619741671-1072542000 will have desired state: Ready
2022-02-23 09:51:49 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-619741671-1072542000 is in desired state: Ready
2022-02-23 09:51:49 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-177978762-1256900243 in namespace namespace-14
2022-02-23 09:51:49 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-14
2022-02-23 09:51:49 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-177978762-1256900243 will have desired state: Ready
2022-02-23 09:51:50 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-177978762-1256900243 is in desired state: Ready
2022-02-23 09:51:50 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-419333991-kafka-clients in namespace namespace-14
2022-02-23 09:51:50 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-14
2022-02-23 09:51:50 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-419333991-kafka-clients will be ready
2022-02-23 09:51:52 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-419333991-kafka-clients is ready
2022-02-23 09:51:52 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 09:51:52 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:811] Verifying that secret Secret(apiVersion=v1, data={ca.crt=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, ca.p12=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, ca.password=dEpLSVBGY2laQkZG}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-02-23T09:46:38Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-419333991, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-419333991, strimzi.io/cluster=my-cluster-419333991, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[], name=my-cluster-419333991-clients-ca-cert, namespace=namespace-14, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-419333991, uid=bfd577be-5187-4a2e-98c7-39cd360b286a, additionalProperties={})], resourceVersion=13502, selfLink=/api/v1/namespaces/namespace-14/secrets/my-cluster-419333991-clients-ca-cert, uid=d04fd3f9-59bd-49eb-ac72-5f52fca86872, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-419333991-clients-ca-cert is present
2022-02-23 09:51:52 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:811] Verifying that secret Secret(apiVersion=v1, data={ca.crt=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, ca.p12=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, ca.password=aVZDNVJieXp5NGdF}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-02-23T09:46:38Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-419333991, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-419333991, strimzi.io/cluster=my-cluster-419333991, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[], name=my-cluster-419333991-cluster-ca-cert, namespace=namespace-14, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-419333991, uid=bfd577be-5187-4a2e-98c7-39cd360b286a, additionalProperties={})], resourceVersion=13503, selfLink=/api/v1/namespaces/namespace-14/secrets/my-cluster-419333991-cluster-ca-cert, uid=76a55d18-4332-449d-a8db-dfde4b6fae79, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-419333991-cluster-ca-cert is present
2022-02-23 09:51:52 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:816] Deleting secret my-cluster-419333991-clients-ca-cert
2022-02-23 09:51:52 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:816] Deleting secret my-cluster-419333991-cluster-ca-cert
2022-02-23 09:51:52 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-419333991-kafka are stable
2022-02-23 09:51:52 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-02-23 09:51:52 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-02-23 09:51:52 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-02-23 09:51:52 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 50
2022-02-23 09:51:53 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-02-23 09:51:53 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-02-23 09:51:53 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-02-23 09:51:53 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 49
2022-02-23 09:51:54 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-02-23 09:51:54 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-02-23 09:51:54 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-02-23 09:51:54 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 48
2022-02-23 09:51:55 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-02-23 09:51:55 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-02-23 09:51:55 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-02-23 09:51:55 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 47
2022-02-23 09:51:56 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-02-23 09:51:56 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-02-23 09:51:56 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-02-23 09:51:56 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 46
2022-02-23 09:51:58 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-02-23 09:51:58 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-02-23 09:51:58 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-02-23 09:51:58 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 45
2022-02-23 09:51:59 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-02-23 09:51:59 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-02-23 09:51:59 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-02-23 09:51:59 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 44
2022-02-23 09:52:00 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-02-23 09:52:00 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-02-23 09:52:00 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-02-23 09:52:00 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 43
2022-02-23 09:52:01 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-02-23 09:52:01 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-02-23 09:52:01 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-02-23 09:52:01 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 42
2022-02-23 09:52:02 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-02-23 09:52:02 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-02-23 09:52:02 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-02-23 09:52:02 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 41
2022-02-23 09:52:03 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-02-23 09:52:03 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-02-23 09:52:03 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-02-23 09:52:03 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 40
2022-02-23 09:52:04 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-02-23 09:52:04 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-02-23 09:52:04 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-02-23 09:52:04 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 39
2022-02-23 09:52:05 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-02-23 09:52:05 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-02-23 09:52:05 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-02-23 09:52:05 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 38
2022-02-23 09:52:06 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-02-23 09:52:06 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-02-23 09:52:06 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-02-23 09:52:06 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 37
2022-02-23 09:52:07 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-02-23 09:52:07 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-02-23 09:52:07 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-02-23 09:52:07 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 36
2022-02-23 09:52:08 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-02-23 09:52:08 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-02-23 09:52:08 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-02-23 09:52:08 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 35
2022-02-23 09:52:09 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-02-23 09:52:09 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-02-23 09:52:09 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-02-23 09:52:09 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 34
2022-02-23 09:52:10 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-02-23 09:52:10 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-02-23 09:52:10 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-02-23 09:52:10 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 33
2022-02-23 09:52:11 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-02-23 09:52:11 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-02-23 09:52:11 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-02-23 09:52:11 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 32
2022-02-23 09:52:12 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-02-23 09:52:12 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-02-23 09:52:12 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-02-23 09:52:12 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 31
2022-02-23 09:52:13 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-02-23 09:52:13 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-02-23 09:52:13 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-02-23 09:52:13 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 30
2022-02-23 09:52:14 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-02-23 09:52:14 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-02-23 09:52:14 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-02-23 09:52:14 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 29
2022-02-23 09:52:15 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-02-23 09:52:15 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-02-23 09:52:15 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-02-23 09:52:15 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 28
2022-02-23 09:52:16 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-02-23 09:52:16 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-02-23 09:52:16 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-02-23 09:52:16 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 27
2022-02-23 09:52:17 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-02-23 09:52:17 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-02-23 09:52:17 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-02-23 09:52:17 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 26
2022-02-23 09:52:18 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-02-23 09:52:18 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-02-23 09:52:18 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-02-23 09:52:18 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 25
2022-02-23 09:52:19 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-02-23 09:52:19 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-02-23 09:52:19 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-02-23 09:52:19 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 24
2022-02-23 09:52:20 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-02-23 09:52:20 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-02-23 09:52:20 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-02-23 09:52:20 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 23
2022-02-23 09:52:21 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-02-23 09:52:21 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-02-23 09:52:21 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-02-23 09:52:21 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 22
2022-02-23 09:52:22 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-02-23 09:52:22 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-02-23 09:52:22 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-02-23 09:52:22 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 21
2022-02-23 09:52:23 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-02-23 09:52:23 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-02-23 09:52:23 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-02-23 09:52:23 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 20
2022-02-23 09:52:24 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-02-23 09:52:24 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-02-23 09:52:24 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-02-23 09:52:24 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 19
2022-02-23 09:52:25 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-02-23 09:52:25 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-02-23 09:52:25 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-02-23 09:52:25 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 18
2022-02-23 09:52:26 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-02-23 09:52:26 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-02-23 09:52:26 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-02-23 09:52:26 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 17
2022-02-23 09:52:27 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-02-23 09:52:27 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-02-23 09:52:27 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-02-23 09:52:27 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 16
2022-02-23 09:52:28 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-02-23 09:52:28 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-02-23 09:52:28 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-02-23 09:52:28 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 15
2022-02-23 09:52:29 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-02-23 09:52:29 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-02-23 09:52:29 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-02-23 09:52:29 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 14
2022-02-23 09:52:30 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1120773431-kafka has been successfully rolled
2022-02-23 09:52:30 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-1120773431-kafka to be ready
2022-02-23 09:52:30 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-02-23 09:52:30 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-02-23 09:52:30 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-02-23 09:52:30 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 13
2022-02-23 09:52:31 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-02-23 09:52:31 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-02-23 09:52:31 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-02-23 09:52:31 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 12
2022-02-23 09:52:32 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-02-23 09:52:32 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-02-23 09:52:32 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-02-23 09:52:32 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 11
2022-02-23 09:52:33 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-02-23 09:52:33 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-02-23 09:52:33 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-02-23 09:52:33 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 10
2022-02-23 09:52:35 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-02-23 09:52:35 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-02-23 09:52:35 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-02-23 09:52:35 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 9
2022-02-23 09:52:36 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-02-23 09:52:36 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-02-23 09:52:36 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-02-23 09:52:36 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 8
2022-02-23 09:52:37 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-02-23 09:52:37 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-02-23 09:52:37 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-02-23 09:52:37 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 7
2022-02-23 09:52:38 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-02-23 09:52:38 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-02-23 09:52:38 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-02-23 09:52:38 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 6
2022-02-23 09:52:39 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-02-23 09:52:39 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-02-23 09:52:39 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-02-23 09:52:39 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 5
2022-02-23 09:52:40 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-02-23 09:52:40 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-02-23 09:52:40 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-02-23 09:52:40 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 4
2022-02-23 09:52:41 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-02-23 09:52:41 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-02-23 09:52:41 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-02-23 09:52:41 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 3
2022-02-23 09:52:42 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-02-23 09:52:42 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-02-23 09:52:42 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-02-23 09:52:42 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 2
2022-02-23 09:52:43 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-02-23 09:52:43 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-02-23 09:52:43 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-02-23 09:52:43 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:322] Pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq is in the Running state. Remaining seconds pod to be stable 1
2022-02-23 09:52:43 [ForkJoinPool-1-worker-5] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-419333991-kafka-0 ,my-cluster-419333991-kafka-1 ,my-cluster-419333991-kafka-2 ,my-cluster-419333991-kafka-clients-7644c8c47b-csgtq
2022-02-23 09:52:43 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-419333991-kafka rolling update
2022-02-23 09:53:24 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:313] Wait for EO to rolling restart ...
2022-02-23 09:53:24 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1120773431-entity-operator rolling update
2022-02-23 09:53:29 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1120773431-entity-operator will be ready
2022-02-23 09:54:05 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1120773431-entity-operator is ready
2022-02-23 09:54:15 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1120773431-entity-operator rolling update finished
2022-02-23 09:54:15 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:317] Wait for CC and KE to rolling restart ...
2022-02-23 09:54:15 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1120773431-kafka-exporter rolling update
2022-02-23 09:55:16 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1120773431-kafka-exporter will be ready
2022-02-23 09:55:16 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1120773431-kafka-exporter is ready
2022-02-23 09:55:26 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1120773431-kafka-exporter rolling update finished
2022-02-23 09:55:26 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1120773431-cruise-control rolling update
2022-02-23 09:55:26 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1120773431-cruise-control will be ready
2022-02-23 09:55:26 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1120773431-cruise-control is ready
2022-02-23 09:55:36 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1120773431-cruise-control rolling update finished
2022-02-23 09:55:36 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:322] Checking the certificates have been replaced
2022-02-23 09:55:36 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:336] Checking consumed messages to pod:my-cluster-1120773431-kafka-clients-786fb569f6-g9hfq
2022-02-23 09:55:36 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4be6a00, messages=[], arguments=[--group-instance-id, instance276409864, --bootstrap-server, my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9092, --max-messages, 100, --topic, my-topic-1238414940-1976308583, --group-id, my-consumer-group-242199911], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1120773431-kafka-clients-786fb569f6-g9hfq', podNamespace='namespace-13', bootstrapServer='my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9092', topicName='my-topic-1238414940-1976308583', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-242199911', consumerInstanceId='instance276409864', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7ac0cdfb}
2022-02-23 09:55:36 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9092#my-topic-1238414940-1976308583 from pod my-cluster-1120773431-kafka-clients-786fb569f6-g9hfq
2022-02-23 09:55:36 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1120773431-kafka-clients-786fb569f6-g9hfq -n namespace-13 -- /opt/kafka/consumer.sh --group-instance-id instance276409864 --bootstrap-server my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9092 --max-messages 100 --topic my-topic-1238414940-1976308583 --group-id my-consumer-group-242199911
2022-02-23 09:55:41 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 09:55:41 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 09:55:41 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser bob-my-cluster-1120773431 in namespace namespace-14
2022-02-23 09:55:41 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-13
2022-02-23 09:55:41 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: bob-my-cluster-1120773431 will have desired state: Ready
2022-02-23 09:55:42 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaUser: bob-my-cluster-1120773431 is in desired state: Ready
2022-02-23 09:55:42 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-1120773431-kafka-clients-tls in namespace namespace-13
2022-02-23 09:55:42 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-13
2022-02-23 09:55:42 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1120773431-kafka-clients-tls will be ready
2022-02-23 09:55:44 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1120773431-kafka-clients-tls is ready
2022-02-23 09:55:44 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:360] Checking consumed messages to pod:my-cluster-1120773431-kafka-clients-tls-5968b4df6f-h6w8p
2022-02-23 09:55:44 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@78917168, messages=[], arguments=[--group-instance-id, instance528273168, USER=bob_my_cluster_1120773431, --bootstrap-server, my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9093, --max-messages, 100, --topic, my-topic-1238414940-1976308583, --group-id, my-consumer-group-997624568], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1120773431-kafka-clients-tls-5968b4df6f-h6w8p', podNamespace='namespace-13', bootstrapServer='my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9093', topicName='my-topic-1238414940-1976308583', maxMessages=100, kafkaUsername='bob-my-cluster-1120773431', consumerGroupName='my-consumer-group-997624568', consumerInstanceId='instance528273168', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@442db0e}
2022-02-23 09:55:44 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9093#my-topic-1238414940-1976308583 from pod my-cluster-1120773431-kafka-clients-tls-5968b4df6f-h6w8p
2022-02-23 09:55:44 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1120773431-kafka-clients-tls-5968b4df6f-h6w8p -n namespace-13 -- /opt/kafka/consumer.sh --group-instance-id instance528273168 USER=bob_my_cluster_1120773431 --bootstrap-server my-cluster-1120773431-kafka-bootstrap.namespace-13.svc:9093 --max-messages 100 --topic my-topic-1238414940-1976308583 --group-id my-consumer-group-997624568
2022-02-23 09:55:50 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 09:55:50 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 09:55:50 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 09:55:50 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:309] Delete all resources for testAutoRenewAllCaCertsTriggeredByAnno
2022-02-23 09:55:50 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-1120773431-kafka-clients in namespace namespace-13
2022-02-23 09:56:28 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-419333991-kafka has been successfully rolled
2022-02-23 09:56:28 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-419333991-kafka to be ready
2022-02-23 09:57:10 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-1120773431-kafka-clients-tls in namespace namespace-13
2022-02-23 09:57:10 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaUser bob-my-cluster-1120773431 in namespace namespace-13
2022-02-23 09:57:20 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-1372108601-2095190637 in namespace namespace-13
2022-02-23 09:57:30 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-1238414940-1976308583 in namespace namespace-13
2022-02-23 09:57:33 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-419333991 will have desired state: Ready
2022-02-23 09:57:33 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-419333991 is in desired state: Ready
2022-02-23 09:57:33 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-419333991 is ready
2022-02-23 09:57:33 [ForkJoinPool-1-worker-5] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-419333991-clients-ca-cert
2022-02-23 09:57:33 [ForkJoinPool-1-worker-5] [32mINFO [m [SecretUtils:50] Secret my-cluster-419333991-clients-ca-cert created
2022-02-23 09:57:33 [ForkJoinPool-1-worker-5] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-419333991-cluster-ca-cert
2022-02-23 09:57:33 [ForkJoinPool-1-worker-5] [32mINFO [m [SecretUtils:50] Secret my-cluster-419333991-cluster-ca-cert created
2022-02-23 09:57:33 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:835] Checking consumed messages to pod:my-cluster-419333991-kafka-clients-7644c8c47b-csgtq
2022-02-23 09:57:33 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6ec51c87, messages=[], arguments=[USER=my_user_619741671_1072542000, --bootstrap-server, my-cluster-419333991-kafka-bootstrap.namespace-14.svc:9093, --max-messages, 100, --topic, my-topic-177978762-1256900243], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-419333991-kafka-clients-7644c8c47b-csgtq', podNamespace='namespace-14', bootstrapServer='my-cluster-419333991-kafka-bootstrap.namespace-14.svc:9093', topicName='my-topic-177978762-1256900243', maxMessages=100, kafkaUsername='my-user-619741671-1072542000', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6c1280dc}
2022-02-23 09:57:33 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-419333991-kafka-bootstrap.namespace-14.svc:9093:my-topic-177978762-1256900243 from pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq
2022-02-23 09:57:33 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-419333991-kafka-clients-7644c8c47b-csgtq -n namespace-14 -- /opt/kafka/producer.sh USER=my_user_619741671_1072542000 --bootstrap-server my-cluster-419333991-kafka-bootstrap.namespace-14.svc:9093 --max-messages 100 --topic my-topic-177978762-1256900243
2022-02-23 09:57:36 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-02-23 09:57:36 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-02-23 09:57:36 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@76867a1, messages=[], arguments=[--group-instance-id, instance1942719577, USER=my_user_619741671_1072542000, --bootstrap-server, my-cluster-419333991-kafka-bootstrap.namespace-14.svc:9093, --max-messages, 100, --topic, my-topic-177978762-1256900243, --group-id, my-consumer-group-903758256], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-419333991-kafka-clients-7644c8c47b-csgtq', podNamespace='namespace-14', bootstrapServer='my-cluster-419333991-kafka-bootstrap.namespace-14.svc:9093', topicName='my-topic-177978762-1256900243', maxMessages=100, kafkaUsername='my-user-619741671-1072542000', consumerGroupName='my-consumer-group-903758256', consumerInstanceId='instance1942719577', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7f040cfd}
2022-02-23 09:57:36 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-419333991-kafka-bootstrap.namespace-14.svc:9093:my-topic-177978762-1256900243 from pod my-cluster-419333991-kafka-clients-7644c8c47b-csgtq
2022-02-23 09:57:36 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-419333991-kafka-clients-7644c8c47b-csgtq -n namespace-14 -- /opt/kafka/consumer.sh --group-instance-id instance1942719577 USER=my_user_619741671_1072542000 --bootstrap-server my-cluster-419333991-kafka-bootstrap.namespace-14.svc:9093 --max-messages 100 --topic my-topic-177978762-1256900243 --group-id my-consumer-group-903758256
2022-02-23 09:57:40 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-1120773431 in namespace namespace-13
2022-02-23 09:57:40 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-13, for cruise control Kafka cluster my-cluster-1120773431
2022-02-23 09:57:43 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-23 09:57:43 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-23 09:57:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 09:57:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:309] Delete all resources for testCertRegeneratedAfterInternalCAisDeleted
2022-02-23 09:57:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-177978762-1256900243 in namespace namespace-14
2022-02-23 09:57:50 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 09:57:50 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-13 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-02-23 09:57:53 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-419333991-kafka-clients in namespace namespace-14
2022-02-23 09:58:34 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-FINISHED
2022-02-23 09:58:34 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 09:58:34 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 09:58:34 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-STARTED
2022-02-23 09:58:35 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 09:58:35 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-15 for test case:testClusterCACertRenew
2022-02-23 09:58:35 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-15
2022-02-23 09:58:35 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-15
2022-02-23 09:58:35 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-15
2022-02-23 09:58:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-2070662685 in namespace namespace-15
2022-02-23 09:58:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-15
2022-02-23 09:58:35 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-2070662685 will have desired state: Ready
2022-02-23 09:58:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-619741671-1072542000 in namespace namespace-14
2022-02-23 09:58:53 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-419333991 in namespace namespace-14
2022-02-23 09:59:03 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 09:59:03 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-14 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-02-23 09:59:46 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-FINISHED
2022-02-23 09:59:46 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 09:59:46 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 09:59:46 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAclRuleReadAndWrite-STARTED
2022-02-23 09:59:49 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 09:59:49 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-16 for test case:testKafkaAndKafkaConnectCipherSuites
2022-02-23 09:59:49 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-16
2022-02-23 09:59:49 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-16
2022-02-23 09:59:49 [ForkJoinPool-1-worker-1] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-16
2022-02-23 09:59:49 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1385] Deploying Kafka cluster with the support TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 cipher algorithms
2022-02-23 09:59:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-1983440110 in namespace namespace-16
2022-02-23 09:59:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-16
2022-02-23 09:59:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-1983440110 will have desired state: Ready
2022-02-23 10:06:36 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-1983440110 is in desired state: Ready
2022-02-23 10:06:36 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1397] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-02-23 10:06:36 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-1983440110-kafka-clients in namespace namespace-16
2022-02-23 10:06:36 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-16
2022-02-23 10:06:36 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1983440110-kafka-clients will be ready
2022-02-23 10:06:38 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1983440110-kafka-clients is ready
2022-02-23 10:06:38 [ForkJoinPool-1-worker-1] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-1983440110-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-02-23 10:06:38 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update NetworkPolicy my-cluster-1983440110-allow in namespace namespace-16
2022-02-23 10:06:38 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-16
2022-02-23 10:06:38 [ForkJoinPool-1-worker-1] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-02-23 10:06:38 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaConnect my-cluster-1983440110 in namespace namespace-16
2022-02-23 10:06:38 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-16
2022-02-23 10:06:38 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1414] Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm
2022-02-23 10:06:38 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaConnect: my-cluster-1983440110 will have desired state: NotReady
2022-02-23 10:06:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-2070662685 is in desired state: Ready
2022-02-23 10:06:50 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1562] Change of kafka validity and renewal days - reconciliation should start.
2022-02-23 10:06:50 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-2070662685-kafka rolling update
2022-02-23 10:09:25 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-2070662685-kafka has been successfully rolled
2022-02-23 10:09:25 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-2070662685-kafka to be ready
2022-02-23 10:10:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-2070662685 will have desired state: Ready
2022-02-23 10:10:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-2070662685 is in desired state: Ready
2022-02-23 10:10:01 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2070662685 is ready
2022-02-23 10:10:01 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1592] Initial ClusterCA cert dates: Wed Feb 23 04:58:35 EST 2022 --> Tue Mar 15 05:58:35 EDT 2022
2022-02-23 10:10:01 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1593] Changed ClusterCA cert dates: Wed Feb 23 05:06:51 EST 2022 --> Sun Sep 11 06:06:51 EDT 2022
2022-02-23 10:10:01 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1594] KafkaBroker cert creation dates: Wed Feb 23 04:59:05 EST 2022 --> Tue Mar 15 05:59:05 EDT 2022
2022-02-23 10:10:01 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1595] KafkaBroker cert changed dates:  Wed Feb 23 05:08:16 EST 2022 --> Sun Sep 11 06:08:16 EDT 2022
2022-02-23 10:10:01 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1596] Zookeeper cert creation dates: Wed Feb 23 04:58:37 EST 2022 --> Tue Mar 15 05:58:37 EDT 2022
2022-02-23 10:10:01 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:1597] Zookeeper cert changed dates:  Wed Feb 23 05:06:52 EST 2022 --> Sun Sep 11 06:06:52 EDT 2022
2022-02-23 10:10:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 10:10:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:309] Delete all resources for testClusterCACertRenew
2022-02-23 10:10:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-2070662685 in namespace namespace-15
2022-02-23 10:10:11 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 10:10:11 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-15 for test case:testClusterCACertRenew
2022-02-23 10:10:54 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-FINISHED
2022-02-23 10:10:54 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 10:10:54 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 10:10:54 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-STARTED
2022-02-23 10:10:56 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 10:10:56 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-17 for test case:testAclRuleReadAndWrite
2022-02-23 10:10:56 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-17
2022-02-23 10:10:56 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-17
2022-02-23 10:10:56 [ForkJoinPool-1-worker-5] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-17
2022-02-23 10:10:56 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-1767916682 in namespace namespace-17
2022-02-23 10:10:56 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-17
2022-02-23 10:10:56 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-1767916682 will have desired state: Ready
2022-02-23 10:11:39 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaConnect: my-cluster-1983440110 is in desired state: NotReady
2022-02-23 10:11:39 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1418] Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.
2022-02-23 10:11:39 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1422] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-02-23 10:11:39 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-02-23 10:11:39 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-02-23 10:11:39 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1427] Verifying that Kafka Connect is stable
2022-02-23 10:11:39 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-1983440110-connect are stable
2022-02-23 10:11:39 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 50
2022-02-23 10:11:40 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 49
2022-02-23 10:11:41 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 48
2022-02-23 10:11:42 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 47
2022-02-23 10:11:43 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 46
2022-02-23 10:11:44 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 45
2022-02-23 10:11:45 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 44
2022-02-23 10:11:46 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 43
2022-02-23 10:11:47 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 42
2022-02-23 10:11:48 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 41
2022-02-23 10:11:49 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 40
2022-02-23 10:11:50 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 39
2022-02-23 10:11:51 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 38
2022-02-23 10:11:52 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 37
2022-02-23 10:11:53 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 36
2022-02-23 10:11:54 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 35
2022-02-23 10:11:55 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 34
2022-02-23 10:11:56 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 33
2022-02-23 10:11:57 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 32
2022-02-23 10:11:59 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 31
2022-02-23 10:12:00 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 30
2022-02-23 10:12:01 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 29
2022-02-23 10:12:02 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 28
2022-02-23 10:12:03 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 27
2022-02-23 10:12:04 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 26
2022-02-23 10:12:05 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 25
2022-02-23 10:12:06 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 24
2022-02-23 10:12:07 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 23
2022-02-23 10:12:08 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 22
2022-02-23 10:12:09 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 21
2022-02-23 10:12:10 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 20
2022-02-23 10:12:11 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 19
2022-02-23 10:12:12 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 18
2022-02-23 10:12:13 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 17
2022-02-23 10:12:14 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 16
2022-02-23 10:12:15 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 15
2022-02-23 10:12:16 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 14
2022-02-23 10:12:17 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 13
2022-02-23 10:12:18 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 12
2022-02-23 10:12:19 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 11
2022-02-23 10:12:20 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 10
2022-02-23 10:12:21 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 9
2022-02-23 10:12:22 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 8
2022-02-23 10:12:23 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 7
2022-02-23 10:12:24 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 6
2022-02-23 10:12:25 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 5
2022-02-23 10:12:26 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 4
2022-02-23 10:12:27 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 3
2022-02-23 10:12:28 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 2
2022-02-23 10:12:29 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:322] Pod my-cluster-1983440110-connect-9c4764868-5lgtl is in the Running state. Remaining seconds pod to be stable 1
2022-02-23 10:12:29 [ForkJoinPool-1-worker-1] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-1983440110-connect-9c4764868-5lgtl
2022-02-23 10:12:29 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1431] Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm
2022-02-23 10:12:29 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaConnect: my-cluster-1983440110 will have desired state: Ready
2022-02-23 10:15:22 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-1767916682 is in desired state: Ready
2022-02-23 10:15:22 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-1237564573-438599821 in namespace namespace-17
2022-02-23 10:15:22 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-17
2022-02-23 10:15:22 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-1237564573-438599821 will have desired state: Ready
2022-02-23 10:15:23 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-1237564573-438599821 is in desired state: Ready
2022-02-23 10:15:23 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser kafka-user-write in namespace namespace-17
2022-02-23 10:15:23 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-17
2022-02-23 10:15:23 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: kafka-user-write will have desired state: Ready
2022-02-23 10:15:24 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaUser: kafka-user-write is in desired state: Ready
2022-02-23 10:15:24 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:1010] Checking KafkaUser kafka-user-write that is able to send messages to topic 'my-topic-1237564573-438599821'
2022-02-23 10:15:24 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 10:15:24 [ForkJoinPool-1-worker-5] [32mINFO [m [ProducerConfig:376] ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.49.2:32608]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-464095070
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 6000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties7227922996958968008.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties16832213155878705026.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-02-23 10:15:24 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-02-23 10:15:24 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-23 10:15:24 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1645611324714
2022-02-23 10:15:24 [kafka-producer-network-thread | producer-464095070] [32mINFO [m [Metadata:402] [Producer clientId=producer-464095070] Resetting the last seen epoch of partition my-topic-1237564573-438599821-0 to 0 since the associated topicId changed from null to fnEoPD7pSCeEYpZmdHzLOA
2022-02-23 10:15:24 [kafka-producer-network-thread | producer-464095070] [32mINFO [m [Metadata:287] [Producer clientId=producer-464095070] Cluster ID: O7Jlz7SdTYarf7iEYZrtLQ
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [ExternalKafkaClient:182] Sent 500 messages.
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [KafkaProducer:1228] [Producer clientId=producer-464095070] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:83] App info kafka.producer for producer-464095070 unregistered
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerConfig:376] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.49.2:32608]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-1544179363
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-419048604
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties15636960595183762190.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties1738759379712034298.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1645611325547
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [KafkaConsumer:966] [Consumer clientId=consumer-1544179363, groupId=my-consumer-group-419048604] Subscribed to topic(s): my-topic-1237564573-438599821
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [Metadata:402] [Consumer clientId=consumer-1544179363, groupId=my-consumer-group-419048604] Resetting the last seen epoch of partition my-topic-1237564573-438599821-0 to 0 since the associated topicId changed from null to fnEoPD7pSCeEYpZmdHzLOA
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [Metadata:287] [Consumer clientId=consumer-1544179363, groupId=my-consumer-group-419048604] Cluster ID: O7Jlz7SdTYarf7iEYZrtLQ
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:261] [Consumer clientId=consumer-1544179363, groupId=my-consumer-group-419048604] FindCoordinator request hit fatal exception
org.apache.kafka.common.errors.GroupAuthorizationException: Not authorized to access group: my-consumer-group-419048604
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser kafka-user-read in namespace namespace-17
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-17
2022-02-23 10:15:25 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: kafka-user-read will have desired state: Ready
2022-02-23 10:15:26 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaUser: kafka-user-read is in desired state: Ready
2022-02-23 10:15:26 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerConfig:376] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.49.2:32608]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-169472841
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = consumer-group-name-1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties17025008524869123627.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties5137016855763035592.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-02-23 10:15:26 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-02-23 10:15:26 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-23 10:15:26 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1645611326698
2022-02-23 10:15:26 [ForkJoinPool-1-worker-5] [32mINFO [m [KafkaConsumer:966] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Subscribed to topic(s): my-topic-1237564573-438599821
2022-02-23 10:15:26 [ForkJoinPool-1-worker-5] [32mINFO [m [Metadata:402] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Resetting the last seen epoch of partition my-topic-1237564573-438599821-0 to 0 since the associated topicId changed from null to fnEoPD7pSCeEYpZmdHzLOA
2022-02-23 10:15:26 [ForkJoinPool-1-worker-5] [32mINFO [m [Metadata:287] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Cluster ID: O7Jlz7SdTYarf7iEYZrtLQ
2022-02-23 10:15:26 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:853] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Discovered group coordinator 192.168.49.2:32598 (id: 2147483647 rack: null)
2022-02-23 10:15:26 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:535] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] (Re-)joining group
2022-02-23 10:15:26 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:1000] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Request joining group due to: need to re-join with the given member-id
2022-02-23 10:15:26 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:535] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] (Re-)joining group
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:595] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Successfully joined group with generation Generation{generationId=1, memberId='consumer-169472841-b505c2de-7f9c-4d24-a4ac-1fd58aeac9fa', protocol='range'}
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:652] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Finished assignment for group at generation 1: {consumer-169472841-b505c2de-7f9c-4d24-a4ac-1fd58aeac9fa=Assignment(partitions=[my-topic-1237564573-438599821-0])}
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:761] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Successfully synced group in generation Generation{generationId=1, memberId='consumer-169472841-b505c2de-7f9c-4d24-a4ac-1fd58aeac9fa', protocol='range'}
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:279] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Notifying assignor about the new Assignment(partitions=[my-topic-1237564573-438599821-0])
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:291] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Adding newly assigned partitions: my-topic-1237564573-438599821-0
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:1388] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Found no committed offset for partition my-topic-1237564573-438599821-0
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [SubscriptionState:398] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Resetting offset for partition my-topic-1237564573-438599821-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.49.2:32755 (id: 1 rack: null)], epoch=0}}.
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [ExternalKafkaClient:224] Received 500 messages.
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:310] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Revoke previously assigned partitions my-topic-1237564573-438599821-0
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:1060] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Member consumer-169472841-b505c2de-7f9c-4d24-a4ac-1fd58aeac9fa sending LeaveGroup request to coordinator 192.168.49.2:32598 (id: 2147483647 rack: null) due to the consumer is being closed
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:972] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Resetting generation due to: consumer pro-actively leaving the group
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [ConsumerCoordinator:1000] [Consumer clientId=consumer-169472841, groupId=consumer-group-name-1] Request joining group due to: consumer pro-actively leaving the group
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:83] App info kafka.consumer for consumer-169472841 unregistered
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:1058] Checking KafkaUser kafka-user-read that is not able to send messages to topic 'my-topic-1237564573-438599821'
2022-02-23 10:15:29 [ForkJoinPool-1-worker-5] [32mINFO [m [ProducerConfig:376] ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.49.2:32608]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2036671951
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 6000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties7306460174148665347.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties12393178087124004061.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-02-23 10:15:30 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-02-23 10:15:30 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-23 10:15:30 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1645611330043
2022-02-23 10:15:30 [kafka-producer-network-thread | producer-2036671951] [32mINFO [m [Metadata:402] [Producer clientId=producer-2036671951] Resetting the last seen epoch of partition my-topic-1237564573-438599821-0 to 0 since the associated topicId changed from null to fnEoPD7pSCeEYpZmdHzLOA
2022-02-23 10:15:30 [kafka-producer-network-thread | producer-2036671951] [32mINFO [m [Metadata:287] [Producer clientId=producer-2036671951] Cluster ID: O7Jlz7SdTYarf7iEYZrtLQ
2022-02-23 10:15:30 [ForkJoinPool-1-worker-5] [1;31mERROR[m [ExternalKafkaClient:171] Error sending message 0 - org.apache.kafka.common.errors.TopicAuthorizationException: Not authorized to access topics: [my-topic-1237564573-438599821]
2022-02-23 10:15:30 [ForkJoinPool-1-worker-5] [32mINFO [m [KafkaProducer:1228] [Producer clientId=producer-2036671951] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-02-23 10:15:30 [ForkJoinPool-1-worker-5] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-02-23 10:15:30 [ForkJoinPool-1-worker-5] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-02-23 10:15:30 [ForkJoinPool-1-worker-5] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-02-23 10:15:30 [ForkJoinPool-1-worker-5] [32mINFO [m [AppInfoParser:83] App info kafka.producer for producer-2036671951 unregistered
2022-02-23 10:15:30 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 10:15:30 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:309] Delete all resources for testAclRuleReadAndWrite
2022-02-23 10:15:30 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaUser kafka-user-write in namespace namespace-17
2022-02-23 10:15:40 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaUser kafka-user-read in namespace namespace-17
2022-02-23 10:15:40 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-1237564573-438599821 in namespace namespace-17
2022-02-23 10:15:50 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-1767916682 in namespace namespace-17
2022-02-23 10:16:00 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 10:16:00 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-17 for test case:testAclRuleReadAndWrite
2022-02-23 10:16:43 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAclRuleReadAndWrite-FINISHED
2022-02-23 10:16:43 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 10:16:43 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 10:16:43 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-STARTED
2022-02-23 10:16:44 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 10:16:44 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-18 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-02-23 10:16:44 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-18
2022-02-23 10:16:44 [ForkJoinPool-1-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-18
2022-02-23 10:16:44 [ForkJoinPool-1-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-18
2022-02-23 10:16:44 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:601] Creating a cluster
2022-02-23 10:16:44 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-1160923759 in namespace namespace-18
2022-02-23 10:16:44 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-18
2022-02-23 10:16:44 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-1160923759 will have desired state: Ready
2022-02-23 10:17:50 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaConnect: my-cluster-1983440110 is in desired state: Ready
2022-02-23 10:17:50 [ForkJoinPool-1-worker-1] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-1983440110-connect is not deleted yet! Triggering force delete by cmd client!
2022-02-23 10:17:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 10:17:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:309] Delete all resources for testKafkaAndKafkaConnectCipherSuites
2022-02-23 10:17:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of NetworkPolicy my-cluster-1983440110-allow in namespace namespace-16
2022-02-23 10:17:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaConnect my-cluster-1983440110 in namespace namespace-16
2022-02-23 10:17:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-1983440110-kafka-clients in namespace namespace-16
2022-02-23 10:18:36 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-1983440110 in namespace namespace-16
2022-02-23 10:18:46 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 10:18:46 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-16 for test case:testKafkaAndKafkaConnectCipherSuites
2022-02-23 10:19:29 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-FINISHED
2022-02-23 10:19:29 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 10:19:29 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 10:19:29 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-STARTED
2022-02-23 10:19:33 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 10:19:33 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-19 for test case:testCertRenewalInMaintenanceWindow
2022-02-23 10:19:33 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-19
2022-02-23 10:19:33 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-19
2022-02-23 10:19:33 [ForkJoinPool-1-worker-5] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-19
2022-02-23 10:19:33 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:712] Maintenance window is: * 24-38 * * * ? *
2022-02-23 10:19:33 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-2004996625 in namespace namespace-19
2022-02-23 10:19:33 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-19
2022-02-23 10:19:33 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-2004996625 will have desired state: Ready
2022-02-23 10:19:59 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-1160923759 is in desired state: Ready
2022-02-23 10:19:59 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-1841206926-255802660 in namespace namespace-19
2022-02-23 10:19:59 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-18
2022-02-23 10:19:59 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-1841206926-255802660 will have desired state: Ready
2022-02-23 10:20:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-1841206926-255802660 is in desired state: Ready
2022-02-23 10:20:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-976787697-86257790 in namespace namespace-19
2022-02-23 10:20:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-18
2022-02-23 10:20:00 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-976787697-86257790 will have desired state: Ready
2022-02-23 10:20:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-976787697-86257790 is in desired state: Ready
2022-02-23 10:20:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-1160923759-kafka-clients in namespace namespace-19
2022-02-23 10:20:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-18
2022-02-23 10:20:01 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1160923759-kafka-clients will be ready
2022-02-23 10:20:04 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1160923759-kafka-clients is ready
2022-02-23 10:20:04 [ForkJoinPool-1-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 10:20:04 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:467] Checking produced and consumed messages to pod:my-cluster-1160923759-kafka-clients-8677b7c8c6-47xcc
2022-02-23 10:20:04 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@38874fd5, messages=[], arguments=[--bootstrap-server, my-cluster-1160923759-kafka-bootstrap.namespace-18.svc:9092, --max-messages, 100, --topic, my-topic-976787697-86257790], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1160923759-kafka-clients-8677b7c8c6-47xcc', podNamespace='namespace-18', bootstrapServer='my-cluster-1160923759-kafka-bootstrap.namespace-18.svc:9092', topicName='my-topic-976787697-86257790', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@16456607}
2022-02-23 10:20:04 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-1160923759-kafka-bootstrap.namespace-18.svc:9092:my-topic-976787697-86257790 from pod my-cluster-1160923759-kafka-clients-8677b7c8c6-47xcc
2022-02-23 10:20:04 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1160923759-kafka-clients-8677b7c8c6-47xcc -n namespace-18 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-1160923759-kafka-bootstrap.namespace-18.svc:9092 --max-messages 100 --topic my-topic-976787697-86257790
2022-02-23 10:20:07 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-02-23 10:20:07 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-02-23 10:20:07 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@e40c605, messages=[], arguments=[--group-instance-id, instance770842507, --bootstrap-server, my-cluster-1160923759-kafka-bootstrap.namespace-18.svc:9092, --max-messages, 100, --topic, my-topic-976787697-86257790, --group-id, my-consumer-group-531326746], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1160923759-kafka-clients-8677b7c8c6-47xcc', podNamespace='namespace-18', bootstrapServer='my-cluster-1160923759-kafka-bootstrap.namespace-18.svc:9092', topicName='my-topic-976787697-86257790', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-531326746', consumerInstanceId='instance770842507', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1cb62332}
2022-02-23 10:20:07 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1160923759-kafka-bootstrap.namespace-18.svc:9092#my-topic-976787697-86257790 from pod my-cluster-1160923759-kafka-clients-8677b7c8c6-47xcc
2022-02-23 10:20:07 [ForkJoinPool-1-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1160923759-kafka-clients-8677b7c8c6-47xcc -n namespace-18 -- /opt/kafka/consumer.sh --group-instance-id instance770842507 --bootstrap-server my-cluster-1160923759-kafka-bootstrap.namespace-18.svc:9092 --max-messages 100 --topic my-topic-976787697-86257790 --group-id my-consumer-group-531326746
2022-02-23 10:20:12 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 10:20:12 [ForkJoinPool-1-worker-3] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 10:20:12 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:481] Triggering CA cert renewal by adding the annotation
2022-02-23 10:20:12 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:493] Patching secret my-cluster-1160923759-cluster-ca with strimzi.io/force-replace
2022-02-23 10:20:12 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:493] Patching secret my-cluster-1160923759-clients-ca with strimzi.io/force-replace
2022-02-23 10:20:12 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:498] Wait for zk to rolling restart (1)...
2022-02-23 10:20:12 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1160923759-zookeeper rolling update
2022-02-23 10:21:37 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1160923759-zookeeper has been successfully rolled
2022-02-23 10:21:37 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:503] Wait for kafka to rolling restart (1)...
2022-02-23 10:21:37 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1160923759-kafka rolling update
2022-02-23 10:22:42 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-2004996625 is in desired state: Ready
2022-02-23 10:22:42 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-441177414-770436271 in namespace namespace-19
2022-02-23 10:22:42 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-19
2022-02-23 10:22:42 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-441177414-770436271 will have desired state: Ready
2022-02-23 10:22:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-441177414-770436271 is in desired state: Ready
2022-02-23 10:22:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-402717506-1854088516 in namespace namespace-19
2022-02-23 10:22:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-19
2022-02-23 10:22:43 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-402717506-1854088516 will have desired state: Ready
2022-02-23 10:22:44 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-402717506-1854088516 is in desired state: Ready
2022-02-23 10:22:44 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-402717506-1854088516 in namespace namespace-19
2022-02-23 10:22:44 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-19
2022-02-23 10:22:44 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-402717506-1854088516 will have desired state: Ready
2022-02-23 10:22:44 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-402717506-1854088516 is in desired state: Ready
2022-02-23 10:22:44 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-2004996625-kafka-clients in namespace namespace-19
2022-02-23 10:22:44 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-19
2022-02-23 10:22:44 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2004996625-kafka-clients will be ready
2022-02-23 10:22:46 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2004996625-kafka-clients is ready
2022-02-23 10:22:46 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 10:22:46 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:742] Annotate secret my-cluster-2004996625-cluster-ca-cert with secret force-renew annotation
2022-02-23 10:22:46 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:749] Wait until maintenance windows starts
2022-02-23 10:24:00 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:755] Maintenance window starts
2022-02-23 10:24:00 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:759] Wait until rolling update is triggered during maintenance window
2022-02-23 10:24:00 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-2004996625-kafka rolling update
2022-02-23 10:24:47 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1160923759-kafka has been successfully rolled
2022-02-23 10:24:47 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:508] Wait for EO to rolling restart (1)...
2022-02-23 10:24:47 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1160923759-entity-operator rolling update
2022-02-23 10:26:02 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1160923759-entity-operator will be ready
2022-02-23 10:28:46 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-2004996625-kafka has been successfully rolled
2022-02-23 10:28:46 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-2004996625-kafka to be ready
2022-02-23 10:29:44 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1160923759-entity-operator is ready
2022-02-23 10:29:54 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1160923759-entity-operator rolling update finished
2022-02-23 10:29:54 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:513] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-02-23 10:29:54 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1160923759-kafka-exporter rolling update
2022-02-23 10:29:58 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-2004996625 will have desired state: Ready
2022-02-23 10:29:58 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-2004996625 is in desired state: Ready
2022-02-23 10:29:58 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2004996625 is ready
2022-02-23 10:29:58 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:764] Checking consumed messages to pod:my-cluster-2004996625-kafka-clients-57cc48d94-4kng8
2022-02-23 10:29:58 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2878a2f4, messages=[], arguments=[USER=my_user_441177414_770436271, --bootstrap-server, my-cluster-2004996625-kafka-bootstrap.namespace-19.svc:9093, --max-messages, 100, --topic, my-topic-402717506-1854088516], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2004996625-kafka-clients-57cc48d94-4kng8', podNamespace='namespace-19', bootstrapServer='my-cluster-2004996625-kafka-bootstrap.namespace-19.svc:9093', topicName='my-topic-402717506-1854088516', maxMessages=100, kafkaUsername='my-user-441177414-770436271', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7898c5a4}
2022-02-23 10:29:58 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-2004996625-kafka-bootstrap.namespace-19.svc:9093:my-topic-402717506-1854088516 from pod my-cluster-2004996625-kafka-clients-57cc48d94-4kng8
2022-02-23 10:29:58 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2004996625-kafka-clients-57cc48d94-4kng8 -n namespace-19 -- /opt/kafka/producer.sh USER=my_user_441177414_770436271 --bootstrap-server my-cluster-2004996625-kafka-bootstrap.namespace-19.svc:9093 --max-messages 100 --topic my-topic-402717506-1854088516
2022-02-23 10:29:59 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1160923759-kafka-exporter will be ready
2022-02-23 10:30:01 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-02-23 10:30:01 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-02-23 10:30:01 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@792e7e37, messages=[], arguments=[--group-instance-id, instance1560705731, USER=my_user_441177414_770436271, --bootstrap-server, my-cluster-2004996625-kafka-bootstrap.namespace-19.svc:9093, --max-messages, 100, --topic, my-topic-402717506-1854088516, --group-id, my-consumer-group-1251001610], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2004996625-kafka-clients-57cc48d94-4kng8', podNamespace='namespace-19', bootstrapServer='my-cluster-2004996625-kafka-bootstrap.namespace-19.svc:9093', topicName='my-topic-402717506-1854088516', maxMessages=100, kafkaUsername='my-user-441177414-770436271', consumerGroupName='my-consumer-group-1251001610', consumerInstanceId='instance1560705731', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@47a52682}
2022-02-23 10:30:01 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2004996625-kafka-bootstrap.namespace-19.svc:9093:my-topic-402717506-1854088516 from pod my-cluster-2004996625-kafka-clients-57cc48d94-4kng8
2022-02-23 10:30:01 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2004996625-kafka-clients-57cc48d94-4kng8 -n namespace-19 -- /opt/kafka/consumer.sh --group-instance-id instance1560705731 USER=my_user_441177414_770436271 --bootstrap-server my-cluster-2004996625-kafka-bootstrap.namespace-19.svc:9093 --max-messages 100 --topic my-topic-402717506-1854088516 --group-id my-consumer-group-1251001610
2022-02-23 10:30:07 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-23 10:30:07 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-23 10:30:07 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 10:30:07 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:309] Delete all resources for testCertRenewalInMaintenanceWindow
2022-02-23 10:30:07 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-402717506-1854088516 in namespace namespace-19
2022-02-23 10:30:16 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1160923759-kafka-exporter is ready
2022-02-23 10:30:17 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-2004996625-kafka-clients in namespace namespace-19
2022-02-23 10:30:26 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1160923759-kafka-exporter rolling update finished
2022-02-23 10:30:26 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1160923759-cruise-control rolling update
2022-02-23 10:30:26 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1160923759-cruise-control will be ready
2022-02-23 10:30:36 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1160923759-cruise-control is ready
2022-02-23 10:30:46 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1160923759-cruise-control rolling update finished
2022-02-23 10:30:46 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:519] Wait for zk to rolling restart (2)...
2022-02-23 10:30:46 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1160923759-zookeeper rolling update
2022-02-23 10:30:57 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-402717506-1854088516 in namespace namespace-19
2022-02-23 10:30:57 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-441177414-770436271 in namespace namespace-19
2022-02-23 10:31:07 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-2004996625 in namespace namespace-19
2022-02-23 10:31:17 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 10:31:17 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-19 for test case:testCertRenewalInMaintenanceWindow
2022-02-23 10:31:45 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-FINISHED
2022-02-23 10:31:45 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 10:31:45 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 10:31:45 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-STARTED
2022-02-23 10:31:46 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1160923759-zookeeper has been successfully rolled
2022-02-23 10:31:46 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-1160923759-zookeeper to be ready
2022-02-23 10:31:49 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 10:31:49 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-20 for test case:testOwnerReferenceOfCASecrets
2022-02-23 10:31:49 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-20
2022-02-23 10:31:49 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-20
2022-02-23 10:31:49 [ForkJoinPool-1-worker-1] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-20
2022-02-23 10:31:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-716452267 in namespace namespace-20
2022-02-23 10:31:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-20
2022-02-23 10:31:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-716452267 will have desired state: Ready
2022-02-23 10:32:23 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:524] Wait for kafka to rolling restart (2)...
2022-02-23 10:32:23 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1160923759-kafka rolling update
2022-02-23 10:35:48 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-716452267 is in desired state: Ready
2022-02-23 10:35:48 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1458] Listing all cluster CAs for my-cluster-716452267
2022-02-23 10:35:48 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1462] Deleting Kafka:my-cluster-716452267
2022-02-23 10:35:48 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaUtils:397] Waiting for deletion of Kafka:my-cluster-716452267
2022-02-23 10:35:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1466] Checking actual secrets after Kafka deletion
2022-02-23 10:35:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1469] Checking that my-cluster-716452267-clients-ca secret is still present
2022-02-23 10:35:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1472] Deleting secret: my-cluster-716452267-clients-ca
2022-02-23 10:35:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1469] Checking that my-cluster-716452267-clients-ca-cert secret is still present
2022-02-23 10:35:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1472] Deleting secret: my-cluster-716452267-clients-ca-cert
2022-02-23 10:35:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1469] Checking that my-cluster-716452267-cluster-ca secret is still present
2022-02-23 10:35:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1472] Deleting secret: my-cluster-716452267-cluster-ca
2022-02-23 10:35:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1469] Checking that my-cluster-716452267-cluster-ca-cert secret is still present
2022-02-23 10:35:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1472] Deleting secret: my-cluster-716452267-cluster-ca-cert
2022-02-23 10:35:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1476] Deploying Kafka with generateSecretOwnerReference set to true
2022-02-23 10:35:52 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-second-cluster-my-cluster-716452267 in namespace namespace-20
2022-02-23 10:35:52 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-20
2022-02-23 10:35:52 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-second-cluster-my-cluster-716452267 will have desired state: Ready
2022-02-23 10:37:09 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1160923759-kafka has been successfully rolled
2022-02-23 10:37:09 [ForkJoinPool-1-worker-3] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-1160923759-kafka to be ready
2022-02-23 10:42:36 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:529] Wait for EO to rolling restart (2)...
2022-02-23 10:42:36 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1160923759-entity-operator rolling update
2022-02-23 10:42:36 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1160923759-entity-operator will be ready
2022-02-23 10:42:49 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] Kafka: my-second-cluster-my-cluster-716452267 is in desired state: Ready
2022-02-23 10:42:49 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1491] Deleting Kafka:my-second-cluster-my-cluster-716452267
2022-02-23 10:42:49 [ForkJoinPool-1-worker-1] [32mINFO [m [KafkaUtils:397] Waiting for deletion of Kafka:my-second-cluster-my-cluster-716452267
2022-02-23 10:42:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1495] Checking actual secrets after Kafka deletion
2022-02-23 10:42:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1498] Checking that my-second-cluster-my-cluster-716452267-clients-ca secret is deleted
2022-02-23 10:42:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1498] Checking that my-second-cluster-my-cluster-716452267-clients-ca-cert secret is deleted
2022-02-23 10:42:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1498] Checking that my-second-cluster-my-cluster-716452267-cluster-ca secret is deleted
2022-02-23 10:42:52 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:1498] Checking that my-second-cluster-my-cluster-716452267-cluster-ca-cert secret is deleted
2022-02-23 10:42:52 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 10:42:52 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:309] Delete all resources for testOwnerReferenceOfCASecrets
2022-02-23 10:42:52 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Kafka my-second-cluster-my-cluster-716452267 in namespace namespace-20
2022-02-23 10:42:52 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-716452267 in namespace namespace-20
2022-02-23 10:42:52 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 10:42:52 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-20 for test case:testOwnerReferenceOfCASecrets
2022-02-23 10:43:35 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-FINISHED
2022-02-23 10:43:35 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 10:43:35 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 10:43:35 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-STARTED
2022-02-23 10:43:40 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 10:43:40 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-21 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-02-23 10:43:40 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-21
2022-02-23 10:43:40 [ForkJoinPool-1-worker-5] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-21
2022-02-23 10:43:40 [ForkJoinPool-1-worker-5] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-21
2022-02-23 10:43:40 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:601] Creating a cluster
2022-02-23 10:43:40 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-681912537 in namespace namespace-21
2022-02-23 10:43:40 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-21
2022-02-23 10:43:40 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-681912537 will have desired state: Ready
2022-02-23 10:46:36 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1160923759-entity-operator is ready
2022-02-23 10:46:47 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1160923759-entity-operator rolling update finished
2022-02-23 10:46:47 [ForkJoinPool-1-worker-3] [32mINFO [m [SecurityST:534] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-02-23 10:46:47 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1160923759-kafka-exporter rolling update
2022-02-23 10:47:02 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1160923759-kafka-exporter will be ready
2022-02-23 10:47:02 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1160923759-kafka-exporter is ready
2022-02-23 10:47:12 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1160923759-kafka-exporter rolling update finished
2022-02-23 10:47:12 [ForkJoinPool-1-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1160923759-cruise-control rolling update
2022-02-23 10:47:46 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-681912537 is in desired state: Ready
2022-02-23 10:47:46 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-1247307101-1376868286 in namespace namespace-21
2022-02-23 10:47:46 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-21
2022-02-23 10:47:46 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-1247307101-1376868286 will have desired state: Ready
2022-02-23 10:47:47 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-1247307101-1376868286 is in desired state: Ready
2022-02-23 10:47:47 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-699442351-1764401160 in namespace namespace-21
2022-02-23 10:47:47 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-21
2022-02-23 10:47:47 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-699442351-1764401160 will have desired state: Ready
2022-02-23 10:47:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-699442351-1764401160 is in desired state: Ready
2022-02-23 10:47:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-681912537-kafka-clients in namespace namespace-21
2022-02-23 10:47:48 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-21
2022-02-23 10:47:48 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-681912537-kafka-clients will be ready
2022-02-23 10:47:49 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-681912537-kafka-clients is ready
2022-02-23 10:47:49 [ForkJoinPool-1-worker-5] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 10:47:49 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:274] Checking produced and consumed messages to pod:my-cluster-681912537-kafka-clients-dc57c598-92lrr
2022-02-23 10:47:49 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@665b0716, messages=[], arguments=[--bootstrap-server, my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9092, --max-messages, 100, --topic, my-topic-699442351-1764401160], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-681912537-kafka-clients-dc57c598-92lrr', podNamespace='namespace-21', bootstrapServer='my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9092', topicName='my-topic-699442351-1764401160', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@375c766d}
2022-02-23 10:47:49 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9092:my-topic-699442351-1764401160 from pod my-cluster-681912537-kafka-clients-dc57c598-92lrr
2022-02-23 10:47:49 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-681912537-kafka-clients-dc57c598-92lrr -n namespace-21 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9092 --max-messages 100 --topic my-topic-699442351-1764401160
2022-02-23 10:47:51 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-02-23 10:47:51 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-02-23 10:47:51 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7b360104, messages=[], arguments=[--group-instance-id, instance713488571, --bootstrap-server, my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9092, --max-messages, 100, --topic, my-topic-699442351-1764401160, --group-id, my-consumer-group-1536091454], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-681912537-kafka-clients-dc57c598-92lrr', podNamespace='namespace-21', bootstrapServer='my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9092', topicName='my-topic-699442351-1764401160', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1536091454', consumerInstanceId='instance713488571', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2f0df596}
2022-02-23 10:47:51 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9092#my-topic-699442351-1764401160 from pod my-cluster-681912537-kafka-clients-dc57c598-92lrr
2022-02-23 10:47:51 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-681912537-kafka-clients-dc57c598-92lrr -n namespace-21 -- /opt/kafka/consumer.sh --group-instance-id instance713488571 --bootstrap-server my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9092 --max-messages 100 --topic my-topic-699442351-1764401160 --group-id my-consumer-group-1536091454
2022-02-23 10:47:56 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 10:47:56 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 10:47:56 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:288] Triggering CA cert renewal by adding the annotation
2022-02-23 10:47:56 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:300] Patching secret my-cluster-681912537-clients-ca-cert with strimzi.io/force-renew
2022-02-23 10:47:56 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:309] Wait for kafka to rolling restart ...
2022-02-23 10:47:56 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-681912537-kafka rolling update
2022-02-23 10:49:21 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-681912537-kafka has been successfully rolled
2022-02-23 10:49:21 [ForkJoinPool-1-worker-5] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-681912537-kafka to be ready
2022-02-23 10:49:47 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:322] Checking the certificates have been replaced
2022-02-23 10:49:47 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:336] Checking consumed messages to pod:my-cluster-681912537-kafka-clients-dc57c598-92lrr
2022-02-23 10:49:47 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4759a42c, messages=[], arguments=[--group-instance-id, instance1238342086, --bootstrap-server, my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9092, --max-messages, 100, --topic, my-topic-699442351-1764401160, --group-id, my-consumer-group-489788993], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-681912537-kafka-clients-dc57c598-92lrr', podNamespace='namespace-21', bootstrapServer='my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9092', topicName='my-topic-699442351-1764401160', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-489788993', consumerInstanceId='instance1238342086', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@66217824}
2022-02-23 10:49:47 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9092#my-topic-699442351-1764401160 from pod my-cluster-681912537-kafka-clients-dc57c598-92lrr
2022-02-23 10:49:47 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-681912537-kafka-clients-dc57c598-92lrr -n namespace-21 -- /opt/kafka/consumer.sh --group-instance-id instance1238342086 --bootstrap-server my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9092 --max-messages 100 --topic my-topic-699442351-1764401160 --group-id my-consumer-group-489788993
2022-02-23 10:49:52 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 10:49:52 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 10:49:52 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser bob-my-cluster-681912537 in namespace namespace-21
2022-02-23 10:49:52 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-21
2022-02-23 10:49:52 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: bob-my-cluster-681912537 will have desired state: Ready
2022-02-23 10:49:53 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:405] KafkaUser: bob-my-cluster-681912537 is in desired state: Ready
2022-02-23 10:49:53 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-681912537-kafka-clients-tls in namespace namespace-21
2022-02-23 10:49:53 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-21
2022-02-23 10:49:53 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-681912537-kafka-clients-tls will be ready
2022-02-23 10:49:55 [ForkJoinPool-1-worker-5] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-681912537-kafka-clients-tls is ready
2022-02-23 10:49:55 [ForkJoinPool-1-worker-5] [32mINFO [m [SecurityST:360] Checking consumed messages to pod:my-cluster-681912537-kafka-clients-tls-6f754b5999-7f7tt
2022-02-23 10:49:55 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@a056524, messages=[], arguments=[--group-instance-id, instance2125504499, USER=bob_my_cluster_681912537, --bootstrap-server, my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9093, --max-messages, 100, --topic, my-topic-699442351-1764401160, --group-id, my-consumer-group-1921189769], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-681912537-kafka-clients-tls-6f754b5999-7f7tt', podNamespace='namespace-21', bootstrapServer='my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9093', topicName='my-topic-699442351-1764401160', maxMessages=100, kafkaUsername='bob-my-cluster-681912537', consumerGroupName='my-consumer-group-1921189769', consumerInstanceId='instance2125504499', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6708c1b9}
2022-02-23 10:49:55 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9093#my-topic-699442351-1764401160 from pod my-cluster-681912537-kafka-clients-tls-6f754b5999-7f7tt
2022-02-23 10:49:55 [ForkJoinPool-1-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-681912537-kafka-clients-tls-6f754b5999-7f7tt -n namespace-21 -- /opt/kafka/consumer.sh --group-instance-id instance2125504499 USER=bob_my_cluster_681912537 --bootstrap-server my-cluster-681912537-kafka-bootstrap.namespace-21.svc:9093 --max-messages 100 --topic my-topic-699442351-1764401160 --group-id my-consumer-group-1921189769
2022-02-23 10:50:02 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 10:50:02 [ForkJoinPool-1-worker-5] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 10:50:02 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 10:50:02 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:309] Delete all resources for testAutoRenewClientsCaCertsTriggeredByAnno
2022-02-23 10:50:02 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-681912537-kafka-clients in namespace namespace-21
2022-02-23 10:51:32 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-681912537-kafka-clients-tls in namespace namespace-21
2022-02-23 10:51:32 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaUser bob-my-cluster-681912537 in namespace namespace-21
2022-02-23 10:51:42 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-1247307101-1376868286 in namespace namespace-21
2022-02-23 10:51:52 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-699442351-1764401160 in namespace namespace-21
2022-02-23 10:52:02 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-681912537 in namespace namespace-21
2022-02-23 10:52:02 [ForkJoinPool-1-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-21, for cruise control Kafka cluster my-cluster-681912537
2022-02-23 10:52:12 [ForkJoinPool-1-worker-3] [1;31mERROR[m [TestExecutionWatcher:28] SecurityST - Exception Timeout after 300000 ms waiting for Deployment my-cluster-1160923759-cruise-control rolling update in namespace:namespace-18 has been thrown in @Test. Going to collect logs from components.
2022-02-23 10:52:12 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-02-23 10:52:12 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-02-23 10:52:12 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-02-23 10:52:12 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 10:52:12 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-21 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-02-23 10:52:14 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-02-23 10:52:14 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-02-23 10:52:14 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-02-23 10:52:14 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-02-23 10:52:14 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 10:52:14 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:252] Collecting events in Namespace namespace-18
2022-02-23 10:52:14 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace namespace-18
2022-02-23 10:52:14 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace namespace-18
2022-02-23 10:52:16 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace namespace-18
2022-02-23 10:52:16 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace namespace-18
2022-02-23 10:52:16 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace namespace-18
2022-02-23 10:52:16 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace namespace-18
2022-02-23 10:52:16 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 10:52:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:252] Collecting events in Namespace security-st
2022-02-23 10:52:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace security-st
2022-02-23 10:52:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace security-st
2022-02-23 10:52:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace security-st
2022-02-23 10:52:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace security-st
2022-02-23 10:52:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace security-st
2022-02-23 10:52:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace security-st
2022-02-23 10:52:17 [ForkJoinPool-1-worker-3] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 10:52:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 10:52:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:309] Delete all resources for testAutoReplaceAllCaKeysTriggeredByAnno
2022-02-23 10:52:17 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-976787697-86257790 in namespace namespace-18
2022-02-23 10:52:27 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-1160923759-kafka-clients in namespace namespace-18
2022-02-23 10:52:55 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-FINISHED
2022-02-23 10:52:55 [ForkJoinPool-1-worker-5] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 10:52:55 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-1841206926-255802660 in namespace namespace-18
2022-02-23 10:52:55 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 10:52:55 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-22 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-02-23 10:52:55 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-22
2022-02-23 10:52:55 [ForkJoinPool-1-worker-1] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-22
2022-02-23 10:52:55 [ForkJoinPool-1-worker-1] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-22
2022-02-23 10:52:55 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:601] Creating a cluster
2022-02-23 10:52:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-514544610 in namespace namespace-22
2022-02-23 10:52:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-22
2022-02-23 10:52:55 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-514544610 will have desired state: Ready
2022-02-23 10:53:05 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-1160923759 in namespace namespace-18
2022-02-23 10:53:05 [ForkJoinPool-1-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-18, for cruise control Kafka cluster my-cluster-1160923759
2022-02-23 10:53:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 10:53:15 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-18 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-02-23 10:53:57 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-FINISHED
2022-02-23 10:53:57 [ForkJoinPool-1-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 10:55:57 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-514544610 is in desired state: Ready
2022-02-23 10:55:57 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-1631826299-1047352721 in namespace namespace-22
2022-02-23 10:55:57 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-22
2022-02-23 10:55:57 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-1631826299-1047352721 will have desired state: Ready
2022-02-23 10:55:58 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-1631826299-1047352721 is in desired state: Ready
2022-02-23 10:55:58 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-1980954973-807121685 in namespace namespace-22
2022-02-23 10:55:58 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-22
2022-02-23 10:55:58 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-1980954973-807121685 will have desired state: Ready
2022-02-23 10:55:59 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-1980954973-807121685 is in desired state: Ready
2022-02-23 10:55:59 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-514544610-kafka-clients in namespace namespace-22
2022-02-23 10:55:59 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-22
2022-02-23 10:55:59 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-514544610-kafka-clients will be ready
2022-02-23 10:56:00 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-514544610-kafka-clients is ready
2022-02-23 10:56:00 [ForkJoinPool-1-worker-1] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 10:56:00 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:467] Checking produced and consumed messages to pod:my-cluster-514544610-kafka-clients-9dd5488d6-xprrw
2022-02-23 10:56:00 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5e9ca839, messages=[], arguments=[--bootstrap-server, my-cluster-514544610-kafka-bootstrap.namespace-22.svc:9092, --max-messages, 100, --topic, my-topic-1980954973-807121685], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-514544610-kafka-clients-9dd5488d6-xprrw', podNamespace='namespace-22', bootstrapServer='my-cluster-514544610-kafka-bootstrap.namespace-22.svc:9092', topicName='my-topic-1980954973-807121685', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@188f5c5c}
2022-02-23 10:56:00 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-514544610-kafka-bootstrap.namespace-22.svc:9092:my-topic-1980954973-807121685 from pod my-cluster-514544610-kafka-clients-9dd5488d6-xprrw
2022-02-23 10:56:00 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-514544610-kafka-clients-9dd5488d6-xprrw -n namespace-22 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-514544610-kafka-bootstrap.namespace-22.svc:9092 --max-messages 100 --topic my-topic-1980954973-807121685
2022-02-23 10:56:02 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-02-23 10:56:02 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-02-23 10:56:02 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3b35797f, messages=[], arguments=[--group-instance-id, instance824497677, --bootstrap-server, my-cluster-514544610-kafka-bootstrap.namespace-22.svc:9092, --max-messages, 100, --topic, my-topic-1980954973-807121685, --group-id, my-consumer-group-1031080886], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-514544610-kafka-clients-9dd5488d6-xprrw', podNamespace='namespace-22', bootstrapServer='my-cluster-514544610-kafka-bootstrap.namespace-22.svc:9092', topicName='my-topic-1980954973-807121685', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1031080886', consumerInstanceId='instance824497677', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@59bab3a8}
2022-02-23 10:56:02 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-514544610-kafka-bootstrap.namespace-22.svc:9092#my-topic-1980954973-807121685 from pod my-cluster-514544610-kafka-clients-9dd5488d6-xprrw
2022-02-23 10:56:02 [ForkJoinPool-1-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-514544610-kafka-clients-9dd5488d6-xprrw -n namespace-22 -- /opt/kafka/consumer.sh --group-instance-id instance824497677 --bootstrap-server my-cluster-514544610-kafka-bootstrap.namespace-22.svc:9092 --max-messages 100 --topic my-topic-1980954973-807121685 --group-id my-consumer-group-1031080886
2022-02-23 10:56:07 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 10:56:07 [ForkJoinPool-1-worker-1] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 10:56:07 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:481] Triggering CA cert renewal by adding the annotation
2022-02-23 10:56:07 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:493] Patching secret my-cluster-514544610-cluster-ca with strimzi.io/force-replace
2022-02-23 10:56:07 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:498] Wait for zk to rolling restart (1)...
2022-02-23 10:56:07 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-514544610-zookeeper rolling update
2022-02-23 10:57:37 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-514544610-zookeeper has been successfully rolled
2022-02-23 10:57:37 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:503] Wait for kafka to rolling restart (1)...
2022-02-23 10:57:37 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-514544610-kafka rolling update
2022-02-23 10:59:17 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-514544610-kafka has been successfully rolled
2022-02-23 10:59:17 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:508] Wait for EO to rolling restart (1)...
2022-02-23 10:59:17 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-514544610-entity-operator rolling update
2022-02-23 10:59:47 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-514544610-entity-operator will be ready
2022-02-23 11:03:18 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-514544610-entity-operator is ready
2022-02-23 11:03:28 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-514544610-entity-operator rolling update finished
2022-02-23 11:03:28 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:513] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-02-23 11:03:28 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-514544610-kafka-exporter rolling update
2022-02-23 11:03:28 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-514544610-kafka-exporter will be ready
2022-02-23 11:03:49 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-514544610-kafka-exporter is ready
2022-02-23 11:03:59 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-514544610-kafka-exporter rolling update finished
2022-02-23 11:03:59 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-514544610-cruise-control rolling update
2022-02-23 11:04:09 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-514544610-cruise-control will be ready
2022-02-23 11:04:13 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-514544610-cruise-control is ready
2022-02-23 11:04:23 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-514544610-cruise-control rolling update finished
2022-02-23 11:04:23 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:519] Wait for zk to rolling restart (2)...
2022-02-23 11:04:23 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-514544610-zookeeper rolling update
2022-02-23 11:05:38 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-514544610-zookeeper has been successfully rolled
2022-02-23 11:05:38 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-514544610-zookeeper to be ready
2022-02-23 11:06:03 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:524] Wait for kafka to rolling restart (2)...
2022-02-23 11:06:03 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-514544610-kafka rolling update
2022-02-23 11:07:08 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-514544610-kafka has been successfully rolled
2022-02-23 11:07:08 [ForkJoinPool-1-worker-1] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-514544610-kafka to be ready
2022-02-23 11:07:33 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:529] Wait for EO to rolling restart (2)...
2022-02-23 11:07:33 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-514544610-entity-operator rolling update
2022-02-23 11:07:38 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-514544610-entity-operator will be ready
2022-02-23 11:13:12 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-514544610-entity-operator is ready
2022-02-23 11:13:22 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-514544610-entity-operator rolling update finished
2022-02-23 11:13:22 [ForkJoinPool-1-worker-1] [32mINFO [m [SecurityST:534] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-02-23 11:13:22 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-514544610-kafka-exporter rolling update
2022-02-23 11:13:53 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-514544610-kafka-exporter will be ready
2022-02-23 11:13:53 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-514544610-kafka-exporter is ready
2022-02-23 11:14:03 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-514544610-kafka-exporter rolling update finished
2022-02-23 11:14:03 [ForkJoinPool-1-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-514544610-cruise-control rolling update
2022-02-23 11:19:03 [ForkJoinPool-1-worker-1] [1;31mERROR[m [TestExecutionWatcher:28] SecurityST - Exception Timeout after 300000 ms waiting for Deployment my-cluster-514544610-cruise-control rolling update in namespace:namespace-22 has been thrown in @Test. Going to collect logs from components.
2022-02-23 11:19:03 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-02-23 11:19:03 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-02-23 11:19:03 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-02-23 11:19:05 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-02-23 11:19:05 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-02-23 11:19:05 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-02-23 11:19:05 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-02-23 11:19:05 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 11:19:05 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:252] Collecting events in Namespace namespace-22
2022-02-23 11:19:05 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace namespace-22
2022-02-23 11:19:05 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace namespace-22
2022-02-23 11:19:07 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace namespace-22
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace namespace-22
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace namespace-22
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace namespace-22
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:252] Collecting events in Namespace security-st
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace security-st
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace security-st
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace security-st
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace security-st
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace security-st
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace security-st
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:309] Delete all resources for testAutoReplaceClusterCaKeysTriggeredByAnno
2022-02-23 11:19:08 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-1980954973-807121685 in namespace namespace-22
2022-02-23 11:19:08 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-1631826299-1047352721 in namespace namespace-22
2022-02-23 11:19:18 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-514544610-kafka-clients in namespace namespace-22
2022-02-23 11:19:18 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-514544610 in namespace namespace-22
2022-02-23 11:19:18 [ForkJoinPool-1-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-22, for cruise control Kafka cluster my-cluster-514544610
2022-02-23 11:20:08 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 11:20:08 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-22 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-02-23 11:20:15 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-FINISHED
2022-02-23 11:20:15 [ForkJoinPool-1-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 11:20:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 11:20:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:307] In context SecurityST is everything deleted.
2022-02-23 11:20:15 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
[[1;31mERROR[m] Tests run: 23, Failures: 0, Errors: 3, Skipped: 0, Time elapsed: 10,106.06 s <<< FAILURE! - in io.strimzi.systemtest.security.SecurityST
[[1;31mERROR[m] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew(ExtensionContext)  Time elapsed: 757.172 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 300000 ms waiting for Deployment my-cluster-1913101644-entity-operator rolling update in namespace:namespace-6
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils.waitTillDepHasRolled(DeploymentUtils.java:137)
	at io.strimzi.systemtest.security.SecurityST.checkClientsCACertRenew(SecurityST.java:1679)
	at io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew(SecurityST.java:1619)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:688)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:210)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:206)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:65)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:396)
	at java.base/java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:721)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.joinConcurrentTasksInReverseOrderToEnableWorkStealing(ForkJoinPoolHierarchicalTestExecutorService.java:162)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.invokeAll(ForkJoinPoolHierarchicalTestExecutorService.java:136)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.invokeAll(ForkJoinPoolHierarchicalTestExecutorService.java:129)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)

[[1;31mERROR[m] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno(ExtensionContext)  Time elapsed: 2,582.846 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 300000 ms waiting for Deployment my-cluster-1160923759-cruise-control rolling update in namespace:namespace-18
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils.waitTillDepHasRolled(DeploymentUtils.java:137)
	at io.strimzi.systemtest.security.SecurityST.autoReplaceSomeKeysTriggeredByAnno(SecurityST.java:536)
	at io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno(SecurityST.java:413)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:688)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:210)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:206)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:65)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:396)
	at java.base/java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:721)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.joinConcurrentTasksInReverseOrderToEnableWorkStealing(ForkJoinPoolHierarchicalTestExecutorService.java:162)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.invokeAll(ForkJoinPoolHierarchicalTestExecutorService.java:136)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.invokeAll(ForkJoinPoolHierarchicalTestExecutorService.java:129)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)

[[1;31mERROR[m] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(ExtensionContext)  Time elapsed: 2,199.393 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 300000 ms waiting for Deployment my-cluster-514544610-cruise-control rolling update in namespace:namespace-22
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils.waitTillDepHasRolled(DeploymentUtils.java:137)
	at io.strimzi.systemtest.security.SecurityST.autoReplaceSomeKeysTriggeredByAnno(SecurityST.java:536)
	at io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(SecurityST.java:387)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:688)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:210)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:206)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:65)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)

2022-02-23 11:20:20 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:586] ============================================================================
2022-02-23 11:20:20 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:587] Un-installing cluster operator from infra-namespace namespace
2022-02-23 11:20:20 [ForkJoinPool-1-worker-3] [32mINFO [m [SetupClusterOperator:588] ============================================================================
2022-02-23 11:20:20 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 11:20:20 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:309] Delete all resources for JUnit Jupiter
2022-02-23 11:20:20 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-02-23 11:20:20 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-02-23 11:20:20 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-02-23 11:20:20 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-02-23 11:20:20 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-02-23 11:20:30 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-02-23 11:20:30 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-02-23 11:20:40 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-02-23 11:20:40 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-02-23 11:20:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-02-23 11:20:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-23 11:20:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-02-23 11:20:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-02-23 11:20:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-02-23 11:20:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-02-23 11:20:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-02-23 11:20:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-02-23 11:20:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-02-23 11:20:50 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-02-23 11:20:50 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-02-23 11:20:50 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-02-23 11:20:50 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-23 11:20:51 [ForkJoinPool-1-worker-5] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-02-23 11:21:00 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-02-23 11:21:01 [ForkJoinPool-1-worker-1] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-02-23 11:21:01 [ForkJoinPool-1-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.SecurityST
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-02-23 11:21:11 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.security.SecurityST
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [SetupClusterOperator:195] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@3e089db2
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [SetupClusterOperator:252] Install ClusterOperator via Yaml bundle
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-02-23 11:21:11 [ForkJoinPool-2-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-02-23 11:21:31 [ForkJoinPool-2-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-02-23 11:21:31 [ForkJoinPool-2-worker-3] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-02-23 11:21:41 [ForkJoinPool-2-worker-3] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-02-23 11:21:41 [ForkJoinPool-2-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: security-st
2022-02-23 11:21:42 [ForkJoinPool-2-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: security-st
2022-02-23 11:21:42 [ForkJoinPool-2-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: security-st
2022-02-23 11:21:42 [ForkJoinPool-2-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 11:21:42 [ForkJoinPool-2-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-STARTED
2022-02-23 11:21:42 [ForkJoinPool-2-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 11:21:42 [ForkJoinPool-2-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-STARTED
2022-02-23 11:21:42 [ForkJoinPool-2-worker-3] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 11:21:42 [ForkJoinPool-2-worker-3] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-23 for test case:testClientsCACertRenew
2022-02-23 11:21:42 [ForkJoinPool-2-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-23
2022-02-23 11:21:42 [ForkJoinPool-2-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-23
2022-02-23 11:21:42 [ForkJoinPool-2-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-23
2022-02-23 11:21:42 [ForkJoinPool-2-worker-1] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 11:21:42 [ForkJoinPool-2-worker-1] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-24 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-02-23 11:21:42 [ForkJoinPool-2-worker-1] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-24
2022-02-23 11:21:42 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-1818413275 in namespace namespace-23
2022-02-23 11:21:42 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-23
2022-02-23 11:21:42 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-1818413275 will have desired state: Ready
2022-02-23 11:21:42 [ForkJoinPool-2-worker-1] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-24
2022-02-23 11:21:42 [ForkJoinPool-2-worker-1] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-24
2022-02-23 11:21:42 [ForkJoinPool-2-worker-1] [32mINFO [m [SecurityST:601] Creating a cluster
2022-02-23 11:21:42 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-34554368 in namespace namespace-24
2022-02-23 11:21:42 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-24
2022-02-23 11:21:42 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-34554368 will have desired state: Ready
2022-02-23 11:23:58 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-1818413275 is in desired state: Ready
2022-02-23 11:23:58 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser strimzi-tls-user-952735474 in namespace namespace-24
2022-02-23 11:23:58 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-23
2022-02-23 11:23:58 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: strimzi-tls-user-952735474 will have desired state: Ready
2022-02-23 11:23:59 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:405] KafkaUser: strimzi-tls-user-952735474 is in desired state: Ready
2022-02-23 11:23:59 [ForkJoinPool-2-worker-3] [32mINFO [m [SecurityST:1669] Change of kafka validity and renewal days - reconciliation should start.
2022-02-23 11:23:59 [ForkJoinPool-2-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1818413275-entity-operator rolling update
2022-02-23 11:24:51 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-34554368 is in desired state: Ready
2022-02-23 11:24:51 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-1130542536-1672653485 in namespace namespace-24
2022-02-23 11:24:51 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-24
2022-02-23 11:24:51 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-1130542536-1672653485 will have desired state: Ready
2022-02-23 11:24:52 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-1130542536-1672653485 is in desired state: Ready
2022-02-23 11:24:52 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-54533008-1476564480 in namespace namespace-24
2022-02-23 11:24:52 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-24
2022-02-23 11:24:52 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-54533008-1476564480 will have desired state: Ready
2022-02-23 11:24:53 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-54533008-1476564480 is in desired state: Ready
2022-02-23 11:24:53 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-34554368-kafka-clients in namespace namespace-24
2022-02-23 11:24:53 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-24
2022-02-23 11:24:53 [ForkJoinPool-2-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-34554368-kafka-clients will be ready
2022-02-23 11:24:55 [ForkJoinPool-2-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-34554368-kafka-clients is ready
2022-02-23 11:24:55 [ForkJoinPool-2-worker-1] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 11:24:55 [ForkJoinPool-2-worker-1] [32mINFO [m [SecurityST:467] Checking produced and consumed messages to pod:my-cluster-34554368-kafka-clients-6db8d4948d-ls9dl
2022-02-23 11:24:55 [ForkJoinPool-2-worker-1] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@228ab860, messages=[], arguments=[--bootstrap-server, my-cluster-34554368-kafka-bootstrap.namespace-24.svc:9092, --max-messages, 100, --topic, my-topic-54533008-1476564480], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-34554368-kafka-clients-6db8d4948d-ls9dl', podNamespace='namespace-24', bootstrapServer='my-cluster-34554368-kafka-bootstrap.namespace-24.svc:9092', topicName='my-topic-54533008-1476564480', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@78ac955c}
2022-02-23 11:24:55 [ForkJoinPool-2-worker-1] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-34554368-kafka-bootstrap.namespace-24.svc:9092:my-topic-54533008-1476564480 from pod my-cluster-34554368-kafka-clients-6db8d4948d-ls9dl
2022-02-23 11:24:55 [ForkJoinPool-2-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-34554368-kafka-clients-6db8d4948d-ls9dl -n namespace-24 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-34554368-kafka-bootstrap.namespace-24.svc:9092 --max-messages 100 --topic my-topic-54533008-1476564480
2022-02-23 11:24:57 [ForkJoinPool-2-worker-1] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-02-23 11:24:57 [ForkJoinPool-2-worker-1] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-02-23 11:24:57 [ForkJoinPool-2-worker-1] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@b8f33eb, messages=[], arguments=[--group-instance-id, instance993295734, --bootstrap-server, my-cluster-34554368-kafka-bootstrap.namespace-24.svc:9092, --max-messages, 100, --topic, my-topic-54533008-1476564480, --group-id, my-consumer-group-810094491], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-34554368-kafka-clients-6db8d4948d-ls9dl', podNamespace='namespace-24', bootstrapServer='my-cluster-34554368-kafka-bootstrap.namespace-24.svc:9092', topicName='my-topic-54533008-1476564480', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-810094491', consumerInstanceId='instance993295734', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@17154220}
2022-02-23 11:24:57 [ForkJoinPool-2-worker-1] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-34554368-kafka-bootstrap.namespace-24.svc:9092#my-topic-54533008-1476564480 from pod my-cluster-34554368-kafka-clients-6db8d4948d-ls9dl
2022-02-23 11:24:57 [ForkJoinPool-2-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-34554368-kafka-clients-6db8d4948d-ls9dl -n namespace-24 -- /opt/kafka/consumer.sh --group-instance-id instance993295734 --bootstrap-server my-cluster-34554368-kafka-bootstrap.namespace-24.svc:9092 --max-messages 100 --topic my-topic-54533008-1476564480 --group-id my-consumer-group-810094491
2022-02-23 11:25:02 [ForkJoinPool-2-worker-1] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 11:25:02 [ForkJoinPool-2-worker-1] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 11:25:02 [ForkJoinPool-2-worker-1] [32mINFO [m [SecurityST:481] Triggering CA cert renewal by adding the annotation
2022-02-23 11:25:02 [ForkJoinPool-2-worker-1] [32mINFO [m [SecurityST:493] Patching secret my-cluster-34554368-cluster-ca with strimzi.io/force-replace
2022-02-23 11:25:02 [ForkJoinPool-2-worker-1] [32mINFO [m [SecurityST:493] Patching secret my-cluster-34554368-clients-ca with strimzi.io/force-replace
2022-02-23 11:25:02 [ForkJoinPool-2-worker-1] [32mINFO [m [SecurityST:498] Wait for zk to rolling restart (1)...
2022-02-23 11:25:02 [ForkJoinPool-2-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-34554368-zookeeper rolling update
2022-02-23 11:26:38 [ForkJoinPool-2-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-34554368-zookeeper has been successfully rolled
2022-02-23 11:26:38 [ForkJoinPool-2-worker-1] [32mINFO [m [SecurityST:503] Wait for kafka to rolling restart (1)...
2022-02-23 11:26:38 [ForkJoinPool-2-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-34554368-kafka rolling update
2022-02-23 11:26:54 [ForkJoinPool-2-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1818413275-entity-operator will be ready
2022-02-23 11:29:08 [ForkJoinPool-2-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-34554368-kafka has been successfully rolled
2022-02-23 11:29:08 [ForkJoinPool-2-worker-1] [32mINFO [m [SecurityST:508] Wait for EO to rolling restart (1)...
2022-02-23 11:29:08 [ForkJoinPool-2-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-34554368-entity-operator rolling update
2022-02-23 11:30:18 [ForkJoinPool-2-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-34554368-entity-operator will be ready
2022-02-23 11:30:32 [ForkJoinPool-2-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1818413275-entity-operator is ready
2022-02-23 11:30:42 [ForkJoinPool-2-worker-3] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1818413275-entity-operator rolling update finished
2022-02-23 11:30:42 [ForkJoinPool-2-worker-3] [32mINFO [m [SecurityST:1691] Initial ClientsCA cert dates: Wed Feb 23 06:21:43 EST 2022 --> Tue Mar 15 07:21:43 EDT 2022
2022-02-23 11:30:42 [ForkJoinPool-2-worker-3] [32mINFO [m [SecurityST:1692] Changed ClientsCA cert dates: Wed Feb 23 06:23:59 EST 2022 --> Sun Sep 11 07:23:59 EDT 2022
2022-02-23 11:30:42 [ForkJoinPool-2-worker-3] [32mINFO [m [SecurityST:1693] Initial userCert dates: Wed Feb 23 06:23:58 EST 2022 --> Tue Mar 15 07:23:58 EDT 2022
2022-02-23 11:30:42 [ForkJoinPool-2-worker-3] [32mINFO [m [SecurityST:1694] Changed userCert dates: Wed Feb 23 06:26:53 EST 2022 --> Sun Sep 11 07:26:53 EDT 2022
2022-02-23 11:30:42 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 11:30:42 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:309] Delete all resources for testClientsCACertRenew
2022-02-23 11:30:42 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of KafkaUser strimzi-tls-user-952735474 in namespace namespace-23
2022-02-23 11:30:52 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-1818413275 in namespace namespace-23
2022-02-23 11:31:02 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 11:31:02 [ForkJoinPool-2-worker-3] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-23 for test case:testClientsCACertRenew
2022-02-23 11:31:15 [ForkJoinPool-2-worker-5] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 11:31:15 [ForkJoinPool-2-worker-5] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-STARTED
2022-02-23 11:31:20 [ForkJoinPool-2-worker-5] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 11:31:20 [ForkJoinPool-2-worker-5] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-25 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-02-23 11:31:20 [ForkJoinPool-2-worker-5] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-25
2022-02-23 11:31:20 [ForkJoinPool-2-worker-5] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-25
2022-02-23 11:31:20 [ForkJoinPool-2-worker-5] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-25
2022-02-23 11:31:20 [ForkJoinPool-2-worker-5] [32mINFO [m [SecurityST:601] Creating a cluster
2022-02-23 11:31:20 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-923448567 in namespace namespace-25
2022-02-23 11:31:20 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-25
2022-02-23 11:31:20 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-923448567 will have desired state: Ready
2022-02-23 11:31:29 [ForkJoinPool-2-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-FINISHED
2022-02-23 11:31:29 [ForkJoinPool-2-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 11:35:37 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-923448567 is in desired state: Ready
2022-02-23 11:35:37 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-1979537438-794179868 in namespace namespace-25
2022-02-23 11:35:37 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-25
2022-02-23 11:35:37 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-1979537438-794179868 will have desired state: Ready
2022-02-23 11:35:38 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-1979537438-794179868 is in desired state: Ready
2022-02-23 11:35:38 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-636383653-2035928489 in namespace namespace-25
2022-02-23 11:35:38 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-25
2022-02-23 11:35:39 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-636383653-2035928489 will have desired state: Ready
2022-02-23 11:35:40 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-636383653-2035928489 is in desired state: Ready
2022-02-23 11:35:40 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-923448567-kafka-clients in namespace namespace-25
2022-02-23 11:35:40 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-25
2022-02-23 11:35:40 [ForkJoinPool-2-worker-5] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-923448567-kafka-clients will be ready
2022-02-23 11:35:42 [ForkJoinPool-2-worker-5] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-923448567-kafka-clients is ready
2022-02-23 11:35:42 [ForkJoinPool-2-worker-5] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 11:35:42 [ForkJoinPool-2-worker-5] [32mINFO [m [SecurityST:467] Checking produced and consumed messages to pod:my-cluster-923448567-kafka-clients-9f788b854-wmjk8
2022-02-23 11:35:42 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@165bda00, messages=[], arguments=[--bootstrap-server, my-cluster-923448567-kafka-bootstrap.namespace-25.svc:9092, --max-messages, 100, --topic, my-topic-636383653-2035928489], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-923448567-kafka-clients-9f788b854-wmjk8', podNamespace='namespace-25', bootstrapServer='my-cluster-923448567-kafka-bootstrap.namespace-25.svc:9092', topicName='my-topic-636383653-2035928489', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@29d4eb8a}
2022-02-23 11:35:42 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-923448567-kafka-bootstrap.namespace-25.svc:9092:my-topic-636383653-2035928489 from pod my-cluster-923448567-kafka-clients-9f788b854-wmjk8
2022-02-23 11:35:42 [ForkJoinPool-2-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-923448567-kafka-clients-9f788b854-wmjk8 -n namespace-25 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-923448567-kafka-bootstrap.namespace-25.svc:9092 --max-messages 100 --topic my-topic-636383653-2035928489
2022-02-23 11:35:44 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-02-23 11:35:44 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-02-23 11:35:44 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5bf18099, messages=[], arguments=[--group-instance-id, instance818369710, --bootstrap-server, my-cluster-923448567-kafka-bootstrap.namespace-25.svc:9092, --max-messages, 100, --topic, my-topic-636383653-2035928489, --group-id, my-consumer-group-1885560241], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-923448567-kafka-clients-9f788b854-wmjk8', podNamespace='namespace-25', bootstrapServer='my-cluster-923448567-kafka-bootstrap.namespace-25.svc:9092', topicName='my-topic-636383653-2035928489', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1885560241', consumerInstanceId='instance818369710', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@55f7b916}
2022-02-23 11:35:44 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-923448567-kafka-bootstrap.namespace-25.svc:9092#my-topic-636383653-2035928489 from pod my-cluster-923448567-kafka-clients-9f788b854-wmjk8
2022-02-23 11:35:44 [ForkJoinPool-2-worker-5] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-923448567-kafka-clients-9f788b854-wmjk8 -n namespace-25 -- /opt/kafka/consumer.sh --group-instance-id instance818369710 --bootstrap-server my-cluster-923448567-kafka-bootstrap.namespace-25.svc:9092 --max-messages 100 --topic my-topic-636383653-2035928489 --group-id my-consumer-group-1885560241
2022-02-23 11:35:49 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 11:35:49 [ForkJoinPool-2-worker-5] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 11:35:49 [ForkJoinPool-2-worker-5] [32mINFO [m [SecurityST:481] Triggering CA cert renewal by adding the annotation
2022-02-23 11:35:49 [ForkJoinPool-2-worker-5] [32mINFO [m [SecurityST:493] Patching secret my-cluster-923448567-cluster-ca with strimzi.io/force-replace
2022-02-23 11:35:49 [ForkJoinPool-2-worker-5] [32mINFO [m [SecurityST:498] Wait for zk to rolling restart (1)...
2022-02-23 11:35:49 [ForkJoinPool-2-worker-5] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-923448567-zookeeper rolling update
2022-02-23 11:35:51 [ForkJoinPool-2-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-34554368-entity-operator is ready
2022-02-23 11:36:01 [ForkJoinPool-2-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-34554368-entity-operator rolling update finished
2022-02-23 11:36:01 [ForkJoinPool-2-worker-1] [32mINFO [m [SecurityST:513] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-02-23 11:36:01 [ForkJoinPool-2-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-34554368-kafka-exporter rolling update
2022-02-23 11:37:24 [ForkJoinPool-2-worker-5] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-923448567-zookeeper has been successfully rolled
2022-02-23 11:37:24 [ForkJoinPool-2-worker-5] [32mINFO [m [SecurityST:503] Wait for kafka to rolling restart (1)...
2022-02-23 11:37:24 [ForkJoinPool-2-worker-5] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-923448567-kafka rolling update
2022-02-23 11:41:01 [ForkJoinPool-2-worker-1] [1;31mERROR[m [TestExecutionWatcher:28] SecurityST - Exception Timeout after 300000 ms waiting for Deployment my-cluster-34554368-kafka-exporter rolling update in namespace:namespace-24 has been thrown in @Test. Going to collect logs from components.
2022-02-23 11:41:01 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-02-23 11:41:01 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-02-23 11:41:01 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-02-23 11:41:01 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-02-23 11:41:01 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-02-23 11:41:01 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-02-23 11:41:01 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-02-23 11:41:01 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 11:41:01 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:252] Collecting events in Namespace security-st
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace security-st
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace security-st
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace security-st
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace security-st
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace security-st
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace security-st
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:252] Collecting events in Namespace namespace-24
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace namespace-24
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace namespace-24
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [33mWARN [m [LogCollector:247] Searching for logs in all pods failed! Some of the logs will not be stored. Exception messageFailure executing: GET at: https://192.168.49.2:8443/api/v1/namespaces/namespace-24/pods/my-cluster-34554368-entity-operator-5b799f8d65-8klwc/log?pretty=false&container=tls-sidecar. Message: container "tls-sidecar" in pod "my-cluster-34554368-entity-operator-5b799f8d65-8klwc" is terminated. Received status: Status(apiVersion=v1, code=400, details=null, kind=Status, message=container "tls-sidecar" in pod "my-cluster-34554368-entity-operator-5b799f8d65-8klwc" is terminated, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=BadRequest, status=Failure, additionalProperties={}).
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace namespace-24
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace namespace-24
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace namespace-24
2022-02-23 11:41:02 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace namespace-24
2022-02-23 11:41:03 [ForkJoinPool-2-worker-1] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 11:41:03 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 11:41:03 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:309] Delete all resources for testAutoReplaceAllCaKeysTriggeredByAnno
2022-02-23 11:41:03 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-54533008-1476564480 in namespace namespace-24
2022-02-23 11:41:13 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-34554368-kafka-clients in namespace namespace-24
2022-02-23 11:41:19 [ForkJoinPool-2-worker-5] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-923448567-kafka has been successfully rolled
2022-02-23 11:41:19 [ForkJoinPool-2-worker-5] [32mINFO [m [SecurityST:508] Wait for EO to rolling restart (1)...
2022-02-23 11:41:19 [ForkJoinPool-2-worker-5] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-923448567-entity-operator rolling update
2022-02-23 11:42:03 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-1130542536-1672653485 in namespace namespace-24
2022-02-23 11:42:13 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-34554368 in namespace namespace-24
2022-02-23 11:42:13 [ForkJoinPool-2-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-24, for cruise control Kafka cluster my-cluster-34554368
2022-02-23 11:42:23 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 11:42:23 [ForkJoinPool-2-worker-1] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-24 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-02-23 11:42:29 [ForkJoinPool-2-worker-5] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-923448567-entity-operator will be ready
2022-02-23 11:42:50 [ForkJoinPool-2-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-FINISHED
2022-02-23 11:42:50 [ForkJoinPool-2-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 11:49:49 [ForkJoinPool-2-worker-5] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-923448567-entity-operator is ready
2022-02-23 11:49:59 [ForkJoinPool-2-worker-5] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-923448567-entity-operator rolling update finished
2022-02-23 11:49:59 [ForkJoinPool-2-worker-5] [32mINFO [m [SecurityST:513] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-02-23 11:49:59 [ForkJoinPool-2-worker-5] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-923448567-kafka-exporter rolling update
2022-02-23 11:53:25 [ForkJoinPool-2-worker-5] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-923448567-kafka-exporter will be ready
2022-02-23 11:53:25 [ForkJoinPool-2-worker-5] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-923448567-kafka-exporter is ready
2022-02-23 11:53:35 [ForkJoinPool-2-worker-5] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-923448567-kafka-exporter rolling update finished
2022-02-23 11:53:35 [ForkJoinPool-2-worker-5] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-923448567-cruise-control rolling update
2022-02-23 11:58:35 [ForkJoinPool-2-worker-5] [1;31mERROR[m [TestExecutionWatcher:28] SecurityST - Exception Timeout after 300000 ms waiting for Deployment my-cluster-923448567-cruise-control rolling update in namespace:namespace-25 has been thrown in @Test. Going to collect logs from components.
2022-02-23 11:58:35 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-02-23 11:58:35 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-02-23 11:58:35 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-02-23 11:58:35 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-02-23 11:58:35 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-02-23 11:58:35 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-02-23 11:58:35 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-02-23 11:58:36 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 11:58:36 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:252] Collecting events in Namespace security-st
2022-02-23 11:58:36 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace security-st
2022-02-23 11:58:36 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace security-st
2022-02-23 11:58:36 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace security-st
2022-02-23 11:58:36 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace security-st
2022-02-23 11:58:36 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace security-st
2022-02-23 11:58:36 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace security-st
2022-02-23 11:58:36 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 11:58:36 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:252] Collecting events in Namespace namespace-25
2022-02-23 11:58:36 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace namespace-25
2022-02-23 11:58:36 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace namespace-25
2022-02-23 11:58:38 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace namespace-25
2022-02-23 11:58:38 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace namespace-25
2022-02-23 11:58:38 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace namespace-25
2022-02-23 11:58:38 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace namespace-25
2022-02-23 11:58:38 [ForkJoinPool-2-worker-5] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-02-23 11:58:38 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 11:58:38 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:309] Delete all resources for testAutoReplaceClusterCaKeysTriggeredByAnno
2022-02-23 11:58:38 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-636383653-2035928489 in namespace namespace-25
2022-02-23 11:58:38 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-1979537438-794179868 in namespace namespace-25
2022-02-23 11:58:48 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-923448567 in namespace namespace-25
2022-02-23 11:58:48 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-923448567-kafka-clients in namespace namespace-25
2022-02-23 11:58:48 [ForkJoinPool-2-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-25, for cruise control Kafka cluster my-cluster-923448567
2022-02-23 11:59:38 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 11:59:38 [ForkJoinPool-2-worker-5] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-25 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-02-23 11:59:45 [ForkJoinPool-2-worker-5] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-FINISHED
2022-02-23 11:59:45 [ForkJoinPool-2-worker-5] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 11:59:45 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 11:59:45 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:307] In context SecurityST is everything deleted.
2022-02-23 11:59:45 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
[[1;31mERROR[m] Tests run: 3, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 2,319.331 s <<< FAILURE! - in io.strimzi.systemtest.security.SecurityST
[[1;31mERROR[m] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno(ExtensionContext)  Time elapsed: 1,268.631 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 300000 ms waiting for Deployment my-cluster-34554368-kafka-exporter rolling update in namespace:namespace-24
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils.waitTillDepHasRolled(DeploymentUtils.java:137)
	at io.strimzi.systemtest.security.SecurityST.autoReplaceSomeKeysTriggeredByAnno(SecurityST.java:514)
	at io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno(SecurityST.java:413)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:688)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:210)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:206)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:65)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)

[[1;31mERROR[m] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(ExtensionContext)  Time elapsed: 1,710.078 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 300000 ms waiting for Deployment my-cluster-923448567-cruise-control rolling update in namespace:namespace-25
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils.waitTillDepHasRolled(DeploymentUtils.java:137)
	at io.strimzi.systemtest.security.SecurityST.autoReplaceSomeKeysTriggeredByAnno(SecurityST.java:515)
	at io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(SecurityST.java:387)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:688)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:210)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:206)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:65)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)

2022-02-23 11:59:50 [ForkJoinPool-2-worker-3] [32mINFO [m [SetupClusterOperator:586] ============================================================================
2022-02-23 11:59:50 [ForkJoinPool-2-worker-3] [32mINFO [m [SetupClusterOperator:587] Un-installing cluster operator from infra-namespace namespace
2022-02-23 11:59:50 [ForkJoinPool-2-worker-3] [32mINFO [m [SetupClusterOperator:588] ============================================================================
2022-02-23 11:59:50 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 11:59:50 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:309] Delete all resources for JUnit Jupiter
2022-02-23 11:59:50 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-02-23 11:59:50 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:00 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-02-23 12:00:00 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-02-23 12:00:00 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:00 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:10 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:10 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:10 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-02-23 12:00:10 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:10 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:20 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-02-23 12:00:20 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-23 12:00:20 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-02-23 12:00:20 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-02-23 12:00:20 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-02-23 12:00:20 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-02-23 12:00:20 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-02-23 12:00:20 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-02-23 12:00:20 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-02-23 12:00:20 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-02-23 12:00:20 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:231] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-02-23 12:00:20 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-23 12:00:20 [ForkJoinPool-2-worker-1] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-02-23 12:00:20 [ForkJoinPool-2-worker-5] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:21 [ForkJoinPool-2-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.SecurityST
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-02-23 12:00:31 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.security.SecurityST
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [SetupClusterOperator:195] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@8f8e118
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [SetupClusterOperator:252] Install ClusterOperator via Yaml bundle
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/cloud-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-02-23 12:00:31 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-02-23 12:01:03 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-02-23 12:01:03 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-02-23 12:01:13 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-02-23 12:01:13 [ForkJoinPool-3-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: security-st
2022-02-23 12:01:13 [ForkJoinPool-3-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: security-st
2022-02-23 12:01:13 [ForkJoinPool-3-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: security-st
2022-02-23 12:01:13 [ForkJoinPool-3-worker-3] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 12:01:13 [ForkJoinPool-3-worker-3] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-STARTED
2022-02-23 12:01:13 [ForkJoinPool-3-worker-1] [32mINFO [m [TestSeparator:23] ############################################################################
2022-02-23 12:01:13 [ForkJoinPool-3-worker-1] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-STARTED
2022-02-23 12:01:13 [ForkJoinPool-3-worker-3] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 12:01:13 [ForkJoinPool-3-worker-3] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-26 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-02-23 12:01:13 [ForkJoinPool-3-worker-3] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-26
2022-02-23 12:01:14 [ForkJoinPool-3-worker-3] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-26
2022-02-23 12:01:14 [ForkJoinPool-3-worker-3] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-26
2022-02-23 12:01:14 [ForkJoinPool-3-worker-1] [32mINFO [m [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-23 12:01:14 [ForkJoinPool-3-worker-1] [32mINFO [m [TestSuiteNamespaceManager:160] Creating namespace:namespace-27 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-02-23 12:01:14 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:601] Creating a cluster
2022-02-23 12:01:14 [ForkJoinPool-3-worker-1] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-27
2022-02-23 12:01:14 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-754624762 in namespace namespace-26
2022-02-23 12:01:14 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-26
2022-02-23 12:01:14 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-754624762 will have desired state: Ready
2022-02-23 12:01:14 [ForkJoinPool-3-worker-1] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-27
2022-02-23 12:01:14 [ForkJoinPool-3-worker-1] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-27
2022-02-23 12:01:14 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:601] Creating a cluster
2022-02-23 12:01:14 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Kafka my-cluster-1370455599 in namespace namespace-27
2022-02-23 12:01:14 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-27
2022-02-23 12:01:14 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:394] Wait for Kafka: my-cluster-1370455599 will have desired state: Ready
2022-02-23 12:04:08 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-1370455599 is in desired state: Ready
2022-02-23 12:04:08 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-360974322-253705524 in namespace namespace-27
2022-02-23 12:04:08 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-27
2022-02-23 12:04:08 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-360974322-253705524 will have desired state: Ready
2022-02-23 12:04:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-360974322-253705524 is in desired state: Ready
2022-02-23 12:04:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-972515317-2129774268 in namespace namespace-27
2022-02-23 12:04:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-27
2022-02-23 12:04:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-972515317-2129774268 will have desired state: Ready
2022-02-23 12:04:10 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-972515317-2129774268 is in desired state: Ready
2022-02-23 12:04:10 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-1370455599-kafka-clients in namespace namespace-27
2022-02-23 12:04:10 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-27
2022-02-23 12:04:10 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1370455599-kafka-clients will be ready
2022-02-23 12:04:12 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1370455599-kafka-clients is ready
2022-02-23 12:04:12 [ForkJoinPool-3-worker-1] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 12:04:12 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:467] Checking produced and consumed messages to pod:my-cluster-1370455599-kafka-clients-5d4897c87b-v977w
2022-02-23 12:04:12 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@35935b3f, messages=[], arguments=[--bootstrap-server, my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092, --max-messages, 100, --topic, my-topic-972515317-2129774268], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1370455599-kafka-clients-5d4897c87b-v977w', podNamespace='namespace-27', bootstrapServer='my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092', topicName='my-topic-972515317-2129774268', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6ca5e7be}
2022-02-23 12:04:12 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092:my-topic-972515317-2129774268 from pod my-cluster-1370455599-kafka-clients-5d4897c87b-v977w
2022-02-23 12:04:12 [ForkJoinPool-3-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1370455599-kafka-clients-5d4897c87b-v977w -n namespace-27 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092 --max-messages 100 --topic my-topic-972515317-2129774268
2022-02-23 12:04:14 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-02-23 12:04:14 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-02-23 12:04:14 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3f707d22, messages=[], arguments=[--group-instance-id, instance1233024309, --bootstrap-server, my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092, --max-messages, 100, --topic, my-topic-972515317-2129774268, --group-id, my-consumer-group-1392700605], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1370455599-kafka-clients-5d4897c87b-v977w', podNamespace='namespace-27', bootstrapServer='my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092', topicName='my-topic-972515317-2129774268', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1392700605', consumerInstanceId='instance1233024309', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7cabed1e}
2022-02-23 12:04:14 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092#my-topic-972515317-2129774268 from pod my-cluster-1370455599-kafka-clients-5d4897c87b-v977w
2022-02-23 12:04:14 [ForkJoinPool-3-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1370455599-kafka-clients-5d4897c87b-v977w -n namespace-27 -- /opt/kafka/consumer.sh --group-instance-id instance1233024309 --bootstrap-server my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092 --max-messages 100 --topic my-topic-972515317-2129774268 --group-id my-consumer-group-1392700605
2022-02-23 12:04:19 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 12:04:19 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 12:04:19 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:481] Triggering CA cert renewal by adding the annotation
2022-02-23 12:04:19 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:493] Patching secret my-cluster-1370455599-cluster-ca with strimzi.io/force-replace
2022-02-23 12:04:19 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:493] Patching secret my-cluster-1370455599-clients-ca with strimzi.io/force-replace
2022-02-23 12:04:19 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:498] Wait for zk to rolling restart (1)...
2022-02-23 12:04:19 [ForkJoinPool-3-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1370455599-zookeeper rolling update
2022-02-23 12:04:30 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:405] Kafka: my-cluster-754624762 is in desired state: Ready
2022-02-23 12:04:30 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-1329411376-509991165 in namespace namespace-27
2022-02-23 12:04:30 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-26
2022-02-23 12:04:30 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-1329411376-509991165 will have desired state: Ready
2022-02-23 12:04:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-1329411376-509991165 is in desired state: Ready
2022-02-23 12:04:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update KafkaTopic my-topic-122046240-1432983013 in namespace namespace-27
2022-02-23 12:04:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-26
2022-02-23 12:04:31 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:394] Wait for KafkaTopic: my-topic-122046240-1432983013 will have desired state: Ready
2022-02-23 12:04:32 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:405] KafkaTopic: my-topic-122046240-1432983013 is in desired state: Ready
2022-02-23 12:04:32 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-754624762-kafka-clients in namespace namespace-27
2022-02-23 12:04:32 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-26
2022-02-23 12:04:32 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-754624762-kafka-clients will be ready
2022-02-23 12:04:34 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-754624762-kafka-clients is ready
2022-02-23 12:04:34 [ForkJoinPool-3-worker-3] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-23 12:04:34 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:467] Checking produced and consumed messages to pod:my-cluster-754624762-kafka-clients-dd79f8d7b-f5mm6
2022-02-23 12:04:34 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2a0378b4, messages=[], arguments=[--bootstrap-server, my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092, --max-messages, 100, --topic, my-topic-122046240-1432983013], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-754624762-kafka-clients-dd79f8d7b-f5mm6', podNamespace='namespace-26', bootstrapServer='my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092', topicName='my-topic-122046240-1432983013', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@46a0f3b4}
2022-02-23 12:04:34 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092:my-topic-122046240-1432983013 from pod my-cluster-754624762-kafka-clients-dd79f8d7b-f5mm6
2022-02-23 12:04:34 [ForkJoinPool-3-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-754624762-kafka-clients-dd79f8d7b-f5mm6 -n namespace-26 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092 --max-messages 100 --topic my-topic-122046240-1432983013
2022-02-23 12:04:36 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-02-23 12:04:36 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-02-23 12:04:36 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3d6f93, messages=[], arguments=[--group-instance-id, instance1303522098, --bootstrap-server, my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092, --max-messages, 100, --topic, my-topic-122046240-1432983013, --group-id, my-consumer-group-536201722], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-754624762-kafka-clients-dd79f8d7b-f5mm6', podNamespace='namespace-26', bootstrapServer='my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092', topicName='my-topic-122046240-1432983013', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-536201722', consumerInstanceId='instance1303522098', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6af53888}
2022-02-23 12:04:36 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092#my-topic-122046240-1432983013 from pod my-cluster-754624762-kafka-clients-dd79f8d7b-f5mm6
2022-02-23 12:04:36 [ForkJoinPool-3-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-754624762-kafka-clients-dd79f8d7b-f5mm6 -n namespace-26 -- /opt/kafka/consumer.sh --group-instance-id instance1303522098 --bootstrap-server my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092 --max-messages 100 --topic my-topic-122046240-1432983013 --group-id my-consumer-group-536201722
2022-02-23 12:04:41 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 12:04:41 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 12:04:41 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:481] Triggering CA cert renewal by adding the annotation
2022-02-23 12:04:41 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:493] Patching secret my-cluster-754624762-cluster-ca with strimzi.io/force-replace
2022-02-23 12:04:41 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:498] Wait for zk to rolling restart (1)...
2022-02-23 12:04:41 [ForkJoinPool-3-worker-3] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-754624762-zookeeper rolling update
2022-02-23 12:05:59 [ForkJoinPool-3-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1370455599-zookeeper has been successfully rolled
2022-02-23 12:05:59 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:503] Wait for kafka to rolling restart (1)...
2022-02-23 12:05:59 [ForkJoinPool-3-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1370455599-kafka rolling update
2022-02-23 12:06:26 [ForkJoinPool-3-worker-3] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-754624762-zookeeper has been successfully rolled
2022-02-23 12:06:26 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:503] Wait for kafka to rolling restart (1)...
2022-02-23 12:06:26 [ForkJoinPool-3-worker-3] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-754624762-kafka rolling update
2022-02-23 12:07:29 [ForkJoinPool-3-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1370455599-kafka has been successfully rolled
2022-02-23 12:07:29 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:508] Wait for EO to rolling restart (1)...
2022-02-23 12:07:29 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1370455599-entity-operator rolling update
2022-02-23 12:08:20 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1370455599-entity-operator will be ready
2022-02-23 12:08:51 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1370455599-entity-operator is ready
2022-02-23 12:09:01 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1370455599-entity-operator rolling update finished
2022-02-23 12:09:01 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:513] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-02-23 12:09:01 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1370455599-kafka-exporter rolling update
2022-02-23 12:09:01 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1370455599-kafka-exporter will be ready
2022-02-23 12:09:27 [ForkJoinPool-3-worker-3] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-754624762-kafka has been successfully rolled
2022-02-23 12:09:27 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:508] Wait for EO to rolling restart (1)...
2022-02-23 12:09:27 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-754624762-entity-operator rolling update
2022-02-23 12:09:33 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1370455599-kafka-exporter is ready
2022-02-23 12:09:43 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1370455599-kafka-exporter rolling update finished
2022-02-23 12:09:43 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1370455599-cruise-control rolling update
2022-02-23 12:09:48 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1370455599-cruise-control will be ready
2022-02-23 12:09:51 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1370455599-cruise-control is ready
2022-02-23 12:10:01 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1370455599-cruise-control rolling update finished
2022-02-23 12:10:01 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:519] Wait for zk to rolling restart (2)...
2022-02-23 12:10:01 [ForkJoinPool-3-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1370455599-zookeeper rolling update
2022-02-23 12:10:32 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-754624762-entity-operator will be ready
2022-02-23 12:10:56 [ForkJoinPool-3-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1370455599-zookeeper has been successfully rolled
2022-02-23 12:10:56 [ForkJoinPool-3-worker-1] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-1370455599-zookeeper to be ready
2022-02-23 12:11:21 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:524] Wait for kafka to rolling restart (2)...
2022-02-23 12:11:21 [ForkJoinPool-3-worker-1] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1370455599-kafka rolling update
2022-02-23 12:12:46 [ForkJoinPool-3-worker-1] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1370455599-kafka has been successfully rolled
2022-02-23 12:12:46 [ForkJoinPool-3-worker-1] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-1370455599-kafka to be ready
2022-02-23 12:14:05 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:529] Wait for EO to rolling restart (2)...
2022-02-23 12:14:05 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1370455599-entity-operator rolling update
2022-02-23 12:14:05 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1370455599-entity-operator will be ready
2022-02-23 12:14:15 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-754624762-entity-operator is ready
2022-02-23 12:14:25 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-754624762-entity-operator rolling update finished
2022-02-23 12:14:25 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:513] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-02-23 12:14:25 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-754624762-kafka-exporter rolling update
2022-02-23 12:14:25 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-754624762-kafka-exporter will be ready
2022-02-23 12:14:51 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1370455599-entity-operator is ready
2022-02-23 12:14:52 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-754624762-kafka-exporter is ready
2022-02-23 12:15:01 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1370455599-entity-operator rolling update finished
2022-02-23 12:15:01 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:534] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-02-23 12:15:01 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1370455599-kafka-exporter rolling update
2022-02-23 12:15:03 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-754624762-kafka-exporter rolling update finished
2022-02-23 12:15:03 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-754624762-cruise-control rolling update
2022-02-23 12:15:03 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-754624762-cruise-control will be ready
2022-02-23 12:15:16 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-754624762-cruise-control is ready
2022-02-23 12:15:26 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-754624762-cruise-control rolling update finished
2022-02-23 12:15:26 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:519] Wait for zk to rolling restart (2)...
2022-02-23 12:15:26 [ForkJoinPool-3-worker-3] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-754624762-zookeeper rolling update
2022-02-23 12:15:36 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1370455599-kafka-exporter will be ready
2022-02-23 12:15:36 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1370455599-kafka-exporter is ready
2022-02-23 12:15:46 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1370455599-kafka-exporter rolling update finished
2022-02-23 12:15:46 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-1370455599-cruise-control rolling update
2022-02-23 12:15:46 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1370455599-cruise-control will be ready
2022-02-23 12:15:46 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1370455599-cruise-control is ready
2022-02-23 12:15:56 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-1370455599-cruise-control rolling update finished
2022-02-23 12:15:56 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:539] Checking the certificates have been replaced
2022-02-23 12:15:56 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:550] Checking consumed messages to pod:my-cluster-1370455599-kafka-clients-5d4897c87b-v977w
2022-02-23 12:15:56 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@ec42570, messages=[], arguments=[--group-instance-id, instance912303915, --bootstrap-server, my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092, --max-messages, 100, --topic, my-topic-972515317-2129774268, --group-id, my-consumer-group-168103203], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1370455599-kafka-clients-5d4897c87b-v977w', podNamespace='namespace-27', bootstrapServer='my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092', topicName='my-topic-972515317-2129774268', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-168103203', consumerInstanceId='instance912303915', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1aafc680}
2022-02-23 12:15:56 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092#my-topic-972515317-2129774268 from pod my-cluster-1370455599-kafka-clients-5d4897c87b-v977w
2022-02-23 12:15:56 [ForkJoinPool-3-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1370455599-kafka-clients-5d4897c87b-v977w -n namespace-27 -- /opt/kafka/consumer.sh --group-instance-id instance912303915 --bootstrap-server my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092 --max-messages 100 --topic my-topic-972515317-2129774268 --group-id my-consumer-group-168103203
2022-02-23 12:16:01 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 12:16:01 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 12:16:01 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-629522580-1273533396 in namespace namespace-27
2022-02-23 12:16:01 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-27
2022-02-23 12:16:01 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-629522580-1273533396 will have desired state: Ready
2022-02-23 12:16:02 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-629522580-1273533396 is in desired state: Ready
2022-02-23 12:16:02 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-1370455599-kafka-clients-tls in namespace namespace-27
2022-02-23 12:16:02 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-27
2022-02-23 12:16:02 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1370455599-kafka-clients-tls will be ready
2022-02-23 12:16:03 [ForkJoinPool-3-worker-1] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1370455599-kafka-clients-tls is ready
2022-02-23 12:16:03 [ForkJoinPool-3-worker-1] [32mINFO [m [SecurityST:575] Checking consumed messages to pod:my-cluster-1370455599-kafka-clients-tls-f557ff994-6xpx7
2022-02-23 12:16:03 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@77f8ec16, messages=[], arguments=[--group-instance-id, instance1887595005, --bootstrap-server, my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092, --max-messages, 100, --topic, my-topic-972515317-2129774268, --group-id, my-consumer-group-1386453676], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1370455599-kafka-clients-tls-f557ff994-6xpx7', podNamespace='namespace-27', bootstrapServer='my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092', topicName='my-topic-972515317-2129774268', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1386453676', consumerInstanceId='instance1887595005', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1307b330}
2022-02-23 12:16:03 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092#my-topic-972515317-2129774268 from pod my-cluster-1370455599-kafka-clients-tls-f557ff994-6xpx7
2022-02-23 12:16:03 [ForkJoinPool-3-worker-1] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1370455599-kafka-clients-tls-f557ff994-6xpx7 -n namespace-27 -- /opt/kafka/consumer.sh --group-instance-id instance1887595005 --bootstrap-server my-cluster-1370455599-kafka-bootstrap.namespace-27.svc:9092 --max-messages 100 --topic my-topic-972515317-2129774268 --group-id my-consumer-group-1386453676
2022-02-23 12:16:06 [ForkJoinPool-3-worker-3] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-754624762-zookeeper has been successfully rolled
2022-02-23 12:16:06 [ForkJoinPool-3-worker-3] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-754624762-zookeeper to be ready
2022-02-23 12:16:08 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 12:16:08 [ForkJoinPool-3-worker-1] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 12:16:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 12:16:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:309] Delete all resources for testAutoReplaceAllCaKeysTriggeredByAnno
2022-02-23 12:16:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-1370455599-kafka-clients in namespace namespace-27
2022-02-23 12:16:37 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:524] Wait for kafka to rolling restart (2)...
2022-02-23 12:16:37 [ForkJoinPool-3-worker-3] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-754624762-kafka rolling update
2022-02-23 12:17:29 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-1370455599-kafka-clients-tls in namespace namespace-27
2022-02-23 12:17:29 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-629522580-1273533396 in namespace namespace-27
2022-02-23 12:17:39 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-360974322-253705524 in namespace namespace-27
2022-02-23 12:17:47 [ForkJoinPool-3-worker-3] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-754624762-kafka has been successfully rolled
2022-02-23 12:17:47 [ForkJoinPool-3-worker-3] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-754624762-kafka to be ready
2022-02-23 12:17:49 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-972515317-2129774268 in namespace namespace-27
2022-02-23 12:17:59 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-1370455599 in namespace namespace-27
2022-02-23 12:17:59 [ForkJoinPool-3-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-27, for cruise control Kafka cluster my-cluster-1370455599
2022-02-23 12:18:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 12:18:09 [ForkJoinPool-3-worker-1] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-27 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-02-23 12:18:16 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:529] Wait for EO to rolling restart (2)...
2022-02-23 12:18:16 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-754624762-entity-operator rolling update
2022-02-23 12:18:16 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-754624762-entity-operator will be ready
2022-02-23 12:18:51 [ForkJoinPool-3-worker-1] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-FINISHED
2022-02-23 12:18:51 [ForkJoinPool-3-worker-1] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 12:20:23 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-754624762-entity-operator is ready
2022-02-23 12:20:33 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-754624762-entity-operator rolling update finished
2022-02-23 12:20:34 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:534] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-02-23 12:20:34 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-754624762-kafka-exporter rolling update
2022-02-23 12:21:34 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-754624762-kafka-exporter will be ready
2022-02-23 12:21:34 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-754624762-kafka-exporter is ready
2022-02-23 12:21:44 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-754624762-kafka-exporter rolling update finished
2022-02-23 12:21:44 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-754624762-cruise-control rolling update
2022-02-23 12:21:44 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-754624762-cruise-control will be ready
2022-02-23 12:21:44 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-754624762-cruise-control is ready
2022-02-23 12:21:54 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-754624762-cruise-control rolling update finished
2022-02-23 12:21:54 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:539] Checking the certificates have been replaced
2022-02-23 12:21:54 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:550] Checking consumed messages to pod:my-cluster-754624762-kafka-clients-dd79f8d7b-f5mm6
2022-02-23 12:21:54 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4fa67d84, messages=[], arguments=[--group-instance-id, instance1028322703, --bootstrap-server, my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092, --max-messages, 100, --topic, my-topic-122046240-1432983013, --group-id, my-consumer-group-380629737], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-754624762-kafka-clients-dd79f8d7b-f5mm6', podNamespace='namespace-26', bootstrapServer='my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092', topicName='my-topic-122046240-1432983013', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-380629737', consumerInstanceId='instance1028322703', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6ffaff9a}
2022-02-23 12:21:54 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092#my-topic-122046240-1432983013 from pod my-cluster-754624762-kafka-clients-dd79f8d7b-f5mm6
2022-02-23 12:21:54 [ForkJoinPool-3-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-754624762-kafka-clients-dd79f8d7b-f5mm6 -n namespace-26 -- /opt/kafka/consumer.sh --group-instance-id instance1028322703 --bootstrap-server my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092 --max-messages 100 --topic my-topic-122046240-1432983013 --group-id my-consumer-group-380629737
2022-02-23 12:21:59 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 12:21:59 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 12:21:59 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update KafkaUser my-user-952568245-1537299308 in namespace namespace-27
2022-02-23 12:21:59 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-26
2022-02-23 12:21:59 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:394] Wait for KafkaUser: my-user-952568245-1537299308 will have desired state: Ready
2022-02-23 12:22:00 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:405] KafkaUser: my-user-952568245-1537299308 is in desired state: Ready
2022-02-23 12:22:00 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:152] Create/Update Deployment my-cluster-754624762-kafka-clients-tls in namespace namespace-27
2022-02-23 12:22:00 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:161] Using Namespace: namespace-26
2022-02-23 12:22:00 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-754624762-kafka-clients-tls will be ready
2022-02-23 12:22:02 [ForkJoinPool-3-worker-3] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-754624762-kafka-clients-tls is ready
2022-02-23 12:22:02 [ForkJoinPool-3-worker-3] [32mINFO [m [SecurityST:575] Checking consumed messages to pod:my-cluster-754624762-kafka-clients-tls-7dbb88fd8f-mhcwq
2022-02-23 12:22:02 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@25a1c7f0, messages=[], arguments=[--group-instance-id, instance394349869, --bootstrap-server, my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092, --max-messages, 100, --topic, my-topic-122046240-1432983013, --group-id, my-consumer-group-264507945], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-754624762-kafka-clients-tls-7dbb88fd8f-mhcwq', podNamespace='namespace-26', bootstrapServer='my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092', topicName='my-topic-122046240-1432983013', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-264507945', consumerInstanceId='instance394349869', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1d9fedf6}
2022-02-23 12:22:02 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092#my-topic-122046240-1432983013 from pod my-cluster-754624762-kafka-clients-tls-7dbb88fd8f-mhcwq
2022-02-23 12:22:02 [ForkJoinPool-3-worker-3] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-754624762-kafka-clients-tls-7dbb88fd8f-mhcwq -n namespace-26 -- /opt/kafka/consumer.sh --group-instance-id instance394349869 --bootstrap-server my-cluster-754624762-kafka-bootstrap.namespace-26.svc:9092 --max-messages 100 --topic my-topic-122046240-1432983013 --group-id my-consumer-group-264507945
2022-02-23 12:22:07 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-23 12:22:07 [ForkJoinPool-3-worker-3] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-23 12:22:07 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 12:22:07 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:309] Delete all resources for testAutoReplaceClusterCaKeysTriggeredByAnno
2022-02-23 12:22:07 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-754624762-kafka-clients in namespace namespace-26
2022-02-23 12:22:07 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-1329411376-509991165 in namespace namespace-26
2022-02-23 12:22:17 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of KafkaTopic my-topic-122046240-1432983013 in namespace namespace-26
2022-02-23 12:22:27 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of Kafka my-cluster-754624762 in namespace namespace-26
2022-02-23 12:22:27 [ForkJoinPool-3-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-26, for cruise control Kafka cluster my-cluster-754624762
2022-02-23 12:22:37 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of Deployment my-cluster-754624762-kafka-clients-tls in namespace namespace-26
2022-02-23 12:23:17 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:231] Delete of KafkaUser my-user-952568245-1537299308 in namespace namespace-26
2022-02-23 12:23:27 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 12:23:27 [ForkJoinPool-3-worker-3] [32mINFO [m [TestSuiteNamespaceManager:197] Deleting namespace:namespace-26 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-02-23 12:23:34 [ForkJoinPool-3-worker-3] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-FINISHED
2022-02-23 12:23:34 [ForkJoinPool-3-worker-3] [32mINFO [m [TestSeparator:30] ############################################################################
2022-02-23 12:23:34 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 12:23:34 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:307] In context SecurityST is everything deleted.
2022-02-23 12:23:34 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,388.062 s - in io.strimzi.systemtest.security.SecurityST
2022-02-23 12:23:39 [ForkJoinPool-3-worker-3] [32mINFO [m [SetupClusterOperator:586] ============================================================================
2022-02-23 12:23:39 [ForkJoinPool-3-worker-3] [32mINFO [m [SetupClusterOperator:587] Un-installing cluster operator from infra-namespace namespace
2022-02-23 12:23:39 [ForkJoinPool-3-worker-3] [32mINFO [m [SetupClusterOperator:588] ============================================================================
2022-02-23 12:23:39 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:305] ############################################################################
2022-02-23 12:23:39 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:309] Delete all resources for JUnit Jupiter
2022-02-23 12:23:39 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-02-23 12:23:39 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-02-23 12:23:49 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:231] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-02-23 12:23:49 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-02-23 12:23:49 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-02-23 12:23:49 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-02-23 12:23:59 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-02-23 12:23:59 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-02-23 12:23:59 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-02-23 12:24:09 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-02-23 12:24:09 [ForkJoinPool-3-worker-1] [32mINFO [m [ResourceManager:231] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-02-23 12:24:19 [ForkJoinPool-3-worker-3] [32mINFO [m [ResourceManager:330] ############################################################################
2022-02-23 12:24:45 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-02-23 12:24:45 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-02-23 12:24:45 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-02-23 12:24:45 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-02-23 12:24:45 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;33mWARNING[m] Flakes: 
[[1;33mWARNING[m] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno(ExtensionContext)
[[1;31mERROR[m]   Run 1: SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno:413->autoReplaceSomeKeysTriggeredByAnno:536 ? Wait
[[1;31mERROR[m]   Run 2: SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno:413->autoReplaceSomeKeysTriggeredByAnno:514 ? Wait
[[1;34mINFO[m]   Run 3: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(ExtensionContext)
[[1;31mERROR[m]   Run 1: SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno:387->autoReplaceSomeKeysTriggeredByAnno:536 ? Wait
[[1;31mERROR[m]   Run 2: SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno:387->autoReplaceSomeKeysTriggeredByAnno:515 ? Wait
[[1;34mINFO[m]   Run 3: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew(ExtensionContext)
[[1;31mERROR[m]   Run 1: SecurityST.testClientsCACertRenew:1619->checkClientsCACertRenew:1679 ? Wait Ti...
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;33mWARNING[m] Tests run: 23, Failures: 0, Errors: 0, Skipped: 0, Flakes: 3
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Summary for Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift . [1;32mSUCCESS[m [  2.011 s]
[[1;34mINFO[m] test ............................................... [1;32mSUCCESS[m [  0.798 s]
[[1;34mINFO[m] crd-annotations .................................... [1;32mSUCCESS[m [  0.817 s]
[[1;34mINFO[m] crd-generator ...................................... [1;32mSUCCESS[m [  2.080 s]
[[1;34mINFO[m] api ................................................ [1;32mSUCCESS[m [  5.023 s]
[[1;34mINFO[m] mockkube ........................................... [1;32mSUCCESS[m [  0.756 s]
[[1;34mINFO[m] config-model ....................................... [1;32mSUCCESS[m [  0.587 s]
[[1;34mINFO[m] certificate-manager ................................ [1;32mSUCCESS[m [  0.628 s]
[[1;34mINFO[m] operator-common .................................... [1;32mSUCCESS[m [  1.026 s]
[[1;34mINFO[m] systemtest ......................................... [1;32mSUCCESS[m [  03:52 h]
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1;32mBUILD SUCCESS[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] Total time:  03:53 h
[[1;34mINFO[m] Finished at: 2022-02-23T07:24:45-05:00
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
