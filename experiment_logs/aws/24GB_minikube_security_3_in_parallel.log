[INFO] Scanning for projects...
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building systemtest 0.29.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.1.2:check (validate) @ systemtest ---
[INFO] Starting audit...
Audit done.
[INFO] You have 0 Checkstyle violations.
[INFO] 
[INFO] --- maven-enforcer-plugin:3.0.0-M2:enforce (enforce-banned-dependencies) @ systemtest ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.9:prepare-agent (default) @ systemtest ---
[INFO] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ systemtest ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ systemtest ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ systemtest ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 31 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.1:testCompile (default-testCompile) @ systemtest ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:3.0.0-M5:test (default-test) @ systemtest ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[ERROR] Feb 17, 2022 9:01:32 AM org.junit.platform.launcher.core.LauncherConfigurationParameters loadClasspathResource
[ERROR] INFO: Loading JUnit Platform configuration parameters from classpath resource [file:/home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/target/test-classes/junit-platform.properties].
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[WARNING] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/target/surefire-reports/2022-02-17T09-01-31_376-jvmRun1.dumpstream
[INFO] 
[INFO] --- maven-jar-plugin:3.1.0:jar (default-jar) @ systemtest ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.9:report (report) @ systemtest ---
[INFO] Skipping JaCoCo execution due to missing execution data file.
[INFO] 
[INFO] >>> maven-source-plugin:3.0.1:jar (attach-sources) > generate-sources @ systemtest >>>
[INFO] 
[INFO] --- maven-checkstyle-plugin:3.1.2:check (validate) @ systemtest ---
[INFO] Starting audit...
Audit done.
[INFO] You have 0 Checkstyle violations.
[INFO] 
[INFO] --- maven-enforcer-plugin:3.0.0-M2:enforce (enforce-banned-dependencies) @ systemtest ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.9:prepare-agent (default) @ systemtest ---
[INFO] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/target/jacoco.exec
[INFO] 
[INFO] <<< maven-source-plugin:3.0.1:jar (attach-sources) < generate-sources @ systemtest <<<
[INFO] 
[INFO] 
[INFO] --- maven-source-plugin:3.0.1:jar (attach-sources) @ systemtest ---
[INFO] Building jar: /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/target/systemtest-0.29.0-SNAPSHOT-sources.jar
[INFO] 
[INFO] --- maven-javadoc-plugin:3.1.0:jar (attach-javadocs) @ systemtest ---
[INFO] Skipping javadoc generation
[INFO] 
[INFO] --- maven-failsafe-plugin:3.0.0-M5:integration-test (default) @ systemtest ---
[WARNING] useSystemClassLoader setting has no effect when not forking
[WARNING] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
2022-02-17 09:01:35 [main] INFO  [TestExecutionListener:29] =======================================================================
2022-02-17 09:01:35 [main] INFO  [TestExecutionListener:30] =======================================================================
2022-02-17 09:01:35 [main] INFO  [TestExecutionListener:31]                         Test run started
2022-02-17 09:01:35 [main] INFO  [TestExecutionListener:32] =======================================================================
2022-02-17 09:01:35 [main] INFO  [TestExecutionListener:33] =======================================================================
2022-02-17 09:01:35 [main] INFO  [TestExecutionListener:48] Following testclasses are selected for run:
2022-02-17 09:01:35 [main] INFO  [TestExecutionListener:51] -> io.strimzi.systemtest.security.SecurityST
2022-02-17 09:01:35 [main] INFO  [TestExecutionListener:52] =======================================================================
2022-02-17 09:01:35 [main] INFO  [TestExecutionListener:53] =======================================================================
[INFO] Running io.strimzi.systemtest.security.SecurityST
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:220] Used environment variables:
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:221] CONFIG: /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/config.json
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] STRIMZI_RBAC_SCOPE: CLUSTER
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] OLM_APP_BUNDLE_PREFIX: strimzi-cluster-operator
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] TEST_CLIENTS_VERSION: 0.1.1
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] OLM_SOURCE_NAMESPACE: openshift-marketplace
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] CLUSTER_OPERATOR_INSTALL_TYPE: BUNDLE
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] STRIMZI_COMPONENTS_LOG_LEVEL: INFO
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] SKIP_TEARDOWN: false
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] LB_FINALIZERS: false
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] OLM_OPERATOR_DEPLOYMENT_NAME: strimzi-cluster-operator
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] DOCKER_ORG: strimzi
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] TEST_LOG_DIR: /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/../systemtest/target/logs/
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] COMPONENTS_IMAGE_PULL_POLICY: IfNotPresent
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] DOCKER_REGISTRY: quay.io
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] TEST_CLIENT_IMAGE: quay.io/strimzi/test-client:latest-kafka-3.0.0
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] SYSTEM_TEST_STRIMZI_IMAGE_PULL_SECRET: 
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] TEST_ADMIN_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-admin:0.1.1-kafka-3.0.0
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] TEST_HTTP_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-http-producer:0.1.1
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] OLM_OPERATOR_NAME: strimzi-kafka-operator
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] DOCKER_TAG: latest
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] OLM_SOURCE_NAME: community-operators
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] STRIMZI_FEATURE_GATES: 
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] CLIENTS_KAFKA_VERSION: 3.0.0
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] TEST_HTTP_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-http-consumer:0.1.1
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] STRIMZI_LOG_LEVEL: DEBUG
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] ST_KAFKA_VERSION: 3.1.0
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] OPERATOR_IMAGE_PULL_POLICY: Always
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] DEFAULT_TO_DENY_NETWORK_POLICIES: true
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] TEST_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-producer:0.1.1-kafka-3.0.0
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] BRIDGE_IMAGE: latest-released
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] TEST_STREAMS_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-streams:0.1.1-kafka-3.0.0
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] TEST_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-consumer:0.1.1-kafka-3.0.0
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [Environment:222] OLM_OPERATOR_VERSION: 0.26.1
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [KubeCluster:87] Using cluster: minikube
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:60] Cluster default namespace is 'default'
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [SetupClusterOperator:195] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@177fb53f
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-02-17 09:01:36 [ForkJoinPool-1-worker-3] INFO  [SetupClusterOperator:252] Install ClusterOperator via Yaml bundle
2022-02-17 09:01:37 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-02-17 09:01:37 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-02-17 09:01:37 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-02-17 09:01:37 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-17 09:01:38 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-02-17 09:01:38 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-02-17 09:01:38 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-02-17 09:01:38 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-02-17 09:01:38 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-02-17 09:01:38 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-02-17 09:01:38 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-02-17 09:01:39 [ForkJoinPool-1-worker-3] INFO  [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-02-17 09:01:40 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-02-17 09:01:40 [ForkJoinPool-1-worker-3] INFO  [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-02-17 09:01:40 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-02-17 09:01:40 [ForkJoinPool-1-worker-3] INFO  [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-02-17 09:01:40 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-02-17 09:01:40 [ForkJoinPool-1-worker-3] INFO  [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-02-17 09:01:40 [ForkJoinPool-1-worker-3] INFO  [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-02-17 09:01:40 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-17 09:01:40 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-02-17 09:01:40 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-02-17 09:01:40 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-02-17 09:02:10 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-02-17 09:02:10 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-02-17 09:02:20 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-02-17 09:02:20 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:156] Creating Namespace: security-st
2022-02-17 09:02:20 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:82] Client use Namespace: security-st
2022-02-17 09:02:20 [ForkJoinPool-1-worker-3] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: security-st
2022-02-17 09:02:20 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:02:20 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:02:20 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:02:20 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-STARTED
2022-02-17 09:02:20 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCustomClusterCACertRenew-STARTED
2022-02-17 09:02:20 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-STARTED
2022-02-17 09:02:20 [ForkJoinPool-1-worker-7] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:02:20 [ForkJoinPool-1-worker-7] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-0 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-02-17 09:02:20 [ForkJoinPool-1-worker-7] INFO  [KubeClusterResource:156] Creating Namespace: namespace-0
2022-02-17 09:02:21 [ForkJoinPool-1-worker-7] INFO  [KubeClusterResource:82] Client use Namespace: namespace-0
2022-02-17 09:02:21 [ForkJoinPool-1-worker-7] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-0
2022-02-17 09:02:21 [ForkJoinPool-1-worker-3] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:02:21 [ForkJoinPool-1-worker-3] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-1 for test case:testCustomClusterCACertRenew
2022-02-17 09:02:21 [ForkJoinPool-1-worker-7] INFO  [SecurityST:601] Creating a cluster
2022-02-17 09:02:21 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:156] Creating Namespace: namespace-1
2022-02-17 09:02:21 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:02:21 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAclWithSuperUser-STARTED
2022-02-17 09:02:21 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:82] Client use Namespace: namespace-1
2022-02-17 09:02:21 [ForkJoinPool-1-worker-3] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-1
2022-02-17 09:02:21 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1828] Generating custom RootCA, IntermediateCA, and ClusterCA, ClientsCA for Strimzi and PEM bundles.
2022-02-17 09:02:21 [ForkJoinPool-1-worker-5] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:02:21 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-2 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-02-17 09:02:21 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:156] Creating Namespace: namespace-2
2022-02-17 09:02:21 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:82] Client use Namespace: namespace-2
2022-02-17 09:02:21 [ForkJoinPool-1-worker-5] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-2
2022-02-17 09:02:21 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:70] Creating secret my-cluster-633186695-cluster-ca-cert
2022-02-17 09:02:21 [ForkJoinPool-1-worker-5] INFO  [SecurityST:601] Creating a cluster
2022-02-17 09:02:21 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-633186695 in namespace namespace-2
2022-02-17 09:02:21 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-2
2022-02-17 09:02:21 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-919906473 in namespace namespace-2
2022-02-17 09:02:21 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-0
2022-02-17 09:02:21 [ForkJoinPool-1-worker-5] WARN  [VersionUsageUtils:60] The client is using resource type 'kafkas' with unstable version 'v1beta2'
2022-02-17 09:02:21 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-633186695 will have desired state: Ready
2022-02-17 09:02:21 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-919906473 will have desired state: Ready
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1844] Deploy all certificates and keys as secrets.
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:150] Waiting for Secret: my-cluster-1454039081-cluster-ca-cert to be deleted
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:154] Secret: my-cluster-1454039081-cluster-ca-cert successfully deleted
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:46] Waiting for Secret my-cluster-1454039081-cluster-ca-cert
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:50] Secret my-cluster-1454039081-cluster-ca-cert created
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:150] Waiting for Secret: my-cluster-1454039081-cluster-ca to be deleted
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:154] Secret: my-cluster-1454039081-cluster-ca successfully deleted
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:150] Waiting for Secret: my-cluster-1454039081-clients-ca-cert to be deleted
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:154] Secret: my-cluster-1454039081-clients-ca-cert successfully deleted
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:46] Waiting for Secret my-cluster-1454039081-clients-ca-cert
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:50] Secret my-cluster-1454039081-clients-ca-cert created
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:150] Waiting for Secret: my-cluster-1454039081-clients-ca to be deleted
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:154] Secret: my-cluster-1454039081-clients-ca successfully deleted
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1805] Check ClusterCA and ClientsCA certificates.
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-1454039081 in namespace namespace-2
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-1
2022-02-17 09:02:23 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1454039081 will have desired state: Ready
2022-02-17 09:05:44 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] Kafka: my-cluster-633186695 is in desired state: Ready
2022-02-17 09:05:44 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-88707196-1937328672 in namespace namespace-2
2022-02-17 09:05:44 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-2
2022-02-17 09:05:44 [ForkJoinPool-1-worker-5] WARN  [VersionUsageUtils:60] The client is using resource type 'kafkausers' with unstable version 'v1beta2'
2022-02-17 09:05:44 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-88707196-1937328672 will have desired state: Ready
2022-02-17 09:05:45 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] Kafka: my-cluster-919906473 is in desired state: Ready
2022-02-17 09:05:45 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-586581055-1848286924 in namespace namespace-2
2022-02-17 09:05:45 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-0
2022-02-17 09:05:45 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-586581055-1848286924 will have desired state: Ready
2022-02-17 09:05:45 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:405] Kafka: my-cluster-1454039081 is in desired state: Ready
2022-02-17 09:05:45 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1562] Change of kafka validity and renewal days - reconciliation should start.
2022-02-17 09:05:45 [ForkJoinPool-1-worker-3] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1454039081-kafka rolling update
2022-02-17 09:05:46 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] KafkaUser: my-user-586581055-1848286924 is in desired state: Ready
2022-02-17 09:05:46 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-1525313696-1959445033 in namespace namespace-2
2022-02-17 09:05:46 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-0
2022-02-17 09:05:46 [ForkJoinPool-1-worker-7] WARN  [VersionUsageUtils:60] The client is using resource type 'kafkatopics' with unstable version 'v1beta2'
2022-02-17 09:05:46 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-1525313696-1959445033 will have desired state: Ready
2022-02-17 09:05:46 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] KafkaUser: my-user-88707196-1937328672 is in desired state: Ready
2022-02-17 09:05:46 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-537241926-1559832458 in namespace namespace-2
2022-02-17 09:05:46 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-2
2022-02-17 09:05:46 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-537241926-1559832458 will have desired state: Ready
2022-02-17 09:05:47 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] KafkaTopic: my-topic-1525313696-1959445033 is in desired state: Ready
2022-02-17 09:05:47 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-919906473-kafka-clients in namespace namespace-2
2022-02-17 09:05:47 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-0
2022-02-17 09:05:47 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-919906473-kafka-clients will be ready
2022-02-17 09:05:47 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] KafkaTopic: my-topic-537241926-1559832458 is in desired state: Ready
2022-02-17 09:05:47 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-633186695-kafka-clients in namespace namespace-2
2022-02-17 09:05:47 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-2
2022-02-17 09:05:47 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-633186695-kafka-clients will be ready
2022-02-17 09:06:00 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:168] Deployment: my-cluster-919906473-kafka-clients is ready
2022-02-17 09:06:00 [ForkJoinPool-1-worker-7] INFO  [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-17 09:06:00 [ForkJoinPool-1-worker-7] INFO  [SecurityST:467] Checking produced and consumed messages to pod:my-cluster-919906473-kafka-clients-6cc7749b98-z2jxn
2022-02-17 09:06:00 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@578f90c7, messages=[], arguments=[--bootstrap-server, my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092, --max-messages, 100, --topic, my-topic-1525313696-1959445033], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-919906473-kafka-clients-6cc7749b98-z2jxn', podNamespace='namespace-0', bootstrapServer='my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092', topicName='my-topic-1525313696-1959445033', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@48f78d9a}
2022-02-17 09:06:00 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:94] Producing 100 messages to my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092:my-topic-1525313696-1959445033 from pod my-cluster-919906473-kafka-clients-6cc7749b98-z2jxn
2022-02-17 09:06:00 [ForkJoinPool-1-worker-7] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-919906473-kafka-clients-6cc7749b98-z2jxn -n namespace-0 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092 --max-messages 100 --topic my-topic-1525313696-1959445033
2022-02-17 09:06:00 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:168] Deployment: my-cluster-633186695-kafka-clients is ready
2022-02-17 09:06:00 [ForkJoinPool-1-worker-5] INFO  [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-17 09:06:00 [ForkJoinPool-1-worker-5] INFO  [SecurityST:674] Checking produced and consumed messages to pod:my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2
2022-02-17 09:06:00 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@51716e0c, messages=[], arguments=[--bootstrap-server, my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092, --max-messages, 100, --topic, my-topic-537241926-1559832458], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2', podNamespace='namespace-2', bootstrapServer='my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092', topicName='my-topic-537241926-1559832458', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@2e7c5ae4}
2022-02-17 09:06:00 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:94] Producing 100 messages to my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092:my-topic-537241926-1559832458 from pod my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2
2022-02-17 09:06:00 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2 -n namespace-2 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092 --max-messages 100 --topic my-topic-537241926-1559832458
2022-02-17 09:06:04 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:97] Producer finished correctly: true
2022-02-17 09:06:04 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:101] Producer produced 100 messages
2022-02-17 09:06:04 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1083d315, messages=[], arguments=[--group-id, my-consumer-group-1964981926, --bootstrap-server, my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092, --max-messages, 100, --group-instance-id, instance1259051909, --topic, my-topic-1525313696-1959445033], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-919906473-kafka-clients-6cc7749b98-z2jxn', podNamespace='namespace-0', bootstrapServer='my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092', topicName='my-topic-1525313696-1959445033', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1964981926', consumerInstanceId='instance1259051909', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@4d4c3506}
2022-02-17 09:06:04 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092#my-topic-1525313696-1959445033 from pod my-cluster-919906473-kafka-clients-6cc7749b98-z2jxn
2022-02-17 09:06:04 [ForkJoinPool-1-worker-7] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-919906473-kafka-clients-6cc7749b98-z2jxn -n namespace-0 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1964981926 --bootstrap-server my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092 --max-messages 100 --group-instance-id instance1259051909 --topic my-topic-1525313696-1959445033
2022-02-17 09:06:04 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:97] Producer finished correctly: true
2022-02-17 09:06:04 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:101] Producer produced 100 messages
2022-02-17 09:06:04 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4c84e47b, messages=[], arguments=[--group-id, my-consumer-group-802886527, --bootstrap-server, my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092, --max-messages, 100, --group-instance-id, instance1165900105, --topic, my-topic-537241926-1559832458], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2', podNamespace='namespace-2', bootstrapServer='my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092', topicName='my-topic-537241926-1559832458', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-802886527', consumerInstanceId='instance1165900105', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@e335f9}
2022-02-17 09:06:04 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092#my-topic-537241926-1559832458 from pod my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2
2022-02-17 09:06:04 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2 -n namespace-2 -- /opt/kafka/consumer.sh --group-id my-consumer-group-802886527 --bootstrap-server my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092 --max-messages 100 --group-instance-id instance1165900105 --topic my-topic-537241926-1559832458
2022-02-17 09:06:10 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:06:10 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:06:10 [ForkJoinPool-1-worker-7] INFO  [SecurityST:481] Triggering CA cert renewal by adding the annotation
2022-02-17 09:06:10 [ForkJoinPool-1-worker-7] INFO  [SecurityST:493] Patching secret my-cluster-919906473-clients-ca with strimzi.io/force-replace
2022-02-17 09:06:10 [ForkJoinPool-1-worker-7] INFO  [SecurityST:503] Wait for kafka to rolling restart (1)...
2022-02-17 09:06:10 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-919906473-kafka rolling update
2022-02-17 09:06:10 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:06:10 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:06:10 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:131] Waiting for Secret my-cluster-633186695-cluster-ca-cert certificate change
2022-02-17 09:06:10 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:138] Certificate in Secret my-cluster-633186695-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUQ1VhtXe5cTRkOzBZVkv39Pyo+cgwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjAyMTcwOTAyMjRaFw0yMzAyMTcwOTAyMjRaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQCpM53MhwCxp0ZbTjyUDE5MBJXZ15i21/Y3ISrcLHm3
ru4t8f3TzqqtTK7VJjaDE4PtmXIeL1fQ6BjOXEzIymTFNjlJjQUD8CVr46wd+Wgd
Ayy3zUAlrQoR3dtG8+mJN0AWAcO6siAxTsiJj1vl5LjQWMpslmmHAgY9odcbE0lO
hm50WR935clBiU/ORg5yRykViZdaJBoakdvVE+1L2laI9/IsDuEIM73ctGIPi+GC
+/PPOAMk/NGrZmzD6RRPQb2wtVRv1dJEH8cPAhEr4OBi5KNRGdIQ3ozc8hALv0e/
9NEjYVGDBC68expKg2v6yZloWPoSyQHKtvF0DELS9NIyzmVDkNf+GNqrEV9xDxdz
mUpf77vK0BOwMOH/7GgDxm+Q6vflF5NOtFSTZzFOr83aVM9Kx23t/t+CyejzeKCk
/OBdEGziIxMXKbnBaufLW78z1dAo1EVxIzU5Hd7ganff7qzTlE4imjdBg2xQbVeK
uqAr6tLvIdMaCih9yyKVf0tcrGIFdtmpLLLrErXv37XmJe6WgrDAWCJ4dsRe9llY
VmoAx3iun3z2BPwvOKqVWksWNCvD90zIiF9w6JDrEiS8WHs+5oDYNJLz3vIAKqXD
7UpQekRM+Pzk64190axqRpo977YdzHySekNxQ5sgWDHzRkVXO+swP/d67ZuGPRha
IwIDAQABo0UwQzAdBgNVHQ4EFgQUm/4bDwaWxoXz/z4z5i2ByBGEkEUwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AJ45Ck2bteCOAD3JMn7Up6/z4HT+X6gsU+bD3D+DOX6mHezCgwUZcUMpFc0Lvvod
yugFODAjo/2zRqYStl+9cqowcJwVNNsY6g6WS8udBh61GJ5wNNL+etTxobtHqjO+
Z2QppnwgzezZaQfYuu4fhB+w2OCeiWvWlemTut4hVhKx8mglL9jnY8VPRoGBFTtb
ZX8NOrsVsKeLe3L5IJCsCxT2A0gyFrL70YiAcUUFtZGrTaiARwy/7rWdIbRV52/V
dy7xkhbJS1fuc5RtobCc2I3gExR3H1Zq89BrdSWWvSJqN1AgzLaj/4a9pt34fgp2
EyLI5tKrJy8XfhTTWU8B0TcT3fL7EUrfgj3uuTOCaQKWmUOQwKV+cFuU2FN4RhIE
tl+ZwTlM6cMIt4zWbCrnWAQ/i4sjqNBYig95Wqu+DshyuqcZl/Hzf3d3xBWrxRMa
J4hZuvLLnEIO06XFLi6bDYJ9Q89AMqsYmsXD89HeU6EOAAWgejoSn8bVESaRvSlN
9jN2oGTbxWlKkXfHPTD8HrQxe+RNRggOD2ot8ZpGkAK3wyQSrskQiaTLmLlrZRzg
gBg0MTBq7q75ZAw6qlkHlSg+wmZZQeZ5qsas7KCpVYfncqJHq4boZTxkdFSmuYJz
Qn3WVvUrk/N3quMkR4TQNd/5dOOPi/Vvn+QVyuP2MhWJ
-----END CERTIFICATE-----

2022-02-17 09:06:10 [ForkJoinPool-1-worker-5] INFO  [KafkaUtils:178] Waiting for cluster stability
2022-02-17 09:07:13 [ForkJoinPool-1-worker-5] INFO  [KafkaUtils:206] Kafka cluster is stable after 61 polls.
2022-02-17 09:07:13 [ForkJoinPool-1-worker-5] INFO  [SecurityST:686] Checking produced and consumed messages to pod:my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2
2022-02-17 09:07:13 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@74e565fe, messages=[], arguments=[--bootstrap-server, my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092, --max-messages, 100, --topic, my-topic-537241926-1559832458], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2', podNamespace='namespace-2', bootstrapServer='my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092', topicName='my-topic-537241926-1559832458', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@5860f7ac}
2022-02-17 09:07:13 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:94] Producing 100 messages to my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092:my-topic-537241926-1559832458 from pod my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2
2022-02-17 09:07:13 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2 -n namespace-2 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092 --max-messages 100 --topic my-topic-537241926-1559832458
2022-02-17 09:07:16 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:97] Producer finished correctly: true
2022-02-17 09:07:16 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:101] Producer produced 100 messages
2022-02-17 09:07:16 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3bb36d8d, messages=[], arguments=[--group-id, my-consumer-group-802886527, --bootstrap-server, my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092, --max-messages, 100, --group-instance-id, instance940815843, --topic, my-topic-537241926-1559832458], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2', podNamespace='namespace-2', bootstrapServer='my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092', topicName='my-topic-537241926-1559832458', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-802886527', consumerInstanceId='instance940815843', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@28f213fa}
2022-02-17 09:07:16 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092#my-topic-537241926-1559832458 from pod my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2
2022-02-17 09:07:16 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-633186695-kafka-clients-54ff4b49b4-8cqx2 -n namespace-2 -- /opt/kafka/consumer.sh --group-id my-consumer-group-802886527 --bootstrap-server my-cluster-633186695-kafka-bootstrap.namespace-2.svc:9092 --max-messages 100 --group-instance-id instance940815843 --topic my-topic-537241926-1559832458
2022-02-17 09:07:23 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:07:23 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:07:23 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:07:23 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:309] Delete all resources for testAutoRenewCaCertsTriggerByExpiredCertificate
2022-02-17 09:07:23 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-537241926-1559832458 in namespace namespace-2
2022-02-17 09:07:33 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of Deployment my-cluster-633186695-kafka-clients in namespace namespace-2
2022-02-17 09:08:05 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-919906473-kafka has been successfully rolled
2022-02-17 09:08:05 [ForkJoinPool-1-worker-7] INFO  [SecurityST:524] Wait for kafka to rolling restart (2)...
2022-02-17 09:08:05 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-919906473-kafka rolling update
2022-02-17 09:08:06 [ForkJoinPool-1-worker-3] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-1454039081-kafka has been successfully rolled
2022-02-17 09:08:06 [ForkJoinPool-1-worker-3] INFO  [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-1454039081-kafka to be ready
2022-02-17 09:08:13 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of KafkaUser my-user-88707196-1937328672 in namespace namespace-2
2022-02-17 09:08:13 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of Kafka my-cluster-633186695 in namespace namespace-2
2022-02-17 09:08:13 [ForkJoinPool-1-worker-5] INFO  [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-2, for cruise control Kafka cluster my-cluster-633186695
2022-02-17 09:08:23 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:08:23 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-2 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-02-17 09:08:32 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1454039081 will have desired state: Ready
2022-02-17 09:08:32 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:405] Kafka: my-cluster-1454039081 is in desired state: Ready
2022-02-17 09:08:32 [ForkJoinPool-1-worker-3] INFO  [RollingUpdateUtils:132] Kafka: my-cluster-1454039081 is ready
2022-02-17 09:08:32 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1592] Initial ClusterCA cert dates: Wed Feb 16 09:02:22 UTC 2022 --> Fri Mar 18 09:02:22 UTC 2022
2022-02-17 09:08:32 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1593] Changed ClusterCA cert dates: Wed Feb 16 09:02:22 UTC 2022 --> Fri Mar 18 09:02:22 UTC 2022
2022-02-17 09:08:32 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1594] KafkaBroker cert creation dates: Thu Feb 17 09:03:19 UTC 2022 --> Wed Mar 09 09:03:19 UTC 2022
2022-02-17 09:08:32 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1595] KafkaBroker cert changed dates:  Thu Feb 17 09:07:00 UTC 2022 --> Mon Sep 05 09:07:00 UTC 2022
2022-02-17 09:08:32 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1596] Zookeeper cert creation dates: Thu Feb 17 09:02:33 UTC 2022 --> Wed Mar 09 09:02:33 UTC 2022
2022-02-17 09:08:32 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1597] Zookeeper cert changed dates:  Thu Feb 17 09:05:51 UTC 2022 --> Mon Sep 05 09:05:51 UTC 2022
2022-02-17 09:08:32 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:08:32 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:309] Delete all resources for testCustomClusterCACertRenew
2022-02-17 09:08:32 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of Kafka my-cluster-1454039081 in namespace namespace-1
2022-02-17 09:08:42 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:08:42 [ForkJoinPool-1-worker-3] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-1 for test case:testCustomClusterCACertRenew
2022-02-17 09:08:57 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-FINISHED
2022-02-17 09:08:57 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:08:57 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:08:57 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCustomClientsCACertRenew-STARTED
2022-02-17 09:09:01 [ForkJoinPool-1-worker-1] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:09:01 [ForkJoinPool-1-worker-1] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-3 for test case:testAclWithSuperUser
2022-02-17 09:09:01 [ForkJoinPool-1-worker-1] INFO  [KubeClusterResource:156] Creating Namespace: namespace-3
2022-02-17 09:09:01 [ForkJoinPool-1-worker-1] INFO  [KubeClusterResource:82] Client use Namespace: namespace-3
2022-02-17 09:09:01 [ForkJoinPool-1-worker-1] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-3
2022-02-17 09:09:01 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-1200899238 in namespace namespace-3
2022-02-17 09:09:01 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-3
2022-02-17 09:09:01 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1200899238 will have desired state: Ready
2022-02-17 09:09:10 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCustomClusterCACertRenew-FINISHED
2022-02-17 09:09:10 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:09:10 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:09:10 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertificates-STARTED
2022-02-17 09:09:12 [ForkJoinPool-1-worker-5] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:09:12 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-4 for test case:testCustomClientsCACertRenew
2022-02-17 09:09:12 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:156] Creating Namespace: namespace-4
2022-02-17 09:09:13 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:82] Client use Namespace: namespace-4
2022-02-17 09:09:13 [ForkJoinPool-1-worker-5] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-4
2022-02-17 09:09:13 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1828] Generating custom RootCA, IntermediateCA, and ClusterCA, ClientsCA for Strimzi and PEM bundles.
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1844] Deploy all certificates and keys as secrets.
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:150] Waiting for Secret: my-cluster-409635382-cluster-ca-cert to be deleted
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:154] Secret: my-cluster-409635382-cluster-ca-cert successfully deleted
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:46] Waiting for Secret my-cluster-409635382-cluster-ca-cert
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:50] Secret my-cluster-409635382-cluster-ca-cert created
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:150] Waiting for Secret: my-cluster-409635382-cluster-ca to be deleted
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:154] Secret: my-cluster-409635382-cluster-ca successfully deleted
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:150] Waiting for Secret: my-cluster-409635382-clients-ca-cert to be deleted
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:154] Secret: my-cluster-409635382-clients-ca-cert successfully deleted
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:46] Waiting for Secret my-cluster-409635382-clients-ca-cert
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:50] Secret my-cluster-409635382-clients-ca-cert created
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:150] Waiting for Secret: my-cluster-409635382-clients-ca to be deleted
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:154] Secret: my-cluster-409635382-clients-ca successfully deleted
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1805] Check ClusterCA and ClientsCA certificates.
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-409635382 in namespace namespace-4
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-4
2022-02-17 09:09:14 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-409635382 will have desired state: Ready
2022-02-17 09:09:51 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-919906473-kafka has been successfully rolled
2022-02-17 09:09:51 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-919906473-kafka to be ready
2022-02-17 09:10:19 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] Kafka: my-cluster-1200899238 is in desired state: Ready
2022-02-17 09:10:19 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-91930105-1193770148 in namespace namespace-4
2022-02-17 09:10:19 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-3
2022-02-17 09:10:19 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-91930105-1193770148 will have desired state: Ready
2022-02-17 09:10:20 [ForkJoinPool-1-worker-7] INFO  [SecurityST:539] Checking the certificates have been replaced
2022-02-17 09:10:20 [ForkJoinPool-1-worker-7] INFO  [SecurityST:550] Checking consumed messages to pod:my-cluster-919906473-kafka-clients-6cc7749b98-z2jxn
2022-02-17 09:10:20 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@57ccb15a, messages=[], arguments=[--group-id, my-consumer-group-1797266745, --bootstrap-server, my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092, --max-messages, 100, --group-instance-id, instance1690038763, --topic, my-topic-1525313696-1959445033], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-919906473-kafka-clients-6cc7749b98-z2jxn', podNamespace='namespace-0', bootstrapServer='my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092', topicName='my-topic-1525313696-1959445033', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1797266745', consumerInstanceId='instance1690038763', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@1024183b}
2022-02-17 09:10:20 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092#my-topic-1525313696-1959445033 from pod my-cluster-919906473-kafka-clients-6cc7749b98-z2jxn
2022-02-17 09:10:20 [ForkJoinPool-1-worker-7] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-919906473-kafka-clients-6cc7749b98-z2jxn -n namespace-0 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1797266745 --bootstrap-server my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092 --max-messages 100 --group-instance-id instance1690038763 --topic my-topic-1525313696-1959445033
2022-02-17 09:10:20 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] KafkaTopic: my-topic-91930105-1193770148 is in desired state: Ready
2022-02-17 09:10:20 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-1208710261-1216395930 in namespace namespace-4
2022-02-17 09:10:20 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-3
2022-02-17 09:10:20 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-1208710261-1216395930 will have desired state: Ready
2022-02-17 09:10:22 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] KafkaUser: my-user-1208710261-1216395930 is in desired state: Ready
2022-02-17 09:10:22 [ForkJoinPool-1-worker-1] INFO  [SecurityST:1108] Checking kafka super user:my-user-1208710261-1216395930 that is able to send messages to topic:my-topic-91930105-1193770148
2022-02-17 09:10:22 [ForkJoinPool-1-worker-1] INFO  [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-17 09:10:23 [ForkJoinPool-1-worker-1] INFO  [ProducerConfig:376] ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.49.2:32484]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-58036027
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 6000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties10003157839820963567.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties15012679635510734982.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-02-17 09:10:23 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:119] Kafka version: 3.1.0
2022-02-17 09:10:23 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-17 09:10:23 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:121] Kafka startTimeMs: 1645089023299
2022-02-17 09:10:23 [kafka-producer-network-thread | producer-58036027] INFO  [Metadata:402] [Producer clientId=producer-58036027] Resetting the last seen epoch of partition my-topic-91930105-1193770148-0 to 0 since the associated topicId changed from null to BA9go7vYQ2GBKDSnjzwLQA
2022-02-17 09:10:23 [kafka-producer-network-thread | producer-58036027] INFO  [Metadata:287] [Producer clientId=producer-58036027] Cluster ID: 5NHKOc0CSEeUUl3SF8tVuw
2022-02-17 09:10:24 [ForkJoinPool-1-worker-1] INFO  [ExternalKafkaClient:182] Sent 100 messages.
2022-02-17 09:10:24 [ForkJoinPool-1-worker-1] INFO  [KafkaProducer:1228] [Producer clientId=producer-58036027] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-02-17 09:10:24 [ForkJoinPool-1-worker-1] INFO  [Metrics:659] Metrics scheduler closed
2022-02-17 09:10:24 [ForkJoinPool-1-worker-1] INFO  [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-02-17 09:10:24 [ForkJoinPool-1-worker-1] INFO  [Metrics:669] Metrics reporters closed
2022-02-17 09:10:24 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:83] App info kafka.producer for producer-58036027 unregistered
2022-02-17 09:10:24 [ForkJoinPool-1-worker-1] INFO  [SecurityST:1122] Checking kafka super user:my-user-1208710261-1216395930 that is able to read messages to topic:my-topic-91930105-1193770148 regardless that we configured Acls with only write operation
2022-02-17 09:10:24 [ForkJoinPool-1-worker-1] INFO  [ConsumerConfig:376] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.49.2:32484]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-246088246
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-1045363027
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties12809832779242415985.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties15612237512972046068.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-02-17 09:10:25 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:119] Kafka version: 3.1.0
2022-02-17 09:10:25 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-17 09:10:25 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:121] Kafka startTimeMs: 1645089025100
2022-02-17 09:10:25 [ForkJoinPool-1-worker-1] INFO  [KafkaConsumer:966] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Subscribed to topic(s): my-topic-91930105-1193770148
2022-02-17 09:10:25 [ForkJoinPool-1-worker-1] INFO  [Metadata:402] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Resetting the last seen epoch of partition my-topic-91930105-1193770148-0 to 0 since the associated topicId changed from null to BA9go7vYQ2GBKDSnjzwLQA
2022-02-17 09:10:25 [ForkJoinPool-1-worker-1] INFO  [Metadata:287] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Cluster ID: 5NHKOc0CSEeUUl3SF8tVuw
2022-02-17 09:10:25 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:853] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Discovered group coordinator 192.168.49.2:32647 (id: 2147483647 rack: null)
2022-02-17 09:10:25 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:535] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] (Re-)joining group
2022-02-17 09:10:25 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:1000] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Request joining group due to: need to re-join with the given member-id
2022-02-17 09:10:25 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:535] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] (Re-)joining group
2022-02-17 09:10:28 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:10:28 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:10:28 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-1723862290-2000069991 in namespace namespace-4
2022-02-17 09:10:28 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-0
2022-02-17 09:10:28 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-1723862290-2000069991 will have desired state: Ready
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:595] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Successfully joined group with generation Generation{generationId=1, memberId='consumer-246088246-b7531084-a752-40c5-8a9b-1de6344089ed', protocol='range'}
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:652] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Finished assignment for group at generation 1: {consumer-246088246-b7531084-a752-40c5-8a9b-1de6344089ed=Assignment(partitions=[my-topic-91930105-1193770148-0])}
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:761] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Successfully synced group in generation Generation{generationId=1, memberId='consumer-246088246-b7531084-a752-40c5-8a9b-1de6344089ed', protocol='range'}
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:279] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Notifying assignor about the new Assignment(partitions=[my-topic-91930105-1193770148-0])
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:291] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Adding newly assigned partitions: my-topic-91930105-1193770148-0
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:1388] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Found no committed offset for partition my-topic-91930105-1193770148-0
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [SubscriptionState:398] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Resetting offset for partition my-topic-91930105-1193770148-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.49.2:32647 (id: 0 rack: null)], epoch=0}}.
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ExternalKafkaClient:224] Received 100 messages.
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:310] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Revoke previously assigned partitions my-topic-91930105-1193770148-0
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:1060] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Member consumer-246088246-b7531084-a752-40c5-8a9b-1de6344089ed sending LeaveGroup request to coordinator 192.168.49.2:32647 (id: 2147483647 rack: null) due to the consumer is being closed
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:972] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Resetting generation due to: consumer pro-actively leaving the group
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:1000] [Consumer clientId=consumer-246088246, groupId=my-consumer-group-1045363027] Request joining group due to: consumer pro-actively leaving the group
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [Metrics:659] Metrics scheduler closed
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [Metrics:669] Metrics reporters closed
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:83] App info kafka.consumer for consumer-246088246 unregistered
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-1208710261-1216395930-non-super-user in namespace namespace-4
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-3
2022-02-17 09:10:28 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-1208710261-1216395930-non-super-user will have desired state: Ready
2022-02-17 09:10:29 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] KafkaUser: my-user-1723862290-2000069991 is in desired state: Ready
2022-02-17 09:10:29 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-919906473-kafka-clients-tls in namespace namespace-4
2022-02-17 09:10:29 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-0
2022-02-17 09:10:29 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-919906473-kafka-clients-tls will be ready
2022-02-17 09:10:29 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] KafkaUser: my-user-1208710261-1216395930-non-super-user is in desired state: Ready
2022-02-17 09:10:29 [ForkJoinPool-1-worker-1] INFO  [SecurityST:1148] Checking kafka super user:my-user-1208710261-1216395930-non-super-user that is able to send messages to topic:my-topic-91930105-1193770148
2022-02-17 09:10:29 [ForkJoinPool-1-worker-1] INFO  [ProducerConfig:376] ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.49.2:32484]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-29974978
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 6000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties18341160884413880198.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties5750900731537362801.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:119] Kafka version: 3.1.0
2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:121] Kafka startTimeMs: 1645089030067
2022-02-17 09:10:30 [kafka-producer-network-thread | producer-29974978] INFO  [Metadata:402] [Producer clientId=producer-29974978] Resetting the last seen epoch of partition my-topic-91930105-1193770148-0 to 0 since the associated topicId changed from null to BA9go7vYQ2GBKDSnjzwLQA
2022-02-17 09:10:30 [kafka-producer-network-thread | producer-29974978] INFO  [Metadata:287] [Producer clientId=producer-29974978] Cluster ID: 5NHKOc0CSEeUUl3SF8tVuw
2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [ExternalKafkaClient:182] Sent 100 messages.
2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [KafkaProducer:1228] [Producer clientId=producer-29974978] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [Metrics:659] Metrics scheduler closed
2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [Metrics:669] Metrics reporters closed
2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:83] App info kafka.producer for producer-29974978 unregistered
2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [SecurityST:1156] Checking kafka super user:my-user-1208710261-1216395930-non-super-user that is not able to read messages to topic:my-topic-91930105-1193770148 because of defined ACLs on only write operation
2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [ConsumerConfig:376] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.49.2:32484]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-1638520498
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-1799853324
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties1994335045843253916.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties10013181953150785076.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:119] Kafka version: 3.1.0
2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [AppInfoParser:121] Kafka startTimeMs: 1645089030996
2022-02-17 09:10:30 [ForkJoinPool-1-worker-1] INFO  [KafkaConsumer:966] [Consumer clientId=consumer-1638520498, groupId=my-consumer-group-1799853324] Subscribed to topic(s): my-topic-91930105-1193770148
2022-02-17 09:10:31 [ForkJoinPool-1-worker-1] INFO  [Metadata:402] [Consumer clientId=consumer-1638520498, groupId=my-consumer-group-1799853324] Resetting the last seen epoch of partition my-topic-91930105-1193770148-0 to 0 since the associated topicId changed from null to BA9go7vYQ2GBKDSnjzwLQA
2022-02-17 09:10:31 [ForkJoinPool-1-worker-1] INFO  [Metadata:287] [Consumer clientId=consumer-1638520498, groupId=my-consumer-group-1799853324] Cluster ID: 5NHKOc0CSEeUUl3SF8tVuw
2022-02-17 09:10:31 [ForkJoinPool-1-worker-1] INFO  [ConsumerCoordinator:261] [Consumer clientId=consumer-1638520498, groupId=my-consumer-group-1799853324] FindCoordinator request hit fatal exception
org.apache.kafka.common.errors.GroupAuthorizationException: Not authorized to access group: my-consumer-group-1799853324
2022-02-17 09:10:31 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:10:31 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:309] Delete all resources for testAclWithSuperUser
2022-02-17 09:10:31 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of KafkaUser my-user-1208710261-1216395930 in namespace namespace-3
2022-02-17 09:10:32 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:168] Deployment: my-cluster-919906473-kafka-clients-tls is ready
2022-02-17 09:10:32 [ForkJoinPool-1-worker-7] INFO  [SecurityST:575] Checking consumed messages to pod:my-cluster-919906473-kafka-clients-tls-556b4c68d7-nclhb
2022-02-17 09:10:32 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6eb952c2, messages=[], arguments=[--group-id, my-consumer-group-825293253, --bootstrap-server, my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092, --max-messages, 100, --group-instance-id, instance1039573570, --topic, my-topic-1525313696-1959445033], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-919906473-kafka-clients-tls-556b4c68d7-nclhb', podNamespace='namespace-0', bootstrapServer='my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092', topicName='my-topic-1525313696-1959445033', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-825293253', consumerInstanceId='instance1039573570', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@4e16b5c8}
2022-02-17 09:10:32 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092#my-topic-1525313696-1959445033 from pod my-cluster-919906473-kafka-clients-tls-556b4c68d7-nclhb
2022-02-17 09:10:32 [ForkJoinPool-1-worker-7] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-919906473-kafka-clients-tls-556b4c68d7-nclhb -n namespace-0 -- /opt/kafka/consumer.sh --group-id my-consumer-group-825293253 --bootstrap-server my-cluster-919906473-kafka-bootstrap.namespace-0.svc:9092 --max-messages 100 --group-instance-id instance1039573570 --topic my-topic-1525313696-1959445033
2022-02-17 09:10:39 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:10:39 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:10:39 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:10:39 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:309] Delete all resources for testAutoReplaceClientsCaKeysTriggeredByAnno
2022-02-17 09:10:39 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of Deployment my-cluster-919906473-kafka-clients in namespace namespace-0
2022-02-17 09:10:41 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of KafkaUser my-user-1208710261-1216395930-non-super-user in namespace namespace-3
2022-02-17 09:10:51 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-91930105-1193770148 in namespace namespace-3
2022-02-17 09:11:01 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of Kafka my-cluster-1200899238 in namespace namespace-3
2022-02-17 09:11:11 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:11:11 [ForkJoinPool-1-worker-1] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-3 for test case:testAclWithSuperUser
2022-02-17 09:11:54 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAclWithSuperUser-FINISHED
2022-02-17 09:11:54 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:11:54 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:11:54 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-STARTED
2022-02-17 09:11:55 [ForkJoinPool-1-worker-3] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:11:55 [ForkJoinPool-1-worker-3] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-5 for test case:testCertificates
2022-02-17 09:11:55 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:156] Creating Namespace: namespace-5
2022-02-17 09:11:55 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:82] Client use Namespace: namespace-5
2022-02-17 09:11:55 [ForkJoinPool-1-worker-3] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-5
2022-02-17 09:11:55 [ForkJoinPool-1-worker-3] INFO  [SecurityST:127] Running testCertificates my-cluster-1428497748
2022-02-17 09:11:55 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-1428497748 in namespace namespace-5
2022-02-17 09:11:55 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-5
2022-02-17 09:11:55 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1428497748 will have desired state: Ready
2022-02-17 09:12:00 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of Deployment my-cluster-919906473-kafka-clients-tls in namespace namespace-0
2022-02-17 09:12:00 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of KafkaUser my-user-1723862290-2000069991 in namespace namespace-0
2022-02-17 09:12:10 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of KafkaUser my-user-586581055-1848286924 in namespace namespace-0
2022-02-17 09:12:20 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-1525313696-1959445033 in namespace namespace-0
2022-02-17 09:12:30 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of Kafka my-cluster-919906473 in namespace namespace-0
2022-02-17 09:12:30 [ForkJoinPool-1-worker-7] INFO  [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-0, for cruise control Kafka cluster my-cluster-919906473
2022-02-17 09:12:40 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:12:40 [ForkJoinPool-1-worker-7] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-0 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-02-17 09:12:50 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] Kafka: my-cluster-409635382 is in desired state: Ready
2022-02-17 09:12:50 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update KafkaUser strimzi-tls-user-1357642853 in namespace namespace-5
2022-02-17 09:12:50 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-4
2022-02-17 09:12:50 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for KafkaUser: strimzi-tls-user-1357642853 will have desired state: Ready
2022-02-17 09:12:51 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] KafkaUser: strimzi-tls-user-1357642853 is in desired state: Ready
2022-02-17 09:12:51 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1669] Change of kafka validity and renewal days - reconciliation should start.
2022-02-17 09:12:51 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-409635382-entity-operator rolling update
2022-02-17 09:12:56 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-409635382-entity-operator will be ready
2022-02-17 09:13:05 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:405] Kafka: my-cluster-1428497748 is in desired state: Ready
2022-02-17 09:13:05 [ForkJoinPool-1-worker-3] INFO  [SecurityST:137] Check Kafka bootstrap certificate
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-1428497748-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1428497748-kafka-bootstrap:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1428497748-kafka-bootstrap
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [SecurityST:140] OPENSSL OUTPUT: 

CONNECTED(00000003)
---
Certificate chain
 0 s:O = io.strimzi, CN = my-cluster-1428497748-kafka
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----
MIIGZTCCBE2gAwIBAgIUUQr3ZZ5E+eZzlTodK/uLOqKTCrAwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjAyMTcwOTEyMjBaFw0yMzAyMTcwOTEyMjBaMDsxEzARBgNVBAoMCmlv
LnN0cmltemkxJDAiBgNVBAMMG215LWNsdXN0ZXItMTQyODQ5Nzc0OC1rYWZrYTCC
ASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAMh5tkrdl812TRuyY8fSDld4
0jiFT0MQ8hQjTIEkH6tWa3HZmHCbKgL4A/HqaypNEChdf6Iqy56P4GLhd01aSljc
0DOSEU/GXml74eJ5iAKF1K9P0rUp7pPSNEfCC/IGam6oDv/yjiGQkZ0RWy56s4hF
bLCE9li7cMFbZgYCtAMj1xswC5m5hCK7kiS3dtYi6UIl1CjYP3R5O0XyUm+W6RXj
qq+JXZ1yRAsQ4cBn0D+77KRc33dNJEVYgsxBZFC5QEmjXzxuHMVqm/tFJb+4hWlA
i8yAfdjv4SuEc2wuYII3gns+XE64TPUsy6+AdXc90Knaj0OkVzHQZTknntNGa/0C
AwEAAaOCAm0wggJpMIICZQYDVR0RBIICXDCCAliCMW15LWNsdXN0ZXItMTQyODQ5
Nzc0OC1rYWZrYS1ib290c3RyYXAubmFtZXNwYWNlLTWCX215LWNsdXN0ZXItMTQy
ODQ5Nzc0OC1rYWZrYS0xLm15LWNsdXN0ZXItMTQyODQ5Nzc0OC1rYWZrYS1icm9r
ZXJzLm5hbWVzcGFjZS01LnN2Yy5jbHVzdGVyLmxvY2FsgjVteS1jbHVzdGVyLTE0
Mjg0OTc3NDgta2Fma2EtYm9vdHN0cmFwLm5hbWVzcGFjZS01LnN2Y4IzbXktY2x1
c3Rlci0xNDI4NDk3NzQ4LWthZmthLWJyb2tlcnMubmFtZXNwYWNlLTUuc3ZjgiNt
eS1jbHVzdGVyLTE0Mjg0OTc3NDgta2Fma2EtYnJva2Vyc4JBbXktY2x1c3Rlci0x
NDI4NDk3NzQ4LWthZmthLWJyb2tlcnMubmFtZXNwYWNlLTUuc3ZjLmNsdXN0ZXIu
bG9jYWyCJW15LWNsdXN0ZXItMTQyODQ5Nzc0OC1rYWZrYS1ib290c3RyYXCCL215
LWNsdXN0ZXItMTQyODQ5Nzc0OC1rYWZrYS1icm9rZXJzLm5hbWVzcGFjZS01glFt
eS1jbHVzdGVyLTE0Mjg0OTc3NDgta2Fma2EtMS5teS1jbHVzdGVyLTE0Mjg0OTc3
NDgta2Fma2EtYnJva2Vycy5uYW1lc3BhY2UtNS5zdmOCQ215LWNsdXN0ZXItMTQy
ODQ5Nzc0OC1rYWZrYS1ib290c3RyYXAubmFtZXNwYWNlLTUuc3ZjLmNsdXN0ZXIu
bG9jYWwwDQYJKoZIhvcNAQENBQADggIBADipy8RVZfeZ6bRoG1eLyK+6l6q2apst
11gy/sHsBgaRB8m3t37jtjGCjylZt8iN9qNc6uUwZ1S971LKdlEPDPPSEGJWDuE5
AbO8c4Br98Awg3LE+6ZxfCj7z3B3/V8GbvBTScjceu3C9M6VG6TLuYP8vhPrULrn
FXKoQSU5Q1UNoRVg+/4O+4NTcMWg3z2S8KXthonUjPJCNb2ASJ6mxSbggPFmjG0b
N71waFnxTV2KFMG2wtH1BmXYuRxk9yoAe0K5+Spr9cRYmHbRu9gv4JMNiC1BqK4S
yIjuwVs61e5tyuojIgtGyOChispU7/XjNkw/qD8N2S5nFWiLr552UIMqH3+WKeua
t/BSXfc0UQjo3RIw+rPRmPN6SIgsLSqoONSdd73sXcQu8abF0rnqYuHOeCxF2iwn
TNSHmJjmD9y2XlXCDlH+P3mvtwhHdW5LiHGnYbBN1D6u7bBHXdGGmg2aLjR0jwli
4WaOVOWmBVc5jSGVPxAcg5BqTnQK8b26ojnh+CQvJBGPE0zwb7oLyLbwiLbAJzes
s5ZFbllUftlPo0z8ce5SPT8QomNkd96Db2BLejAiIgDe3uqsio0U3CmaMlavWW4H
dOIu+nsBsF1EwHlMpFRRt3WsP+yQwpx6ImZWB0STk0M+ucFVwNp9xn8eBB2uhGVX
L0PqKPGWpxls
-----END CERTIFICATE-----
 1 s:O = io.strimzi, CN = cluster-ca v0
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUBwMsj8gcNTCqgH4Jk4zrz8XH+JIwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjAyMTcwOTExNTVaFw0yMzAyMTcwOTExNTVaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQC6UU6RmunGx5B1vftwwDF74BDTr6IXJO98EzZH4Vz9
7BTkKjOOz2nU6RRunNQggVzNfJG/xExNo+xCtuLEqrNwMZEjtNYqbOSkP/+gmlkY
L0uWrPkNlvClYnAxKZXzpILWQxauXm57H+hX/nIcrjwHmytP/qiDjouFE+aPb3lm
stgJxzGMI9P5//TZ7muKoC5nXoz0Hn31vsH9DtbSIuMptSbiudGoJ/uS25Do5YCp
aguOAMZrL+79iclAqKzDKM2J1ztnkvxX1cuCR61gAe+KIVfcyjkZRA+bMQQu1DMF
sysZlLsCJKaqYpaXHOf1w41QHao+51kma6+uAw8CZdiJTtqC7HGL9vkUr8bFhnGF
lBC+fY8M1YtNV0SyqoqTwxRywq9SiOp+UIJR7VQ6cA2hwFcnJANEtxVMvQcCzuL+
W4ZD6Rniamc0wsNUpnwIvTIpdELFbdOcgrufmpJDakrn2LAajUTON85hvcAsyabi
grqvp2OleOd3jxWjhcuQTknY2DSYnxQJUNqw+1KOZ6IeuNDCUigJ6Rzb00CLJPPg
WSC0z+QCOV/ipLFf/S/58mOd3qwjJCFRUPlQTnA5XK5BlUZ8Au4q9J6Wf9KEnzyp
kb57herPcT6p9GE6US/uCpBhIbOm2XpuNYLnxX2H/j2/SVUKAXjdMIGM/ka4U9U/
LwIDAQABo0UwQzAdBgNVHQ4EFgQUOeQyKe8ZzgMjNTgPmjKRRqMa5wwwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AHRVdrfePXQFbslJ6vay6XP+wtOfPsZhqhDDf69VYmemT2fFiw5c6PKiuHieLmIj
CJlvW+vWXzuny6sgApenx5caVMimXKIwZlDn+Nwmt2JntaghGmC2DZ/HeoR2+VQk
KARw80SLu51N084/augRoqbGv7yjHnGN+Sz4+QEUMqjNDvtDndQ187mpU30IBwXo
zm+DRRQ0pFLLryJh3MuW5zLPUxGeBx8+H8SAopxyNHRm4TlFk2gS7gHereo5+qxM
ycn0uFbt9n0TQzEOsWcwA53yDn7RLSIRc3r61ulX3FVG8pqK3HuZp1mZSRRNqvQj
wK0HdXxagzRnZ1PEhqu8uh8D2FclQfem0EgJpLm2JpEHew0tDy/oSBHSVJqqT4+G
8mak94x0JLQ1LKnmEwvq8LL/MvLmZE6GKWeDP69LhLhE2smeHJ8yogxC887k9vIt
IYdTNp6c9mcTAUMw14BcXROI9uB98D4ybdIOUQsbzpEQOc/J15puvSiGzBzy+ycW
fnTZnoZjrebGGB3972+YmgdcoiiCXjc056wLQDLAUWhhEiApYBNu1FmWYHKDWq18
910s7UVThM9HDpIUSKa5Jzp3LR6moo5Xp+1jRaPh8QvVH1tHcY4VaWzm/EXrNDx/
Q6Q7D5j/cVwu+/Bb1MgkpeWbo6QfP8WBiHLbjXVgZvvY
-----END CERTIFICATE-----
---
Server certificate
subject=O = io.strimzi, CN = my-cluster-1428497748-kafka

issuer=O = io.strimzi, CN = cluster-ca v0

---
No client certificate CA names sent
Peer signing digest: SHA256
Peer signature type: RSA-PSS
Server Temp Key: X25519, 253 bits
---
SSL handshake has read 3507 bytes and written 369 bytes
Verification: OK
Verified peername: my-cluster-1428497748-kafka-bootstrap
---
New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384
Server public key is 2048 bit
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
Early data was not sent
Verify return code: 0 (ok)
---



2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [SecurityST:143] Check zookeeper client certificate
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-1428497748-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1428497748-zookeeper-client:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1428497748-zookeeper-client -cert /opt/kafka/broker-certs/my-cluster-1428497748-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-1428497748-kafka-0.key
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [SecurityST:154] Checking certificates for podId 0
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [SecurityST:156] Check kafka certificate for port 9091
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-1428497748-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1428497748-kafka-0.my-cluster-1428497748-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1428497748-kafka-0.my-cluster-1428497748-kafka-brokers.namespace-5.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-1428497748-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-1428497748-kafka-0.key
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [SecurityST:156] Check kafka certificate for port 9093
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-1428497748-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1428497748-kafka-0.my-cluster-1428497748-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1428497748-kafka-0.my-cluster-1428497748-kafka-brokers.namespace-5.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-1428497748-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-1428497748-kafka-0.key
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [SecurityST:163] Check zookeeper certificate for port 2181
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-1428497748-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1428497748-zookeeper-0.my-cluster-1428497748-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1428497748-zookeeper-0.my-cluster-1428497748-zookeeper-nodes.namespace-5.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-1428497748-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-1428497748-zookeeper-0.key
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:13:06 [ForkJoinPool-1-worker-3] INFO  [SecurityST:163] Check zookeeper certificate for port 3888
2022-02-17 09:13:07 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-1428497748-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1428497748-zookeeper-0.my-cluster-1428497748-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1428497748-zookeeper-0.my-cluster-1428497748-zookeeper-nodes.namespace-5.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-1428497748-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-1428497748-zookeeper-0.key
2022-02-17 09:13:07 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:13:07 [ForkJoinPool-1-worker-3] INFO  [SecurityST:154] Checking certificates for podId 1
2022-02-17 09:13:07 [ForkJoinPool-1-worker-3] INFO  [SecurityST:156] Check kafka certificate for port 9091
2022-02-17 09:13:07 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-1428497748-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1428497748-kafka-1.my-cluster-1428497748-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1428497748-kafka-1.my-cluster-1428497748-kafka-brokers.namespace-5.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-1428497748-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-1428497748-kafka-1.key
2022-02-17 09:13:07 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:13:07 [ForkJoinPool-1-worker-3] INFO  [SecurityST:156] Check kafka certificate for port 9093
2022-02-17 09:13:07 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-1428497748-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1428497748-kafka-1.my-cluster-1428497748-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1428497748-kafka-1.my-cluster-1428497748-kafka-brokers.namespace-5.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-1428497748-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-1428497748-kafka-1.key
2022-02-17 09:13:07 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:13:07 [ForkJoinPool-1-worker-3] INFO  [SecurityST:163] Check zookeeper certificate for port 2181
2022-02-17 09:13:07 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-1428497748-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1428497748-zookeeper-1.my-cluster-1428497748-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1428497748-zookeeper-1.my-cluster-1428497748-zookeeper-nodes.namespace-5.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-1428497748-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-1428497748-zookeeper-1.key
2022-02-17 09:13:07 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:13:07 [ForkJoinPool-1-worker-3] INFO  [SecurityST:163] Check zookeeper certificate for port 3888
2022-02-17 09:13:08 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-1428497748-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-1428497748-zookeeper-1.my-cluster-1428497748-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-1428497748-zookeeper-1.my-cluster-1428497748-zookeeper-nodes.namespace-5.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-1428497748-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-1428497748-zookeeper-1.key
2022-02-17 09:13:08 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:13:08 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:13:08 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:309] Delete all resources for testCertificates
2022-02-17 09:13:08 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of Kafka my-cluster-1428497748 in namespace namespace-5
2022-02-17 09:13:13 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-FINISHED
2022-02-17 09:13:13 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:13:13 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:13:13 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-STARTED
2022-02-17 09:13:14 [ForkJoinPool-1-worker-1] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:13:14 [ForkJoinPool-1-worker-1] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-6 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-02-17 09:13:14 [ForkJoinPool-1-worker-1] INFO  [KubeClusterResource:156] Creating Namespace: namespace-6
2022-02-17 09:13:15 [ForkJoinPool-1-worker-1] INFO  [KubeClusterResource:82] Client use Namespace: namespace-6
2022-02-17 09:13:15 [ForkJoinPool-1-worker-1] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-6
2022-02-17 09:13:15 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-1507422181-source in namespace namespace-6
2022-02-17 09:13:15 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-6
2022-02-17 09:13:15 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1507422181-source will have desired state: Ready
2022-02-17 09:13:18 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:13:18 [ForkJoinPool-1-worker-3] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-5 for test case:testCertificates
2022-02-17 09:13:45 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertificates-FINISHED
2022-02-17 09:13:45 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:13:45 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:13:45 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-STARTED
2022-02-17 09:13:46 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:168] Deployment: my-cluster-409635382-entity-operator is ready
2022-02-17 09:13:48 [ForkJoinPool-1-worker-7] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:13:48 [ForkJoinPool-1-worker-7] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-7 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-02-17 09:13:48 [ForkJoinPool-1-worker-7] INFO  [KubeClusterResource:156] Creating Namespace: namespace-7
2022-02-17 09:13:48 [ForkJoinPool-1-worker-7] INFO  [KubeClusterResource:82] Client use Namespace: namespace-7
2022-02-17 09:13:48 [ForkJoinPool-1-worker-7] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-7
2022-02-17 09:13:48 [ForkJoinPool-1-worker-7] INFO  [SecurityST:601] Creating a cluster
2022-02-17 09:13:48 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-226613017 in namespace namespace-7
2022-02-17 09:13:48 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-7
2022-02-17 09:13:48 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-226613017 will have desired state: Ready
2022-02-17 09:13:57 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:141] Deployment my-cluster-409635382-entity-operator rolling update finished
2022-02-17 09:13:57 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1691] Initial ClientsCA cert dates: Wed Feb 16 09:09:14 UTC 2022 --> Fri Mar 18 09:09:14 UTC 2022
2022-02-17 09:13:57 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1692] Changed ClientsCA cert dates: Wed Feb 16 09:09:14 UTC 2022 --> Fri Mar 18 09:09:14 UTC 2022
2022-02-17 09:13:57 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1693] Initial userCert dates: Thu Feb 17 09:12:50 UTC 2022 --> Wed Mar 09 09:12:50 UTC 2022
2022-02-17 09:13:57 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1694] Changed userCert dates: Thu Feb 17 09:13:00 UTC 2022 --> Mon Sep 05 09:13:00 UTC 2022
2022-02-17 09:13:57 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:13:57 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:309] Delete all resources for testCustomClientsCACertRenew
2022-02-17 09:13:57 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of KafkaUser strimzi-tls-user-1357642853 in namespace namespace-4
2022-02-17 09:14:07 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of Kafka my-cluster-409635382 in namespace namespace-4
2022-02-17 09:14:17 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:14:17 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-4 for test case:testCustomClientsCACertRenew
2022-02-17 09:14:23 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] Kafka: my-cluster-1507422181-source is in desired state: Ready
2022-02-17 09:14:23 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-1507422181-target in namespace namespace-7
2022-02-17 09:14:23 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-6
2022-02-17 09:14:23 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1507422181-target will have desired state: Ready
2022-02-17 09:15:00 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCustomClientsCACertRenew-FINISHED
2022-02-17 09:15:00 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:15:00 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:15:00 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-STARTED
2022-02-17 09:15:05 [ForkJoinPool-1-worker-3] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:15:05 [ForkJoinPool-1-worker-3] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-8 for test case:testClientsCACertRenew
2022-02-17 09:15:05 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:156] Creating Namespace: namespace-8
2022-02-17 09:15:05 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:82] Client use Namespace: namespace-8
2022-02-17 09:15:05 [ForkJoinPool-1-worker-3] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-8
2022-02-17 09:15:05 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-1629715604 in namespace namespace-8
2022-02-17 09:15:05 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-8
2022-02-17 09:15:05 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1629715604 will have desired state: Ready
2022-02-17 09:15:39 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] Kafka: my-cluster-1507422181-target is in desired state: Ready
2022-02-17 09:15:39 [ForkJoinPool-1-worker-1] INFO  [SecurityST:905] Getting IP of the source bootstrap service for consumer
2022-02-17 09:15:39 [ForkJoinPool-1-worker-1] INFO  [SecurityST:908] Getting IP of the target bootstrap service for producer
2022-02-17 09:15:39 [ForkJoinPool-1-worker-1] INFO  [SecurityST:911] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to consumer with address 10.97.174.176:9093
2022-02-17 09:15:39 [ForkJoinPool-1-worker-1] INFO  [SecurityST:912] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to producer with address 10.103.250.32:9093
2022-02-17 09:15:39 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update KafkaMirrorMaker my-cluster-1507422181 in namespace namespace-8
2022-02-17 09:15:39 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-6
2022-02-17 09:15:39 [ForkJoinPool-1-worker-1] WARN  [VersionUsageUtils:60] The client is using resource type 'kafkamirrormakers' with unstable version 'v1beta2'
2022-02-17 09:15:39 [ForkJoinPool-1-worker-1] INFO  [PodUtils:245] Wait until Pod my-cluster-1507422181-mirror-maker is present
2022-02-17 09:15:40 [ForkJoinPool-1-worker-1] INFO  [PodUtils:249] Pod my-cluster-1507422181-mirror-maker is present
2022-02-17 09:15:40 [ForkJoinPool-1-worker-1] INFO  [PodUtils:236] Wait until Pod my-cluster-1507422181-mirror-maker-f99469b4f-44wgw is in CrashLoopBackOff state
2022-02-17 09:16:00 [ForkJoinPool-1-worker-1] INFO  [PodUtils:241] Pod my-cluster-1507422181-mirror-maker-f99469b4f-44wgw is in CrashLoopBackOff state
2022-02-17 09:16:00 [ForkJoinPool-1-worker-1] INFO  [SecurityST:947] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to consumer with address 10.97.174.176:9093
2022-02-17 09:16:00 [ForkJoinPool-1-worker-1] INFO  [SecurityST:948] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to producer with address 10.103.250.32:9093
2022-02-17 09:16:00 [ForkJoinPool-1-worker-1] INFO  [SecurityST:950] Adding configuration ssl.endpoint.identification.algorithm to the mirror maker...
2022-02-17 09:16:00 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for KafkaMirrorMaker: my-cluster-1507422181 will have desired state: Ready
2022-02-17 09:16:15 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:405] Kafka: my-cluster-1629715604 is in desired state: Ready
2022-02-17 09:16:15 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update KafkaUser strimzi-tls-user-624995408 in namespace namespace-8
2022-02-17 09:16:15 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-8
2022-02-17 09:16:15 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:394] Wait for KafkaUser: strimzi-tls-user-624995408 will have desired state: Ready
2022-02-17 09:16:16 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:405] KafkaUser: strimzi-tls-user-624995408 is in desired state: Ready
2022-02-17 09:16:16 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1669] Change of kafka validity and renewal days - reconciliation should start.
2022-02-17 09:16:16 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-1629715604-entity-operator rolling update
2022-02-17 09:16:29 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] Kafka: my-cluster-226613017 is in desired state: Ready
2022-02-17 09:16:29 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-1804308153-1789931370 in namespace namespace-8
2022-02-17 09:16:29 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-7
2022-02-17 09:16:29 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-1804308153-1789931370 will have desired state: Ready
2022-02-17 09:16:30 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] KafkaUser: my-user-1804308153-1789931370 is in desired state: Ready
2022-02-17 09:16:30 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-1067450038-675276496 in namespace namespace-8
2022-02-17 09:16:30 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-7
2022-02-17 09:16:30 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-1067450038-675276496 will have desired state: Ready
2022-02-17 09:16:31 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] KafkaTopic: my-topic-1067450038-675276496 is in desired state: Ready
2022-02-17 09:16:31 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-226613017-kafka-clients in namespace namespace-8
2022-02-17 09:16:31 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-7
2022-02-17 09:16:31 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-226613017-kafka-clients will be ready
2022-02-17 09:16:34 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:168] Deployment: my-cluster-226613017-kafka-clients is ready
2022-02-17 09:16:34 [ForkJoinPool-1-worker-7] INFO  [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-17 09:16:34 [ForkJoinPool-1-worker-7] INFO  [SecurityST:274] Checking produced and consumed messages to pod:my-cluster-226613017-kafka-clients-68549f4598-l8j7x
2022-02-17 09:16:34 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@45183a78, messages=[], arguments=[--bootstrap-server, my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9092, --max-messages, 100, --topic, my-topic-1067450038-675276496], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-226613017-kafka-clients-68549f4598-l8j7x', podNamespace='namespace-7', bootstrapServer='my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9092', topicName='my-topic-1067450038-675276496', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@91eead1}
2022-02-17 09:16:34 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:94] Producing 100 messages to my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9092:my-topic-1067450038-675276496 from pod my-cluster-226613017-kafka-clients-68549f4598-l8j7x
2022-02-17 09:16:34 [ForkJoinPool-1-worker-7] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-226613017-kafka-clients-68549f4598-l8j7x -n namespace-7 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9092 --max-messages 100 --topic my-topic-1067450038-675276496
2022-02-17 09:16:36 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:97] Producer finished correctly: true
2022-02-17 09:16:36 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:101] Producer produced 100 messages
2022-02-17 09:16:36 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@dc2ff07, messages=[], arguments=[--group-id, my-consumer-group-758875931, --bootstrap-server, my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9092, --max-messages, 100, --group-instance-id, instance1100022215, --topic, my-topic-1067450038-675276496], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-226613017-kafka-clients-68549f4598-l8j7x', podNamespace='namespace-7', bootstrapServer='my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9092', topicName='my-topic-1067450038-675276496', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-758875931', consumerInstanceId='instance1100022215', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@7374cbda}
2022-02-17 09:16:36 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9092#my-topic-1067450038-675276496 from pod my-cluster-226613017-kafka-clients-68549f4598-l8j7x
2022-02-17 09:16:36 [ForkJoinPool-1-worker-7] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-226613017-kafka-clients-68549f4598-l8j7x -n namespace-7 -- /opt/kafka/consumer.sh --group-id my-consumer-group-758875931 --bootstrap-server my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9092 --max-messages 100 --group-instance-id instance1100022215 --topic my-topic-1067450038-675276496
2022-02-17 09:16:42 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:16:42 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:16:42 [ForkJoinPool-1-worker-7] INFO  [SecurityST:288] Triggering CA cert renewal by adding the annotation
2022-02-17 09:16:42 [ForkJoinPool-1-worker-7] INFO  [SecurityST:300] Patching secret my-cluster-226613017-cluster-ca-cert with strimzi.io/force-renew
2022-02-17 09:16:42 [ForkJoinPool-1-worker-7] INFO  [SecurityST:305] Wait for zk to rolling restart ...
2022-02-17 09:16:42 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-226613017-zookeeper rolling update
2022-02-17 09:17:37 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-1629715604-entity-operator will be ready
2022-02-17 09:17:47 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-226613017-zookeeper has been successfully rolled
2022-02-17 09:17:47 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-226613017-zookeeper to be ready
2022-02-17 09:18:19 [ForkJoinPool-1-worker-7] INFO  [SecurityST:309] Wait for kafka to rolling restart ...
2022-02-17 09:18:19 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-226613017-kafka rolling update
2022-02-17 09:18:27 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:168] Deployment: my-cluster-1629715604-entity-operator is ready
2022-02-17 09:18:37 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:141] Deployment my-cluster-1629715604-entity-operator rolling update finished
2022-02-17 09:18:37 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1691] Initial ClientsCA cert dates: Thu Feb 17 09:15:05 UTC 2022 --> Wed Mar 09 09:15:05 UTC 2022
2022-02-17 09:18:37 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1692] Changed ClientsCA cert dates: Thu Feb 17 09:16:17 UTC 2022 --> Mon Sep 05 09:16:17 UTC 2022
2022-02-17 09:18:37 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1693] Initial userCert dates: Thu Feb 17 09:16:16 UTC 2022 --> Wed Mar 09 09:16:16 UTC 2022
2022-02-17 09:18:37 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1694] Changed userCert dates: Thu Feb 17 09:17:41 UTC 2022 --> Mon Sep 05 09:17:41 UTC 2022
2022-02-17 09:18:37 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:18:37 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:309] Delete all resources for testClientsCACertRenew
2022-02-17 09:18:37 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of KafkaUser strimzi-tls-user-624995408 in namespace namespace-8
2022-02-17 09:18:47 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of Kafka my-cluster-1629715604 in namespace namespace-8
2022-02-17 09:18:57 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:18:57 [ForkJoinPool-1-worker-3] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-8 for test case:testClientsCACertRenew
2022-02-17 09:19:09 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-226613017-kafka has been successfully rolled
2022-02-17 09:19:09 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-226613017-kafka to be ready
2022-02-17 09:19:38 [ForkJoinPool-1-worker-7] INFO  [SecurityST:313] Wait for EO to rolling restart ...
2022-02-17 09:19:38 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-226613017-entity-operator rolling update
2022-02-17 09:19:38 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-226613017-entity-operator will be ready
2022-02-17 09:20:20 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:168] Deployment: my-cluster-226613017-entity-operator is ready
2022-02-17 09:20:30 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:141] Deployment my-cluster-226613017-entity-operator rolling update finished
2022-02-17 09:20:30 [ForkJoinPool-1-worker-7] INFO  [SecurityST:317] Wait for CC and KE to rolling restart ...
2022-02-17 09:20:30 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-226613017-kafka-exporter rolling update
2022-02-17 09:21:00 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-FINISHED
2022-02-17 09:21:00 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:21:00 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:21:00 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCustomClusterCAClientsCA-STARTED
2022-02-17 09:21:00 [ForkJoinPool-1-worker-5] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:21:00 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-9 for test case:testCaRenewalBreakInMiddle
2022-02-17 09:21:00 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:156] Creating Namespace: namespace-9
2022-02-17 09:21:01 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:82] Client use Namespace: namespace-9
2022-02-17 09:21:01 [ForkJoinPool-1-worker-5] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-9
2022-02-17 09:21:01 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-1278734482 in namespace namespace-9
2022-02-17 09:21:01 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-9
2022-02-17 09:21:01 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1278734482 will have desired state: Ready
2022-02-17 09:21:15 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-226613017-kafka-exporter will be ready
2022-02-17 09:21:15 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:168] Deployment: my-cluster-226613017-kafka-exporter is ready
2022-02-17 09:21:25 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:141] Deployment my-cluster-226613017-kafka-exporter rolling update finished
2022-02-17 09:21:25 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-226613017-cruise-control rolling update
2022-02-17 09:21:25 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-226613017-cruise-control will be ready
2022-02-17 09:21:25 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:168] Deployment: my-cluster-226613017-cruise-control is ready
2022-02-17 09:21:36 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:141] Deployment my-cluster-226613017-cruise-control rolling update finished
2022-02-17 09:21:36 [ForkJoinPool-1-worker-7] INFO  [SecurityST:322] Checking the certificates have been replaced
2022-02-17 09:21:36 [ForkJoinPool-1-worker-7] INFO  [SecurityST:336] Checking consumed messages to pod:my-cluster-226613017-kafka-clients-68549f4598-l8j7x
2022-02-17 09:21:36 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3e8179a6, messages=[], arguments=[--group-id, my-consumer-group-1746759578, --bootstrap-server, my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9092, --max-messages, 100, --group-instance-id, instance562372378, --topic, my-topic-1067450038-675276496], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-226613017-kafka-clients-68549f4598-l8j7x', podNamespace='namespace-7', bootstrapServer='my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9092', topicName='my-topic-1067450038-675276496', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1746759578', consumerInstanceId='instance562372378', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@3ad020ef}
2022-02-17 09:21:36 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9092#my-topic-1067450038-675276496 from pod my-cluster-226613017-kafka-clients-68549f4598-l8j7x
2022-02-17 09:21:36 [ForkJoinPool-1-worker-7] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-226613017-kafka-clients-68549f4598-l8j7x -n namespace-7 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1746759578 --bootstrap-server my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9092 --max-messages 100 --group-instance-id instance562372378 --topic my-topic-1067450038-675276496
2022-02-17 09:21:45 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:21:45 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:21:45 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update KafkaUser bob-my-cluster-226613017 in namespace namespace-9
2022-02-17 09:21:45 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-7
2022-02-17 09:21:45 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for KafkaUser: bob-my-cluster-226613017 will have desired state: Ready
2022-02-17 09:21:46 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] KafkaUser: bob-my-cluster-226613017 is in desired state: Ready
2022-02-17 09:21:46 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-226613017-kafka-clients-tls in namespace namespace-7
2022-02-17 09:21:46 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-7
2022-02-17 09:21:46 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-226613017-kafka-clients-tls will be ready
2022-02-17 09:21:49 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:168] Deployment: my-cluster-226613017-kafka-clients-tls is ready
2022-02-17 09:21:49 [ForkJoinPool-1-worker-7] INFO  [SecurityST:360] Checking consumed messages to pod:my-cluster-226613017-kafka-clients-tls-658cb4fb6f-wkc2j
2022-02-17 09:21:49 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5dba19f7, messages=[], arguments=[--group-id, my-consumer-group-896090747, --bootstrap-server, my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9093, USER=bob_my_cluster_226613017, --max-messages, 100, --group-instance-id, instance1390956714, --topic, my-topic-1067450038-675276496], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-226613017-kafka-clients-tls-658cb4fb6f-wkc2j', podNamespace='namespace-7', bootstrapServer='my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9093', topicName='my-topic-1067450038-675276496', maxMessages=100, kafkaUsername='bob-my-cluster-226613017', consumerGroupName='my-consumer-group-896090747', consumerInstanceId='instance1390956714', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@6f9efd3f}
2022-02-17 09:21:49 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9093#my-topic-1067450038-675276496 from pod my-cluster-226613017-kafka-clients-tls-658cb4fb6f-wkc2j
2022-02-17 09:21:49 [ForkJoinPool-1-worker-7] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-226613017-kafka-clients-tls-658cb4fb6f-wkc2j -n namespace-7 -- /opt/kafka/consumer.sh --group-id my-consumer-group-896090747 --bootstrap-server my-cluster-226613017-kafka-bootstrap.namespace-7.svc:9093 USER=bob_my_cluster_226613017 --max-messages 100 --group-instance-id instance1390956714 --topic my-topic-1067450038-675276496
2022-02-17 09:21:51 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] KafkaMirrorMaker: my-cluster-1507422181 is in desired state: Ready
2022-02-17 09:21:51 [ForkJoinPool-1-worker-1] WARN  [DeploymentUtils:213] Deployment my-cluster-1507422181-mirror-maker is not deleted yet! Triggering force delete by cmd client!
2022-02-17 09:21:56 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:21:56 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:309] Delete all resources for testTlsHostnameVerificationWithMirrorMaker
2022-02-17 09:21:56 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of Kafka my-cluster-1507422181-target in namespace namespace-6
2022-02-17 09:21:59 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:21:59 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:21:59 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:21:59 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:309] Delete all resources for testAutoRenewClusterCaCertsTriggeredByAnno
2022-02-17 09:21:59 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of Deployment my-cluster-226613017-kafka-clients in namespace namespace-7
2022-02-17 09:22:06 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of KafkaMirrorMaker my-cluster-1507422181 in namespace namespace-6
2022-02-17 09:22:06 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of Kafka my-cluster-1507422181-source in namespace namespace-6
2022-02-17 09:22:12 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] Kafka: my-cluster-1278734482 is in desired state: Ready
2022-02-17 09:22:12 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-2070712369-1323600697 in namespace namespace-9
2022-02-17 09:22:12 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-9
2022-02-17 09:22:12 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-2070712369-1323600697 will have desired state: Ready
2022-02-17 09:22:14 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] KafkaUser: my-user-2070712369-1323600697 is in desired state: Ready
2022-02-17 09:22:14 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-696188601-613781114 in namespace namespace-9
2022-02-17 09:22:14 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-9
2022-02-17 09:22:14 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-696188601-613781114 will have desired state: Ready
2022-02-17 09:22:15 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] KafkaTopic: my-topic-696188601-613781114 is in desired state: Ready
2022-02-17 09:22:15 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-1278734482-kafka-clients in namespace namespace-9
2022-02-17 09:22:15 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-9
2022-02-17 09:22:15 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-1278734482-kafka-clients will be ready
2022-02-17 09:22:16 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:22:16 [ForkJoinPool-1-worker-1] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-6 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-02-17 09:22:17 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:168] Deployment: my-cluster-1278734482-kafka-clients is ready
2022-02-17 09:22:17 [ForkJoinPool-1-worker-5] INFO  [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-17 09:22:17 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@40c8ad72, messages=[], arguments=[--bootstrap-server, my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093, USER=my_user_2070712369_1323600697, --max-messages, 100, --topic, my-topic-696188601-613781114], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql', podNamespace='namespace-9', bootstrapServer='my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093', topicName='my-topic-696188601-613781114', maxMessages=100, kafkaUsername='my-user-2070712369-1323600697', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@23f82207}
2022-02-17 09:22:17 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:124] Producing 100 messages to my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093:my-topic-696188601-613781114 from pod my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql
2022-02-17 09:22:17 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql -n namespace-9 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093 USER=my_user_2070712369_1323600697 --max-messages 100 --topic my-topic-696188601-613781114
2022-02-17 09:22:21 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:127] Producer finished correctly: true
2022-02-17 09:22:21 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:131] Producer produced 100 messages
2022-02-17 09:22:21 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4e60f015, messages=[], arguments=[--group-id, my-consumer-group-1944243906, --bootstrap-server, my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093, USER=my_user_2070712369_1323600697, --max-messages, 100, --group-instance-id, instance1881942029, --topic, my-topic-696188601-613781114], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql', podNamespace='namespace-9', bootstrapServer='my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093', topicName='my-topic-696188601-613781114', maxMessages=100, kafkaUsername='my-user-2070712369-1323600697', consumerGroupName='my-consumer-group-1944243906', consumerInstanceId='instance1881942029', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@160b91df}
2022-02-17 09:22:21 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:192] Consuming 100 messages from my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093:my-topic-696188601-613781114 from pod my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql
2022-02-17 09:22:21 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql -n namespace-9 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1944243906 --bootstrap-server my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093 USER=my_user_2070712369_1323600697 --max-messages 100 --group-instance-id instance1881942029 --topic my-topic-696188601-613781114
2022-02-17 09:22:28 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-17 09:22:28 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-17 09:22:28 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:70] Creating secret my-cluster-1278734482-cluster-ca-cert
2022-02-17 09:22:28 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1238] No pods of my-cluster-1278734482-zookeeper are in desired state
2022-02-17 09:22:29 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1238] No pods of my-cluster-1278734482-zookeeper are in desired state
2022-02-17 09:22:30 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1238] No pods of my-cluster-1278734482-zookeeper are in desired state
2022-02-17 09:22:31 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1241] Pod in 'Pending' state: my-cluster-1278734482-zookeeper-1
2022-02-17 09:22:31 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@54c18c11, messages=[], arguments=[--group-id, my-consumer-group-2051974966, --bootstrap-server, my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093, USER=my_user_2070712369_1323600697, --max-messages, 100, --group-instance-id, instance915844893, --topic, my-topic-696188601-613781114], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql', podNamespace='namespace-9', bootstrapServer='my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093', topicName='my-topic-696188601-613781114', maxMessages=100, kafkaUsername='my-user-2070712369-1323600697', consumerGroupName='my-consumer-group-2051974966', consumerInstanceId='instance915844893', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@6f65b153}
2022-02-17 09:22:31 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:192] Consuming 100 messages from my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093:my-topic-696188601-613781114 from pod my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql
2022-02-17 09:22:31 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql -n namespace-9 -- /opt/kafka/consumer.sh --group-id my-consumer-group-2051974966 --bootstrap-server my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093 USER=my_user_2070712369_1323600697 --max-messages 100 --group-instance-id instance915844893 --topic my-topic-696188601-613781114
2022-02-17 09:22:38 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-17 09:22:38 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-17 09:22:38 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:131] Waiting for Secret my-cluster-1278734482-cluster-ca-cert certificate change
2022-02-17 09:22:38 [ForkJoinPool-1-worker-5] INFO  [SecretUtils:138] Certificate in Secret my-cluster-1278734482-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUDrFBDmqYJY63ga3puWuE9u2oAwowDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjAyMTcwOTIyMjhaFw0yMjAyMjQwOTIyMjhaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQDSdhJzPRkWmJ7MRc6q5TDz9vYNoMWlOr+K0SfeL/Er
wX/womn9N7B3sFkDixGvox0HNXGsW9sjP0tbMw4bLtV4KHO2/oT79zRon6VefcWB
x41pkJxnjtrGBLDJ9AMoTVErjqqC3vWoebTWb6WnQapj50wPJhtE1S5jZ/Qm2XLu
HrPNjpmcwVVjcuAt7Ick30+7jBBMgHw3ujV55hAbXNjNjJCfilC3DQWWDXlb5ONw
03DyLRyP0i9ZtLxFaI7kmzXYUWOvNYmrzTKma4xvYfpeY3MQiNF0TjQm+PgHMLV4
QrPEWLA+WeoK4zoAPsK50fKMdiAHmu8MFNO4iCCw6Ylhkf88nb2HBE9EQAd5jw08
Gc7yU0Do9jbiWaJXchUrYtIzAjslHJesCHwSyCCnM3i4+0ACmo/CTSFHO/OlZSS/
eJ6+pb39V0B04dkYmgyH9J+hYeKA20FxeE00g7l9hra5PPBjl3lIuQM0cw7FmoLT
KjLitIb/5oyzrRK6eboDONgHV+6UMhZoOjqnLl9qVHl2618v4i0AgMMm+TsZd1kw
Roos3wtApvyeNUsHPew3iGzZ2cLCYE6mdHE3vqwq/oPbiv1eO5FqDnN1EFOGhqWO
FYHr8ln32c3ZF4pTxuDTRsWZr0dFwrbWFw8I9mzSvEBIIzq9X2fV8l1tAcpLPvVa
RQIDAQABo0UwQzAdBgNVHQ4EFgQUvuatCaiUqCypYurKKX7c8coUpLAwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AAyDGg0nRVIoupWyunYAXgf44qW2+6vdBwQJqXkZ4wrWEBAJ2DTves/TJvc+aUYQ
+5ySkXi4mJDCptgDih1yhaCtZnzzMS/gnFIDrY1IseYpFU0WxniQsRFpW3rTjcwO
f2nFiNrwmrAUnJDFCat6wCpgxTtH6Sl8N9y/qEM2XIpVCJx3QcrK8Bsc48pSpaEb
sDpgBFbRpcG0N2txBs9/k/FSZv3kPqkXIhTaqeb2jWgraFiPT5mpQsbEppWi57gc
lvPyN2tmPN2JO1dak0L3CREyREm70um3GnyhLPSp5mrYcD73mKbCs0XMbq9HDWU9
QGxUl/IH+Y3vhbQjtdVXJk62Pb6VU0d2dcoawfBH5jGpr8txL3ob9yITFtHZpnBU
gP6n6mWmkZ0r4IYDnPBb1xws/DpIlxzrOQLV3V75IerkExBK6H2E228woSinD2S+
o4Q2NNTUlWvLquRN6ul/yyqPEnpCGBVxvhIRngxGuSCcLDzOi4qSSiox/KE207LB
udDLtyS8ITWZ1B5lwBeqgXhYs/kqn4+wuR/lZpvOqN28EFqua50/MNPdFdEBUTka
esNjT/t5ZeFDUX36K36fsJizlR9+N+4gljmgf5ow3yCFYtgMkQG0YnoAjfDoksSK
3m9w3SnwbebgqLIN1hLDMfrRTq7KavUMZTXo9viR4jGp
-----END CERTIFICATE-----

2022-02-17 09:22:38 [ForkJoinPool-1-worker-5] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1278734482-zookeeper rolling update
2022-02-17 09:22:43 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-FINISHED
2022-02-17 09:22:43 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:22:43 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:22:43 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-STARTED
2022-02-17 09:22:45 [ForkJoinPool-1-worker-3] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:22:45 [ForkJoinPool-1-worker-3] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-10 for test case:testCustomClusterCAClientsCA
2022-02-17 09:22:45 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:156] Creating Namespace: namespace-10
2022-02-17 09:22:45 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:82] Client use Namespace: namespace-10
2022-02-17 09:22:45 [ForkJoinPool-1-worker-3] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-10
2022-02-17 09:22:45 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1828] Generating custom RootCA, IntermediateCA, and ClusterCA, ClientsCA for Strimzi and PEM bundles.
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1844] Deploy all certificates and keys as secrets.
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:150] Waiting for Secret: my-cluster-677240277-cluster-ca-cert to be deleted
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:154] Secret: my-cluster-677240277-cluster-ca-cert successfully deleted
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:46] Waiting for Secret my-cluster-677240277-cluster-ca-cert
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:50] Secret my-cluster-677240277-cluster-ca-cert created
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:150] Waiting for Secret: my-cluster-677240277-cluster-ca to be deleted
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:154] Secret: my-cluster-677240277-cluster-ca successfully deleted
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:150] Waiting for Secret: my-cluster-677240277-clients-ca-cert to be deleted
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:154] Secret: my-cluster-677240277-clients-ca-cert successfully deleted
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:46] Waiting for Secret my-cluster-677240277-clients-ca-cert
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:50] Secret my-cluster-677240277-clients-ca-cert created
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:150] Waiting for Secret: my-cluster-677240277-clients-ca to be deleted
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecretUtils:154] Secret: my-cluster-677240277-clients-ca successfully deleted
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1805] Check ClusterCA and ClientsCA certificates.
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1720]  Deploy kafka with new certs/secrets.
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-677240277 in namespace namespace-10
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-10
2022-02-17 09:22:46 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-677240277 will have desired state: Ready
2022-02-17 09:23:19 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of Deployment my-cluster-226613017-kafka-clients-tls in namespace namespace-7
2022-02-17 09:23:19 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of KafkaUser bob-my-cluster-226613017 in namespace namespace-7
2022-02-17 09:23:19 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of KafkaUser my-user-1804308153-1789931370 in namespace namespace-7
2022-02-17 09:23:29 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-1067450038-675276496 in namespace namespace-7
2022-02-17 09:23:39 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of Kafka my-cluster-226613017 in namespace namespace-7
2022-02-17 09:23:39 [ForkJoinPool-1-worker-7] INFO  [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-7, for cruise control Kafka cluster my-cluster-226613017
2022-02-17 09:23:50 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:23:50 [ForkJoinPool-1-worker-7] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-7 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-02-17 09:23:55 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:405] Kafka: my-cluster-677240277 is in desired state: Ready
2022-02-17 09:23:55 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1748] Check Kafka(s) and Zookeeper(s) certificates.
2022-02-17 09:23:55 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-1148419294-236744490 in namespace namespace-10
2022-02-17 09:23:55 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-10
2022-02-17 09:23:55 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-1148419294-236744490 will have desired state: Ready
2022-02-17 09:23:56 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:405] KafkaTopic: my-topic-1148419294-236744490 is in desired state: Ready
2022-02-17 09:23:56 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1759] Check KafkaUser certificate.
2022-02-17 09:23:56 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-1467718881-1589666376 in namespace namespace-10
2022-02-17 09:23:56 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-10
2022-02-17 09:23:56 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-1467718881-1589666376 will have desired state: Ready
2022-02-17 09:23:57 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:405] KafkaUser: my-user-1467718881-1589666376 is in desired state: Ready
2022-02-17 09:23:57 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1766] Send and receive messages over TLS.
2022-02-17 09:23:57 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-677240277-kafka-clients in namespace namespace-10
2022-02-17 09:23:57 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-10
2022-02-17 09:23:57 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-677240277-kafka-clients will be ready
2022-02-17 09:23:59 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:168] Deployment: my-cluster-677240277-kafka-clients is ready
2022-02-17 09:23:59 [ForkJoinPool-1-worker-3] INFO  [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-17 09:23:59 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1780] Check for certificates used within kafka pod internal clients (producer/consumer)
2022-02-17 09:23:59 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-10 exec my-cluster-677240277-kafka-clients-6cfbd59757-jf9bx -- /bin/bash -c openssl x509 -in /opt/kafka/user-secret-my-user-1467718881-1589666376/ca.crt -noout -nameopt RFC2253 -issuer
2022-02-17 09:23:59 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:23:59 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-10 exec my-cluster-677240277-kafka-clients-6cfbd59757-jf9bx -- /bin/bash -c openssl x509 -in /opt/kafka/user-secret-my-user-1467718881-1589666376/ca.crt -noout -nameopt RFC2253 -subject
2022-02-17 09:23:59 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:24:00 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-10 exec my-cluster-677240277-kafka-clients-6cfbd59757-jf9bx -- /bin/bash -c openssl x509 -in /opt/kafka/cluster-ca-my-user-1467718881-1589666376/ca.crt -noout -nameopt RFC2253 -issuer
2022-02-17 09:24:00 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:24:00 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Command: kubectl --namespace namespace-10 exec my-cluster-677240277-kafka-clients-6cfbd59757-jf9bx -- /bin/bash -c openssl x509 -in /opt/kafka/cluster-ca-my-user-1467718881-1589666376/ca.crt -noout -nameopt RFC2253 -subject
2022-02-17 09:24:00 [ForkJoinPool-1-worker-3] INFO  [Exec:417] Return code: 0
2022-02-17 09:24:00 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1797] Checking produced and consumed messages via TLS to pod:my-cluster-677240277-kafka-clients-6cfbd59757-jf9bx
2022-02-17 09:24:00 [ForkJoinPool-1-worker-3] INFO  [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@651cb3, messages=[], arguments=[--bootstrap-server, my-cluster-677240277-kafka-bootstrap.namespace-10.svc:9093, USER=my_user_1467718881_1589666376, --max-messages, 100, --topic, my-topic-1148419294-236744490], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-677240277-kafka-clients-6cfbd59757-jf9bx', podNamespace='namespace-10', bootstrapServer='my-cluster-677240277-kafka-bootstrap.namespace-10.svc:9093', topicName='my-topic-1148419294-236744490', maxMessages=100, kafkaUsername='my-user-1467718881-1589666376', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@2d1fc99c}
2022-02-17 09:24:00 [ForkJoinPool-1-worker-3] INFO  [InternalKafkaClient:124] Producing 100 messages to my-cluster-677240277-kafka-bootstrap.namespace-10.svc:9093:my-topic-1148419294-236744490 from pod my-cluster-677240277-kafka-clients-6cfbd59757-jf9bx
2022-02-17 09:24:00 [ForkJoinPool-1-worker-3] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-677240277-kafka-clients-6cfbd59757-jf9bx -n namespace-10 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-677240277-kafka-bootstrap.namespace-10.svc:9093 USER=my_user_1467718881_1589666376 --max-messages 100 --topic my-topic-1148419294-236744490
2022-02-17 09:24:03 [ForkJoinPool-1-worker-3] INFO  [InternalKafkaClient:127] Producer finished correctly: true
2022-02-17 09:24:03 [ForkJoinPool-1-worker-3] INFO  [InternalKafkaClient:131] Producer produced 100 messages
2022-02-17 09:24:03 [ForkJoinPool-1-worker-3] INFO  [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3b7f76a6, messages=[], arguments=[--group-id, my-consumer-group-1127469558, --bootstrap-server, my-cluster-677240277-kafka-bootstrap.namespace-10.svc:9093, USER=my_user_1467718881_1589666376, --max-messages, 100, --group-instance-id, instance1313362005, --topic, my-topic-1148419294-236744490], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-677240277-kafka-clients-6cfbd59757-jf9bx', podNamespace='namespace-10', bootstrapServer='my-cluster-677240277-kafka-bootstrap.namespace-10.svc:9093', topicName='my-topic-1148419294-236744490', maxMessages=100, kafkaUsername='my-user-1467718881-1589666376', consumerGroupName='my-consumer-group-1127469558', consumerInstanceId='instance1313362005', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@27f37492}
2022-02-17 09:24:03 [ForkJoinPool-1-worker-3] INFO  [InternalKafkaClient:192] Consuming 100 messages from my-cluster-677240277-kafka-bootstrap.namespace-10.svc:9093:my-topic-1148419294-236744490 from pod my-cluster-677240277-kafka-clients-6cfbd59757-jf9bx
2022-02-17 09:24:03 [ForkJoinPool-1-worker-3] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-677240277-kafka-clients-6cfbd59757-jf9bx -n namespace-10 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1127469558 --bootstrap-server my-cluster-677240277-kafka-bootstrap.namespace-10.svc:9093 USER=my_user_1467718881_1589666376 --max-messages 100 --group-instance-id instance1313362005 --topic my-topic-1148419294-236744490
2022-02-17 09:24:10 [ForkJoinPool-1-worker-3] INFO  [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-17 09:24:10 [ForkJoinPool-1-worker-3] INFO  [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-17 09:24:10 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:24:10 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:309] Delete all resources for testCustomClusterCAClientsCA
2022-02-17 09:24:10 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of KafkaUser my-user-1467718881-1589666376 in namespace namespace-10
2022-02-17 09:24:20 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of Deployment my-cluster-677240277-kafka-clients in namespace namespace-10
2022-02-17 09:24:22 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-FINISHED
2022-02-17 09:24:22 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:24:22 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:24:22 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-STARTED
2022-02-17 09:24:23 [ForkJoinPool-1-worker-1] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:24:23 [ForkJoinPool-1-worker-1] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-11 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-02-17 09:24:23 [ForkJoinPool-1-worker-1] INFO  [KubeClusterResource:156] Creating Namespace: namespace-11
2022-02-17 09:24:23 [ForkJoinPool-1-worker-1] INFO  [KubeClusterResource:82] Client use Namespace: namespace-11
2022-02-17 09:24:23 [ForkJoinPool-1-worker-1] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-11
2022-02-17 09:24:23 [ForkJoinPool-1-worker-1] INFO  [SecurityST:601] Creating a cluster
2022-02-17 09:24:23 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-662551037 in namespace namespace-11
2022-02-17 09:24:23 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-11
2022-02-17 09:24:23 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-662551037 will have desired state: Ready
2022-02-17 09:25:00 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-1148419294-236744490 in namespace namespace-10
2022-02-17 09:25:10 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of Kafka my-cluster-677240277 in namespace namespace-10
2022-02-17 09:25:20 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:25:20 [ForkJoinPool-1-worker-3] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-10 for test case:testCustomClusterCAClientsCA
2022-02-17 09:25:53 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCustomClusterCAClientsCA-FINISHED
2022-02-17 09:25:53 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:25:53 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:25:53 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-STARTED
2022-02-17 09:25:57 [ForkJoinPool-1-worker-7] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:25:57 [ForkJoinPool-1-worker-7] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-12 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-02-17 09:25:57 [ForkJoinPool-1-worker-7] INFO  [KubeClusterResource:156] Creating Namespace: namespace-12
2022-02-17 09:25:57 [ForkJoinPool-1-worker-7] INFO  [KubeClusterResource:82] Client use Namespace: namespace-12
2022-02-17 09:25:57 [ForkJoinPool-1-worker-7] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-12
2022-02-17 09:25:57 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-245899140 in namespace namespace-12
2022-02-17 09:25:57 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-12
2022-02-17 09:25:57 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-245899140 will have desired state: Ready
2022-02-17 09:27:07 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] Kafka: my-cluster-245899140 is in desired state: Ready
2022-02-17 09:27:07 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-623043205-204601120 in namespace namespace-12
2022-02-17 09:27:07 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-12
2022-02-17 09:27:07 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-623043205-204601120 will have desired state: Ready
2022-02-17 09:27:08 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] KafkaUser: my-user-623043205-204601120 is in desired state: Ready
2022-02-17 09:27:08 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-1677417510-379342979 in namespace namespace-12
2022-02-17 09:27:08 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-12
2022-02-17 09:27:08 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-1677417510-379342979 will have desired state: Ready
2022-02-17 09:27:09 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] KafkaTopic: my-topic-1677417510-379342979 is in desired state: Ready
2022-02-17 09:27:09 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-245899140-kafka-clients in namespace namespace-12
2022-02-17 09:27:09 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-12
2022-02-17 09:27:09 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-245899140-kafka-clients will be ready
2022-02-17 09:27:11 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:168] Deployment: my-cluster-245899140-kafka-clients is ready
2022-02-17 09:27:11 [ForkJoinPool-1-worker-7] INFO  [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-17 09:27:11 [ForkJoinPool-1-worker-7] INFO  [SecurityST:811] Verifying that secret Secret(apiVersion=v1, data={ca.crt=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, ca.p12=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, ca.password=TUZjWEZSZmxGb0tU}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-02-17T09:25:59Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-245899140, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-245899140, strimzi.io/cluster=my-cluster-245899140, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[ManagedFieldsEntry(apiVersion=v1, fieldsType=FieldsV1, fieldsV1=FieldsV1(additionalProperties={f:data={.={}, f:ca.crt={}, f:ca.p12={}, f:ca.password={}}, f:metadata={f:annotations={.={}, f:strimzi.io/ca-cert-generation={}}, f:labels={.={}, f:app.kubernetes.io/instance={}, f:app.kubernetes.io/managed-by={}, f:app.kubernetes.io/name={}, f:app.kubernetes.io/part-of={}, f:strimzi.io/cluster={}, f:strimzi.io/kind={}, f:strimzi.io/name={}, f:test.case={}}, f:ownerReferences={.={}, k:{"uid":"1521f1e8-8cce-4bea-b2f0-f59e0862fcd7"}={}}}, f:type={}}), manager=okhttp, operation=Update, subresource=null, time=2022-02-17T09:25:59Z, additionalProperties={})], name=my-cluster-245899140-clients-ca-cert, namespace=namespace-12, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-245899140, uid=1521f1e8-8cce-4bea-b2f0-f59e0862fcd7, additionalProperties={})], resourceVersion=10275, selfLink=null, uid=c332fbd3-d8bd-48fc-aacf-b56dcaedca6c, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-245899140-clients-ca-cert is present
2022-02-17 09:27:11 [ForkJoinPool-1-worker-7] INFO  [SecurityST:811] Verifying that secret Secret(apiVersion=v1, data={ca.crt=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, ca.p12=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, ca.password=dXRRa0Rub3N6MHdB}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-02-17T09:25:59Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-245899140, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-245899140, strimzi.io/cluster=my-cluster-245899140, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[ManagedFieldsEntry(apiVersion=v1, fieldsType=FieldsV1, fieldsV1=FieldsV1(additionalProperties={f:data={.={}, f:ca.crt={}, f:ca.p12={}, f:ca.password={}}, f:metadata={f:annotations={.={}, f:strimzi.io/ca-cert-generation={}}, f:labels={.={}, f:app.kubernetes.io/instance={}, f:app.kubernetes.io/managed-by={}, f:app.kubernetes.io/name={}, f:app.kubernetes.io/part-of={}, f:strimzi.io/cluster={}, f:strimzi.io/kind={}, f:strimzi.io/name={}, f:test.case={}}, f:ownerReferences={.={}, k:{"uid":"1521f1e8-8cce-4bea-b2f0-f59e0862fcd7"}={}}}, f:type={}}), manager=okhttp, operation=Update, subresource=null, time=2022-02-17T09:25:59Z, additionalProperties={})], name=my-cluster-245899140-cluster-ca-cert, namespace=namespace-12, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-245899140, uid=1521f1e8-8cce-4bea-b2f0-f59e0862fcd7, additionalProperties={})], resourceVersion=10276, selfLink=null, uid=de46168d-3f9a-40b0-a75f-aed7ca91bd50, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-245899140-cluster-ca-cert is present
2022-02-17 09:27:11 [ForkJoinPool-1-worker-7] INFO  [SecurityST:816] Deleting secret my-cluster-245899140-clients-ca-cert
2022-02-17 09:27:11 [ForkJoinPool-1-worker-7] INFO  [SecurityST:816] Deleting secret my-cluster-245899140-cluster-ca-cert
2022-02-17 09:27:11 [ForkJoinPool-1-worker-7] INFO  [PodUtils:296] Verify that all pods with prefix: my-cluster-245899140-kafka are stable
2022-02-17 09:27:11 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-02-17 09:27:11 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-02-17 09:27:11 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-02-17 09:27:11 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 50
2022-02-17 09:27:12 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-02-17 09:27:12 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-02-17 09:27:12 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-02-17 09:27:12 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 49
2022-02-17 09:27:13 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-02-17 09:27:13 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-02-17 09:27:13 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-02-17 09:27:13 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 48
2022-02-17 09:27:14 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-02-17 09:27:14 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-02-17 09:27:14 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-02-17 09:27:14 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 47
2022-02-17 09:27:15 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-02-17 09:27:15 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-02-17 09:27:15 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-02-17 09:27:15 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 46
2022-02-17 09:27:16 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-02-17 09:27:16 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-02-17 09:27:16 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-02-17 09:27:16 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 45
2022-02-17 09:27:17 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-02-17 09:27:17 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-02-17 09:27:17 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-02-17 09:27:17 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 44
2022-02-17 09:27:18 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-02-17 09:27:18 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-02-17 09:27:18 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-02-17 09:27:18 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 43
2022-02-17 09:27:19 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-02-17 09:27:19 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-02-17 09:27:19 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-02-17 09:27:19 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 42
2022-02-17 09:27:20 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-02-17 09:27:20 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-02-17 09:27:20 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-02-17 09:27:20 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 41
2022-02-17 09:27:21 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-02-17 09:27:21 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-02-17 09:27:21 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-02-17 09:27:21 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 40
2022-02-17 09:27:22 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-02-17 09:27:22 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-02-17 09:27:22 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-02-17 09:27:22 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 39
2022-02-17 09:27:23 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-02-17 09:27:23 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-02-17 09:27:23 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-02-17 09:27:23 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 38
2022-02-17 09:27:24 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-02-17 09:27:24 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-02-17 09:27:24 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-02-17 09:27:24 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 37
2022-02-17 09:27:24 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] Kafka: my-cluster-662551037 is in desired state: Ready
2022-02-17 09:27:24 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-561574907-82701917 in namespace namespace-12
2022-02-17 09:27:24 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-11
2022-02-17 09:27:24 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-561574907-82701917 will have desired state: Ready
2022-02-17 09:27:25 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-02-17 09:27:25 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-02-17 09:27:25 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-02-17 09:27:25 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 36
2022-02-17 09:27:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] KafkaUser: my-user-561574907-82701917 is in desired state: Ready
2022-02-17 09:27:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-947080340-1422215235 in namespace namespace-12
2022-02-17 09:27:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-11
2022-02-17 09:27:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-947080340-1422215235 will have desired state: Ready
2022-02-17 09:27:26 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-02-17 09:27:26 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-02-17 09:27:26 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-02-17 09:27:26 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 35
2022-02-17 09:27:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] KafkaTopic: my-topic-947080340-1422215235 is in desired state: Ready
2022-02-17 09:27:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-662551037-kafka-clients in namespace namespace-12
2022-02-17 09:27:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-11
2022-02-17 09:27:26 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-662551037-kafka-clients will be ready
2022-02-17 09:27:27 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-02-17 09:27:27 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-02-17 09:27:27 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-02-17 09:27:27 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 34
2022-02-17 09:27:28 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-02-17 09:27:28 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-02-17 09:27:28 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-02-17 09:27:28 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 33
2022-02-17 09:27:28 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:168] Deployment: my-cluster-662551037-kafka-clients is ready
2022-02-17 09:27:28 [ForkJoinPool-1-worker-1] INFO  [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-17 09:27:28 [ForkJoinPool-1-worker-1] INFO  [SecurityST:274] Checking produced and consumed messages to pod:my-cluster-662551037-kafka-clients-65cfc8667d-cpjtr
2022-02-17 09:27:28 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@c0bde99, messages=[], arguments=[--bootstrap-server, my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9092, --max-messages, 100, --topic, my-topic-947080340-1422215235], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-662551037-kafka-clients-65cfc8667d-cpjtr', podNamespace='namespace-11', bootstrapServer='my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9092', topicName='my-topic-947080340-1422215235', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@56794f34}
2022-02-17 09:27:28 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:94] Producing 100 messages to my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9092:my-topic-947080340-1422215235 from pod my-cluster-662551037-kafka-clients-65cfc8667d-cpjtr
2022-02-17 09:27:28 [ForkJoinPool-1-worker-1] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-662551037-kafka-clients-65cfc8667d-cpjtr -n namespace-11 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9092 --max-messages 100 --topic my-topic-947080340-1422215235
2022-02-17 09:27:29 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-02-17 09:27:29 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-02-17 09:27:29 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-02-17 09:27:29 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 32
2022-02-17 09:27:30 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-02-17 09:27:30 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-02-17 09:27:30 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-02-17 09:27:30 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 31
2022-02-17 09:27:31 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:97] Producer finished correctly: true
2022-02-17 09:27:31 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:101] Producer produced 100 messages
2022-02-17 09:27:31 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@39077bf1, messages=[], arguments=[--group-id, my-consumer-group-278120332, --bootstrap-server, my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9092, --max-messages, 100, --group-instance-id, instance713601830, --topic, my-topic-947080340-1422215235], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-662551037-kafka-clients-65cfc8667d-cpjtr', podNamespace='namespace-11', bootstrapServer='my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9092', topicName='my-topic-947080340-1422215235', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-278120332', consumerInstanceId='instance713601830', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@251b9089}
2022-02-17 09:27:31 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9092#my-topic-947080340-1422215235 from pod my-cluster-662551037-kafka-clients-65cfc8667d-cpjtr
2022-02-17 09:27:31 [ForkJoinPool-1-worker-1] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-662551037-kafka-clients-65cfc8667d-cpjtr -n namespace-11 -- /opt/kafka/consumer.sh --group-id my-consumer-group-278120332 --bootstrap-server my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9092 --max-messages 100 --group-instance-id instance713601830 --topic my-topic-947080340-1422215235
2022-02-17 09:27:31 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-02-17 09:27:31 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-02-17 09:27:31 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-02-17 09:27:31 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 30
2022-02-17 09:27:32 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-02-17 09:27:32 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-02-17 09:27:32 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-02-17 09:27:32 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 29
2022-02-17 09:27:33 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-02-17 09:27:33 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-02-17 09:27:33 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-02-17 09:27:33 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 28
2022-02-17 09:27:34 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-02-17 09:27:34 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-02-17 09:27:34 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-02-17 09:27:34 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 27
2022-02-17 09:27:35 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-02-17 09:27:35 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-02-17 09:27:35 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-02-17 09:27:35 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 26
2022-02-17 09:27:36 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-02-17 09:27:36 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-02-17 09:27:36 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-02-17 09:27:36 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 25
2022-02-17 09:27:37 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:27:37 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:27:37 [ForkJoinPool-1-worker-1] INFO  [SecurityST:288] Triggering CA cert renewal by adding the annotation
2022-02-17 09:27:37 [ForkJoinPool-1-worker-1] INFO  [SecurityST:300] Patching secret my-cluster-662551037-cluster-ca-cert with strimzi.io/force-renew
2022-02-17 09:27:37 [ForkJoinPool-1-worker-1] INFO  [SecurityST:300] Patching secret my-cluster-662551037-clients-ca-cert with strimzi.io/force-renew
2022-02-17 09:27:37 [ForkJoinPool-1-worker-1] INFO  [SecurityST:305] Wait for zk to rolling restart ...
2022-02-17 09:27:37 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-662551037-zookeeper rolling update
2022-02-17 09:27:37 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-02-17 09:27:37 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-02-17 09:27:37 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-02-17 09:27:37 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 24
2022-02-17 09:27:38 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-02-17 09:27:38 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-02-17 09:27:38 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-02-17 09:27:38 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 23
2022-02-17 09:27:39 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-02-17 09:27:39 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-02-17 09:27:39 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-02-17 09:27:39 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 22
2022-02-17 09:27:40 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-02-17 09:27:40 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-02-17 09:27:40 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-02-17 09:27:40 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 21
2022-02-17 09:27:41 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-02-17 09:27:41 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-02-17 09:27:41 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-02-17 09:27:41 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 20
2022-02-17 09:27:42 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-02-17 09:27:42 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-02-17 09:27:42 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-02-17 09:27:42 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 19
2022-02-17 09:27:44 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-02-17 09:27:44 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-02-17 09:27:44 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-02-17 09:27:44 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 18
2022-02-17 09:27:45 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-02-17 09:27:45 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-02-17 09:27:45 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-02-17 09:27:45 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 17
2022-02-17 09:27:46 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-02-17 09:27:46 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-02-17 09:27:46 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-02-17 09:27:46 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 16
2022-02-17 09:27:47 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-02-17 09:27:47 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-02-17 09:27:47 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-02-17 09:27:47 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 15
2022-02-17 09:27:48 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-02-17 09:27:48 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-02-17 09:27:48 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-02-17 09:27:48 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 14
2022-02-17 09:27:49 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-02-17 09:27:49 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-02-17 09:27:49 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-02-17 09:27:49 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 13
2022-02-17 09:27:50 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-02-17 09:27:50 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-02-17 09:27:50 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-02-17 09:27:50 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 12
2022-02-17 09:27:51 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-02-17 09:27:51 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-02-17 09:27:51 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-02-17 09:27:51 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 11
2022-02-17 09:27:52 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-02-17 09:27:52 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-02-17 09:27:52 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-02-17 09:27:52 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 10
2022-02-17 09:27:53 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-02-17 09:27:53 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-02-17 09:27:53 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-02-17 09:27:53 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 9
2022-02-17 09:27:54 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-02-17 09:27:54 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-02-17 09:27:54 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-02-17 09:27:54 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 8
2022-02-17 09:27:55 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-02-17 09:27:55 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-02-17 09:27:55 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-02-17 09:27:55 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 7
2022-02-17 09:27:56 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-02-17 09:27:56 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-02-17 09:27:56 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-02-17 09:27:56 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 6
2022-02-17 09:27:57 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-02-17 09:27:57 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-02-17 09:27:57 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-02-17 09:27:57 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 5
2022-02-17 09:27:58 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-02-17 09:27:58 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-02-17 09:27:58 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-02-17 09:27:58 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 4
2022-02-17 09:27:59 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-02-17 09:27:59 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-02-17 09:27:59 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-02-17 09:27:59 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 3
2022-02-17 09:28:00 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-02-17 09:28:00 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-02-17 09:28:00 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-02-17 09:28:00 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 2
2022-02-17 09:28:01 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-02-17 09:28:01 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-02-17 09:28:01 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-02-17 09:28:01 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-245899140-kafka-clients-56df76c756-l74lz is in the Running state. Remaining seconds pod to be stable 1
2022-02-17 09:28:01 [ForkJoinPool-1-worker-7] INFO  [PodUtils:335] All pods are stable my-cluster-245899140-kafka-0 ,my-cluster-245899140-kafka-1 ,my-cluster-245899140-kafka-2 ,my-cluster-245899140-kafka-clients-56df76c756-l74lz
2022-02-17 09:28:01 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-245899140-kafka rolling update
2022-02-17 09:28:18 [ForkJoinPool-1-worker-5] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-1278734482-zookeeper has been successfully rolled
2022-02-17 09:28:18 [ForkJoinPool-1-worker-5] INFO  [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-1278734482-zookeeper to be ready
2022-02-17 09:28:45 [ForkJoinPool-1-worker-5] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1278734482-kafka rolling update
2022-02-17 09:28:47 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-662551037-zookeeper has been successfully rolled
2022-02-17 09:28:47 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-662551037-zookeeper to be ready
2022-02-17 09:29:06 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-245899140-kafka has been successfully rolled
2022-02-17 09:29:06 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-245899140-kafka to be ready
2022-02-17 09:29:17 [ForkJoinPool-1-worker-1] INFO  [SecurityST:309] Wait for kafka to rolling restart ...
2022-02-17 09:29:17 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-662551037-kafka rolling update
2022-02-17 09:29:33 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-245899140 will have desired state: Ready
2022-02-17 09:29:33 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] Kafka: my-cluster-245899140 is in desired state: Ready
2022-02-17 09:29:33 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:132] Kafka: my-cluster-245899140 is ready
2022-02-17 09:29:33 [ForkJoinPool-1-worker-7] INFO  [SecretUtils:46] Waiting for Secret my-cluster-245899140-clients-ca-cert
2022-02-17 09:29:33 [ForkJoinPool-1-worker-7] INFO  [SecretUtils:50] Secret my-cluster-245899140-clients-ca-cert created
2022-02-17 09:29:33 [ForkJoinPool-1-worker-7] INFO  [SecretUtils:46] Waiting for Secret my-cluster-245899140-cluster-ca-cert
2022-02-17 09:29:33 [ForkJoinPool-1-worker-7] INFO  [SecretUtils:50] Secret my-cluster-245899140-cluster-ca-cert created
2022-02-17 09:29:33 [ForkJoinPool-1-worker-7] INFO  [SecurityST:835] Checking consumed messages to pod:my-cluster-245899140-kafka-clients-56df76c756-l74lz
2022-02-17 09:29:33 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2c301db3, messages=[], arguments=[--bootstrap-server, my-cluster-245899140-kafka-bootstrap.namespace-12.svc:9093, USER=my_user_623043205_204601120, --max-messages, 100, --topic, my-topic-1677417510-379342979], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-245899140-kafka-clients-56df76c756-l74lz', podNamespace='namespace-12', bootstrapServer='my-cluster-245899140-kafka-bootstrap.namespace-12.svc:9093', topicName='my-topic-1677417510-379342979', maxMessages=100, kafkaUsername='my-user-623043205-204601120', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@715bfe2d}
2022-02-17 09:29:33 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:124] Producing 100 messages to my-cluster-245899140-kafka-bootstrap.namespace-12.svc:9093:my-topic-1677417510-379342979 from pod my-cluster-245899140-kafka-clients-56df76c756-l74lz
2022-02-17 09:29:33 [ForkJoinPool-1-worker-7] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-245899140-kafka-clients-56df76c756-l74lz -n namespace-12 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-245899140-kafka-bootstrap.namespace-12.svc:9093 USER=my_user_623043205_204601120 --max-messages 100 --topic my-topic-1677417510-379342979
2022-02-17 09:29:35 [ForkJoinPool-1-worker-5] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-1278734482-kafka has been successfully rolled
2022-02-17 09:29:35 [ForkJoinPool-1-worker-5] INFO  [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-1278734482-kafka to be ready
2022-02-17 09:29:37 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:127] Producer finished correctly: true
2022-02-17 09:29:37 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:131] Producer produced 100 messages
2022-02-17 09:29:37 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@21c5c228, messages=[], arguments=[--group-id, my-consumer-group-1044909145, --bootstrap-server, my-cluster-245899140-kafka-bootstrap.namespace-12.svc:9093, USER=my_user_623043205_204601120, --max-messages, 100, --group-instance-id, instance1285289237, --topic, my-topic-1677417510-379342979], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-245899140-kafka-clients-56df76c756-l74lz', podNamespace='namespace-12', bootstrapServer='my-cluster-245899140-kafka-bootstrap.namespace-12.svc:9093', topicName='my-topic-1677417510-379342979', maxMessages=100, kafkaUsername='my-user-623043205-204601120', consumerGroupName='my-consumer-group-1044909145', consumerInstanceId='instance1285289237', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@fc1ef6b}
2022-02-17 09:29:37 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:192] Consuming 100 messages from my-cluster-245899140-kafka-bootstrap.namespace-12.svc:9093:my-topic-1677417510-379342979 from pod my-cluster-245899140-kafka-clients-56df76c756-l74lz
2022-02-17 09:29:37 [ForkJoinPool-1-worker-7] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-245899140-kafka-clients-56df76c756-l74lz -n namespace-12 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1044909145 --bootstrap-server my-cluster-245899140-kafka-bootstrap.namespace-12.svc:9093 USER=my_user_623043205_204601120 --max-messages 100 --group-instance-id instance1285289237 --topic my-topic-1677417510-379342979
2022-02-17 09:29:44 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-17 09:29:44 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-17 09:29:44 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:29:44 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:309] Delete all resources for testCertRegeneratedAfterInternalCAisDeleted
2022-02-17 09:29:44 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-1677417510-379342979 in namespace namespace-12
2022-02-17 09:29:54 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of Deployment my-cluster-245899140-kafka-clients in namespace namespace-12
2022-02-17 09:30:04 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-1278734482-entity-operator rolling update
2022-02-17 09:30:04 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-1278734482-entity-operator will be ready
2022-02-17 09:30:07 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-662551037-kafka has been successfully rolled
2022-02-17 09:30:07 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-662551037-kafka to be ready
2022-02-17 09:30:34 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of KafkaUser my-user-623043205-204601120 in namespace namespace-12
2022-02-17 09:30:34 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of Kafka my-cluster-245899140 in namespace namespace-12
2022-02-17 09:30:38 [ForkJoinPool-1-worker-1] INFO  [SecurityST:313] Wait for EO to rolling restart ...
2022-02-17 09:30:38 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-662551037-entity-operator rolling update
2022-02-17 09:30:38 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-662551037-entity-operator will be ready
2022-02-17 09:30:44 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:30:44 [ForkJoinPool-1-worker-7] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-12 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-02-17 09:30:46 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:168] Deployment: my-cluster-1278734482-entity-operator is ready
2022-02-17 09:30:56 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:141] Deployment my-cluster-1278734482-entity-operator rolling update finished
2022-02-17 09:30:56 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1272] Checking produced and consumed messages to pod:my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql
2022-02-17 09:30:56 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4b82e1d7, messages=[], arguments=[--group-id, my-consumer-group-1309537225, --bootstrap-server, my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093, USER=my_user_2070712369_1323600697, --max-messages, 100, --group-instance-id, instance118973942, --topic, my-topic-696188601-613781114], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql', podNamespace='namespace-9', bootstrapServer='my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093', topicName='my-topic-696188601-613781114', maxMessages=100, kafkaUsername='my-user-2070712369-1323600697', consumerGroupName='my-consumer-group-1309537225', consumerInstanceId='instance118973942', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@443ac439}
2022-02-17 09:30:56 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:192] Consuming 100 messages from my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093:my-topic-696188601-613781114 from pod my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql
2022-02-17 09:30:56 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql -n namespace-9 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1309537225 --bootstrap-server my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093 USER=my_user_2070712369_1323600697 --max-messages 100 --group-instance-id instance118973942 --topic my-topic-696188601-613781114
2022-02-17 09:31:03 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-17 09:31:03 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-17 09:31:03 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-1543170048-156377541 in namespace namespace-12
2022-02-17 09:31:03 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-9
2022-02-17 09:31:03 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-1543170048-156377541 will have desired state: Ready
2022-02-17 09:31:04 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] KafkaTopic: my-topic-1543170048-156377541 is in desired state: Ready
2022-02-17 09:31:04 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@32f7bb19, messages=[], arguments=[--bootstrap-server, my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093, USER=my_user_2070712369_1323600697, --max-messages, 100, --topic, my-topic-1543170048-156377541], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql', podNamespace='namespace-9', bootstrapServer='my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093', topicName='my-topic-1543170048-156377541', maxMessages=100, kafkaUsername='my-user-2070712369-1323600697', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@491e08c0}
2022-02-17 09:31:04 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:124] Producing 100 messages to my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093:my-topic-1543170048-156377541 from pod my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql
2022-02-17 09:31:04 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql -n namespace-9 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093 USER=my_user_2070712369_1323600697 --max-messages 100 --topic my-topic-1543170048-156377541
2022-02-17 09:31:07 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:127] Producer finished correctly: true
2022-02-17 09:31:07 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:131] Producer produced 100 messages
2022-02-17 09:31:07 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7c2e6bf3, messages=[], arguments=[--group-id, my-consumer-group-229413700, --bootstrap-server, my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093, USER=my_user_2070712369_1323600697, --max-messages, 100, --group-instance-id, instance2024739588, --topic, my-topic-1543170048-156377541], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql', podNamespace='namespace-9', bootstrapServer='my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093', topicName='my-topic-1543170048-156377541', maxMessages=100, kafkaUsername='my-user-2070712369-1323600697', consumerGroupName='my-consumer-group-229413700', consumerInstanceId='instance2024739588', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@207eaa72}
2022-02-17 09:31:07 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:192] Consuming 100 messages from my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093:my-topic-1543170048-156377541 from pod my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql
2022-02-17 09:31:07 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-1278734482-kafka-clients-7c5445bb85-2dlql -n namespace-9 -- /opt/kafka/consumer.sh --group-id my-consumer-group-229413700 --bootstrap-server my-cluster-1278734482-kafka-bootstrap.namespace-9.svc:9093 USER=my_user_2070712369_1323600697 --max-messages 100 --group-instance-id instance2024739588 --topic my-topic-1543170048-156377541
2022-02-17 09:31:14 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-17 09:31:14 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-17 09:31:14 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:31:14 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:309] Delete all resources for testCaRenewalBreakInMiddle
2022-02-17 09:31:14 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-696188601-613781114 in namespace namespace-9
2022-02-17 09:31:20 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:168] Deployment: my-cluster-662551037-entity-operator is ready
2022-02-17 09:31:24 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-1543170048-156377541 in namespace namespace-9
2022-02-17 09:31:28 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-FINISHED
2022-02-17 09:31:28 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:31:28 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:31:28 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-STARTED
2022-02-17 09:31:30 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:141] Deployment my-cluster-662551037-entity-operator rolling update finished
2022-02-17 09:31:30 [ForkJoinPool-1-worker-1] INFO  [SecurityST:317] Wait for CC and KE to rolling restart ...
2022-02-17 09:31:30 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-662551037-kafka-exporter rolling update
2022-02-17 09:31:33 [ForkJoinPool-1-worker-3] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:31:33 [ForkJoinPool-1-worker-3] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-13 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-02-17 09:31:33 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:156] Creating Namespace: namespace-13
2022-02-17 09:31:33 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:82] Client use Namespace: namespace-13
2022-02-17 09:31:33 [ForkJoinPool-1-worker-3] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-13
2022-02-17 09:31:33 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-692170219 in namespace namespace-13
2022-02-17 09:31:33 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-13
2022-02-17 09:31:33 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-692170219 will have desired state: Ready
2022-02-17 09:31:34 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of Deployment my-cluster-1278734482-kafka-clients in namespace namespace-9
2022-02-17 09:32:14 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of KafkaUser my-user-2070712369-1323600697 in namespace namespace-9
2022-02-17 09:32:14 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of Kafka my-cluster-1278734482 in namespace namespace-9
2022-02-17 09:32:15 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-662551037-kafka-exporter will be ready
2022-02-17 09:32:15 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:168] Deployment: my-cluster-662551037-kafka-exporter is ready
2022-02-17 09:32:24 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:32:24 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-9 for test case:testCaRenewalBreakInMiddle
2022-02-17 09:32:25 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:141] Deployment my-cluster-662551037-kafka-exporter rolling update finished
2022-02-17 09:32:25 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-662551037-cruise-control rolling update
2022-02-17 09:32:25 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-662551037-cruise-control will be ready
2022-02-17 09:32:25 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:168] Deployment: my-cluster-662551037-cruise-control is ready
2022-02-17 09:32:35 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:141] Deployment my-cluster-662551037-cruise-control rolling update finished
2022-02-17 09:32:35 [ForkJoinPool-1-worker-1] INFO  [SecurityST:322] Checking the certificates have been replaced
2022-02-17 09:32:35 [ForkJoinPool-1-worker-1] INFO  [SecurityST:336] Checking consumed messages to pod:my-cluster-662551037-kafka-clients-65cfc8667d-cpjtr
2022-02-17 09:32:35 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3610c662, messages=[], arguments=[--group-id, my-consumer-group-498514393, --bootstrap-server, my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9092, --max-messages, 100, --group-instance-id, instance132291334, --topic, my-topic-947080340-1422215235], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-662551037-kafka-clients-65cfc8667d-cpjtr', podNamespace='namespace-11', bootstrapServer='my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9092', topicName='my-topic-947080340-1422215235', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-498514393', consumerInstanceId='instance132291334', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@33f63111}
2022-02-17 09:32:35 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9092#my-topic-947080340-1422215235 from pod my-cluster-662551037-kafka-clients-65cfc8667d-cpjtr
2022-02-17 09:32:35 [ForkJoinPool-1-worker-1] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-662551037-kafka-clients-65cfc8667d-cpjtr -n namespace-11 -- /opt/kafka/consumer.sh --group-id my-consumer-group-498514393 --bootstrap-server my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9092 --max-messages 100 --group-instance-id instance132291334 --topic my-topic-947080340-1422215235
2022-02-17 09:32:41 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:32:41 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:32:41 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update KafkaUser bob-my-cluster-662551037 in namespace namespace-13
2022-02-17 09:32:41 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-11
2022-02-17 09:32:41 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for KafkaUser: bob-my-cluster-662551037 will have desired state: Ready
2022-02-17 09:32:42 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] KafkaUser: bob-my-cluster-662551037 is in desired state: Ready
2022-02-17 09:32:42 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-662551037-kafka-clients-tls in namespace namespace-11
2022-02-17 09:32:42 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-11
2022-02-17 09:32:42 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-662551037-kafka-clients-tls will be ready
2022-02-17 09:32:44 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:168] Deployment: my-cluster-662551037-kafka-clients-tls is ready
2022-02-17 09:32:44 [ForkJoinPool-1-worker-1] INFO  [SecurityST:360] Checking consumed messages to pod:my-cluster-662551037-kafka-clients-tls-67cd485fcc-5ddzr
2022-02-17 09:32:44 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7e8c9b8c, messages=[], arguments=[--group-id, my-consumer-group-357198304, --bootstrap-server, my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9093, USER=bob_my_cluster_662551037, --max-messages, 100, --group-instance-id, instance68467216, --topic, my-topic-947080340-1422215235], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-662551037-kafka-clients-tls-67cd485fcc-5ddzr', podNamespace='namespace-11', bootstrapServer='my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9093', topicName='my-topic-947080340-1422215235', maxMessages=100, kafkaUsername='bob-my-cluster-662551037', consumerGroupName='my-consumer-group-357198304', consumerInstanceId='instance68467216', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@2829caa2}
2022-02-17 09:32:44 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9093#my-topic-947080340-1422215235 from pod my-cluster-662551037-kafka-clients-tls-67cd485fcc-5ddzr
2022-02-17 09:32:44 [ForkJoinPool-1-worker-1] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-662551037-kafka-clients-tls-67cd485fcc-5ddzr -n namespace-11 -- /opt/kafka/consumer.sh --group-id my-consumer-group-357198304 --bootstrap-server my-cluster-662551037-kafka-bootstrap.namespace-11.svc:9093 USER=bob_my_cluster_662551037 --max-messages 100 --group-instance-id instance68467216 --topic my-topic-947080340-1422215235
2022-02-17 09:32:44 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:405] Kafka: my-cluster-692170219 is in desired state: Ready
2022-02-17 09:32:44 [ForkJoinPool-1-worker-3] INFO  [SecurityST:852] Getting IP of the bootstrap service
2022-02-17 09:32:44 [ForkJoinPool-1-worker-3] INFO  [SecurityST:856] KafkaConnect without config ssl.endpoint.identification.algorithm will not connect to 10.109.10.180:9093
2022-02-17 09:32:44 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-692170219-kafka-clients in namespace namespace-13
2022-02-17 09:32:44 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-13
2022-02-17 09:32:44 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-692170219-kafka-clients will be ready
2022-02-17 09:32:46 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:168] Deployment: my-cluster-692170219-kafka-clients is ready
2022-02-17 09:32:46 [ForkJoinPool-1-worker-3] INFO  [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-692170219-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-02-17 09:32:46 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update NetworkPolicy my-cluster-692170219-allow in namespace namespace-13
2022-02-17 09:32:46 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-13
2022-02-17 09:32:46 [ForkJoinPool-1-worker-3] INFO  [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-02-17 09:32:46 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update KafkaConnect my-cluster-692170219 in namespace namespace-13
2022-02-17 09:32:46 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-13
2022-02-17 09:32:46 [ForkJoinPool-1-worker-3] WARN  [VersionUsageUtils:60] The client is using resource type 'kafkaconnects' with unstable version 'v1beta2'
2022-02-17 09:32:46 [ForkJoinPool-1-worker-3] INFO  [PodUtils:245] Wait until Pod my-cluster-692170219-connect is present
2022-02-17 09:32:47 [ForkJoinPool-1-worker-3] INFO  [PodUtils:249] Pod my-cluster-692170219-connect is present
2022-02-17 09:32:48 [ForkJoinPool-1-worker-3] INFO  [PodUtils:236] Wait until Pod my-cluster-692170219-connect-58d848c97c-xwfrr is in CrashLoopBackOff state
2022-02-17 09:32:51 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:32:51 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:32:51 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:32:51 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:309] Delete all resources for testAutoRenewAllCaCertsTriggeredByAnno
2022-02-17 09:32:51 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of Deployment my-cluster-662551037-kafka-clients in namespace namespace-11
2022-02-17 09:33:07 [ForkJoinPool-1-worker-3] INFO  [PodUtils:241] Pod my-cluster-692170219-connect-58d848c97c-xwfrr is in CrashLoopBackOff state
2022-02-17 09:33:07 [ForkJoinPool-1-worker-3] INFO  [SecurityST:886] KafkaConnect with config ssl.endpoint.identification.algorithm will connect to 10.109.10.180:9093
2022-02-17 09:33:07 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:394] Wait for KafkaConnect: my-cluster-692170219 will have desired state: Ready
2022-02-17 09:33:08 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-FINISHED
2022-02-17 09:33:08 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:33:08 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:33:08 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAclRuleReadAndWrite-STARTED
2022-02-17 09:33:08 [ForkJoinPool-1-worker-7] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:33:08 [ForkJoinPool-1-worker-7] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-14 for test case:testKafkaAndKafkaConnectCipherSuites
2022-02-17 09:33:08 [ForkJoinPool-1-worker-7] INFO  [KubeClusterResource:156] Creating Namespace: namespace-14
2022-02-17 09:33:08 [ForkJoinPool-1-worker-7] INFO  [KubeClusterResource:82] Client use Namespace: namespace-14
2022-02-17 09:33:08 [ForkJoinPool-1-worker-7] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-14
2022-02-17 09:33:08 [ForkJoinPool-1-worker-7] INFO  [SecurityST:1385] Deploying Kafka cluster with the support TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 cipher algorithms
2022-02-17 09:33:08 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-1172092675 in namespace namespace-14
2022-02-17 09:33:08 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-14
2022-02-17 09:33:08 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1172092675 will have desired state: Ready
2022-02-17 09:34:11 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of Deployment my-cluster-662551037-kafka-clients-tls in namespace namespace-11
2022-02-17 09:34:11 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of KafkaUser bob-my-cluster-662551037 in namespace namespace-11
2022-02-17 09:34:11 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of KafkaUser my-user-561574907-82701917 in namespace namespace-11
2022-02-17 09:34:19 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] Kafka: my-cluster-1172092675 is in desired state: Ready
2022-02-17 09:34:19 [ForkJoinPool-1-worker-7] INFO  [SecurityST:1397] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-02-17 09:34:19 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-1172092675-kafka-clients in namespace namespace-14
2022-02-17 09:34:19 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-14
2022-02-17 09:34:19 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-1172092675-kafka-clients will be ready
2022-02-17 09:34:21 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-947080340-1422215235 in namespace namespace-11
2022-02-17 09:34:21 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:168] Deployment: my-cluster-1172092675-kafka-clients is ready
2022-02-17 09:34:21 [ForkJoinPool-1-worker-7] INFO  [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-1172092675-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-02-17 09:34:21 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update NetworkPolicy my-cluster-1172092675-allow in namespace namespace-14
2022-02-17 09:34:21 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-14
2022-02-17 09:34:21 [ForkJoinPool-1-worker-7] INFO  [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-02-17 09:34:21 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update KafkaConnect my-cluster-1172092675 in namespace namespace-14
2022-02-17 09:34:21 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-14
2022-02-17 09:34:21 [ForkJoinPool-1-worker-7] INFO  [SecurityST:1414] Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm
2022-02-17 09:34:21 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for KafkaConnect: my-cluster-1172092675 will have desired state: NotReady
2022-02-17 09:34:31 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of Kafka my-cluster-662551037 in namespace namespace-11
2022-02-17 09:34:31 [ForkJoinPool-1-worker-1] INFO  [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-11, for cruise control Kafka cluster my-cluster-662551037
2022-02-17 09:34:41 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:34:41 [ForkJoinPool-1-worker-1] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-11 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-02-17 09:35:24 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-FINISHED
2022-02-17 09:35:24 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:35:24 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:35:24 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-STARTED
2022-02-17 09:35:28 [ForkJoinPool-1-worker-5] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:35:28 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-15 for test case:testAclRuleReadAndWrite
2022-02-17 09:35:28 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:156] Creating Namespace: namespace-15
2022-02-17 09:35:28 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:82] Client use Namespace: namespace-15
2022-02-17 09:35:28 [ForkJoinPool-1-worker-5] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-15
2022-02-17 09:35:28 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-241732185 in namespace namespace-15
2022-02-17 09:35:28 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-15
2022-02-17 09:35:28 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-241732185 will have desired state: Ready
2022-02-17 09:36:42 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] Kafka: my-cluster-241732185 is in desired state: Ready
2022-02-17 09:36:42 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-1936982337-644622290 in namespace namespace-15
2022-02-17 09:36:42 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-15
2022-02-17 09:36:42 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-1936982337-644622290 will have desired state: Ready
2022-02-17 09:36:43 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] KafkaTopic: my-topic-1936982337-644622290 is in desired state: Ready
2022-02-17 09:36:43 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update KafkaUser kafka-user-write in namespace namespace-15
2022-02-17 09:36:43 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-15
2022-02-17 09:36:43 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for KafkaUser: kafka-user-write will have desired state: Ready
2022-02-17 09:36:44 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] KafkaUser: kafka-user-write is in desired state: Ready
2022-02-17 09:36:44 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1010] Checking KafkaUser kafka-user-write that is able to send messages to topic 'my-topic-1936982337-644622290'
2022-02-17 09:36:44 [ForkJoinPool-1-worker-5] INFO  [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-17 09:36:44 [ForkJoinPool-1-worker-5] INFO  [ProducerConfig:376] ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.49.2:30536]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1296278815
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 6000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties14146383948897239588.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties14421532734706792208.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-02-17 09:36:44 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:119] Kafka version: 3.1.0
2022-02-17 09:36:44 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-17 09:36:44 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:121] Kafka startTimeMs: 1645090604775
2022-02-17 09:36:44 [kafka-producer-network-thread | producer-1296278815] INFO  [Metadata:402] [Producer clientId=producer-1296278815] Resetting the last seen epoch of partition my-topic-1936982337-644622290-0 to 0 since the associated topicId changed from null to rEK4Fe3wTMqK6jnWdwjlCw
2022-02-17 09:36:44 [kafka-producer-network-thread | producer-1296278815] INFO  [Metadata:287] [Producer clientId=producer-1296278815] Cluster ID: qcMvJ5xyTNmpQB6BQVILjg
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [ExternalKafkaClient:182] Sent 500 messages.
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [KafkaProducer:1228] [Producer clientId=producer-1296278815] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [Metrics:659] Metrics scheduler closed
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [Metrics:669] Metrics reporters closed
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:83] App info kafka.producer for producer-1296278815 unregistered
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [ConsumerConfig:376] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.49.2:30536]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-1010594386
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-1229540560
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties9377718444241259302.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties15624521662375249494.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:119] Kafka version: 3.1.0
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:121] Kafka startTimeMs: 1645090605691
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [KafkaConsumer:966] [Consumer clientId=consumer-1010594386, groupId=my-consumer-group-1229540560] Subscribed to topic(s): my-topic-1936982337-644622290
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [Metadata:402] [Consumer clientId=consumer-1010594386, groupId=my-consumer-group-1229540560] Resetting the last seen epoch of partition my-topic-1936982337-644622290-0 to 0 since the associated topicId changed from null to rEK4Fe3wTMqK6jnWdwjlCw
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [Metadata:287] [Consumer clientId=consumer-1010594386, groupId=my-consumer-group-1229540560] Cluster ID: qcMvJ5xyTNmpQB6BQVILjg
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:261] [Consumer clientId=consumer-1010594386, groupId=my-consumer-group-1229540560] FindCoordinator request hit fatal exception
org.apache.kafka.common.errors.GroupAuthorizationException: Not authorized to access group: my-consumer-group-1229540560
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update KafkaUser kafka-user-read in namespace namespace-15
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-15
2022-02-17 09:36:45 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for KafkaUser: kafka-user-read will have desired state: Ready
2022-02-17 09:36:46 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] KafkaUser: kafka-user-read is in desired state: Ready
2022-02-17 09:36:46 [ForkJoinPool-1-worker-5] INFO  [ConsumerConfig:376] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [192.168.49.2:30536]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-1759024080
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = consumer-group-name-1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties10401588568471276727.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties4035995569928943135.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-02-17 09:36:46 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:119] Kafka version: 3.1.0
2022-02-17 09:36:46 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-17 09:36:46 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:121] Kafka startTimeMs: 1645090606844
2022-02-17 09:36:46 [ForkJoinPool-1-worker-5] INFO  [KafkaConsumer:966] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Subscribed to topic(s): my-topic-1936982337-644622290
2022-02-17 09:36:46 [ForkJoinPool-1-worker-5] INFO  [Metadata:402] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Resetting the last seen epoch of partition my-topic-1936982337-644622290-0 to 0 since the associated topicId changed from null to rEK4Fe3wTMqK6jnWdwjlCw
2022-02-17 09:36:46 [ForkJoinPool-1-worker-5] INFO  [Metadata:287] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Cluster ID: qcMvJ5xyTNmpQB6BQVILjg
2022-02-17 09:36:46 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:853] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Discovered group coordinator 192.168.49.2:31884 (id: 2147483645 rack: null)
2022-02-17 09:36:46 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:535] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] (Re-)joining group
2022-02-17 09:36:46 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:1000] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Request joining group due to: need to re-join with the given member-id
2022-02-17 09:36:46 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:535] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] (Re-)joining group
2022-02-17 09:36:49 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:595] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Successfully joined group with generation Generation{generationId=1, memberId='consumer-1759024080-ca3721ee-2118-4004-9a13-3e3aa3be2509', protocol='range'}
2022-02-17 09:36:49 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:652] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Finished assignment for group at generation 1: {consumer-1759024080-ca3721ee-2118-4004-9a13-3e3aa3be2509=Assignment(partitions=[my-topic-1936982337-644622290-0])}
2022-02-17 09:36:49 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:761] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Successfully synced group in generation Generation{generationId=1, memberId='consumer-1759024080-ca3721ee-2118-4004-9a13-3e3aa3be2509', protocol='range'}
2022-02-17 09:36:49 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:279] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Notifying assignor about the new Assignment(partitions=[my-topic-1936982337-644622290-0])
2022-02-17 09:36:49 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:291] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Adding newly assigned partitions: my-topic-1936982337-644622290-0
2022-02-17 09:36:49 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:1388] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Found no committed offset for partition my-topic-1936982337-644622290-0
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [SubscriptionState:398] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Resetting offset for partition my-topic-1936982337-644622290-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.49.2:32516 (id: 1 rack: null)], epoch=0}}.
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [ExternalKafkaClient:224] Received 500 messages.
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:310] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Revoke previously assigned partitions my-topic-1936982337-644622290-0
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:1060] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Member consumer-1759024080-ca3721ee-2118-4004-9a13-3e3aa3be2509 sending LeaveGroup request to coordinator 192.168.49.2:31884 (id: 2147483645 rack: null) due to the consumer is being closed
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:972] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Resetting generation due to: consumer pro-actively leaving the group
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [ConsumerCoordinator:1000] [Consumer clientId=consumer-1759024080, groupId=consumer-group-name-1] Request joining group due to: consumer pro-actively leaving the group
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [Metrics:659] Metrics scheduler closed
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [Metrics:669] Metrics reporters closed
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:83] App info kafka.consumer for consumer-1759024080 unregistered
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1058] Checking KafkaUser kafka-user-read that is not able to send messages to topic 'my-topic-1936982337-644622290'
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [ProducerConfig:376] ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [192.168.49.2:30536]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-681786953
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 6000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = 
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = 
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties1445272178750954613.keystore
	ssl.keystore.password = [hidden]
	ssl.keystore.type = PKCS12
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = /tmp/io.strimzi.systemtest.kafkaclients.clientproperties.AbstractKafkaClientProperties11348084364093862215.truststore
	ssl.truststore.password = [hidden]
	ssl.truststore.type = PKCS12
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:119] Kafka version: 3.1.0
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:121] Kafka startTimeMs: 1645090610200
2022-02-17 09:36:50 [kafka-producer-network-thread | producer-681786953] INFO  [Metadata:402] [Producer clientId=producer-681786953] Resetting the last seen epoch of partition my-topic-1936982337-644622290-0 to 0 since the associated topicId changed from null to rEK4Fe3wTMqK6jnWdwjlCw
2022-02-17 09:36:50 [kafka-producer-network-thread | producer-681786953] INFO  [Metadata:287] [Producer clientId=producer-681786953] Cluster ID: qcMvJ5xyTNmpQB6BQVILjg
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] ERROR [ExternalKafkaClient:171] Error sending message 0 - org.apache.kafka.common.errors.TopicAuthorizationException: Not authorized to access topics: [my-topic-1936982337-644622290]
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [KafkaProducer:1228] [Producer clientId=producer-681786953] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [Metrics:659] Metrics scheduler closed
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [Metrics:669] Metrics reporters closed
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [AppInfoParser:83] App info kafka.producer for producer-681786953 unregistered
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:309] Delete all resources for testAclRuleReadAndWrite
2022-02-17 09:36:50 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of KafkaUser kafka-user-write in namespace namespace-15
2022-02-17 09:37:00 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of KafkaUser kafka-user-read in namespace namespace-15
2022-02-17 09:37:10 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-1936982337-644622290 in namespace namespace-15
2022-02-17 09:37:20 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of Kafka my-cluster-241732185 in namespace namespace-15
2022-02-17 09:37:30 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:37:30 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-15 for test case:testAclRuleReadAndWrite
2022-02-17 09:38:13 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAclRuleReadAndWrite-FINISHED
2022-02-17 09:38:13 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:38:13 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:38:13 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-STARTED
2022-02-17 09:38:14 [ForkJoinPool-1-worker-1] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:38:14 [ForkJoinPool-1-worker-1] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-16 for test case:testCertRenewalInMaintenanceWindow
2022-02-17 09:38:14 [ForkJoinPool-1-worker-1] INFO  [KubeClusterResource:156] Creating Namespace: namespace-16
2022-02-17 09:38:14 [ForkJoinPool-1-worker-1] INFO  [KubeClusterResource:82] Client use Namespace: namespace-16
2022-02-17 09:38:14 [ForkJoinPool-1-worker-1] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-16
2022-02-17 09:38:14 [ForkJoinPool-1-worker-1] INFO  [SecurityST:712] Maintenance window is: * 43-57 * * * ? *
2022-02-17 09:38:14 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-1993793092 in namespace namespace-16
2022-02-17 09:38:14 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-16
2022-02-17 09:38:14 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1993793092 will have desired state: Ready
2022-02-17 09:38:59 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:405] KafkaConnect: my-cluster-692170219 is in desired state: Ready
2022-02-17 09:38:59 [ForkJoinPool-1-worker-3] WARN  [DeploymentUtils:213] Deployment my-cluster-692170219-connect is not deleted yet! Triggering force delete by cmd client!
2022-02-17 09:39:04 [ForkJoinPool-1-worker-3] WARN  [DeploymentUtils:213] Deployment my-cluster-692170219-connect is not deleted yet! Triggering force delete by cmd client!
2022-02-17 09:39:09 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:39:09 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:309] Delete all resources for testTlsHostnameVerificationWithKafkaConnect
2022-02-17 09:39:09 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of NetworkPolicy my-cluster-692170219-allow in namespace namespace-13
2022-02-17 09:39:09 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of KafkaConnect my-cluster-692170219 in namespace namespace-13
2022-02-17 09:39:19 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of Deployment my-cluster-692170219-kafka-clients in namespace namespace-13
2022-02-17 09:39:23 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] KafkaConnect: my-cluster-1172092675 is in desired state: NotReady
2022-02-17 09:39:23 [ForkJoinPool-1-worker-7] INFO  [SecurityST:1418] Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.
2022-02-17 09:39:23 [ForkJoinPool-1-worker-7] INFO  [SecurityST:1422] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-02-17 09:39:23 [ForkJoinPool-1-worker-7] INFO  [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-02-17 09:39:23 [ForkJoinPool-1-worker-7] INFO  [KafkaConnectUtils:109] Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-02-17 09:39:23 [ForkJoinPool-1-worker-7] INFO  [SecurityST:1427] Verifying that Kafka Connect is stable
2022-02-17 09:39:23 [ForkJoinPool-1-worker-7] INFO  [PodUtils:296] Verify that all pods with prefix: my-cluster-1172092675-connect are stable
2022-02-17 09:39:23 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 50
2022-02-17 09:39:24 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 49
2022-02-17 09:39:24 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] Kafka: my-cluster-1993793092 is in desired state: Ready
2022-02-17 09:39:24 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-1053915362-1833089503 in namespace namespace-16
2022-02-17 09:39:24 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-16
2022-02-17 09:39:24 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-1053915362-1833089503 will have desired state: Ready
2022-02-17 09:39:25 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 48
2022-02-17 09:39:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] KafkaUser: my-user-1053915362-1833089503 is in desired state: Ready
2022-02-17 09:39:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-1441128375-1517160289 in namespace namespace-16
2022-02-17 09:39:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-16
2022-02-17 09:39:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-1441128375-1517160289 will have desired state: Ready
2022-02-17 09:39:26 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 47
2022-02-17 09:39:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] KafkaTopic: my-topic-1441128375-1517160289 is in desired state: Ready
2022-02-17 09:39:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-1441128375-1517160289 in namespace namespace-16
2022-02-17 09:39:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-16
2022-02-17 09:39:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-1441128375-1517160289 will have desired state: Ready
2022-02-17 09:39:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] KafkaTopic: my-topic-1441128375-1517160289 is in desired state: Ready
2022-02-17 09:39:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-1993793092-kafka-clients in namespace namespace-16
2022-02-17 09:39:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-16
2022-02-17 09:39:26 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-1993793092-kafka-clients will be ready
2022-02-17 09:39:27 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 46
2022-02-17 09:39:28 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 45
2022-02-17 09:39:28 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:168] Deployment: my-cluster-1993793092-kafka-clients is ready
2022-02-17 09:39:28 [ForkJoinPool-1-worker-1] INFO  [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-17 09:39:28 [ForkJoinPool-1-worker-1] INFO  [SecurityST:742] Annotate secret my-cluster-1993793092-cluster-ca-cert with secret force-renew annotation
2022-02-17 09:39:28 [ForkJoinPool-1-worker-1] INFO  [SecurityST:749] Wait until maintenance windows starts
2022-02-17 09:39:29 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 44
2022-02-17 09:39:30 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 43
2022-02-17 09:39:31 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 42
2022-02-17 09:39:32 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 41
2022-02-17 09:39:33 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 40
2022-02-17 09:39:34 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 39
2022-02-17 09:39:35 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 38
2022-02-17 09:39:36 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 37
2022-02-17 09:39:37 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 36
2022-02-17 09:39:38 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 35
2022-02-17 09:39:39 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 34
2022-02-17 09:39:40 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 33
2022-02-17 09:39:41 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 32
2022-02-17 09:39:42 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 31
2022-02-17 09:39:43 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 30
2022-02-17 09:39:44 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 29
2022-02-17 09:39:45 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 28
2022-02-17 09:39:46 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 27
2022-02-17 09:39:47 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 26
2022-02-17 09:39:48 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 25
2022-02-17 09:39:49 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 24
2022-02-17 09:39:50 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 23
2022-02-17 09:39:51 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 22
2022-02-17 09:39:52 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 21
2022-02-17 09:39:53 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 20
2022-02-17 09:39:54 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 19
2022-02-17 09:39:55 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 18
2022-02-17 09:39:56 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 17
2022-02-17 09:39:57 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 16
2022-02-17 09:39:58 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 15
2022-02-17 09:39:59 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 14
2022-02-17 09:39:59 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of Kafka my-cluster-692170219 in namespace namespace-13
2022-02-17 09:40:00 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 13
2022-02-17 09:40:01 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 12
2022-02-17 09:40:02 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 11
2022-02-17 09:40:03 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 10
2022-02-17 09:40:04 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 9
2022-02-17 09:40:05 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 8
2022-02-17 09:40:06 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 7
2022-02-17 09:40:07 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 6
2022-02-17 09:40:08 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 5
2022-02-17 09:40:09 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 4
2022-02-17 09:40:10 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:40:10 [ForkJoinPool-1-worker-3] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-13 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-02-17 09:40:10 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 3
2022-02-17 09:40:11 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 2
2022-02-17 09:40:12 [ForkJoinPool-1-worker-7] INFO  [PodUtils:322] Pod my-cluster-1172092675-connect-586584c56d-5wbx5 is in the Running state. Remaining seconds pod to be stable 1
2022-02-17 09:40:12 [ForkJoinPool-1-worker-7] INFO  [PodUtils:335] All pods are stable my-cluster-1172092675-connect-586584c56d-5wbx5
2022-02-17 09:40:12 [ForkJoinPool-1-worker-7] INFO  [SecurityST:1431] Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm
2022-02-17 09:40:12 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for KafkaConnect: my-cluster-1172092675 will have desired state: Ready
2022-02-17 09:40:37 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-FINISHED
2022-02-17 09:40:37 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:40:37 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:40:37 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-STARTED
2022-02-17 09:40:38 [ForkJoinPool-1-worker-5] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:40:38 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-17 for test case:testOwnerReferenceOfCASecrets
2022-02-17 09:40:38 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:156] Creating Namespace: namespace-17
2022-02-17 09:40:38 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:82] Client use Namespace: namespace-17
2022-02-17 09:40:38 [ForkJoinPool-1-worker-5] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-17
2022-02-17 09:40:38 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-571186689 in namespace namespace-17
2022-02-17 09:40:38 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-17
2022-02-17 09:40:38 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-571186689 will have desired state: Ready
2022-02-17 09:41:48 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] Kafka: my-cluster-571186689 is in desired state: Ready
2022-02-17 09:41:48 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1458] Listing all cluster CAs for my-cluster-571186689
2022-02-17 09:41:48 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1462] Deleting Kafka:my-cluster-571186689
2022-02-17 09:41:48 [ForkJoinPool-1-worker-5] INFO  [KafkaUtils:397] Waiting for deletion of Kafka:my-cluster-571186689
2022-02-17 09:41:50 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1466] Checking actual secrets after Kafka deletion
2022-02-17 09:41:50 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1469] Checking that my-cluster-571186689-clients-ca secret is still present
2022-02-17 09:41:50 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1472] Deleting secret: my-cluster-571186689-clients-ca
2022-02-17 09:41:50 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1469] Checking that my-cluster-571186689-clients-ca-cert secret is still present
2022-02-17 09:41:50 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1472] Deleting secret: my-cluster-571186689-clients-ca-cert
2022-02-17 09:41:50 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1469] Checking that my-cluster-571186689-cluster-ca secret is still present
2022-02-17 09:41:50 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1472] Deleting secret: my-cluster-571186689-cluster-ca
2022-02-17 09:41:50 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1469] Checking that my-cluster-571186689-cluster-ca-cert secret is still present
2022-02-17 09:41:50 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1472] Deleting secret: my-cluster-571186689-cluster-ca-cert
2022-02-17 09:41:50 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1476] Deploying Kafka with generateSecretOwnerReference set to true
2022-02-17 09:41:50 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update Kafka my-second-cluster-my-cluster-571186689 in namespace namespace-17
2022-02-17 09:41:50 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-17
2022-02-17 09:41:50 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for Kafka: my-second-cluster-my-cluster-571186689 will have desired state: Ready
2022-02-17 09:43:01 [ForkJoinPool-1-worker-1] INFO  [SecurityST:755] Maintenance window starts
2022-02-17 09:43:01 [ForkJoinPool-1-worker-1] INFO  [SecurityST:759] Wait until rolling update is triggered during maintenance window
2022-02-17 09:43:01 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1993793092-kafka rolling update
2022-02-17 09:43:29 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] Kafka: my-second-cluster-my-cluster-571186689 is in desired state: Ready
2022-02-17 09:43:29 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1491] Deleting Kafka:my-second-cluster-my-cluster-571186689
2022-02-17 09:43:29 [ForkJoinPool-1-worker-5] INFO  [KafkaUtils:397] Waiting for deletion of Kafka:my-second-cluster-my-cluster-571186689
2022-02-17 09:43:37 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1495] Checking actual secrets after Kafka deletion
2022-02-17 09:43:37 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1498] Checking that my-second-cluster-my-cluster-571186689-clients-ca secret is deleted
2022-02-17 09:43:37 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1498] Checking that my-second-cluster-my-cluster-571186689-clients-ca-cert secret is deleted
2022-02-17 09:43:37 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1498] Checking that my-second-cluster-my-cluster-571186689-cluster-ca secret is deleted
2022-02-17 09:43:37 [ForkJoinPool-1-worker-5] INFO  [SecurityST:1498] Checking that my-second-cluster-my-cluster-571186689-cluster-ca-cert secret is deleted
2022-02-17 09:43:37 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:43:37 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:309] Delete all resources for testOwnerReferenceOfCASecrets
2022-02-17 09:43:37 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of Kafka my-second-cluster-my-cluster-571186689 in namespace namespace-17
2022-02-17 09:43:37 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of Kafka my-cluster-571186689 in namespace namespace-17
2022-02-17 09:43:37 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:43:37 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-17 for test case:testOwnerReferenceOfCASecrets
2022-02-17 09:44:05 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-FINISHED
2022-02-17 09:44:05 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:44:05 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:44:05 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-STARTED
2022-02-17 09:44:07 [ForkJoinPool-1-worker-3] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:44:07 [ForkJoinPool-1-worker-3] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-18 for test case:testKafkaAndKafkaConnectTlsVersion
2022-02-17 09:44:07 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:156] Creating Namespace: namespace-18
2022-02-17 09:44:07 [ForkJoinPool-1-worker-3] INFO  [KubeClusterResource:82] Client use Namespace: namespace-18
2022-02-17 09:44:07 [ForkJoinPool-1-worker-3] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-18
2022-02-17 09:44:07 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1307] Deploying Kafka cluster with the support TLSv1.2 TLS
2022-02-17 09:44:07 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-1952121097 in namespace namespace-18
2022-02-17 09:44:07 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-18
2022-02-17 09:44:07 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1952121097 will have desired state: Ready
2022-02-17 09:44:56 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-1993793092-kafka has been successfully rolled
2022-02-17 09:44:56 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-1993793092-kafka to be ready
2022-02-17 09:45:17 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:405] Kafka: my-cluster-1952121097 is in desired state: Ready
2022-02-17 09:45:17 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1319] Verifying that Kafka cluster has the accepted configuration:
ssl.enabled.protocols -> TLSv1.2
ssl.protocol -> TLSv1.3
2022-02-17 09:45:17 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-1952121097-kafka-clients in namespace namespace-18
2022-02-17 09:45:17 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-18
2022-02-17 09:45:17 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-1952121097-kafka-clients will be ready
2022-02-17 09:45:19 [ForkJoinPool-1-worker-3] INFO  [DeploymentUtils:168] Deployment: my-cluster-1952121097-kafka-clients is ready
2022-02-17 09:45:19 [ForkJoinPool-1-worker-3] INFO  [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-1952121097-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-02-17 09:45:19 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update NetworkPolicy my-cluster-1952121097-allow in namespace namespace-18
2022-02-17 09:45:19 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-18
2022-02-17 09:45:19 [ForkJoinPool-1-worker-3] INFO  [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-02-17 09:45:19 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:152] Create/Update KafkaConnect my-cluster-1952121097 in namespace namespace-18
2022-02-17 09:45:19 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-18
2022-02-17 09:45:19 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1342] Verifying that Kafka Connect status is NotReady because of different TLS version
2022-02-17 09:45:19 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:394] Wait for KafkaConnect: my-cluster-1952121097 will have desired state: NotReady
2022-02-17 09:45:24 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1993793092 will have desired state: Ready
2022-02-17 09:45:24 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] Kafka: my-cluster-1993793092 is in desired state: Ready
2022-02-17 09:45:24 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:132] Kafka: my-cluster-1993793092 is ready
2022-02-17 09:45:24 [ForkJoinPool-1-worker-1] INFO  [SecurityST:764] Checking consumed messages to pod:my-cluster-1993793092-kafka-clients-5b4c859f9d-59vp7
2022-02-17 09:45:24 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5be10f40, messages=[], arguments=[--bootstrap-server, my-cluster-1993793092-kafka-bootstrap.namespace-16.svc:9093, USER=my_user_1053915362_1833089503, --max-messages, 100, --topic, my-topic-1441128375-1517160289], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1993793092-kafka-clients-5b4c859f9d-59vp7', podNamespace='namespace-16', bootstrapServer='my-cluster-1993793092-kafka-bootstrap.namespace-16.svc:9093', topicName='my-topic-1441128375-1517160289', maxMessages=100, kafkaUsername='my-user-1053915362-1833089503', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@2809139e}
2022-02-17 09:45:24 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:124] Producing 100 messages to my-cluster-1993793092-kafka-bootstrap.namespace-16.svc:9093:my-topic-1441128375-1517160289 from pod my-cluster-1993793092-kafka-clients-5b4c859f9d-59vp7
2022-02-17 09:45:24 [ForkJoinPool-1-worker-1] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-1993793092-kafka-clients-5b4c859f9d-59vp7 -n namespace-16 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-1993793092-kafka-bootstrap.namespace-16.svc:9093 USER=my_user_1053915362_1833089503 --max-messages 100 --topic my-topic-1441128375-1517160289
2022-02-17 09:45:28 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:127] Producer finished correctly: true
2022-02-17 09:45:28 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:131] Producer produced 100 messages
2022-02-17 09:45:28 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3970a9a3, messages=[], arguments=[--group-id, my-consumer-group-696084386, --bootstrap-server, my-cluster-1993793092-kafka-bootstrap.namespace-16.svc:9093, USER=my_user_1053915362_1833089503, --max-messages, 100, --group-instance-id, instance1225496979, --topic, my-topic-1441128375-1517160289], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1993793092-kafka-clients-5b4c859f9d-59vp7', podNamespace='namespace-16', bootstrapServer='my-cluster-1993793092-kafka-bootstrap.namespace-16.svc:9093', topicName='my-topic-1441128375-1517160289', maxMessages=100, kafkaUsername='my-user-1053915362-1833089503', consumerGroupName='my-consumer-group-696084386', consumerInstanceId='instance1225496979', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@5985c4ee}
2022-02-17 09:45:28 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:192] Consuming 100 messages from my-cluster-1993793092-kafka-bootstrap.namespace-16.svc:9093:my-topic-1441128375-1517160289 from pod my-cluster-1993793092-kafka-clients-5b4c859f9d-59vp7
2022-02-17 09:45:28 [ForkJoinPool-1-worker-1] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-1993793092-kafka-clients-5b4c859f9d-59vp7 -n namespace-16 -- /opt/kafka/consumer.sh --group-id my-consumer-group-696084386 --bootstrap-server my-cluster-1993793092-kafka-bootstrap.namespace-16.svc:9093 USER=my_user_1053915362_1833089503 --max-messages 100 --group-instance-id instance1225496979 --topic my-topic-1441128375-1517160289
2022-02-17 09:45:35 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:195] Consumer finished correctly: true
2022-02-17 09:45:35 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:198] Consumer consumed 100 messages
2022-02-17 09:45:35 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:45:35 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:309] Delete all resources for testCertRenewalInMaintenanceWindow
2022-02-17 09:45:35 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-1441128375-1517160289 in namespace namespace-16
2022-02-17 09:45:41 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] KafkaConnect: my-cluster-1172092675 is in desired state: Ready
2022-02-17 09:45:41 [ForkJoinPool-1-worker-7] WARN  [DeploymentUtils:213] Deployment my-cluster-1172092675-connect is not deleted yet! Triggering force delete by cmd client!
2022-02-17 09:45:45 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of Deployment my-cluster-1993793092-kafka-clients in namespace namespace-16
2022-02-17 09:45:46 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:45:46 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:309] Delete all resources for testKafkaAndKafkaConnectCipherSuites
2022-02-17 09:45:46 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of NetworkPolicy my-cluster-1172092675-allow in namespace namespace-14
2022-02-17 09:45:46 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of KafkaConnect my-cluster-1172092675 in namespace namespace-14
2022-02-17 09:45:46 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of Deployment my-cluster-1172092675-kafka-clients in namespace namespace-14
2022-02-17 09:46:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-1441128375-1517160289 in namespace namespace-16
2022-02-17 09:46:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of KafkaUser my-user-1053915362-1833089503 in namespace namespace-16
2022-02-17 09:46:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of Kafka my-cluster-1993793092 in namespace namespace-16
2022-02-17 09:46:26 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of Kafka my-cluster-1172092675 in namespace namespace-14
2022-02-17 09:46:35 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:46:35 [ForkJoinPool-1-worker-1] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-16 for test case:testCertRenewalInMaintenanceWindow
2022-02-17 09:46:36 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:46:36 [ForkJoinPool-1-worker-7] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-14 for test case:testKafkaAndKafkaConnectCipherSuites
2022-02-17 09:47:08 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-FINISHED
2022-02-17 09:47:08 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:47:08 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:47:08 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-STARTED
2022-02-17 09:47:10 [ForkJoinPool-1-worker-5] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:47:10 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-19 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-02-17 09:47:10 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:156] Creating Namespace: namespace-19
2022-02-17 09:47:10 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:82] Client use Namespace: namespace-19
2022-02-17 09:47:10 [ForkJoinPool-1-worker-5] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-19
2022-02-17 09:47:10 [ForkJoinPool-1-worker-5] INFO  [SecurityST:601] Creating a cluster
2022-02-17 09:47:10 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-696765618 in namespace namespace-19
2022-02-17 09:47:10 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-19
2022-02-17 09:47:10 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-696765618 will have desired state: Ready
2022-02-17 09:47:11 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-FINISHED
2022-02-17 09:47:11 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:47:11 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:47:11 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-STARTED
2022-02-17 09:47:13 [ForkJoinPool-1-worker-1] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:47:13 [ForkJoinPool-1-worker-1] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-20 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-02-17 09:47:13 [ForkJoinPool-1-worker-1] INFO  [KubeClusterResource:156] Creating Namespace: namespace-20
2022-02-17 09:47:13 [ForkJoinPool-1-worker-1] INFO  [KubeClusterResource:82] Client use Namespace: namespace-20
2022-02-17 09:47:13 [ForkJoinPool-1-worker-1] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-20
2022-02-17 09:47:13 [ForkJoinPool-1-worker-1] INFO  [SecurityST:601] Creating a cluster
2022-02-17 09:47:13 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-799998736 in namespace namespace-20
2022-02-17 09:47:13 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-20
2022-02-17 09:47:13 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-799998736 will have desired state: Ready
2022-02-17 09:49:42 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] Kafka: my-cluster-696765618 is in desired state: Ready
2022-02-17 09:49:42 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-1420248781-223596747 in namespace namespace-20
2022-02-17 09:49:42 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-19
2022-02-17 09:49:42 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-1420248781-223596747 will have desired state: Ready
2022-02-17 09:49:43 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] KafkaUser: my-user-1420248781-223596747 is in desired state: Ready
2022-02-17 09:49:43 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-1491847637-1100576533 in namespace namespace-20
2022-02-17 09:49:43 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-19
2022-02-17 09:49:43 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-1491847637-1100576533 will have desired state: Ready
2022-02-17 09:49:44 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] KafkaTopic: my-topic-1491847637-1100576533 is in desired state: Ready
2022-02-17 09:49:44 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-696765618-kafka-clients in namespace namespace-20
2022-02-17 09:49:44 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-19
2022-02-17 09:49:44 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-696765618-kafka-clients will be ready
2022-02-17 09:49:48 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:168] Deployment: my-cluster-696765618-kafka-clients is ready
2022-02-17 09:49:48 [ForkJoinPool-1-worker-5] INFO  [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-17 09:49:48 [ForkJoinPool-1-worker-5] INFO  [SecurityST:274] Checking produced and consumed messages to pod:my-cluster-696765618-kafka-clients-5c497d6686-lbz9t
2022-02-17 09:49:48 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@10272f8e, messages=[], arguments=[--bootstrap-server, my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9092, --max-messages, 100, --topic, my-topic-1491847637-1100576533], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-696765618-kafka-clients-5c497d6686-lbz9t', podNamespace='namespace-19', bootstrapServer='my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9092', topicName='my-topic-1491847637-1100576533', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@64aa5794}
2022-02-17 09:49:48 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:94] Producing 100 messages to my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9092:my-topic-1491847637-1100576533 from pod my-cluster-696765618-kafka-clients-5c497d6686-lbz9t
2022-02-17 09:49:48 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-696765618-kafka-clients-5c497d6686-lbz9t -n namespace-19 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9092 --max-messages 100 --topic my-topic-1491847637-1100576533
2022-02-17 09:49:50 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:97] Producer finished correctly: true
2022-02-17 09:49:50 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:101] Producer produced 100 messages
2022-02-17 09:49:50 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@138d5265, messages=[], arguments=[--group-id, my-consumer-group-1686882702, --bootstrap-server, my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9092, --max-messages, 100, --group-instance-id, instance473542046, --topic, my-topic-1491847637-1100576533], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-696765618-kafka-clients-5c497d6686-lbz9t', podNamespace='namespace-19', bootstrapServer='my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9092', topicName='my-topic-1491847637-1100576533', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1686882702', consumerInstanceId='instance473542046', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@25adb7b3}
2022-02-17 09:49:50 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9092#my-topic-1491847637-1100576533 from pod my-cluster-696765618-kafka-clients-5c497d6686-lbz9t
2022-02-17 09:49:50 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-696765618-kafka-clients-5c497d6686-lbz9t -n namespace-19 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1686882702 --bootstrap-server my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9092 --max-messages 100 --group-instance-id instance473542046 --topic my-topic-1491847637-1100576533
2022-02-17 09:49:55 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:49:55 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:49:55 [ForkJoinPool-1-worker-5] INFO  [SecurityST:288] Triggering CA cert renewal by adding the annotation
2022-02-17 09:49:55 [ForkJoinPool-1-worker-5] INFO  [SecurityST:300] Patching secret my-cluster-696765618-clients-ca-cert with strimzi.io/force-renew
2022-02-17 09:49:55 [ForkJoinPool-1-worker-5] INFO  [SecurityST:309] Wait for kafka to rolling restart ...
2022-02-17 09:49:55 [ForkJoinPool-1-worker-5] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-696765618-kafka rolling update
2022-02-17 09:50:20 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:405] KafkaConnect: my-cluster-1952121097 is in desired state: NotReady
2022-02-17 09:50:20 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1346] Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.
2022-02-17 09:50:20 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1350] Verifying that Kafka Connect has the accepted configuration:
 ssl.enabled.protocols -> TLSv1.2
 ssl.protocol -> TLSv1.3
2022-02-17 09:50:20 [ForkJoinPool-1-worker-3] INFO  [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-02-17 09:50:20 [ForkJoinPool-1-worker-3] INFO  [KafkaConnectUtils:109] Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-02-17 09:50:20 [ForkJoinPool-1-worker-3] INFO  [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-02-17 09:50:20 [ForkJoinPool-1-worker-3] INFO  [KafkaConnectUtils:109] Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-02-17 09:50:20 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1359] Verifying that Kafka Connect is stable
2022-02-17 09:50:20 [ForkJoinPool-1-worker-3] INFO  [PodUtils:296] Verify that all pods with prefix: my-cluster-1952121097-connect are stable
2022-02-17 09:50:20 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 50
2022-02-17 09:50:21 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 49
2022-02-17 09:50:22 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 48
2022-02-17 09:50:23 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 47
2022-02-17 09:50:24 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 46
2022-02-17 09:50:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] Kafka: my-cluster-799998736 is in desired state: Ready
2022-02-17 09:50:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-710287841-440042878 in namespace namespace-20
2022-02-17 09:50:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-20
2022-02-17 09:50:25 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-710287841-440042878 will have desired state: Ready
2022-02-17 09:50:25 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 45
2022-02-17 09:50:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] KafkaUser: my-user-710287841-440042878 is in desired state: Ready
2022-02-17 09:50:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-24663393-1305297790 in namespace namespace-20
2022-02-17 09:50:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-20
2022-02-17 09:50:26 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-24663393-1305297790 will have desired state: Ready
2022-02-17 09:50:26 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 44
2022-02-17 09:50:27 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:405] KafkaTopic: my-topic-24663393-1305297790 is in desired state: Ready
2022-02-17 09:50:27 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-799998736-kafka-clients in namespace namespace-20
2022-02-17 09:50:27 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:161] Using Namespace: namespace-20
2022-02-17 09:50:27 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-799998736-kafka-clients will be ready
2022-02-17 09:50:27 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 43
2022-02-17 09:50:28 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 42
2022-02-17 09:50:29 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:168] Deployment: my-cluster-799998736-kafka-clients is ready
2022-02-17 09:50:29 [ForkJoinPool-1-worker-1] INFO  [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-17 09:50:29 [ForkJoinPool-1-worker-1] INFO  [SecurityST:467] Checking produced and consumed messages to pod:my-cluster-799998736-kafka-clients-6f95f4596b-tbrr2
2022-02-17 09:50:29 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6e6e38af, messages=[], arguments=[--bootstrap-server, my-cluster-799998736-kafka-bootstrap.namespace-20.svc:9092, --max-messages, 100, --topic, my-topic-24663393-1305297790], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-799998736-kafka-clients-6f95f4596b-tbrr2', podNamespace='namespace-20', bootstrapServer='my-cluster-799998736-kafka-bootstrap.namespace-20.svc:9092', topicName='my-topic-24663393-1305297790', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@69605690}
2022-02-17 09:50:29 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:94] Producing 100 messages to my-cluster-799998736-kafka-bootstrap.namespace-20.svc:9092:my-topic-24663393-1305297790 from pod my-cluster-799998736-kafka-clients-6f95f4596b-tbrr2
2022-02-17 09:50:29 [ForkJoinPool-1-worker-1] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-799998736-kafka-clients-6f95f4596b-tbrr2 -n namespace-20 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-799998736-kafka-bootstrap.namespace-20.svc:9092 --max-messages 100 --topic my-topic-24663393-1305297790
2022-02-17 09:50:29 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 41
2022-02-17 09:50:30 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 40
2022-02-17 09:50:31 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:97] Producer finished correctly: true
2022-02-17 09:50:31 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:101] Producer produced 100 messages
2022-02-17 09:50:31 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5eee1eee, messages=[], arguments=[--group-id, my-consumer-group-763331104, --bootstrap-server, my-cluster-799998736-kafka-bootstrap.namespace-20.svc:9092, --max-messages, 100, --group-instance-id, instance2073662247, --topic, my-topic-24663393-1305297790], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-799998736-kafka-clients-6f95f4596b-tbrr2', podNamespace='namespace-20', bootstrapServer='my-cluster-799998736-kafka-bootstrap.namespace-20.svc:9092', topicName='my-topic-24663393-1305297790', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-763331104', consumerInstanceId='instance2073662247', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@49ecc230}
2022-02-17 09:50:31 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-799998736-kafka-bootstrap.namespace-20.svc:9092#my-topic-24663393-1305297790 from pod my-cluster-799998736-kafka-clients-6f95f4596b-tbrr2
2022-02-17 09:50:31 [ForkJoinPool-1-worker-1] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-799998736-kafka-clients-6f95f4596b-tbrr2 -n namespace-20 -- /opt/kafka/consumer.sh --group-id my-consumer-group-763331104 --bootstrap-server my-cluster-799998736-kafka-bootstrap.namespace-20.svc:9092 --max-messages 100 --group-instance-id instance2073662247 --topic my-topic-24663393-1305297790
2022-02-17 09:50:31 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 39
2022-02-17 09:50:32 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 38
2022-02-17 09:50:33 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 37
2022-02-17 09:50:34 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 36
2022-02-17 09:50:35 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 35
2022-02-17 09:50:36 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 34
2022-02-17 09:50:37 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:50:37 [ForkJoinPool-1-worker-1] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:50:37 [ForkJoinPool-1-worker-1] INFO  [SecurityST:481] Triggering CA cert renewal by adding the annotation
2022-02-17 09:50:37 [ForkJoinPool-1-worker-1] INFO  [SecurityST:493] Patching secret my-cluster-799998736-cluster-ca with strimzi.io/force-replace
2022-02-17 09:50:37 [ForkJoinPool-1-worker-1] INFO  [SecurityST:498] Wait for zk to rolling restart (1)...
2022-02-17 09:50:37 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-799998736-zookeeper rolling update
2022-02-17 09:50:37 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 33
2022-02-17 09:50:38 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 32
2022-02-17 09:50:39 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 31
2022-02-17 09:50:40 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 30
2022-02-17 09:50:41 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 29
2022-02-17 09:50:42 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 28
2022-02-17 09:50:43 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 27
2022-02-17 09:50:44 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 26
2022-02-17 09:50:45 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 25
2022-02-17 09:50:46 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 24
2022-02-17 09:50:47 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 23
2022-02-17 09:50:48 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 22
2022-02-17 09:50:49 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 21
2022-02-17 09:50:50 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 20
2022-02-17 09:50:51 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 19
2022-02-17 09:50:52 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 18
2022-02-17 09:50:53 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 17
2022-02-17 09:50:54 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 16
2022-02-17 09:50:55 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 15
2022-02-17 09:50:56 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 14
2022-02-17 09:50:57 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 13
2022-02-17 09:50:58 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 12
2022-02-17 09:50:59 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 11
2022-02-17 09:51:00 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 10
2022-02-17 09:51:01 [ForkJoinPool-1-worker-5] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-696765618-kafka has been successfully rolled
2022-02-17 09:51:01 [ForkJoinPool-1-worker-5] INFO  [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-696765618-kafka to be ready
2022-02-17 09:51:01 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 9
2022-02-17 09:51:02 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 8
2022-02-17 09:51:03 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 7
2022-02-17 09:51:04 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 6
2022-02-17 09:51:05 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 5
2022-02-17 09:51:07 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 4
2022-02-17 09:51:08 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 3
2022-02-17 09:51:09 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 2
2022-02-17 09:51:10 [ForkJoinPool-1-worker-3] INFO  [PodUtils:322] Pod my-cluster-1952121097-connect-758c9f478b-kmw4k is in the Running state. Remaining seconds pod to be stable 1
2022-02-17 09:51:10 [ForkJoinPool-1-worker-3] INFO  [PodUtils:335] All pods are stable my-cluster-1952121097-connect-758c9f478b-kmw4k
2022-02-17 09:51:10 [ForkJoinPool-1-worker-3] INFO  [SecurityST:1363] Verifying that Kafka Connect status is Ready because of same TLS version
2022-02-17 09:51:10 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:394] Wait for KafkaConnect: my-cluster-1952121097 will have desired state: Ready
2022-02-17 09:51:30 [ForkJoinPool-1-worker-5] INFO  [SecurityST:322] Checking the certificates have been replaced
2022-02-17 09:51:30 [ForkJoinPool-1-worker-5] INFO  [SecurityST:336] Checking consumed messages to pod:my-cluster-696765618-kafka-clients-5c497d6686-lbz9t
2022-02-17 09:51:30 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@392080bf, messages=[], arguments=[--group-id, my-consumer-group-759568651, --bootstrap-server, my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9092, --max-messages, 100, --group-instance-id, instance1843708231, --topic, my-topic-1491847637-1100576533], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-696765618-kafka-clients-5c497d6686-lbz9t', podNamespace='namespace-19', bootstrapServer='my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9092', topicName='my-topic-1491847637-1100576533', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-759568651', consumerInstanceId='instance1843708231', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@260e443}
2022-02-17 09:51:30 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9092#my-topic-1491847637-1100576533 from pod my-cluster-696765618-kafka-clients-5c497d6686-lbz9t
2022-02-17 09:51:30 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-696765618-kafka-clients-5c497d6686-lbz9t -n namespace-19 -- /opt/kafka/consumer.sh --group-id my-consumer-group-759568651 --bootstrap-server my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9092 --max-messages 100 --group-instance-id instance1843708231 --topic my-topic-1491847637-1100576533
2022-02-17 09:51:36 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:51:36 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:51:36 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update KafkaUser bob-my-cluster-696765618 in namespace namespace-20
2022-02-17 09:51:36 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-19
2022-02-17 09:51:36 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for KafkaUser: bob-my-cluster-696765618 will have desired state: Ready
2022-02-17 09:51:37 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:405] KafkaUser: bob-my-cluster-696765618 is in desired state: Ready
2022-02-17 09:51:37 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-696765618-kafka-clients-tls in namespace namespace-19
2022-02-17 09:51:37 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-19
2022-02-17 09:51:37 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-696765618-kafka-clients-tls will be ready
2022-02-17 09:51:39 [ForkJoinPool-1-worker-5] INFO  [DeploymentUtils:168] Deployment: my-cluster-696765618-kafka-clients-tls is ready
2022-02-17 09:51:39 [ForkJoinPool-1-worker-5] INFO  [SecurityST:360] Checking consumed messages to pod:my-cluster-696765618-kafka-clients-tls-66f4765885-vrdt6
2022-02-17 09:51:39 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3cda01e6, messages=[], arguments=[--group-id, my-consumer-group-65322954, --bootstrap-server, my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9093, USER=bob_my_cluster_696765618, --max-messages, 100, --group-instance-id, instance569744499, --topic, my-topic-1491847637-1100576533], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-696765618-kafka-clients-tls-66f4765885-vrdt6', podNamespace='namespace-19', bootstrapServer='my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9093', topicName='my-topic-1491847637-1100576533', maxMessages=100, kafkaUsername='bob-my-cluster-696765618', consumerGroupName='my-consumer-group-65322954', consumerInstanceId='instance569744499', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@416b8cbe}
2022-02-17 09:51:39 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9093#my-topic-1491847637-1100576533 from pod my-cluster-696765618-kafka-clients-tls-66f4765885-vrdt6
2022-02-17 09:51:39 [ForkJoinPool-1-worker-5] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-696765618-kafka-clients-tls-66f4765885-vrdt6 -n namespace-19 -- /opt/kafka/consumer.sh --group-id my-consumer-group-65322954 --bootstrap-server my-cluster-696765618-kafka-bootstrap.namespace-19.svc:9093 USER=bob_my_cluster_696765618 --max-messages 100 --group-instance-id instance569744499 --topic my-topic-1491847637-1100576533
2022-02-17 09:51:46 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:51:46 [ForkJoinPool-1-worker-5] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:51:46 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:51:46 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:309] Delete all resources for testAutoRenewClientsCaCertsTriggeredByAnno
2022-02-17 09:51:46 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of Deployment my-cluster-696765618-kafka-clients in namespace namespace-19
2022-02-17 09:51:52 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-799998736-zookeeper has been successfully rolled
2022-02-17 09:51:52 [ForkJoinPool-1-worker-1] INFO  [SecurityST:503] Wait for kafka to rolling restart (1)...
2022-02-17 09:51:52 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-799998736-kafka rolling update
2022-02-17 09:53:06 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of Deployment my-cluster-696765618-kafka-clients-tls in namespace namespace-19
2022-02-17 09:53:06 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of KafkaUser bob-my-cluster-696765618 in namespace namespace-19
2022-02-17 09:53:07 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-799998736-kafka has been successfully rolled
2022-02-17 09:53:07 [ForkJoinPool-1-worker-1] INFO  [SecurityST:508] Wait for EO to rolling restart (1)...
2022-02-17 09:53:07 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-799998736-entity-operator rolling update
2022-02-17 09:53:16 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of KafkaUser my-user-1420248781-223596747 in namespace namespace-19
2022-02-17 09:53:16 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-1491847637-1100576533 in namespace namespace-19
2022-02-17 09:53:26 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of Kafka my-cluster-696765618 in namespace namespace-19
2022-02-17 09:53:26 [ForkJoinPool-1-worker-5] INFO  [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-19, for cruise control Kafka cluster my-cluster-696765618
2022-02-17 09:53:33 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-799998736-entity-operator will be ready
2022-02-17 09:53:36 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:53:36 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-19 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-02-17 09:54:09 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-FINISHED
2022-02-17 09:54:09 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:54:09 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:23] ############################################################################
2022-02-17 09:54:09 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-STARTED
2022-02-17 09:54:11 [ForkJoinPool-1-worker-7] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:54:11 [ForkJoinPool-1-worker-7] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-21 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-02-17 09:54:11 [ForkJoinPool-1-worker-7] INFO  [KubeClusterResource:156] Creating Namespace: namespace-21
2022-02-17 09:54:11 [ForkJoinPool-1-worker-7] INFO  [KubeClusterResource:82] Client use Namespace: namespace-21
2022-02-17 09:54:11 [ForkJoinPool-1-worker-7] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-21
2022-02-17 09:54:11 [ForkJoinPool-1-worker-7] INFO  [SecurityST:601] Creating a cluster
2022-02-17 09:54:11 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-1709720907 in namespace namespace-21
2022-02-17 09:54:11 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-21
2022-02-17 09:54:11 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1709720907 will have desired state: Ready
2022-02-17 09:54:17 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:168] Deployment: my-cluster-799998736-entity-operator is ready
2022-02-17 09:54:27 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:141] Deployment my-cluster-799998736-entity-operator rolling update finished
2022-02-17 09:54:27 [ForkJoinPool-1-worker-1] INFO  [SecurityST:513] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-02-17 09:54:27 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-799998736-kafka-exporter rolling update
2022-02-17 09:54:27 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-799998736-kafka-exporter will be ready
2022-02-17 09:54:48 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:168] Deployment: my-cluster-799998736-kafka-exporter is ready
2022-02-17 09:54:58 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:141] Deployment my-cluster-799998736-kafka-exporter rolling update finished
2022-02-17 09:54:58 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-799998736-cruise-control rolling update
2022-02-17 09:54:58 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-799998736-cruise-control will be ready
2022-02-17 09:55:09 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:168] Deployment: my-cluster-799998736-cruise-control is ready
2022-02-17 09:55:19 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:141] Deployment my-cluster-799998736-cruise-control rolling update finished
2022-02-17 09:55:19 [ForkJoinPool-1-worker-1] INFO  [SecurityST:519] Wait for zk to rolling restart (2)...
2022-02-17 09:55:19 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-799998736-zookeeper rolling update
2022-02-17 09:55:59 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-799998736-zookeeper has been successfully rolled
2022-02-17 09:55:59 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-799998736-zookeeper to be ready
2022-02-17 09:56:25 [ForkJoinPool-1-worker-1] INFO  [SecurityST:524] Wait for kafka to rolling restart (2)...
2022-02-17 09:56:25 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-799998736-kafka rolling update
2022-02-17 09:56:41 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:405] KafkaConnect: my-cluster-1952121097 is in desired state: Ready
2022-02-17 09:56:41 [ForkJoinPool-1-worker-3] WARN  [DeploymentUtils:213] Deployment my-cluster-1952121097-connect is not deleted yet! Triggering force delete by cmd client!
2022-02-17 09:56:41 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] Kafka: my-cluster-1709720907 is in desired state: Ready
2022-02-17 09:56:41 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update KafkaUser my-user-1675042719-2100686491 in namespace namespace-21
2022-02-17 09:56:41 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-21
2022-02-17 09:56:41 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for KafkaUser: my-user-1675042719-2100686491 will have desired state: Ready
2022-02-17 09:56:42 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] KafkaUser: my-user-1675042719-2100686491 is in desired state: Ready
2022-02-17 09:56:42 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update KafkaTopic my-topic-702272404-1587300943 in namespace namespace-21
2022-02-17 09:56:42 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-21
2022-02-17 09:56:42 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:394] Wait for KafkaTopic: my-topic-702272404-1587300943 will have desired state: Ready
2022-02-17 09:56:43 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:405] KafkaTopic: my-topic-702272404-1587300943 is in desired state: Ready
2022-02-17 09:56:43 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:152] Create/Update Deployment my-cluster-1709720907-kafka-clients in namespace namespace-21
2022-02-17 09:56:43 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-21
2022-02-17 09:56:43 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-1709720907-kafka-clients will be ready
2022-02-17 09:56:45 [ForkJoinPool-1-worker-7] INFO  [DeploymentUtils:168] Deployment: my-cluster-1709720907-kafka-clients is ready
2022-02-17 09:56:45 [ForkJoinPool-1-worker-7] INFO  [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-02-17 09:56:45 [ForkJoinPool-1-worker-7] INFO  [SecurityST:467] Checking produced and consumed messages to pod:my-cluster-1709720907-kafka-clients-6d4c5cd6d8-rh8l5
2022-02-17 09:56:45 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@65cd4d55, messages=[], arguments=[--bootstrap-server, my-cluster-1709720907-kafka-bootstrap.namespace-21.svc:9092, --max-messages, 100, --topic, my-topic-702272404-1587300943], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1709720907-kafka-clients-6d4c5cd6d8-rh8l5', podNamespace='namespace-21', bootstrapServer='my-cluster-1709720907-kafka-bootstrap.namespace-21.svc:9092', topicName='my-topic-702272404-1587300943', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@244effd5}
2022-02-17 09:56:45 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:94] Producing 100 messages to my-cluster-1709720907-kafka-bootstrap.namespace-21.svc:9092:my-topic-702272404-1587300943 from pod my-cluster-1709720907-kafka-clients-6d4c5cd6d8-rh8l5
2022-02-17 09:56:45 [ForkJoinPool-1-worker-7] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-1709720907-kafka-clients-6d4c5cd6d8-rh8l5 -n namespace-21 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-1709720907-kafka-bootstrap.namespace-21.svc:9092 --max-messages 100 --topic my-topic-702272404-1587300943
2022-02-17 09:56:46 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:305] ############################################################################
2022-02-17 09:56:46 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:309] Delete all resources for testKafkaAndKafkaConnectTlsVersion
2022-02-17 09:56:46 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of NetworkPolicy my-cluster-1952121097-allow in namespace namespace-18
2022-02-17 09:56:46 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of KafkaConnect my-cluster-1952121097 in namespace namespace-18
2022-02-17 09:56:46 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of Deployment my-cluster-1952121097-kafka-clients in namespace namespace-18
2022-02-17 09:56:47 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:97] Producer finished correctly: true
2022-02-17 09:56:47 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:101] Producer produced 100 messages
2022-02-17 09:56:47 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3538fd46, messages=[], arguments=[--group-id, my-consumer-group-1821481502, --bootstrap-server, my-cluster-1709720907-kafka-bootstrap.namespace-21.svc:9092, --max-messages, 100, --group-instance-id, instance1831483394, --topic, my-topic-702272404-1587300943], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1709720907-kafka-clients-6d4c5cd6d8-rh8l5', podNamespace='namespace-21', bootstrapServer='my-cluster-1709720907-kafka-bootstrap.namespace-21.svc:9092', topicName='my-topic-702272404-1587300943', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1821481502', consumerInstanceId='instance1831483394', clientArgumentMap=io.strimzi.systemtest.kafkaclients.internalClients.ClientArgumentMap@585c116a}
2022-02-17 09:56:47 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1709720907-kafka-bootstrap.namespace-21.svc:9092#my-topic-702272404-1587300943 from pod my-cluster-1709720907-kafka-clients-6d4c5cd6d8-rh8l5
2022-02-17 09:56:47 [ForkJoinPool-1-worker-7] INFO  [VerifiableClient:192] Client command: kubectl exec my-cluster-1709720907-kafka-clients-6d4c5cd6d8-rh8l5 -n namespace-21 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1821481502 --bootstrap-server my-cluster-1709720907-kafka-bootstrap.namespace-21.svc:9092 --max-messages 100 --group-instance-id instance1831483394 --topic my-topic-702272404-1587300943
2022-02-17 09:56:53 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:160] Consumer finished correctly: true
2022-02-17 09:56:53 [ForkJoinPool-1-worker-7] INFO  [InternalKafkaClient:163] Consumer consumed 100 messages
2022-02-17 09:56:53 [ForkJoinPool-1-worker-7] INFO  [SecurityST:481] Triggering CA cert renewal by adding the annotation
2022-02-17 09:56:53 [ForkJoinPool-1-worker-7] INFO  [SecurityST:493] Patching secret my-cluster-1709720907-cluster-ca with strimzi.io/force-replace
2022-02-17 09:56:53 [ForkJoinPool-1-worker-7] INFO  [SecurityST:493] Patching secret my-cluster-1709720907-clients-ca with strimzi.io/force-replace
2022-02-17 09:56:53 [ForkJoinPool-1-worker-7] INFO  [SecurityST:498] Wait for zk to rolling restart (1)...
2022-02-17 09:56:53 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1709720907-zookeeper rolling update
2022-02-17 09:57:16 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-799998736-kafka has been successfully rolled
2022-02-17 09:57:16 [ForkJoinPool-1-worker-1] INFO  [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-799998736-kafka to be ready
2022-02-17 09:57:26 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of Kafka my-cluster-1952121097 in namespace namespace-18
2022-02-17 09:57:36 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:330] ############################################################################
2022-02-17 09:57:36 [ForkJoinPool-1-worker-3] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-18 for test case:testKafkaAndKafkaConnectTlsVersion
2022-02-17 09:57:46 [ForkJoinPool-1-worker-1] INFO  [SecurityST:529] Wait for EO to rolling restart (2)...
2022-02-17 09:57:46 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-799998736-entity-operator rolling update
2022-02-17 09:57:46 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:161] Wait for Deployment: my-cluster-799998736-entity-operator will be ready
2022-02-17 09:57:48 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:86] Component with name: my-cluster-1709720907-zookeeper has been successfully rolled
2022-02-17 09:57:48 [ForkJoinPool-1-worker-7] INFO  [SecurityST:503] Wait for kafka to rolling restart (1)...
2022-02-17 09:57:48 [ForkJoinPool-1-worker-7] INFO  [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1709720907-kafka rolling update
2022-02-17 09:58:03 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-FINISHED
2022-02-17 09:58:03 [ForkJoinPool-1-worker-3] INFO  [TestSeparator:30] ############################################################################
2022-02-17 09:58:04 [ForkJoinPool-1-worker-5] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 09:58:04 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-22 for test case:testClusterCACertRenew
2022-02-17 09:58:04 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:156] Creating Namespace: namespace-22
2022-02-17 09:58:04 [ForkJoinPool-1-worker-5] INFO  [KubeClusterResource:82] Client use Namespace: namespace-22
2022-02-17 09:58:04 [ForkJoinPool-1-worker-5] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-22
2022-02-17 09:58:04 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-206127643 in namespace namespace-22
2022-02-17 09:58:04 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-22
2022-02-17 09:58:04 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-206127643 will have desired state: Ready
2022-02-17 09:58:34 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:168] Deployment: my-cluster-799998736-entity-operator is ready
2022-02-17 09:58:44 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:141] Deployment my-cluster-799998736-entity-operator rolling update finished
2022-02-17 09:58:44 [ForkJoinPool-1-worker-1] INFO  [SecurityST:534] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-02-17 09:58:44 [ForkJoinPool-1-worker-1] INFO  [DeploymentUtils:136] Waiting for Deployment my-cluster-799998736-kafka-exporter rolling update
2022-02-17 10:03:44 [ForkJoinPool-1-worker-1] ERROR [TestExecutionWatcher:28] SecurityST - Exception Timeout after 300000 ms waiting for Deployment my-cluster-799998736-kafka-exporter rolling update in namespace:namespace-20 has been thrown in @Test. Going to collect logs from components.
2022-02-17 10:03:45 [ForkJoinPool-1-worker-1] INFO  [LogCollector:251] Collecting events in Namespace infra-namespace
2022-02-17 10:03:47 [ForkJoinPool-1-worker-1] INFO  [LogCollector:258] Collecting ConfigMaps in Namespace infra-namespace
2022-02-17 10:03:47 [ForkJoinPool-1-worker-1] INFO  [LogCollector:216] Collecting logs for Pod(s) in Namespace infra-namespace
2022-02-17 10:04:15 [ForkJoinPool-1-worker-1] INFO  [LogCollector:265] Collecting Deployments in Namespace infra-namespace
2022-02-17 10:04:17 [ForkJoinPool-1-worker-1] INFO  [LogCollector:270] Collecting StatefulSets in Namespace infra-namespace
2022-02-17 10:04:18 [ForkJoinPool-1-worker-1] INFO  [LogCollector:275] Collecting ReplicaSets in Namespace infra-namespace
2022-02-17 10:04:19 [ForkJoinPool-1-worker-1] INFO  [LogCollector:280] Collecting Strimzi in Namespace infra-namespace
2022-02-17 10:04:23 [ForkJoinPool-1-worker-1] INFO  [LogCollector:286] Collecting cluster status
2022-02-17 10:04:25 [ForkJoinPool-1-worker-1] INFO  [LogCollector:251] Collecting events in Namespace namespace-20
2022-02-17 10:04:27 [ForkJoinPool-1-worker-1] INFO  [LogCollector:258] Collecting ConfigMaps in Namespace namespace-20
2022-02-17 10:04:27 [ForkJoinPool-1-worker-1] INFO  [LogCollector:216] Collecting logs for Pod(s) in Namespace namespace-20
2022-02-17 10:04:49 [ForkJoinPool-1-worker-1] WARN  [LogCollector:246] Searching for logs in all pods failed! Some of the logs will not be stored. Exception messageOperation: [doGetLog]  for kind: [Pod]  with name: [my-cluster-799998736-entity-operator-7b6c48bf47-lnf6t]  in namespace: [namespace-20]  failed.
2022-02-17 10:04:49 [ForkJoinPool-1-worker-1] INFO  [LogCollector:265] Collecting Deployments in Namespace namespace-20
2022-02-17 10:04:52 [ForkJoinPool-1-worker-1] INFO  [LogCollector:270] Collecting StatefulSets in Namespace namespace-20
2022-02-17 10:04:53 [ForkJoinPool-1-worker-1] INFO  [LogCollector:275] Collecting ReplicaSets in Namespace namespace-20
2022-02-17 10:04:55 [ForkJoinPool-1-worker-1] INFO  [LogCollector:280] Collecting Strimzi in Namespace namespace-20
2022-02-17 10:04:59 [ForkJoinPool-1-worker-1] INFO  [LogCollector:286] Collecting cluster status
2022-02-17 10:05:01 [ForkJoinPool-1-worker-1] INFO  [LogCollector:251] Collecting events in Namespace security-st
2022-02-17 10:05:02 [ForkJoinPool-1-worker-1] INFO  [LogCollector:258] Collecting ConfigMaps in Namespace security-st
2022-02-17 10:05:02 [ForkJoinPool-1-worker-1] INFO  [LogCollector:216] Collecting logs for Pod(s) in Namespace security-st
2022-02-17 10:05:02 [ForkJoinPool-1-worker-1] INFO  [LogCollector:265] Collecting Deployments in Namespace security-st
2022-02-17 10:05:04 [ForkJoinPool-1-worker-1] INFO  [LogCollector:270] Collecting StatefulSets in Namespace security-st
2022-02-17 10:05:05 [ForkJoinPool-1-worker-1] INFO  [LogCollector:275] Collecting ReplicaSets in Namespace security-st
2022-02-17 10:05:06 [ForkJoinPool-1-worker-1] INFO  [LogCollector:280] Collecting Strimzi in Namespace security-st
2022-02-17 10:05:06 [ForkJoinPool-1-worker-1] INFO  [LogCollector:286] Collecting cluster status
2022-02-17 10:05:07 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:305] ############################################################################
2022-02-17 10:05:07 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:309] Delete all resources for testAutoReplaceClusterCaKeysTriggeredByAnno
2022-02-17 10:05:07 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-24663393-1305297790 in namespace namespace-20
2022-02-17 10:05:07 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of Deployment my-cluster-799998736-kafka-clients in namespace namespace-20
2022-02-17 10:05:47 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of KafkaUser my-user-710287841-440042878 in namespace namespace-20
2022-02-17 10:05:57 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of Kafka my-cluster-799998736 in namespace namespace-20
2022-02-17 10:05:57 [ForkJoinPool-1-worker-1] INFO  [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-20, for cruise control Kafka cluster my-cluster-799998736
2022-02-17 10:06:08 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:330] ############################################################################
2022-02-17 10:06:08 [ForkJoinPool-1-worker-1] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-20 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-02-17 10:08:29 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-FINISHED
2022-02-17 10:08:29 [ForkJoinPool-1-worker-1] INFO  [TestSeparator:30] ############################################################################
2022-02-17 10:12:04 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:375] Kafka status:

Conditions:
	Type: NotReady
	Message: Exceeded timeout of 300000ms while waiting for Pods resource my-cluster-206127643-zookeeper-0 in namespace namespace-22 to be ready

Pods with conditions and messages:

my-cluster-206127643-kafka-0:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: Ready
	Message: containers with unready status: [kafka]

	Type: ContainersReady
	Message: containers with unready status: [kafka]

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-206127643-kafka-1:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: Ready
	Message: containers with unready status: [kafka]

	Type: ContainersReady
	Message: containers with unready status: [kafka]

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-206127643-kafka-2:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: Ready
	Message: containers with unready status: [kafka]

	Type: ContainersReady
	Message: containers with unready status: [kafka]

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-206127643-zookeeper-0:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-206127643-zookeeper-1:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: Ready
	Message: containers with unready status: [zookeeper]

	Type: ContainersReady
	Message: containers with unready status: [zookeeper]

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-206127643-zookeeper-2:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>
2022-02-17 10:12:04 [ForkJoinPool-1-worker-5] ERROR [TestExecutionWatcher:28] SecurityST - Exception Timeout after 840000 ms waiting for Resource condition: readiness is fulfilled for resource Kafka:my-cluster-206127643 has been thrown in @Test. Going to collect logs from components.
2022-02-17 10:12:04 [ForkJoinPool-1-worker-5] INFO  [LogCollector:251] Collecting events in Namespace infra-namespace
2022-02-17 10:12:05 [ForkJoinPool-1-worker-5] INFO  [LogCollector:258] Collecting ConfigMaps in Namespace infra-namespace
2022-02-17 10:12:05 [ForkJoinPool-1-worker-5] INFO  [LogCollector:216] Collecting logs for Pod(s) in Namespace infra-namespace
2022-02-17 10:12:27 [ForkJoinPool-1-worker-5] INFO  [LogCollector:265] Collecting Deployments in Namespace infra-namespace
2022-02-17 10:12:28 [ForkJoinPool-1-worker-5] INFO  [LogCollector:270] Collecting StatefulSets in Namespace infra-namespace
2022-02-17 10:12:29 [ForkJoinPool-1-worker-5] INFO  [LogCollector:275] Collecting ReplicaSets in Namespace infra-namespace
2022-02-17 10:12:30 [ForkJoinPool-1-worker-5] INFO  [LogCollector:280] Collecting Strimzi in Namespace infra-namespace
2022-02-17 10:12:33 [ForkJoinPool-1-worker-5] INFO  [LogCollector:286] Collecting cluster status
2022-02-17 10:12:34 [ForkJoinPool-1-worker-5] INFO  [LogCollector:251] Collecting events in Namespace namespace-22
2022-02-17 10:12:35 [ForkJoinPool-1-worker-5] INFO  [LogCollector:258] Collecting ConfigMaps in Namespace namespace-22
2022-02-17 10:12:35 [ForkJoinPool-1-worker-5] INFO  [LogCollector:216] Collecting logs for Pod(s) in Namespace namespace-22
2022-02-17 10:12:39 [ForkJoinPool-1-worker-5] INFO  [LogCollector:265] Collecting Deployments in Namespace namespace-22
2022-02-17 10:12:39 [ForkJoinPool-1-worker-5] INFO  [LogCollector:270] Collecting StatefulSets in Namespace namespace-22
2022-02-17 10:12:39 [ForkJoinPool-1-worker-5] INFO  [LogCollector:275] Collecting ReplicaSets in Namespace namespace-22
2022-02-17 10:12:40 [ForkJoinPool-1-worker-5] INFO  [LogCollector:280] Collecting Strimzi in Namespace namespace-22
2022-02-17 10:12:41 [ForkJoinPool-1-worker-5] INFO  [LogCollector:286] Collecting cluster status
2022-02-17 10:12:41 [ForkJoinPool-1-worker-5] INFO  [LogCollector:251] Collecting events in Namespace security-st
2022-02-17 10:12:42 [ForkJoinPool-1-worker-5] INFO  [LogCollector:258] Collecting ConfigMaps in Namespace security-st
2022-02-17 10:12:42 [ForkJoinPool-1-worker-5] INFO  [LogCollector:216] Collecting logs for Pod(s) in Namespace security-st
2022-02-17 10:12:42 [ForkJoinPool-1-worker-5] INFO  [LogCollector:265] Collecting Deployments in Namespace security-st
2022-02-17 10:12:42 [ForkJoinPool-1-worker-5] INFO  [LogCollector:270] Collecting StatefulSets in Namespace security-st
2022-02-17 10:12:42 [ForkJoinPool-1-worker-5] INFO  [LogCollector:275] Collecting ReplicaSets in Namespace security-st
2022-02-17 10:12:43 [ForkJoinPool-1-worker-5] INFO  [LogCollector:280] Collecting Strimzi in Namespace security-st
2022-02-17 10:12:43 [ForkJoinPool-1-worker-5] INFO  [LogCollector:286] Collecting cluster status
2022-02-17 10:12:44 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:305] ############################################################################
2022-02-17 10:12:44 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:309] Delete all resources for testClusterCACertRenew
2022-02-17 10:12:44 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of Kafka my-cluster-206127643 in namespace namespace-22
2022-02-17 10:12:48 [ForkJoinPool-1-worker-7] ERROR [TestExecutionWatcher:28] SecurityST - Exception Timeout after 900000 ms waiting for component with name my-cluster-1709720907-kafka rolling update has been thrown in @Test. Going to collect logs from components.
2022-02-17 10:12:49 [ForkJoinPool-1-worker-7] INFO  [LogCollector:251] Collecting events in Namespace infra-namespace
2022-02-17 10:12:50 [ForkJoinPool-1-worker-7] INFO  [LogCollector:258] Collecting ConfigMaps in Namespace infra-namespace
2022-02-17 10:12:50 [ForkJoinPool-1-worker-7] INFO  [LogCollector:216] Collecting logs for Pod(s) in Namespace infra-namespace
2022-02-17 10:12:54 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:330] ############################################################################
2022-02-17 10:12:54 [ForkJoinPool-1-worker-5] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-22 for test case:testClusterCACertRenew
2022-02-17 10:13:05 [ForkJoinPool-1-worker-7] INFO  [LogCollector:265] Collecting Deployments in Namespace infra-namespace
2022-02-17 10:13:05 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-FINISHED
2022-02-17 10:13:05 [ForkJoinPool-1-worker-5] INFO  [TestSeparator:30] ############################################################################
2022-02-17 10:13:05 [ForkJoinPool-1-worker-7] INFO  [LogCollector:270] Collecting StatefulSets in Namespace infra-namespace
2022-02-17 10:13:06 [ForkJoinPool-1-worker-7] INFO  [LogCollector:275] Collecting ReplicaSets in Namespace infra-namespace
2022-02-17 10:13:07 [ForkJoinPool-1-worker-7] INFO  [LogCollector:280] Collecting Strimzi in Namespace infra-namespace
2022-02-17 10:13:08 [ForkJoinPool-1-worker-7] INFO  [LogCollector:286] Collecting cluster status
2022-02-17 10:13:09 [ForkJoinPool-1-worker-7] INFO  [LogCollector:251] Collecting events in Namespace namespace-21
2022-02-17 10:13:10 [ForkJoinPool-1-worker-7] INFO  [LogCollector:258] Collecting ConfigMaps in Namespace namespace-21
2022-02-17 10:13:10 [ForkJoinPool-1-worker-7] INFO  [LogCollector:216] Collecting logs for Pod(s) in Namespace namespace-21
2022-02-17 10:13:38 [ForkJoinPool-1-worker-7] INFO  [LogCollector:265] Collecting Deployments in Namespace namespace-21
2022-02-17 10:13:39 [ForkJoinPool-1-worker-7] INFO  [LogCollector:270] Collecting StatefulSets in Namespace namespace-21
2022-02-17 10:13:40 [ForkJoinPool-1-worker-7] INFO  [LogCollector:275] Collecting ReplicaSets in Namespace namespace-21
2022-02-17 10:13:41 [ForkJoinPool-1-worker-7] INFO  [LogCollector:280] Collecting Strimzi in Namespace namespace-21
2022-02-17 10:13:44 [ForkJoinPool-1-worker-7] INFO  [LogCollector:286] Collecting cluster status
2022-02-17 10:13:45 [ForkJoinPool-1-worker-7] INFO  [LogCollector:251] Collecting events in Namespace security-st
2022-02-17 10:13:46 [ForkJoinPool-1-worker-7] INFO  [LogCollector:258] Collecting ConfigMaps in Namespace security-st
2022-02-17 10:13:46 [ForkJoinPool-1-worker-7] INFO  [LogCollector:216] Collecting logs for Pod(s) in Namespace security-st
2022-02-17 10:13:46 [ForkJoinPool-1-worker-7] INFO  [LogCollector:265] Collecting Deployments in Namespace security-st
2022-02-17 10:13:47 [ForkJoinPool-1-worker-7] INFO  [LogCollector:270] Collecting StatefulSets in Namespace security-st
2022-02-17 10:13:48 [ForkJoinPool-1-worker-7] INFO  [LogCollector:275] Collecting ReplicaSets in Namespace security-st
2022-02-17 10:13:49 [ForkJoinPool-1-worker-7] INFO  [LogCollector:280] Collecting Strimzi in Namespace security-st
2022-02-17 10:13:51 [ForkJoinPool-1-worker-7] INFO  [LogCollector:286] Collecting cluster status
2022-02-17 10:13:52 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:305] ############################################################################
2022-02-17 10:13:52 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:309] Delete all resources for testAutoReplaceAllCaKeysTriggeredByAnno
2022-02-17 10:13:52 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of KafkaTopic my-topic-702272404-1587300943 in namespace namespace-21
2022-02-17 10:13:52 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of KafkaUser my-user-1675042719-2100686491 in namespace namespace-21
2022-02-17 10:13:52 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of Kafka my-cluster-1709720907 in namespace namespace-21
2022-02-17 10:13:52 [ForkJoinPool-1-worker-1] INFO  [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-21, for cruise control Kafka cluster my-cluster-1709720907
2022-02-17 10:14:02 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of Deployment my-cluster-1709720907-kafka-clients in namespace namespace-21
2022-02-17 10:14:43 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:330] ############################################################################
2022-02-17 10:14:43 [ForkJoinPool-1-worker-7] INFO  [TestSuiteNamespaceManager:197] Deleting namespace:namespace-21 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-02-17 10:14:50 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-FINISHED
2022-02-17 10:14:50 [ForkJoinPool-1-worker-7] INFO  [TestSeparator:30] ############################################################################
2022-02-17 10:14:50 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:305] ############################################################################
2022-02-17 10:14:50 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:307] In context SecurityST is everything deleted.
2022-02-17 10:14:50 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:330] ############################################################################
[ERROR] Tests run: 23, Failures: 0, Errors: 3, Skipped: 0, Time elapsed: 4,401.35 s <<< FAILURE! - in io.strimzi.systemtest.security.SecurityST
[ERROR] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(ExtensionContext)  Time elapsed: 1,281.361 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 300000 ms waiting for Deployment my-cluster-799998736-kafka-exporter rolling update in namespace:namespace-20
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils.waitTillDepHasRolled(DeploymentUtils.java:137)
	at io.strimzi.systemtest.security.SecurityST.autoReplaceSomeKeysTriggeredByAnno(SecurityST.java:535)
	at io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(SecurityST.java:387)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:688)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:210)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:206)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:65)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)

[ERROR] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew(ExtensionContext)  Time elapsed: 1,136.105 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 840000 ms waiting for Resource condition: readiness is fulfilled for resource Kafka:my-cluster-206127643
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:254)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:216)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:145)
	at io.strimzi.systemtest.security.SecurityST.checkClusterCACertRenew(SecurityST.java:1533)
	at io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew(SecurityST.java:1506)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:688)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:210)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:206)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:65)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)

[ERROR] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno(ExtensionContext)  Time elapsed: 1,659.156 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 900000 ms waiting for component with name my-cluster-1709720907-kafka rolling update
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.RollingUpdateUtils.waitTillComponentHasRolled(RollingUpdateUtils.java:76)
	at io.strimzi.systemtest.security.SecurityST.autoReplaceSomeKeysTriggeredByAnno(SecurityST.java:504)
	at io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno(SecurityST.java:413)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:688)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:210)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:206)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:65)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)
	at java.base/java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)

2022-02-17 10:14:57 [ForkJoinPool-1-worker-3] INFO  [SetupClusterOperator:586] ============================================================================
2022-02-17 10:14:57 [ForkJoinPool-1-worker-3] INFO  [SetupClusterOperator:587] Un-installing cluster operator from infra-namespace namespace
2022-02-17 10:14:57 [ForkJoinPool-1-worker-3] INFO  [SetupClusterOperator:588] ============================================================================
2022-02-17 10:14:57 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:305] ############################################################################
2022-02-17 10:14:57 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:309] Delete all resources for JUnit Jupiter
2022-02-17 10:14:57 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-02-17 10:14:57 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-02-17 10:14:57 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-02-17 10:14:57 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-17 10:14:57 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-02-17 10:14:57 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-02-17 10:14:57 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-02-17 10:14:57 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-02-17 10:14:57 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-02-17 10:14:57 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-02-17 10:14:57 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:07 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-02-17 10:15:07 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-02-17 10:15:07 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-02-17 10:15:07 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:07 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:231] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:07 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-02-17 10:15:07 [ForkJoinPool-1-worker-5] INFO  [ResourceManager:231] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:08 [ForkJoinPool-1-worker-7] INFO  [ResourceManager:231] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:17 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-17 10:15:17 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-02-17 10:15:17 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-02-17 10:15:17 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-02-17 10:15:17 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-02-17 10:15:17 [ForkJoinPool-1-worker-1] INFO  [ResourceManager:231] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:27 [ForkJoinPool-1-worker-3] INFO  [ResourceManager:330] ############################################################################
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:40] =======================================================================
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:41] =======================================================================
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:42]                         Test run finished
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:43] =======================================================================
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:44] =======================================================================
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:29] =======================================================================
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:30] =======================================================================
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:31]                         Test run started
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:32] =======================================================================
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:33] =======================================================================
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:48] Following testclasses are selected for run:
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:51] -> io.strimzi.systemtest.security.SecurityST
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:52] =======================================================================
2022-02-17 10:15:37 [main] INFO  [TestExecutionListener:53] =======================================================================
[INFO] Running io.strimzi.systemtest.security.SecurityST
2022-02-17 10:15:37 [ForkJoinPool-2-worker-3] INFO  [SetupClusterOperator:195] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@216708a5
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-02-17 10:15:37 [ForkJoinPool-2-worker-3] INFO  [SetupClusterOperator:252] Install ClusterOperator via Yaml bundle
2022-02-17 10:15:37 [ForkJoinPool-2-worker-3] INFO  [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-02-17 10:15:37 [ForkJoinPool-2-worker-3] INFO  [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-02-17 10:15:37 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-02-17 10:15:37 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-17 10:15:37 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-02-17 10:15:37 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-02-17 10:15:37 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-02-17 10:15:37 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-02-17 10:15:37 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/my-fork/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-02-17 10:15:38 [ForkJoinPool-2-worker-3] INFO  [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-02-17 10:16:09 [ForkJoinPool-2-worker-3] INFO  [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-02-17 10:16:09 [ForkJoinPool-2-worker-3] INFO  [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [KubeClusterResource:156] Creating Namespace: security-st
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [KubeClusterResource:82] Client use Namespace: security-st
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: security-st
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [TestSeparator:23] ############################################################################
2022-02-17 10:16:19 [ForkJoinPool-2-worker-5] INFO  [TestSeparator:23] ############################################################################
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-STARTED
2022-02-17 10:16:19 [ForkJoinPool-2-worker-7] INFO  [TestSeparator:23] ############################################################################
2022-02-17 10:16:19 [ForkJoinPool-2-worker-5] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-STARTED
2022-02-17 10:16:19 [ForkJoinPool-2-worker-7] INFO  [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-STARTED
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-23 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [KubeClusterResource:156] Creating Namespace: namespace-23
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [KubeClusterResource:82] Client use Namespace: namespace-23
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-23
2022-02-17 10:16:19 [ForkJoinPool-2-worker-7] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 10:16:19 [ForkJoinPool-2-worker-7] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-24 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [SecurityST:601] Creating a cluster
2022-02-17 10:16:19 [ForkJoinPool-2-worker-7] INFO  [KubeClusterResource:156] Creating Namespace: namespace-24
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-1686981463 in namespace namespace-23
2022-02-17 10:16:19 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:161] Using Namespace: namespace-23
2022-02-17 10:16:20 [ForkJoinPool-2-worker-3] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-1686981463 will have desired state: Ready
2022-02-17 10:16:20 [ForkJoinPool-2-worker-7] INFO  [KubeClusterResource:82] Client use Namespace: namespace-24
2022-02-17 10:16:20 [ForkJoinPool-2-worker-7] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-24
2022-02-17 10:16:20 [ForkJoinPool-2-worker-5] INFO  [AbstractST:596] Not first test we are gonna generate cluster name
2022-02-17 10:16:20 [ForkJoinPool-2-worker-5] INFO  [TestSuiteNamespaceManager:160] Creating namespace:namespace-25 for test case:testClusterCACertRenew
2022-02-17 10:16:20 [ForkJoinPool-2-worker-7] INFO  [SecurityST:601] Creating a cluster
2022-02-17 10:16:20 [ForkJoinPool-2-worker-5] INFO  [KubeClusterResource:156] Creating Namespace: namespace-25
2022-02-17 10:16:20 [ForkJoinPool-2-worker-7] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-240705591 in namespace namespace-24
2022-02-17 10:16:20 [ForkJoinPool-2-worker-7] INFO  [ResourceManager:161] Using Namespace: namespace-24
2022-02-17 10:16:20 [ForkJoinPool-2-worker-7] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-240705591 will have desired state: Ready
2022-02-17 10:16:20 [ForkJoinPool-2-worker-5] INFO  [KubeClusterResource:82] Client use Namespace: namespace-25
2022-02-17 10:16:20 [ForkJoinPool-2-worker-5] INFO  [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-25
2022-02-17 10:16:20 [ForkJoinPool-2-worker-5] INFO  [ResourceManager:152] Create/Update Kafka my-cluster-510994227 in namespace namespace-25
2022-02-17 10:16:20 [ForkJoinPool-2-worker-5] INFO  [ResourceManager:161] Using Namespace: namespace-25
2022-02-17 10:16:20 [ForkJoinPool-2-worker-5] INFO  [ResourceManager:394] Wait for Kafka: my-cluster-510994227 will have desired state: Ready
