[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Build Order:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift                 [pom]
[[1;34mINFO[m] test                                                               [jar]
[[1;34mINFO[m] crd-annotations                                                    [jar]
[[1;34mINFO[m] crd-generator                                                      [jar]
[[1;34mINFO[m] api                                                                [jar]
[[1;34mINFO[m] mockkube                                                           [jar]
[[1;34mINFO[m] config-model                                                       [jar]
[[1;34mINFO[m] certificate-manager                                                [jar]
[[1;34mINFO[m] operator-common                                                    [jar]
[[1;34mINFO[m] systemtest                                                         [jar]
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------------< [0;36mio.strimzi:strimzi[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT [1/10][m
[[1;34mINFO[m] [1m--------------------------------[ pom ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mstrimzi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mstrimzi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping pom project
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--------------------------< [0;36mio.strimzi:test[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding test 0.29.0-SNAPSHOT                                     [2/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/test/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/test/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No sources to compile
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/test/target/test-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:crd-annotations[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding crd-annotations 0.29.0-SNAPSHOT                          [3/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-annotations/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-annotations/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/crd-annotations/target/crd-annotations-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:crd-generator[0;1m >----------------------[m
[[1;34mINFO[m] [1mBuilding crd-generator 0.29.0-SNAPSHOT                            [4/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-generator/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 7 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-shade-plugin:3.1.0:shade[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Including io.strimzi:crd-annotations:jar:0.29.0-SNAPSHOT in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-core:jar:2.12.6 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-databind:jar:2.12.6.1 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.12.6 in the shaded jar.
[[1;34mINFO[m] Including org.yaml:snakeyaml:jar:1.27 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-client:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-rbac:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-admissionregistration:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apps:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-autoscaling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apiextensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-batch:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-certificates:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-coordination:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-discovery:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-events:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-extensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-flowcontrol:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-networking:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-metrics:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-policy:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-scheduling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-storageclass:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-node:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:okhttp:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okio:okio:jar:1.15.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:logging-interceptor:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including org.slf4j:slf4j-api:jar:1.7.36 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.datatype:jackson-datatype-jsr310:jar:2.13.1 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:zjsonpatch:jar:0.3.0 in the shaded jar.
[[1;34mINFO[m] Including com.github.mifmif:generex:jar:1.0.2 in the shaded jar.
[[1;34mINFO[m] Including dk.brics.automaton:automaton:jar:1.11-8 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-core:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-common:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-annotations:jar:2.12.6 in the shaded jar.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, generex-1.0.2.jar define 7 overlapping classes: 
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator
[[1;33mWARNING[m]   - com.mifmif.common.regex.Generex
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator$Step
[[1;33mWARNING[m]   - com.mifmif.common.regex.Node
[[1;33mWARNING[m]   - com.mifmif.common.regex.Main
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterable
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterator
[[1;33mWARNING[m] kubernetes-model-rbac-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 80 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.AggregationRuleFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.PolicyRuleFluent
[[1;33mWARNING[m]   - 70 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-annotations-2.12.6.jar define 71 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonAutoDetect
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonInclude
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.ObjectIdGenerators
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Features
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonIgnore
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSetter
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonTypeInfo$None
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Shape
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSubTypes
[[1;33mWARNING[m]   - 61 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-extensions-5.12.0.jar define 264 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetConditionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DeploymentStrategyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicySpecFluent$IngressNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressSpecFluent$RulesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyPeerBuilder
[[1;33mWARNING[m]   - 254 more...
[[1;33mWARNING[m] kubernetes-model-autoscaling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricSpecFluentImpl$ObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.CrossVersionObjectReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.ContainerResourceMetricStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricStatusFluent$ObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpecFluent$ScaleTargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] kubernetes-model-storageclass-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 172 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIStorageCapacityListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeDriverFluentImpl$AllocatableNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.StorageClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.TokenRequestFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSINodeDriverFluent$AllocatableNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIDriverSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSpecFluent
[[1;33mWARNING[m]   - 162 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-batch-5.12.0.jar define 112 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobStatusFluentImpl$ActiveNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluent$TemplateNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluentImpl$TemplateNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.Job
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobListFluent
[[1;33mWARNING[m]   - 102 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-apiextensions-5.12.0.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrBoolBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionSpecFluent$ValidationNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionFluentImpl$SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrStringArraySerDe$Deserializer$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceValidationFluentImpl$OpenAPIV3SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsFluentImpl$NotNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.WebhookClientConfigFluentImpl$ServiceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrArrayFluent$SchemaNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1.JSONSchemaPropsOrBoolSerDe
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-discovery-5.12.0.jar define 88 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.ForZoneBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointFluent$TargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluentImpl$ConditionsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointConditionsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 78 more...
[[1;33mWARNING[m] okhttp-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 208 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.WebSocket
[[1;33mWARNING[m]   - okhttp3.Cookie$Builder
[[1;33mWARNING[m]   - okhttp3.internal.http.HttpHeaders
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$ReaderRunnable
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Reader$ContinuationSource
[[1;33mWARNING[m]   - okhttp3.internal.tls.OkHostnameVerifier
[[1;33mWARNING[m]   - okhttp3.Cache$Entry
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$3
[[1;33mWARNING[m]   - okhttp3.internal.ws.RealWebSocket$Streams
[[1;33mWARNING[m]   - okhttp3.CacheControl$Builder
[[1;33mWARNING[m]   - 198 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-metrics-5.12.0.jar define 30 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.ContainerMetricsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetrics
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl$ContainersNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListBuilder
[[1;33mWARNING[m]   - 20 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-flowcontrol-5.12.0.jar define 132 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowSchemaConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowDistinguisherMethodBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfigurationFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReference
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PolicyRulesWithSubjects
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationListFluent$ItemsNested
[[1;33mWARNING[m]   - 122 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-events-5.12.0.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$SeriesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$RegardingNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventSeriesFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] automaton-1.11-8.jar, crd-generator-0.29.0-SNAPSHOT.jar define 25 overlapping classes: 
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonMatcher
[[1;33mWARNING[m]   - dk.brics.automaton.ShuffleOperations$ShuffleConfiguration
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$Kind
[[1;33mWARNING[m]   - dk.brics.automaton.RunAutomaton
[[1;33mWARNING[m]   - dk.brics.automaton.Automaton
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonProvider
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$1
[[1;33mWARNING[m]   - dk.brics.automaton.MinimizationOperations$StateListNode
[[1;33mWARNING[m]   - dk.brics.automaton.State
[[1;33mWARNING[m]   - 15 more...
[[1;33mWARNING[m] jackson-core-2.12.6.jar, crd-generator-0.29.0-SNAPSHOT.jar define 124 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.JsonGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.json.JsonReadFeature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.ThreadLocalBufferManager$ThreadLocalBufferManagerHolder
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.Separators
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.io.SegmentedStringWriter
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.TreeNode
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.sym.Name
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.RequestPayload
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.JsonGeneratorDelegate
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.async.NonBlockingInputFeeder
[[1;33mWARNING[m]   - 114 more...
[[1;33mWARNING[m] kubernetes-model-networking-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 234 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressServiceBackend
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressClassFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressRuleFluentImpl$HttpNestedImpl
[[1;33mWARNING[m]   - 224 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-coordination-5.12.0.jar define 18 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluent
[[1;33mWARNING[m]   - 8 more...
[[1;33mWARNING[m] zjsonpatch-0.3.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.InsertCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Operation
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.CommandVisitor
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.guava.Strings
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.EditCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonDiff$EncodePathFunction
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.SequencesComparator
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Diff
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.ListUtils
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonPatch
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-common-5.12.0.jar define 16 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Plural
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Group
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer$CancelUnwrapped
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.PrinterColumn
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.UnwrappedTypeResolverBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Singular
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.StatusReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.SpecReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Version
[[1;33mWARNING[m]   - 6 more...
[[1;33mWARNING[m] kubernetes-model-admissionregistration-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 362 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluent$ObjectSelectorNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1.SubjectAccessReviewSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SubjectRulesReviewStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.ValidatingWebhookConfigurationBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authentication.TokenReviewFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectRulesReviewSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluentImpl$NamespaceSelectorNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookConfigurationFluentImpl$WebhooksNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectAccessReviewFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.MutatingWebhookFluent$ClientConfigNested
[[1;33mWARNING[m]   - 352 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, okio-1.15.0.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - okio.ByteString
[[1;33mWARNING[m]   - okio.Source
[[1;33mWARNING[m]   - okio.ForwardingSink
[[1;33mWARNING[m]   - okio.BufferedSource
[[1;33mWARNING[m]   - okio.Util
[[1;33mWARNING[m]   - okio.AsyncTimeout$1
[[1;33mWARNING[m]   - okio.HashingSource
[[1;33mWARNING[m]   - okio.GzipSink
[[1;33mWARNING[m]   - okio.Okio$1
[[1;33mWARNING[m]   - okio.Pipe$PipeSink
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-certificates-5.12.0.jar define 60 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestConditionFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl
[[1;33mWARNING[m]   - 50 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-datatype-jsr310-2.13.1.jar define 59 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.Jsr310KeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.PackageVersion
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.YearDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.key.Jsr310NullKeySerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.LocalDateTimeKeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.util.DurationUnitConverter
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.InstantSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.OffsetDateTimeSerializer
[[1;33mWARNING[m]   - 49 more...
[[1;33mWARNING[m] crd-annotations-0.29.0-SNAPSHOT.jar, crd-generator-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$Stability
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$1
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedType
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedProperty
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange$VersionParser
[[1;33mWARNING[m]   - io.strimzi.api.annotations.KubeVersion
[[1;33mWARNING[m] kubernetes-model-apps-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 212 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentStrategyFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluent$DeploymentDataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluentImpl$PersistentVolumeClaimDataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetCondition
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - 202 more...
[[1;33mWARNING[m] logging-interceptor-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger$1
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$Factory
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Level
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor
[[1;33mWARNING[m]   - okhttp3.logging.package-info
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$1
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger
[[1;33mWARNING[m] jackson-dataformat-yaml-2.12.6.jar, crd-generator-0.29.0-SNAPSHOT.jar define 17 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLMapper$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.snakeyaml.error.Mark
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.UTF8Reader
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.util.StringQuotingChecker
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.JacksonYAMLParseException
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.util.StringQuotingChecker$Default
[[1;33mWARNING[m]   - 7 more...
[[1;33mWARNING[m] kubernetes-model-core-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 2394 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.BaseKubernetesListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.StatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.KubeSchemaFluentImpl$APIResourceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.NodeListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ResourceQuotaListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluentImpl$APIServiceStatusObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluent$VsphereVirtualDiskVolumeSourceObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ProbeFluentImpl$HttpGetNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.PatchOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ServerAddressByClientCIDRFluentImpl
[[1;33mWARNING[m]   - 2384 more...
[[1;33mWARNING[m] slf4j-api-1.7.36.jar, crd-generator-0.29.0-SNAPSHOT.jar define 34 overlapping classes: 
[[1;33mWARNING[m]   - org.slf4j.helpers.SubstituteLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.NamedLoggerBase
[[1;33mWARNING[m]   - org.slf4j.helpers.NOPMDCAdapter
[[1;33mWARNING[m]   - org.slf4j.MarkerFactory
[[1;33mWARNING[m]   - org.slf4j.helpers.BasicMarker
[[1;33mWARNING[m]   - org.slf4j.spi.LoggerFactoryBinder
[[1;33mWARNING[m]   - org.slf4j.MDC$MDCCloseable
[[1;33mWARNING[m]   - org.slf4j.spi.LocationAwareLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.MessageFormatter
[[1;33mWARNING[m]   - org.slf4j.helpers.Util$ClassContextSecurityManager
[[1;33mWARNING[m]   - 24 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-node-5.12.0.jar define 78 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.OverheadBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.Scheduling
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.SchedulingFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.RuntimeClassSpecFluent$OverheadNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - 68 more...
[[1;33mWARNING[m] jackson-databind-2.12.6.1.jar, crd-generator-0.29.0-SNAPSHOT.jar define 700 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$NoAnnotations
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.jsontype.BasicPolymorphicTypeValidator$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.BeanDescription
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.deser.impl.BeanAsArrayBuilderDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotatedMethodMap
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.SerializerProvider
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$OneAnnotation
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.StaticListSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.NumberSerializers$ShortSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.BeanSerializerFactory
[[1;33mWARNING[m]   - 690 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, snakeyaml-1.27.jar define 216 overlapping classes: 
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockNode
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingSimpleValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectDocumentEnd
[[1;33mWARNING[m]   - org.yaml.snakeyaml.Yaml$3
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockSequenceItem
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockSequenceEntry
[[1;33mWARNING[m]   - org.yaml.snakeyaml.util.ArrayUtils
[[1;33mWARNING[m]   - org.yaml.snakeyaml.tokens.Token$ID
[[1;33mWARNING[m]   - org.yaml.snakeyaml.reader.StreamReader
[[1;33mWARNING[m]   - 206 more...
[[1;33mWARNING[m] kubernetes-client-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 536 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.CertUtils
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.CustomResource
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.osgi.ManagedKubernetesClient
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.V1beta1ApiextensionAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.PatchUtils$SingletonHolder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.VersionInfo$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.utils.ReplaceValueStream
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.CreateFromServerGettable
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.ApiextensionsAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.Containerable
[[1;33mWARNING[m]   - 526 more...
[[1;33mWARNING[m] kubernetes-model-scheduling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassFluent$MetadataNested
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] kubernetes-model-policy-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 162 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1.PodDisruptionBudgetList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.HostPortRangeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.EvictionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$AllowedCSIDriversNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.AllowedFlexVolumeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.IDRangeFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.SELinuxStrategyOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$FsGroupNestedImpl
[[1;33mWARNING[m]   - 152 more...
[[1;33mWARNING[m] maven-shade-plugin has detected that some class files are
[[1;33mWARNING[m] present in two or more JARs. When this happens, only one
[[1;33mWARNING[m] single version of the class is copied to the uber jar.
[[1;33mWARNING[m] Usually this is not harmful and you can skip these warnings,
[[1;33mWARNING[m] otherwise try to manually exclude artifacts based on
[[1;33mWARNING[m] mvn dependency:tree -Ddetail=true and the above output.
[[1;33mWARNING[m] See http://maven.apache.org/plugins/maven-shade-plugin/
[[1;34mINFO[m] Replacing original artifact with shaded artifact.
[[1;34mINFO[m] Replacing /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT.jar with /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-shaded.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------------< [0;36mio.strimzi:api[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding api 0.29.0-SNAPSHOT                                      [5/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/api/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1)[m @ [36mapi[0;1m ---[m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1-eo)[m @ [36mapi[0;1m ---[m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-doc)[m @ [36mapi[0;1m ---[m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 99 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-test-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mapi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mapi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m------------------------< [0;36mio.strimzi:mockkube[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding mockkube 0.29.0-SNAPSHOT                                 [6/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/mockkube/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mmockkube[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mmockkube[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/mockkube/target/mockkube-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:config-model[0;1m >-----------------------[m
[[1;34mINFO[m] [1mBuilding config-model 0.29.0-SNAPSHOT                             [7/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/config-model/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/config-model/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mconfig-model[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mconfig-model[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/config-model/target/config-model-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------< [0;36mio.strimzi:certificate-manager[0;1m >-------------------[m
[[1;34mINFO[m] [1mBuilding certificate-manager 0.29.0-SNAPSHOT                      [8/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/certificate-manager/target/certificate-manager-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:operator-common[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding operator-common 0.29.0-SNAPSHOT                          [9/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/operator-common/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 9 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36moperator-common[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36moperator-common[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/operator-common/target/operator-common-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-----------------------< [0;36mio.strimzi:systemtest[0;1m >------------------------[m
[[1;34mINFO[m] [1mBuilding systemtest 0.29.0-SNAPSHOT                              [10/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 3 resources
[[1;34mINFO[m] Copying 2 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 32 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;33mWARNING[m] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file /home/ec2-user/strimzi-kafka-operator/systemtest/target/surefire-reports/2022-04-04T06-54-35_684-jvmRun1.dumpstream
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36msystemtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36msystemtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.user.UserST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.topic.TopicST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.ReconciliationST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeScramShaST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeTlsST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.tracing.TracingST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.KafkaST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.ListenersST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.MultipleListenersST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.ConfigProviderST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.OpaIntegrationST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.SecurityST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.custom.CustomAuthorizerST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.log.LoggingChangeST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.log.LogSettingST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.FeatureGatesIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.RecoveryIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.SpecificIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.DrainCleanerIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.connect.ConnectIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.metrics.MetricsIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.metrics.JmxIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-04-04 06:54:55 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.user.UserST
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:219] Used environment variables:
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:220] CONFIG: /home/ec2-user/strimzi-kafka-operator/systemtest/config.json
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] STRIMZI_RBAC_SCOPE: CLUSTER
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] OLM_APP_BUNDLE_PREFIX: strimzi-cluster-operator
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] TEST_CLIENTS_VERSION: 0.2.0
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] OLM_SOURCE_NAMESPACE: openshift-marketplace
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] CLUSTER_OPERATOR_INSTALL_TYPE: BUNDLE
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] STRIMZI_COMPONENTS_LOG_LEVEL: INFO
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] SKIP_TEARDOWN: false
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] LB_FINALIZERS: false
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_DEPLOYMENT_NAME: strimzi-cluster-operator
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] DOCKER_ORG: strimzi
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] TEST_LOG_DIR: /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/target/logs/
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] COMPONENTS_IMAGE_PULL_POLICY: IfNotPresent
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] DOCKER_REGISTRY: quay.io
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] TEST_CLIENT_IMAGE: quay.io/strimzi/test-client:latest-kafka-3.1.0
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] SYSTEM_TEST_STRIMZI_IMAGE_PULL_SECRET: 
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] TEST_ADMIN_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-admin:0.2.0-kafka-3.1.0
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] TEST_HTTP_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-http-producer:0.2.0
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_NAME: strimzi-kafka-operator
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] DOCKER_TAG: latest
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] OLM_SOURCE_NAME: community-operators
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] STRIMZI_FEATURE_GATES: 
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] CLIENTS_KAFKA_VERSION: 3.1.0
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] TEST_HTTP_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-http-consumer:0.2.0
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] STRIMZI_LOG_LEVEL: DEBUG
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] ST_KAFKA_VERSION: 3.1.0
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] OPERATOR_IMAGE_PULL_POLICY: Always
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] DEFAULT_TO_DENY_NETWORK_POLICIES: true
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] TEST_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-producer:0.2.0-kafka-3.1.0
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] BRIDGE_IMAGE: latest-released
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] TEST_STREAMS_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-streams:0.2.0-kafka-3.1.0
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] TEST_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-consumer:0.2.0-kafka-3.1.0
2022-04-04 06:54:55 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_VERSION: 
2022-04-04 06:54:56 [main] [32mINFO [m [KubeCluster:87] Using cluster: minikube
2022-04-04 06:54:56 [main] [32mINFO [m [KubeClusterResource:60] Cluster default namespace is 'default'
2022-04-04 06:54:56 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 06:54:56 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 06:54:56 [main] [33mWARN [m [KubeClusterResource:151] Namespace infra-namespace is already created, going to delete it
2022-04-04 06:55:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 06:55:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 06:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 06:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 06:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 06:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 06:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 06:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 06:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 06:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 06:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 06:55:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 06:55:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 06:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 06:55:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 06:55:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 06:55:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 06:55:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 06:55:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 06:55:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 06:55:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 06:55:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 06:55:10 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 06:55:10 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 06:55:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 06:55:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 06:55:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 06:55:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 06:55:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 06:55:31 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 06:55:41 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 06:55:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: user-st
2022-04-04 06:55:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: user-st
2022-04-04 06:55:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: user-st
2022-04-04 06:55:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka user-cluster-name in namespace user-st
2022-04-04 06:55:42 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkas' with unstable version 'v1beta2'
2022-04-04 06:55:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: user-cluster-name will have desired state: Ready
2022-04-04 06:56:39 [main] [32mINFO [m [ResourceManager:444] Kafka: user-cluster-name is in desired state: Ready
2022-04-04 06:56:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 06:56:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUserWithQuotas-STARTED
2022-04-04 06:56:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 06:56:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1742502971-1354039067 in namespace user-st
2022-04-04 06:56:39 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkausers' with unstable version 'v1beta2'
2022-04-04 06:56:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1742502971-1354039067 will have desired state: Ready
2022-04-04 06:56:40 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1742502971-1354039067 is in desired state: Ready
2022-04-04 06:56:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=my-user-1742502971-1354039067
2022-04-04 06:56:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 06:56:43 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion my-user-1742502971-1354039067
2022-04-04 06:56:43 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser my-user-1742502971-1354039067 is not deleted yet! Triggering force delete by cmd client!
2022-04-04 06:56:44 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser my-user-1742502971-1354039067 deleted
2022-04-04 06:56:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=my-user-1742502971-1354039067
2022-04-04 06:56:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 06:56:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 06:56:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsExternalUserWithQuotas
2022-04-04 06:56:47 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1742502971-1354039067 in namespace user-st
2022-04-04 06:56:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 06:56:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUserWithQuotas-FINISHED
2022-04-04 06:56:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 06:56:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 06:56:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUserTemplate-STARTED
2022-04-04 06:56:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 06:56:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1069347253-1588464152 in namespace user-st
2022-04-04 06:56:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1069347253-1588464152 will have desired state: Ready
2022-04-04 06:56:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1069347253-1588464152 is in desired state: Ready
2022-04-04 06:56:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 06:56:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserTemplate
2022-04-04 06:56:48 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1069347253-1588464152 in namespace user-st
2022-04-04 06:56:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 06:56:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUserTemplate-FINISHED
2022-04-04 06:56:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 06:56:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 06:56:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUpdateUser-STARTED
2022-04-04 06:56:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 06:56:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1630659665-1504156660 in namespace user-st
2022-04-04 06:56:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1630659665-1504156660 will have desired state: Ready
2022-04-04 06:56:59 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1630659665-1504156660 is in desired state: Ready
2022-04-04 06:57:00 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-user-1630659665-1504156660
2022-04-04 06:57:00 [main] [32mINFO [m [SecretUtils:50] Secret my-user-1630659665-1504156660 created
2022-04-04 06:57:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1630659665-1504156660 will have desired state: Ready
2022-04-04 06:57:00 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1630659665-1504156660 is in desired state: Ready
2022-04-04 06:57:00 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion my-user-1630659665-1504156660
2022-04-04 06:57:00 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser my-user-1630659665-1504156660 deleted
2022-04-04 06:57:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 06:57:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateUser
2022-04-04 06:57:00 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1630659665-1504156660 in namespace user-st
2022-04-04 06:57:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 06:57:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUpdateUser-FINISHED
2022-04-04 06:57:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 06:57:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 06:57:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUser-STARTED
2022-04-04 06:57:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 06:57:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-0 for test case:testTlsExternalUser
2022-04-04 06:57:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-0
2022-04-04 06:57:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-0
2022-04-04 06:57:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-0
2022-04-04 06:57:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8ae593c6 in namespace namespace-0
2022-04-04 06:57:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-0
2022-04-04 06:57:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8ae593c6 will have desired state: Ready
2022-04-04 06:58:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8ae593c6 is in desired state: Ready
2022-04-04 06:58:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1500057521-1113941398 in namespace namespace-0
2022-04-04 06:58:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-0
2022-04-04 06:58:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1500057521-1113941398 will have desired state: Ready
2022-04-04 06:58:20 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1500057521-1113941398 is in desired state: Ready
2022-04-04 06:58:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1500057521-1113941398 will have desired state: Ready
2022-04-04 06:58:20 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1500057521-1113941398 is in desired state: Ready
2022-04-04 06:58:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 06:58:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsExternalUser
2022-04-04 06:58:20 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1500057521-1113941398 in namespace namespace-0
2022-04-04 06:58:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8ae593c6 in namespace namespace-0
2022-04-04 06:58:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 06:58:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-0 for test case:testTlsExternalUser
2022-04-04 06:58:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUser-FINISHED
2022-04-04 06:58:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 06:58:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 06:58:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUserWithNameMoreThan64Chars-STARTED
2022-04-04 06:58:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 06:58:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq in namespace user-st
2022-04-04 06:58:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq will have desired state: Ready
2022-04-04 06:58:42 [main] [32mINFO [m [ResourceManager:444] KafkaUser: user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq is in desired state: Ready
2022-04-04 06:58:42 [main] [32mINFO [m [KafkaUserUtils:90] Wait until KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq status is available
2022-04-04 06:58:42 [main] [32mINFO [m [KafkaUserUtils:95] KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq status is available
2022-04-04 06:58:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace user-st
2022-04-04 06:58:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef will have desired state: Ready
2022-04-04 06:58:43 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: Ready
2022-04-04 06:58:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk in namespace user-st
2022-04-04 06:58:43 [main] [32mINFO [m [KafkaUserUtils:90] Wait until KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk status is available
2022-04-04 06:58:44 [main] [32mINFO [m [KafkaUserUtils:95] KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk status is available
2022-04-04 06:58:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 06:58:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserWithNameMoreThan64Chars
2022-04-04 06:58:44 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace user-st
2022-04-04 06:58:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq in namespace user-st
2022-04-04 06:58:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk in namespace user-st
2022-04-04 06:58:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 06:58:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUserWithNameMoreThan64Chars-FINISHED
2022-04-04 06:58:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 06:58:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 06:58:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsUserWithQuotas-STARTED
2022-04-04 06:58:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 06:58:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser encrypted-arnost in namespace user-st
2022-04-04 06:58:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: encrypted-arnost will have desired state: Ready
2022-04-04 06:58:55 [main] [32mINFO [m [ResourceManager:444] KafkaUser: encrypted-arnost is in desired state: Ready
2022-04-04 06:58:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=encrypted-arnost
2022-04-04 06:58:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 06:58:57 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion encrypted-arnost
2022-04-04 06:58:57 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser encrypted-arnost is not deleted yet! Triggering force delete by cmd client!
2022-04-04 06:58:59 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser encrypted-arnost deleted
2022-04-04 06:59:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=encrypted-arnost
2022-04-04 06:59:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 06:59:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 06:59:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsUserWithQuotas
2022-04-04 06:59:01 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser encrypted-arnost in namespace user-st
2022-04-04 06:59:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 06:59:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsUserWithQuotas-FINISHED
2022-04-04 06:59:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 06:59:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 06:59:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testScramUserWithQuotas-STARTED
2022-04-04 06:59:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 06:59:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser scramed-arnost in namespace user-st
2022-04-04 06:59:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: scramed-arnost will have desired state: Ready
2022-04-04 06:59:02 [main] [32mINFO [m [ResourceManager:444] KafkaUser: scramed-arnost is in desired state: Ready
2022-04-04 06:59:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user scramed-arnost
2022-04-04 06:59:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 06:59:05 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion scramed-arnost
2022-04-04 06:59:05 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser scramed-arnost is not deleted yet! Triggering force delete by cmd client!
2022-04-04 06:59:06 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser scramed-arnost deleted
2022-04-04 06:59:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user scramed-arnost
2022-04-04 06:59:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 06:59:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 06:59:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScramUserWithQuotas
2022-04-04 06:59:08 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser scramed-arnost in namespace user-st
2022-04-04 06:59:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 06:59:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testScramUserWithQuotas-FINISHED
2022-04-04 06:59:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 06:59:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 06:59:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testCreatingUsersWithSecretPrefix-STARTED
2022-04-04 06:59:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 06:59:08 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-1 for test case:testCreatingUsersWithSecretPrefix
2022-04-04 06:59:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-1
2022-04-04 06:59:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-1
2022-04-04 06:59:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-1
2022-04-04 06:59:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-53017561 in namespace namespace-1
2022-04-04 06:59:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-04 06:59:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-53017561 will have desired state: Ready
2022-04-04 07:00:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-53017561 is in desired state: Ready
2022-04-04 07:00:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1434824349-1259210541 in namespace namespace-1
2022-04-04 07:00:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-04 07:00:27 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkatopics' with unstable version 'v1beta2'
2022-04-04 07:00:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1434824349-1259210541 will have desired state: Ready
2022-04-04 07:00:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1434824349-1259210541 is in desired state: Ready
2022-04-04 07:00:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser encrypted-leopold in namespace namespace-1
2022-04-04 07:00:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-04 07:00:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: encrypted-leopold will have desired state: Ready
2022-04-04 07:00:29 [main] [32mINFO [m [ResourceManager:444] KafkaUser: encrypted-leopold is in desired state: Ready
2022-04-04 07:00:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser scramed-leopold in namespace namespace-1
2022-04-04 07:00:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-04 07:00:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: scramed-leopold will have desired state: Ready
2022-04-04 07:00:30 [main] [32mINFO [m [ResourceManager:444] KafkaUser: scramed-leopold is in desired state: Ready
2022-04-04 07:00:30 [main] [32mINFO [m [UserST:346] Deploying KafkaClients pod for TLS listener
2022-04-04 07:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-53017561-tls-kafka-clients in namespace namespace-1
2022-04-04 07:00:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-04 07:00:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-53017561-tls-kafka-clients will be ready
2022-04-04 07:00:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-53017561-tls-kafka-clients is ready
2022-04-04 07:00:32 [main] [32mINFO [m [UserST:350] Deploying KafkaClients pod for PLAIN listener
2022-04-04 07:00:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-53017561-plain-kafka-clients in namespace namespace-1
2022-04-04 07:00:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-04 07:00:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-53017561-plain-kafka-clients will be ready
2022-04-04 07:00:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-53017561-plain-kafka-clients is ready
2022-04-04 07:00:34 [main] [32mINFO [m [UserST:357] Checking if user secrets with secret prefixes exists
2022-04-04 07:00:34 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 07:00:34 [main] [32mINFO [m [UserST:373] Checking if TLS user is able to send messages
2022-04-04 07:00:34 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@70b0812a, messages=[], arguments=[--topic, my-topic-1670769365-1601814202, --max-messages, 100, USER=top_secret_encrypted_leopold, --bootstrap-server, my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-53017561-tls-kafka-clients-74ddb76d7c-fpv69', podNamespace='namespace-1', bootstrapServer='my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9093', topicName='my-topic-1670769365-1601814202', maxMessages=100, kafkaUsername='top-secret-encrypted-leopold', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3c255eb9}
2022-04-04 07:00:34 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9093:my-topic-1670769365-1601814202 from pod my-cluster-53017561-tls-kafka-clients-74ddb76d7c-fpv69
2022-04-04 07:00:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-53017561-tls-kafka-clients-74ddb76d7c-fpv69 -n namespace-1 -- /opt/kafka/producer.sh --topic my-topic-1670769365-1601814202 --max-messages 100 USER=top_secret_encrypted_leopold --bootstrap-server my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9093
2022-04-04 07:00:38 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 07:00:38 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 07:00:38 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@52298f36, messages=[], arguments=[--topic, my-topic-1670769365-1601814202, --max-messages, 100, --group-instance-id, instance416348522, --group-id, my-consumer-group-266467269, USER=top_secret_encrypted_leopold, --bootstrap-server, my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-53017561-tls-kafka-clients-74ddb76d7c-fpv69', podNamespace='namespace-1', bootstrapServer='my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9093', topicName='my-topic-1670769365-1601814202', maxMessages=100, kafkaUsername='top-secret-encrypted-leopold', consumerGroupName='my-consumer-group-266467269', consumerInstanceId='instance416348522', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6a8e8a2c}
2022-04-04 07:00:38 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9093:my-topic-1670769365-1601814202 from pod my-cluster-53017561-tls-kafka-clients-74ddb76d7c-fpv69
2022-04-04 07:00:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-53017561-tls-kafka-clients-74ddb76d7c-fpv69 -n namespace-1 -- /opt/kafka/consumer.sh --topic my-topic-1670769365-1601814202 --max-messages 100 --group-instance-id instance416348522 --group-id my-consumer-group-266467269 USER=top_secret_encrypted_leopold --bootstrap-server my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9093
2022-04-04 07:00:45 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 07:00:45 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 07:00:45 [main] [32mINFO [m [UserST:386] Checking if SCRAM-SHA user is able to send messages
2022-04-04 07:00:45 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@66d5f68e, messages=[], arguments=[--topic, my-topic-1670769365-1601814202, --max-messages, 100, USER=top_secret_scramed_leopold, --bootstrap-server, my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-53017561-plain-kafka-clients-7cd5d6c474-24lpr', podNamespace='namespace-1', bootstrapServer='my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-1670769365-1601814202', maxMessages=100, kafkaUsername='top-secret-scramed-leopold', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2840d256}
2022-04-04 07:00:45 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9092:my-topic-1670769365-1601814202 from pod my-cluster-53017561-plain-kafka-clients-7cd5d6c474-24lpr
2022-04-04 07:00:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-53017561-plain-kafka-clients-7cd5d6c474-24lpr -n namespace-1 -- /opt/kafka/producer.sh --topic my-topic-1670769365-1601814202 --max-messages 100 USER=top_secret_scramed_leopold --bootstrap-server my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9092
2022-04-04 07:00:48 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 07:00:48 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 07:00:48 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@66dabf89, messages=[], arguments=[--topic, my-topic-1670769365-1601814202, --max-messages, 100, --group-instance-id, instance778865018, --group-id, my-consumer-group-266467269, USER=top_secret_scramed_leopold, --bootstrap-server, my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-53017561-plain-kafka-clients-7cd5d6c474-24lpr', podNamespace='namespace-1', bootstrapServer='my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-1670769365-1601814202', maxMessages=100, kafkaUsername='top-secret-scramed-leopold', consumerGroupName='my-consumer-group-266467269', consumerInstanceId='instance778865018', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7894cf92}
2022-04-04 07:00:48 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9092#my-topic-1670769365-1601814202 from pod my-cluster-53017561-plain-kafka-clients-7cd5d6c474-24lpr
2022-04-04 07:00:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-53017561-plain-kafka-clients-7cd5d6c474-24lpr -n namespace-1 -- /opt/kafka/consumer.sh --topic my-topic-1670769365-1601814202 --max-messages 100 --group-instance-id instance778865018 --group-id my-consumer-group-266467269 USER=top_secret_scramed_leopold --bootstrap-server my-cluster-53017561-kafka-bootstrap.namespace-1.svc:9092
2022-04-04 07:01:15 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 07:01:15 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 07:01:15 [main] [32mINFO [m [UserST:392] Checking owner reference - if the secret will be deleted when we delete KafkaUser
2022-04-04 07:01:15 [main] [32mINFO [m [UserST:394] Deleting KafkaUser:encrypted-leopold
2022-04-04 07:01:15 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion encrypted-leopold
2022-04-04 07:01:15 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser encrypted-leopold deleted
2022-04-04 07:01:15 [main] [32mINFO [m [UserST:398] Deleting KafkaUser:scramed-leopold
2022-04-04 07:01:15 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion scramed-leopold
2022-04-04 07:01:15 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser scramed-leopold deleted
2022-04-04 07:01:15 [main] [32mINFO [m [UserST:402] Checking if secrets are deleted
2022-04-04 07:01:15 [main] [32mINFO [m [SecretUtils:54] Waiting for Secret deletion top-secret-encrypted-leopold
2022-04-04 07:01:17 [main] [32mINFO [m [SecretUtils:58] Secret top-secret-encrypted-leopold deleted
2022-04-04 07:01:17 [main] [32mINFO [m [SecretUtils:54] Waiting for Secret deletion top-secret-scramed-leopold
2022-04-04 07:01:17 [main] [32mINFO [m [SecretUtils:58] Secret top-secret-scramed-leopold deleted
2022-04-04 07:01:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:01:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreatingUsersWithSecretPrefix
2022-04-04 07:01:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser scramed-leopold in namespace namespace-1
2022-04-04 07:01:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-53017561 in namespace namespace-1
2022-04-04 07:01:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1434824349-1259210541 in namespace namespace-1
2022-04-04 07:01:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser encrypted-leopold in namespace namespace-1
2022-04-04 07:01:17 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-53017561-plain-kafka-clients in namespace namespace-1
2022-04-04 07:01:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-53017561-tls-kafka-clients in namespace namespace-1
2022-04-04 07:01:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:01:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-1 for test case:testCreatingUsersWithSecretPrefix
2022-04-04 07:02:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testCreatingUsersWithSecretPrefix-FINISHED
2022-04-04 07:02:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:02:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:02:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for UserST
2022-04-04 07:02:02 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka user-cluster-name in namespace user-st
2022-04-04 07:02:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 12, Failures: 0, Errors: 0, Skipped: 4, Time elapsed: 442.875 s - in io.strimzi.systemtest.operators.user.UserST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
2022-04-04 07:02:18 [main] [33mWARN [m [KubeClusterResource:151] Namespace throttling-quota-st is already created, going to delete it
2022-04-04 07:02:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: throttling-quota-st
2022-04-04 07:02:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: throttling-quota-st
2022-04-04 07:02:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: throttling-quota-st
2022-04-04 07:02:31 [main] [32mINFO [m [ThrottlingQuotaST:304] Deploying shared Kafka across all test cases in throttling-quota-st namespace
2022-04-04 07:02:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka quota-cluster in namespace throttling-quota-st
2022-04-04 07:02:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: quota-cluster will have desired state: Ready
2022-04-04 07:03:37 [main] [32mINFO [m [ResourceManager:444] Kafka: quota-cluster is in desired state: Ready
2022-04-04 07:03:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:03:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateAlterPartitions-STARTED
2022-04-04 07:03:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:03:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-129409157-1551159984 in namespace throttling-quota-st
2022-04-04 07:03:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-129409157-1551159984 will have desired state: Ready
2022-04-04 07:03:38 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-129409157-1551159984 is in desired state: Ready
2022-04-04 07:03:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-18bb722a-kafka-clients in namespace throttling-quota-st
2022-04-04 07:03:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-18bb722a-kafka-clients will be in active state
2022-04-04 07:03:39 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:07:41 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in create-admin-my-cluster-18bb722a-kafka-clients-tnrtb log
2022-04-04 07:07:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-18bb722a-kafka-clients in namespace throttling-quota-st
2022-04-04 07:07:46 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-18bb722a-kafka-clients will be in active state
2022-04-04 07:07:47 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:08:49 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-18bb722a-kafka-clients-969gz log
2022-04-04 07:08:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Job alter-admin-my-cluster-18bb722a-kafka-clients in namespace throttling-quota-st
2022-04-04 07:08:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: alter-admin-my-cluster-18bb722a-kafka-clients will be in active state
2022-04-04 07:08:55 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:12:56 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in alter-admin-my-cluster-18bb722a-kafka-clients-cpf2g log
2022-04-04 07:13:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job teardown-delete in namespace throttling-quota-st
2022-04-04 07:13:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: teardown-delete will be in active state
2022-04-04 07:13:03 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:teardown-delete to finished
2022-04-04 07:14:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:14:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasCreateAlterPartitions
2022-04-04 07:14:10 [main] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-18bb722a-kafka-clients in namespace throttling-quota-st
2022-04-04 07:14:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-18bb722a-kafka-clients in namespace throttling-quota-st
2022-04-04 07:14:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job teardown-delete in namespace throttling-quota-st
2022-04-04 07:14:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job alter-admin-my-cluster-18bb722a-kafka-clients in namespace throttling-quota-st
2022-04-04 07:14:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-129409157-1551159984 in namespace throttling-quota-st
2022-04-04 07:14:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:14:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateAlterPartitions-FINISHED
2022-04-04 07:14:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:14:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:14:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testKafkaAdminTopicOperations-STARTED
2022-04-04 07:14:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:14:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1202905358-922611816 in namespace throttling-quota-st
2022-04-04 07:14:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1202905358-922611816 will have desired state: Ready
2022-04-04 07:14:11 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1202905358-922611816 is in desired state: Ready
2022-04-04 07:14:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-9fb57efa-kafka-clients in namespace throttling-quota-st
2022-04-04 07:14:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-9fb57efa-kafka-clients will be in active state
2022-04-04 07:14:12 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:15:42 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-9fb57efa-kafka-clients-xxpq8 log
2022-04-04 07:15:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job list-admin-my-cluster-9fb57efa-kafka-clients in namespace throttling-quota-st
2022-04-04 07:15:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: list-admin-my-cluster-9fb57efa-kafka-clients will be in active state
2022-04-04 07:15:48 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:15:50 [main] [32mINFO [m [PodUtils:189] Message quota-topic-test-simple-99 found in list-admin-my-cluster-9fb57efa-kafka-clients-mqj9w log
2022-04-04 07:16:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-9fb57efa-kafka-clients in namespace throttling-quota-st
2022-04-04 07:16:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-9fb57efa-kafka-clients will be in active state
2022-04-04 07:16:01 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:17:31 [main] [32mINFO [m [PodUtils:189] Message Successfully removed all 100 found in delete-admin-my-cluster-9fb57efa-kafka-clients-jpszz log
2022-04-04 07:17:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job list-admin-my-cluster-9fb57efa-kafka-clients in namespace throttling-quota-st
2022-04-04 07:17:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: list-admin-my-cluster-9fb57efa-kafka-clients will be in active state
2022-04-04 07:17:37 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:list-admin-my-cluster-9fb57efa-kafka-clients to finished
2022-04-04 07:17:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:17:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAdminTopicOperations
2022-04-04 07:17:39 [main] [32mINFO [m [ResourceManager:241] Delete of Job list-admin-my-cluster-9fb57efa-kafka-clients in namespace throttling-quota-st
2022-04-04 07:17:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-9fb57efa-kafka-clients in namespace throttling-quota-st
2022-04-04 07:17:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job list-admin-my-cluster-9fb57efa-kafka-clients in namespace throttling-quota-st
2022-04-04 07:17:39 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-9fb57efa-kafka-clients in namespace throttling-quota-st
2022-04-04 07:17:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1202905358-922611816 in namespace throttling-quota-st
2022-04-04 07:17:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:17:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testKafkaAdminTopicOperations-FINISHED
2022-04-04 07:17:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:17:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:17:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasDeleteTopic-STARTED
2022-04-04 07:17:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:17:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1603023700-1865456936 in namespace throttling-quota-st
2022-04-04 07:17:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1603023700-1865456936 will have desired state: Ready
2022-04-04 07:17:50 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1603023700-1865456936 is in desired state: Ready
2022-04-04 07:17:50 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 1/5 iteration.
2022-04-04 07:17:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:17:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-ceee7327-kafka-clients will be in active state
2022-04-04 07:17:51 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-ceee7327-kafka-clients to finished
2022-04-04 07:19:22 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:19:22 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-ceee7327-kafka-clients-8n4h8 log
2022-04-04 07:19:27 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 2/5 iteration.
2022-04-04 07:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:19:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-ceee7327-kafka-clients will be in active state
2022-04-04 07:19:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-ceee7327-kafka-clients to finished
2022-04-04 07:21:02 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:21:02 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-ceee7327-kafka-clients-pt4jv log
2022-04-04 07:21:07 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 3/5 iteration.
2022-04-04 07:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:21:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-ceee7327-kafka-clients will be in active state
2022-04-04 07:21:08 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-ceee7327-kafka-clients to finished
2022-04-04 07:22:42 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:22:42 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-ceee7327-kafka-clients-4v8zh log
2022-04-04 07:22:47 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 4/5 iteration.
2022-04-04 07:22:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:22:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-ceee7327-kafka-clients will be in active state
2022-04-04 07:22:48 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-ceee7327-kafka-clients to finished
2022-04-04 07:24:22 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:24:22 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-ceee7327-kafka-clients-pcwnw log
2022-04-04 07:24:27 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 5/5 iteration.
2022-04-04 07:24:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:24:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-ceee7327-kafka-clients will be in active state
2022-04-04 07:24:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-ceee7327-kafka-clients to finished
2022-04-04 07:26:02 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:26:02 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-ceee7327-kafka-clients-s99fn log
2022-04-04 07:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:26:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-ceee7327-kafka-clients will be in active state
2022-04-04 07:26:08 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:30:10 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in delete-admin-my-cluster-ceee7327-kafka-clients-557hb log
2022-04-04 07:30:15 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 1/5 iteration for delete-admin-my-cluster-ceee7327-kafka-clients.
2022-04-04 07:30:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:30:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-ceee7327-kafka-clients will be in active state
2022-04-04 07:30:16 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-ceee7327-kafka-clients to finished
2022-04-04 07:31:24 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 2/5 iteration for delete-admin-my-cluster-ceee7327-kafka-clients.
2022-04-04 07:31:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:31:24 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-ceee7327-kafka-clients will be in active state
2022-04-04 07:31:25 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-ceee7327-kafka-clients to finished
2022-04-04 07:32:32 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 3/5 iteration for delete-admin-my-cluster-ceee7327-kafka-clients.
2022-04-04 07:32:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:32:32 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-ceee7327-kafka-clients will be in active state
2022-04-04 07:32:33 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-ceee7327-kafka-clients to finished
2022-04-04 07:33:41 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 4/5 iteration for delete-admin-my-cluster-ceee7327-kafka-clients.
2022-04-04 07:33:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:33:41 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-ceee7327-kafka-clients will be in active state
2022-04-04 07:33:42 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-ceee7327-kafka-clients to finished
2022-04-04 07:34:49 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 5/5 iteration for delete-admin-my-cluster-ceee7327-kafka-clients.
2022-04-04 07:34:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:34:49 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-ceee7327-kafka-clients will be in active state
2022-04-04 07:34:50 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-ceee7327-kafka-clients to finished
2022-04-04 07:35:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:35:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasDeleteTopic
2022-04-04 07:35:57 [main] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:35:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:35:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:35:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:35:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:35:57 [main] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:35:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:35:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:35:57 [main] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:35:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:35:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1603023700-1865456936 in namespace throttling-quota-st
2022-04-04 07:35:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-ceee7327-kafka-clients in namespace throttling-quota-st
2022-04-04 07:36:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:36:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasDeleteTopic-FINISHED
2022-04-04 07:36:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:36:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:36:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateTopic-STARTED
2022-04-04 07:36:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:36:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1756590184-322383295 in namespace throttling-quota-st
2022-04-04 07:36:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1756590184-322383295 will have desired state: Ready
2022-04-04 07:36:08 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1756590184-322383295 is in desired state: Ready
2022-04-04 07:36:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-351d592a-kafka-clients in namespace throttling-quota-st
2022-04-04 07:36:08 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-351d592a-kafka-clients will be in active state
2022-04-04 07:36:09 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-04 07:40:11 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in create-admin-my-cluster-351d592a-kafka-clients-22kdk log
2022-04-04 07:40:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:40:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasCreateTopic
2022-04-04 07:40:43 [main] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-351d592a-kafka-clients in namespace throttling-quota-st
2022-04-04 07:40:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1756590184-322383295 in namespace throttling-quota-st
2022-04-04 07:40:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:40:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateTopic-FINISHED
2022-04-04 07:40:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:40:53 [main] [32mINFO [m [ThrottlingQuotaST:353] Tearing down resources after all test
2022-04-04 07:41:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:41:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for ThrottlingQuotaST
2022-04-04 07:41:18 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka quota-cluster in namespace throttling-quota-st
2022-04-04 07:41:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,360.842 s - in io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.topic.TopicST
2022-04-04 07:41:38 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: topic-st
2022-04-04 07:41:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: topic-st
2022-04-04 07:41:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: topic-st
2022-04-04 07:41:39 [main] [32mINFO [m [TopicST:491] Deploying shared Kafka across all test cases in topic-st namespace
2022-04-04 07:41:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka topic-cluster-name in namespace topic-st
2022-04-04 07:41:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: topic-cluster-name will have desired state: Ready
2022-04-04 07:42:53 [main] [32mINFO [m [ResourceManager:444] Kafka: topic-cluster-name is in desired state: Ready
2022-04-04 07:42:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:42:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaAdminClient-STARTED
2022-04-04 07:42:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:42:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-11a411ba in namespace topic-st
2022-04-04 07:42:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-11a411ba will have desired state: Ready
2022-04-04 07:44:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-11a411ba is in desired state: Ready
2022-04-04 07:44:08 [main] [32mINFO [m [AdminClientConfig:376] AdminClientConfig values: 
	bootstrap.servers = [192.168.49.2:32674]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-04-04 07:44:08 [main] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-04-04 07:44:08 [main] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-04-04 07:44:08 [main] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1649058248890
2022-04-04 07:44:09 [main] [32mINFO [m [TopicST:166] Creating async topic my-topic-1880500147-558907814 via Admin client
2022-04-04 07:44:09 [main] [32mINFO [m [TopicST:172] Verify that in Kafka cluster contains 3 topics
2022-04-04 07:44:09 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-1880500147-558907814 creation 
2022-04-04 07:44:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1880500147-558907814 will have desired state: Ready
2022-04-04 07:44:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1880500147-558907814 is in desired state: Ready
2022-04-04 07:44:10 [kafka-admin-client-thread | adminclient-1] [32mINFO [m [AppInfoParser:83] App info kafka.admin.client for adminclient-1 unregistered
2022-04-04 07:44:10 [kafka-admin-client-thread | adminclient-1] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-04-04 07:44:10 [kafka-admin-client-thread | adminclient-1] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-04-04 07:44:10 [kafka-admin-client-thread | adminclient-1] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-04-04 07:44:10 [main] [32mINFO [m [TopicST:182] Verify that corresponding 1 KafkaTopic custom resources were created and topic is in Ready state
2022-04-04 07:44:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:44:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreateTopicViaAdminClient
2022-04-04 07:44:10 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-11a411ba in namespace topic-st
2022-04-04 07:44:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:44:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaAdminClient-FINISHED
2022-04-04 07:44:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:44:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:44:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateDeleteCreate-STARTED
2022-04-04 07:44:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:44:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cc6ab309 in namespace topic-st
2022-04-04 07:44:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cc6ab309 will have desired state: Ready
2022-04-04 07:45:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cc6ab309 is in desired state: Ready
2022-04-04 07:45:49 [main] [32mINFO [m [AdminClientConfig:376] AdminClientConfig values: 
	bootstrap.servers = [192.168.49.2:30261]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-04-04 07:45:49 [main] [32mINFO [m [AppInfoParser:119] Kafka version: 3.1.0
2022-04-04 07:45:49 [main] [32mINFO [m [AppInfoParser:120] Kafka commitId: 37edeed0777bacb3
2022-04-04 07:45:49 [main] [32mINFO [m [AppInfoParser:121] Kafka startTimeMs: 1649058349970
2022-04-04 07:45:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:45:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:45:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:45:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:45:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:45:53 [main] [32mINFO [m [TopicST:238] Iteration 0: Deleting my-topic-688289232-1983946918
2022-04-04 07:45:53 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-688289232-1983946918 deletion
2022-04-04 07:45:56 [main] [32mINFO [m [TopicST:250] Iteration 0: Recreating my-topic-688289232-1983946918
2022-04-04 07:45:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:45:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:45:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:45:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:45:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:45:59 [main] [32mINFO [m [TopicST:238] Iteration 1: Deleting my-topic-688289232-1983946918
2022-04-04 07:45:59 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-688289232-1983946918 deletion
2022-04-04 07:46:02 [main] [32mINFO [m [TopicST:250] Iteration 1: Recreating my-topic-688289232-1983946918
2022-04-04 07:46:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:46:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:03 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:03 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:05 [main] [32mINFO [m [TopicST:238] Iteration 2: Deleting my-topic-688289232-1983946918
2022-04-04 07:46:05 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-688289232-1983946918 deletion
2022-04-04 07:46:08 [main] [32mINFO [m [TopicST:250] Iteration 2: Recreating my-topic-688289232-1983946918
2022-04-04 07:46:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:46:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:11 [main] [32mINFO [m [TopicST:238] Iteration 3: Deleting my-topic-688289232-1983946918
2022-04-04 07:46:11 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-688289232-1983946918 deletion
2022-04-04 07:46:14 [main] [32mINFO [m [TopicST:250] Iteration 3: Recreating my-topic-688289232-1983946918
2022-04-04 07:46:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:46:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:17 [main] [32mINFO [m [TopicST:238] Iteration 4: Deleting my-topic-688289232-1983946918
2022-04-04 07:46:17 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-688289232-1983946918 deletion
2022-04-04 07:46:20 [main] [32mINFO [m [TopicST:250] Iteration 4: Recreating my-topic-688289232-1983946918
2022-04-04 07:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:46:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:21 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:21 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:23 [main] [32mINFO [m [TopicST:238] Iteration 5: Deleting my-topic-688289232-1983946918
2022-04-04 07:46:23 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-688289232-1983946918 deletion
2022-04-04 07:46:26 [main] [32mINFO [m [TopicST:250] Iteration 5: Recreating my-topic-688289232-1983946918
2022-04-04 07:46:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:46:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:27 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:27 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:29 [main] [32mINFO [m [TopicST:238] Iteration 6: Deleting my-topic-688289232-1983946918
2022-04-04 07:46:29 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-688289232-1983946918 deletion
2022-04-04 07:46:32 [main] [32mINFO [m [TopicST:250] Iteration 6: Recreating my-topic-688289232-1983946918
2022-04-04 07:46:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:46:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:35 [main] [32mINFO [m [TopicST:238] Iteration 7: Deleting my-topic-688289232-1983946918
2022-04-04 07:46:36 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-688289232-1983946918 deletion
2022-04-04 07:46:39 [main] [32mINFO [m [TopicST:250] Iteration 7: Recreating my-topic-688289232-1983946918
2022-04-04 07:46:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:46:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:40 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:40 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:42 [main] [32mINFO [m [TopicST:238] Iteration 8: Deleting my-topic-688289232-1983946918
2022-04-04 07:46:42 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-688289232-1983946918 deletion
2022-04-04 07:46:45 [main] [32mINFO [m [TopicST:250] Iteration 8: Recreating my-topic-688289232-1983946918
2022-04-04 07:46:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:46:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:48 [main] [32mINFO [m [TopicST:238] Iteration 9: Deleting my-topic-688289232-1983946918
2022-04-04 07:46:48 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-688289232-1983946918 deletion
2022-04-04 07:46:51 [main] [32mINFO [m [TopicST:250] Iteration 9: Recreating my-topic-688289232-1983946918
2022-04-04 07:46:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:46:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-688289232-1983946918 will have desired state: Ready
2022-04-04 07:46:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-688289232-1983946918 is in desired state: Ready
2022-04-04 07:46:52 [kafka-admin-client-thread | adminclient-2] [32mINFO [m [AppInfoParser:83] App info kafka.admin.client for adminclient-2 unregistered
2022-04-04 07:46:52 [kafka-admin-client-thread | adminclient-2] [32mINFO [m [Metrics:659] Metrics scheduler closed
2022-04-04 07:46:52 [kafka-admin-client-thread | adminclient-2] [32mINFO [m [Metrics:663] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-04-04 07:46:52 [kafka-admin-client-thread | adminclient-2] [32mINFO [m [Metrics:669] Metrics reporters closed
2022-04-04 07:46:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:46:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreateDeleteCreate
2022-04-04 07:46:52 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:46:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:46:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:46:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:47:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:47:02 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:47:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:47:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:47:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:47:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:47:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-688289232-1983946918 in namespace topic-st
2022-04-04 07:47:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cc6ab309 in namespace topic-st
2022-04-04 07:47:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:47:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateDeleteCreate-FINISHED
2022-04-04 07:47:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:47:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:47:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testTopicModificationOfReplicationFactor-STARTED
2022-04-04 07:47:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:47:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-180370877-268514585 in namespace topic-st
2022-04-04 07:47:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-180370877-268514585 will have desired state: Ready
2022-04-04 07:47:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-180370877-268514585 is in desired state: Ready
2022-04-04 07:47:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-180370877-268514585 will have desired state: NotReady
2022-04-04 07:47:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-180370877-268514585 is in desired state: NotReady
2022-04-04 07:47:14 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-180370877-268514585 deletion
2022-04-04 07:47:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:47:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicModificationOfReplicationFactor
2022-04-04 07:47:14 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-180370877-268514585 in namespace topic-st
2022-04-04 07:47:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:47:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testTopicModificationOfReplicationFactor-FINISHED
2022-04-04 07:47:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:47:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:47:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testDeleteTopicEnableFalse-STARTED
2022-04-04 07:47:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:47:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-44a4998f-isolated in namespace topic-st
2022-04-04 07:47:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-44a4998f-isolated will have desired state: Ready
2022-04-04 07:48:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-44a4998f-isolated is in desired state: Ready
2022-04-04 07:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-44a4998f-isolated-kafka-clients in namespace topic-st
2022-04-04 07:48:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-44a4998f-isolated-kafka-clients will be ready
2022-04-04 07:48:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-44a4998f-isolated-kafka-clients is ready
2022-04-04 07:48:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-399874895-527157336 in namespace topic-st
2022-04-04 07:48:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-399874895-527157336 will have desired state: Ready
2022-04-04 07:48:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-399874895-527157336 is in desired state: Ready
2022-04-04 07:48:25 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 07:48:25 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1737422c, messages=[], arguments=[--topic, my-topic-399874895-527157336, --max-messages, 100, --bootstrap-server, my-cluster-44a4998f-isolated-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-44a4998f-isolated-kafka-clients-5684bcc6d6-42f5w', podNamespace='topic-st', bootstrapServer='my-cluster-44a4998f-isolated-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-399874895-527157336', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7d971230}
2022-04-04 07:48:25 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-44a4998f-isolated-kafka-bootstrap.topic-st.svc:9092:my-topic-399874895-527157336 from pod my-cluster-44a4998f-isolated-kafka-clients-5684bcc6d6-42f5w
2022-04-04 07:48:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-44a4998f-isolated-kafka-clients-5684bcc6d6-42f5w -n topic-st -- /opt/kafka/producer.sh --topic my-topic-399874895-527157336 --max-messages 100 --bootstrap-server my-cluster-44a4998f-isolated-kafka-bootstrap.topic-st.svc:9092
2022-04-04 07:48:28 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 07:48:28 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 07:48:28 [main] [32mINFO [m [TopicST:395] Deleting KafkaTopic: my-topic-399874895-527157336
2022-04-04 07:48:28 [main] [32mINFO [m [TopicST:397] KafkaTopic my-topic-399874895-527157336 deleted
2022-04-04 07:50:16 [main] [32mINFO [m [TopicST:401] Wait KafkaTopic my-topic-399874895-527157336 recreation
2022-04-04 07:50:16 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-399874895-527157336 creation 
2022-04-04 07:50:16 [main] [32mINFO [m [TopicST:403] KafkaTopic my-topic-399874895-527157336 recreated
2022-04-04 07:50:16 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@210d7213, messages=[], arguments=[--topic, my-topic-399874895-527157336, --max-messages, 100, --group-instance-id, instance1363854864, --group-id, my-consumer-group-1134181694, --bootstrap-server, my-cluster-44a4998f-isolated-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-44a4998f-isolated-kafka-clients-5684bcc6d6-42f5w', podNamespace='topic-st', bootstrapServer='my-cluster-44a4998f-isolated-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-399874895-527157336', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1134181694', consumerInstanceId='instance1363854864', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@c06779d}
2022-04-04 07:50:16 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-44a4998f-isolated-kafka-bootstrap.topic-st.svc:9092#my-topic-399874895-527157336 from pod my-cluster-44a4998f-isolated-kafka-clients-5684bcc6d6-42f5w
2022-04-04 07:50:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-44a4998f-isolated-kafka-clients-5684bcc6d6-42f5w -n topic-st -- /opt/kafka/consumer.sh --topic my-topic-399874895-527157336 --max-messages 100 --group-instance-id instance1363854864 --group-id my-consumer-group-1134181694 --bootstrap-server my-cluster-44a4998f-isolated-kafka-bootstrap.topic-st.svc:9092
2022-04-04 07:50:22 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 07:50:22 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 07:50:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:50:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeleteTopicEnableFalse
2022-04-04 07:50:22 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-44a4998f-isolated-kafka-clients in namespace topic-st
2022-04-04 07:50:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-44a4998f-isolated in namespace topic-st
2022-04-04 07:50:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-399874895-527157336 in namespace topic-st
2022-04-04 07:51:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:51:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testDeleteTopicEnableFalse-FINISHED
2022-04-04 07:51:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:51:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:51:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testSendingMessagesToNonExistingTopic-STARTED
2022-04-04 07:51:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:51:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment topic-cluster-name-kafka-clients in namespace topic-st
2022-04-04 07:51:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: topic-cluster-name-kafka-clients will be ready
2022-04-04 07:51:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: topic-cluster-name-kafka-clients is ready
2022-04-04 07:51:04 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 07:51:04 [main] [32mINFO [m [TopicST:320] Checking if my-topic-2080309760-1057467440 is on topic list
2022-04-04 07:51:04 [main] [32mINFO [m [TopicST:456] Checking topic my-topic-2080309760-1057467440 in Kafka
2022-04-04 07:51:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:51:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:51:07 [main] [32mINFO [m [TopicST:323] Topic with name my-topic-2080309760-1057467440 is not created yet
2022-04-04 07:51:07 [main] [32mINFO [m [TopicST:325] Trying to send messages to non-existing topic my-topic-2080309760-1057467440
2022-04-04 07:51:07 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6444c163, messages=[], arguments=[--topic, my-topic-2080309760-1057467440, --max-messages, 100, --bootstrap-server, topic-cluster-name-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='topic-cluster-name-kafka-clients-7dd7cb68d4-5nr6l', podNamespace='topic-st', bootstrapServer='topic-cluster-name-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-2080309760-1057467440', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@31ff0947}
2022-04-04 07:51:07 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to topic-cluster-name-kafka-bootstrap.topic-st.svc:9092:my-topic-2080309760-1057467440 from pod topic-cluster-name-kafka-clients-7dd7cb68d4-5nr6l
2022-04-04 07:51:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec topic-cluster-name-kafka-clients-7dd7cb68d4-5nr6l -n topic-st -- /opt/kafka/producer.sh --topic my-topic-2080309760-1057467440 --max-messages 100 --bootstrap-server topic-cluster-name-kafka-bootstrap.topic-st.svc:9092
2022-04-04 07:51:09 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 07:51:09 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 07:51:09 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3bb80060, messages=[], arguments=[--topic, my-topic-2080309760-1057467440, --max-messages, 100, --group-instance-id, instance727972512, --group-id, my-consumer-group-531549236, --bootstrap-server, topic-cluster-name-kafka-bootstrap.topic-st.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='topic-cluster-name-kafka-clients-7dd7cb68d4-5nr6l', podNamespace='topic-st', bootstrapServer='topic-cluster-name-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-2080309760-1057467440', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-531549236', consumerInstanceId='instance727972512', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@13878c50}
2022-04-04 07:51:09 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from topic-cluster-name-kafka-bootstrap.topic-st.svc:9092#my-topic-2080309760-1057467440 from pod topic-cluster-name-kafka-clients-7dd7cb68d4-5nr6l
2022-04-04 07:51:09 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec topic-cluster-name-kafka-clients-7dd7cb68d4-5nr6l -n topic-st -- /opt/kafka/consumer.sh --topic my-topic-2080309760-1057467440 --max-messages 100 --group-instance-id instance727972512 --group-id my-consumer-group-531549236 --bootstrap-server topic-cluster-name-kafka-bootstrap.topic-st.svc:9092
2022-04-04 07:51:15 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 07:51:15 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 07:51:15 [main] [32mINFO [m [TopicST:341] Checking if my-topic-2080309760-1057467440 is on topic list
2022-04-04 07:51:15 [main] [32mINFO [m [TopicST:456] Checking topic my-topic-2080309760-1057467440 in Kafka
2022-04-04 07:51:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:51:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:51:18 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-2080309760-1057467440 creation 
2022-04-04 07:51:18 [main] [32mINFO [m [TopicST:353] Topic successfully created
2022-04-04 07:51:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:51:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendingMessagesToNonExistingTopic
2022-04-04 07:51:18 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment topic-cluster-name-kafka-clients in namespace topic-st
2022-04-04 07:51:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:51:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testSendingMessagesToNonExistingTopic-FINISHED
2022-04-04 07:51:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:51:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:51:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testMoreReplicasThanAvailableBrokers-STARTED
2022-04-04 07:51:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:51:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-7222889-1028858573 in namespace topic-st
2022-04-04 07:51:58 [main] [32mINFO [m [TopicST:461] Checking in KafkaTopic CR that topic my-topic-7222889-1028858573 exists
2022-04-04 07:51:58 [main] [32mINFO [m [TopicST:456] Checking topic my-topic-7222889-1028858573 in Kafka
2022-04-04 07:52:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:52:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:52:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-7222889-1028858573 will have desired state: NotReady
2022-04-04 07:52:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-7222889-1028858573 is in desired state: NotReady
2022-04-04 07:52:00 [main] [32mINFO [m [TopicST:90] Delete topic my-topic-7222889-1028858573
2022-04-04 07:52:00 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-7222889-1028858573 deletion
2022-04-04 07:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-example-new in namespace topic-st
2022-04-04 07:52:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-example-new will have desired state: Ready
2022-04-04 07:52:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-example-new is in desired state: Ready
2022-04-04 07:52:01 [main] [32mINFO [m [TopicST:456] Checking topic topic-example-new in Kafka
2022-04-04 07:52:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:52:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:52:04 [main] [32mINFO [m [TopicST:461] Checking in KafkaTopic CR that topic topic-example-new exists
2022-04-04 07:52:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:52:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMoreReplicasThanAvailableBrokers
2022-04-04 07:52:04 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-example-new in namespace topic-st
2022-04-04 07:52:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-7222889-1028858573 in namespace topic-st
2022-04-04 07:52:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:52:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testMoreReplicasThanAvailableBrokers-FINISHED
2022-04-04 07:52:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:52:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:52:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaKafka-STARTED
2022-04-04 07:52:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:52:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --create  --topic my-topic-21507635-1584103412 --replication-factor 3 --partitions 3
2022-04-04 07:52:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:52:17 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-21507635-1584103412 creation 
2022-04-04 07:52:18 [main] [32mINFO [m [TopicST:482] Checking in KafkaTopic CR that topic my-topic-21507635-1584103412 was created with expected settings
2022-04-04 07:52:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:52:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:52:20 [main] [32mINFO [m [TopicST:121] Editing topic via Kafka, settings to partitions 5
2022-04-04 07:52:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic-21507635-1584103412 --partitions 5
2022-04-04 07:52:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:52:23 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-21507635-1584103412
2022-04-04 07:52:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-topic-21507635-1584103412
2022-04-04 07:52:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:52:26 [main] [32mINFO [m [TopicST:470] Checking topic my-topic-21507635-1584103412 in Kafka topic-cluster-name
2022-04-04 07:52:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:52:26 [main] [32mINFO [m [ResourceManager:346] In context testCreateTopicViaKafka is everything deleted.
2022-04-04 07:52:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:52:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaKafka-FINISHED
2022-04-04 07:52:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:52:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:52:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicAfterUnsupportedOperation-STARTED
2022-04-04 07:52:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:52:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-with-replication-to-change in namespace topic-st
2022-04-04 07:52:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-with-replication-to-change will have desired state: Ready
2022-04-04 07:52:27 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-with-replication-to-change is in desired state: Ready
2022-04-04 07:52:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-with-replication-to-change will have desired state: NotReady
2022-04-04 07:52:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-with-replication-to-change is in desired state: NotReady
2022-04-04 07:52:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic another-topic in namespace topic-st
2022-04-04 07:52:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: another-topic will have desired state: Ready
2022-04-04 07:52:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: another-topic is in desired state: Ready
2022-04-04 07:52:29 [main] [32mINFO [m [TopicST:456] Checking topic topic-with-replication-to-change in Kafka
2022-04-04 07:52:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:52:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:52:31 [main] [32mINFO [m [TopicST:461] Checking in KafkaTopic CR that topic topic-with-replication-to-change exists
2022-04-04 07:52:31 [main] [32mINFO [m [TopicST:456] Checking topic another-topic in Kafka
2022-04-04 07:52:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 07:52:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:52:34 [main] [32mINFO [m [TopicST:461] Checking in KafkaTopic CR that topic another-topic exists
2022-04-04 07:52:34 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic topic-with-replication-to-change deletion
2022-04-04 07:52:34 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic another-topic deletion
2022-04-04 07:52:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:52:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreateTopicAfterUnsupportedOperation
2022-04-04 07:52:34 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic another-topic in namespace topic-st
2022-04-04 07:52:34 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-with-replication-to-change in namespace topic-st
2022-04-04 07:52:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 07:52:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicAfterUnsupportedOperation-FINISHED
2022-04-04 07:52:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 07:52:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:52:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for TopicST
2022-04-04 07:52:34 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka topic-cluster-name in namespace topic-st
2022-04-04 07:52:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 708.774 s - in io.strimzi.systemtest.operators.topic.TopicST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.ReconciliationST
2022-04-04 07:53:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: reconciliation-st
2022-04-04 07:53:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: reconciliation-st
2022-04-04 07:53:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: reconciliation-st
2022-04-04 07:53:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 07:53:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaAndKafkaConnectWithConnector-STARTED
2022-04-04 07:53:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 07:53:27 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-2 for test case:testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-04 07:53:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-2
2022-04-04 07:53:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-2
2022-04-04 07:53:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-2
2022-04-04 07:53:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-07d47315 in namespace namespace-2
2022-04-04 07:53:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-04 07:53:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-07d47315 will have desired state: Ready
2022-04-04 07:54:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-07d47315 is in desired state: Ready
2022-04-04 07:54:50 [main] [32mINFO [m [ReconciliationST:80] Adding pause annotation into Kafka resource and also scaling replicas to 4, new pod should not appear
2022-04-04 07:54:50 [main] [32mINFO [m [ReconciliationST:86] Kafka should contain status with ReconciliationPaused
2022-04-04 07:54:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-07d47315 will have desired state: ReconciliationPaused
2022-04-04 07:54:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-07d47315 is in desired state: ReconciliationPaused
2022-04-04 07:54:52 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-07d47315-kafka will have stable 3 replicas
2022-04-04 07:54:52 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-04 07:54:53 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-04 07:54:54 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-04 07:54:55 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-04 07:54:56 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-04 07:54:57 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-04 07:54:58 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-04 07:54:59 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-04 07:55:00 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-04 07:55:01 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-04 07:55:02 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-04 07:55:03 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-04 07:55:04 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-04 07:55:05 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-04 07:55:06 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-04 07:55:07 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-04 07:55:08 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-04 07:55:09 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-04 07:55:10 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-04 07:55:11 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-04 07:55:11 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-07d47315-kafka has 3 replicas
2022-04-04 07:55:11 [main] [32mINFO [m [ReconciliationST:90] Setting annotation to "false", Kafka should be scaled to 4
2022-04-04 07:55:11 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-07d47315-kafka to be ready
2022-04-04 07:57:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-07d47315 will have desired state: Ready
2022-04-04 07:57:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-07d47315 is in desired state: Ready
2022-04-04 07:57:18 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-07d47315 is ready
2022-04-04 07:57:18 [main] [32mINFO [m [ReconciliationST:94] Deploying KafkaConnect with pause annotation from the start, no pods should appear
2022-04-04 07:57:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-07d47315-kafka-clients in namespace namespace-2
2022-04-04 07:57:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-04 07:57:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-07d47315-kafka-clients will be ready
2022-04-04 07:57:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-07d47315-kafka-clients is ready
2022-04-04 07:57:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-07d47315-scraper in namespace namespace-2
2022-04-04 07:57:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-04 07:57:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-07d47315-scraper will be ready
2022-04-04 07:57:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-07d47315-scraper is ready
2022-04-04 07:57:22 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-07d47315-scraper to be ready
2022-04-04 07:57:32 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-07d47315-scraper is ready
2022-04-04 07:57:32 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-07d47315-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 07:57:32 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-07d47315-allow in namespace namespace-2
2022-04-04 07:57:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-04 07:57:32 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 07:57:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-07d47315 in namespace namespace-2
2022-04-04 07:57:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-04 07:57:32 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkaconnects' with unstable version 'v1beta2'
2022-04-04 07:57:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-07d47315 will have desired state: ReconciliationPaused
2022-04-04 07:57:33 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-07d47315 is in desired state: ReconciliationPaused
2022-04-04 07:57:33 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-07d47315-connect will have stable 0 replicas
2022-04-04 07:57:33 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-04 07:57:34 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-04 07:57:35 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-04 07:57:36 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-04 07:57:37 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-04 07:57:38 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-04 07:57:39 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-04 07:57:40 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-04 07:57:41 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-04 07:57:42 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-04 07:57:43 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-04 07:57:44 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-04 07:57:45 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-04 07:57:46 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-04 07:57:47 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-04 07:57:48 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-04 07:57:49 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-04 07:57:50 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-04 07:57:51 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-04 07:57:52 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-04 07:57:52 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-07d47315-connect has 0 replicas
2022-04-04 07:57:52 [main] [32mINFO [m [ReconciliationST:108] Setting annotation to "false" and creating KafkaConnector
2022-04-04 07:57:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-07d47315-connect will be ready
2022-04-04 07:59:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-07d47315-connect is ready
2022-04-04 07:59:02 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-07d47315-connect to be ready
2022-04-04 07:59:12 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-07d47315-connect is ready
2022-04-04 07:59:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-07d47315 in namespace namespace-2
2022-04-04 07:59:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-04 07:59:12 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkaconnectors' with unstable version 'v1beta2'
2022-04-04 07:59:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-07d47315 will have desired state: Ready
2022-04-04 07:59:14 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-07d47315 is in desired state: Ready
2022-04-04 07:59:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:14 [main] [32mINFO [m [ReconciliationST:118] Adding pause annotation into the KafkaConnector and scaling taskMax to 4
2022-04-04 07:59:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-07d47315 will have desired state: ReconciliationPaused
2022-04-04 07:59:15 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-07d47315 is in desired state: ReconciliationPaused
2022-04-04 07:59:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:15 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 19 polls
2022-04-04 07:59:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:16 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 18 polls
2022-04-04 07:59:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:17 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 17 polls
2022-04-04 07:59:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:19 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 16 polls
2022-04-04 07:59:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:20 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 15 polls
2022-04-04 07:59:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:21 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 14 polls
2022-04-04 07:59:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:22 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 13 polls
2022-04-04 07:59:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:23 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 12 polls
2022-04-04 07:59:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:25 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 11 polls
2022-04-04 07:59:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:26 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 10 polls
2022-04-04 07:59:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:27 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 9 polls
2022-04-04 07:59:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:28 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 8 polls
2022-04-04 07:59:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:29 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 7 polls
2022-04-04 07:59:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:31 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 6 polls
2022-04-04 07:59:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:32 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 5 polls
2022-04-04 07:59:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:33 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 4 polls
2022-04-04 07:59:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:34 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 3 polls
2022-04-04 07:59:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:35 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 2 polls
2022-04-04 07:59:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:37 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 1 polls
2022-04-04 07:59:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315
2022-04-04 07:59:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:38 [main] [32mINFO [m [KafkaConnectorUtils:154] Connector's spec is stable for 20 polls intervals
2022-04-04 07:59:38 [main] [32mINFO [m [ReconciliationST:127] Setting annotation to "false", taskMax should be increased to 4
2022-04-04 07:59:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315/config
2022-04-04 07:59:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-07d47315-connect-fd767dd84-95gxm -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-07d47315/config
2022-04-04 07:59:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 07:59:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 07:59:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-04 07:59:38 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-07d47315-allow in namespace namespace-2
2022-04-04 07:59:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-07d47315-kafka-clients in namespace namespace-2
2022-04-04 07:59:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-07d47315 in namespace namespace-2
2022-04-04 07:59:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-07d47315-scraper in namespace namespace-2
2022-04-04 07:59:38 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-07d47315 in namespace namespace-2
2022-04-04 07:59:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-07d47315 in namespace namespace-2
2022-04-04 08:00:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:00:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-2 for test case:testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-04 08:00:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaAndKafkaConnectWithConnector-FINISHED
2022-04-04 08:00:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:00:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:00:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaRebalanceAndTopic-STARTED
2022-04-04 08:00:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:00:34 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-3 for test case:testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-04 08:00:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-3
2022-04-04 08:00:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-3
2022-04-04 08:00:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-3
2022-04-04 08:00:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e705e030 in namespace namespace-3
2022-04-04 08:00:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-04 08:00:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e705e030 will have desired state: Ready
2022-04-04 08:02:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e705e030 is in desired state: Ready
2022-04-04 08:02:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-659700782-1143278525 in namespace namespace-3
2022-04-04 08:02:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-04 08:02:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-659700782-1143278525 will have desired state: Ready
2022-04-04 08:02:12 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-659700782-1143278525 is in desired state: Ready
2022-04-04 08:02:12 [main] [32mINFO [m [ReconciliationST:147] Adding pause annotation into KafkaTopic resource and changing replication factor
2022-04-04 08:02:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-659700782-1143278525 will have desired state: ReconciliationPaused
2022-04-04 08:02:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-659700782-1143278525 is in desired state: ReconciliationPaused
2022-04-04 08:02:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:02:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:02:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:18 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 19 polls
2022-04-04 08:02:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:02:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:23 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 18 polls
2022-04-04 08:02:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:02:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:27 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 17 polls
2022-04-04 08:02:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:02:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:31 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 16 polls
2022-04-04 08:02:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:02:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:35 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 15 polls
2022-04-04 08:02:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:02:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:42 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 14 polls
2022-04-04 08:02:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:02:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:46 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 13 polls
2022-04-04 08:02:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:02:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:50 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 12 polls
2022-04-04 08:02:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:02:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:53 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 11 polls
2022-04-04 08:02:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:02:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:02:57 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 10 polls
2022-04-04 08:03:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:03:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:03:02 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 9 polls
2022-04-04 08:03:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:03:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:03:05 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 8 polls
2022-04-04 08:03:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:03:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:03:09 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 7 polls
2022-04-04 08:03:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:03:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:03:13 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 6 polls
2022-04-04 08:03:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:03:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:03:16 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 5 polls
2022-04-04 08:03:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:03:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:03:20 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 4 polls
2022-04-04 08:03:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:03:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:03:24 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 3 polls
2022-04-04 08:03:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:03:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:03:28 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 2 polls
2022-04-04 08:03:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:03:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:03:31 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 1 polls
2022-04-04 08:03:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-e705e030-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-659700782-1143278525 --describe --bootstrap-server my-cluster-e705e030-kafka-bootstrap:9092
2022-04-04 08:03:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:03:36 [main] [32mINFO [m [KafkaTopicUtils:197] KafkaTopic's spec is stable for 20 polls intervals
2022-04-04 08:03:36 [main] [32mINFO [m [ReconciliationST:156] Setting annotation to "false", partitions should be scaled to 4
2022-04-04 08:03:36 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-659700782-1143278525
2022-04-04 08:03:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-e705e030 in namespace namespace-3
2022-04-04 08:03:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-04 08:03:36 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkarebalances' with unstable version 'v1beta2'
2022-04-04 08:03:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-e705e030 will have desired state: PendingProposal
2022-04-04 08:03:37 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-e705e030 is in desired state: PendingProposal
2022-04-04 08:03:37 [main] [32mINFO [m [ReconciliationST:164] Waiting for ProposalReady, then add pause and rebalance annotation, rebalancing should not be triggered
2022-04-04 08:03:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-e705e030 will have desired state: ProposalReady
2022-04-04 08:06:02 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-e705e030 is in desired state: ProposalReady
2022-04-04 08:06:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-e705e030 will have desired state: ReconciliationPaused
2022-04-04 08:06:04 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-e705e030 is in desired state: ReconciliationPaused
2022-04-04 08:06:04 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #1(test) KafkaRebalance(namespace-3/my-cluster-e705e030): Annotating KafkaRebalance:my-cluster-e705e030 with annotation approve
2022-04-04 08:06:04 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 19 polls
2022-04-04 08:06:05 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 18 polls
2022-04-04 08:06:06 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 17 polls
2022-04-04 08:06:07 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 16 polls
2022-04-04 08:06:08 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 15 polls
2022-04-04 08:06:09 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 14 polls
2022-04-04 08:06:10 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 13 polls
2022-04-04 08:06:11 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 12 polls
2022-04-04 08:06:12 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 11 polls
2022-04-04 08:06:13 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 10 polls
2022-04-04 08:06:14 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 9 polls
2022-04-04 08:06:15 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 8 polls
2022-04-04 08:06:16 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 7 polls
2022-04-04 08:06:17 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 6 polls
2022-04-04 08:06:18 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 5 polls
2022-04-04 08:06:19 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 4 polls
2022-04-04 08:06:20 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 3 polls
2022-04-04 08:06:21 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 2 polls
2022-04-04 08:06:22 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status gonna be stable in 1 polls
2022-04-04 08:06:23 [main] [32mINFO [m [KafkaRebalanceUtils:118] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-e705e030): KafkaRebalance status is stable for 20 polls intervals
2022-04-04 08:06:23 [main] [32mINFO [m [ReconciliationST:178] Setting annotation to "false" and waiting for KafkaRebalance to be in Ready state
2022-04-04 08:06:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-e705e030 will have desired state: ProposalReady
2022-04-04 08:06:24 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-e705e030 is in desired state: ProposalReady
2022-04-04 08:06:24 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #3(test) KafkaRebalance(namespace-3/my-cluster-e705e030): Annotating KafkaRebalance:my-cluster-e705e030 with annotation approve
2022-04-04 08:06:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-e705e030 will have desired state: Ready
2022-04-04 08:07:10 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-e705e030 is in desired state: Ready
2022-04-04 08:07:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:07:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-04 08:07:10 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-659700782-1143278525 in namespace namespace-3
2022-04-04 08:07:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e705e030 in namespace namespace-3
2022-04-04 08:07:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-3, for cruise control Kafka cluster my-cluster-e705e030
2022-04-04 08:07:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-e705e030 in namespace namespace-3
2022-04-04 08:07:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:07:20 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-3 for test case:testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-04 08:08:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaRebalanceAndTopic-FINISHED
2022-04-04 08:08:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:08:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:08:03 [main] [32mINFO [m [ResourceManager:346] In context ReconciliationST is everything deleted.
2022-04-04 08:08:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 881.451 s - in io.strimzi.systemtest.operators.ReconciliationST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeScramShaST
2022-04-04 08:08:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: http-bridge-scram-sha-st
2022-04-04 08:08:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: http-bridge-scram-sha-st
2022-04-04 08:08:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: http-bridge-scram-sha-st
2022-04-04 08:08:09 [main] [32mINFO [m [HttpBridgeScramShaST:123] Deploy Kafka and KafkaBridge before tests
2022-04-04 08:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-04 08:08:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-scram-sha-cluster-name will have desired state: Ready
2022-04-04 08:09:18 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-scram-sha-cluster-name is in desired state: Ready
2022-04-04 08:09:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-658059026-1656359126 in namespace http-bridge-scram-sha-st
2022-04-04 08:09:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-658059026-1656359126 will have desired state: Ready
2022-04-04 08:09:19 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-658059026-1656359126 is in desired state: Ready
2022-04-04 08:09:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment http-bridge-scram-sha-st-shared-kafka-clients in namespace http-bridge-scram-sha-st
2022-04-04 08:09:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: http-bridge-scram-sha-st-shared-kafka-clients will be ready
2022-04-04 08:09:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: http-bridge-scram-sha-st-shared-kafka-clients is ready
2022-04-04 08:09:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-04 08:09:21 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkabridges' with unstable version 'v1beta2'
2022-04-04 08:09:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-scram-sha-cluster-name will have desired state: Ready
2022-04-04 08:09:46 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-scram-sha-cluster-name is in desired state: Ready
2022-04-04 08:09:46 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:09:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:09:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testSendSimpleMessageTlsScramSha-STARTED
2022-04-04 08:09:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:09:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1632962453-1309407914 in namespace http-bridge-scram-sha-st
2022-04-04 08:09:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1632962453-1309407914 will have desired state: Ready
2022-04-04 08:09:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1632962453-1309407914 is in desired state: Ready
2022-04-04 08:09:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1628995690 in namespace http-bridge-scram-sha-st
2022-04-04 08:09:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1628995690 will be in active state
2022-04-04 08:09:48 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-1628995690 to finished
2022-04-04 08:09:58 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:09:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-2106403918 in namespace http-bridge-scram-sha-st
2022-04-04 08:09:58 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-2106403918 will be in active state
2022-04-04 08:09:59 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-2106403918 to finished
2022-04-04 08:10:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:10:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessageTlsScramSha
2022-04-04 08:10:10 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-1628995690 in namespace http-bridge-scram-sha-st
2022-04-04 08:10:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1632962453-1309407914 in namespace http-bridge-scram-sha-st
2022-04-04 08:10:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job consumer-2106403918 in namespace http-bridge-scram-sha-st
2022-04-04 08:10:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:10:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testSendSimpleMessageTlsScramSha-FINISHED
2022-04-04 08:10:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:10:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:10:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testReceiveSimpleMessageTlsScramSha-STARTED
2022-04-04 08:10:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:10:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1670769365-1601814202 in namespace http-bridge-scram-sha-st
2022-04-04 08:10:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1670769365-1601814202 will have desired state: Ready
2022-04-04 08:10:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1670769365-1601814202 is in desired state: Ready
2022-04-04 08:10:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-209237328 in namespace http-bridge-scram-sha-st
2022-04-04 08:10:22 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-209237328 will be in active state
2022-04-04 08:10:23 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:10:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1945690175 in namespace http-bridge-scram-sha-st
2022-04-04 08:10:23 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1945690175 will be in active state
2022-04-04 08:10:23 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-1945690175 and consumer consumer-209237328 finish
2022-04-04 08:10:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:10:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessageTlsScramSha
2022-04-04 08:10:39 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-209237328 in namespace http-bridge-scram-sha-st
2022-04-04 08:10:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job producer-1945690175 in namespace http-bridge-scram-sha-st
2022-04-04 08:10:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1670769365-1601814202 in namespace http-bridge-scram-sha-st
2022-04-04 08:10:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:10:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testReceiveSimpleMessageTlsScramSha-FINISHED
2022-04-04 08:10:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:10:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:10:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeScramShaST
2022-04-04 08:10:49 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment http-bridge-scram-sha-st-shared-kafka-clients in namespace http-bridge-scram-sha-st
2022-04-04 08:10:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-04 08:10:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-658059026-1656359126 in namespace http-bridge-scram-sha-st
2022-04-04 08:10:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-04 08:11:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 205.445 s - in io.strimzi.systemtest.bridge.HttpBridgeScramShaST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeTlsST
2022-04-04 08:11:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: http-bridge-tls-st
2022-04-04 08:11:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: http-bridge-tls-st
2022-04-04 08:11:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: http-bridge-tls-st
2022-04-04 08:11:34 [main] [32mINFO [m [HttpBridgeTlsST:129] Deploy Kafka and KafkaBridge before tests
2022-04-04 08:11:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-04 08:11:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-tls-cluster-name will have desired state: Ready
2022-04-04 08:12:48 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-tls-cluster-name is in desired state: Ready
2022-04-04 08:12:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2027907585-1328845731 in namespace http-bridge-tls-st
2022-04-04 08:12:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2027907585-1328845731 will have desired state: Ready
2022-04-04 08:12:49 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2027907585-1328845731 is in desired state: Ready
2022-04-04 08:12:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment http-bridge-tls-st-kafka-clients in namespace http-bridge-tls-st
2022-04-04 08:12:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: http-bridge-tls-st-kafka-clients will be ready
2022-04-04 08:12:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: http-bridge-tls-st-kafka-clients is ready
2022-04-04 08:12:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-04 08:12:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-tls-cluster-name will have desired state: Ready
2022-04-04 08:13:13 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-tls-cluster-name is in desired state: Ready
2022-04-04 08:13:13 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:13:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:13:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testReceiveSimpleMessageTls-STARTED
2022-04-04 08:13:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:13:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1497295510-495894764 in namespace http-bridge-tls-st
2022-04-04 08:13:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1497295510-495894764 will have desired state: Ready
2022-04-04 08:13:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1497295510-495894764 is in desired state: Ready
2022-04-04 08:13:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-719020540 in namespace http-bridge-tls-st
2022-04-04 08:13:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-719020540 will be in active state
2022-04-04 08:13:15 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:13:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1700631710 in namespace http-bridge-tls-st
2022-04-04 08:13:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1700631710 will be in active state
2022-04-04 08:13:16 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-1700631710 and consumer consumer-719020540 finish
2022-04-04 08:13:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:13:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessageTls
2022-04-04 08:13:31 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-719020540 in namespace http-bridge-tls-st
2022-04-04 08:13:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1497295510-495894764 in namespace http-bridge-tls-st
2022-04-04 08:13:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job producer-1700631710 in namespace http-bridge-tls-st
2022-04-04 08:13:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:13:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testReceiveSimpleMessageTls-FINISHED
2022-04-04 08:13:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:13:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:13:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testSendSimpleMessageTls-STARTED
2022-04-04 08:13:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:13:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-860783203-293336368 in namespace http-bridge-tls-st
2022-04-04 08:13:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-860783203-293336368 will have desired state: Ready
2022-04-04 08:13:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-860783203-293336368 is in desired state: Ready
2022-04-04 08:13:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1031808384 in namespace http-bridge-tls-st
2022-04-04 08:13:42 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1031808384 will be in active state
2022-04-04 08:13:43 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-1031808384 to finished
2022-04-04 08:13:52 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:13:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-841151595 in namespace http-bridge-tls-st
2022-04-04 08:13:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-841151595 will be in active state
2022-04-04 08:13:53 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-841151595 to finished
2022-04-04 08:14:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:14:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessageTls
2022-04-04 08:14:04 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-1031808384 in namespace http-bridge-tls-st
2022-04-04 08:14:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-860783203-293336368 in namespace http-bridge-tls-st
2022-04-04 08:14:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job consumer-841151595 in namespace http-bridge-tls-st
2022-04-04 08:14:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:14:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testSendSimpleMessageTls-FINISHED
2022-04-04 08:14:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:14:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:14:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeTlsST
2022-04-04 08:14:14 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment http-bridge-tls-st-kafka-clients in namespace http-bridge-tls-st
2022-04-04 08:14:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2027907585-1328845731 in namespace http-bridge-tls-st
2022-04-04 08:14:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-04 08:14:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-04 08:14:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 205.483 s - in io.strimzi.systemtest.bridge.HttpBridgeTlsST
[[1;34mINFO[m] Running io.strimzi.systemtest.tracing.TracingST
2022-04-04 08:15:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: tracing-st
2022-04-04 08:15:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: tracing-st
2022-04-04 08:15:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: tracing-st
2022-04-04 08:15:00 [main] [32mINFO [m [TracingST:497] === Applying jaeger operator install files ===
2022-04-04 08:15:00 [main] [32mINFO [m [TracingST:488] Creating jaeger-cluster-role-binding.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-cluster-role-binding.yaml
2022-04-04 08:15:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:15:00 [main] [32mINFO [m [Exec:417] Input: ---
kind: "ClusterRoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
  namespace: "tracing-st"
roleRef:
  kind: "ClusterRole"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-04 08:15:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:15:00 [main] [32mINFO [m [TracingST:488] Creating jaeger-cluster-role.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-cluster-role.yaml
2022-04-04 08:15:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:15:00 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "ClusterRole"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "console.openshift.io"
  resources:
  - "consolelinks"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "namespaces"
  verbs:
  - "get"
  - "list"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  verbs:
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - "clusterrolebindings"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-04 08:15:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:15:01 [main] [32mINFO [m [TracingST:488] Creating jaeger-crd.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-crd.yaml
2022-04-04 08:15:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:15:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:15:01 [main] [32mINFO [m [TracingST:488] Creating jaeger-operator.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-operator.yaml
2022-04-04 08:15:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:15:01 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "apps/v1"
kind: "Deployment"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
spec:
  replicas: 1
  selector:
    matchLabels:
      name: "jaeger-operator"
  template:
    metadata:
      labels:
        name: "jaeger-operator"
    spec:
      serviceAccountName: "jaeger-operator"
      containers:
      - name: "jaeger-operator"
        image: "jaegertracing/jaeger-operator:1.20.0"
        ports:
        - containerPort: 8383
          name: "http-metrics"
        - containerPort: 8686
          name: "cr-metrics"
        args:
        - "start"
        - "--kafka-provision=no"
        imagePullPolicy: "Always"
        env:
        - name: "WATCH_NAMESPACE"
          value: ""
        - name: "POD_NAME"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.name"
        - name: "POD_NAMESPACE"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.namespace"
        - name: "OPERATOR_NAME"
          value: "jaeger-operator"
2022-04-04 08:15:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:15:01 [main] [32mINFO [m [TracingST:488] Creating jaeger-role-binding.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-role-binding.yaml
2022-04-04 08:15:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:15:01 [main] [32mINFO [m [Exec:417] Input: ---
kind: "RoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
roleRef:
  kind: "Role"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-04 08:15:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:15:01 [main] [32mINFO [m [TracingST:488] Creating jaeger-role.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-role.yaml
2022-04-04 08:15:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:15:02 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "Role"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "image.openshift.io"
  resources:
  - "imagestreams"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-04 08:15:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:15:02 [main] [32mINFO [m [TracingST:488] Creating jaeger-service-account.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-service-account.yaml
2022-04-04 08:15:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-04 08:15:02 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "v1"
kind: "ServiceAccount"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
2022-04-04 08:15:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:15:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: jaeger-operator will be ready
2022-04-04 08:15:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: jaeger-operator is ready
2022-04-04 08:15:05 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment jaeger-operator to be ready
2022-04-04 08:15:15 [main] [32mINFO [m [DeploymentUtils:197] Deployment jaeger-operator is ready
2022-04-04 08:15:15 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy jaeger-allow in namespace tracing-st
2022-04-04 08:15:15 [main] [32mINFO [m [TracingST:524] Network policy for jaeger successfully created
2022-04-04 08:15:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:15:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsConnectService-STARTED
2022-04-04 08:15:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:15:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-4 for test case:testProducerConsumerStreamsConnectService
2022-04-04 08:15:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-4
2022-04-04 08:15:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-4
2022-04-04 08:15:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-4
2022-04-04 08:15:15 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-04 08:15:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 apply -f -
2022-04-04 08:15:15 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:15:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:15:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-04 08:15:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-04 08:15:20 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-04 08:15:31 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-04 08:15:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-faef19f7-kafka-clients in namespace namespace-4
2022-04-04 08:15:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:15:31 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-faef19f7-kafka-clients will be ready
2022-04-04 08:15:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-faef19f7-kafka-clients is ready
2022-04-04 08:15:32 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:15:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-faef19f7 in namespace namespace-4
2022-04-04 08:15:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:15:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-faef19f7 will have desired state: Ready
2022-04-04 08:16:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-faef19f7 is in desired state: Ready
2022-04-04 08:16:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-868015984-340388052 in namespace namespace-4
2022-04-04 08:16:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:16:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-868015984-340388052 will have desired state: Ready
2022-04-04 08:16:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-868015984-340388052 is in desired state: Ready
2022-04-04 08:16:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1013029938-193583918 in namespace namespace-4
2022-04-04 08:16:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:16:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1013029938-193583918 will have desired state: Ready
2022-04-04 08:16:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1013029938-193583918 is in desired state: Ready
2022-04-04 08:16:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-faef19f7-scraper in namespace namespace-4
2022-04-04 08:16:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:16:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-faef19f7-scraper will be ready
2022-04-04 08:16:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-faef19f7-scraper is ready
2022-04-04 08:16:55 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-faef19f7-scraper to be ready
2022-04-04 08:17:05 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-faef19f7-scraper is ready
2022-04-04 08:17:05 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-faef19f7-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 08:17:05 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-faef19f7-allow in namespace namespace-4
2022-04-04 08:17:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:17:05 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 08:17:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-faef19f7 in namespace namespace-4
2022-04-04 08:17:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:17:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-faef19f7 will have desired state: Ready
2022-04-04 08:18:15 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-faef19f7 is in desired state: Ready
2022-04-04 08:18:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-faef19f7 in namespace namespace-4
2022-04-04 08:18:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:18:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-faef19f7 will have desired state: Ready
2022-04-04 08:18:16 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-faef19f7 is in desired state: Ready
2022-04-04 08:18:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-faef19f7-hello-world-producer in namespace namespace-4
2022-04-04 08:18:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:18:16 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-faef19f7-hello-world-producer will be in active state
2022-04-04 08:18:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-faef19f7-hello-world-consumer in namespace namespace-4
2022-04-04 08:18:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-04 08:18:17 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-faef19f7-hello-world-consumer will be in active state
2022-04-04 08:18:18 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-faef19f7-hello-world-producer and consumer my-cluster-faef19f7-hello-world-consumer finish
2022-04-04 08:18:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-faef19f7-kafka-clients-6c649ddffd-6g8hr -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:18:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:18:36 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-04 08:18:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-faef19f7-kafka-clients-6c649ddffd-6g8hr -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-868015984-340388052
2022-04-04 08:18:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:18:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-faef19f7-kafka-clients-6c649ddffd-6g8hr -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:18:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:18:36 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-04 08:18:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-faef19f7-kafka-clients-6c649ddffd-6g8hr -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-topic-868015984-340388052
2022-04-04 08:18:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:18:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-faef19f7-kafka-clients-6c649ddffd-6g8hr -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:18:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:18:37 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-connect is present
2022-04-04 08:18:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-faef19f7-kafka-clients-6c649ddffd-6g8hr -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-connect&operation=From_my-topic-868015984-340388052
2022-04-04 08:18:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:18:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:18:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerStreamsConnectService
2022-04-04 08:18:37 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-faef19f7-allow in namespace namespace-4
2022-04-04 08:18:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-faef19f7 in namespace namespace-4
2022-04-04 08:18:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-faef19f7-kafka-clients in namespace namespace-4
2022-04-04 08:18:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1013029938-193583918 in namespace namespace-4
2022-04-04 08:18:37 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-faef19f7 in namespace namespace-4
2022-04-04 08:18:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-868015984-340388052 in namespace namespace-4
2022-04-04 08:18:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-faef19f7-hello-world-producer in namespace namespace-4
2022-04-04 08:18:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-faef19f7-hello-world-consumer in namespace namespace-4
2022-04-04 08:18:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-faef19f7 in namespace namespace-4
2022-04-04 08:18:47 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-faef19f7-scraper in namespace namespace-4
2022-04-04 08:18:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 delete -f -
2022-04-04 08:18:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:18:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:19:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:19:27 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-4 for test case:testProducerConsumerStreamsConnectService
2022-04-04 08:19:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsConnectService-FINISHED
2022-04-04 08:19:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:19:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:19:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testKafkaBridgeService-STARTED
2022-04-04 08:19:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:19:33 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-5 for test case:testKafkaBridgeService
2022-04-04 08:19:33 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-5
2022-04-04 08:19:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-5
2022-04-04 08:19:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-5
2022-04-04 08:19:33 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-04 08:19:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 apply -f -
2022-04-04 08:19:33 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:19:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:19:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-04 08:19:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-04 08:19:37 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-04 08:19:47 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-04 08:19:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ac9d7366-kafka-clients in namespace namespace-5
2022-04-04 08:19:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-04 08:19:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ac9d7366-kafka-clients will be ready
2022-04-04 08:19:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ac9d7366-kafka-clients is ready
2022-04-04 08:19:49 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:19:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ac9d7366 in namespace namespace-5
2022-04-04 08:19:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-04 08:19:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ac9d7366 will have desired state: Ready
2022-04-04 08:21:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ac9d7366 is in desired state: Ready
2022-04-04 08:21:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-ac9d7366 in namespace namespace-5
2022-04-04 08:21:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-04 08:21:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-ac9d7366 will have desired state: Ready
2022-04-04 08:21:25 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-ac9d7366 is in desired state: Ready
2022-04-04 08:21:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1305074384-176829692 in namespace namespace-5
2022-04-04 08:21:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-04 08:21:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1305074384-176829692 will have desired state: Ready
2022-04-04 08:21:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1305074384-176829692 is in desired state: Ready
2022-04-04 08:21:26 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:21:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer in namespace namespace-5
2022-04-04 08:21:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-04 08:21:26 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer will be in active state
2022-04-04 08:21:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-ac9d7366-hello-world-consumer in namespace namespace-5
2022-04-04 08:21:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-04 08:21:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-ac9d7366-hello-world-consumer will be in active state
2022-04-04 08:21:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer to finished
2022-04-04 08:23:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-ac9d7366-kafka-clients-5ddbc9895b-9gtgj -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:23:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:23:16 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-kafka-bridge is present
2022-04-04 08:23:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-ac9d7366-kafka-clients-5ddbc9895b-9gtgj -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-kafka-bridge
2022-04-04 08:23:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:23:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:23:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeService
2022-04-04 08:23:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1305074384-176829692 in namespace namespace-5
2022-04-04 08:23:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ac9d7366-kafka-clients in namespace namespace-5
2022-04-04 08:23:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ac9d7366 in namespace namespace-5
2022-04-04 08:23:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 delete -f -
2022-04-04 08:23:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:23:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:23:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-ac9d7366-hello-world-consumer in namespace namespace-5
2022-04-04 08:23:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer in namespace namespace-5
2022-04-04 08:23:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-ac9d7366 in namespace namespace-5
2022-04-04 08:24:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:24:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-5 for test case:testKafkaBridgeService
2022-04-04 08:24:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testKafkaBridgeService-FINISHED
2022-04-04 08:24:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:24:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:24:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsService-STARTED
2022-04-04 08:24:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:24:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-6 for test case:testProducerConsumerStreamsService
2022-04-04 08:24:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-6
2022-04-04 08:24:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-6
2022-04-04 08:24:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-6
2022-04-04 08:24:22 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-04 08:24:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 apply -f -
2022-04-04 08:24:23 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:24:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:24:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-04 08:24:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-04 08:24:27 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-04 08:24:37 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-04 08:24:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-62bec21a-kafka-clients in namespace namespace-6
2022-04-04 08:24:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:24:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-62bec21a-kafka-clients will be ready
2022-04-04 08:24:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-62bec21a-kafka-clients is ready
2022-04-04 08:24:39 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:24:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-62bec21a in namespace namespace-6
2022-04-04 08:24:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:24:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-62bec21a will have desired state: Ready
2022-04-04 08:26:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-62bec21a is in desired state: Ready
2022-04-04 08:26:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1233007939-1607946653 in namespace namespace-6
2022-04-04 08:26:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:26:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1233007939-1607946653 will have desired state: Ready
2022-04-04 08:26:02 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1233007939-1607946653 is in desired state: Ready
2022-04-04 08:26:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2129109295-1498550297 in namespace namespace-6
2022-04-04 08:26:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:26:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2129109295-1498550297 will have desired state: Ready
2022-04-04 08:26:03 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2129109295-1498550297 is in desired state: Ready
2022-04-04 08:26:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-62bec21a-hello-world-producer in namespace namespace-6
2022-04-04 08:26:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:26:03 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-62bec21a-hello-world-producer will be in active state
2022-04-04 08:26:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-62bec21a-kafka-clients-79b847c6bb-qg9jk -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:26:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:26:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-62bec21a-kafka-clients-79b847c6bb-qg9jk -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:26:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:26:06 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-04 08:26:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-62bec21a-kafka-clients-79b847c6bb-qg9jk -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer
2022-04-04 08:26:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:26:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-62bec21a-hello-world-consumer in namespace namespace-6
2022-04-04 08:26:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:26:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-62bec21a-hello-world-consumer will be in active state
2022-04-04 08:26:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-62bec21a-kafka-clients-79b847c6bb-qg9jk -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:26:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:26:06 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-04 08:26:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-62bec21a-kafka-clients-79b847c6bb-qg9jk -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:26:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:26:08 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-04 08:26:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-62bec21a-kafka-clients-79b847c6bb-qg9jk -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:26:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:26:09 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-04 08:26:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-62bec21a-kafka-clients-79b847c6bb-qg9jk -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:26:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:26:10 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["hello-world-producer","jaeger-query"].
2022-04-04 08:26:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-62bec21a-kafka-clients-79b847c6bb-qg9jk -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:26:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:26:11 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["hello-world-producer","jaeger-query"].
2022-04-04 08:26:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-62bec21a-kafka-clients-79b847c6bb-qg9jk -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:26:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:26:13 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-04 08:26:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-62bec21a-kafka-clients-79b847c6bb-qg9jk -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:26:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:26:14 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-04 08:26:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-62bec21a-kafka-clients-79b847c6bb-qg9jk -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer
2022-04-04 08:26:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:26:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-streams in namespace namespace-6
2022-04-04 08:26:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-04 08:26:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-streams will be in active state
2022-04-04 08:26:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:26:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerStreamsService
2022-04-04 08:26:15 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-62bec21a-hello-world-producer in namespace namespace-6
2022-04-04 08:26:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-streams in namespace namespace-6
2022-04-04 08:26:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-62bec21a in namespace namespace-6
2022-04-04 08:26:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-62bec21a-hello-world-consumer in namespace namespace-6
2022-04-04 08:26:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2129109295-1498550297 in namespace namespace-6
2022-04-04 08:26:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-62bec21a-kafka-clients in namespace namespace-6
2022-04-04 08:26:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1233007939-1607946653 in namespace namespace-6
2022-04-04 08:26:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 delete -f -
2022-04-04 08:26:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:26:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:27:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:27:05 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-6 for test case:testProducerConsumerStreamsService
2022-04-04 08:27:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsService-FINISHED
2022-04-04 08:27:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:27:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:27:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMakerService-STARTED
2022-04-04 08:27:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:27:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-7 for test case:testProducerConsumerMirrorMakerService
2022-04-04 08:27:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-7
2022-04-04 08:27:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-7
2022-04-04 08:27:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-7
2022-04-04 08:27:11 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-04 08:27:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 apply -f -
2022-04-04 08:27:11 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:27:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:27:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-04 08:27:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-04 08:27:20 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-04 08:27:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-04 08:27:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a5bb4794-kafka-clients in namespace namespace-7
2022-04-04 08:27:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:27:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a5bb4794-kafka-clients will be ready
2022-04-04 08:27:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a5bb4794-kafka-clients is ready
2022-04-04 08:27:32 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:27:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a5bb4794 in namespace namespace-7
2022-04-04 08:27:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:27:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a5bb4794 will have desired state: Ready
2022-04-04 08:28:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a5bb4794 is in desired state: Ready
2022-04-04 08:28:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a5bb4794-target in namespace namespace-7
2022-04-04 08:28:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:28:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a5bb4794-target will have desired state: Ready
2022-04-04 08:29:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a5bb4794-target is in desired state: Ready
2022-04-04 08:29:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1619370060-514715846 in namespace namespace-7
2022-04-04 08:29:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:29:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1619370060-514715846 will have desired state: Ready
2022-04-04 08:29:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1619370060-514715846 is in desired state: Ready
2022-04-04 08:29:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1619370060-514715846-target in namespace namespace-7
2022-04-04 08:29:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:29:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1619370060-514715846-target will have desired state: Ready
2022-04-04 08:30:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1619370060-514715846-target is in desired state: Ready
2022-04-04 08:30:00 [main] [32mINFO [m [TracingST:267] Setting for kafka source plain bootstrap:my-cluster-a5bb4794-kafka-bootstrap:9092
2022-04-04 08:30:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-a5bb4794-hello-world-producer in namespace namespace-7
2022-04-04 08:30:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:30:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-a5bb4794-hello-world-producer will be in active state
2022-04-04 08:30:01 [main] [32mINFO [m [TracingST:276] Setting for kafka target plain bootstrap:my-cluster-a5bb4794-target-kafka-bootstrap:9092
2022-04-04 08:30:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-a5bb4794-hello-world-consumer in namespace namespace-7
2022-04-04 08:30:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:30:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-a5bb4794-hello-world-consumer will be in active state
2022-04-04 08:30:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-a5bb4794 in namespace namespace-7
2022-04-04 08:30:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-04 08:30:02 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkamirrormakers' with unstable version 'v1beta2'
2022-04-04 08:30:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-a5bb4794 will have desired state: Ready
2022-04-04 08:31:08 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-a5bb4794 is in desired state: Ready
2022-04-04 08:31:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-a5bb4794-kafka-clients-6759478bcd-rzq7r -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:31:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:08 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-04 08:31:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-a5bb4794-kafka-clients-6759478bcd-rzq7r -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-1619370060-514715846
2022-04-04 08:31:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-a5bb4794-kafka-clients-6759478bcd-rzq7r -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:31:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:09 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-04 08:31:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-a5bb4794-kafka-clients-6759478bcd-rzq7r -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-topic-1619370060-514715846
2022-04-04 08:31:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-a5bb4794-kafka-clients-6759478bcd-rzq7r -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:31:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:10 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker is present
2022-04-04 08:31:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-a5bb4794-kafka-clients-6759478bcd-rzq7r -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker&operation=From_my-topic-1619370060-514715846
2022-04-04 08:31:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-a5bb4794-kafka-clients-6759478bcd-rzq7r -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:31:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:10 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker is present
2022-04-04 08:31:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-a5bb4794-kafka-clients-6759478bcd-rzq7r -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker&operation=To_my-topic-1619370060-514715846
2022-04-04 08:31:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:31:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMakerService
2022-04-04 08:31:10 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1619370060-514715846-target in namespace namespace-7
2022-04-04 08:31:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a5bb4794 in namespace namespace-7
2022-04-04 08:31:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a5bb4794-kafka-clients in namespace namespace-7
2022-04-04 08:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 delete -f -
2022-04-04 08:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-a5bb4794-hello-world-consumer in namespace namespace-7
2022-04-04 08:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-a5bb4794 in namespace namespace-7
2022-04-04 08:31:21 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1619370060-514715846 in namespace namespace-7
2022-04-04 08:31:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a5bb4794-target in namespace namespace-7
2022-04-04 08:31:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-a5bb4794-hello-world-producer in namespace namespace-7
2022-04-04 08:32:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:32:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-7 for test case:testProducerConsumerMirrorMakerService
2022-04-04 08:32:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMakerService-FINISHED
2022-04-04 08:32:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:32:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:32:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMaker2Service-STARTED
2022-04-04 08:32:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:32:12 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-8 for test case:testProducerConsumerMirrorMaker2Service
2022-04-04 08:32:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-8
2022-04-04 08:32:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-8
2022-04-04 08:32:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-8
2022-04-04 08:32:12 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-04 08:32:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 apply -f -
2022-04-04 08:32:12 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:32:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:32:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-04 08:32:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-04 08:32:21 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-04 08:32:31 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-04 08:32:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3ac9b9f1-kafka-clients in namespace namespace-8
2022-04-04 08:32:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:32:31 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3ac9b9f1-kafka-clients will be ready
2022-04-04 08:32:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3ac9b9f1-kafka-clients is ready
2022-04-04 08:32:32 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 08:32:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3ac9b9f1 in namespace namespace-8
2022-04-04 08:32:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:32:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3ac9b9f1 will have desired state: Ready
2022-04-04 08:33:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3ac9b9f1 is in desired state: Ready
2022-04-04 08:33:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3ac9b9f1-target in namespace namespace-8
2022-04-04 08:33:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:33:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3ac9b9f1-target will have desired state: Ready
2022-04-04 08:34:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3ac9b9f1-target is in desired state: Ready
2022-04-04 08:34:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-507714194-2111530867 in namespace namespace-8
2022-04-04 08:34:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:34:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-507714194-2111530867 will have desired state: Ready
2022-04-04 08:34:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-507714194-2111530867 is in desired state: Ready
2022-04-04 08:34:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-3ac9b9f1.my-topic-507714194-2111530867 in namespace namespace-8
2022-04-04 08:34:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:34:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-3ac9b9f1.my-topic-507714194-2111530867 will have desired state: Ready
2022-04-04 08:34:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-3ac9b9f1.my-topic-507714194-2111530867 is in desired state: Ready
2022-04-04 08:34:54 [main] [32mINFO [m [TracingST:177] Setting for kafka source plain bootstrap:my-cluster-3ac9b9f1-kafka-bootstrap:9092
2022-04-04 08:34:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-3ac9b9f1-hello-world-producer in namespace namespace-8
2022-04-04 08:34:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:34:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-3ac9b9f1-hello-world-producer will be in active state
2022-04-04 08:34:55 [main] [32mINFO [m [TracingST:186] Setting for kafka target plain bootstrap:my-cluster-3ac9b9f1-target-kafka-bootstrap:9092
2022-04-04 08:34:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-3ac9b9f1-hello-world-consumer in namespace namespace-8
2022-04-04 08:34:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:34:55 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-3ac9b9f1-hello-world-consumer will be in active state
2022-04-04 08:34:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-3ac9b9f1 in namespace namespace-8
2022-04-04 08:34:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-04 08:34:56 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkamirrormaker2s' with unstable version 'v1beta2'
2022-04-04 08:34:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-3ac9b9f1 will have desired state: Ready
2022-04-04 08:36:07 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-3ac9b9f1 is in desired state: Ready
2022-04-04 08:36:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-3ac9b9f1-kafka-clients-6775647b6-l2scp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:36:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:07 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-04 08:36:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-3ac9b9f1-kafka-clients-6775647b6-l2scp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-507714194-2111530867
2022-04-04 08:36:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-3ac9b9f1-kafka-clients-6775647b6-l2scp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:36:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:08 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-04 08:36:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-3ac9b9f1-kafka-clients-6775647b6-l2scp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-cluster-3ac9b9f1.my-topic-507714194-2111530867
2022-04-04 08:36:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-3ac9b9f1-kafka-clients-6775647b6-l2scp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:36:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:08 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker2 is present
2022-04-04 08:36:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-3ac9b9f1-kafka-clients-6775647b6-l2scp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker2&operation=From_my-topic-507714194-2111530867
2022-04-04 08:36:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-3ac9b9f1-kafka-clients-6775647b6-l2scp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-04 08:36:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:09 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker2 is present
2022-04-04 08:36:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-3ac9b9f1-kafka-clients-6775647b6-l2scp -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker2&operation=To_my-cluster-3ac9b9f1.my-topic-507714194-2111530867
2022-04-04 08:36:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:36:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker2Service
2022-04-04 08:36:09 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-3ac9b9f1.my-topic-507714194-2111530867 in namespace namespace-8
2022-04-04 08:36:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3ac9b9f1 in namespace namespace-8
2022-04-04 08:36:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3ac9b9f1-kafka-clients in namespace namespace-8
2022-04-04 08:36:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3ac9b9f1-target in namespace namespace-8
2022-04-04 08:36:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-3ac9b9f1-hello-world-consumer in namespace namespace-8
2022-04-04 08:36:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-3ac9b9f1-hello-world-producer in namespace namespace-8
2022-04-04 08:36:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-3ac9b9f1 in namespace namespace-8
2022-04-04 08:36:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-507714194-2111530867 in namespace namespace-8
2022-04-04 08:36:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 delete -f -
2022-04-04 08:36:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-04 08:36:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:36:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:36:59 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-8 for test case:testProducerConsumerMirrorMaker2Service
2022-04-04 08:37:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMaker2Service-FINISHED
2022-04-04 08:37:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:37:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:37:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for TracingST
2022-04-04 08:37:10 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy jaeger-allow in namespace tracing-st
2022-04-04 08:37:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:37:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Input: ---
apiVersion: "v1"
kind: "ServiceAccount"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
2022-04-04 08:37:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:37:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:37:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "Role"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "image.openshift.io"
  resources:
  - "imagestreams"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-04 08:37:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:37:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:37:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Input: ---
kind: "RoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
roleRef:
  kind: "Role"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-04 08:37:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:37:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:37:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Input: ---
apiVersion: "apps/v1"
kind: "Deployment"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
spec:
  replicas: 1
  selector:
    matchLabels:
      name: "jaeger-operator"
  template:
    metadata:
      labels:
        name: "jaeger-operator"
    spec:
      serviceAccountName: "jaeger-operator"
      containers:
      - name: "jaeger-operator"
        image: "jaegertracing/jaeger-operator:1.20.0"
        ports:
        - containerPort: 8383
          name: "http-metrics"
        - containerPort: 8686
          name: "cr-metrics"
        args:
        - "start"
        - "--kafka-provision=no"
        imagePullPolicy: "Always"
        env:
        - name: "WATCH_NAMESPACE"
          value: ""
        - name: "POD_NAME"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.name"
        - name: "POD_NAMESPACE"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.namespace"
        - name: "OPERATOR_NAME"
          value: "jaeger-operator"
2022-04-04 08:37:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:37:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:37:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:37:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:37:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "ClusterRole"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "console.openshift.io"
  resources:
  - "consolelinks"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "namespaces"
  verbs:
  - "get"
  - "list"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  verbs:
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - "clusterrolebindings"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-04 08:37:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:37:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-04 08:37:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Input: ---
kind: "ClusterRoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
  namespace: "tracing-st"
roleRef:
  kind: "ClusterRole"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-04 08:37:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:37:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,342.537 s - in io.strimzi.systemtest.tracing.TracingST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
2022-04-04 08:37:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-api-st
2022-04-04 08:37:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-api-st
2022-04-04 08:37:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-api-st
2022-04-04 08:37:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:37:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequests-STARTED
2022-04-04 08:37:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:37:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-9 for test case:testCruiseControlBasicAPIRequests
2022-04-04 08:37:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-9
2022-04-04 08:37:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-9
2022-04-04 08:37:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-9
2022-04-04 08:37:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7d8e209f in namespace namespace-9
2022-04-04 08:37:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-9
2022-04-04 08:37:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7d8e209f will have desired state: Ready
2022-04-04 08:38:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7d8e209f is in desired state: Ready
2022-04-04 08:38:58 [main] [32mINFO [m [CruiseControlApiST:48] ----> CRUISE CONTROL DEPLOYMENT STATE ENDPOINT <----
2022-04-04 08:38:58 [main] [32mINFO [m [CruiseControlApiST:58] Verifying that Cruise Control REST API is available
2022-04-04 08:38:58 [main] [32mINFO [m [CruiseControlApiST:66] ----> KAFKA REBALANCE <----
2022-04-04 08:38:58 [main] [32mINFO [m [CruiseControlApiST:73] Waiting for CC will have for enough metrics to be recorded to make a proposal 
2022-04-04 08:40:55 [main] [32mINFO [m [CruiseControlApiST:97] ----> EXECUTION OF STOP PROPOSAL <----
2022-04-04 08:40:55 [main] [32mINFO [m [CruiseControlApiST:108] ----> USER TASKS <----
2022-04-04 08:40:56 [main] [32mINFO [m [CruiseControlApiST:126] Verifying that Cruise Control REST API doesn't allow HTTP requests
2022-04-04 08:40:56 [main] [32mINFO [m [CruiseControlApiST:132] Verifying that Cruise Control REST API doesn't allow unauthenticated requests
2022-04-04 08:40:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:40:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlBasicAPIRequests
2022-04-04 08:40:56 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7d8e209f in namespace namespace-9
2022-04-04 08:40:56 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-9, for cruise control Kafka cluster my-cluster-7d8e209f
2022-04-04 08:41:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:41:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-9 for test case:testCruiseControlBasicAPIRequests
2022-04-04 08:41:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequests-FINISHED
2022-04-04 08:41:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:41:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:41:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequestsWithSecurityDisabled-STARTED
2022-04-04 08:41:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:41:49 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-10 for test case:testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-04 08:41:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-10
2022-04-04 08:41:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-10
2022-04-04 08:41:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-10
2022-04-04 08:41:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka cruise-control-api-cluster-name in namespace namespace-10
2022-04-04 08:41:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-10
2022-04-04 08:41:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: cruise-control-api-cluster-name will have desired state: Ready
2022-04-04 08:43:29 [main] [32mINFO [m [ResourceManager:444] Kafka: cruise-control-api-cluster-name is in desired state: Ready
2022-04-04 08:43:29 [main] [32mINFO [m [CruiseControlApiST:153] ----> CRUISE CONTROL DEPLOYMENT STATE ENDPOINT <----
2022-04-04 08:43:29 [main] [32mINFO [m [CruiseControlApiST:157] Verifying that Cruise Control REST API is available using HTTP request without credentials
2022-04-04 08:43:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:43:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-04 08:43:29 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka cruise-control-api-cluster-name in namespace namespace-10
2022-04-04 08:43:29 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-10, for cruise control Kafka cluster cruise-control-api-cluster-name
2022-04-04 08:43:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:43:39 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-10 for test case:testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-04 08:44:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequestsWithSecurityDisabled-FINISHED
2022-04-04 08:44:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:44:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:44:22 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlApiST is everything deleted.
2022-04-04 08:44:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 425.61 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
2022-04-04 08:44:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-configuration-st
2022-04-04 08:44:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-configuration-st
2022-04-04 08:44:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-configuration-st
2022-04-04 08:44:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:44:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationFileIsCreated-STARTED
2022-04-04 08:44:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:44:28 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-11 for test case:testConfigurationFileIsCreated
2022-04-04 08:44:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-11
2022-04-04 08:44:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-11
2022-04-04 08:44:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-11
2022-04-04 08:44:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-34d142b5 in namespace namespace-11
2022-04-04 08:44:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-11
2022-04-04 08:44:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-34d142b5 will have desired state: Ready
2022-04-04 08:46:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-34d142b5 is in desired state: Ready
2022-04-04 08:46:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-11 exec my-cluster-34d142b5-cruise-control-b7bc5cf77-lthgn -- /bin/bash -c cat /tmp/cruisecontrol.properties
2022-04-04 08:46:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 08:46:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:46:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationFileIsCreated
2022-04-04 08:46:09 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-34d142b5 in namespace namespace-11
2022-04-04 08:46:09 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-11, for cruise control Kafka cluster my-cluster-34d142b5
2022-04-04 08:46:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:46:19 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-11 for test case:testConfigurationFileIsCreated
2022-04-04 08:47:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationFileIsCreated-FINISHED
2022-04-04 08:47:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:47:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:47:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl-STARTED
2022-04-04 08:47:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:47:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-12 for test case:testDeployAndUnDeployCruiseControl
2022-04-04 08:47:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-12
2022-04-04 08:47:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-12
2022-04-04 08:47:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-12
2022-04-04 08:47:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-238759df in namespace namespace-12
2022-04-04 08:47:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-12
2022-04-04 08:47:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-238759df will have desired state: Ready
2022-04-04 08:48:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-238759df is in desired state: Ready
2022-04-04 08:48:43 [main] [32mINFO [m [CruiseControlConfigurationST:111] Removing Cruise Control to the classic Kafka.
2022-04-04 08:48:43 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-238759df-kafka rolling update
2022-04-04 08:49:58 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-238759df-kafka has been successfully rolled
2022-04-04 08:49:58 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-238759df-kafka to be ready
2022-04-04 08:50:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-238759df will have desired state: Ready
2022-04-04 08:50:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-238759df is in desired state: Ready
2022-04-04 08:50:28 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-238759df is ready
2022-04-04 08:50:28 [main] [32mINFO [m [CruiseControlConfigurationST:117] Verifying that in Cruise Control is not present in the Kafka cluster
2022-04-04 08:50:28 [main] [32mINFO [m [CruiseControlConfigurationST:120] Verifying that my-cluster-238759df-cruise-control- pod is not present
2022-04-04 08:50:28 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-238759df-cruise-control- will have stable 0 replicas
2022-04-04 08:50:28 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-04 08:50:29 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-04 08:50:30 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-04 08:50:31 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-04 08:50:32 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-04 08:50:33 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-04 08:50:34 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-04 08:50:35 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-04 08:50:36 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-04 08:50:37 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-04 08:50:38 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-04 08:50:39 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-04 08:50:40 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-04 08:50:41 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-04 08:50:42 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-04 08:50:43 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-04 08:50:44 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-04 08:50:45 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-04 08:50:46 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-04 08:50:47 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-04 08:50:47 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-238759df-cruise-control- has 0 replicas
2022-04-04 08:50:47 [main] [32mINFO [m [CruiseControlConfigurationST:123] Verifying that in Kafka config map there is no configuration to cruise control metric reporter
2022-04-04 08:52:47 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Verify that kafka configuration {cluster-name=my-cluster-238759df} has correct cruise control metric reporter properties, null
io.strimzi.test.WaitException: Timeout after 120000 ms waiting for Verify that kafka configuration {cluster-name=my-cluster-238759df} has correct cruise control metric reporter properties
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.specific.CruiseControlUtils.verifyCruiseControlMetricReporterConfigurationInKafkaConfigMapIsPresent(CruiseControlUtils.java:83)
	at io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.lambda$testDeployAndUnDeployCruiseControl$1(CruiseControlConfigurationST.java:124)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:55)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:37)
	at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3082)
	at io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl(CruiseControlConfigurationST.java:124)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 08:52:47 [main] [32mINFO [m [CruiseControlConfigurationST:126] Cruise Control topics will not be deleted and will stay in the Kafka cluster
2022-04-04 08:52:47 [main] [32mINFO [m [CruiseControlConfigurationST:130] Adding Cruise Control to the classic Kafka.
2022-04-04 08:52:47 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-238759df-kafka rolling update
2022-04-04 08:53:52 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-238759df-kafka has been successfully rolled
2022-04-04 08:53:52 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-238759df-kafka to be ready
2022-04-04 08:54:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-238759df will have desired state: Ready
2022-04-04 08:54:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-238759df is in desired state: Ready
2022-04-04 08:54:19 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-238759df is ready
2022-04-04 08:54:19 [main] [32mINFO [m [CruiseControlConfigurationST:136] Verifying that in Kafka config map there is configuration to cruise control metric reporter
2022-04-04 08:54:19 [main] [32mINFO [m [CruiseControlConfigurationST:139] Verifying that Cruise Control topics are created after CC is instantiated.
2022-04-04 08:54:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:54:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployAndUnDeployCruiseControl
2022-04-04 08:54:19 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-238759df in namespace namespace-12
2022-04-04 08:54:19 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-12, for cruise control Kafka cluster my-cluster-238759df
2022-04-04 08:54:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:54:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-12 for test case:testDeployAndUnDeployCruiseControl
2022-04-04 08:55:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl-FINISHED
2022-04-04 08:55:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:55:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:55:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationPerformanceOptions-STARTED
2022-04-04 08:55:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:55:13 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-13 for test case:testConfigurationPerformanceOptions
2022-04-04 08:55:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-13
2022-04-04 08:55:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-13
2022-04-04 08:55:13 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-13
2022-04-04 08:55:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-845923a4 in namespace namespace-13
2022-04-04 08:55:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-13
2022-04-04 08:55:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-845923a4 will have desired state: Ready
2022-04-04 08:56:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-845923a4 is in desired state: Ready
2022-04-04 08:56:47 [main] [32mINFO [m [CruiseControlConfigurationST:271] Changing cruise control performance tuning options
2022-04-04 08:56:47 [main] [32mINFO [m [CruiseControlConfigurationST:277] Verifying that CC pod is rolling, after changing options
2022-04-04 08:56:47 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-845923a4-cruise-control rolling update
2022-04-04 08:57:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-845923a4-cruise-control will be ready
2022-04-04 08:57:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-845923a4-cruise-control is ready
2022-04-04 08:57:27 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-845923a4-cruise-control rolling update finished
2022-04-04 08:57:27 [main] [32mINFO [m [CruiseControlConfigurationST:280] Verifying that Kafka pods did not roll
2022-04-04 08:57:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 08:57:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 08:57:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 08:57:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 08:57:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 08:57:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 08:57:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 08:57:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 08:57:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 08:57:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 08:57:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 08:57:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 08:57:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 08:57:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 08:57:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 08:57:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 08:57:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 08:57:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 08:57:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 08:57:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 08:57:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 08:57:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 08:57:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 08:57:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 08:57:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 08:57:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 08:57:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 08:57:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 08:57:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 08:57:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 08:57:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 08:57:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 08:58:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 08:58:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 08:58:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 08:58:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 08:58:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 08:58:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 08:58:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 08:58:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 08:58:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 08:58:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 08:58:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 08:58:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 08:58:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 08:58:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 08:58:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 08:58:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 08:58:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 08:58:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 08:58:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-845923a4-kafka-0=d125e183-27ba-442e-bcc1-e4fecef8f31a, my-cluster-845923a4-kafka-1=461aed65-c38a-4ce2-b3c1-e30e4c03f5f3, my-cluster-845923a4-kafka-2=7f495853-c050-498a-a227-8da4fcac01d2} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 08:58:18 [main] [32mINFO [m [CruiseControlConfigurationST:283] Verifying new configuration in the Kafka CR
2022-04-04 08:58:18 [main] [32mINFO [m [CruiseControlConfigurationST:300] Verifying Cruise control performance options are set in Kafka CR
2022-04-04 08:58:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 08:58:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationPerformanceOptions
2022-04-04 08:58:18 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-845923a4 in namespace namespace-13
2022-04-04 08:58:18 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-13, for cruise control Kafka cluster my-cluster-845923a4
2022-04-04 08:58:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 08:58:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-13 for test case:testConfigurationPerformanceOptions
2022-04-04 08:59:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationPerformanceOptions-FINISHED
2022-04-04 08:59:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 08:59:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 08:59:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationReflection-STARTED
2022-04-04 08:59:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 08:59:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-14 for test case:testConfigurationReflection
2022-04-04 08:59:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-14
2022-04-04 08:59:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-14
2022-04-04 08:59:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-14
2022-04-04 08:59:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a8093add in namespace namespace-14
2022-04-04 08:59:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-14
2022-04-04 08:59:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a8093add will have desired state: Ready
2022-04-04 09:00:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a8093add is in desired state: Ready
2022-04-04 09:00:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-14 exec my-cluster-a8093add-cruise-control-789f75dd9b-rmmcl -- /bin/bash -c cat /tmp/cruisecontrol.properties
2022-04-04 09:00:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 09:00:51 [main] [32mINFO [m [CruiseControlConfigurationST:221] Verifying that all configuration in the cruise control container matching the cruise control file /tmp/cruisecontrol.properties properties
2022-04-04 09:00:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:00:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationReflection
2022-04-04 09:00:51 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a8093add in namespace namespace-14
2022-04-04 09:00:51 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-14, for cruise control Kafka cluster my-cluster-a8093add
2022-04-04 09:01:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:01:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-14 for test case:testConfigurationReflection
2022-04-04 09:01:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationReflection-FINISHED
2022-04-04 09:01:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:01:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:01:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods-STARTED
2022-04-04 09:01:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:01:44 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-15 for test case:testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-04 09:01:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-15
2022-04-04 09:01:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-15
2022-04-04 09:01:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-15
2022-04-04 09:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-29745a91 in namespace namespace-15
2022-04-04 09:01:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-15
2022-04-04 09:01:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-29745a91 will have desired state: Ready
2022-04-04 09:03:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-29745a91 is in desired state: Ready
2022-04-04 09:03:27 [main] [32mINFO [m [CruiseControlConfigurationST:157] Changing the broker capacity of the cruise control
2022-04-04 09:03:27 [main] [32mINFO [m [CruiseControlConfigurationST:168] Verifying that CC pod is rolling, because of change size of disk
2022-04-04 09:03:27 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-29745a91-cruise-control rolling update
2022-04-04 09:04:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-29745a91-cruise-control will be ready
2022-04-04 09:04:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-29745a91-cruise-control is ready
2022-04-04 09:04:17 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-29745a91-cruise-control rolling update finished
2022-04-04 09:04:17 [main] [32mINFO [m [CruiseControlConfigurationST:171] Verifying that Kafka pods did not roll
2022-04-04 09:04:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 09:04:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 09:04:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 09:04:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 09:04:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 09:04:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 09:04:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 09:04:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 09:04:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 09:04:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 09:04:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 09:04:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 09:04:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 09:04:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 09:04:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 09:04:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 09:04:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 09:04:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 09:04:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 09:04:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 09:04:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 09:04:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 09:04:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 09:04:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 09:04:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 09:04:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 09:04:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 09:04:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 09:04:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 09:04:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 09:04:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 09:04:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 09:04:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 09:04:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 09:04:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 09:04:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 09:04:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 09:04:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 09:04:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 09:04:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 09:04:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 09:04:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 09:04:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 09:05:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 09:05:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 09:05:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 09:05:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 09:05:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 09:05:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 09:05:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 09:05:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-29745a91-kafka-1=d9daee27-7457-4067-9f39-475043fda04a, my-cluster-29745a91-kafka-0=cad67330-c6ba-41fc-aff9-b4289eeb8624, my-cluster-29745a91-kafka-2=5a1b56bb-273e-422d-b010-275ac9dfde94} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 09:05:07 [main] [32mINFO [m [CruiseControlConfigurationST:174] Verifying new configuration in the Kafka CR
2022-04-04 09:05:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:05:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-04 09:05:07 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-29745a91 in namespace namespace-15
2022-04-04 09:05:07 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-15, for cruise control Kafka cluster my-cluster-29745a91
2022-04-04 09:05:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:05:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-15 for test case:testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-04 09:06:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods-FINISHED
2022-04-04 09:06:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:06:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:06:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testCapacityFile-STARTED
2022-04-04 09:06:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:06:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-16 for test case:testCapacityFile
2022-04-04 09:06:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-16
2022-04-04 09:06:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-16
2022-04-04 09:06:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-16
2022-04-04 09:06:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b3721a93 in namespace namespace-16
2022-04-04 09:06:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-16
2022-04-04 09:06:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b3721a93 will have desired state: Ready
2022-04-04 09:07:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b3721a93 is in desired state: Ready
2022-04-04 09:07:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-16 exec my-cluster-b3721a93-cruise-control-5d7f4fc89c-dfjs9 -- /bin/bash -c cat /tmp/capacity.json
2022-04-04 09:07:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 09:07:40 [main] [32mINFO [m [CruiseControlConfigurationST:80] We got only one configuration of broker-capacities
2022-04-04 09:07:40 [main] [32mINFO [m [CruiseControlConfigurationST:83] Verifying cruise control configuration.
2022-04-04 09:07:40 [main] [32mINFO [m [CruiseControlConfigurationST:92] Verifying default cruise control capacities
2022-04-04 09:07:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:07:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCapacityFile
2022-04-04 09:07:40 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b3721a93 in namespace namespace-16
2022-04-04 09:07:40 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-16, for cruise control Kafka cluster my-cluster-b3721a93
2022-04-04 09:07:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:07:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-16 for test case:testCapacityFile
2022-04-04 09:08:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testCapacityFile-FINISHED
2022-04-04 09:08:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:08:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:08:34 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlConfigurationST is everything deleted.
2022-04-04 09:08:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,451.234 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlST
2022-04-04 09:08:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-st
2022-04-04 09:08:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-st
2022-04-04 09:08:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-st
2022-04-04 09:08:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:08:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlTopicExclusion-STARTED
2022-04-04 09:08:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:08:39 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-17 for test case:testCruiseControlTopicExclusion
2022-04-04 09:08:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-17
2022-04-04 09:08:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-17
2022-04-04 09:08:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-17
2022-04-04 09:08:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-99d6598d in namespace namespace-17
2022-04-04 09:08:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-04 09:08:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-99d6598d will have desired state: Ready
2022-04-04 09:10:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-99d6598d is in desired state: Ready
2022-04-04 09:10:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic excluded-topic-1 in namespace namespace-17
2022-04-04 09:10:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-04 09:10:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: excluded-topic-1 will have desired state: Ready
2022-04-04 09:10:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: excluded-topic-1 is in desired state: Ready
2022-04-04 09:10:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic excluded-topic-2 in namespace namespace-17
2022-04-04 09:10:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-04 09:10:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: excluded-topic-2 will have desired state: Ready
2022-04-04 09:10:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: excluded-topic-2 is in desired state: Ready
2022-04-04 09:10:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic included-topic in namespace namespace-17
2022-04-04 09:10:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-04 09:10:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: included-topic will have desired state: Ready
2022-04-04 09:10:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: included-topic is in desired state: Ready
2022-04-04 09:10:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-99d6598d in namespace namespace-17
2022-04-04 09:10:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-04 09:10:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-99d6598d will have desired state: PendingProposal
2022-04-04 09:10:25 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-99d6598d is in desired state: PendingProposal
2022-04-04 09:10:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-99d6598d will have desired state: ProposalReady
2022-04-04 09:16:15 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-99d6598d is in desired state: ProposalReady
2022-04-04 09:16:15 [main] [32mINFO [m [CruiseControlST:208] Checking status of KafkaRebalance
2022-04-04 09:16:15 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #4(test) KafkaRebalance(cruise-control-st/my-cluster-99d6598d): Annotating KafkaRebalance:my-cluster-99d6598d with annotation approve
2022-04-04 09:16:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-99d6598d will have desired state: Ready
2022-04-04 09:17:01 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-99d6598d is in desired state: Ready
2022-04-04 09:17:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:17:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlTopicExclusion
2022-04-04 09:17:01 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic excluded-topic-2 in namespace namespace-17
2022-04-04 09:17:01 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic excluded-topic-1 in namespace namespace-17
2022-04-04 09:17:01 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-99d6598d in namespace namespace-17
2022-04-04 09:17:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-99d6598d in namespace namespace-17
2022-04-04 09:17:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-17, for cruise control Kafka cluster my-cluster-99d6598d
2022-04-04 09:17:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic included-topic in namespace namespace-17
2022-04-04 09:17:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:17:11 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-17 for test case:testCruiseControlTopicExclusion
2022-04-04 09:17:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlTopicExclusion-FINISHED
2022-04-04 09:17:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:17:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:17:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage-STARTED
2022-04-04 09:17:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:17:54 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-18 for test case:testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-04 09:17:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-18
2022-04-04 09:17:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-18
2022-04-04 09:17:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-18
2022-04-04 09:17:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6980b210 in namespace namespace-18
2022-04-04 09:17:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-18
2022-04-04 09:17:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6980b210 will have desired state: Ready
2022-04-04 09:19:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6980b210 is in desired state: Ready
2022-04-04 09:19:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-6980b210 in namespace namespace-18
2022-04-04 09:19:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-18
2022-04-04 09:19:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-6980b210 will have desired state: NotReady
2022-04-04 09:19:43 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-6980b210 is in desired state: NotReady
2022-04-04 09:19:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:19:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-04 09:19:43 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-6980b210 in namespace namespace-18
2022-04-04 09:19:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6980b210 in namespace namespace-18
2022-04-04 09:19:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-18, for cruise control Kafka cluster my-cluster-6980b210
2022-04-04 09:19:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:19:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-18 for test case:testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-04 09:20:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage-FINISHED
2022-04-04 09:20:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:20:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:20:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testAutoCreationOfCruiseControlTopics-STARTED
2022-04-04 09:20:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:20:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2eeab0aa in namespace cruise-control-st
2022-04-04 09:20:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2eeab0aa will have desired state: Ready
2022-04-04 09:22:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2eeab0aa is in desired state: Ready
2022-04-04 09:22:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.metrics will have desired state: Ready
2022-04-04 09:22:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.metrics is in desired state: Ready
2022-04-04 09:22:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples will have desired state: Ready
2022-04-04 09:22:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples is in desired state: Ready
2022-04-04 09:22:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples will have desired state: Ready
2022-04-04 09:22:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples is in desired state: Ready
2022-04-04 09:22:15 [main] [32mINFO [m [CruiseControlST:96] Checking partitions and replicas for strimzi.cruisecontrol.metrics
2022-04-04 09:22:15 [main] [32mINFO [m [CruiseControlST:100] Checking partitions and replicas for strimzi.cruisecontrol.modeltrainingsamples
2022-04-04 09:22:15 [main] [32mINFO [m [CruiseControlST:104] Checking partitions and replicas for strimzi.cruisecontrol.partitionmetricsamples
2022-04-04 09:22:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:22:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoCreationOfCruiseControlTopics
2022-04-04 09:22:15 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2eeab0aa in namespace cruise-control-st
2022-04-04 09:22:15 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-2eeab0aa
2022-04-04 09:22:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:22:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testAutoCreationOfCruiseControlTopics-FINISHED
2022-04-04 09:22:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:22:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:22:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlReplicaMovementStrategy-STARTED
2022-04-04 09:22:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:22:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-19 for test case:testCruiseControlReplicaMovementStrategy
2022-04-04 09:22:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-19
2022-04-04 09:22:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-19
2022-04-04 09:22:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-19
2022-04-04 09:22:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b4bde7ad in namespace namespace-19
2022-04-04 09:22:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-19
2022-04-04 09:22:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b4bde7ad will have desired state: Ready
2022-04-04 09:24:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b4bde7ad is in desired state: Ready
2022-04-04 09:24:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b4bde7ad-kafka-clients in namespace namespace-19
2022-04-04 09:24:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-19
2022-04-04 09:24:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b4bde7ad-kafka-clients will be ready
2022-04-04 09:24:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b4bde7ad-kafka-clients is ready
2022-04-04 09:24:43 [main] [32mINFO [m [CruiseControlST:234] Check for default CruiseControl replicaMovementStrategy in pod configuration file.
2022-04-04 09:24:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-19 exec my-cluster-b4bde7ad-cruise-control-65d988f469-vskpx -c cruise-control -- cat /tmp/cruisecontrol.properties
2022-04-04 09:24:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 09:24:44 [main] [32mINFO [m [CruiseControlST:248] Set non-default CruiseControl replicaMovementStrategies to KafkaRebalance resource.
2022-04-04 09:24:44 [main] [32mINFO [m [CruiseControlST:252] Verifying that CC pod is rolling, because of change size of disk
2022-04-04 09:24:44 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-b4bde7ad-cruise-control rolling update
2022-04-04 09:25:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b4bde7ad-cruise-control will be ready
2022-04-04 09:25:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b4bde7ad-cruise-control is ready
2022-04-04 09:25:29 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-b4bde7ad-cruise-control rolling update finished
2022-04-04 09:25:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-19 exec my-cluster-b4bde7ad-cruise-control-784794c8f-fl9zz -c cruise-control -- cat /tmp/cruisecontrol.properties
2022-04-04 09:25:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 09:25:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:25:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlReplicaMovementStrategy
2022-04-04 09:25:29 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b4bde7ad-kafka-clients in namespace namespace-19
2022-04-04 09:25:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b4bde7ad in namespace namespace-19
2022-04-04 09:25:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-19, for cruise control Kafka cluster my-cluster-b4bde7ad
2022-04-04 09:26:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:26:19 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-19 for test case:testCruiseControlReplicaMovementStrategy
2022-04-04 09:26:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlReplicaMovementStrategy-FINISHED
2022-04-04 09:26:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:26:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:26:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithSingleNodeKafka-STARTED
2022-04-04 09:26:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:26:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-20 for test case:testCruiseControlWithSingleNodeKafka
2022-04-04 09:26:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-20
2022-04-04 09:26:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-20
2022-04-04 09:26:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-20
2022-04-04 09:26:25 [main] [32mINFO [m [CruiseControlST:169] Deploying single node Kafka with CruiseControl
2022-04-04 09:26:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-32b73540 in namespace namespace-20
2022-04-04 09:26:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-20
2022-04-04 09:26:28 [main] [32mINFO [m [CruiseControlST:178] Increasing Kafka nodes to 3
2022-04-04 09:26:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-32b73540 will have desired state: Ready
2022-04-04 09:28:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-32b73540 is in desired state: Ready
2022-04-04 09:28:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:28:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithSingleNodeKafka
2022-04-04 09:28:08 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-32b73540 in namespace namespace-20
2022-04-04 09:28:08 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-20, for cruise control Kafka cluster my-cluster-32b73540
2022-04-04 09:28:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:28:18 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-20 for test case:testCruiseControlWithSingleNodeKafka
2022-04-04 09:29:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithSingleNodeKafka-FINISHED
2022-04-04 09:29:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:29:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:29:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithRebalanceResourceAndRefreshAnnotation-STARTED
2022-04-04 09:29:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:29:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b0d80d10 in namespace cruise-control-st
2022-04-04 09:29:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b0d80d10 will have desired state: Ready
2022-04-04 09:30:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b0d80d10 is in desired state: Ready
2022-04-04 09:30:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-b0d80d10 in namespace cruise-control-st
2022-04-04 09:30:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-b0d80d10 will have desired state: PendingProposal
2022-04-04 09:30:38 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-b0d80d10 is in desired state: PendingProposal
2022-04-04 09:30:38 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): ============================================================================
2022-04-04 09:30:38 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): PendingProposal
2022-04-04 09:30:38 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): ============================================================================
2022-04-04 09:30:38 [main] [32mINFO [m [KafkaRebalanceUtils:81] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): Verifying that KafkaRebalance resource is in PendingProposal state
2022-04-04 09:30:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-b0d80d10 will have desired state: PendingProposal
2022-04-04 09:30:38 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-b0d80d10 is in desired state: PendingProposal
2022-04-04 09:30:38 [main] [32mINFO [m [KafkaRebalanceUtils:85] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): Verifying that KafkaRebalance resource is in ProposalReady state
2022-04-04 09:30:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-b0d80d10 will have desired state: ProposalReady
2022-04-04 09:36:33 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-b0d80d10 is in desired state: ProposalReady
2022-04-04 09:36:33 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): ============================================================================
2022-04-04 09:36:33 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): ProposalReady
2022-04-04 09:36:33 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): ============================================================================
2022-04-04 09:36:33 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-04 09:36:33 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): Annotating KafkaRebalance:my-cluster-b0d80d10 with annotation approve
2022-04-04 09:36:33 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-b0d80d10 annotated
2022-04-04 09:36:33 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): Verifying that annotation triggers the Rebalancing state
2022-04-04 09:36:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-b0d80d10 will have desired state: Rebalancing
2022-04-04 09:36:34 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-b0d80d10 is in desired state: Rebalancing
2022-04-04 09:36:34 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): Verifying that KafkaRebalance is in the Ready state
2022-04-04 09:36:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-b0d80d10 will have desired state: Ready
2022-04-04 09:37:39 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-b0d80d10 is in desired state: Ready
2022-04-04 09:37:39 [main] [32mINFO [m [CruiseControlST:152] Annotating KafkaRebalance: my-cluster-b0d80d10 with 'refresh' anno
2022-04-04 09:37:39 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #6(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): Annotating KafkaRebalance:my-cluster-b0d80d10 with annotation refresh
2022-04-04 09:37:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-b0d80d10 will have desired state: ProposalReady
2022-04-04 09:37:40 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-b0d80d10 is in desired state: ProposalReady
2022-04-04 09:37:40 [main] [32mINFO [m [CruiseControlST:156] Trying rebalancing process again
2022-04-04 09:37:40 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): ============================================================================
2022-04-04 09:37:40 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): ProposalReady
2022-04-04 09:37:40 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): ============================================================================
2022-04-04 09:37:40 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): ============================================================================
2022-04-04 09:37:40 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): ProposalReady
2022-04-04 09:37:40 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): ============================================================================
2022-04-04 09:37:40 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-04 09:37:40 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): Annotating KafkaRebalance:my-cluster-b0d80d10 with annotation approve
2022-04-04 09:37:40 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-b0d80d10 annotated
2022-04-04 09:37:40 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): Verifying that annotation triggers the Rebalancing state
2022-04-04 09:37:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-b0d80d10 will have desired state: Rebalancing
2022-04-04 09:37:41 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-b0d80d10 is in desired state: Rebalancing
2022-04-04 09:37:41 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-b0d80d10): Verifying that KafkaRebalance is in the Ready state
2022-04-04 09:37:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-b0d80d10 will have desired state: Ready
2022-04-04 09:37:56 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-b0d80d10 is in desired state: Ready
2022-04-04 09:37:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:37:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithRebalanceResourceAndRefreshAnnotation
2022-04-04 09:37:56 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-b0d80d10 in namespace cruise-control-st
2022-04-04 09:37:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b0d80d10 in namespace cruise-control-st
2022-04-04 09:37:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-b0d80d10
2022-04-04 09:38:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:38:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithRebalanceResourceAndRefreshAnnotation-FINISHED
2022-04-04 09:38:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:38:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:38:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithApiSecurityDisabled-STARTED
2022-04-04 09:38:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:38:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-96751630 in namespace cruise-control-st
2022-04-04 09:38:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-96751630 will have desired state: Ready
2022-04-04 09:39:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-96751630 is in desired state: Ready
2022-04-04 09:39:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-96751630 in namespace cruise-control-st
2022-04-04 09:39:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-96751630 will have desired state: PendingProposal
2022-04-04 09:39:46 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-96751630 is in desired state: PendingProposal
2022-04-04 09:39:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-96751630 will have desired state: ProposalReady
2022-04-04 09:41:40 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-96751630 is in desired state: ProposalReady
2022-04-04 09:41:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:41:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithApiSecurityDisabled
2022-04-04 09:41:40 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-96751630 in namespace cruise-control-st
2022-04-04 09:41:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-96751630 in namespace cruise-control-st
2022-04-04 09:41:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-96751630
2022-04-04 09:41:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:41:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithApiSecurityDisabled-FINISHED
2022-04-04 09:41:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:41:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:41:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancing-STARTED
2022-04-04 09:41:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:41:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-21 for test case:testCruiseControlIntraBrokerBalancing
2022-04-04 09:41:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-21
2022-04-04 09:41:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-21
2022-04-04 09:41:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-21
2022-04-04 09:41:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b0e57186 in namespace namespace-21
2022-04-04 09:41:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-21
2022-04-04 09:41:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b0e57186 will have desired state: Ready
2022-04-04 09:43:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b0e57186 is in desired state: Ready
2022-04-04 09:43:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-b0e57186 in namespace namespace-21
2022-04-04 09:43:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-21
2022-04-04 09:43:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-b0e57186 will have desired state: PendingProposal
2022-04-04 09:43:38 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-b0e57186 is in desired state: PendingProposal
2022-04-04 09:43:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-b0e57186 will have desired state: ProposalReady
2022-04-04 09:46:28 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-b0e57186 is in desired state: ProposalReady
2022-04-04 09:46:28 [main] [32mINFO [m [CruiseControlST:292] Checking status of KafkaRebalance
2022-04-04 09:46:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:46:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlIntraBrokerBalancing
2022-04-04 09:46:28 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-b0e57186 in namespace namespace-21
2022-04-04 09:46:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b0e57186 in namespace namespace-21
2022-04-04 09:46:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-21, for cruise control Kafka cluster my-cluster-b0e57186
2022-04-04 09:46:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:46:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-21 for test case:testCruiseControlIntraBrokerBalancing
2022-04-04 09:47:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancing-FINISHED
2022-04-04 09:47:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:47:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:47:22 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlST is everything deleted.
2022-04-04 09:47:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,329.378 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.KafkaST
2022-04-04 09:47:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: kafka-st
2022-04-04 09:47:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kafka-st
2022-04-04 09:47:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: kafka-st
2022-04-04 09:47:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:47:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaOffsetsReplicationFactorHigherThanReplicas-STARTED
2022-04-04 09:47:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:47:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-22 for test case:testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-04 09:47:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-22
2022-04-04 09:47:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-22
2022-04-04 09:47:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-22
2022-04-04 09:47:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0fbddacf in namespace namespace-22
2022-04-04 09:47:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-04 09:47:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:47:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-04 09:47:33 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0fbddacf in namespace namespace-22
2022-04-04 09:47:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:47:43 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-22 for test case:testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-04 09:47:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaOffsetsReplicationFactorHigherThanReplicas-FINISHED
2022-04-04 09:47:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:47:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:47:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserOperator-STARTED
2022-04-04 09:47:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:47:48 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-23 for test case:testEntityOperatorWithoutUserOperator
2022-04-04 09:47:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-23
2022-04-04 09:47:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-23
2022-04-04 09:47:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-23
2022-04-04 09:47:48 [main] [32mINFO [m [KafkaST:787] Deploying Kafka cluster without UO in EO
2022-04-04 09:47:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2a60e00b in namespace namespace-23
2022-04-04 09:47:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-04 09:47:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2a60e00b will have desired state: Ready
2022-04-04 09:49:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2a60e00b is in desired state: Ready
2022-04-04 09:49:05 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 76 seconds
2022-04-04 09:49:05 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-04 09:49:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:49:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutUserOperator
2022-04-04 09:49:05 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2a60e00b in namespace namespace-23
2022-04-04 09:49:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:49:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-23 for test case:testEntityOperatorWithoutUserOperator
2022-04-04 09:49:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserOperator-FINISHED
2022-04-04 09:49:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:49:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:49:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutTopicOperator-STARTED
2022-04-04 09:49:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:49:58 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-24 for test case:testEntityOperatorWithoutTopicOperator
2022-04-04 09:49:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-24
2022-04-04 09:49:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-24
2022-04-04 09:49:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-24
2022-04-04 09:49:58 [main] [32mINFO [m [KafkaST:757] Deploying Kafka cluster without TO in EO
2022-04-04 09:49:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1b58e086 in namespace namespace-24
2022-04-04 09:49:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-24
2022-04-04 09:49:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1b58e086 will have desired state: Ready
2022-04-04 09:51:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1b58e086 is in desired state: Ready
2022-04-04 09:51:14 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 76 seconds
2022-04-04 09:51:14 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-04 09:51:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:51:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutTopicOperator
2022-04-04 09:51:14 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1b58e086 in namespace namespace-24
2022-04-04 09:51:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:51:24 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-24 for test case:testEntityOperatorWithoutTopicOperator
2022-04-04 09:51:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutTopicOperator-FINISHED
2022-04-04 09:51:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:51:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:51:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testTopicWithoutLabels-STARTED
2022-04-04 09:51:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:51:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-25 for test case:testTopicWithoutLabels
2022-04-04 09:51:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-25
2022-04-04 09:51:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-25
2022-04-04 09:51:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-25
2022-04-04 09:51:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8427d48a in namespace namespace-25
2022-04-04 09:51:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-25
2022-04-04 09:51:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8427d48a will have desired state: Ready
2022-04-04 09:53:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8427d48a is in desired state: Ready
2022-04-04 09:53:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-without-labels in namespace namespace-25
2022-04-04 09:53:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-25
2022-04-04 09:53:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-25 exec my-cluster-8427d48a-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 09:53:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 09:53:06 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic topic-without-labels deletion
2022-04-04 09:53:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-25 exec my-cluster-8427d48a-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 09:53:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 09:53:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:53:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicWithoutLabels
2022-04-04 09:53:09 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-without-labels in namespace namespace-25
2022-04-04 09:53:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8427d48a in namespace namespace-25
2022-04-04 09:53:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:53:19 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-25 for test case:testTopicWithoutLabels
2022-04-04 09:54:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testTopicWithoutLabels-FINISHED
2022-04-04 09:54:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:54:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:54:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveTopicOperatorFromEntityOperator-STARTED
2022-04-04 09:54:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:54:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-26 for test case:testRemoveTopicOperatorFromEntityOperator
2022-04-04 09:54:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-26
2022-04-04 09:54:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-26
2022-04-04 09:54:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-26
2022-04-04 09:54:02 [main] [32mINFO [m [KafkaST:623] Deploying Kafka cluster my-cluster-8a52eeec
2022-04-04 09:54:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8a52eeec in namespace namespace-26
2022-04-04 09:54:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-26
2022-04-04 09:54:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8a52eeec will have desired state: Ready
2022-04-04 09:55:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8a52eeec is in desired state: Ready
2022-04-04 09:55:16 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-8a52eeec-entity-operator-6c7b6cfdf-shrq9 will be deleted
2022-04-04 09:55:26 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-8a52eeec-entity-operator-6c7b6cfdf-shrq9 deleted
2022-04-04 09:55:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8a52eeec-entity-operator will be ready
2022-04-04 09:55:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8a52eeec-entity-operator is ready
2022-04-04 09:55:42 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-8a52eeec-entity-operator to be ready
2022-04-04 09:55:52 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-8a52eeec-entity-operator is ready
2022-04-04 09:55:52 [main] [32mINFO [m [PodUtils:201] Wait until Pod my-cluster-8a52eeec-entity-operator will have 1 containers
2022-04-04 09:55:52 [main] [32mINFO [m [PodUtils:205] Pod my-cluster-8a52eeec-entity-operator has 1 containers
2022-04-04 09:55:52 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-8a52eeec-entity-operator-77c78fbf7b-ksw7g will be deleted
2022-04-04 09:55:57 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-8a52eeec-entity-operator-77c78fbf7b-ksw7g deleted
2022-04-04 09:55:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8a52eeec-entity-operator will be ready
2022-04-04 09:56:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8a52eeec-entity-operator is ready
2022-04-04 09:56:17 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-8a52eeec-entity-operator to be ready
2022-04-04 09:56:27 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-8a52eeec-entity-operator is ready
2022-04-04 09:56:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:56:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveTopicOperatorFromEntityOperator
2022-04-04 09:56:27 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8a52eeec in namespace namespace-26
2022-04-04 09:56:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:56:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-26 for test case:testRemoveTopicOperatorFromEntityOperator
2022-04-04 09:57:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveTopicOperatorFromEntityOperator-FINISHED
2022-04-04 09:57:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:57:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:57:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserAndTopicOperators-STARTED
2022-04-04 09:57:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:57:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-27 for test case:testEntityOperatorWithoutUserAndTopicOperators
2022-04-04 09:57:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-27
2022-04-04 09:57:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-27
2022-04-04 09:57:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-27
2022-04-04 09:57:21 [main] [32mINFO [m [KafkaST:814] Deploying Kafka cluster without UO and TO in EO
2022-04-04 09:57:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d47271d9 in namespace namespace-27
2022-04-04 09:57:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-04 09:57:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d47271d9 will have desired state: Ready
2022-04-04 09:58:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d47271d9 is in desired state: Ready
2022-04-04 09:58:13 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 52 seconds
2022-04-04 09:58:13 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-04 09:58:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 09:58:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutUserAndTopicOperators
2022-04-04 09:58:13 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d47271d9 in namespace namespace-27
2022-04-04 09:58:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 09:58:23 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-27 for test case:testEntityOperatorWithoutUserAndTopicOperators
2022-04-04 09:58:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserAndTopicOperators-FINISHED
2022-04-04 09:58:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 09:58:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 09:58:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserAndTopicOperatorsFromEntityOperator-STARTED
2022-04-04 09:58:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 09:58:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-28 for test case:testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-04 09:58:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-28
2022-04-04 09:58:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-28
2022-04-04 09:58:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-28
2022-04-04 09:58:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e483d54c in namespace namespace-28
2022-04-04 09:58:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-04 09:58:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e483d54c will have desired state: Ready
2022-04-04 10:00:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e483d54c is in desired state: Ready
2022-04-04 10:00:09 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-e483d54c-entity-operator will have stable 0 replicas
2022-04-04 10:00:09 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:00:10 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:00:11 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:00:12 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:00:13 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:00:14 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:00:15 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 10:00:16 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-04 10:00:17 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-04 10:00:18 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-04 10:00:19 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-04 10:00:20 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-04 10:00:21 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-04 10:00:22 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-04 10:00:23 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-04 10:00:24 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-04 10:00:25 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-04 10:00:26 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-04 10:00:27 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-04 10:00:28 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-04 10:00:29 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-04 10:00:30 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-04 10:00:31 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-04 10:00:32 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-04 10:00:33 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-04 10:00:34 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-04 10:00:35 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-04 10:00:35 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-e483d54c-entity-operator has 0 replicas
2022-04-04 10:00:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e483d54c-entity-operator will be ready
2022-04-04 10:01:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e483d54c-entity-operator is ready
2022-04-04 10:01:07 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 136 seconds
2022-04-04 10:01:07 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-04 10:01:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:01:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-04 10:01:07 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e483d54c in namespace namespace-28
2022-04-04 10:01:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:01:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-28 for test case:testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-04 10:02:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserAndTopicOperatorsFromEntityOperator-FINISHED
2022-04-04 10:02:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:02:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:02:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testConsumerOffsetFiles-STARTED
2022-04-04 10:02:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:02:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-29 for test case:testConsumerOffsetFiles
2022-04-04 10:02:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-29
2022-04-04 10:02:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-29
2022-04-04 10:02:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-29
2022-04-04 10:02:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f43c6c95 in namespace namespace-29
2022-04-04 10:02:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-29
2022-04-04 10:02:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f43c6c95 will have desired state: Ready
2022-04-04 10:03:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f43c6c95 is in desired state: Ready
2022-04-04 10:03:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-568022407-1594590290 in namespace namespace-29
2022-04-04 10:03:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-29
2022-04-04 10:03:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-568022407-1594590290 will have desired state: Ready
2022-04-04 10:03:20 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-568022407-1594590290 is in desired state: Ready
2022-04-04 10:03:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f43c6c95-kafka-clients in namespace namespace-29
2022-04-04 10:03:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-29
2022-04-04 10:03:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f43c6c95-kafka-clients will be ready
2022-04-04 10:03:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f43c6c95-kafka-clients is ready
2022-04-04 10:03:22 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 10:03:22 [main] [32mINFO [m [KafkaST:1415] Executing command cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V in my-cluster-f43c6c95-kafka-0
2022-04-04 10:03:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-29 exec my-cluster-f43c6c95-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V
2022-04-04 10:03:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:03:22 [main] [32mINFO [m [KafkaST:1422] Result: 
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99

2022-04-04 10:03:22 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@55036033, messages=[], arguments=[--topic, my-topic-568022407-1594590290, --max-messages, 100, --bootstrap-server, my-cluster-f43c6c95-kafka-bootstrap.namespace-29.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-f43c6c95-kafka-clients-54fc897dd6-xps99', podNamespace='namespace-29', bootstrapServer='my-cluster-f43c6c95-kafka-bootstrap.namespace-29.svc:9092', topicName='my-topic-568022407-1594590290', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@324332a}
2022-04-04 10:03:22 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-f43c6c95-kafka-bootstrap.namespace-29.svc:9092:my-topic-568022407-1594590290 from pod my-cluster-f43c6c95-kafka-clients-54fc897dd6-xps99
2022-04-04 10:03:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f43c6c95-kafka-clients-54fc897dd6-xps99 -n namespace-29 -- /opt/kafka/producer.sh --topic my-topic-568022407-1594590290 --max-messages 100 --bootstrap-server my-cluster-f43c6c95-kafka-bootstrap.namespace-29.svc:9092
2022-04-04 10:03:25 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 10:03:25 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 10:03:25 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7dcca43f, messages=[], arguments=[--topic, my-topic-568022407-1594590290, --max-messages, 100, --group-instance-id, instance534941243, --group-id, my-consumer-group-458597307, --bootstrap-server, my-cluster-f43c6c95-kafka-bootstrap.namespace-29.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f43c6c95-kafka-clients-54fc897dd6-xps99', podNamespace='namespace-29', bootstrapServer='my-cluster-f43c6c95-kafka-bootstrap.namespace-29.svc:9092', topicName='my-topic-568022407-1594590290', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-458597307', consumerInstanceId='instance534941243', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@d8199f3}
2022-04-04 10:03:25 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-f43c6c95-kafka-bootstrap.namespace-29.svc:9092#my-topic-568022407-1594590290 from pod my-cluster-f43c6c95-kafka-clients-54fc897dd6-xps99
2022-04-04 10:03:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f43c6c95-kafka-clients-54fc897dd6-xps99 -n namespace-29 -- /opt/kafka/consumer.sh --topic my-topic-568022407-1594590290 --max-messages 100 --group-instance-id instance534941243 --group-id my-consumer-group-458597307 --bootstrap-server my-cluster-f43c6c95-kafka-bootstrap.namespace-29.svc:9092
2022-04-04 10:03:30 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 10:03:30 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 10:03:30 [main] [32mINFO [m [KafkaST:1429] Executing command cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V in my-cluster-f43c6c95-kafka-0
2022-04-04 10:03:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-29 exec my-cluster-f43c6c95-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V
2022-04-04 10:03:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:03:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:03:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConsumerOffsetFiles
2022-04-04 10:03:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f43c6c95 in namespace namespace-29
2022-04-04 10:03:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f43c6c95-kafka-clients in namespace namespace-29
2022-04-04 10:03:31 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-568022407-1594590290 in namespace namespace-29
2022-04-04 10:04:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:04:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-29 for test case:testConsumerOffsetFiles
2022-04-04 10:04:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testConsumerOffsetFiles-FINISHED
2022-04-04 10:04:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:04:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:04:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testAppDomainLabels-STARTED
2022-04-04 10:04:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:04:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-30 for test case:testAppDomainLabels
2022-04-04 10:04:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-30
2022-04-04 10:04:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-30
2022-04-04 10:04:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-30
2022-04-04 10:04:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-dc5be5a4 in namespace namespace-30
2022-04-04 10:04:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-30
2022-04-04 10:04:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-dc5be5a4 will have desired state: Ready
2022-04-04 10:05:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-dc5be5a4 is in desired state: Ready
2022-04-04 10:05:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-675984414-904514864 in namespace namespace-30
2022-04-04 10:05:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-30
2022-04-04 10:05:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-675984414-904514864 will have desired state: Ready
2022-04-04 10:05:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-675984414-904514864 is in desired state: Ready
2022-04-04 10:05:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-dc5be5a4-kafka-clients in namespace namespace-30
2022-04-04 10:05:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-30
2022-04-04 10:05:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-dc5be5a4-kafka-clients will be ready
2022-04-04 10:05:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-dc5be5a4-kafka-clients is ready
2022-04-04 10:05:44 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1220] ---> PODS <---
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1232] ---> STATEFUL SETS <---
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1236] Getting labels from stateful set of kafka resource
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dc5be5a4-kafka, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1241] Getting labels from stateful set of zookeeper resource
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dc5be5a4-zookeeper, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1244] ---> SERVICES <---
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-dc5be5a4-kafka-bootstrap service
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/discovery=true, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dc5be5a4-kafka, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-dc5be5a4-kafka-brokers service
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dc5be5a4-kafka, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-dc5be5a4-zookeeper-client service
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dc5be5a4-zookeeper-client, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-dc5be5a4-zookeeper-nodes service
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dc5be5a4-zookeeper, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1255] ---> SECRETS <---
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-dc5be5a4-clients-ca secret
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-dc5be5a4-clients-ca-cert secret
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-dc5be5a4-cluster-ca secret
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-dc5be5a4-cluster-ca-cert secret
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-dc5be5a4-cluster-operator-certs secret
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-dc5be5a4-entity-topic-operator-certs secret
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-topic-operator, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-dc5be5a4-entity-user-operator-certs secret
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-user-operator, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-dc5be5a4-kafka-brokers secret
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-dc5be5a4-zookeeper-nodes secret
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1266] ---> CONFIG MAPS <---
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-dc5be5a4-entity-topic-operator-config config map
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-topic-operator, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-dc5be5a4-entity-user-operator-config config map
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-user-operator, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-dc5be5a4-kafka-config config map
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dc5be5a4-kafka, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-dc5be5a4-zookeeper-config config map
2022-04-04 10:05:44 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-dc5be5a4, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-dc5be5a4, strimzi.io/cluster=my-cluster-dc5be5a4, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-04 10:05:44 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5d8a6614, messages=[], arguments=[--topic, my-topic-675984414-904514864, --max-messages, 100, --bootstrap-server, my-cluster-dc5be5a4-kafka-bootstrap.namespace-30.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-dc5be5a4-kafka-clients-69897b8456-7fgpc', podNamespace='namespace-30', bootstrapServer='my-cluster-dc5be5a4-kafka-bootstrap.namespace-30.svc:9092', topicName='my-topic-675984414-904514864', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@645342c}
2022-04-04 10:05:44 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-dc5be5a4-kafka-bootstrap.namespace-30.svc:9092:my-topic-675984414-904514864 from pod my-cluster-dc5be5a4-kafka-clients-69897b8456-7fgpc
2022-04-04 10:05:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-dc5be5a4-kafka-clients-69897b8456-7fgpc -n namespace-30 -- /opt/kafka/producer.sh --topic my-topic-675984414-904514864 --max-messages 100 --bootstrap-server my-cluster-dc5be5a4-kafka-bootstrap.namespace-30.svc:9092
2022-04-04 10:05:46 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 10:05:46 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 10:05:46 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@61e45f16, messages=[], arguments=[--topic, my-topic-675984414-904514864, --max-messages, 100, --group-instance-id, instance1038091385, --group-id, my-consumer-group-1712341589, --bootstrap-server, my-cluster-dc5be5a4-kafka-bootstrap.namespace-30.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-dc5be5a4-kafka-clients-69897b8456-7fgpc', podNamespace='namespace-30', bootstrapServer='my-cluster-dc5be5a4-kafka-bootstrap.namespace-30.svc:9092', topicName='my-topic-675984414-904514864', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1712341589', consumerInstanceId='instance1038091385', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4eaff6bb}
2022-04-04 10:05:46 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-dc5be5a4-kafka-bootstrap.namespace-30.svc:9092#my-topic-675984414-904514864 from pod my-cluster-dc5be5a4-kafka-clients-69897b8456-7fgpc
2022-04-04 10:05:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-dc5be5a4-kafka-clients-69897b8456-7fgpc -n namespace-30 -- /opt/kafka/consumer.sh --topic my-topic-675984414-904514864 --max-messages 100 --group-instance-id instance1038091385 --group-id my-consumer-group-1712341589 --bootstrap-server my-cluster-dc5be5a4-kafka-bootstrap.namespace-30.svc:9092
2022-04-04 10:05:52 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 10:05:52 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 10:05:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:05:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAppDomainLabels
2022-04-04 10:05:52 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-675984414-904514864 in namespace namespace-30
2022-04-04 10:05:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-dc5be5a4-kafka-clients in namespace namespace-30
2022-04-04 10:05:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-dc5be5a4 in namespace namespace-30
2022-04-04 10:06:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:06:42 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-30 for test case:testAppDomainLabels
2022-04-04 10:06:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testAppDomainLabels-FINISHED
2022-04-04 10:06:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:06:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:06:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserOperatorFromEntityOperator-STARTED
2022-04-04 10:06:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:06:48 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-31 for test case:testRemoveUserOperatorFromEntityOperator
2022-04-04 10:06:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-31
2022-04-04 10:06:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-31
2022-04-04 10:06:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-31
2022-04-04 10:06:48 [main] [32mINFO [m [KafkaST:669] Deploying Kafka cluster my-cluster-bc269fcf
2022-04-04 10:06:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bc269fcf in namespace namespace-31
2022-04-04 10:06:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-04 10:06:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bc269fcf will have desired state: Ready
2022-04-04 10:08:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bc269fcf is in desired state: Ready
2022-04-04 10:08:06 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-bc269fcf-entity-operator-8c4f4d6f7-58tl9 will be deleted
2022-04-04 10:08:16 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-bc269fcf-entity-operator-8c4f4d6f7-58tl9 deleted
2022-04-04 10:08:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bc269fcf-entity-operator will be ready
2022-04-04 10:09:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bc269fcf-entity-operator is ready
2022-04-04 10:09:46 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-bc269fcf-entity-operator to be ready
2022-04-04 10:09:56 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-bc269fcf-entity-operator is ready
2022-04-04 10:09:56 [main] [32mINFO [m [PodUtils:201] Wait until Pod my-cluster-bc269fcf-entity-operator will have 2 containers
2022-04-04 10:09:56 [main] [32mINFO [m [PodUtils:205] Pod my-cluster-bc269fcf-entity-operator has 2 containers
2022-04-04 10:09:56 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-bc269fcf-entity-operator-574dc6f49d-jjkgk will be deleted
2022-04-04 10:10:06 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-bc269fcf-entity-operator-574dc6f49d-jjkgk deleted
2022-04-04 10:10:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bc269fcf-entity-operator will be ready
2022-04-04 10:10:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bc269fcf-entity-operator is ready
2022-04-04 10:10:52 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-bc269fcf-entity-operator to be ready
2022-04-04 10:11:02 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-bc269fcf-entity-operator is ready
2022-04-04 10:11:02 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 253 seconds
2022-04-04 10:11:02 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-04 10:11:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:11:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveUserOperatorFromEntityOperator
2022-04-04 10:11:02 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bc269fcf in namespace namespace-31
2022-04-04 10:11:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:11:12 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-31 for test case:testRemoveUserOperatorFromEntityOperator
2022-04-04 10:11:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserOperatorFromEntityOperator-FINISHED
2022-04-04 10:11:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:11:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:11:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testUOListeningOnlyUsersInSameCluster-STARTED
2022-04-04 10:11:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:11:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-32 for test case:testUOListeningOnlyUsersInSameCluster
2022-04-04 10:11:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-32
2022-04-04 10:11:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-32
2022-04-04 10:11:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-32
2022-04-04 10:11:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1 in namespace namespace-32
2022-04-04 10:11:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-32
2022-04-04 10:11:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1 will have desired state: Ready
2022-04-04 10:13:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1 is in desired state: Ready
2022-04-04 10:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2 in namespace namespace-32
2022-04-04 10:13:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-32
2022-04-04 10:13:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2 will have desired state: Ready
2022-04-04 10:14:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2 is in desired state: Ready
2022-04-04 10:14:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1634455730-597215221 in namespace namespace-32
2022-04-04 10:14:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-32
2022-04-04 10:14:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1634455730-597215221 will have desired state: Ready
2022-04-04 10:14:26 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1634455730-597215221 is in desired state: Ready
2022-04-04 10:14:26 [main] [32mINFO [m [KafkaST:1292] Verifying that user my-user-1634455730-597215221 in cluster my-cluster-1 is created
2022-04-04 10:14:26 [main] [32mINFO [m [KafkaST:1297] Verifying that user my-user-1634455730-597215221 in cluster my-cluster-2 is not created
2022-04-04 10:14:26 [main] [32mINFO [m [KafkaST:1302] Verifying that user belongs to my-cluster-1 cluster
2022-04-04 10:14:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:14:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUOListeningOnlyUsersInSameCluster
2022-04-04 10:14:26 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2 in namespace namespace-32
2022-04-04 10:14:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1634455730-597215221 in namespace namespace-32
2022-04-04 10:14:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1 in namespace namespace-32
2022-04-04 10:14:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:14:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-32 for test case:testUOListeningOnlyUsersInSameCluster
2022-04-04 10:15:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testUOListeningOnlyUsersInSameCluster-FINISHED
2022-04-04 10:15:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:15:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:15:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrueFalse-STARTED
2022-04-04 10:15:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:15:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-33 for test case:testKafkaJBODDeleteClaimsTrueFalse
2022-04-04 10:15:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-33
2022-04-04 10:15:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-33
2022-04-04 10:15:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-33
2022-04-04 10:15:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ff886695 in namespace namespace-33
2022-04-04 10:15:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-33
2022-04-04 10:15:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ff886695 will have desired state: Ready
2022-04-04 10:16:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ff886695 is in desired state: Ready
2022-04-04 10:16:36 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-ff886695-kafka-0
2022-04-04 10:16:36 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-ff886695-kafka-1
2022-04-04 10:16:36 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-ff886695-kafka-0
2022-04-04 10:16:36 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-ff886695-kafka-1
2022-04-04 10:16:36 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-04 10:16:36 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-04 10:16:36 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-04 10:16:36 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-04 10:16:36 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-04 10:16:36 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-04 10:16:36 [main] [32mINFO [m [KafkaST:882] Deleting cluster
2022-04-04 10:16:36 [main] [32mINFO [m [KafkaST:885] Waiting for PVC deletion
2022-04-04 10:17:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:17:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsTrueFalse
2022-04-04 10:17:11 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ff886695 in namespace namespace-33
2022-04-04 10:17:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:17:11 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-33 for test case:testKafkaJBODDeleteClaimsTrueFalse
2022-04-04 10:17:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrueFalse-FINISHED
2022-04-04 10:17:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:17:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:17:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testLabelsAndAnnotationForPVC-STARTED
2022-04-04 10:17:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:17:17 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-34 for test case:testLabelsAndAnnotationForPVC
2022-04-04 10:17:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-34
2022-04-04 10:17:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-34
2022-04-04 10:17:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-34
2022-04-04 10:17:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-876099d5 in namespace namespace-34
2022-04-04 10:17:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-34
2022-04-04 10:17:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-876099d5 will have desired state: Ready
2022-04-04 10:18:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-876099d5 is in desired state: Ready
2022-04-04 10:18:25 [main] [32mINFO [m [KafkaST:1510] Check if Kubernetes labels are applied
2022-04-04 10:18:25 [main] [32mINFO [m [KafkaST:1517] Kubernetes labels are correctly set and present
2022-04-04 10:18:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-876099d5-kafka-0 - testValue = testValue
2022-04-04 10:18:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-876099d5-kafka-1 - testValue = testValue
2022-04-04 10:18:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-876099d5-kafka-2 - testValue = testValue
2022-04-04 10:18:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-876099d5-kafka-0 - testValue = testValue
2022-04-04 10:18:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-876099d5-kafka-1 - testValue = testValue
2022-04-04 10:18:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-876099d5-kafka-2 - testValue = testValue
2022-04-04 10:18:25 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-my-cluster-876099d5-zookeeper-0 - testValue = testValue
2022-04-04 10:18:25 [main] [32mINFO [m [KafkaST:1535] Replacing kafka && zookeeper labels and annotations from testKey to editedTestValue
2022-04-04 10:18:25 [main] [32mINFO [m [PersistentVolumeClaimUtils:30] Wait until PVC labels will change {testKey=editedTestValue}
2022-04-04 10:18:28 [main] [32mINFO [m [PersistentVolumeClaimUtils:46] PVC labels has changed {testKey=editedTestValue}
2022-04-04 10:18:28 [main] [32mINFO [m [PersistentVolumeClaimUtils:50] Wait until PVC annotation will change {testKey=editedTestValue}
2022-04-04 10:18:28 [main] [32mINFO [m [PersistentVolumeClaimUtils:66] PVC annotation has changed {testKey=editedTestValue}
2022-04-04 10:18:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-876099d5 will have desired state: Ready
2022-04-04 10:18:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-876099d5 is in desired state: Ready
2022-04-04 10:18:29 [main] [32mINFO [m [KafkaST:1549] [PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:17:40Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-876099d5, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-876099d5, strimzi.io/cluster=my-cluster-876099d5, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-876099d5-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-876099d5-kafka-0, namespace=namespace-34, ownerReferences=[], resourceVersion=484858, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-0-my-cluster-876099d5-kafka-0, uid=eba3d8f9-4ef0-4f48-8e70-a0290f8507e8, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-eba3d8f9-4ef0-4f48-8e70-a0290f8507e8, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:17:40Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-876099d5, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-876099d5, strimzi.io/cluster=my-cluster-876099d5, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-876099d5-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-876099d5-kafka-1, namespace=namespace-34, ownerReferences=[], resourceVersion=484855, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-0-my-cluster-876099d5-kafka-1, uid=c188b51c-40fc-42b3-b632-64f50f61771f, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-c188b51c-40fc-42b3-b632-64f50f61771f, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:17:40Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-876099d5, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-876099d5, strimzi.io/cluster=my-cluster-876099d5, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-876099d5-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-876099d5-kafka-2, namespace=namespace-34, ownerReferences=[], resourceVersion=484861, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-0-my-cluster-876099d5-kafka-2, uid=63c1cce0-9ab2-4391-8b2b-4c82b06fa214, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-63c1cce0-9ab2-4391-8b2b-4c82b06fa214, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:17:40Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-876099d5, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-876099d5, strimzi.io/cluster=my-cluster-876099d5, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-876099d5-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-876099d5-kafka-0, namespace=namespace-34, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-876099d5, uid=51f246dd-dd90-4fcd-bd9e-d7bcbec72b0f, additionalProperties={})], resourceVersion=484860, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-1-my-cluster-876099d5-kafka-0, uid=f0a75045-1fc0-4ad9-9e47-0170f11fa136, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-f0a75045-1fc0-4ad9-9e47-0170f11fa136, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:17:40Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-876099d5, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-876099d5, strimzi.io/cluster=my-cluster-876099d5, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-876099d5-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-876099d5-kafka-1, namespace=namespace-34, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-876099d5, uid=51f246dd-dd90-4fcd-bd9e-d7bcbec72b0f, additionalProperties={})], resourceVersion=484863, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-1-my-cluster-876099d5-kafka-1, uid=ad767bf8-bfea-4ad4-ab05-fd298da88b36, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-ad767bf8-bfea-4ad4-ab05-fd298da88b36, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:17:40Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-876099d5, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-876099d5, strimzi.io/cluster=my-cluster-876099d5, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-876099d5-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-876099d5-kafka-2, namespace=namespace-34, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-876099d5, uid=51f246dd-dd90-4fcd-bd9e-d7bcbec72b0f, additionalProperties={})], resourceVersion=484862, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-1-my-cluster-876099d5-kafka-2, uid=7626a50d-7497-47d8-8511-12e437f0905a, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-7626a50d-7497-47d8-8511-12e437f0905a, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-04T10:17:20Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-876099d5, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-876099d5, strimzi.io/cluster=my-cluster-876099d5, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-876099d5-zookeeper, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-my-cluster-876099d5-zookeeper-0, namespace=namespace-34, ownerReferences=[], resourceVersion=484845, selfLink=/api/v1/namespaces/namespace-34/persistentvolumeclaims/data-my-cluster-876099d5-zookeeper-0, uid=6b301b0d-bfa9-4f62-9183-cc380eb05afa, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=3Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-6b301b0d-bfa9-4f62-9183-cc380eb05afa, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=3Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={})]
2022-04-04 10:18:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-876099d5-kafka-0 - testValue = editedTestValue
2022-04-04 10:18:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-876099d5-kafka-1 - testValue = editedTestValue
2022-04-04 10:18:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-876099d5-kafka-2 - testValue = editedTestValue
2022-04-04 10:18:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-876099d5-kafka-0 - testValue = editedTestValue
2022-04-04 10:18:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-876099d5-kafka-1 - testValue = editedTestValue
2022-04-04 10:18:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-876099d5-kafka-2 - testValue = editedTestValue
2022-04-04 10:18:29 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-my-cluster-876099d5-zookeeper-0 - testValue = editedTestValue
2022-04-04 10:18:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:18:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLabelsAndAnnotationForPVC
2022-04-04 10:18:29 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-876099d5 in namespace namespace-34
2022-04-04 10:18:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:18:39 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-34 for test case:testLabelsAndAnnotationForPVC
2022-04-04 10:19:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testLabelsAndAnnotationForPVC-FINISHED
2022-04-04 10:19:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:19:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:19:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testMessagesAreStoredInDisk-STARTED
2022-04-04 10:19:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:19:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-35 for test case:testMessagesAreStoredInDisk
2022-04-04 10:19:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-35
2022-04-04 10:19:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-35
2022-04-04 10:19:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-35
2022-04-04 10:19:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fdb3b399 in namespace namespace-35
2022-04-04 10:19:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-35
2022-04-04 10:19:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fdb3b399 will have desired state: Ready
2022-04-04 10:20:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fdb3b399 is in desired state: Ready
2022-04-04 10:20:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1281565826-2006588397 in namespace namespace-35
2022-04-04 10:20:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-35
2022-04-04 10:20:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1281565826-2006588397 will have desired state: Ready
2022-04-04 10:20:31 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1281565826-2006588397 is in desired state: Ready
2022-04-04 10:20:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fdb3b399-kafka-clients in namespace namespace-35
2022-04-04 10:20:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-35
2022-04-04 10:20:31 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fdb3b399-kafka-clients will be ready
2022-04-04 10:20:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fdb3b399-kafka-clients is ready
2022-04-04 10:20:33 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 10:20:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-fdb3b399-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0; ls -1
2022-04-04 10:20:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:20:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-fdb3b399-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0; ls -1 | sed -n '/my-topic-1281565826-2006588397/p'
2022-04-04 10:20:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:20:34 [main] [32mINFO [m [KafkaST:1344] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-1281565826-2006588397-0
/;cat 00000000000000000000.log in my-cluster-fdb3b399-kafka-0
2022-04-04 10:20:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-fdb3b399-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-1281565826-2006588397-0
/;cat 00000000000000000000.log
2022-04-04 10:20:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:20:34 [main] [32mINFO [m [KafkaST:1348] Topic my-topic-1281565826-2006588397 is present in kafka broker my-cluster-fdb3b399-kafka-0 with no data
2022-04-04 10:20:34 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3fb3ff86, messages=[], arguments=[--topic, my-topic-1281565826-2006588397, --max-messages, 100, --bootstrap-server, my-cluster-fdb3b399-kafka-bootstrap.namespace-35.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-fdb3b399-kafka-clients-69b5b4774f-6dhs8', podNamespace='namespace-35', bootstrapServer='my-cluster-fdb3b399-kafka-bootstrap.namespace-35.svc:9092', topicName='my-topic-1281565826-2006588397', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@130ca5a7}
2022-04-04 10:20:34 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-fdb3b399-kafka-bootstrap.namespace-35.svc:9092:my-topic-1281565826-2006588397 from pod my-cluster-fdb3b399-kafka-clients-69b5b4774f-6dhs8
2022-04-04 10:20:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fdb3b399-kafka-clients-69b5b4774f-6dhs8 -n namespace-35 -- /opt/kafka/producer.sh --topic my-topic-1281565826-2006588397 --max-messages 100 --bootstrap-server my-cluster-fdb3b399-kafka-bootstrap.namespace-35.svc:9092
2022-04-04 10:20:36 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 10:20:36 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 10:20:36 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@d078b7d, messages=[], arguments=[--topic, my-topic-1281565826-2006588397, --max-messages, 100, --group-instance-id, instance1861259972, --group-id, my-consumer-group-1958928715, --bootstrap-server, my-cluster-fdb3b399-kafka-bootstrap.namespace-35.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fdb3b399-kafka-clients-69b5b4774f-6dhs8', podNamespace='namespace-35', bootstrapServer='my-cluster-fdb3b399-kafka-bootstrap.namespace-35.svc:9092', topicName='my-topic-1281565826-2006588397', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1958928715', consumerInstanceId='instance1861259972', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@46176e92}
2022-04-04 10:20:36 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-fdb3b399-kafka-bootstrap.namespace-35.svc:9092#my-topic-1281565826-2006588397 from pod my-cluster-fdb3b399-kafka-clients-69b5b4774f-6dhs8
2022-04-04 10:20:36 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fdb3b399-kafka-clients-69b5b4774f-6dhs8 -n namespace-35 -- /opt/kafka/consumer.sh --topic my-topic-1281565826-2006588397 --max-messages 100 --group-instance-id instance1861259972 --group-id my-consumer-group-1958928715 --bootstrap-server my-cluster-fdb3b399-kafka-bootstrap.namespace-35.svc:9092
2022-04-04 10:20:42 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 10:20:42 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 10:20:42 [main] [32mINFO [m [KafkaST:1355] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-1281565826-2006588397-0
/;cat 00000000000000000000.log in my-cluster-fdb3b399-kafka-0
2022-04-04 10:20:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-fdb3b399-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-1281565826-2006588397-0
/;cat 00000000000000000000.log
2022-04-04 10:20:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:20:42 [main] [32mINFO [m [KafkaST:1364] Deleting kafka pod my-cluster-fdb3b399-kafka-0
2022-04-04 10:20:42 [main] [32mINFO [m [KafkaST:1364] Deleting kafka pod my-cluster-fdb3b399-kafka-clients-69b5b4774f-6dhs8
2022-04-04 10:20:42 [main] [32mINFO [m [KafkaST:1368] Wait for kafka to rolling restart ...
2022-04-04 10:20:42 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-fdb3b399-kafka rolling update
2022-04-04 10:20:52 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-fdb3b399-kafka has been successfully rolled
2022-04-04 10:20:52 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of my-cluster-fdb3b399-kafka to be ready
2022-04-04 10:21:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fdb3b399 will have desired state: Ready
2022-04-04 10:21:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fdb3b399 is in desired state: Ready
2022-04-04 10:21:19 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-fdb3b399 is ready
2022-04-04 10:21:19 [main] [32mINFO [m [KafkaST:1371] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-1281565826-2006588397-0
/;cat 00000000000000000000.log in my-cluster-fdb3b399-kafka-0
2022-04-04 10:21:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-fdb3b399-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-1281565826-2006588397-0
/;cat 00000000000000000000.log
2022-04-04 10:21:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:21:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:21:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMessagesAreStoredInDisk
2022-04-04 10:21:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1281565826-2006588397 in namespace namespace-35
2022-04-04 10:21:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fdb3b399 in namespace namespace-35
2022-04-04 10:21:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fdb3b399-kafka-clients in namespace namespace-35
2022-04-04 10:22:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:22:09 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-35 for test case:testMessagesAreStoredInDisk
2022-04-04 10:22:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testMessagesAreStoredInDisk-FINISHED
2022-04-04 10:22:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:22:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:22:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-STARTED
2022-04-04 10:22:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:22:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-36 for test case:testLabelModificationDoesNotBreakCluster
2022-04-04 10:22:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-36
2022-04-04 10:22:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-36
2022-04-04 10:22:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-36
2022-04-04 10:22:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fc48cb0c in namespace namespace-36
2022-04-04 10:22:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-36
2022-04-04 10:22:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fc48cb0c will have desired state: Ready
2022-04-04 10:23:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fc48cb0c is in desired state: Ready
2022-04-04 10:23:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-797880612-2057492325 in namespace namespace-36
2022-04-04 10:23:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-36
2022-04-04 10:23:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-797880612-2057492325 will have desired state: Ready
2022-04-04 10:23:35 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-797880612-2057492325 is in desired state: Ready
2022-04-04 10:23:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fc48cb0c-kafka-clients in namespace namespace-36
2022-04-04 10:23:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-36
2022-04-04 10:23:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fc48cb0c-kafka-clients will be ready
2022-04-04 10:23:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fc48cb0c-kafka-clients is ready
2022-04-04 10:23:37 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 10:23:37 [main] [32mINFO [m [KafkaST:1078] Waiting for kafka stateful set labels changed {label-name-1=name-of-the-label-1, label-name-2=name-of-the-label-2}
2022-04-04 10:23:37 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> name-of-the-label-1
2022-04-04 10:23:37 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> name-of-the-label-2
2022-04-04 10:23:37 [main] [32mINFO [m [KafkaST:1081] Getting labels from stateful set resource
2022-04-04 10:23:37 [main] [32mINFO [m [KafkaST:1084] Verifying default labels in the Kafka CR
2022-04-04 10:23:37 [main] [32mINFO [m [KafkaST:1095] Setting new values of labels from name-of-the-label-1 to new-name-of-the-label-1 | from name-of-the-label-2 to new-name-of-the-label-2 and adding one label-name-3 with value name-of-the-label-3
2022-04-04 10:23:37 [main] [32mINFO [m [KafkaST:1098] Edit kafka labels in Kafka CR
2022-04-04 10:23:37 [main] [32mINFO [m [KafkaST:1109] Waiting for kafka service labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-04 10:23:37 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-1 -> new-name-of-the-label-1
2022-04-04 10:24:14 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-2 -> new-name-of-the-label-2
2022-04-04 10:24:14 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-3 -> name-of-the-label-3
2022-04-04 10:24:14 [main] [32mINFO [m [KafkaST:1112] Verifying kafka labels via services
2022-04-04 10:24:14 [main] [32mINFO [m [KafkaST:1118] Waiting for Kafka ConfigMap my-cluster-fc48cb0c-kafka-config in namespace namespace-36 to have new labels: {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-04 10:24:14 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-fc48cb0c-kafka-config label change label-name-1 -> new-name-of-the-label-1
2022-04-04 10:24:14 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-fc48cb0c-kafka-config label change label-name-2 -> new-name-of-the-label-2
2022-04-04 10:24:14 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-fc48cb0c-kafka-config label change label-name-3 -> name-of-the-label-3
2022-04-04 10:24:14 [main] [32mINFO [m [KafkaST:1121] Verifying Kafka labels on ConfigMap my-cluster-fc48cb0c-kafka-config in namespace namespace-36
2022-04-04 10:24:14 [main] [32mINFO [m [KafkaST:1127] Waiting for kafka stateful set labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-04 10:24:14 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> new-name-of-the-label-1
2022-04-04 10:24:14 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> new-name-of-the-label-2
2022-04-04 10:24:14 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-3 -> name-of-the-label-3
2022-04-04 10:24:14 [main] [32mINFO [m [KafkaST:1130] Verifying kafka labels via stateful set
2022-04-04 10:24:14 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-fc48cb0c-kafka rolling update
2022-04-04 10:25:29 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-fc48cb0c-kafka has been successfully rolled
2022-04-04 10:25:29 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-fc48cb0c-kafka to be ready
2022-04-04 10:25:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fc48cb0c will have desired state: Ready
2022-04-04 10:25:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fc48cb0c is in desired state: Ready
2022-04-04 10:25:55 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-fc48cb0c is ready
2022-04-04 10:25:55 [main] [32mINFO [m [KafkaST:1136] Verifying via kafka pods
2022-04-04 10:25:55 [main] [32mINFO [m [KafkaST:1143] Removing labels: label-name-1 -> new-name-of-the-label-1, label-name-2 -> new-name-of-the-label-2, label-name-3 -> name-of-the-label-3
2022-04-04 10:25:55 [main] [32mINFO [m [KafkaST:1155] Waiting for kafka service labels deletion {app.kubernetes.io/instance=my-cluster-fc48cb0c, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-fc48cb0c, controller-revision-hash=my-cluster-fc48cb0c-kafka-5cc64dd6b, statefulset.kubernetes.io/pod-name=my-cluster-fc48cb0c-kafka-0, strimzi.io/cluster=my-cluster-fc48cb0c, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-fc48cb0c-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-04 10:25:55 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-1 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-2 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-3 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [KafkaST:1158] Verifying kafka labels via services
2022-04-04 10:27:11 [main] [32mINFO [m [KafkaST:1164] Waiting for Kafka ConfigMap my-cluster-fc48cb0c-kafka-config in namespace namespace-36 to have labels removed: [label-name-1, label-name-2, label-name-3]
2022-04-04 10:27:11 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-fc48cb0c-kafka-config label label-name-1 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-fc48cb0c-kafka-config label label-name-1 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-fc48cb0c-kafka-config label label-name-2 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-fc48cb0c-kafka-config label label-name-2 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-fc48cb0c-kafka-config label label-name-3 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-fc48cb0c-kafka-config label label-name-3 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [KafkaST:1167] Verifying Kafka labels on ConfigMap my-cluster-fc48cb0c-kafka-config in namespace namespace-36
2022-04-04 10:27:11 [main] [32mINFO [m [KafkaST:1173] Waiting for kafka stateful set labels changed {app.kubernetes.io/instance=my-cluster-fc48cb0c, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-fc48cb0c, controller-revision-hash=my-cluster-fc48cb0c-kafka-5cc64dd6b, statefulset.kubernetes.io/pod-name=my-cluster-fc48cb0c-kafka-0, strimzi.io/cluster=my-cluster-fc48cb0c, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-fc48cb0c-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-04 10:27:11 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-1 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-1 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-2 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-2 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-3 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-3 change to null
2022-04-04 10:27:11 [main] [32mINFO [m [KafkaST:1176] Verifying kafka labels via stateful set
2022-04-04 10:27:11 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-fc48cb0c-kafka rolling update
2022-04-04 10:27:11 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-fc48cb0c-kafka has been successfully rolled
2022-04-04 10:27:11 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-fc48cb0c-kafka to be ready
2022-04-04 10:28:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fc48cb0c will have desired state: Ready
2022-04-04 10:28:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fc48cb0c is in desired state: Ready
2022-04-04 10:28:56 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-fc48cb0c is ready
2022-04-04 10:28:56 [main] [32mINFO [m [KafkaST:1181] Waiting for kafka pod labels deletion {app.kubernetes.io/instance=my-cluster-fc48cb0c, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-fc48cb0c, controller-revision-hash=my-cluster-fc48cb0c-kafka-5cc64dd6b, statefulset.kubernetes.io/pod-name=my-cluster-fc48cb0c-kafka-0, strimzi.io/cluster=my-cluster-fc48cb0c, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-fc48cb0c-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-04 10:28:56 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-1 change to null
2022-04-04 10:28:56 [main] [32mINFO [m [PodUtils:267] Pod label label-name-1 changed to null
2022-04-04 10:28:56 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-2 change to null
2022-04-04 10:28:56 [main] [32mINFO [m [PodUtils:267] Pod label label-name-2 changed to null
2022-04-04 10:28:56 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-3 change to null
2022-04-04 10:28:56 [main] [32mINFO [m [PodUtils:267] Pod label label-name-3 changed to null
2022-04-04 10:28:56 [main] [32mINFO [m [KafkaST:1186] Verifying via kafka pods
2022-04-04 10:28:56 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@22b6ba19, messages=[], arguments=[--topic, my-topic-797880612-2057492325, --max-messages, 100, --bootstrap-server, my-cluster-fc48cb0c-kafka-bootstrap.namespace-36.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-fc48cb0c-kafka-clients-6595f65b79-v4xfc', podNamespace='namespace-36', bootstrapServer='my-cluster-fc48cb0c-kafka-bootstrap.namespace-36.svc:9092', topicName='my-topic-797880612-2057492325', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2f2362b9}
2022-04-04 10:28:56 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-fc48cb0c-kafka-bootstrap.namespace-36.svc:9092:my-topic-797880612-2057492325 from pod my-cluster-fc48cb0c-kafka-clients-6595f65b79-v4xfc
2022-04-04 10:28:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fc48cb0c-kafka-clients-6595f65b79-v4xfc -n namespace-36 -- /opt/kafka/producer.sh --topic my-topic-797880612-2057492325 --max-messages 100 --bootstrap-server my-cluster-fc48cb0c-kafka-bootstrap.namespace-36.svc:9092
2022-04-04 10:28:58 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 10:28:58 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 10:28:58 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@70fba437, messages=[], arguments=[--topic, my-topic-797880612-2057492325, --max-messages, 100, --group-instance-id, instance822911035, --group-id, my-consumer-group-1950389618, --bootstrap-server, my-cluster-fc48cb0c-kafka-bootstrap.namespace-36.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-fc48cb0c-kafka-clients-6595f65b79-v4xfc', podNamespace='namespace-36', bootstrapServer='my-cluster-fc48cb0c-kafka-bootstrap.namespace-36.svc:9092', topicName='my-topic-797880612-2057492325', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1950389618', consumerInstanceId='instance822911035', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@44f930bb}
2022-04-04 10:28:58 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-fc48cb0c-kafka-bootstrap.namespace-36.svc:9092#my-topic-797880612-2057492325 from pod my-cluster-fc48cb0c-kafka-clients-6595f65b79-v4xfc
2022-04-04 10:28:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-fc48cb0c-kafka-clients-6595f65b79-v4xfc -n namespace-36 -- /opt/kafka/consumer.sh --topic my-topic-797880612-2057492325 --max-messages 100 --group-instance-id instance822911035 --group-id my-consumer-group-1950389618 --bootstrap-server my-cluster-fc48cb0c-kafka-bootstrap.namespace-36.svc:9092
2022-04-04 10:29:04 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 10:29:04 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 10:29:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:29:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLabelModificationDoesNotBreakCluster
2022-04-04 10:29:04 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-797880612-2057492325 in namespace namespace-36
2022-04-04 10:29:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fc48cb0c in namespace namespace-36
2022-04-04 10:29:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fc48cb0c-kafka-clients in namespace namespace-36
2022-04-04 10:29:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:29:54 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-36 for test case:testLabelModificationDoesNotBreakCluster
2022-04-04 10:30:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-FINISHED
2022-04-04 10:30:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:30:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:30:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEODeletion-STARTED
2022-04-04 10:30:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:30:01 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-37 for test case:testEODeletion
2022-04-04 10:30:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-37
2022-04-04 10:30:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-37
2022-04-04 10:30:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-37
2022-04-04 10:30:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-de421144 in namespace namespace-37
2022-04-04 10:30:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-37
2022-04-04 10:30:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-de421144 will have desired state: Ready
2022-04-04 10:31:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-de421144 is in desired state: Ready
2022-04-04 10:31:22 [main] [32mINFO [m [KafkaST:122] Setting entity operator to null
2022-04-04 10:31:22 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-de421144-entity-operator is not deleted yet! Triggering force delete by cmd client!
2022-04-04 10:31:27 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-de421144-entity-operator is not deleted yet! Triggering force delete by cmd client!
2022-04-04 10:31:33 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-de421144-entity-operator-79f79d895c-6vvl5 will be deleted
2022-04-04 10:31:38 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-de421144-entity-operator-79f79d895c-6vvl5 deleted
2022-04-04 10:31:38 [main] [32mINFO [m [KafkaST:130] Entity operator was deleted
2022-04-04 10:31:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:31:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEODeletion
2022-04-04 10:31:38 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-de421144 in namespace namespace-37
2022-04-04 10:31:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:31:48 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-37 for test case:testEODeletion
2022-04-04 10:32:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEODeletion-FINISHED
2022-04-04 10:32:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:32:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:32:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testJvmAndResources-STARTED
2022-04-04 10:32:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:32:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-38 for test case:testJvmAndResources
2022-04-04 10:32:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-38
2022-04-04 10:32:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-38
2022-04-04 10:32:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-38
2022-04-04 10:32:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d42edc23 in namespace namespace-38
2022-04-04 10:32:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-38
2022-04-04 10:32:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d42edc23 will have desired state: Ready
2022-04-04 10:33:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d42edc23 is in desired state: Ready
2022-04-04 10:33:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-38 exec my-cluster-d42edc23-kafka-0 -c kafka -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-04 10:33:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:33:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-38 exec my-cluster-d42edc23-zookeeper-0 -c zookeeper -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-04 10:33:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:33:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-38 exec my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w -c topic-operator -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-04 10:33:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:33:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-38 exec my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w -c user-operator -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-04 10:33:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:33:46 [main] [32mINFO [m [KafkaST:533] Check if -D java options are present in topic-operator
2022-04-04 10:33:46 [main] [32mINFO [m [KafkaST:533] Check if -D java options are present in user-operator
2022-04-04 10:33:46 [main] [32mINFO [m [KafkaST:552] Checking no rolling update for Kafka cluster
2022-04-04 10:33:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 10:33:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 10:33:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 10:33:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 10:33:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 10:33:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 10:33:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 10:33:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 10:33:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 10:33:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 10:33:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 10:33:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 10:33:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 10:33:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 10:34:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 10:34:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 10:34:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 10:34:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 10:34:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 10:34:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 10:34:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 10:34:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 10:34:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 10:34:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 10:34:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 10:34:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 10:34:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 10:34:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 10:34:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 10:34:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 10:34:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 10:34:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 10:34:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 10:34:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 10:34:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 10:34:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 10:34:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 10:34:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 10:34:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 10:34:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 10:34:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 10:34:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 10:34:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 10:34:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 10:34:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 10:34:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 10:34:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 10:34:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 10:34:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 10:34:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 10:34:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-zookeeper-0=7fddc932-d4f6-4dff-b232-516f8d98f735} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 10:34:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 10:34:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 10:34:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 10:34:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 10:34:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 10:34:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 10:34:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 10:34:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 10:34:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 10:34:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 10:34:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 10:34:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 10:34:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 10:34:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 10:34:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 10:34:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 10:34:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 10:34:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 10:34:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 10:34:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 10:34:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 10:34:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 10:34:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 10:34:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 10:35:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 10:35:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 10:35:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 10:35:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 10:35:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 10:35:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 10:35:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 10:35:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 10:35:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 10:35:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 10:35:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 10:35:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 10:35:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 10:35:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 10:35:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 10:35:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 10:35:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 10:35:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 10:35:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 10:35:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 10:35:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 10:35:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 10:35:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 10:35:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 10:35:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 10:35:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 10:35:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d42edc23-kafka-0=18ba8afc-7007-45fd-aa60-7b657ac6e3d9} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 10:35:26 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 50
2022-04-04 10:35:27 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 49
2022-04-04 10:35:28 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 48
2022-04-04 10:35:29 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 47
2022-04-04 10:35:30 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 46
2022-04-04 10:35:31 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 45
2022-04-04 10:35:32 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 44
2022-04-04 10:35:33 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 43
2022-04-04 10:35:34 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 42
2022-04-04 10:35:35 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 41
2022-04-04 10:35:36 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 40
2022-04-04 10:35:37 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 39
2022-04-04 10:35:38 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 38
2022-04-04 10:35:39 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 37
2022-04-04 10:35:40 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 36
2022-04-04 10:35:41 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 35
2022-04-04 10:35:42 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 34
2022-04-04 10:35:43 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 33
2022-04-04 10:35:44 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 32
2022-04-04 10:35:45 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 31
2022-04-04 10:35:46 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 30
2022-04-04 10:35:47 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 29
2022-04-04 10:35:48 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 28
2022-04-04 10:35:49 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 27
2022-04-04 10:35:50 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 26
2022-04-04 10:35:51 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 25
2022-04-04 10:35:52 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 24
2022-04-04 10:35:53 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 23
2022-04-04 10:35:54 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 22
2022-04-04 10:35:55 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 21
2022-04-04 10:35:56 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 20
2022-04-04 10:35:57 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 19
2022-04-04 10:35:58 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 18
2022-04-04 10:35:59 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 17
2022-04-04 10:36:00 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 16
2022-04-04 10:36:01 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 15
2022-04-04 10:36:02 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 14
2022-04-04 10:36:03 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 13
2022-04-04 10:36:04 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 12
2022-04-04 10:36:05 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 11
2022-04-04 10:36:06 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 10
2022-04-04 10:36:07 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 9
2022-04-04 10:36:08 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 8
2022-04-04 10:36:09 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 7
2022-04-04 10:36:10 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 6
2022-04-04 10:36:11 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 5
2022-04-04 10:36:12 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 4
2022-04-04 10:36:13 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 3
2022-04-04 10:36:14 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 2
2022-04-04 10:36:15 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 1
2022-04-04 10:36:16 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-d42edc23-entity-operator-6876845d7b-wpx6w=34b9e946-82f5-4ef5-97a4-c1b373bb405c} pods not rolling waiting, remaining seconds for stability 0
2022-04-04 10:36:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:36:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJvmAndResources
2022-04-04 10:36:16 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d42edc23 in namespace namespace-38
2022-04-04 10:36:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:36:26 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-38 for test case:testJvmAndResources
2022-04-04 10:36:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testJvmAndResources-FINISHED
2022-04-04 10:36:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:36:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:36:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testPersistentStorageSize-STARTED
2022-04-04 10:36:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:36:32 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-39 for test case:testPersistentStorageSize
2022-04-04 10:36:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-39
2022-04-04 10:36:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-39
2022-04-04 10:36:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-39
2022-04-04 10:36:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8c0d10a3 in namespace namespace-39
2022-04-04 10:36:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-04 10:36:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8c0d10a3 will have desired state: Ready
2022-04-04 10:37:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8c0d10a3 is in desired state: Ready
2022-04-04 10:37:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-26875822-331572901 in namespace namespace-39
2022-04-04 10:37:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-04 10:37:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-26875822-331572901 will have desired state: Ready
2022-04-04 10:37:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-26875822-331572901 is in desired state: Ready
2022-04-04 10:37:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8c0d10a3-kafka-clients in namespace namespace-39
2022-04-04 10:37:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-04 10:37:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8c0d10a3-kafka-clients will be ready
2022-04-04 10:37:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8c0d10a3-kafka-clients is ready
2022-04-04 10:37:45 [main] [32mINFO [m [KafkaST:1694] Checking volume data-0-my-cluster-8c0d10a3-kafka-0 and size of storage 70Gi
2022-04-04 10:37:45 [main] [32mINFO [m [KafkaST:1694] Checking volume data-0-my-cluster-8c0d10a3-kafka-1 and size of storage 70Gi
2022-04-04 10:37:45 [main] [32mINFO [m [KafkaST:1694] Checking volume data-1-my-cluster-8c0d10a3-kafka-0 and size of storage 20Gi
2022-04-04 10:37:45 [main] [32mINFO [m [KafkaST:1694] Checking volume data-1-my-cluster-8c0d10a3-kafka-1 and size of storage 20Gi
2022-04-04 10:37:45 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 10:37:45 [main] [32mINFO [m [KafkaST:983] Checking produced and consumed messages to pod:my-cluster-8c0d10a3-kafka-clients-85cbfd98c7-7kp6s
2022-04-04 10:37:45 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@388aedda, messages=[], arguments=[--topic, my-topic-26875822-331572901, --max-messages, 100, --bootstrap-server, my-cluster-8c0d10a3-kafka-bootstrap.namespace-39.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-8c0d10a3-kafka-clients-85cbfd98c7-7kp6s', podNamespace='namespace-39', bootstrapServer='my-cluster-8c0d10a3-kafka-bootstrap.namespace-39.svc:9092', topicName='my-topic-26875822-331572901', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@481b13f}
2022-04-04 10:37:45 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-8c0d10a3-kafka-bootstrap.namespace-39.svc:9092:my-topic-26875822-331572901 from pod my-cluster-8c0d10a3-kafka-clients-85cbfd98c7-7kp6s
2022-04-04 10:37:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8c0d10a3-kafka-clients-85cbfd98c7-7kp6s -n namespace-39 -- /opt/kafka/producer.sh --topic my-topic-26875822-331572901 --max-messages 100 --bootstrap-server my-cluster-8c0d10a3-kafka-bootstrap.namespace-39.svc:9092
2022-04-04 10:37:48 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 10:37:48 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 10:37:48 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2abc21b, messages=[], arguments=[--topic, my-topic-26875822-331572901, --max-messages, 100, --group-instance-id, instance1194359704, --group-id, my-consumer-group-947004365, --bootstrap-server, my-cluster-8c0d10a3-kafka-bootstrap.namespace-39.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8c0d10a3-kafka-clients-85cbfd98c7-7kp6s', podNamespace='namespace-39', bootstrapServer='my-cluster-8c0d10a3-kafka-bootstrap.namespace-39.svc:9092', topicName='my-topic-26875822-331572901', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-947004365', consumerInstanceId='instance1194359704', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@baa9218}
2022-04-04 10:37:48 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-8c0d10a3-kafka-bootstrap.namespace-39.svc:9092#my-topic-26875822-331572901 from pod my-cluster-8c0d10a3-kafka-clients-85cbfd98c7-7kp6s
2022-04-04 10:37:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8c0d10a3-kafka-clients-85cbfd98c7-7kp6s -n namespace-39 -- /opt/kafka/consumer.sh --topic my-topic-26875822-331572901 --max-messages 100 --group-instance-id instance1194359704 --group-id my-consumer-group-947004365 --bootstrap-server my-cluster-8c0d10a3-kafka-bootstrap.namespace-39.svc:9092
2022-04-04 10:37:54 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 10:37:54 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 10:37:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:37:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPersistentStorageSize
2022-04-04 10:37:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-26875822-331572901 in namespace namespace-39
2022-04-04 10:37:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8c0d10a3 in namespace namespace-39
2022-04-04 10:37:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8c0d10a3-kafka-clients in namespace namespace-39
2022-04-04 10:38:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:38:44 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-39 for test case:testPersistentStorageSize
2022-04-04 10:38:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testPersistentStorageSize-FINISHED
2022-04-04 10:38:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:38:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:38:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testForTopicOperator-STARTED
2022-04-04 10:38:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:38:49 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-40 for test case:testForTopicOperator
2022-04-04 10:38:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-40
2022-04-04 10:38:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-40
2022-04-04 10:38:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-40
2022-04-04 10:38:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1211340a in namespace namespace-40
2022-04-04 10:38:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-40
2022-04-04 10:38:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1211340a will have desired state: Ready
2022-04-04 10:40:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1211340a is in desired state: Ready
2022-04-04 10:40:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-928489931-1975698436 in namespace namespace-40
2022-04-04 10:40:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-40
2022-04-04 10:40:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-928489931-1975698436 will have desired state: Ready
2022-04-04 10:40:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-928489931-1975698436 is in desired state: Ready
2022-04-04 10:40:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-928489931-1975698436 will have desired state: Ready
2022-04-04 10:40:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-928489931-1975698436 is in desired state: Ready
2022-04-04 10:40:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-1211340a-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 10:40:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:40:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-1211340a-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --create  --topic topic-from-cli --replication-factor 1 --partitions 1
2022-04-04 10:40:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:40:12 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic topic-from-cli creation 
2022-04-04 10:42:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-1211340a-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 10:42:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:42:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-1211340a-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic-928489931-1975698436 --partitions 2
2022-04-04 10:42:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:42:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1211340a will have desired state: Ready
2022-04-04 10:42:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1211340a is in desired state: Ready
2022-04-04 10:42:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-1211340a-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-topic-928489931-1975698436
2022-04-04 10:42:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:42:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1211340a will have desired state: Ready
2022-04-04 10:42:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1211340a is in desired state: Ready
2022-04-04 10:42:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-1211340a-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic-from-cli
2022-04-04 10:42:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:42:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-1211340a-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic my-topic-928489931-1975698436
2022-04-04 10:42:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:42:12 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-928489931-1975698436 deletion
2022-04-04 10:42:12 [main] [33mWARN [m [KafkaTopicUtils:110] KafkaTopic my-topic-928489931-1975698436 is not deleted yet! Triggering force delete by cmd client!
2022-04-04 10:42:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-40 exec my-cluster-1211340a-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 10:42:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:42:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:42:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testForTopicOperator
2022-04-04 10:42:26 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-928489931-1975698436 in namespace namespace-40
2022-04-04 10:42:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1211340a in namespace namespace-40
2022-04-04 10:42:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:42:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-40 for test case:testForTopicOperator
2022-04-04 10:43:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testForTopicOperator-FINISHED
2022-04-04 10:43:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:43:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:43:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testReadOnlyRootFileSystem-STARTED
2022-04-04 10:43:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:43:19 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-41 for test case:testReadOnlyRootFileSystem
2022-04-04 10:43:19 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-41
2022-04-04 10:43:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-41
2022-04-04 10:43:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-41
2022-04-04 10:43:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1b6feafe in namespace namespace-41
2022-04-04 10:43:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-41
2022-04-04 10:43:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1b6feafe will have desired state: Ready
2022-04-04 10:45:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1b6feafe is in desired state: Ready
2022-04-04 10:45:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1b6feafe will have desired state: Ready
2022-04-04 10:45:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1b6feafe is in desired state: Ready
2022-04-04 10:45:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-215237347-1910189262 in namespace namespace-41
2022-04-04 10:45:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-41
2022-04-04 10:45:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-215237347-1910189262 will have desired state: Ready
2022-04-04 10:45:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-215237347-1910189262 is in desired state: Ready
2022-04-04 10:45:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1b6feafe-kafka-clients in namespace namespace-41
2022-04-04 10:45:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-41
2022-04-04 10:45:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1b6feafe-kafka-clients will be ready
2022-04-04 10:45:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1b6feafe-kafka-clients is ready
2022-04-04 10:45:46 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 10:45:46 [main] [32mINFO [m [KafkaST:1652] Checking produced and consumed messages to pod:my-cluster-1b6feafe-kafka-clients-dc678d655-6664v
2022-04-04 10:45:46 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@99727e9, messages=[], arguments=[--topic, my-topic-215237347-1910189262, --max-messages, 100, --bootstrap-server, my-cluster-1b6feafe-kafka-bootstrap.namespace-41.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1b6feafe-kafka-clients-dc678d655-6664v', podNamespace='namespace-41', bootstrapServer='my-cluster-1b6feafe-kafka-bootstrap.namespace-41.svc:9092', topicName='my-topic-215237347-1910189262', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7a1ad4e7}
2022-04-04 10:45:46 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-1b6feafe-kafka-bootstrap.namespace-41.svc:9092:my-topic-215237347-1910189262 from pod my-cluster-1b6feafe-kafka-clients-dc678d655-6664v
2022-04-04 10:45:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1b6feafe-kafka-clients-dc678d655-6664v -n namespace-41 -- /opt/kafka/producer.sh --topic my-topic-215237347-1910189262 --max-messages 100 --bootstrap-server my-cluster-1b6feafe-kafka-bootstrap.namespace-41.svc:9092
2022-04-04 10:45:49 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 10:45:49 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 10:45:49 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4c4e395e, messages=[], arguments=[--topic, my-topic-215237347-1910189262, --max-messages, 100, --group-instance-id, instance1384111006, --group-id, my-consumer-group-1426663740, --bootstrap-server, my-cluster-1b6feafe-kafka-bootstrap.namespace-41.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1b6feafe-kafka-clients-dc678d655-6664v', podNamespace='namespace-41', bootstrapServer='my-cluster-1b6feafe-kafka-bootstrap.namespace-41.svc:9092', topicName='my-topic-215237347-1910189262', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1426663740', consumerInstanceId='instance1384111006', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@605f745e}
2022-04-04 10:45:49 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-1b6feafe-kafka-bootstrap.namespace-41.svc:9092#my-topic-215237347-1910189262 from pod my-cluster-1b6feafe-kafka-clients-dc678d655-6664v
2022-04-04 10:45:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1b6feafe-kafka-clients-dc678d655-6664v -n namespace-41 -- /opt/kafka/consumer.sh --topic my-topic-215237347-1910189262 --max-messages 100 --group-instance-id instance1384111006 --group-id my-consumer-group-1426663740 --bootstrap-server my-cluster-1b6feafe-kafka-bootstrap.namespace-41.svc:9092
2022-04-04 10:45:55 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 10:45:55 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 10:45:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:45:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReadOnlyRootFileSystem
2022-04-04 10:45:55 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-215237347-1910189262 in namespace namespace-41
2022-04-04 10:45:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1b6feafe in namespace namespace-41
2022-04-04 10:45:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-41, for cruise control Kafka cluster my-cluster-1b6feafe
2022-04-04 10:45:55 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1b6feafe-kafka-clients in namespace namespace-41
2022-04-04 10:46:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:46:45 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-41 for test case:testReadOnlyRootFileSystem
2022-04-04 10:46:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testReadOnlyRootFileSystem-FINISHED
2022-04-04 10:46:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:46:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:46:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testCustomAndUpdatedValues-STARTED
2022-04-04 10:46:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:46:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-42 for test case:testCustomAndUpdatedValues
2022-04-04 10:46:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-42
2022-04-04 10:46:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-42
2022-04-04 10:46:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-42
2022-04-04 10:46:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-72da41db in namespace namespace-42
2022-04-04 10:46:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-42
2022-04-04 10:46:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-72da41db will have desired state: Ready
2022-04-04 10:49:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-72da41db is in desired state: Ready
2022-04-04 10:49:00 [main] [32mINFO [m [KafkaST:290] Verify values before update
2022-04-04 10:49:00 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-72da41db-kafka in pod name
2022-04-04 10:49:00 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container kafka
2022-04-04 10:49:00 [main] [32mINFO [m [KafkaST:1661] Checking kafka configuration
2022-04-04 10:49:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-72da41db-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-04 10:49:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:49:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-72da41db-kafka-1 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-04 10:49:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:49:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-72da41db-kafka-2 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-04 10:49:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:49:00 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-72da41db-kafka
2022-04-04 10:49:00 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container kafka
2022-04-04 10:49:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-72da41db-kafka-0 -- cat /tmp/strimzi.properties
2022-04-04 10:49:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:49:01 [main] [32mINFO [m [KafkaST:308] Testing Zookeepers
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-72da41db-zookeeper in pod name
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container zookeeper
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-72da41db-zookeeper
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:194] Testing configuration for container zookeeper
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-72da41db-zookeeper
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container zookeeper
2022-04-04 10:49:01 [main] [32mINFO [m [KafkaST:315] Checking configuration of TO and UO
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-72da41db-entity-operator in pod name
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container topic-operator
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-72da41db-entity-operator
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container topic-operator
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-72da41db-entity-operator in pod name
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container user-operator
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-72da41db-entity-operator
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container user-operator
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-72da41db-entity-operator in pod name
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container tls-sidecar
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-72da41db-entity-operator
2022-04-04 10:49:01 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container tls-sidecar
2022-04-04 10:49:01 [main] [32mINFO [m [KafkaST:326] Updating configuration of Kafka cluster
2022-04-04 10:49:01 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-72da41db-zookeeper rolling update
2022-04-04 10:50:21 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-72da41db-zookeeper has been successfully rolled
2022-04-04 10:50:21 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-72da41db-zookeeper to be ready
2022-04-04 10:51:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-72da41db will have desired state: Ready
2022-04-04 10:51:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-72da41db is in desired state: Ready
2022-04-04 10:51:05 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-72da41db is ready
2022-04-04 10:51:05 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-72da41db-kafka rolling update
2022-04-04 10:52:30 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-72da41db-kafka has been successfully rolled
2022-04-04 10:52:30 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-72da41db-kafka to be ready
2022-04-04 10:53:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-72da41db will have desired state: Ready
2022-04-04 10:53:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-72da41db is in desired state: Ready
2022-04-04 10:53:08 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-72da41db is ready
2022-04-04 10:53:08 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-72da41db-entity-operator rolling update
2022-04-04 10:53:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-72da41db-entity-operator will be ready
2022-04-04 10:55:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-72da41db-entity-operator is ready
2022-04-04 10:56:08 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-72da41db-entity-operator rolling update finished
2022-04-04 10:56:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-72da41db will have desired state: Ready
2022-04-04 10:56:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-72da41db is in desired state: Ready
2022-04-04 10:56:08 [main] [32mINFO [m [KafkaST:386] Verify values after update
2022-04-04 10:56:08 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-72da41db-kafka in pod name
2022-04-04 10:56:08 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container kafka
2022-04-04 10:56:08 [main] [32mINFO [m [KafkaST:1661] Checking kafka configuration
2022-04-04 10:56:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-72da41db-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-04 10:56:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:56:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-72da41db-kafka-1 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-04 10:56:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:56:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-72da41db-kafka-2 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-04 10:56:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-72da41db-kafka
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container kafka
2022-04-04 10:56:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-42 exec my-cluster-72da41db-kafka-0 -- cat /tmp/strimzi.properties
2022-04-04 10:56:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 10:56:09 [main] [32mINFO [m [KafkaST:404] Testing Zookeepers
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-72da41db-zookeeper in pod name
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container zookeeper
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-72da41db-zookeeper
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:194] Testing configuration for container zookeeper
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-72da41db-zookeeper
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container zookeeper
2022-04-04 10:56:09 [main] [32mINFO [m [KafkaST:410] Getting entity operator to check configuration of TO and UO
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-72da41db-entity-operator in pod name
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container topic-operator
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-72da41db-entity-operator
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container topic-operator
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-72da41db-entity-operator in pod name
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container user-operator
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-72da41db-entity-operator
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container user-operator
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-72da41db-entity-operator in pod name
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container tls-sidecar
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-72da41db-entity-operator
2022-04-04 10:56:09 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container tls-sidecar
2022-04-04 10:56:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:56:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-04 10:56:09 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-72da41db in namespace namespace-42
2022-04-04 10:56:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:56:19 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-42 for test case:testCustomAndUpdatedValues
2022-04-04 10:57:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testCustomAndUpdatedValues-FINISHED
2022-04-04 10:57:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:57:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:57:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrue-STARTED
2022-04-04 10:57:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:57:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-43 for test case:testKafkaJBODDeleteClaimsTrue
2022-04-04 10:57:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-43
2022-04-04 10:57:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-43
2022-04-04 10:57:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-43
2022-04-04 10:57:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6081ae43 in namespace namespace-43
2022-04-04 10:57:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-43
2022-04-04 10:57:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6081ae43 will have desired state: Ready
2022-04-04 10:58:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6081ae43 is in desired state: Ready
2022-04-04 10:58:51 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-6081ae43-kafka-0
2022-04-04 10:58:51 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-6081ae43-kafka-1
2022-04-04 10:58:51 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-6081ae43-kafka-0
2022-04-04 10:58:51 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-6081ae43-kafka-1
2022-04-04 10:58:51 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-04 10:58:51 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-04 10:58:51 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-04 10:58:51 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-04 10:58:51 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-04 10:58:51 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-04 10:58:51 [main] [32mINFO [m [KafkaST:906] Deleting cluster
2022-04-04 10:58:51 [main] [32mINFO [m [KafkaST:909] Waiting for PVC deletion
2022-04-04 10:59:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 10:59:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsTrue
2022-04-04 10:59:41 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6081ae43 in namespace namespace-43
2022-04-04 10:59:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 10:59:41 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-43 for test case:testKafkaJBODDeleteClaimsTrue
2022-04-04 10:59:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrue-FINISHED
2022-04-04 10:59:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 10:59:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 10:59:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsFalse-STARTED
2022-04-04 10:59:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 10:59:47 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-44 for test case:testKafkaJBODDeleteClaimsFalse
2022-04-04 10:59:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-44
2022-04-04 10:59:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-44
2022-04-04 10:59:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-44
2022-04-04 10:59:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5a99c238 in namespace namespace-44
2022-04-04 10:59:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-44
2022-04-04 10:59:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5a99c238 will have desired state: Ready
2022-04-04 11:01:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5a99c238 is in desired state: Ready
2022-04-04 11:01:03 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-5a99c238-kafka-0
2022-04-04 11:01:03 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-5a99c238-kafka-1
2022-04-04 11:01:03 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-5a99c238-kafka-0
2022-04-04 11:01:03 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-5a99c238-kafka-1
2022-04-04 11:01:03 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-04 11:01:03 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-04 11:01:03 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-04 11:01:03 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-04 11:01:03 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-04 11:01:03 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-04 11:01:03 [main] [32mINFO [m [KafkaST:930] Deleting cluster
2022-04-04 11:01:03 [main] [32mINFO [m [KafkaST:933] Waiting for PVC deletion
2022-04-04 11:01:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:01:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsFalse
2022-04-04 11:01:03 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5a99c238 in namespace namespace-44
2022-04-04 11:01:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:01:03 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-44 for test case:testKafkaJBODDeleteClaimsFalse
2022-04-04 11:01:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsFalse-FINISHED
2022-04-04 11:01:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:01:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:01:52 [main] [32mINFO [m [ResourceManager:346] In context KafkaST is everything deleted.
2022-04-04 11:01:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 23, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4,469.172 s - in io.strimzi.systemtest.kafka.KafkaST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.ListenersST
2022-04-04 11:02:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: listeners-st
2022-04-04 11:02:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: listeners-st
2022-04-04 11:02:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: listeners-st
2022-04-04 11:02:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:02:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsAuthenticated-STARTED
2022-04-04 11:02:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:02:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-45 for test case:testSendMessagesTlsAuthenticated
2022-04-04 11:02:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-45
2022-04-04 11:02:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-45
2022-04-04 11:02:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-45
2022-04-04 11:02:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-85c96c18 in namespace namespace-45
2022-04-04 11:02:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-04 11:02:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-85c96c18 will have desired state: Ready
2022-04-04 11:03:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-85c96c18 is in desired state: Ready
2022-04-04 11:03:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-900055967-350258334 in namespace namespace-45
2022-04-04 11:03:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-04 11:03:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-900055967-350258334 will have desired state: Ready
2022-04-04 11:03:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-900055967-350258334 is in desired state: Ready
2022-04-04 11:03:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-437255483-1066629119 in namespace namespace-45
2022-04-04 11:03:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-04 11:03:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-437255483-1066629119 will have desired state: Ready
2022-04-04 11:03:18 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-437255483-1066629119 is in desired state: Ready
2022-04-04 11:03:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-85c96c18-kafka-clients in namespace namespace-45
2022-04-04 11:03:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-04 11:03:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-85c96c18-kafka-clients will be ready
2022-04-04 11:03:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-85c96c18-kafka-clients is ready
2022-04-04 11:03:20 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:03:20 [main] [32mINFO [m [ListenersST:221] Checking produced and consumed messages to pod:my-cluster-85c96c18-kafka-clients-64fb49dd58-6g9hd
2022-04-04 11:03:20 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1611387b, messages=[], arguments=[--topic, my-topic-900055967-350258334, --max-messages, 100, USER=my_user_437255483_1066629119, --bootstrap-server, my-cluster-85c96c18-kafka-bootstrap.namespace-45.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-85c96c18-kafka-clients-64fb49dd58-6g9hd', podNamespace='namespace-45', bootstrapServer='my-cluster-85c96c18-kafka-bootstrap.namespace-45.svc:9093', topicName='my-topic-900055967-350258334', maxMessages=100, kafkaUsername='my-user-437255483-1066629119', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@277d3e21}
2022-04-04 11:03:20 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-85c96c18-kafka-bootstrap.namespace-45.svc:9093:my-topic-900055967-350258334 from pod my-cluster-85c96c18-kafka-clients-64fb49dd58-6g9hd
2022-04-04 11:03:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-85c96c18-kafka-clients-64fb49dd58-6g9hd -n namespace-45 -- /opt/kafka/producer.sh --topic my-topic-900055967-350258334 --max-messages 100 USER=my_user_437255483_1066629119 --bootstrap-server my-cluster-85c96c18-kafka-bootstrap.namespace-45.svc:9093
2022-04-04 11:03:24 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:03:24 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 11:03:24 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@39802e15, messages=[], arguments=[--topic, my-topic-900055967-350258334, --max-messages, 100, --group-instance-id, instance1347927293, --group-id, my-consumer-group-1883959034, USER=my_user_437255483_1066629119, --bootstrap-server, my-cluster-85c96c18-kafka-bootstrap.namespace-45.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-85c96c18-kafka-clients-64fb49dd58-6g9hd', podNamespace='namespace-45', bootstrapServer='my-cluster-85c96c18-kafka-bootstrap.namespace-45.svc:9093', topicName='my-topic-900055967-350258334', maxMessages=100, kafkaUsername='my-user-437255483-1066629119', consumerGroupName='my-consumer-group-1883959034', consumerInstanceId='instance1347927293', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@77c29afa}
2022-04-04 11:03:24 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-85c96c18-kafka-bootstrap.namespace-45.svc:9093:my-topic-900055967-350258334 from pod my-cluster-85c96c18-kafka-clients-64fb49dd58-6g9hd
2022-04-04 11:03:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-85c96c18-kafka-clients-64fb49dd58-6g9hd -n namespace-45 -- /opt/kafka/consumer.sh --topic my-topic-900055967-350258334 --max-messages 100 --group-instance-id instance1347927293 --group-id my-consumer-group-1883959034 USER=my_user_437255483_1066629119 --bootstrap-server my-cluster-85c96c18-kafka-bootstrap.namespace-45.svc:9093
2022-04-04 11:03:31 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:03:31 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:03:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:03:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesTlsAuthenticated
2022-04-04 11:03:31 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-437255483-1066629119 in namespace namespace-45
2022-04-04 11:03:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-85c96c18-kafka-clients in namespace namespace-45
2022-04-04 11:03:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-85c96c18 in namespace namespace-45
2022-04-04 11:03:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-900055967-350258334 in namespace namespace-45
2022-04-04 11:04:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:04:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-45 for test case:testSendMessagesTlsAuthenticated
2022-04-04 11:04:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsAuthenticated-FINISHED
2022-04-04 11:04:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:04:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:04:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-STARTED
2022-04-04 11:04:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:04:27 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-46 for test case:testSendMessagesCustomListenerTlsScramSha
2022-04-04 11:04:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-46
2022-04-04 11:04:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-46
2022-04-04 11:04:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-46
2022-04-04 11:04:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b77a08bc in namespace namespace-46
2022-04-04 11:04:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-04 11:04:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b77a08bc will have desired state: Ready
2022-04-04 11:05:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b77a08bc is in desired state: Ready
2022-04-04 11:05:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2112666092-2017855426 in namespace namespace-46
2022-04-04 11:05:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-04 11:05:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2112666092-2017855426 will have desired state: Ready
2022-04-04 11:05:40 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2112666092-2017855426 is in desired state: Ready
2022-04-04 11:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1642420488-1572229393 in namespace namespace-46
2022-04-04 11:05:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-04 11:05:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1642420488-1572229393 will have desired state: Ready
2022-04-04 11:05:41 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1642420488-1572229393 is in desired state: Ready
2022-04-04 11:05:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b77a08bc-kafka-clients in namespace namespace-46
2022-04-04 11:05:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-04 11:05:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b77a08bc-kafka-clients will be ready
2022-04-04 11:05:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b77a08bc-kafka-clients is ready
2022-04-04 11:05:43 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:05:43 [main] [32mINFO [m [ListenersST:442] Checking produced and consumed messages to pod:my-cluster-b77a08bc-kafka-clients-787df6854f-8vgt4
2022-04-04 11:05:43 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@25e46443, messages=[], arguments=[--topic, my-topic-2112666092-2017855426, --max-messages, 100, USER=my_user_1642420488_1572229393, --bootstrap-server, my-cluster-b77a08bc-kafka-bootstrap.namespace-46.svc:9122], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b77a08bc-kafka-clients-787df6854f-8vgt4', podNamespace='namespace-46', bootstrapServer='my-cluster-b77a08bc-kafka-bootstrap.namespace-46.svc:9122', topicName='my-topic-2112666092-2017855426', maxMessages=100, kafkaUsername='my-user-1642420488-1572229393', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5488d56}
2022-04-04 11:05:43 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-b77a08bc-kafka-bootstrap.namespace-46.svc:9122:my-topic-2112666092-2017855426 from pod my-cluster-b77a08bc-kafka-clients-787df6854f-8vgt4
2022-04-04 11:05:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b77a08bc-kafka-clients-787df6854f-8vgt4 -n namespace-46 -- /opt/kafka/producer.sh --topic my-topic-2112666092-2017855426 --max-messages 100 USER=my_user_1642420488_1572229393 --bootstrap-server my-cluster-b77a08bc-kafka-bootstrap.namespace-46.svc:9122
2022-04-04 11:05:47 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:05:47 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 11:05:47 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@470216ec, messages=[], arguments=[--topic, my-topic-2112666092-2017855426, --max-messages, 100, --group-instance-id, instance236585910, --group-id, my-consumer-group-1492722640, USER=my_user_1642420488_1572229393, --bootstrap-server, my-cluster-b77a08bc-kafka-bootstrap.namespace-46.svc:9122], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b77a08bc-kafka-clients-787df6854f-8vgt4', podNamespace='namespace-46', bootstrapServer='my-cluster-b77a08bc-kafka-bootstrap.namespace-46.svc:9122', topicName='my-topic-2112666092-2017855426', maxMessages=100, kafkaUsername='my-user-1642420488-1572229393', consumerGroupName='my-consumer-group-1492722640', consumerInstanceId='instance236585910', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6e1195b}
2022-04-04 11:05:47 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b77a08bc-kafka-bootstrap.namespace-46.svc:9122:my-topic-2112666092-2017855426 from pod my-cluster-b77a08bc-kafka-clients-787df6854f-8vgt4
2022-04-04 11:05:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b77a08bc-kafka-clients-787df6854f-8vgt4 -n namespace-46 -- /opt/kafka/consumer.sh --topic my-topic-2112666092-2017855426 --max-messages 100 --group-instance-id instance236585910 --group-id my-consumer-group-1492722640 USER=my_user_1642420488_1572229393 --bootstrap-server my-cluster-b77a08bc-kafka-bootstrap.namespace-46.svc:9122
2022-04-04 11:05:54 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:05:54 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:05:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:05:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesCustomListenerTlsScramSha
2022-04-04 11:05:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1642420488-1572229393 in namespace namespace-46
2022-04-04 11:05:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b77a08bc-kafka-clients in namespace namespace-46
2022-04-04 11:05:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2112666092-2017855426 in namespace namespace-46
2022-04-04 11:05:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b77a08bc in namespace namespace-46
2022-04-04 11:06:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:06:44 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-46 for test case:testSendMessagesCustomListenerTlsScramSha
2022-04-04 11:06:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-FINISHED
2022-04-04 11:06:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:06:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:06:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataCrt-STARTED
2022-04-04 11:06:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:06:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-47 for test case:testCertificateWithNonExistingDataCrt
2022-04-04 11:06:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-47
2022-04-04 11:06:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-47
2022-04-04 11:06:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-47
2022-04-04 11:06:50 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-257c4808-custom-certificate-server-1
2022-04-04 11:06:50 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-257c4808-custom-certificate-server-1 created
2022-04-04 11:06:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-257c4808 in namespace namespace-47
2022-04-04 11:06:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-47
2022-04-04 11:07:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:07:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificateWithNonExistingDataCrt
2022-04-04 11:07:21 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-257c4808 in namespace namespace-47
2022-04-04 11:07:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:07:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-47 for test case:testCertificateWithNonExistingDataCrt
2022-04-04 11:07:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataCrt-FINISHED
2022-04-04 11:07:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:07:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:07:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataKey-STARTED
2022-04-04 11:07:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:07:32 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-48 for test case:testCertificateWithNonExistingDataKey
2022-04-04 11:07:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-48
2022-04-04 11:07:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-48
2022-04-04 11:07:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-48
2022-04-04 11:07:32 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-da8e9e12-custom-certificate-server-1
2022-04-04 11:07:32 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-da8e9e12-custom-certificate-server-1 created
2022-04-04 11:07:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-da8e9e12 in namespace namespace-48
2022-04-04 11:07:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-48
2022-04-04 11:08:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:08:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificateWithNonExistingDataKey
2022-04-04 11:08:02 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-da8e9e12 in namespace namespace-48
2022-04-04 11:08:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:08:02 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-48 for test case:testCertificateWithNonExistingDataKey
2022-04-04 11:08:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataKey-FINISHED
2022-04-04 11:08:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:08:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:08:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainAnonymous-STARTED
2022-04-04 11:08:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:08:30 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-49 for test case:testSendMessagesPlainAnonymous
2022-04-04 11:08:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-49
2022-04-04 11:08:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-49
2022-04-04 11:08:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-49
2022-04-04 11:08:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-19eead05 in namespace namespace-49
2022-04-04 11:08:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-04 11:08:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-19eead05 will have desired state: Ready
2022-04-04 11:09:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-19eead05 is in desired state: Ready
2022-04-04 11:09:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-763650556-1506559652 in namespace namespace-49
2022-04-04 11:09:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-04 11:09:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-763650556-1506559652 will have desired state: Ready
2022-04-04 11:09:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-763650556-1506559652 is in desired state: Ready
2022-04-04 11:09:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-19eead05-kafka-clients in namespace namespace-49
2022-04-04 11:09:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-04 11:09:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-19eead05-kafka-clients will be ready
2022-04-04 11:09:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-19eead05-kafka-clients is ready
2022-04-04 11:09:48 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:09:48 [main] [32mINFO [m [ListenersST:152] Checking produced and consumed messages to pod:my-cluster-19eead05-kafka-clients-8456c74dfc-29ppt
2022-04-04 11:09:48 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@63d10a3b, messages=[], arguments=[--topic, my-topic-763650556-1506559652, --max-messages, 100, --bootstrap-server, my-cluster-19eead05-kafka-bootstrap.namespace-49.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-19eead05-kafka-clients-8456c74dfc-29ppt', podNamespace='namespace-49', bootstrapServer='my-cluster-19eead05-kafka-bootstrap.namespace-49.svc:9092', topicName='my-topic-763650556-1506559652', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7048889b}
2022-04-04 11:09:48 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-19eead05-kafka-bootstrap.namespace-49.svc:9092:my-topic-763650556-1506559652 from pod my-cluster-19eead05-kafka-clients-8456c74dfc-29ppt
2022-04-04 11:09:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-19eead05-kafka-clients-8456c74dfc-29ppt -n namespace-49 -- /opt/kafka/producer.sh --topic my-topic-763650556-1506559652 --max-messages 100 --bootstrap-server my-cluster-19eead05-kafka-bootstrap.namespace-49.svc:9092
2022-04-04 11:09:50 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 11:09:50 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 11:09:50 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1adc1d78, messages=[], arguments=[--topic, my-topic-763650556-1506559652, --max-messages, 100, --group-instance-id, instance986705298, --group-id, my-consumer-group-751648909, --bootstrap-server, my-cluster-19eead05-kafka-bootstrap.namespace-49.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-19eead05-kafka-clients-8456c74dfc-29ppt', podNamespace='namespace-49', bootstrapServer='my-cluster-19eead05-kafka-bootstrap.namespace-49.svc:9092', topicName='my-topic-763650556-1506559652', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-751648909', consumerInstanceId='instance986705298', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2ee4446f}
2022-04-04 11:09:50 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-19eead05-kafka-bootstrap.namespace-49.svc:9092#my-topic-763650556-1506559652 from pod my-cluster-19eead05-kafka-clients-8456c74dfc-29ppt
2022-04-04 11:09:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-19eead05-kafka-clients-8456c74dfc-29ppt -n namespace-49 -- /opt/kafka/consumer.sh --topic my-topic-763650556-1506559652 --max-messages 100 --group-instance-id instance986705298 --group-id my-consumer-group-751648909 --bootstrap-server my-cluster-19eead05-kafka-bootstrap.namespace-49.svc:9092
2022-04-04 11:09:56 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 11:09:56 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 11:09:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:09:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesPlainAnonymous
2022-04-04 11:09:56 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-763650556-1506559652 in namespace namespace-49
2022-04-04 11:09:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-19eead05 in namespace namespace-49
2022-04-04 11:09:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-19eead05-kafka-clients in namespace namespace-49
2022-04-04 11:10:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:10:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-49 for test case:testSendMessagesPlainAnonymous
2022-04-04 11:10:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainAnonymous-FINISHED
2022-04-04 11:10:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:10:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:10:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainScramSha-STARTED
2022-04-04 11:10:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:10:47 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-50 for test case:testSendMessagesPlainScramSha
2022-04-04 11:10:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-50
2022-04-04 11:10:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-50
2022-04-04 11:10:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-50
2022-04-04 11:10:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-72c7ad78 in namespace namespace-50
2022-04-04 11:10:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-04 11:10:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-72c7ad78 will have desired state: Ready
2022-04-04 11:12:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-72c7ad78 is in desired state: Ready
2022-04-04 11:12:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-621647229-1011389392 in namespace namespace-50
2022-04-04 11:12:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-04 11:12:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-621647229-1011389392 will have desired state: Ready
2022-04-04 11:12:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-621647229-1011389392 is in desired state: Ready
2022-04-04 11:12:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1529216681-1868778544 in namespace namespace-50
2022-04-04 11:12:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-04 11:12:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1529216681-1868778544 will have desired state: Ready
2022-04-04 11:12:11 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1529216681-1868778544 is in desired state: Ready
2022-04-04 11:12:11 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1529216681-1868778544: 2022-04-04 11:12:10,506 INFO Processing override for entityPath: users/my-user-1529216681-1868778544 with config: HashMap(SCRAM-SHA-512 -> [hidden]) (kafka.server.DynamicConfigManager) [/config/changes-event-process-thread]
2022-04-04 11:12:11 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1529216681-1868778544: 2022-04-04 11:12:10,512 INFO Removing PRODUCE quota for user my-user-1529216681-1868778544 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:12:11 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1529216681-1868778544: 2022-04-04 11:12:10,517 INFO Removing FETCH quota for user my-user-1529216681-1868778544 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:12:11 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1529216681-1868778544: 2022-04-04 11:12:10,517 INFO Removing REQUEST quota for user my-user-1529216681-1868778544 (kafka.server.ClientRequestQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:12:11 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1529216681-1868778544: 2022-04-04 11:12:10,517 INFO Removing CONTROLLER_MUTATION quota for user my-user-1529216681-1868778544 (kafka.server.ControllerMutationQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:12:11 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1529216681-1868778544: 2022-04-04 11:12:10,782 INFO Processing override for entityPath: users/my-user-1529216681-1868778544 with config: HashMap(SCRAM-SHA-512 -> [hidden]) (kafka.server.DynamicConfigManager) [/config/changes-event-process-thread]
2022-04-04 11:12:11 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1529216681-1868778544: 2022-04-04 11:12:10,782 INFO Removing PRODUCE quota for user my-user-1529216681-1868778544 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:12:11 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1529216681-1868778544: 2022-04-04 11:12:10,782 INFO Removing FETCH quota for user my-user-1529216681-1868778544 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:12:11 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1529216681-1868778544: 2022-04-04 11:12:10,782 INFO Removing REQUEST quota for user my-user-1529216681-1868778544 (kafka.server.ClientRequestQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:12:11 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1529216681-1868778544: 2022-04-04 11:12:10,783 INFO Removing CONTROLLER_MUTATION quota for user my-user-1529216681-1868778544 (kafka.server.ControllerMutationQuotaManager) [/config/changes-event-process-thread]
2022-04-04 11:12:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-72c7ad78-kafka-clients in namespace namespace-50
2022-04-04 11:12:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-04 11:12:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-72c7ad78-kafka-clients will be ready
2022-04-04 11:12:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-72c7ad78-kafka-clients is ready
2022-04-04 11:12:13 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:12:13 [main] [32mINFO [m [ListenersST:296] Checking produced and consumed messages to pod:my-cluster-72c7ad78-kafka-clients-7965d58d7-6rjmh
2022-04-04 11:12:13 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@57a9c5bd, messages=[], arguments=[--topic, my-topic-621647229-1011389392, --max-messages, 100, USER=my_user_1529216681_1868778544, --bootstrap-server, my-cluster-72c7ad78-kafka-bootstrap.namespace-50.svc:9095], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-72c7ad78-kafka-clients-7965d58d7-6rjmh', podNamespace='namespace-50', bootstrapServer='my-cluster-72c7ad78-kafka-bootstrap.namespace-50.svc:9095', topicName='my-topic-621647229-1011389392', maxMessages=100, kafkaUsername='my-user-1529216681-1868778544', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1cb97fb3}
2022-04-04 11:12:13 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-72c7ad78-kafka-bootstrap.namespace-50.svc:9095:my-topic-621647229-1011389392 from pod my-cluster-72c7ad78-kafka-clients-7965d58d7-6rjmh
2022-04-04 11:12:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-72c7ad78-kafka-clients-7965d58d7-6rjmh -n namespace-50 -- /opt/kafka/producer.sh --topic my-topic-621647229-1011389392 --max-messages 100 USER=my_user_1529216681_1868778544 --bootstrap-server my-cluster-72c7ad78-kafka-bootstrap.namespace-50.svc:9095
2022-04-04 11:12:16 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 11:12:16 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 11:12:16 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@547a8702, messages=[], arguments=[--topic, my-topic-621647229-1011389392, --max-messages, 100, --group-instance-id, instance1208068809, --group-id, my-consumer-group-568561434, USER=my_user_1529216681_1868778544, --bootstrap-server, my-cluster-72c7ad78-kafka-bootstrap.namespace-50.svc:9095], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-72c7ad78-kafka-clients-7965d58d7-6rjmh', podNamespace='namespace-50', bootstrapServer='my-cluster-72c7ad78-kafka-bootstrap.namespace-50.svc:9095', topicName='my-topic-621647229-1011389392', maxMessages=100, kafkaUsername='my-user-1529216681-1868778544', consumerGroupName='my-consumer-group-568561434', consumerInstanceId='instance1208068809', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@369243b}
2022-04-04 11:12:16 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-72c7ad78-kafka-bootstrap.namespace-50.svc:9095#my-topic-621647229-1011389392 from pod my-cluster-72c7ad78-kafka-clients-7965d58d7-6rjmh
2022-04-04 11:12:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-72c7ad78-kafka-clients-7965d58d7-6rjmh -n namespace-50 -- /opt/kafka/consumer.sh --topic my-topic-621647229-1011389392 --max-messages 100 --group-instance-id instance1208068809 --group-id my-consumer-group-568561434 USER=my_user_1529216681_1868778544 --bootstrap-server my-cluster-72c7ad78-kafka-bootstrap.namespace-50.svc:9095
2022-04-04 11:12:22 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 11:12:22 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 11:12:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:12:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesPlainScramSha
2022-04-04 11:12:22 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1529216681-1868778544 in namespace namespace-50
2022-04-04 11:12:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-72c7ad78-kafka-clients in namespace namespace-50
2022-04-04 11:12:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-621647229-1011389392 in namespace namespace-50
2022-04-04 11:12:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-72c7ad78 in namespace namespace-50
2022-04-04 11:13:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:13:02 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-50 for test case:testSendMessagesPlainScramSha
2022-04-04 11:13:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainScramSha-FINISHED
2022-04-04 11:13:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:13:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:13:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-STARTED
2022-04-04 11:13:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:13:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-51 for test case:testSendMessagesTlsScramSha
2022-04-04 11:13:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-51
2022-04-04 11:13:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-51
2022-04-04 11:13:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-51
2022-04-04 11:13:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-56d90b7f in namespace namespace-51
2022-04-04 11:13:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-04 11:13:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-56d90b7f will have desired state: Ready
2022-04-04 11:14:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-56d90b7f is in desired state: Ready
2022-04-04 11:14:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1619586561-1399433463 in namespace namespace-51
2022-04-04 11:14:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-04 11:14:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1619586561-1399433463 will have desired state: Ready
2022-04-04 11:14:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1619586561-1399433463 is in desired state: Ready
2022-04-04 11:14:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1243467995-751593013 in namespace namespace-51
2022-04-04 11:14:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-04 11:14:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1243467995-751593013 will have desired state: Ready
2022-04-04 11:14:27 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1243467995-751593013 is in desired state: Ready
2022-04-04 11:14:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-56d90b7f-kafka-clients in namespace namespace-51
2022-04-04 11:14:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-04 11:14:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-56d90b7f-kafka-clients will be ready
2022-04-04 11:14:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-56d90b7f-kafka-clients is ready
2022-04-04 11:14:29 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:14:29 [main] [32mINFO [m [ListenersST:370] Checking produced and consumed messages to pod:my-cluster-56d90b7f-kafka-clients-67b6778d49-85cfq
2022-04-04 11:14:29 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@af2d433, messages=[], arguments=[--topic, my-topic-1619586561-1399433463, --max-messages, 100, USER=my_user_1243467995_751593013, --bootstrap-server, my-cluster-56d90b7f-kafka-bootstrap.namespace-51.svc:9096], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-56d90b7f-kafka-clients-67b6778d49-85cfq', podNamespace='namespace-51', bootstrapServer='my-cluster-56d90b7f-kafka-bootstrap.namespace-51.svc:9096', topicName='my-topic-1619586561-1399433463', maxMessages=100, kafkaUsername='my-user-1243467995-751593013', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@aada50f}
2022-04-04 11:14:29 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-56d90b7f-kafka-bootstrap.namespace-51.svc:9096:my-topic-1619586561-1399433463 from pod my-cluster-56d90b7f-kafka-clients-67b6778d49-85cfq
2022-04-04 11:14:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-56d90b7f-kafka-clients-67b6778d49-85cfq -n namespace-51 -- /opt/kafka/producer.sh --topic my-topic-1619586561-1399433463 --max-messages 100 USER=my_user_1243467995_751593013 --bootstrap-server my-cluster-56d90b7f-kafka-bootstrap.namespace-51.svc:9096
2022-04-04 11:14:33 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:14:33 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 11:14:33 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@44a25091, messages=[], arguments=[--topic, my-topic-1619586561-1399433463, --max-messages, 100, --group-instance-id, instance1971703416, --group-id, my-consumer-group-1380575766, USER=my_user_1243467995_751593013, --bootstrap-server, my-cluster-56d90b7f-kafka-bootstrap.namespace-51.svc:9096], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-56d90b7f-kafka-clients-67b6778d49-85cfq', podNamespace='namespace-51', bootstrapServer='my-cluster-56d90b7f-kafka-bootstrap.namespace-51.svc:9096', topicName='my-topic-1619586561-1399433463', maxMessages=100, kafkaUsername='my-user-1243467995-751593013', consumerGroupName='my-consumer-group-1380575766', consumerInstanceId='instance1971703416', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@23c00c3b}
2022-04-04 11:14:33 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-56d90b7f-kafka-bootstrap.namespace-51.svc:9096:my-topic-1619586561-1399433463 from pod my-cluster-56d90b7f-kafka-clients-67b6778d49-85cfq
2022-04-04 11:14:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-56d90b7f-kafka-clients-67b6778d49-85cfq -n namespace-51 -- /opt/kafka/consumer.sh --topic my-topic-1619586561-1399433463 --max-messages 100 --group-instance-id instance1971703416 --group-id my-consumer-group-1380575766 USER=my_user_1243467995_751593013 --bootstrap-server my-cluster-56d90b7f-kafka-bootstrap.namespace-51.svc:9096
2022-04-04 11:14:40 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:14:40 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:14:40 [main] [32mINFO [m [ListenersST:377] Checking if generated password has 25 characters
2022-04-04 11:14:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:14:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesTlsScramSha
2022-04-04 11:14:40 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1243467995-751593013 in namespace namespace-51
2022-04-04 11:14:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-56d90b7f-kafka-clients in namespace namespace-51
2022-04-04 11:14:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1619586561-1399433463 in namespace namespace-51
2022-04-04 11:14:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-56d90b7f in namespace namespace-51
2022-04-04 11:15:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:15:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-51 for test case:testSendMessagesTlsScramSha
2022-04-04 11:15:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-FINISHED
2022-04-04 11:15:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:15:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:15:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testNonExistingCustomCertificate-STARTED
2022-04-04 11:15:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:15:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-52 for test case:testNonExistingCustomCertificate
2022-04-04 11:15:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-52
2022-04-04 11:15:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-52
2022-04-04 11:15:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-52
2022-04-04 11:15:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cd610551 in namespace namespace-52
2022-04-04 11:15:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-52
2022-04-04 11:16:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:16:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNonExistingCustomCertificate
2022-04-04 11:16:11 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cd610551 in namespace namespace-52
2022-04-04 11:16:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:16:11 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-52 for test case:testNonExistingCustomCertificate
2022-04-04 11:16:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testNonExistingCustomCertificate-FINISHED
2022-04-04 11:16:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:16:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:16:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testAdvertisedHostNamesAppearsInBrokerCerts-STARTED
2022-04-04 11:16:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:16:16 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-53 for test case:testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-04 11:16:16 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-53
2022-04-04 11:16:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-53
2022-04-04 11:16:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-53
2022-04-04 11:16:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6916afd2 in namespace namespace-53
2022-04-04 11:16:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-53
2022-04-04 11:16:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6916afd2 will have desired state: Ready
2022-04-04 11:17:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6916afd2 is in desired state: Ready
2022-04-04 11:17:39 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-6916afd2-kafka-0.crt
2022-04-04 11:17:39 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-6916afd2-kafka-1.crt
2022-04-04 11:17:39 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-6916afd2-kafka-2.crt
2022-04-04 11:17:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:17:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-04 11:17:39 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6916afd2 in namespace namespace-53
2022-04-04 11:17:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:17:49 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-53 for test case:testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-04 11:18:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testAdvertisedHostNamesAppearsInBrokerCerts-FINISHED
2022-04-04 11:18:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:18:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:18:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testMessagesTlsScramShaWithPredefinedPassword-STARTED
2022-04-04 11:18:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:18:32 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-54 for test case:testMessagesTlsScramShaWithPredefinedPassword
2022-04-04 11:18:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-54
2022-04-04 11:18:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-54
2022-04-04 11:18:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-54
2022-04-04 11:18:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0f557cb4 in namespace namespace-54
2022-04-04 11:18:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-54
2022-04-04 11:18:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1948058652-892742500 in namespace namespace-54
2022-04-04 11:18:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-54
2022-04-04 11:18:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-511131022-644945059 in namespace namespace-54
2022-04-04 11:18:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-54
2022-04-04 11:18:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0f557cb4 will have desired state: Ready
2022-04-04 11:19:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0f557cb4 is in desired state: Ready
2022-04-04 11:19:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1948058652-892742500 will have desired state: Ready
2022-04-04 11:19:44 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1948058652-892742500 is in desired state: Ready
2022-04-04 11:19:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-511131022-644945059 will have desired state: Ready
2022-04-04 11:19:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-511131022-644945059 is in desired state: Ready
2022-04-04 11:19:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0f557cb4-kafka-clients in namespace namespace-54
2022-04-04 11:19:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-54
2022-04-04 11:19:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0f557cb4-kafka-clients will be ready
2022-04-04 11:19:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0f557cb4-kafka-clients is ready
2022-04-04 11:19:47 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:19:47 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@45dc4752, messages=[], arguments=[--topic, my-topic-511131022-644945059, --max-messages, 100, USER=my_user_1948058652_892742500, --bootstrap-server, my-cluster-0f557cb4-kafka-bootstrap.namespace-54.svc:9096], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0f557cb4-kafka-clients-7fdbdf99f8-rnsdk', podNamespace='namespace-54', bootstrapServer='my-cluster-0f557cb4-kafka-bootstrap.namespace-54.svc:9096', topicName='my-topic-511131022-644945059', maxMessages=100, kafkaUsername='my-user-1948058652-892742500', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@644cfd99}
2022-04-04 11:19:47 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-0f557cb4-kafka-bootstrap.namespace-54.svc:9096:my-topic-511131022-644945059 from pod my-cluster-0f557cb4-kafka-clients-7fdbdf99f8-rnsdk
2022-04-04 11:19:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0f557cb4-kafka-clients-7fdbdf99f8-rnsdk -n namespace-54 -- /opt/kafka/producer.sh --topic my-topic-511131022-644945059 --max-messages 100 USER=my_user_1948058652_892742500 --bootstrap-server my-cluster-0f557cb4-kafka-bootstrap.namespace-54.svc:9096
2022-04-04 11:19:51 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:19:51 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 11:19:51 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7fab9649, messages=[], arguments=[--topic, my-topic-511131022-644945059, --max-messages, 100, --group-instance-id, instance1087014494, --group-id, my-consumer-group-1602610429, USER=my_user_1948058652_892742500, --bootstrap-server, my-cluster-0f557cb4-kafka-bootstrap.namespace-54.svc:9096], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0f557cb4-kafka-clients-7fdbdf99f8-rnsdk', podNamespace='namespace-54', bootstrapServer='my-cluster-0f557cb4-kafka-bootstrap.namespace-54.svc:9096', topicName='my-topic-511131022-644945059', maxMessages=100, kafkaUsername='my-user-1948058652-892742500', consumerGroupName='my-consumer-group-1602610429', consumerInstanceId='instance1087014494', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7c081c64}
2022-04-04 11:19:51 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-0f557cb4-kafka-bootstrap.namespace-54.svc:9096:my-topic-511131022-644945059 from pod my-cluster-0f557cb4-kafka-clients-7fdbdf99f8-rnsdk
2022-04-04 11:19:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0f557cb4-kafka-clients-7fdbdf99f8-rnsdk -n namespace-54 -- /opt/kafka/consumer.sh --topic my-topic-511131022-644945059 --max-messages 100 --group-instance-id instance1087014494 --group-id my-consumer-group-1602610429 USER=my_user_1948058652_892742500 --bootstrap-server my-cluster-0f557cb4-kafka-bootstrap.namespace-54.svc:9096
2022-04-04 11:19:58 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:19:58 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:19:58 [main] [32mINFO [m [ListenersST:2213] Changing password in secret: my-cluster-0f557cb4-secret, we should be able to send/receive messages
2022-04-04 11:19:58 [main] [32mINFO [m [SecretUtils:171] Waiting for user password will be changed to Y29tcGxldGVseV9kaWZmZXJlbnRfc2VjcmV0X3Bhc3N3b3Jk in secret: my-user-1948058652-892742500
2022-04-04 11:21:26 [main] [32mINFO [m [ListenersST:2222] We need to recreate Kafka Clients deployment, so the correct password from secret will be taken
2022-04-04 11:21:26 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0f557cb4-kafka-clients in namespace namespace-54
2022-04-04 11:22:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0f557cb4-kafka-clients in namespace namespace-54
2022-04-04 11:22:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-54
2022-04-04 11:22:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0f557cb4-kafka-clients will be ready
2022-04-04 11:22:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0f557cb4-kafka-clients is ready
2022-04-04 11:22:18 [main] [32mINFO [m [ListenersST:2226] Receiving messages with new password
2022-04-04 11:22:18 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3e1aea5e, messages=[], arguments=[--topic, my-topic-511131022-644945059, --max-messages, 100, --group-instance-id, instance228297957, --group-id, my-consumer-group-1495255302, USER=my_user_1948058652_892742500, --bootstrap-server, my-cluster-0f557cb4-kafka-bootstrap.namespace-54.svc:9096], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0f557cb4-kafka-clients-746995c798-kfp58', podNamespace='namespace-54', bootstrapServer='my-cluster-0f557cb4-kafka-bootstrap.namespace-54.svc:9096', topicName='my-topic-511131022-644945059', maxMessages=100, kafkaUsername='my-user-1948058652-892742500', consumerGroupName='my-consumer-group-1495255302', consumerInstanceId='instance228297957', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@24d2d4f}
2022-04-04 11:22:18 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-0f557cb4-kafka-bootstrap.namespace-54.svc:9096:my-topic-511131022-644945059 from pod my-cluster-0f557cb4-kafka-clients-746995c798-kfp58
2022-04-04 11:22:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0f557cb4-kafka-clients-746995c798-kfp58 -n namespace-54 -- /opt/kafka/consumer.sh --topic my-topic-511131022-644945059 --max-messages 100 --group-instance-id instance228297957 --group-id my-consumer-group-1495255302 USER=my_user_1948058652_892742500 --bootstrap-server my-cluster-0f557cb4-kafka-bootstrap.namespace-54.svc:9096
2022-04-04 11:22:25 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:22:25 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:22:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:22:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMessagesTlsScramShaWithPredefinedPassword
2022-04-04 11:22:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-511131022-644945059 in namespace namespace-54
2022-04-04 11:22:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1948058652-892742500 in namespace namespace-54
2022-04-04 11:22:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0f557cb4-kafka-clients in namespace namespace-54
2022-04-04 11:22:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0f557cb4 in namespace namespace-54
2022-04-04 11:22:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0f557cb4-kafka-clients in namespace namespace-54
2022-04-04 11:23:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:23:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-54 for test case:testMessagesTlsScramShaWithPredefinedPassword
2022-04-04 11:23:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testMessagesTlsScramShaWithPredefinedPassword-FINISHED
2022-04-04 11:23:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:23:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:23:21 [main] [32mINFO [m [ResourceManager:346] In context ListenersST is everything deleted.
2022-04-04 11:23:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,288.667 s - in io.strimzi.systemtest.kafka.listeners.ListenersST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.MultipleListenersST
2022-04-04 11:23:26 [main] [32mINFO [m [MultipleListenersST:294] Starting to generate test cases for multiple listeners
2022-04-04 11:23:26 [main] [32mINFO [m [MultipleListenersST:300] Generating INTERNAL listener
2022-04-04 11:23:26 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type INTERNAL -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@ee339035, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@3c8b9e43, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@7de38a5f]
2022-04-04 11:23:26 [main] [32mINFO [m [MultipleListenersST:300] Generating ROUTE listener
2022-04-04 11:23:26 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type ROUTE -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@9edb94cb]
2022-04-04 11:23:26 [main] [32mINFO [m [MultipleListenersST:300] Generating LOADBALANCER listener
2022-04-04 11:23:26 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type LOADBALANCER -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@2e1a83bd, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@6f726fd9]
2022-04-04 11:23:26 [main] [32mINFO [m [MultipleListenersST:300] Generating NODEPORT listener
2022-04-04 11:23:26 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type NODEPORT -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@e4c7838c, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@261f6fa8, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@5a7739d2, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@9bcf25ee]
2022-04-04 11:23:26 [main] [32mINFO [m [MultipleListenersST:300] Generating INGRESS listener
2022-04-04 11:23:26 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type INGRESS -> []
2022-04-04 11:23:26 [main] [32mINFO [m [MultipleListenersST:367] Finished with generation of test cases for multiple listeners
2022-04-04 11:23:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-listeners-st
2022-04-04 11:23:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-listeners-st
2022-04-04 11:23:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-listeners-st
2022-04-04 11:23:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:23:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.MultipleListenersST.testMultipleInternal-STARTED
2022-04-04 11:23:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:23:26 [main] [32mINFO [m [MultipleListenersST:163] This is listeners [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@ee339035, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@3c8b9e43, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@7de38a5f], which will verified.
2022-04-04 11:23:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5208cca7 in namespace multiple-listeners-st
2022-04-04 11:23:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5208cca7 will have desired state: Ready
2022-04-04 11:24:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5208cca7 is in desired state: Ready
2022-04-04 11:24:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1849695939-1582596038 in namespace multiple-listeners-st
2022-04-04 11:24:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1849695939-1582596038 will have desired state: Ready
2022-04-04 11:24:44 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1849695939-1582596038 is in desired state: Ready
2022-04-04 11:24:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1116436890-1340319562 in namespace multiple-listeners-st
2022-04-04 11:24:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1116436890-1340319562 will have desired state: Ready
2022-04-04 11:24:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1116436890-1340319562 is in desired state: Ready
2022-04-04 11:24:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5208cca7-kafka-clients-tls in namespace multiple-listeners-st
2022-04-04 11:24:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5208cca7-kafka-clients-tls will be ready
2022-04-04 11:24:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5208cca7-kafka-clients-tls is ready
2022-04-04 11:24:47 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:24:47 [main] [32mINFO [m [MultipleListenersST:252] Checking produced and consumed messages to pod:my-cluster-5208cca7-kafka-clients-tls-78756d548f-ts4nn
2022-04-04 11:24:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2115214956-1497829353 in namespace multiple-listeners-st
2022-04-04 11:24:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2115214956-1497829353 will have desired state: Ready
2022-04-04 11:24:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2115214956-1497829353 is in desired state: Ready
2022-04-04 11:24:48 [main] [32mINFO [m [ClientUtils:127] Sending messages to - topic my-topic-1116436890-1340319562, cluster my-cluster-5208cca7 and message count of 100
2022-04-04 11:24:48 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1bae9b5b, messages=[], arguments=[--topic, my-topic-2115214956-1497829353, --max-messages, 100, USER=my_user_1849695939_1582596038, --bootstrap-server, my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13900], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5208cca7-kafka-clients-tls-78756d548f-ts4nn', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13900', topicName='my-topic-2115214956-1497829353', maxMessages=100, kafkaUsername='my-user-1849695939-1582596038', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@65a5a206}
2022-04-04 11:24:48 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13900:my-topic-2115214956-1497829353 from pod my-cluster-5208cca7-kafka-clients-tls-78756d548f-ts4nn
2022-04-04 11:24:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5208cca7-kafka-clients-tls-78756d548f-ts4nn -n multiple-listeners-st -- /opt/kafka/producer.sh --topic my-topic-2115214956-1497829353 --max-messages 100 USER=my_user_1849695939_1582596038 --bootstrap-server my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13900
2022-04-04 11:24:51 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:24:51 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 11:24:51 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3d946afa, messages=[], arguments=[--topic, my-topic-2115214956-1497829353, --max-messages, 100, --group-instance-id, instance1330710482, --group-id, my-consumer-group-1473643926, USER=my_user_1849695939_1582596038, --bootstrap-server, my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13900], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5208cca7-kafka-clients-tls-78756d548f-ts4nn', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13900', topicName='my-topic-2115214956-1497829353', maxMessages=100, kafkaUsername='my-user-1849695939-1582596038', consumerGroupName='my-consumer-group-1473643926', consumerInstanceId='instance1330710482', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@75e953d3}
2022-04-04 11:24:51 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13900:my-topic-2115214956-1497829353 from pod my-cluster-5208cca7-kafka-clients-tls-78756d548f-ts4nn
2022-04-04 11:24:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5208cca7-kafka-clients-tls-78756d548f-ts4nn -n multiple-listeners-st -- /opt/kafka/consumer.sh --topic my-topic-2115214956-1497829353 --max-messages 100 --group-instance-id instance1330710482 --group-id my-consumer-group-1473643926 USER=my_user_1849695939_1582596038 --bootstrap-server my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13900
2022-04-04 11:24:58 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:24:58 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:24:58 [main] [32mINFO [m [ClientUtils:133] Sent 100 and received 100
2022-04-04 11:24:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1044059152-1594746220 in namespace multiple-listeners-st
2022-04-04 11:24:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1044059152-1594746220 will have desired state: Ready
2022-04-04 11:24:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1044059152-1594746220 is in desired state: Ready
2022-04-04 11:24:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5208cca7-kafka-clients-plain in namespace multiple-listeners-st
2022-04-04 11:25:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5208cca7-kafka-clients-plain will be ready
2022-04-04 11:25:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5208cca7-kafka-clients-plain is ready
2022-04-04 11:25:02 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:25:02 [main] [32mINFO [m [MultipleListenersST:274] Checking produced and consumed messages to pod:my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj
2022-04-04 11:25:02 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1c50f92b, messages=[], arguments=[--topic, my-topic-1044059152-1594746220, --max-messages, 100, --bootstrap-server, my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13901], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13901', topicName='my-topic-1044059152-1594746220', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@528f5a50}
2022-04-04 11:25:02 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13901:my-topic-1044059152-1594746220 from pod my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj
2022-04-04 11:25:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj -n multiple-listeners-st -- /opt/kafka/producer.sh --topic my-topic-1044059152-1594746220 --max-messages 100 --bootstrap-server my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13901
2022-04-04 11:25:04 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 11:25:04 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 11:25:04 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3dc52b8a, messages=[], arguments=[--topic, my-topic-1044059152-1594746220, --max-messages, 100, --group-instance-id, instance1081807558, --group-id, my-consumer-group-482868421, --bootstrap-server, my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13901], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13901', topicName='my-topic-1044059152-1594746220', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-482868421', consumerInstanceId='instance1081807558', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@239856b9}
2022-04-04 11:25:04 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13901#my-topic-1044059152-1594746220 from pod my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj
2022-04-04 11:25:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj -n multiple-listeners-st -- /opt/kafka/consumer.sh --topic my-topic-1044059152-1594746220 --max-messages 100 --group-instance-id instance1081807558 --group-id my-consumer-group-482868421 --bootstrap-server my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13901
2022-04-04 11:25:10 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 11:25:10 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 11:25:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-900089790-1919337136 in namespace multiple-listeners-st
2022-04-04 11:25:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-900089790-1919337136 will have desired state: Ready
2022-04-04 11:25:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-900089790-1919337136 is in desired state: Ready
2022-04-04 11:25:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5208cca7-kafka-clients-plain in namespace multiple-listeners-st
2022-04-04 11:25:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5208cca7-kafka-clients-plain will be ready
2022-04-04 11:25:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5208cca7-kafka-clients-plain is ready
2022-04-04 11:25:11 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:25:11 [main] [32mINFO [m [MultipleListenersST:274] Checking produced and consumed messages to pod:my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj
2022-04-04 11:25:11 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@e329184, messages=[], arguments=[--topic, my-topic-900089790-1919337136, --max-messages, 100, --bootstrap-server, my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13902], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13902', topicName='my-topic-900089790-1919337136', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@15b0bbb8}
2022-04-04 11:25:11 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13902:my-topic-900089790-1919337136 from pod my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj
2022-04-04 11:25:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj -n multiple-listeners-st -- /opt/kafka/producer.sh --topic my-topic-900089790-1919337136 --max-messages 100 --bootstrap-server my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13902
2022-04-04 11:25:13 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 11:25:13 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 11:25:13 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7bf3dc6b, messages=[], arguments=[--topic, my-topic-900089790-1919337136, --max-messages, 100, --group-instance-id, instance1043319787, --group-id, my-consumer-group-986911340, --bootstrap-server, my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13902], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13902', topicName='my-topic-900089790-1919337136', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-986911340', consumerInstanceId='instance1043319787', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6ffe3365}
2022-04-04 11:25:13 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13902#my-topic-900089790-1919337136 from pod my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj
2022-04-04 11:25:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5208cca7-kafka-clients-plain-774c8b9c6c-fxhmj -n multiple-listeners-st -- /opt/kafka/consumer.sh --topic my-topic-900089790-1919337136 --max-messages 100 --group-instance-id instance1043319787 --group-id my-consumer-group-986911340 --bootstrap-server my-cluster-5208cca7-kafka-bootstrap.multiple-listeners-st.svc:13902
2022-04-04 11:25:19 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 11:25:19 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 11:25:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:25:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultipleInternal
2022-04-04 11:25:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1044059152-1594746220 in namespace multiple-listeners-st
2022-04-04 11:25:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-900089790-1919337136 in namespace multiple-listeners-st
2022-04-04 11:25:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1116436890-1340319562 in namespace multiple-listeners-st
2022-04-04 11:25:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2115214956-1497829353 in namespace multiple-listeners-st
2022-04-04 11:25:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5208cca7-kafka-clients-tls in namespace multiple-listeners-st
2022-04-04 11:25:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1849695939-1582596038 in namespace multiple-listeners-st
2022-04-04 11:25:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5208cca7-kafka-clients-plain in namespace multiple-listeners-st
2022-04-04 11:25:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5208cca7 in namespace multiple-listeners-st
2022-04-04 11:25:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5208cca7-kafka-clients-plain in namespace multiple-listeners-st
2022-04-04 11:26:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:26:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.MultipleListenersST.testMultipleInternal-FINISHED
2022-04-04 11:26:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:26:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:26:09 [main] [32mINFO [m [ResourceManager:346] In context MultipleListenersST is everything deleted.
2022-04-04 11:26:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 189.917 s - in io.strimzi.systemtest.kafka.listeners.MultipleListenersST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
2022-04-04 11:26:36 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: dynamic-conf-st
2022-04-04 11:26:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: dynamic-conf-st
2022-04-04 11:26:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: dynamic-conf-st
2022-04-04 11:26:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:26:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testSimpleDynamicConfiguration-STARTED
2022-04-04 11:26:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:26:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4932aef8 in namespace dynamic-conf-st
2022-04-04 11:26:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4932aef8 will have desired state: Ready
2022-04-04 11:27:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4932aef8 is in desired state: Ready
2022-04-04 11:27:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-4932aef8-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:27:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:27:43 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-04 11:27:43 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-4932aef8-kafka are stable
2022-04-04 11:27:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:27:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:27:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:27:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:27:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:27:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:27:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:27:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:27:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:27:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:27:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:27:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:27:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:27:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:27:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:27:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:27:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:27:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:27:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:27:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:27:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:27:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:27:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:27:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:27:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:27:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:27:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:27:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:27:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:27:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:27:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:27:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:27:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:27:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:27:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:27:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:27:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:27:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:27:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:27:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:27:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:27:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:27:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:27:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:27:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:27:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:27:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:27:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:28:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:28:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:28:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:28:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:28:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:28:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:28:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:28:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:28:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:28:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:28:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:28:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:28:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:28:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:28:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:28:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:28:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:28:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:28:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:28:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:28:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:28:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:28:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:28:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:28:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:28:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:28:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:28:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:28:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:28:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:28:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:28:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:28:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:28:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:28:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:28:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:28:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:28:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:28:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:28:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:28:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:28:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:28:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:28:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:28:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:28:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:28:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:28:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:28:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:28:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:28:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:28:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:28:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:28:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:28:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:28:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:28:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:28:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:28:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:28:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:28:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:28:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:28:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:28:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:28:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:28:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:28:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:28:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:28:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:28:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:28:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:28:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:28:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:28:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:28:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:28:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:28:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:28:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:28:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:28:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:28:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:28:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:28:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:28:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:28:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:28:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:28:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:28:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:28:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:28:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:28:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:28:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:28:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:28:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:28:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:28:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:28:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:28:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:28:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:28:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:28:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:28:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-4932aef8-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:28:33 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-4932aef8-kafka-0 ,my-cluster-4932aef8-kafka-1 ,my-cluster-4932aef8-kafka-2
2022-04-04 11:28:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-4932aef8-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:28:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:28:36 [main] [32mINFO [m [DynamicConfST:102] Verify values after update
2022-04-04 11:28:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:28:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSimpleDynamicConfiguration
2022-04-04 11:28:36 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4932aef8 in namespace dynamic-conf-st
2022-04-04 11:28:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:28:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testSimpleDynamicConfiguration-FINISHED
2022-04-04 11:28:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:28:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:28:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testUpdateToExternalListenerCausesRollingRestart-STARTED
2022-04-04 11:28:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:28:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ca7b01cc in namespace dynamic-conf-st
2022-04-04 11:28:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ca7b01cc will have desired state: Ready
2022-04-04 11:30:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ca7b01cc is in desired state: Ready
2022-04-04 11:30:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ca7b01cc-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:30:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:30:08 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-04 11:30:08 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-ca7b01cc-kafka are stable
2022-04-04 11:30:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:30:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:30:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:30:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:30:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:30:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:30:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:30:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:30:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:30:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:30:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:30:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:30:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:30:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:30:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:30:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:30:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:30:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:30:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:30:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:30:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:30:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:30:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:30:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:30:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:30:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:30:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:30:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:30:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:30:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:30:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:30:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:30:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:30:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:30:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:30:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:30:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:30:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:30:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:30:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:30:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:30:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:30:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:30:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:30:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:30:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:30:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:30:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:30:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:30:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:30:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:30:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:30:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:30:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:30:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:30:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:30:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:30:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:30:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:30:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:30:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:30:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:30:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:30:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:30:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:30:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:30:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:30:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:30:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:30:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:30:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:30:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:30:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:30:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:30:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:30:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:30:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:30:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:30:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:30:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:30:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:30:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:30:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:30:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:30:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:30:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:30:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:30:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:30:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:30:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:30:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:30:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:30:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:30:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:30:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:30:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:30:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:30:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:30:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:30:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:30:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:30:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:30:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:30:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:30:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:30:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:30:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:30:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:30:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:30:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:30:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:30:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:30:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:30:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:30:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:30:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:30:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:30:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:30:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:30:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:30:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:30:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:30:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:30:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:30:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:30:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:30:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:30:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:30:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:30:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:30:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:30:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:30:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:30:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:30:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:30:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:30:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:30:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:30:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:30:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:30:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:30:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:30:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:30:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:30:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:30:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:30:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:30:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:30:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:30:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:30:58 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-ca7b01cc-kafka-0 ,my-cluster-ca7b01cc-kafka-1 ,my-cluster-ca7b01cc-kafka-2
2022-04-04 11:31:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ca7b01cc-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:31:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:31:01 [main] [32mINFO [m [DynamicConfST:163] Updating listeners of Kafka cluster
2022-04-04 11:31:01 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ca7b01cc-kafka rolling update
2022-04-04 11:32:21 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ca7b01cc-kafka has been successfully rolled
2022-04-04 11:32:21 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-ca7b01cc-kafka to be ready
2022-04-04 11:32:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ca7b01cc will have desired state: Ready
2022-04-04 11:32:54 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ca7b01cc is in desired state: Ready
2022-04-04 11:32:54 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-ca7b01cc is ready
2022-04-04 11:32:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ca7b01cc-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:32:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:32:57 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-04 11:32:57 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-ca7b01cc-kafka are stable
2022-04-04 11:32:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:32:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:32:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:32:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:32:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:32:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:32:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:32:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:32:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:33:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:33:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:33:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:33:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:33:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:33:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:33:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:33:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:33:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:33:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:33:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:33:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:33:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:33:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:33:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:33:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:33:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:33:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:33:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:33:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:33:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:33:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:33:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:33:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:33:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:33:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:33:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:33:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:33:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:33:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:33:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:33:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:33:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:33:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:33:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:33:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:33:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:33:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:33:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:33:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:33:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:33:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:33:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:33:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:33:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:33:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:33:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:33:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:33:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:33:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:33:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:33:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:33:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:33:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:33:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:33:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:33:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:33:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:33:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:33:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:33:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:33:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:33:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:33:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:33:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:33:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:33:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:33:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:33:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:33:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:33:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:33:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:33:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:33:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:33:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:33:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:33:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:33:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:33:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:33:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:33:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:33:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:33:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:33:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:33:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:33:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:33:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:33:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:33:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:33:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:33:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:33:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:33:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:33:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:33:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:33:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:33:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:33:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:33:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:33:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:33:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:33:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:33:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:33:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:33:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:33:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:33:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:33:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:33:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:33:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:33:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:33:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:33:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:33:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:33:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:33:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:33:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:33:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:33:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:33:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:33:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:33:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:33:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:33:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:33:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:33:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:33:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:33:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:33:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:33:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:33:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:33:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:33:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:33:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:33:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:33:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:33:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:33:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:33:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:33:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:33:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:33:46 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-ca7b01cc-kafka-0 ,my-cluster-ca7b01cc-kafka-1 ,my-cluster-ca7b01cc-kafka-2
2022-04-04 11:33:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ca7b01cc-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:33:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:33:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ca7b01cc-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:33:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:33:52 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-04 11:33:52 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-ca7b01cc-kafka are stable
2022-04-04 11:33:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:33:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:33:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:33:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:33:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:33:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:33:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:33:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:33:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:33:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:33:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:33:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:33:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:33:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:33:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:33:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:33:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:33:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:33:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:33:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:33:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:33:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:33:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:33:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:34:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:34:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:34:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:34:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:34:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:34:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:34:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:34:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:34:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:34:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:34:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:34:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:34:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:34:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:34:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:34:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:34:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:34:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:34:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:34:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:34:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:34:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:34:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:34:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:34:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:34:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:34:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:34:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:34:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:34:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:34:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:34:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:34:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:34:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:34:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:34:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:34:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:34:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:34:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:34:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:34:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:34:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:34:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:34:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:34:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:34:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:34:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:34:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:34:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:34:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:34:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:34:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:34:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:34:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:34:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:34:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:34:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:34:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:34:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:34:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:34:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:34:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:34:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:34:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:34:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:34:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:34:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:34:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:34:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:34:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:34:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:34:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:34:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:34:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:34:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:34:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:34:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:34:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:34:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:34:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:34:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:34:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:34:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:34:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:34:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:34:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:34:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:34:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:34:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:34:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:34:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:34:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:34:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:34:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:34:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:34:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:34:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:34:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:34:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:34:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:34:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:34:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:34:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:34:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:34:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:34:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:34:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:34:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:34:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:34:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:34:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:34:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:34:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:34:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:34:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:34:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:34:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:34:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:34:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:34:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:34:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:34:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:34:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:34:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:34:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:34:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:34:42 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-ca7b01cc-kafka-0 ,my-cluster-ca7b01cc-kafka-1 ,my-cluster-ca7b01cc-kafka-2
2022-04-04 11:34:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ca7b01cc-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:34:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:34:44 [main] [32mINFO [m [DynamicConfST:214] Updating listeners of Kafka cluster
2022-04-04 11:34:44 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ca7b01cc-kafka rolling update
2022-04-04 11:36:10 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ca7b01cc-kafka has been successfully rolled
2022-04-04 11:36:10 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-ca7b01cc-kafka to be ready
2022-04-04 11:36:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ca7b01cc will have desired state: Ready
2022-04-04 11:36:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ca7b01cc is in desired state: Ready
2022-04-04 11:36:38 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-ca7b01cc is ready
2022-04-04 11:36:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ca7b01cc-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:36:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:36:40 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-04 11:36:41 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-ca7b01cc-kafka are stable
2022-04-04 11:36:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:36:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:36:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 11:36:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:36:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:36:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 11:36:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:36:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:36:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 11:36:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:36:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:36:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 11:36:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:36:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:36:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 11:36:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:36:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:36:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 11:36:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:36:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:36:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 11:36:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:36:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:36:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 11:36:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:36:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:36:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 11:36:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:36:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:36:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 11:36:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:36:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:36:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 11:36:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:36:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:36:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 11:36:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:36:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:36:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 11:36:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:36:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:36:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 11:36:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:36:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:36:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 11:36:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:36:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:36:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 11:36:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:36:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:36:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 11:36:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:36:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:36:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 11:36:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:36:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:36:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 11:37:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:37:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:37:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 11:37:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:37:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:37:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 11:37:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:37:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:37:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 11:37:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:37:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:37:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 11:37:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:37:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:37:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 11:37:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:37:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:37:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 11:37:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:37:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:37:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 11:37:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:37:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:37:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 11:37:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:37:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:37:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 11:37:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:37:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:37:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 11:37:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:37:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:37:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 11:37:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:37:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:37:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 11:37:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:37:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:37:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 11:37:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:37:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:37:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 11:37:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:37:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:37:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 11:37:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:37:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:37:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 11:37:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:37:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:37:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 11:37:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:37:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:37:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 11:37:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:37:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:37:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 11:37:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:37:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:37:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 11:37:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:37:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:37:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 11:37:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:37:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:37:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 11:37:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:37:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:37:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 11:37:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:37:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:37:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 11:37:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:37:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:37:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 11:37:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:37:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:37:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 11:37:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:37:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:37:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 11:37:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:37:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:37:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 11:37:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:37:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:37:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 11:37:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:37:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:37:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 11:37:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:37:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:37:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-ca7b01cc-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 11:37:30 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-ca7b01cc-kafka-0 ,my-cluster-ca7b01cc-kafka-1 ,my-cluster-ca7b01cc-kafka-2
2022-04-04 11:37:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-ca7b01cc-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:37:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:37:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:37:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateToExternalListenerCausesRollingRestart
2022-04-04 11:37:33 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ca7b01cc in namespace dynamic-conf-st
2022-04-04 11:37:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:37:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testUpdateToExternalListenerCausesRollingRestart-FINISHED
2022-04-04 11:37:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:37:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:37:43 [main] [32mINFO [m [ResourceManager:346] In context DynamicConfST is everything deleted.
2022-04-04 11:37:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 694.069 s - in io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-04 11:38:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: dynamic-conf-shared-st
2022-04-04 11:38:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: dynamic-conf-shared-st
2022-04-04 11:38:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: dynamic-conf-shared-st
2022-04-04 11:38:10 [main] [32mINFO [m [DynamicConfSharedST:218] Deploying shared Kafka across all test cases!
2022-04-04 11:38:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-04 11:38:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: dynamic-configuration-shared-cluster-name will have desired state: Ready
2022-04-04 11:39:28 [main] [32mINFO [m [ResourceManager:444] Kafka: dynamic-configuration-shared-cluster-name is in desired state: Ready
2022-04-04 11:39:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:39:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-STARTED
2022-04-04 11:39:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:334] Kafka config {advertised.listeners=io.strimzi.kafka.config.model.ConfigModel@357020d5, alter.config.policy.class.name=io.strimzi.kafka.config.model.ConfigModel@323a2b55, alter.log.dirs.replication.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@69942950, alter.log.dirs.replication.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@11b65246, authorizer.class.name=io.strimzi.kafka.config.model.ConfigModel@25f4be2d, auto.create.topics.enable=io.strimzi.kafka.config.model.ConfigModel@46f74945, auto.leader.rebalance.enable=io.strimzi.kafka.config.model.ConfigModel@ee12662, background.threads=io.strimzi.kafka.config.model.ConfigModel@2de6619a, broker.heartbeat.interval.ms=io.strimzi.kafka.config.model.ConfigModel@2de3b7dd, broker.id=io.strimzi.kafka.config.model.ConfigModel@51226e45, broker.id.generation.enable=io.strimzi.kafka.config.model.ConfigModel@56f78035, broker.rack=io.strimzi.kafka.config.model.ConfigModel@4803d1c0, broker.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@786eda42, client.quota.callback.class=io.strimzi.kafka.config.model.ConfigModel@3a7cc34c, compression.type=io.strimzi.kafka.config.model.ConfigModel@50601a1e, connection.failed.authentication.delay.ms=io.strimzi.kafka.config.model.ConfigModel@6bb5c03, connections.max.idle.ms=io.strimzi.kafka.config.model.ConfigModel@8093a5c, connections.max.reauth.ms=io.strimzi.kafka.config.model.ConfigModel@54b3eeb2, control.plane.listener.name=io.strimzi.kafka.config.model.ConfigModel@4d3bed0, controlled.shutdown.enable=io.strimzi.kafka.config.model.ConfigModel@58d4b10d, controlled.shutdown.max.retries=io.strimzi.kafka.config.model.ConfigModel@19ceab91, controlled.shutdown.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@52c31064, controller.listener.names=io.strimzi.kafka.config.model.ConfigModel@4bff11d2, controller.quorum.append.linger.ms=io.strimzi.kafka.config.model.ConfigModel@36de8d79, controller.quorum.election.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@5a202a10, controller.quorum.election.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@10aa4100, controller.quorum.fetch.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@23e8b346, controller.quorum.request.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@611f4707, controller.quorum.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@3ab4919e, controller.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@78546589, controller.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@1e408b46, controller.socket.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@5fcc0f6, create.topic.policy.class.name=io.strimzi.kafka.config.model.ConfigModel@1bda99b6, default.replication.factor=io.strimzi.kafka.config.model.ConfigModel@40f9cf69, delegation.token.expiry.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@5a79668b, delegation.token.expiry.time.ms=io.strimzi.kafka.config.model.ConfigModel@3961f642, delegation.token.master.key=io.strimzi.kafka.config.model.ConfigModel@76b9cff1, delegation.token.max.lifetime.ms=io.strimzi.kafka.config.model.ConfigModel@78b5d4c8, delegation.token.secret.key=io.strimzi.kafka.config.model.ConfigModel@69e9a86b, delete.records.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@5f0c90f2, delete.topic.enable=io.strimzi.kafka.config.model.ConfigModel@67f21aa5, fetch.max.bytes=io.strimzi.kafka.config.model.ConfigModel@31379107, fetch.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@15b9ddba, group.initial.rebalance.delay.ms=io.strimzi.kafka.config.model.ConfigModel@2e0944ff, group.max.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@59d944a9, group.max.size=io.strimzi.kafka.config.model.ConfigModel@546b593c, group.min.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@f640a06, initial.broker.registration.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@6bae99a9, inter.broker.listener.name=io.strimzi.kafka.config.model.ConfigModel@78c17479, inter.broker.protocol.version=io.strimzi.kafka.config.model.ConfigModel@766d60e4, kafka.metrics.polling.interval.secs=io.strimzi.kafka.config.model.ConfigModel@59766015, kafka.metrics.reporters=io.strimzi.kafka.config.model.ConfigModel@468ad943, leader.imbalance.check.interval.seconds=io.strimzi.kafka.config.model.ConfigModel@359b1f57, leader.imbalance.per.broker.percentage=io.strimzi.kafka.config.model.ConfigModel@28ec2340, listener.security.protocol.map=io.strimzi.kafka.config.model.ConfigModel@42708880, listeners=io.strimzi.kafka.config.model.ConfigModel@52a0014c, log.cleaner.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@3facdde8, log.cleaner.dedupe.buffer.size=io.strimzi.kafka.config.model.ConfigModel@76931f7e, log.cleaner.delete.retention.ms=io.strimzi.kafka.config.model.ConfigModel@3061ada4, log.cleaner.enable=io.strimzi.kafka.config.model.ConfigModel@62197085, log.cleaner.io.buffer.load.factor=io.strimzi.kafka.config.model.ConfigModel@3b83a2b3, log.cleaner.io.buffer.size=io.strimzi.kafka.config.model.ConfigModel@55053252, log.cleaner.io.max.bytes.per.second=io.strimzi.kafka.config.model.ConfigModel@68b4b9db, log.cleaner.max.compaction.lag.ms=io.strimzi.kafka.config.model.ConfigModel@41806110, log.cleaner.min.cleanable.ratio=io.strimzi.kafka.config.model.ConfigModel@67b0c5a9, log.cleaner.min.compaction.lag.ms=io.strimzi.kafka.config.model.ConfigModel@1b5becaf, log.cleaner.threads=io.strimzi.kafka.config.model.ConfigModel@566ce47e, log.cleanup.policy=io.strimzi.kafka.config.model.ConfigModel@14a69742, log.dir=io.strimzi.kafka.config.model.ConfigModel@755a95f2, log.dirs=io.strimzi.kafka.config.model.ConfigModel@31202162, log.flush.interval.messages=io.strimzi.kafka.config.model.ConfigModel@de6c2c, log.flush.interval.ms=io.strimzi.kafka.config.model.ConfigModel@2062f7f2, log.flush.offset.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@1b61309, log.flush.scheduler.interval.ms=io.strimzi.kafka.config.model.ConfigModel@312d196c, log.flush.start.offset.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@4261ac69, log.index.interval.bytes=io.strimzi.kafka.config.model.ConfigModel@750b0eb0, log.index.size.max.bytes=io.strimzi.kafka.config.model.ConfigModel@44147543, log.message.downconversion.enable=io.strimzi.kafka.config.model.ConfigModel@1dabe2d4, log.message.format.version=io.strimzi.kafka.config.model.ConfigModel@526607ec, log.message.timestamp.difference.max.ms=io.strimzi.kafka.config.model.ConfigModel@7f35ed9e, log.message.timestamp.type=io.strimzi.kafka.config.model.ConfigModel@186c2156, log.preallocate=io.strimzi.kafka.config.model.ConfigModel@5a93ddcd, log.retention.bytes=io.strimzi.kafka.config.model.ConfigModel@3828e814, log.retention.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@6821bb92, log.retention.hours=io.strimzi.kafka.config.model.ConfigModel@113e5151, log.retention.minutes=io.strimzi.kafka.config.model.ConfigModel@55878b0e, log.retention.ms=io.strimzi.kafka.config.model.ConfigModel@2a10a1e2, log.roll.hours=io.strimzi.kafka.config.model.ConfigModel@4f086219, log.roll.jitter.hours=io.strimzi.kafka.config.model.ConfigModel@2cdf0670, log.roll.jitter.ms=io.strimzi.kafka.config.model.ConfigModel@4569271e, log.roll.ms=io.strimzi.kafka.config.model.ConfigModel@6a5981e0, log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@664d3e18, log.segment.delete.delay.ms=io.strimzi.kafka.config.model.ConfigModel@32755827, max.connection.creation.rate=io.strimzi.kafka.config.model.ConfigModel@3e28c8a0, max.connections=io.strimzi.kafka.config.model.ConfigModel@18d80804, max.connections.per.ip=io.strimzi.kafka.config.model.ConfigModel@176a48f9, max.connections.per.ip.overrides=io.strimzi.kafka.config.model.ConfigModel@fc69e53, max.incremental.fetch.session.cache.slots=io.strimzi.kafka.config.model.ConfigModel@77533ac3, message.max.bytes=io.strimzi.kafka.config.model.ConfigModel@2f139405, metadata.log.dir=io.strimzi.kafka.config.model.ConfigModel@6a7b3c9e, metadata.log.max.record.bytes.between.snapshots=io.strimzi.kafka.config.model.ConfigModel@51740384, metadata.log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@3f9fae4b, metadata.log.segment.min.bytes=io.strimzi.kafka.config.model.ConfigModel@c9fa601, metadata.log.segment.ms=io.strimzi.kafka.config.model.ConfigModel@3fb3e4c0, metadata.max.retention.bytes=io.strimzi.kafka.config.model.ConfigModel@4e2aa891, metadata.max.retention.ms=io.strimzi.kafka.config.model.ConfigModel@c05aae9, metric.reporters=io.strimzi.kafka.config.model.ConfigModel@7ddbaac6, metrics.num.samples=io.strimzi.kafka.config.model.ConfigModel@5deed459, metrics.recording.level=io.strimzi.kafka.config.model.ConfigModel@461b8155, metrics.sample.window.ms=io.strimzi.kafka.config.model.ConfigModel@6768399d, min.insync.replicas=io.strimzi.kafka.config.model.ConfigModel@4745222c, node.id=io.strimzi.kafka.config.model.ConfigModel@6ca26a81, num.io.threads=io.strimzi.kafka.config.model.ConfigModel@76295f69, num.network.threads=io.strimzi.kafka.config.model.ConfigModel@50ab34e0, num.partitions=io.strimzi.kafka.config.model.ConfigModel@3e11389b, num.recovery.threads.per.data.dir=io.strimzi.kafka.config.model.ConfigModel@4198abba, num.replica.alter.log.dirs.threads=io.strimzi.kafka.config.model.ConfigModel@7df666f7, num.replica.fetchers=io.strimzi.kafka.config.model.ConfigModel@7473419d, offset.metadata.max.bytes=io.strimzi.kafka.config.model.ConfigModel@43117a68, offsets.commit.required.acks=io.strimzi.kafka.config.model.ConfigModel@4750dccb, offsets.commit.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@9dfcb08, offsets.load.buffer.size=io.strimzi.kafka.config.model.ConfigModel@674e1c07, offsets.retention.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@2fc4f8bc, offsets.retention.minutes=io.strimzi.kafka.config.model.ConfigModel@6eb3df0b, offsets.topic.compression.codec=io.strimzi.kafka.config.model.ConfigModel@19c3de5e, offsets.topic.num.partitions=io.strimzi.kafka.config.model.ConfigModel@efa4745, offsets.topic.replication.factor=io.strimzi.kafka.config.model.ConfigModel@6735f3e, offsets.topic.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@76c8837c, password.encoder.cipher.algorithm=io.strimzi.kafka.config.model.ConfigModel@717e92d5, password.encoder.iterations=io.strimzi.kafka.config.model.ConfigModel@2d6223d0, password.encoder.key.length=io.strimzi.kafka.config.model.ConfigModel@31f403ed, password.encoder.keyfactory.algorithm=io.strimzi.kafka.config.model.ConfigModel@315b5cc, password.encoder.old.secret=io.strimzi.kafka.config.model.ConfigModel@6f86741, password.encoder.secret=io.strimzi.kafka.config.model.ConfigModel@3ab8b8ed, principal.builder.class=io.strimzi.kafka.config.model.ConfigModel@2bc23f3c, process.roles=io.strimzi.kafka.config.model.ConfigModel@5d7445d, producer.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@40d0e9c9, queued.max.request.bytes=io.strimzi.kafka.config.model.ConfigModel@3f505eee, queued.max.requests=io.strimzi.kafka.config.model.ConfigModel@5d1bde7, quota.window.num=io.strimzi.kafka.config.model.ConfigModel@3a9bf4ac, quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@7d42cc97, remote.log.index.file.cache.total.size.bytes=io.strimzi.kafka.config.model.ConfigModel@40584aff, remote.log.manager.task.interval.ms=io.strimzi.kafka.config.model.ConfigModel@486ee996, remote.log.manager.task.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@2db55aa3, remote.log.manager.task.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@46f80df6, remote.log.manager.task.retry.jitter=io.strimzi.kafka.config.model.ConfigModel@44f5b864, remote.log.manager.thread.pool.size=io.strimzi.kafka.config.model.ConfigModel@7b68cb35, remote.log.metadata.manager.class.name=io.strimzi.kafka.config.model.ConfigModel@7c8ff6b9, remote.log.metadata.manager.class.path=io.strimzi.kafka.config.model.ConfigModel@7a9ed363, remote.log.metadata.manager.impl.prefix=io.strimzi.kafka.config.model.ConfigModel@134162cc, remote.log.metadata.manager.listener.name=io.strimzi.kafka.config.model.ConfigModel@2ecd32f2, remote.log.reader.max.pending.tasks=io.strimzi.kafka.config.model.ConfigModel@2df423ac, remote.log.reader.threads=io.strimzi.kafka.config.model.ConfigModel@21fdf8ba, remote.log.storage.manager.class.name=io.strimzi.kafka.config.model.ConfigModel@39b2b94b, remote.log.storage.manager.class.path=io.strimzi.kafka.config.model.ConfigModel@7e2f562d, remote.log.storage.manager.impl.prefix=io.strimzi.kafka.config.model.ConfigModel@72caf307, remote.log.storage.system.enable=io.strimzi.kafka.config.model.ConfigModel@3cbcedcc, replica.fetch.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@10e873f1, replica.fetch.max.bytes=io.strimzi.kafka.config.model.ConfigModel@1472d1ff, replica.fetch.min.bytes=io.strimzi.kafka.config.model.ConfigModel@31054abd, replica.fetch.response.max.bytes=io.strimzi.kafka.config.model.ConfigModel@6a0c13dc, replica.fetch.wait.max.ms=io.strimzi.kafka.config.model.ConfigModel@39288297, replica.high.watermark.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@3b574164, replica.lag.time.max.ms=io.strimzi.kafka.config.model.ConfigModel@201cb411, replica.selector.class=io.strimzi.kafka.config.model.ConfigModel@2a04d13d, replica.socket.receive.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@57c5c2d0, replica.socket.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@5618f52d, replication.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@13616fc3, replication.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@1f60d9ab, request.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@66ca5bd5, reserved.broker.max.id=io.strimzi.kafka.config.model.ConfigModel@776a6bbc, sasl.client.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@6f6d1de5, sasl.enabled.mechanisms=io.strimzi.kafka.config.model.ConfigModel@76592c22, sasl.jaas.config=io.strimzi.kafka.config.model.ConfigModel@42f9c5cf, sasl.kerberos.kinit.cmd=io.strimzi.kafka.config.model.ConfigModel@666a61a7, sasl.kerberos.min.time.before.relogin=io.strimzi.kafka.config.model.ConfigModel@616fdaba, sasl.kerberos.principal.to.local.rules=io.strimzi.kafka.config.model.ConfigModel@5ee8c289, sasl.kerberos.service.name=io.strimzi.kafka.config.model.ConfigModel@5233a326, sasl.kerberos.ticket.renew.jitter=io.strimzi.kafka.config.model.ConfigModel@6761979e, sasl.kerberos.ticket.renew.window.factor=io.strimzi.kafka.config.model.ConfigModel@78442bc2, sasl.login.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@60a042c9, sasl.login.class=io.strimzi.kafka.config.model.ConfigModel@2f45e768, sasl.login.connect.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@44f35879, sasl.login.read.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@1d30711e, sasl.login.refresh.buffer.seconds=io.strimzi.kafka.config.model.ConfigModel@7f64de7b, sasl.login.refresh.min.period.seconds=io.strimzi.kafka.config.model.ConfigModel@7f1a0858, sasl.login.refresh.window.factor=io.strimzi.kafka.config.model.ConfigModel@21f4a752, sasl.login.refresh.window.jitter=io.strimzi.kafka.config.model.ConfigModel@3f528af3, sasl.login.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@669c0c64, sasl.login.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@496b8027, sasl.mechanism.controller.protocol=io.strimzi.kafka.config.model.ConfigModel@4da1706f, sasl.mechanism.inter.broker.protocol=io.strimzi.kafka.config.model.ConfigModel@668f6e3a, sasl.oauthbearer.clock.skew.seconds=io.strimzi.kafka.config.model.ConfigModel@6076b1a3, sasl.oauthbearer.expected.audience=io.strimzi.kafka.config.model.ConfigModel@75096f32, sasl.oauthbearer.expected.issuer=io.strimzi.kafka.config.model.ConfigModel@336d4bf4, sasl.oauthbearer.jwks.endpoint.refresh.ms=io.strimzi.kafka.config.model.ConfigModel@2e8e0d1d, sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@7ba05ac6, sasl.oauthbearer.jwks.endpoint.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@45eeca7f, sasl.oauthbearer.jwks.endpoint.url=io.strimzi.kafka.config.model.ConfigModel@1c850bdd, sasl.oauthbearer.scope.claim.name=io.strimzi.kafka.config.model.ConfigModel@423d1bb5, sasl.oauthbearer.sub.claim.name=io.strimzi.kafka.config.model.ConfigModel@3bb21f5e, sasl.oauthbearer.token.endpoint.url=io.strimzi.kafka.config.model.ConfigModel@8bc9765, sasl.server.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@3cd3be4c, security.inter.broker.protocol=io.strimzi.kafka.config.model.ConfigModel@1619ead0, security.providers=io.strimzi.kafka.config.model.ConfigModel@3dfa4fa2, socket.connection.setup.timeout.max.ms=io.strimzi.kafka.config.model.ConfigModel@5191e0c7, socket.connection.setup.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@70110567, socket.receive.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@29872edf, socket.request.max.bytes=io.strimzi.kafka.config.model.ConfigModel@466fe312, socket.send.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@18a6b4c0, ssl.cipher.suites=io.strimzi.kafka.config.model.ConfigModel@6064a08e, ssl.client.auth=io.strimzi.kafka.config.model.ConfigModel@70058b8b, ssl.enabled.protocols=io.strimzi.kafka.config.model.ConfigModel@49cb91ea, ssl.endpoint.identification.algorithm=io.strimzi.kafka.config.model.ConfigModel@64662ca7, ssl.engine.factory.class=io.strimzi.kafka.config.model.ConfigModel@21438075, ssl.key.password=io.strimzi.kafka.config.model.ConfigModel@7dc61e05, ssl.keymanager.algorithm=io.strimzi.kafka.config.model.ConfigModel@68979496, ssl.keystore.certificate.chain=io.strimzi.kafka.config.model.ConfigModel@3d418e37, ssl.keystore.key=io.strimzi.kafka.config.model.ConfigModel@bcf1c2, ssl.keystore.location=io.strimzi.kafka.config.model.ConfigModel@4dc7f1e6, ssl.keystore.password=io.strimzi.kafka.config.model.ConfigModel@1920efec, ssl.keystore.type=io.strimzi.kafka.config.model.ConfigModel@28a1fac9, ssl.principal.mapping.rules=io.strimzi.kafka.config.model.ConfigModel@4f742cfe, ssl.protocol=io.strimzi.kafka.config.model.ConfigModel@3d4ebc37, ssl.provider=io.strimzi.kafka.config.model.ConfigModel@238f7bfd, ssl.secure.random.implementation=io.strimzi.kafka.config.model.ConfigModel@4dfbaf7, ssl.trustmanager.algorithm=io.strimzi.kafka.config.model.ConfigModel@6aa2754e, ssl.truststore.certificates=io.strimzi.kafka.config.model.ConfigModel@22c5d329, ssl.truststore.location=io.strimzi.kafka.config.model.ConfigModel@7acd041f, ssl.truststore.password=io.strimzi.kafka.config.model.ConfigModel@33c11b3, ssl.truststore.type=io.strimzi.kafka.config.model.ConfigModel@7a4d1c9f, transaction.abort.timed.out.transaction.cleanup.interval.ms=io.strimzi.kafka.config.model.ConfigModel@769dd464, transaction.max.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@64e2db54, transaction.remove.expired.transaction.cleanup.interval.ms=io.strimzi.kafka.config.model.ConfigModel@7b0eff2, transaction.state.log.load.buffer.size=io.strimzi.kafka.config.model.ConfigModel@150bb27f, transaction.state.log.min.isr=io.strimzi.kafka.config.model.ConfigModel@d2d6a4e, transaction.state.log.num.partitions=io.strimzi.kafka.config.model.ConfigModel@7f6738c4, transaction.state.log.replication.factor=io.strimzi.kafka.config.model.ConfigModel@7fa897a5, transaction.state.log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@37f85a65, transactional.id.expiration.ms=io.strimzi.kafka.config.model.ConfigModel@516139ce, unclean.leader.election.enable=io.strimzi.kafka.config.model.ConfigModel@17069a3e, zookeeper.clientCnxnSocket=io.strimzi.kafka.config.model.ConfigModel@2ca832c4, zookeeper.connect=io.strimzi.kafka.config.model.ConfigModel@59767e46, zookeeper.connection.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@10193ef, zookeeper.max.in.flight.requests=io.strimzi.kafka.config.model.ConfigModel@22f53e9b, zookeeper.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@4f260613, zookeeper.set.acl=io.strimzi.kafka.config.model.ConfigModel@2548c5ff, zookeeper.ssl.cipher.suites=io.strimzi.kafka.config.model.ConfigModel@285ba452, zookeeper.ssl.client.enable=io.strimzi.kafka.config.model.ConfigModel@23514624, zookeeper.ssl.crl.enable=io.strimzi.kafka.config.model.ConfigModel@5c38cac3, zookeeper.ssl.enabled.protocols=io.strimzi.kafka.config.model.ConfigModel@3fbc9b86, zookeeper.ssl.endpoint.identification.algorithm=io.strimzi.kafka.config.model.ConfigModel@4a30c117, zookeeper.ssl.keystore.location=io.strimzi.kafka.config.model.ConfigModel@63f9ce13, zookeeper.ssl.keystore.password=io.strimzi.kafka.config.model.ConfigModel@790d6e7d, zookeeper.ssl.keystore.type=io.strimzi.kafka.config.model.ConfigModel@2236aa71, zookeeper.ssl.ocsp.enable=io.strimzi.kafka.config.model.ConfigModel@6ec2ef59, zookeeper.ssl.protocol=io.strimzi.kafka.config.model.ConfigModel@43662dc4, zookeeper.ssl.truststore.location=io.strimzi.kafka.config.model.ConfigModel@510acd53, zookeeper.ssl.truststore.password=io.strimzi.kafka.config.model.ConfigModel@46f89021, zookeeper.ssl.truststore.type=io.strimzi.kafka.config.model.ConfigModel@3fb90780, zookeeper.sync.time.ms=io.strimzi.kafka.config.model.ConfigModel@4d4315be}
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:336] Number of all kafka configs 261
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:356] Number of dynamic-configs 40
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:364] Number of forbidden-exception-configs 7
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:371] Size of dynamic-configs with forbidden-exception-configs 46
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] compression.type -> CLUSTER_WIDE:STRING
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.min.compaction.lag.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.retention.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] max.connections.per.ip.overrides -> CLUSTER_WIDE:STRING
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] metric.reporters -> CLUSTER_WIDE:LIST
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.flush.interval.messages -> CLUSTER_WIDE:LONG
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.message.timestamp.difference.max.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.flush.interval.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] principal.builder.class -> PER_BROKER:CLASS
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.delete.retention.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.buffer.size -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] min.insync.replicas -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] zookeeper.connection.timeout.ms -> READ_ONLY:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.threads -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.max.bytes.per.second -> CLUSTER_WIDE:DOUBLE
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.min.cleanable.ratio -> CLUSTER_WIDE:DOUBLE
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] num.recovery.threads.per.data.dir -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.retention.bytes -> CLUSTER_WIDE:LONG
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] num.network.threads -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.cleanup.policy -> CLUSTER_WIDE:LIST
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.message.timestamp.type -> CLUSTER_WIDE:STRING
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.preallocate -> CLUSTER_WIDE:BOOLEAN
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.roll.jitter.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] max.connections -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] max.connections.per.ip -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] background.threads -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.message.downconversion.enable -> CLUSTER_WIDE:BOOLEAN
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] message.max.bytes -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] ssl.protocol -> PER_BROKER:STRING
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] num.partitions -> READ_ONLY:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] num.io.threads -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] ssl.enabled.protocols -> PER_BROKER:LIST
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] max.connection.creation.rate -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.roll.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] ssl.cipher.suites -> PER_BROKER:LIST
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] unclean.leader.election.enable -> CLUSTER_WIDE:BOOLEAN
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.index.interval.bytes -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.backoff.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.segment.bytes -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.buffer.load.factor -> CLUSTER_WIDE:DOUBLE
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.index.size.max.bytes -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] zookeeper.connect -> READ_ONLY:STRING
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.segment.delete.delay.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.max.compaction.lag.ms -> CLUSTER_WIDE:LONG
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] num.replica.fetchers -> CLUSTER_WIDE:INT
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.dedupe.buffer.size -> CLUSTER_WIDE:LONG
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, log.retention.bytes=44593}'
2022-04-04 11:39:28 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-04 11:40:30 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-04 11:40:30 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is log.retention.bytes=44593 and expected is log.retention.bytes=44593
2022-04-04 11:40:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:40:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:40:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-1 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:40:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:40:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-2 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:40:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:40:38 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, log.retention.bytes=44593, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-04 11:40:38 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, log.retention.bytes=44593, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, log.cleaner.io.buffer.load.factor=3.994489473520559}'
2022-04-04 11:40:38 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-04 11:41:41 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-04 11:41:41 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is log.cleaner.io.buffer.load.factor=3.994489473520559 and expected is log.cleaner.io.buffer.load.factor=3.994489473520559
2022-04-04 11:41:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:41:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:41:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-1 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:41:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:41:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-2 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:41:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:41:49 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.cleaner.io.buffer.load.factor=3.994489473520559, log.message.format.version=3.1, log.retention.bytes=44593, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-04 11:41:49 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.cleaner.io.buffer.load.factor=3.994489473520559, log.message.format.version=3.1, log.retention.bytes=44593, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, log.cleaner.io.max.bytes.per.second=7.368630267930203}'
2022-04-04 11:41:49 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-04 11:42:51 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-04 11:42:51 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is log.cleaner.io.max.bytes.per.second=7.368630267930203 and expected is log.cleaner.io.max.bytes.per.second=7.368630267930203
2022-04-04 11:42:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:42:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:42:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-1 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:42:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:43:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-2 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-04 11:43:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 11:43:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:43:00 [main] [32mINFO [m [ResourceManager:346] In context testDynConfiguration is everything deleted.
2022-04-04 11:43:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:43:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-FINISHED
2022-04-04 11:43:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:43:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:43:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for DynamicConfSharedST
2022-04-04 11:43:00 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-04 11:43:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 342.865 s - in io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.ConfigProviderST
2022-04-04 11:43:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: config-provider-st
2022-04-04 11:43:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: config-provider-st
2022-04-04 11:43:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: config-provider-st
2022-04-04 11:43:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:43:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.ConfigProviderST.testConnectWithConnectorUsingConfigAndEnvProvider-STARTED
2022-04-04 11:43:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:43:53 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-55 for test case:testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-04 11:43:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-55
2022-04-04 11:43:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-55
2022-04-04 11:43:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-55
2022-04-04 11:43:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-dfeea79a in namespace namespace-55
2022-04-04 11:43:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-04 11:43:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-dfeea79a will have desired state: Ready
2022-04-04 11:45:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-dfeea79a is in desired state: Ready
2022-04-04 11:45:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-dfeea79a in namespace namespace-55
2022-04-04 11:45:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-04 11:45:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-dfeea79a will have desired state: Ready
2022-04-04 11:46:08 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-dfeea79a is in desired state: Ready
2022-04-04 11:46:08 [main] [32mINFO [m [ConfigProviderST:100] Creating needed RoleBinding and Role for Kubernetes Config Provider
2022-04-04 11:46:08 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding connector-config-rb in namespace namespace-55
2022-04-04 11:46:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-04 11:46:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-dfeea79a in namespace namespace-55
2022-04-04 11:46:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-04 11:46:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-dfeea79a will have desired state: Ready
2022-04-04 11:46:09 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-dfeea79a is in desired state: Ready
2022-04-04 11:46:09 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 11:46:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-my-consumer-group-281158879 in namespace namespace-55
2022-04-04 11:46:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-04 11:46:09 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-my-consumer-group-281158879 will be in active state
2022-04-04 11:46:10 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-dfeea79a-connect-5977966c5f-z4kvn
2022-04-04 11:46:15 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-dfeea79a-connect-5977966c5f-z4kvn
2022-04-04 11:46:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:46:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-04 11:46:15 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding connector-config-rb in namespace namespace-55
2022-04-04 11:46:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job producer-my-consumer-group-281158879 in namespace namespace-55
2022-04-04 11:46:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-dfeea79a in namespace namespace-55
2022-04-04 11:46:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-dfeea79a in namespace namespace-55
2022-04-04 11:46:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-dfeea79a in namespace namespace-55
2022-04-04 11:46:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:46:25 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-55 for test case:testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-04 11:46:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.ConfigProviderST.testConnectWithConnectorUsingConfigAndEnvProvider-FINISHED
2022-04-04 11:46:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:46:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:46:52 [main] [32mINFO [m [ResourceManager:346] In context ConfigProviderST is everything deleted.
2022-04-04 11:46:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 184.543 s - in io.strimzi.systemtest.kafka.ConfigProviderST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.OpaIntegrationST
2022-04-04 11:46:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: opa-integration-st
2022-04-04 11:46:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: opa-integration-st
2022-04-04 11:46:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: opa-integration-st
2022-04-04 11:46:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka opa-cluster in namespace opa-integration-st
2022-04-04 11:46:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: opa-cluster will have desired state: Ready
2022-04-04 11:48:14 [main] [32mINFO [m [ResourceManager:444] Kafka: opa-cluster is in desired state: Ready
2022-04-04 11:48:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:48:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorizationSuperUser-STARTED
2022-04-04 11:48:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:48:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-14040425-468718232 in namespace opa-integration-st
2022-04-04 11:48:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-14040425-468718232 will have desired state: Ready
2022-04-04 11:48:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-14040425-468718232 is in desired state: Ready
2022-04-04 11:48:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser arnost in namespace opa-integration-st
2022-04-04 11:48:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: arnost will have desired state: Ready
2022-04-04 11:48:16 [main] [32mINFO [m [ResourceManager:444] KafkaUser: arnost is in desired state: Ready
2022-04-04 11:48:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d5bbf8df-kafka-clients in namespace opa-integration-st
2022-04-04 11:48:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d5bbf8df-kafka-clients will be ready
2022-04-04 11:48:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d5bbf8df-kafka-clients is ready
2022-04-04 11:48:17 [main] [32mINFO [m [OpaIntegrationST:120] Checking KafkaUser good-user that is able to send and receive messages to/from topic 'my-topic-14040425-468718232'
2022-04-04 11:48:17 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@451506cf, messages=[], arguments=[--topic, my-topic-14040425-468718232, --max-messages, 100, USER=arnost, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d5bbf8df-kafka-clients-8677bf4886-7hfgm', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-14040425-468718232', maxMessages=100, kafkaUsername='arnost', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2bf3f3a0}
2022-04-04 11:48:17 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-14040425-468718232 from pod my-cluster-d5bbf8df-kafka-clients-8677bf4886-7hfgm
2022-04-04 11:48:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d5bbf8df-kafka-clients-8677bf4886-7hfgm -n opa-integration-st -- /opt/kafka/producer.sh --topic my-topic-14040425-468718232 --max-messages 100 USER=arnost --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-04 11:48:21 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:48:21 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 11:48:21 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@112a82fb, messages=[], arguments=[--topic, my-topic-14040425-468718232, --max-messages, 100, --group-instance-id, instance357940209, --group-id, consumer-group-name-2, USER=arnost, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d5bbf8df-kafka-clients-8677bf4886-7hfgm', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-14040425-468718232', maxMessages=100, kafkaUsername='arnost', consumerGroupName='consumer-group-name-2', consumerInstanceId='instance357940209', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@25f00b16}
2022-04-04 11:48:21 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-14040425-468718232 from pod my-cluster-d5bbf8df-kafka-clients-8677bf4886-7hfgm
2022-04-04 11:48:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d5bbf8df-kafka-clients-8677bf4886-7hfgm -n opa-integration-st -- /opt/kafka/consumer.sh --topic my-topic-14040425-468718232 --max-messages 100 --group-instance-id instance357940209 --group-id consumer-group-name-2 USER=arnost --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-04 11:48:28 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:48:28 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:48:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:48:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOpaAuthorizationSuperUser
2022-04-04 11:48:28 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser arnost in namespace opa-integration-st
2022-04-04 11:48:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-14040425-468718232 in namespace opa-integration-st
2022-04-04 11:48:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d5bbf8df-kafka-clients in namespace opa-integration-st
2022-04-04 11:49:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:49:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorizationSuperUser-FINISHED
2022-04-04 11:49:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:49:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:49:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorization-STARTED
2022-04-04 11:49:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:49:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser good-user in namespace opa-integration-st
2022-04-04 11:49:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: good-user will have desired state: Ready
2022-04-04 11:49:10 [main] [32mINFO [m [ResourceManager:444] KafkaUser: good-user is in desired state: Ready
2022-04-04 11:49:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bad-user in namespace opa-integration-st
2022-04-04 11:49:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bad-user will have desired state: Ready
2022-04-04 11:49:11 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bad-user is in desired state: Ready
2022-04-04 11:49:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-272fb5b1-kafka-clients in namespace opa-integration-st
2022-04-04 11:49:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-272fb5b1-kafka-clients will be ready
2022-04-04 11:49:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-272fb5b1-kafka-clients is ready
2022-04-04 11:49:13 [main] [32mINFO [m [OpaIntegrationST:72] Checking KafkaUser good-user that is able to send and receive messages to/from topic 'my-topic-530023289-1771515044'
2022-04-04 11:49:13 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3a33f3ae, messages=[], arguments=[--topic, my-topic-530023289-1771515044, --max-messages, 100, USER=good_user, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-272fb5b1-kafka-clients-6c68f94944-hnc7s', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-530023289-1771515044', maxMessages=100, kafkaUsername='good-user', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1fbef3f4}
2022-04-04 11:49:13 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-530023289-1771515044 from pod my-cluster-272fb5b1-kafka-clients-6c68f94944-hnc7s
2022-04-04 11:49:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-272fb5b1-kafka-clients-6c68f94944-hnc7s -n opa-integration-st -- /opt/kafka/producer.sh --topic my-topic-530023289-1771515044 --max-messages 100 USER=good_user --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-04 11:49:18 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:49:18 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 11:49:18 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@259eb66a, messages=[], arguments=[--topic, my-topic-530023289-1771515044, --max-messages, 100, --group-instance-id, instance1852052731, --group-id, my-consumer-group-993465263, USER=good_user, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-272fb5b1-kafka-clients-6c68f94944-hnc7s', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-530023289-1771515044', maxMessages=100, kafkaUsername='good-user', consumerGroupName='my-consumer-group-993465263', consumerInstanceId='instance1852052731', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7f4b8349}
2022-04-04 11:49:18 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-530023289-1771515044 from pod my-cluster-272fb5b1-kafka-clients-6c68f94944-hnc7s
2022-04-04 11:49:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-272fb5b1-kafka-clients-6c68f94944-hnc7s -n opa-integration-st -- /opt/kafka/consumer.sh --topic my-topic-530023289-1771515044 --max-messages 100 --group-instance-id instance1852052731 --group-id my-consumer-group-993465263 USER=good_user --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-04 11:49:26 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:49:26 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 11:49:26 [main] [32mINFO [m [OpaIntegrationST:89] Checking KafkaUser bad-user that is not able to send or receive messages to/from topic 'my-topic-530023289-1771515044'
2022-04-04 11:49:26 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@685ce4e9, messages=[], arguments=[--topic, my-topic-530023289-1771515044, --max-messages, 100, USER=bad_user, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-272fb5b1-kafka-clients-6c68f94944-hnc7s', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-530023289-1771515044', maxMessages=100, kafkaUsername='bad-user', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4dd7d07e}
2022-04-04 11:49:26 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-530023289-1771515044 from pod my-cluster-272fb5b1-kafka-clients-6c68f94944-hnc7s
2022-04-04 11:49:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-272fb5b1-kafka-clients-6c68f94944-hnc7s -n opa-integration-st -- /opt/kafka/producer.sh --topic my-topic-530023289-1771515044 --max-messages 100 USER=bad_user --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-04 11:49:30 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 11:49:30 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced -1 messages
2022-04-04 11:49:30 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1bd3a199, messages=[], arguments=[--topic, my-topic-530023289-1771515044, --max-messages, 100, --group-instance-id, instance996105684, --group-id, my-consumer-group-993465263, USER=bad_user, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-272fb5b1-kafka-clients-6c68f94944-hnc7s', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-530023289-1771515044', maxMessages=100, kafkaUsername='bad-user', consumerGroupName='my-consumer-group-993465263', consumerInstanceId='instance996105684', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4bae6360}
2022-04-04 11:49:30 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-530023289-1771515044 from pod my-cluster-272fb5b1-kafka-clients-6c68f94944-hnc7s
2022-04-04 11:49:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-272fb5b1-kafka-clients-6c68f94944-hnc7s -n opa-integration-st -- /opt/kafka/consumer.sh --topic my-topic-530023289-1771515044 --max-messages 100 --group-instance-id instance996105684 --group-id my-consumer-group-993465263 USER=bad_user --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093
2022-04-04 11:49:56 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 11:49:56 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 0 messages
2022-04-04 11:49:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:49:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOpaAuthorization
2022-04-04 11:49:56 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bad-user in namespace opa-integration-st
2022-04-04 11:49:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser good-user in namespace opa-integration-st
2022-04-04 11:49:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-272fb5b1-kafka-clients in namespace opa-integration-st
2022-04-04 11:50:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:50:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorization-FINISHED
2022-04-04 11:50:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:50:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:50:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OpaIntegrationST
2022-04-04 11:50:46 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka opa-cluster in namespace opa-integration-st
2022-04-04 11:50:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 265.84 s - in io.strimzi.systemtest.security.OpaIntegrationST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.SecurityST
2022-04-04 11:51:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: security-st
2022-04-04 11:51:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: security-st
2022-04-04 11:51:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: security-st
2022-04-04 11:51:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:51:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-STARTED
2022-04-04 11:51:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:51:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-56 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-04 11:51:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-56
2022-04-04 11:51:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-56
2022-04-04 11:51:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-56
2022-04-04 11:51:24 [main] [32mINFO [m [SecretUtils:70] Creating secret my-cluster-3fc38684-cluster-ca-cert
2022-04-04 11:51:24 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 11:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3fc38684 in namespace namespace-56
2022-04-04 11:51:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-04 11:51:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3fc38684 will have desired state: Ready
2022-04-04 11:53:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3fc38684 is in desired state: Ready
2022-04-04 11:53:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1178654218-520584636 in namespace namespace-56
2022-04-04 11:53:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-04 11:53:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1178654218-520584636 will have desired state: Ready
2022-04-04 11:53:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1178654218-520584636 is in desired state: Ready
2022-04-04 11:53:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-760979466-900579046 in namespace namespace-56
2022-04-04 11:53:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-04 11:53:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-760979466-900579046 will have desired state: Ready
2022-04-04 11:53:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-760979466-900579046 is in desired state: Ready
2022-04-04 11:53:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3fc38684-kafka-clients in namespace namespace-56
2022-04-04 11:53:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-04 11:53:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3fc38684-kafka-clients will be ready
2022-04-04 11:53:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3fc38684-kafka-clients is ready
2022-04-04 11:53:51 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:53:51 [main] [32mINFO [m [SecurityST:660] Checking produced and consumed messages to pod:my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb
2022-04-04 11:53:51 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@17db0fad, messages=[], arguments=[--topic, my-topic-760979466-900579046, --max-messages, 100, --bootstrap-server, my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb', podNamespace='namespace-56', bootstrapServer='my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-760979466-900579046', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@59546b04}
2022-04-04 11:53:51 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092:my-topic-760979466-900579046 from pod my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb
2022-04-04 11:53:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb -n namespace-56 -- /opt/kafka/producer.sh --topic my-topic-760979466-900579046 --max-messages 100 --bootstrap-server my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092
2022-04-04 11:53:54 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 11:53:54 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 11:53:54 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3ba15499, messages=[], arguments=[--topic, my-topic-760979466-900579046, --max-messages, 100, --group-instance-id, instance1087848263, --group-id, my-consumer-group-1762828617, --bootstrap-server, my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb', podNamespace='namespace-56', bootstrapServer='my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-760979466-900579046', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1762828617', consumerInstanceId='instance1087848263', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@41d71bec}
2022-04-04 11:53:54 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092#my-topic-760979466-900579046 from pod my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb
2022-04-04 11:53:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb -n namespace-56 -- /opt/kafka/consumer.sh --topic my-topic-760979466-900579046 --max-messages 100 --group-instance-id instance1087848263 --group-id my-consumer-group-1762828617 --bootstrap-server my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092
2022-04-04 11:54:00 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 11:54:00 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 11:54:00 [main] [32mINFO [m [SecretUtils:131] Waiting for Secret my-cluster-3fc38684-cluster-ca-cert certificate change
2022-04-04 11:54:00 [main] [32mINFO [m [SecretUtils:138] Certificate in Secret my-cluster-3fc38684-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUYGUMYOBwClzeYK6Cy1l00JRxJ/IwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDQxMTUxMjRaFw0yMzA0MDQxMTUxMjRaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQDUpAmPPq8KE87XBOsjbC2HfvU8clE2m8+XORJG4QwW
9tKNvwb6hYPVfn8Bl6pAsPOhytJZF+zenHypAwORGxeT2oPxwsIrRub9z47/C1wZ
u6occqmuwhV8/EoDInNZnqcOqviiG04xMxDG+TGqOe0CW+VGXJFIGZjdx0yiglo/
n6X1GUPoCawen7cpAIQrN4BiLUtu7Rq9IyBE7GnXqKDjmVgnvIgIHdJdaH7VQIi5
iiycpPcGI8ge8KjKMW5CT8eNxsnYoMl2NM9xbd52VT0LsMaEAngf06w99pbXP51w
P1zMKZ3SlkPKVjYd8jGsSukT5GvNgQ8gidRHaycyD/yUVrBcTZvWEGidOo9891bs
+dP3bVsT4BpOvDhFpl1xh07F2TxH/+zBjlAvWC23uBJPLwnLPrtk0cZhzmIKe3Mv
Hye7bq4Z7VNJcZzWyoyqcSbfSdxQ51nPXJSpF66LDNUDKzZqs87xtbeL1Fd4TNG+
gAvA6jAoc9QDD0+fDAVgS0czXSoUElsKIBbNoMmFbcu1mkYzU3VoSAI0G3bdhAiy
vR22KBMcLNniBKoKBDXVBwkjjAItKB2k805j1MRDdL0RP6AlrP1n4fmSWMHG7LhC
acXbekd6SHBLah+NeAm6mp4YMibsphrXwMsaOqBwUaGFpovphDMkCFlwR0US5z/N
awIDAQABo0UwQzAdBgNVHQ4EFgQU76tsjL/X9UpDwuVOWj5nwaPE1m8wEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AJvajMzLqYa44AFtnBJFudyGkxNdo3onpCJMNBgShbLyGGy+LUe5aCBFcsNCPm6i
diEnzQkHK8qBYE1RAGwvapPVlgvsMCy/WF3mDgoVGyh/ERXtnm58fNEjL4ffKDrr
H57pOqIm01pcgY13MjM8MwbKGDnjrvOBBQC1KwlnG1kGGvYM3BcdDOhkzL6hKI3H
Nm6R+EER24Rrxbo6E9wIe4tv2O86z4ZyOV3R4tLxisX0nQDlAtkcSj41PfIkHANz
O9gHj0QWgF73bnjfU1wTleFJjSIZ84vesNTxrQ3Tcp5z8FtHaLFbYwEvotPNyYwp
1hKypfVlIcpRUaQbO0d8F6RcuY+eMOwdBNX7ys4uelBGwLh+rqys8U3ZJIebe0XE
pspUaowSzibkLyPWa7MRHsZg0HxwXH0J0UkvpNL6XK8F7orF5RnwhADlwksjHul6
GjMM2rre1sTJQnLiY2ITAh9mIO29CRP223oQqYt+Oa8SeF0m9WqHKKvOJkw51irf
/2tP09cohiJTTXTwXyJX/pWbUCboM6JLJsXIDQeDo8+kXXcXp581yPp8xicOghyw
wbDAkQh+txmAmeks7gN5uiWTF6LLxkFqcjVnBNI8MFwTZgGCZrxcxCxLl8yNH8vQ
bfAxwylwImAdxebIYXhfQ3Tvjl287DJ2Ok4ZwLk0xsrZ
-----END CERTIFICATE-----

2022-04-04 11:54:00 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-04 11:55:02 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-04 11:55:02 [main] [32mINFO [m [SecurityST:672] Checking produced and consumed messages to pod:my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb
2022-04-04 11:55:02 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2378ad42, messages=[], arguments=[--topic, my-topic-760979466-900579046, --max-messages, 100, --bootstrap-server, my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb', podNamespace='namespace-56', bootstrapServer='my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-760979466-900579046', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5a89d584}
2022-04-04 11:55:02 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092:my-topic-760979466-900579046 from pod my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb
2022-04-04 11:55:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb -n namespace-56 -- /opt/kafka/producer.sh --topic my-topic-760979466-900579046 --max-messages 100 --bootstrap-server my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092
2022-04-04 11:55:04 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 11:55:04 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 11:55:04 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@369415c9, messages=[], arguments=[--topic, my-topic-760979466-900579046, --max-messages, 100, --group-instance-id, instance1854368083, --group-id, my-consumer-group-1762828617, --bootstrap-server, my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb', podNamespace='namespace-56', bootstrapServer='my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-760979466-900579046', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1762828617', consumerInstanceId='instance1854368083', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@22a5c1ec}
2022-04-04 11:55:04 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092#my-topic-760979466-900579046 from pod my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb
2022-04-04 11:55:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3fc38684-kafka-clients-567dcb56d4-dq8rb -n namespace-56 -- /opt/kafka/consumer.sh --topic my-topic-760979466-900579046 --max-messages 100 --group-instance-id instance1854368083 --group-id my-consumer-group-1762828617 --bootstrap-server my-cluster-3fc38684-kafka-bootstrap.namespace-56.svc:9092
2022-04-04 11:55:10 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 11:55:10 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 11:55:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 11:55:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-04 11:55:10 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-760979466-900579046 in namespace namespace-56
2022-04-04 11:55:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1178654218-520584636 in namespace namespace-56
2022-04-04 11:55:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3fc38684 in namespace namespace-56
2022-04-04 11:55:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-56, for cruise control Kafka cluster my-cluster-3fc38684
2022-04-04 11:55:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3fc38684-kafka-clients in namespace namespace-56
2022-04-04 11:56:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 11:56:00 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-56 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-04 11:56:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-FINISHED
2022-04-04 11:56:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 11:56:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 11:56:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-STARTED
2022-04-04 11:56:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 11:56:06 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-57 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-04 11:56:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-57
2022-04-04 11:56:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-57
2022-04-04 11:56:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-57
2022-04-04 11:56:06 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 11:56:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b5326001 in namespace namespace-57
2022-04-04 11:56:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-04 11:56:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b5326001 will have desired state: Ready
2022-04-04 11:58:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b5326001 is in desired state: Ready
2022-04-04 11:58:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1794534962-706352088 in namespace namespace-57
2022-04-04 11:58:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-04 11:58:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1794534962-706352088 will have desired state: Ready
2022-04-04 11:58:37 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1794534962-706352088 is in desired state: Ready
2022-04-04 11:58:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-231766345-2115579963 in namespace namespace-57
2022-04-04 11:58:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-04 11:58:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-231766345-2115579963 will have desired state: Ready
2022-04-04 11:58:38 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-231766345-2115579963 is in desired state: Ready
2022-04-04 11:58:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b5326001-kafka-clients in namespace namespace-57
2022-04-04 11:58:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-04 11:58:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b5326001-kafka-clients will be ready
2022-04-04 11:58:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b5326001-kafka-clients is ready
2022-04-04 11:58:40 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 11:58:40 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-b5326001-kafka-clients-869c5b8695-q24km
2022-04-04 11:58:40 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3954f6fd, messages=[], arguments=[--topic, my-topic-231766345-2115579963, --max-messages, 100, --bootstrap-server, my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b5326001-kafka-clients-869c5b8695-q24km', podNamespace='namespace-57', bootstrapServer='my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-231766345-2115579963', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2ff88496}
2022-04-04 11:58:40 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092:my-topic-231766345-2115579963 from pod my-cluster-b5326001-kafka-clients-869c5b8695-q24km
2022-04-04 11:58:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b5326001-kafka-clients-869c5b8695-q24km -n namespace-57 -- /opt/kafka/producer.sh --topic my-topic-231766345-2115579963 --max-messages 100 --bootstrap-server my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092
2022-04-04 11:58:43 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 11:58:43 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 11:58:43 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5065105c, messages=[], arguments=[--topic, my-topic-231766345-2115579963, --max-messages, 100, --group-instance-id, instance155814021, --group-id, my-consumer-group-38592262, --bootstrap-server, my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b5326001-kafka-clients-869c5b8695-q24km', podNamespace='namespace-57', bootstrapServer='my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-231766345-2115579963', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-38592262', consumerInstanceId='instance155814021', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3bd2ff84}
2022-04-04 11:58:43 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092#my-topic-231766345-2115579963 from pod my-cluster-b5326001-kafka-clients-869c5b8695-q24km
2022-04-04 11:58:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b5326001-kafka-clients-869c5b8695-q24km -n namespace-57 -- /opt/kafka/consumer.sh --topic my-topic-231766345-2115579963 --max-messages 100 --group-instance-id instance155814021 --group-id my-consumer-group-38592262 --bootstrap-server my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092
2022-04-04 11:58:49 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 11:58:49 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 11:58:49 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-04 11:58:49 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-b5326001-clients-ca with strimzi.io/force-replace
2022-04-04 11:58:49 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-04 11:58:49 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-b5326001-kafka rolling update
2022-04-04 12:00:29 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-b5326001-kafka has been successfully rolled
2022-04-04 12:00:29 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-04 12:00:29 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-b5326001-kafka rolling update
2022-04-04 12:02:14 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-b5326001-kafka has been successfully rolled
2022-04-04 12:02:14 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-b5326001-kafka to be ready
2022-04-04 12:02:44 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-04 12:02:44 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-b5326001-kafka-clients-869c5b8695-q24km
2022-04-04 12:02:44 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@eddc0f8, messages=[], arguments=[--topic, my-topic-231766345-2115579963, --max-messages, 100, --group-instance-id, instance618688789, --group-id, my-consumer-group-869997959, --bootstrap-server, my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b5326001-kafka-clients-869c5b8695-q24km', podNamespace='namespace-57', bootstrapServer='my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-231766345-2115579963', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-869997959', consumerInstanceId='instance618688789', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@37f4baac}
2022-04-04 12:02:44 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092#my-topic-231766345-2115579963 from pod my-cluster-b5326001-kafka-clients-869c5b8695-q24km
2022-04-04 12:02:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b5326001-kafka-clients-869c5b8695-q24km -n namespace-57 -- /opt/kafka/consumer.sh --topic my-topic-231766345-2115579963 --max-messages 100 --group-instance-id instance618688789 --group-id my-consumer-group-869997959 --bootstrap-server my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092
2022-04-04 12:02:50 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:02:50 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:02:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2098203308-1780489803 in namespace namespace-57
2022-04-04 12:02:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-04 12:02:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2098203308-1780489803 will have desired state: Ready
2022-04-04 12:02:51 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2098203308-1780489803 is in desired state: Ready
2022-04-04 12:02:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b5326001-kafka-clients-tls in namespace namespace-57
2022-04-04 12:02:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-04 12:02:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b5326001-kafka-clients-tls will be ready
2022-04-04 12:02:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b5326001-kafka-clients-tls is ready
2022-04-04 12:02:53 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-b5326001-kafka-clients-tls-795fd5ff98-5mc4s
2022-04-04 12:02:53 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4d4e1369, messages=[], arguments=[--topic, my-topic-231766345-2115579963, --max-messages, 100, --group-instance-id, instance177660268, --group-id, my-consumer-group-1943813983, --bootstrap-server, my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b5326001-kafka-clients-tls-795fd5ff98-5mc4s', podNamespace='namespace-57', bootstrapServer='my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-231766345-2115579963', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1943813983', consumerInstanceId='instance177660268', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5f7df3f0}
2022-04-04 12:02:53 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092#my-topic-231766345-2115579963 from pod my-cluster-b5326001-kafka-clients-tls-795fd5ff98-5mc4s
2022-04-04 12:02:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b5326001-kafka-clients-tls-795fd5ff98-5mc4s -n namespace-57 -- /opt/kafka/consumer.sh --topic my-topic-231766345-2115579963 --max-messages 100 --group-instance-id instance177660268 --group-id my-consumer-group-1943813983 --bootstrap-server my-cluster-b5326001-kafka-bootstrap.namespace-57.svc:9092
2022-04-04 12:02:59 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:02:59 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:02:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:02:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-04 12:02:59 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b5326001-kafka-clients in namespace namespace-57
2022-04-04 12:02:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1794534962-706352088 in namespace namespace-57
2022-04-04 12:02:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b5326001 in namespace namespace-57
2022-04-04 12:02:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-57, for cruise control Kafka cluster my-cluster-b5326001
2022-04-04 12:02:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-231766345-2115579963 in namespace namespace-57
2022-04-04 12:03:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b5326001-kafka-clients-tls in namespace namespace-57
2022-04-04 12:03:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2098203308-1780489803 in namespace namespace-57
2022-04-04 12:03:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 12:03:49 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-57 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-04 12:03:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-FINISHED
2022-04-04 12:03:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 12:03:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 12:03:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-STARTED
2022-04-04 12:03:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 12:03:56 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-58 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-04-04 12:03:56 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-58
2022-04-04 12:03:56 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-58
2022-04-04 12:03:56 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-58
2022-04-04 12:03:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-615bf66b-source in namespace namespace-58
2022-04-04 12:03:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-04 12:03:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-615bf66b-source will have desired state: Ready
2022-04-04 12:05:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-615bf66b-source is in desired state: Ready
2022-04-04 12:05:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-615bf66b-target in namespace namespace-58
2022-04-04 12:05:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-04 12:05:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-615bf66b-target will have desired state: Ready
2022-04-04 12:06:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-615bf66b-target is in desired state: Ready
2022-04-04 12:06:15 [main] [32mINFO [m [SecurityST:888] Getting IP of the source bootstrap service for consumer
2022-04-04 12:06:15 [main] [32mINFO [m [SecurityST:891] Getting IP of the target bootstrap service for producer
2022-04-04 12:06:15 [main] [32mINFO [m [SecurityST:894] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to consumer with address 10.106.92.127:9093
2022-04-04 12:06:15 [main] [32mINFO [m [SecurityST:895] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to producer with address 10.108.189.138:9093
2022-04-04 12:06:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-615bf66b in namespace namespace-58
2022-04-04 12:06:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-04 12:06:15 [main] [32mINFO [m [PodUtils:245] Wait until Pod my-cluster-615bf66b-mirror-maker is present
2022-04-04 12:06:16 [main] [32mINFO [m [PodUtils:249] Pod my-cluster-615bf66b-mirror-maker is present
2022-04-04 12:06:16 [main] [32mINFO [m [PodUtils:236] Wait until Pod my-cluster-615bf66b-mirror-maker-c5f778bb-7dkfg is in CrashLoopBackOff state
2022-04-04 12:06:31 [main] [32mINFO [m [PodUtils:241] Pod my-cluster-615bf66b-mirror-maker-c5f778bb-7dkfg is in CrashLoopBackOff state
2022-04-04 12:06:31 [main] [32mINFO [m [SecurityST:930] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to consumer with address 10.106.92.127:9093
2022-04-04 12:06:31 [main] [32mINFO [m [SecurityST:931] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to producer with address 10.108.189.138:9093
2022-04-04 12:06:31 [main] [32mINFO [m [SecurityST:933] Adding configuration ssl.endpoint.identification.algorithm to the mirror maker...
2022-04-04 12:06:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-615bf66b will have desired state: Ready
2022-04-04 12:12:29 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-615bf66b is in desired state: Ready
2022-04-04 12:12:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:12:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsHostnameVerificationWithMirrorMaker
2022-04-04 12:12:29 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-615bf66b-target in namespace namespace-58
2022-04-04 12:12:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-615bf66b in namespace namespace-58
2022-04-04 12:12:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-615bf66b-source in namespace namespace-58
2022-04-04 12:12:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 12:12:49 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-58 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-04-04 12:13:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-FINISHED
2022-04-04 12:13:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 12:13:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 12:13:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-STARTED
2022-04-04 12:13:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 12:13:16 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-59 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-04 12:13:16 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-59
2022-04-04 12:13:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-59
2022-04-04 12:13:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-59
2022-04-04 12:13:16 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 12:13:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a2ae6d91 in namespace namespace-59
2022-04-04 12:13:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-04 12:13:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a2ae6d91 will have desired state: Ready
2022-04-04 12:15:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a2ae6d91 is in desired state: Ready
2022-04-04 12:15:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2030692313-1793878066 in namespace namespace-59
2022-04-04 12:15:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-04 12:15:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2030692313-1793878066 will have desired state: Ready
2022-04-04 12:15:20 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2030692313-1793878066 is in desired state: Ready
2022-04-04 12:15:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2075378949-2115640821 in namespace namespace-59
2022-04-04 12:15:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-04 12:15:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2075378949-2115640821 will have desired state: Ready
2022-04-04 12:15:21 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2075378949-2115640821 is in desired state: Ready
2022-04-04 12:15:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a2ae6d91-kafka-clients in namespace namespace-59
2022-04-04 12:15:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-04 12:15:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a2ae6d91-kafka-clients will be ready
2022-04-04 12:15:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a2ae6d91-kafka-clients is ready
2022-04-04 12:15:23 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 12:15:23 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-a2ae6d91-kafka-clients-67df4ff9f7-xt9d8
2022-04-04 12:15:23 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@432184df, messages=[], arguments=[--topic, my-topic-2075378949-2115640821, --max-messages, 100, --bootstrap-server, my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a2ae6d91-kafka-clients-67df4ff9f7-xt9d8', podNamespace='namespace-59', bootstrapServer='my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-2075378949-2115640821', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@59ad86db}
2022-04-04 12:15:23 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9092:my-topic-2075378949-2115640821 from pod my-cluster-a2ae6d91-kafka-clients-67df4ff9f7-xt9d8
2022-04-04 12:15:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a2ae6d91-kafka-clients-67df4ff9f7-xt9d8 -n namespace-59 -- /opt/kafka/producer.sh --topic my-topic-2075378949-2115640821 --max-messages 100 --bootstrap-server my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9092
2022-04-04 12:15:26 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 12:15:26 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 12:15:26 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5869142a, messages=[], arguments=[--topic, my-topic-2075378949-2115640821, --max-messages, 100, --group-instance-id, instance921383456, --group-id, my-consumer-group-992146395, --bootstrap-server, my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a2ae6d91-kafka-clients-67df4ff9f7-xt9d8', podNamespace='namespace-59', bootstrapServer='my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-2075378949-2115640821', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-992146395', consumerInstanceId='instance921383456', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6d47cc07}
2022-04-04 12:15:26 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9092#my-topic-2075378949-2115640821 from pod my-cluster-a2ae6d91-kafka-clients-67df4ff9f7-xt9d8
2022-04-04 12:15:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a2ae6d91-kafka-clients-67df4ff9f7-xt9d8 -n namespace-59 -- /opt/kafka/consumer.sh --topic my-topic-2075378949-2115640821 --max-messages 100 --group-instance-id instance921383456 --group-id my-consumer-group-992146395 --bootstrap-server my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9092
2022-04-04 12:15:32 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:15:32 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:15:32 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-04 12:15:32 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-a2ae6d91-cluster-ca-cert with strimzi.io/force-renew
2022-04-04 12:15:32 [main] [32mINFO [m [SecurityST:291] Wait for zk to rolling restart ...
2022-04-04 12:15:32 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a2ae6d91-zookeeper rolling update
2022-04-04 12:16:47 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a2ae6d91-zookeeper has been successfully rolled
2022-04-04 12:16:47 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-a2ae6d91-zookeeper to be ready
2022-04-04 12:17:17 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-04 12:17:17 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a2ae6d91-kafka rolling update
2022-04-04 12:18:17 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a2ae6d91-kafka has been successfully rolled
2022-04-04 12:18:17 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-a2ae6d91-kafka to be ready
2022-04-04 12:18:51 [main] [32mINFO [m [SecurityST:299] Wait for EO to rolling restart ...
2022-04-04 12:18:51 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a2ae6d91-entity-operator rolling update
2022-04-04 12:18:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a2ae6d91-entity-operator will be ready
2022-04-04 12:26:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a2ae6d91-entity-operator is ready
2022-04-04 12:26:27 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a2ae6d91-entity-operator rolling update finished
2022-04-04 12:26:27 [main] [32mINFO [m [SecurityST:303] Wait for CC and KE to rolling restart ...
2022-04-04 12:26:27 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a2ae6d91-kafka-exporter rolling update
2022-04-04 12:27:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a2ae6d91-kafka-exporter will be ready
2022-04-04 12:27:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a2ae6d91-kafka-exporter is ready
2022-04-04 12:27:37 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a2ae6d91-kafka-exporter rolling update finished
2022-04-04 12:27:37 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a2ae6d91-cruise-control rolling update
2022-04-04 12:27:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a2ae6d91-cruise-control will be ready
2022-04-04 12:27:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a2ae6d91-cruise-control is ready
2022-04-04 12:27:47 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a2ae6d91-cruise-control rolling update finished
2022-04-04 12:27:47 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-04 12:27:47 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-a2ae6d91-kafka-clients-67df4ff9f7-xt9d8
2022-04-04 12:27:47 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@15963000, messages=[], arguments=[--topic, my-topic-2075378949-2115640821, --max-messages, 100, --group-instance-id, instance1543396190, --group-id, my-consumer-group-1316034162, --bootstrap-server, my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a2ae6d91-kafka-clients-67df4ff9f7-xt9d8', podNamespace='namespace-59', bootstrapServer='my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-2075378949-2115640821', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1316034162', consumerInstanceId='instance1543396190', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3d752234}
2022-04-04 12:27:47 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9092#my-topic-2075378949-2115640821 from pod my-cluster-a2ae6d91-kafka-clients-67df4ff9f7-xt9d8
2022-04-04 12:27:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a2ae6d91-kafka-clients-67df4ff9f7-xt9d8 -n namespace-59 -- /opt/kafka/consumer.sh --topic my-topic-2075378949-2115640821 --max-messages 100 --group-instance-id instance1543396190 --group-id my-consumer-group-1316034162 --bootstrap-server my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9092
2022-04-04 12:27:53 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:27:53 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:27:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-a2ae6d91 in namespace namespace-59
2022-04-04 12:27:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-04 12:27:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-a2ae6d91 will have desired state: Ready
2022-04-04 12:27:54 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-a2ae6d91 is in desired state: Ready
2022-04-04 12:27:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a2ae6d91-kafka-clients-tls in namespace namespace-59
2022-04-04 12:27:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-04 12:27:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a2ae6d91-kafka-clients-tls will be ready
2022-04-04 12:27:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a2ae6d91-kafka-clients-tls is ready
2022-04-04 12:27:56 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-a2ae6d91-kafka-clients-tls-56bf567676-qxfdw
2022-04-04 12:27:56 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@19521976, messages=[], arguments=[--topic, my-topic-2075378949-2115640821, --max-messages, 100, --group-instance-id, instance859392334, --group-id, my-consumer-group-2024593035, USER=bob_my_cluster_a2ae6d91, --bootstrap-server, my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a2ae6d91-kafka-clients-tls-56bf567676-qxfdw', podNamespace='namespace-59', bootstrapServer='my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9093', topicName='my-topic-2075378949-2115640821', maxMessages=100, kafkaUsername='bob-my-cluster-a2ae6d91', consumerGroupName='my-consumer-group-2024593035', consumerInstanceId='instance859392334', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@da2ee74}
2022-04-04 12:27:56 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9093#my-topic-2075378949-2115640821 from pod my-cluster-a2ae6d91-kafka-clients-tls-56bf567676-qxfdw
2022-04-04 12:27:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a2ae6d91-kafka-clients-tls-56bf567676-qxfdw -n namespace-59 -- /opt/kafka/consumer.sh --topic my-topic-2075378949-2115640821 --max-messages 100 --group-instance-id instance859392334 --group-id my-consumer-group-2024593035 USER=bob_my_cluster_a2ae6d91 --bootstrap-server my-cluster-a2ae6d91-kafka-bootstrap.namespace-59.svc:9093
2022-04-04 12:28:04 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:28:04 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:28:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:28:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-04 12:28:04 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a2ae6d91-kafka-clients in namespace namespace-59
2022-04-04 12:28:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a2ae6d91-kafka-clients-tls in namespace namespace-59
2022-04-04 12:28:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2030692313-1793878066 in namespace namespace-59
2022-04-04 12:28:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-a2ae6d91 in namespace namespace-59
2022-04-04 12:28:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2075378949-2115640821 in namespace namespace-59
2022-04-04 12:28:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a2ae6d91 in namespace namespace-59
2022-04-04 12:28:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-59, for cruise control Kafka cluster my-cluster-a2ae6d91
2022-04-04 12:28:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 12:28:54 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-59 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-04 12:29:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-FINISHED
2022-04-04 12:29:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 12:29:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 12:29:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-STARTED
2022-04-04 12:29:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 12:29:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-60 for test case:testCaRenewalBreakInMiddle
2022-04-04 12:29:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-60
2022-04-04 12:29:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-60
2022-04-04 12:29:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-60
2022-04-04 12:29:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-09317a8f in namespace namespace-60
2022-04-04 12:29:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-04 12:29:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-09317a8f will have desired state: Ready
2022-04-04 12:30:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-09317a8f is in desired state: Ready
2022-04-04 12:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2072439778-1517208714 in namespace namespace-60
2022-04-04 12:30:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-04 12:30:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2072439778-1517208714 will have desired state: Ready
2022-04-04 12:30:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2072439778-1517208714 is in desired state: Ready
2022-04-04 12:30:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-787071919-1319940386 in namespace namespace-60
2022-04-04 12:30:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-04 12:30:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-787071919-1319940386 will have desired state: Ready
2022-04-04 12:30:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-787071919-1319940386 is in desired state: Ready
2022-04-04 12:30:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-09317a8f-kafka-clients in namespace namespace-60
2022-04-04 12:30:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-04 12:30:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-09317a8f-kafka-clients will be ready
2022-04-04 12:30:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-09317a8f-kafka-clients is ready
2022-04-04 12:30:16 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 12:30:16 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6b894822, messages=[], arguments=[--topic, my-topic-787071919-1319940386, --max-messages, 100, USER=my_user_2072439778_1517208714, --bootstrap-server, my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9', podNamespace='namespace-60', bootstrapServer='my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-787071919-1319940386', maxMessages=100, kafkaUsername='my-user-2072439778-1517208714', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1c0ef02d}
2022-04-04 12:30:16 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093:my-topic-787071919-1319940386 from pod my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9
2022-04-04 12:30:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9 -n namespace-60 -- /opt/kafka/producer.sh --topic my-topic-787071919-1319940386 --max-messages 100 USER=my_user_2072439778_1517208714 --bootstrap-server my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093
2022-04-04 12:30:20 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 12:30:20 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 12:30:20 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@62535806, messages=[], arguments=[--topic, my-topic-787071919-1319940386, --max-messages, 100, --group-instance-id, instance1623516266, --group-id, my-consumer-group-185294667, USER=my_user_2072439778_1517208714, --bootstrap-server, my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9', podNamespace='namespace-60', bootstrapServer='my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-787071919-1319940386', maxMessages=100, kafkaUsername='my-user-2072439778-1517208714', consumerGroupName='my-consumer-group-185294667', consumerInstanceId='instance1623516266', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@9b75e85}
2022-04-04 12:30:20 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093:my-topic-787071919-1319940386 from pod my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9
2022-04-04 12:30:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9 -n namespace-60 -- /opt/kafka/consumer.sh --topic my-topic-787071919-1319940386 --max-messages 100 --group-instance-id instance1623516266 --group-id my-consumer-group-185294667 USER=my_user_2072439778_1517208714 --bootstrap-server my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093
2022-04-04 12:30:27 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 12:30:27 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 12:30:27 [main] [32mINFO [m [SecretUtils:70] Creating secret my-cluster-09317a8f-cluster-ca-cert
2022-04-04 12:30:27 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-09317a8f-zookeeper are in desired state
2022-04-04 12:30:28 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-09317a8f-zookeeper are in desired state
2022-04-04 12:30:29 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-09317a8f-zookeeper are in desired state
2022-04-04 12:30:30 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-09317a8f-zookeeper are in desired state
2022-04-04 12:30:31 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-09317a8f-zookeeper are in desired state
2022-04-04 12:30:32 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-09317a8f-zookeeper are in desired state
2022-04-04 12:30:33 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-09317a8f-zookeeper are in desired state
2022-04-04 12:30:34 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-09317a8f-zookeeper are in desired state
2022-04-04 12:30:35 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-09317a8f-zookeeper are in desired state
2022-04-04 12:30:36 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-09317a8f-zookeeper are in desired state
2022-04-04 12:30:37 [main] [32mINFO [m [SecurityST:1221] Pod in 'Pending' state: my-cluster-09317a8f-zookeeper-1
2022-04-04 12:30:37 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@39562ff7, messages=[], arguments=[--topic, my-topic-787071919-1319940386, --max-messages, 100, --group-instance-id, instance137768381, --group-id, my-consumer-group-1618859256, USER=my_user_2072439778_1517208714, --bootstrap-server, my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9', podNamespace='namespace-60', bootstrapServer='my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-787071919-1319940386', maxMessages=100, kafkaUsername='my-user-2072439778-1517208714', consumerGroupName='my-consumer-group-1618859256', consumerInstanceId='instance137768381', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@51fdc261}
2022-04-04 12:30:37 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093:my-topic-787071919-1319940386 from pod my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9
2022-04-04 12:30:37 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9 -n namespace-60 -- /opt/kafka/consumer.sh --topic my-topic-787071919-1319940386 --max-messages 100 --group-instance-id instance137768381 --group-id my-consumer-group-1618859256 USER=my_user_2072439778_1517208714 --bootstrap-server my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093
2022-04-04 12:30:44 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 12:30:44 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 12:30:44 [main] [32mINFO [m [SecretUtils:131] Waiting for Secret my-cluster-09317a8f-cluster-ca-cert certificate change
2022-04-04 12:30:44 [main] [32mINFO [m [SecretUtils:138] Certificate in Secret my-cluster-09317a8f-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUSulTktq0WI22qI2wmxyTSRBFwq4wDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDQxMjMwMjdaFw0yMjA0MTExMjMwMjdaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQCwY+o3UZ4AgjnSqbCLvJtfIGzZ3vVpxjXd543pg66H
MbwvKiH5az3GFTs1PB50w0Yj/rafeLzwyLHRSCMuC8jbq89FuxpNy/Xx2v3cA6MM
xVn+RsAFhpF3C+gFVewYeofVOUBmLLz9kg/fp+enN9VLGbge/zMfZ9QDxskWjn9y
rAFT7HcgaTKHbaJ/TpiYIbGQ0HGrJlZi0Jt5XTUBQWgRSITCS/kODbEiNeQz/vZk
0of1gRXMliTABH8gY7iV4IXnJ3Dq1O5FA2+7tADD8R92WMTs1zX3XTxL5fOISXQZ
KhuBB/FkWQVd3oTZ/tKvZCfQcdJAmEdQAxDlRDs7sIhsMic2MmfOGloLlko+Kq66
+ykVA6h98EnLnIH3Li0gWlV56qtv4i0Vzwudm6aqtNeIayrVpUVmlGXs00jqjL0C
eEzdsOM/BV01XzD4nRJUzLkvoxoju7DPNpvaq46QKf1qIJKSdaTbLzCSfJWbxXHq
vzfEzUMVYhOyInJhbW1dI6TDubJX0LNiKH+jrpDD2941To5ktSS5worqq8EHg8B+
fBLMpoLWEUanqZZv9ztuO2Oi9meFupghozxxE+bkgr5U+xpSwF1ZYchGrzsIUO2+
+UI5JRRxXQJN6uSvdnbfzvyDUM9q+SZJLpU3Jq/yUXiI7hMZhmrNyIVFRw1m2eDA
NQIDAQABo0UwQzAdBgNVHQ4EFgQUJGS2w735KRuCByIS/qrcyv70DUMwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AKzynyW6N/aXJQTUm/59mL/d9s/iEAzN8AgppgWV8TodqpCi0UV/mFsur1TJ1BZK
b/FYkZqReVFPdG+GorbSlb8I8p1qYdfXlpbCw72cuSlZfnuMuOjAbsOasfoVXkI4
i5bbgmq5/WUH/U/lEJFaHkKgdz9cHKceUaaJl+Fx4rFAXT5ma2BAYyfpIk411W6k
l8UDQiXlVczGs2m/g68Ip+gAaW3bjkwh/Dci9Whp4u62T1uPHdfKWFZiRcHaTr4M
jRAfdK2h9QZmRxASNZAPYE6R5l083tMBkjUL77n/FIo7OKIfbaaTTRSVoNx9ozxu
HERjSdh0NjmtD2xd7UhkBcLKUpKfT9xQyok3S+k3PCU81WdVcsKkFiQH7C+nCTnc
g8wuQ1VRQvGIBly/r9aNrHOtp+y+nc/Kj+RwkJHaHCbrxy5cXisQJANgDpL5PKHE
TPQVlmxmfFS4ttvf2V22ti0sLIDxscHFhoKKB/VBrNBrTEMcxuj4yokHbKB4sWAm
QzIiegyJmRq3G6eN7ntX+ut+ebFj6QOFsTGicI55Q82HmM6JIPs41WoUdaMwqO6X
46yhPERcfcH65+jyzgYyqHDotwBuuQ/apajXEEE12Jg2wQMb6FtMZF1gW+upRCsi
+1JY2IPsfdw+GtD3tR2Ls5q3lXzt26zseD7/uwuQ00At
-----END CERTIFICATE-----

2022-04-04 12:30:44 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-09317a8f-zookeeper rolling update
2022-04-04 12:37:19 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-09317a8f-zookeeper has been successfully rolled
2022-04-04 12:37:19 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-09317a8f-zookeeper to be ready
2022-04-04 12:37:47 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-09317a8f-kafka rolling update
2022-04-04 12:38:52 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-09317a8f-kafka has been successfully rolled
2022-04-04 12:38:52 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-09317a8f-kafka to be ready
2022-04-04 12:39:23 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-09317a8f-entity-operator rolling update
2022-04-04 12:39:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-09317a8f-entity-operator will be ready
2022-04-04 12:42:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-09317a8f-entity-operator is ready
2022-04-04 12:42:56 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-09317a8f-entity-operator rolling update finished
2022-04-04 12:42:56 [main] [32mINFO [m [SecurityST:1252] Checking produced and consumed messages to pod:my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9
2022-04-04 12:42:56 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@437b8095, messages=[], arguments=[--topic, my-topic-787071919-1319940386, --max-messages, 100, --group-instance-id, instance571109623, --group-id, my-consumer-group-1407492122, USER=my_user_2072439778_1517208714, --bootstrap-server, my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9', podNamespace='namespace-60', bootstrapServer='my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-787071919-1319940386', maxMessages=100, kafkaUsername='my-user-2072439778-1517208714', consumerGroupName='my-consumer-group-1407492122', consumerInstanceId='instance571109623', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@11c11a8b}
2022-04-04 12:42:56 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093:my-topic-787071919-1319940386 from pod my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9
2022-04-04 12:42:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9 -n namespace-60 -- /opt/kafka/consumer.sh --topic my-topic-787071919-1319940386 --max-messages 100 --group-instance-id instance571109623 --group-id my-consumer-group-1407492122 USER=my_user_2072439778_1517208714 --bootstrap-server my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093
2022-04-04 12:43:03 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 12:43:03 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 12:43:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-265698080-2106474978 in namespace namespace-60
2022-04-04 12:43:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-04 12:43:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-265698080-2106474978 will have desired state: Ready
2022-04-04 12:44:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-265698080-2106474978 is in desired state: Ready
2022-04-04 12:44:45 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1feda0e1, messages=[], arguments=[--topic, my-topic-265698080-2106474978, --max-messages, 100, USER=my_user_2072439778_1517208714, --bootstrap-server, my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9', podNamespace='namespace-60', bootstrapServer='my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-265698080-2106474978', maxMessages=100, kafkaUsername='my-user-2072439778-1517208714', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6e1f7f4}
2022-04-04 12:44:45 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093:my-topic-265698080-2106474978 from pod my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9
2022-04-04 12:44:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9 -n namespace-60 -- /opt/kafka/producer.sh --topic my-topic-265698080-2106474978 --max-messages 100 USER=my_user_2072439778_1517208714 --bootstrap-server my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093
2022-04-04 12:44:49 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 12:44:49 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 12:44:49 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5dbc9ceb, messages=[], arguments=[--topic, my-topic-265698080-2106474978, --max-messages, 100, --group-instance-id, instance38027005, --group-id, my-consumer-group-1580485272, USER=my_user_2072439778_1517208714, --bootstrap-server, my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9', podNamespace='namespace-60', bootstrapServer='my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-265698080-2106474978', maxMessages=100, kafkaUsername='my-user-2072439778-1517208714', consumerGroupName='my-consumer-group-1580485272', consumerInstanceId='instance38027005', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@54eb8fd5}
2022-04-04 12:44:49 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093:my-topic-265698080-2106474978 from pod my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9
2022-04-04 12:44:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-09317a8f-kafka-clients-77d8df8b54-xxhg9 -n namespace-60 -- /opt/kafka/consumer.sh --topic my-topic-265698080-2106474978 --max-messages 100 --group-instance-id instance38027005 --group-id my-consumer-group-1580485272 USER=my_user_2072439778_1517208714 --bootstrap-server my-cluster-09317a8f-kafka-bootstrap.namespace-60.svc:9093
2022-04-04 12:44:55 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 12:44:55 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 12:44:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:44:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCaRenewalBreakInMiddle
2022-04-04 12:44:55 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-787071919-1319940386 in namespace namespace-60
2022-04-04 12:44:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-09317a8f in namespace namespace-60
2022-04-04 12:44:55 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-265698080-2106474978 in namespace namespace-60
2022-04-04 12:44:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2072439778-1517208714 in namespace namespace-60
2022-04-04 12:45:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-09317a8f-kafka-clients in namespace namespace-60
2022-04-04 12:45:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 12:45:56 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-60 for test case:testCaRenewalBreakInMiddle
2022-04-04 12:46:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-FINISHED
2022-04-04 12:46:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 12:46:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 12:46:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-STARTED
2022-04-04 12:46:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 12:46:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-61 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-04-04 12:46:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-61
2022-04-04 12:46:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-61
2022-04-04 12:46:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-61
2022-04-04 12:46:02 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 12:46:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9dea1f53 in namespace namespace-61
2022-04-04 12:46:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-04 12:46:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9dea1f53 will have desired state: Ready
2022-04-04 12:48:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9dea1f53 is in desired state: Ready
2022-04-04 12:48:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1527563307-1695912852 in namespace namespace-61
2022-04-04 12:48:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-04 12:48:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1527563307-1695912852 will have desired state: Ready
2022-04-04 12:48:25 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1527563307-1695912852 is in desired state: Ready
2022-04-04 12:48:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-798030602-1883458295 in namespace namespace-61
2022-04-04 12:48:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-04 12:48:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-798030602-1883458295 will have desired state: Ready
2022-04-04 12:48:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-798030602-1883458295 is in desired state: Ready
2022-04-04 12:48:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-9dea1f53-kafka-clients in namespace namespace-61
2022-04-04 12:48:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-04 12:48:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9dea1f53-kafka-clients will be ready
2022-04-04 12:48:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9dea1f53-kafka-clients is ready
2022-04-04 12:48:28 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 12:48:28 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-9dea1f53-kafka-clients-c9f4cd998-zgqgk
2022-04-04 12:48:28 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2898c948, messages=[], arguments=[--topic, my-topic-798030602-1883458295, --max-messages, 100, --bootstrap-server, my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-9dea1f53-kafka-clients-c9f4cd998-zgqgk', podNamespace='namespace-61', bootstrapServer='my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-798030602-1883458295', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4b23c619}
2022-04-04 12:48:28 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9092:my-topic-798030602-1883458295 from pod my-cluster-9dea1f53-kafka-clients-c9f4cd998-zgqgk
2022-04-04 12:48:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9dea1f53-kafka-clients-c9f4cd998-zgqgk -n namespace-61 -- /opt/kafka/producer.sh --topic my-topic-798030602-1883458295 --max-messages 100 --bootstrap-server my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9092
2022-04-04 12:48:30 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 12:48:30 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 12:48:30 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1d120fb2, messages=[], arguments=[--topic, my-topic-798030602-1883458295, --max-messages, 100, --group-instance-id, instance13022344, --group-id, my-consumer-group-540676795, --bootstrap-server, my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-9dea1f53-kafka-clients-c9f4cd998-zgqgk', podNamespace='namespace-61', bootstrapServer='my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-798030602-1883458295', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-540676795', consumerInstanceId='instance13022344', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@48d41bbf}
2022-04-04 12:48:30 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9092#my-topic-798030602-1883458295 from pod my-cluster-9dea1f53-kafka-clients-c9f4cd998-zgqgk
2022-04-04 12:48:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9dea1f53-kafka-clients-c9f4cd998-zgqgk -n namespace-61 -- /opt/kafka/consumer.sh --topic my-topic-798030602-1883458295 --max-messages 100 --group-instance-id instance13022344 --group-id my-consumer-group-540676795 --bootstrap-server my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9092
2022-04-04 12:48:36 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:48:36 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:48:36 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-04 12:48:36 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-9dea1f53-cluster-ca-cert with strimzi.io/force-renew
2022-04-04 12:48:36 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-9dea1f53-clients-ca-cert with strimzi.io/force-renew
2022-04-04 12:48:36 [main] [32mINFO [m [SecurityST:291] Wait for zk to rolling restart ...
2022-04-04 12:48:36 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-9dea1f53-zookeeper rolling update
2022-04-04 12:50:01 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-9dea1f53-zookeeper has been successfully rolled
2022-04-04 12:50:01 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-9dea1f53-zookeeper to be ready
2022-04-04 12:50:30 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-04 12:50:30 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-9dea1f53-kafka rolling update
2022-04-04 12:51:40 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-9dea1f53-kafka has been successfully rolled
2022-04-04 12:51:40 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-9dea1f53-kafka to be ready
2022-04-04 12:52:10 [main] [32mINFO [m [SecurityST:299] Wait for EO to rolling restart ...
2022-04-04 12:52:10 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-9dea1f53-entity-operator rolling update
2022-04-04 12:52:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9dea1f53-entity-operator will be ready
2022-04-04 12:52:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9dea1f53-entity-operator is ready
2022-04-04 12:53:00 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-9dea1f53-entity-operator rolling update finished
2022-04-04 12:53:00 [main] [32mINFO [m [SecurityST:303] Wait for CC and KE to rolling restart ...
2022-04-04 12:53:00 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-9dea1f53-kafka-exporter rolling update
2022-04-04 12:53:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9dea1f53-kafka-exporter will be ready
2022-04-04 12:53:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9dea1f53-kafka-exporter is ready
2022-04-04 12:53:50 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-9dea1f53-kafka-exporter rolling update finished
2022-04-04 12:53:50 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-9dea1f53-cruise-control rolling update
2022-04-04 12:53:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9dea1f53-cruise-control will be ready
2022-04-04 12:53:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9dea1f53-cruise-control is ready
2022-04-04 12:54:00 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-9dea1f53-cruise-control rolling update finished
2022-04-04 12:54:00 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-04 12:54:00 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-9dea1f53-kafka-clients-c9f4cd998-zgqgk
2022-04-04 12:54:00 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@244d258c, messages=[], arguments=[--topic, my-topic-798030602-1883458295, --max-messages, 100, --group-instance-id, instance42687838, --group-id, my-consumer-group-2043587953, --bootstrap-server, my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-9dea1f53-kafka-clients-c9f4cd998-zgqgk', podNamespace='namespace-61', bootstrapServer='my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-798030602-1883458295', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2043587953', consumerInstanceId='instance42687838', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@665967db}
2022-04-04 12:54:00 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9092#my-topic-798030602-1883458295 from pod my-cluster-9dea1f53-kafka-clients-c9f4cd998-zgqgk
2022-04-04 12:54:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9dea1f53-kafka-clients-c9f4cd998-zgqgk -n namespace-61 -- /opt/kafka/consumer.sh --topic my-topic-798030602-1883458295 --max-messages 100 --group-instance-id instance42687838 --group-id my-consumer-group-2043587953 --bootstrap-server my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9092
2022-04-04 12:54:06 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:54:06 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:54:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-9dea1f53 in namespace namespace-61
2022-04-04 12:54:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-04 12:54:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-9dea1f53 will have desired state: Ready
2022-04-04 12:54:07 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-9dea1f53 is in desired state: Ready
2022-04-04 12:54:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-9dea1f53-kafka-clients-tls in namespace namespace-61
2022-04-04 12:54:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-04 12:54:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9dea1f53-kafka-clients-tls will be ready
2022-04-04 12:54:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9dea1f53-kafka-clients-tls is ready
2022-04-04 12:54:09 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-9dea1f53-kafka-clients-tls-586d76d6fc-p65kd
2022-04-04 12:54:09 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@de599df, messages=[], arguments=[--topic, my-topic-798030602-1883458295, --max-messages, 100, --group-instance-id, instance1346808372, --group-id, my-consumer-group-1387826733, USER=bob_my_cluster_9dea1f53, --bootstrap-server, my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-9dea1f53-kafka-clients-tls-586d76d6fc-p65kd', podNamespace='namespace-61', bootstrapServer='my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9093', topicName='my-topic-798030602-1883458295', maxMessages=100, kafkaUsername='bob-my-cluster-9dea1f53', consumerGroupName='my-consumer-group-1387826733', consumerInstanceId='instance1346808372', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@20af45ae}
2022-04-04 12:54:09 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9093#my-topic-798030602-1883458295 from pod my-cluster-9dea1f53-kafka-clients-tls-586d76d6fc-p65kd
2022-04-04 12:54:09 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9dea1f53-kafka-clients-tls-586d76d6fc-p65kd -n namespace-61 -- /opt/kafka/consumer.sh --topic my-topic-798030602-1883458295 --max-messages 100 --group-instance-id instance1346808372 --group-id my-consumer-group-1387826733 USER=bob_my_cluster_9dea1f53 --bootstrap-server my-cluster-9dea1f53-kafka-bootstrap.namespace-61.svc:9093
2022-04-04 12:54:16 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 12:54:16 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 12:54:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:54:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewAllCaCertsTriggeredByAnno
2022-04-04 12:54:16 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-9dea1f53-kafka-clients in namespace namespace-61
2022-04-04 12:54:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-9dea1f53-kafka-clients-tls in namespace namespace-61
2022-04-04 12:54:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1527563307-1695912852 in namespace namespace-61
2022-04-04 12:54:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9dea1f53 in namespace namespace-61
2022-04-04 12:54:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-61, for cruise control Kafka cluster my-cluster-9dea1f53
2022-04-04 12:54:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-798030602-1883458295 in namespace namespace-61
2022-04-04 12:54:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-9dea1f53 in namespace namespace-61
2022-04-04 12:55:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 12:55:16 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-61 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-04-04 12:55:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-FINISHED
2022-04-04 12:55:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 12:55:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 12:55:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-STARTED
2022-04-04 12:55:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 12:55:23 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-62 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-04-04 12:55:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-62
2022-04-04 12:55:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-62
2022-04-04 12:55:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-62
2022-04-04 12:55:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8b325716 in namespace namespace-62
2022-04-04 12:55:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-04 12:55:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8b325716 will have desired state: Ready
2022-04-04 12:56:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8b325716 is in desired state: Ready
2022-04-04 12:56:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1560868913-1353853205 in namespace namespace-62
2022-04-04 12:56:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-04 12:56:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1560868913-1353853205 will have desired state: Ready
2022-04-04 12:56:41 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1560868913-1353853205 is in desired state: Ready
2022-04-04 12:56:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1575102967-518191670 in namespace namespace-62
2022-04-04 12:56:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-04 12:56:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1575102967-518191670 will have desired state: Ready
2022-04-04 12:56:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1575102967-518191670 is in desired state: Ready
2022-04-04 12:56:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8b325716-kafka-clients in namespace namespace-62
2022-04-04 12:56:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-04 12:56:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8b325716-kafka-clients will be ready
2022-04-04 12:56:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8b325716-kafka-clients is ready
2022-04-04 12:56:44 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 12:56:44 [main] [32mINFO [m [SecurityST:797] Verifying that secret Secret(apiVersion=v1, data={ca.crt=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, ca.p12=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, ca.password=SVAwSkdXOHJ6MG9U}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-04-04T12:55:26Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-8b325716, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-8b325716, strimzi.io/cluster=my-cluster-8b325716, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[], name=my-cluster-8b325716-clients-ca-cert, namespace=namespace-62, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-8b325716, uid=dfb03627-51d3-4965-8201-a92158f33145, additionalProperties={})], resourceVersion=509792, selfLink=/api/v1/namespaces/namespace-62/secrets/my-cluster-8b325716-clients-ca-cert, uid=7d8d9d6b-c1f2-4e08-b75c-39b4180ad128, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-8b325716-clients-ca-cert is present
2022-04-04 12:56:44 [main] [32mINFO [m [SecurityST:797] Verifying that secret Secret(apiVersion=v1, data={ca.crt=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, ca.p12=MIIGkwIBAzCCBkwGCSqGSIb3DQEHAaCCBj0EggY5MIIGNTCCBjEGCSqGSIb3DQEHBqCCBiIwggYeAgEAMIIGFwYJKoZIhvcNAQcBMGYGCSqGSIb3DQEFDTBZMDgGCSqGSIb3DQEFDDArBBRS/H2/yADrV3mW+8tF367UjqaxdwICJxACASAwDAYIKoZIhvcNAgkFADAdBglghkgBZQMEASoEELOOC0DAKg9+TOJuxrbylvqAggWgok+qMy2GOtMgnUvVcu4wsYHIWmiDwKVOyg4HR49OHrwahF9wEWjUuYRngmh0WTg+IaY3t9xvH1TaMPnDoesdq+uuk7yDFNEKZjL8PKFXbOk4udTFDEt1crdzWEmHlhgEJcBzr+SUiEs8krVhdOTWPRDSzvSEDZ1xT4zKkLhE0AU0rcDoqaE3yKuDx7hp9ewz0X/IbpZxUge8YIrpVIoKjjxkeixMcIMWA3qnWx+tFs9rO77ILb67QmJbgA6eTTT1klA7210fxuWAu/4TeZqlPa1sg0ThBE3TLxWQL9pVgZpe+K/SdeaVT2/pVebPPDUQP/rEocZy4am7DxDApgbPAeOiDUtwqt6UAn/3yWfCtvEN7I7kJG5w0AxVql7csHPm1QLkknt14AxR0Sy7S36aySMz8TlNIkwYP3wIKq/RblPTVyfrMCrzYMxUr3poznNzP7a4dy6VGYZbQ+yY2NdO7dzRJLRTwTeVHlhnzS5h/RYgCQGQZGkeHA/bWcvQRTjkciOsgBEz/QnZd6195kFodBGckEWGzfT3/+H3TiyNFqe3GQlrrtl0LeJUMtsvPcEZDOjbjTZngCEd7CRrbiaux86zgt07z+wr8MknZHR/amLv5kwPKgnk6vIYP5l9in8qXTxZNSpwDaNgXCkBekmivK72YM/kslhHTscK+R5qH/3JrwPmes7BnXIlvDYTbz+IVy8bh5uH0SUvDFjBRIyZd7fqbO7G6E4QbFCaRn5SiykhqXWjGrVBHS3EmDCrTRjlCteDvej6QbJ/sOUWNBj/dH699fhYvH7xSVW0NgoaB7bpBv/6Z3SV1pjNh4qG2MKXaPHwAlfqZdtXLr4+HHKAq1LJdFSz92y/1jY8M+3mLznao8PJ7fKY4oCPnbjNipDM9yw8Q6tMNqt+0QVf1DkPOr/BC0hU0IL5UqSTLJyzhHWwrkfCuUx2MN+dyQnq71g0+p14fDOtY4qyXA8nu0LWKQV/GaEIFP5CADr+qrsTY26tPX2LixGt+aPnVxBzUk2PfkxYho6ZZsN999hnIbcfY9onKdwr7vyMH8YHX1DlydBK2R6olpm+H1WqtR3XOXRQx0h8hOyodTLgIto0X5CiWuNtT2LY1TnL7ix7jADBpLfDtONATWH2zjzykIKOIVIAVC0U87nexz5R4nPT+CFoBDGHWygBMNctZlKBFnsFo1kxrD//FAFo4yQt4+yCOlCbwU0xB+qdYuAE4K1cWOUcTgs/glHWcIYS768c5WETrqnvOxFrQVXvqd/xw5qhWFkr83iFUfehl14Q8KdHD5EEhUDis+RY6559+3UQzsTnDXnJbknGUw0fUzr69wBm0dk2z4q1IKDeRf5leHHGSGT6myw676+NTVq0VT4NngovE9PIuAGYnLlYnFMpaBp9Ts0y7qWWUwPLtxzvpggEpv5jZpp0dcCy3vi6SvDG1WKvxKjo5omDaJqSXeZVHrbFkSgcbksHwruaav4TpJ5spD+1+wSDD0l6k6IQ7JLptS80qr857aeF5w15YGm7weaaeQqHK9kLABo/q/qxkJyUKM701BNcbY4ZbnUGmsxqIRTK+4jsh9PKcO7ZZUcrJ3CnnIgKT2+59onA+JFGYbkQ2G4scR2To19bJuKXiTCi6kL1F0ga/EEurY9riEyRFSSgtsWBelNqnovLmw3TzUS4wMvQ1XRe/Ek2Wtw433tKZz6XivhC4qSgzYx7XUmscgxTz/n7oQGy/NKaG9iXZlzeynMC3AJCb53VjYcF3A0FKkh9eZDjxHZU9k7WaeAbPEQMpppcGuR2dzgKcvsKGt3UZr70W5L5+QNXdVeGy4FR3jljAA+ilNm7AxyoumMumEBymDHSlZpRVFWOIGDP9QF/DEWuKYobGhHJHuJYcpmNwnru3wy1N6ef0ZtvPQgFqI7Fwd0DMD4wITAJBgUrDgMCGgUABBTQDqfUJdV2+9+l71/8AAIactsZ7wQU88mZNVVANmjLca9xGmnxAg13rkoCAwGGoA==, ca.password=TU0zTjZyRmpaZHBI}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-04-04T12:55:26Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-8b325716, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-8b325716, strimzi.io/cluster=my-cluster-8b325716, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[], name=my-cluster-8b325716-cluster-ca-cert, namespace=namespace-62, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-8b325716, uid=dfb03627-51d3-4965-8201-a92158f33145, additionalProperties={})], resourceVersion=509793, selfLink=/api/v1/namespaces/namespace-62/secrets/my-cluster-8b325716-cluster-ca-cert, uid=76887ec6-887c-4ace-942d-b54463deec45, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-8b325716-cluster-ca-cert is present
2022-04-04 12:56:44 [main] [32mINFO [m [SecurityST:802] Deleting secret my-cluster-8b325716-clients-ca-cert
2022-04-04 12:56:44 [main] [32mINFO [m [SecurityST:802] Deleting secret my-cluster-8b325716-cluster-ca-cert
2022-04-04 12:56:44 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-8b325716-kafka are stable
2022-04-04 12:56:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:56:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:56:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:56:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:56:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:56:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:56:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:56:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:56:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:56:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:56:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:56:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:56:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:56:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:56:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:56:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:56:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:56:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:56:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:56:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:56:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:56:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:56:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:56:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:56:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:56:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:56:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:56:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:56:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:56:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:56:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:56:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:56:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:56:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:56:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:56:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:56:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:56:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:56:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:56:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:56:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:56:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:56:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:56:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:56:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:56:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:56:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:56:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:56:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:56:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:56:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:56:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:56:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:56:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:56:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:56:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:56:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:56:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:56:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:56:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:57:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:57:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:57:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:57:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:57:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:57:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:57:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:57:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:57:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:57:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:57:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:57:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:57:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:57:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:57:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:57:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:57:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:57:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:57:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:57:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:57:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:57:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:57:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:57:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:57:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:57:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:57:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:57:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:57:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:57:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:57:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:57:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:57:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:57:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:57:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:57:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:57:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:57:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:57:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:57:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:57:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:57:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:57:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:57:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:57:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:57:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:57:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:57:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:57:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:57:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:57:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:57:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:57:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:57:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:57:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:57:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:57:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:57:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:57:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:57:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:57:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:57:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:57:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:57:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:57:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:57:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:57:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:57:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:57:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:57:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:57:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:57:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:57:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:57:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:57:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:57:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:57:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 12:57:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 12:57:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 12:57:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 12:57:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 12:57:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 12:57:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 12:57:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 12:57:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 12:57:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 12:57:21 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-8b325716-kafka-2 is not stable in phase following phase Pending reset the stability counter from 36 to 0
2022-04-04 12:57:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:57:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:57:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:57:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:57:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:57:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:57:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:57:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:57:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:57:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:57:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:57:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:57:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:57:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:57:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:57:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:57:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:57:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:57:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:57:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:57:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:57:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:57:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:57:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:57:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:57:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:57:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:57:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:57:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:57:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:57:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:57:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:57:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:57:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:57:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:57:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:57:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:57:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:57:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:57:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:57:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:57:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:57:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:57:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:57:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:57:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:57:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:57:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:57:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:57:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:57:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:57:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:57:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:57:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:57:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:57:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:57:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:57:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:57:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:57:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:57:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:57:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:57:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:57:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:57:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:57:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:57:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:57:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:57:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:57:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:57:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:57:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:57:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:57:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:57:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:57:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:57:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:57:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:57:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:57:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:57:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:57:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:57:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:57:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:57:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:57:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:57:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:57:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:57:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:57:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:57:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:57:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:57:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:57:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:57:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:57:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:57:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:57:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:57:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:57:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:57:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:57:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:57:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:57:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:57:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:57:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:57:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:57:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:57:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:57:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:57:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:57:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:57:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:57:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:57:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:57:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:57:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:57:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:57:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:57:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:57:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:57:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:57:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:57:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:57:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:57:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:57:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:57:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:57:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:57:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:57:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:57:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:57:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:57:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:57:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:57:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:57:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 12:57:57 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-8b325716-kafka-1 is not stable in phase following phase Pending reset the stability counter from 34 to 0
2022-04-04 12:57:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:57:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:57:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:57:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:57:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:57:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:57:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:57:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:58:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:58:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:58:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:58:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:58:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:58:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:58:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:58:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:58:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:58:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:58:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:58:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:58:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:58:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:58:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:58:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:58:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:58:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:58:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:58:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:58:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:58:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:58:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:58:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:58:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:58:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:58:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:58:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:58:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:58:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:58:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:58:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:58:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:58:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:58:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:58:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:58:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:58:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:58:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:58:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:58:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:58:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:58:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:58:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:58:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:58:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:58:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:58:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:58:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:58:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:58:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:58:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:58:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:58:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:58:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:58:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:58:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:58:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:58:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:58:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:58:28 [main] [32mINFO [m [PodUtils:326] Pod my-cluster-8b325716-kafka-0 is not stable in phase following phase Pending reset the stability counter from 29 to 0
2022-04-04 12:58:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 12:58:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:58:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:58:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:58:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 12:58:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 12:58:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 12:58:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 12:58:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 12:58:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 12:58:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 12:58:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 12:58:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 12:58:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 12:58:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 12:58:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 12:58:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 12:58:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:58:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:58:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:58:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 12:58:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:58:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:58:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:58:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 12:58:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:58:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:58:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:58:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 12:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 12:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 12:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 12:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 12:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 12:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 12:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 12:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 12:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 12:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 12:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 12:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 12:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 12:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:58:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 12:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 12:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 12:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 12:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 12:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 12:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 12:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 12:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 12:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 12:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 12:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 12:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 12:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 12:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 12:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 12:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 12:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 12:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 12:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 12:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 12:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 12:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 12:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 12:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 12:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 12:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 12:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 12:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 12:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 12:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 12:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 12:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 12:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 12:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 12:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 12:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 12:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 12:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 12:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 12:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 12:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 12:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 12:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 12:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 12:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 12:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 12:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 12:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 12:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 12:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 12:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 12:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 12:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 12:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 12:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 12:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 12:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 12:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 12:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 12:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 12:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 12:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 12:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 12:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 12:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 12:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 12:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 12:59:19 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-8b325716-kafka-0 ,my-cluster-8b325716-kafka-1 ,my-cluster-8b325716-kafka-2 ,my-cluster-8b325716-kafka-clients-75747b47bc-6zc45
2022-04-04 12:59:19 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-8b325716-kafka rolling update
2022-04-04 12:59:19 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-8b325716-kafka has been successfully rolled
2022-04-04 12:59:19 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-8b325716-kafka to be ready
2022-04-04 12:59:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8b325716 will have desired state: Ready
2022-04-04 12:59:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8b325716 is in desired state: Ready
2022-04-04 12:59:29 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-8b325716 is ready
2022-04-04 12:59:29 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-8b325716-clients-ca-cert
2022-04-04 12:59:29 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-8b325716-clients-ca-cert created
2022-04-04 12:59:29 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-8b325716-cluster-ca-cert
2022-04-04 12:59:29 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-8b325716-cluster-ca-cert created
2022-04-04 12:59:29 [main] [32mINFO [m [SecurityST:821] Checking consumed messages to pod:my-cluster-8b325716-kafka-clients-75747b47bc-6zc45
2022-04-04 12:59:29 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@64705742, messages=[], arguments=[--topic, my-topic-1575102967-518191670, --max-messages, 100, USER=my_user_1560868913_1353853205, --bootstrap-server, my-cluster-8b325716-kafka-bootstrap.namespace-62.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-8b325716-kafka-clients-75747b47bc-6zc45', podNamespace='namespace-62', bootstrapServer='my-cluster-8b325716-kafka-bootstrap.namespace-62.svc:9093', topicName='my-topic-1575102967-518191670', maxMessages=100, kafkaUsername='my-user-1560868913-1353853205', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5e8d1f19}
2022-04-04 12:59:29 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-8b325716-kafka-bootstrap.namespace-62.svc:9093:my-topic-1575102967-518191670 from pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45
2022-04-04 12:59:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 -n namespace-62 -- /opt/kafka/producer.sh --topic my-topic-1575102967-518191670 --max-messages 100 USER=my_user_1560868913_1353853205 --bootstrap-server my-cluster-8b325716-kafka-bootstrap.namespace-62.svc:9093
2022-04-04 12:59:33 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 12:59:33 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 12:59:33 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2820c8f2, messages=[], arguments=[--topic, my-topic-1575102967-518191670, --max-messages, 100, --group-instance-id, instance1961788263, --group-id, my-consumer-group-605274320, USER=my_user_1560868913_1353853205, --bootstrap-server, my-cluster-8b325716-kafka-bootstrap.namespace-62.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-8b325716-kafka-clients-75747b47bc-6zc45', podNamespace='namespace-62', bootstrapServer='my-cluster-8b325716-kafka-bootstrap.namespace-62.svc:9093', topicName='my-topic-1575102967-518191670', maxMessages=100, kafkaUsername='my-user-1560868913-1353853205', consumerGroupName='my-consumer-group-605274320', consumerInstanceId='instance1961788263', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1ee379e0}
2022-04-04 12:59:33 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-8b325716-kafka-bootstrap.namespace-62.svc:9093:my-topic-1575102967-518191670 from pod my-cluster-8b325716-kafka-clients-75747b47bc-6zc45
2022-04-04 12:59:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-8b325716-kafka-clients-75747b47bc-6zc45 -n namespace-62 -- /opt/kafka/consumer.sh --topic my-topic-1575102967-518191670 --max-messages 100 --group-instance-id instance1961788263 --group-id my-consumer-group-605274320 USER=my_user_1560868913_1353853205 --bootstrap-server my-cluster-8b325716-kafka-bootstrap.namespace-62.svc:9093
2022-04-04 12:59:40 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 12:59:40 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 12:59:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 12:59:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertRegeneratedAfterInternalCAisDeleted
2022-04-04 12:59:40 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1575102967-518191670 in namespace namespace-62
2022-04-04 12:59:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1560868913-1353853205 in namespace namespace-62
2022-04-04 12:59:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8b325716 in namespace namespace-62
2022-04-04 12:59:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8b325716-kafka-clients in namespace namespace-62
2022-04-04 13:00:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 13:00:20 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-62 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-04-04 13:00:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-FINISHED
2022-04-04 13:00:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 13:00:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 13:00:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-STARTED
2022-04-04 13:00:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 13:00:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-63 for test case:testKafkaAndKafkaConnectCipherSuites
2022-04-04 13:00:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-63
2022-04-04 13:00:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-63
2022-04-04 13:00:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-63
2022-04-04 13:00:25 [main] [32mINFO [m [SecurityST:1362] Deploying Kafka cluster with the support TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 cipher algorithms
2022-04-04 13:00:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8a75f91b in namespace namespace-63
2022-04-04 13:00:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-04 13:00:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8a75f91b will have desired state: Ready
2022-04-04 13:01:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8a75f91b is in desired state: Ready
2022-04-04 13:01:42 [main] [32mINFO [m [SecurityST:1374] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-04-04 13:01:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8a75f91b-kafka-clients in namespace namespace-63
2022-04-04 13:01:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-04 13:01:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8a75f91b-kafka-clients will be ready
2022-04-04 13:01:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8a75f91b-kafka-clients is ready
2022-04-04 13:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8a75f91b-scraper in namespace namespace-63
2022-04-04 13:01:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-04 13:01:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8a75f91b-scraper will be ready
2022-04-04 13:01:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8a75f91b-scraper is ready
2022-04-04 13:01:46 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-8a75f91b-scraper to be ready
2022-04-04 13:01:56 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-8a75f91b-scraper is ready
2022-04-04 13:01:56 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-8a75f91b-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 13:01:56 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-8a75f91b-allow in namespace namespace-63
2022-04-04 13:01:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-04 13:01:56 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 13:01:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-8a75f91b in namespace namespace-63
2022-04-04 13:01:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-04 13:01:56 [main] [32mINFO [m [SecurityST:1391] Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm
2022-04-04 13:01:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-8a75f91b will have desired state: NotReady
2022-04-04 13:06:57 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-8a75f91b is in desired state: NotReady
2022-04-04 13:06:57 [main] [32mINFO [m [SecurityST:1395] Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.
2022-04-04 13:06:57 [main] [32mINFO [m [SecurityST:1399] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-04-04 13:06:57 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-04-04 13:06:57 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-04-04 13:06:57 [main] [32mINFO [m [SecurityST:1404] Verifying that Kafka Connect is stable
2022-04-04 13:06:57 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-8a75f91b-connect are stable
2022-04-04 13:06:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 13:06:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 13:06:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 13:07:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 13:07:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 13:07:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 13:07:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 13:07:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 13:07:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 13:07:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 13:07:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 13:07:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 13:07:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 13:07:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 13:07:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 13:07:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 13:07:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 13:07:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 13:07:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 13:07:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 13:07:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 13:07:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 13:07:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 13:07:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 13:07:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 13:07:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 13:07:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 13:07:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 13:07:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 13:07:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 13:07:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 13:07:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 13:07:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 13:07:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 13:07:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 13:07:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 13:07:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 13:07:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 13:07:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 13:07:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 13:07:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 13:07:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 13:07:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 13:07:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 13:07:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 13:07:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 13:07:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 13:07:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 13:07:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 13:07:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8a75f91b-connect-75c4bb7486-qbrvr is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 13:07:46 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-8a75f91b-connect-75c4bb7486-qbrvr
2022-04-04 13:07:46 [main] [32mINFO [m [SecurityST:1408] Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm
2022-04-04 13:07:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-8a75f91b will have desired state: Ready
2022-04-04 13:13:00 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-8a75f91b is in desired state: Ready
2022-04-04 13:13:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 13:13:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndKafkaConnectCipherSuites
2022-04-04 13:13:00 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8a75f91b-scraper in namespace namespace-63
2022-04-04 13:13:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-8a75f91b in namespace namespace-63
2022-04-04 13:13:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8a75f91b-kafka-clients in namespace namespace-63
2022-04-04 13:13:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8a75f91b in namespace namespace-63
2022-04-04 13:13:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-8a75f91b-allow in namespace namespace-63
2022-04-04 13:13:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 13:13:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-63 for test case:testKafkaAndKafkaConnectCipherSuites
2022-04-04 13:13:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-FINISHED
2022-04-04 13:13:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 13:13:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 13:13:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-STARTED
2022-04-04 13:13:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 13:13:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-64 for test case:testCertRenewalInMaintenanceWindow
2022-04-04 13:13:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-64
2022-04-04 13:13:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-64
2022-04-04 13:13:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-64
2022-04-04 13:13:55 [main] [32mINFO [m [SecurityST:698] Maintenance window is: * 18-32 * * * ? *
2022-04-04 13:13:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3063f555 in namespace namespace-64
2022-04-04 13:13:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-04 13:13:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3063f555 will have desired state: Ready
2022-04-04 13:15:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3063f555 is in desired state: Ready
2022-04-04 13:15:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1988557574-1688108361 in namespace namespace-64
2022-04-04 13:15:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-04 13:15:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1988557574-1688108361 will have desired state: Ready
2022-04-04 13:15:08 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1988557574-1688108361 is in desired state: Ready
2022-04-04 13:15:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-359415420-184146072 in namespace namespace-64
2022-04-04 13:15:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-04 13:15:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-359415420-184146072 will have desired state: Ready
2022-04-04 13:15:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-359415420-184146072 is in desired state: Ready
2022-04-04 13:15:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-359415420-184146072 in namespace namespace-64
2022-04-04 13:15:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-04 13:15:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-359415420-184146072 will have desired state: Ready
2022-04-04 13:15:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-359415420-184146072 is in desired state: Ready
2022-04-04 13:15:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3063f555-kafka-clients in namespace namespace-64
2022-04-04 13:15:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-04 13:15:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3063f555-kafka-clients will be ready
2022-04-04 13:15:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3063f555-kafka-clients is ready
2022-04-04 13:15:11 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 13:15:11 [main] [32mINFO [m [SecurityST:728] Annotate secret my-cluster-3063f555-cluster-ca-cert with secret force-renew annotation
2022-04-04 13:15:11 [main] [32mINFO [m [SecurityST:735] Wait until maintenance windows starts
2022-04-04 13:18:01 [main] [32mINFO [m [SecurityST:741] Maintenance window starts
2022-04-04 13:18:01 [main] [32mINFO [m [SecurityST:745] Wait until rolling update is triggered during maintenance window
2022-04-04 13:18:01 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-3063f555-kafka rolling update
2022-04-04 13:19:51 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-3063f555-kafka has been successfully rolled
2022-04-04 13:19:51 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-3063f555-kafka to be ready
2022-04-04 13:20:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3063f555 will have desired state: Ready
2022-04-04 13:20:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3063f555 is in desired state: Ready
2022-04-04 13:20:20 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-3063f555 is ready
2022-04-04 13:20:20 [main] [32mINFO [m [SecurityST:750] Checking consumed messages to pod:my-cluster-3063f555-kafka-clients-6958b8cf45-nvn8k
2022-04-04 13:20:20 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@36be660, messages=[], arguments=[--topic, my-topic-359415420-184146072, --max-messages, 100, USER=my_user_1988557574_1688108361, --bootstrap-server, my-cluster-3063f555-kafka-bootstrap.namespace-64.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-3063f555-kafka-clients-6958b8cf45-nvn8k', podNamespace='namespace-64', bootstrapServer='my-cluster-3063f555-kafka-bootstrap.namespace-64.svc:9093', topicName='my-topic-359415420-184146072', maxMessages=100, kafkaUsername='my-user-1988557574-1688108361', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6ab9bf6a}
2022-04-04 13:20:20 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-3063f555-kafka-bootstrap.namespace-64.svc:9093:my-topic-359415420-184146072 from pod my-cluster-3063f555-kafka-clients-6958b8cf45-nvn8k
2022-04-04 13:20:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3063f555-kafka-clients-6958b8cf45-nvn8k -n namespace-64 -- /opt/kafka/producer.sh --topic my-topic-359415420-184146072 --max-messages 100 USER=my_user_1988557574_1688108361 --bootstrap-server my-cluster-3063f555-kafka-bootstrap.namespace-64.svc:9093
2022-04-04 13:20:24 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 13:20:24 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 13:20:24 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4f4cba01, messages=[], arguments=[--topic, my-topic-359415420-184146072, --max-messages, 100, --group-instance-id, instance1372336514, --group-id, my-consumer-group-1361080438, USER=my_user_1988557574_1688108361, --bootstrap-server, my-cluster-3063f555-kafka-bootstrap.namespace-64.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-3063f555-kafka-clients-6958b8cf45-nvn8k', podNamespace='namespace-64', bootstrapServer='my-cluster-3063f555-kafka-bootstrap.namespace-64.svc:9093', topicName='my-topic-359415420-184146072', maxMessages=100, kafkaUsername='my-user-1988557574-1688108361', consumerGroupName='my-consumer-group-1361080438', consumerInstanceId='instance1372336514', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@68290a81}
2022-04-04 13:20:24 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-3063f555-kafka-bootstrap.namespace-64.svc:9093:my-topic-359415420-184146072 from pod my-cluster-3063f555-kafka-clients-6958b8cf45-nvn8k
2022-04-04 13:20:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3063f555-kafka-clients-6958b8cf45-nvn8k -n namespace-64 -- /opt/kafka/consumer.sh --topic my-topic-359415420-184146072 --max-messages 100 --group-instance-id instance1372336514 --group-id my-consumer-group-1361080438 USER=my_user_1988557574_1688108361 --bootstrap-server my-cluster-3063f555-kafka-bootstrap.namespace-64.svc:9093
2022-04-04 13:20:31 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 13:20:31 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 13:20:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 13:20:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertRenewalInMaintenanceWindow
2022-04-04 13:20:31 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-359415420-184146072 in namespace namespace-64
2022-04-04 13:20:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1988557574-1688108361 in namespace namespace-64
2022-04-04 13:20:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3063f555 in namespace namespace-64
2022-04-04 13:20:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3063f555-kafka-clients in namespace namespace-64
2022-04-04 13:20:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-359415420-184146072 in namespace namespace-64
2022-04-04 13:21:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 13:21:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-64 for test case:testCertRenewalInMaintenanceWindow
2022-04-04 13:21:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-FINISHED
2022-04-04 13:21:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 13:21:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 13:21:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-STARTED
2022-04-04 13:21:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 13:21:27 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-65 for test case:testOwnerReferenceOfCASecrets
2022-04-04 13:21:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-65
2022-04-04 13:21:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-65
2022-04-04 13:21:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-65
2022-04-04 13:21:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-51646752 in namespace namespace-65
2022-04-04 13:21:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-65
2022-04-04 13:21:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-51646752 will have desired state: Ready
2022-04-04 13:22:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-51646752 is in desired state: Ready
2022-04-04 13:22:43 [main] [32mINFO [m [SecurityST:1432] Listing all cluster CAs for my-cluster-51646752
2022-04-04 13:22:43 [main] [32mINFO [m [SecurityST:1436] Deleting Kafka:my-cluster-51646752
2022-04-04 13:22:43 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-cluster-51646752
2022-04-04 13:22:45 [main] [32mINFO [m [SecurityST:1440] Checking actual secrets after Kafka deletion
2022-04-04 13:22:45 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-51646752-clients-ca secret is still present
2022-04-04 13:22:45 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-51646752-clients-ca
2022-04-04 13:22:45 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-51646752-clients-ca-cert secret is still present
2022-04-04 13:22:45 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-51646752-clients-ca-cert
2022-04-04 13:22:45 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-51646752-cluster-ca secret is still present
2022-04-04 13:22:45 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-51646752-cluster-ca
2022-04-04 13:22:45 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-51646752-cluster-ca-cert secret is still present
2022-04-04 13:22:45 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-51646752-cluster-ca-cert
2022-04-04 13:22:45 [main] [32mINFO [m [SecurityST:1450] Deploying Kafka with generateSecretOwnerReference set to true
2022-04-04 13:22:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-second-cluster-my-cluster-51646752 in namespace namespace-65
2022-04-04 13:22:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-65
2022-04-04 13:22:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-second-cluster-my-cluster-51646752 will have desired state: Ready
2022-04-04 13:24:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-second-cluster-my-cluster-51646752 is in desired state: Ready
2022-04-04 13:24:31 [main] [32mINFO [m [SecurityST:1465] Deleting Kafka:my-second-cluster-my-cluster-51646752
2022-04-04 13:24:31 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-second-cluster-my-cluster-51646752
2022-04-04 13:24:32 [main] [32mINFO [m [SecurityST:1469] Checking actual secrets after Kafka deletion
2022-04-04 13:24:32 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-51646752-clients-ca secret is deleted
2022-04-04 13:24:32 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-51646752-clients-ca-cert secret is deleted
2022-04-04 13:24:32 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-51646752-cluster-ca secret is deleted
2022-04-04 13:24:32 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-51646752-cluster-ca-cert secret is deleted
2022-04-04 13:24:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 13:24:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOwnerReferenceOfCASecrets
2022-04-04 13:24:34 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-second-cluster-my-cluster-51646752 in namespace namespace-65
2022-04-04 13:24:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-51646752 in namespace namespace-65
2022-04-04 13:24:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 13:24:34 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-65 for test case:testOwnerReferenceOfCASecrets
2022-04-04 13:25:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-FINISHED
2022-04-04 13:25:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 13:25:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 13:25:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-STARTED
2022-04-04 13:25:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 13:25:17 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-66 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-04 13:25:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-66
2022-04-04 13:25:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-66
2022-04-04 13:25:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-66
2022-04-04 13:25:18 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 13:25:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-dd42ca71 in namespace namespace-66
2022-04-04 13:25:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-04 13:25:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-dd42ca71 will have desired state: Ready
2022-04-04 13:27:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-dd42ca71 is in desired state: Ready
2022-04-04 13:27:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-114123489-1610539277 in namespace namespace-66
2022-04-04 13:27:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-04 13:27:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-114123489-1610539277 will have desired state: Ready
2022-04-04 13:27:49 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-114123489-1610539277 is in desired state: Ready
2022-04-04 13:27:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1758098417-562417750 in namespace namespace-66
2022-04-04 13:27:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-04 13:27:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1758098417-562417750 will have desired state: Ready
2022-04-04 13:27:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1758098417-562417750 is in desired state: Ready
2022-04-04 13:27:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-dd42ca71-kafka-clients in namespace namespace-66
2022-04-04 13:27:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-04 13:27:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-dd42ca71-kafka-clients will be ready
2022-04-04 13:27:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-dd42ca71-kafka-clients is ready
2022-04-04 13:27:52 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 13:27:52 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-dd42ca71-kafka-clients-878c8897f-ggmh5
2022-04-04 13:27:52 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@67659fab, messages=[], arguments=[--topic, my-topic-1758098417-562417750, --max-messages, 100, --bootstrap-server, my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-dd42ca71-kafka-clients-878c8897f-ggmh5', podNamespace='namespace-66', bootstrapServer='my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-1758098417-562417750', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@373ac817}
2022-04-04 13:27:52 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9092:my-topic-1758098417-562417750 from pod my-cluster-dd42ca71-kafka-clients-878c8897f-ggmh5
2022-04-04 13:27:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-dd42ca71-kafka-clients-878c8897f-ggmh5 -n namespace-66 -- /opt/kafka/producer.sh --topic my-topic-1758098417-562417750 --max-messages 100 --bootstrap-server my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9092
2022-04-04 13:27:55 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 13:27:55 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 13:27:55 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@30d88d5e, messages=[], arguments=[--topic, my-topic-1758098417-562417750, --max-messages, 100, --group-instance-id, instance863787289, --group-id, my-consumer-group-651198104, --bootstrap-server, my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-dd42ca71-kafka-clients-878c8897f-ggmh5', podNamespace='namespace-66', bootstrapServer='my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-1758098417-562417750', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-651198104', consumerInstanceId='instance863787289', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@51438d11}
2022-04-04 13:27:55 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9092#my-topic-1758098417-562417750 from pod my-cluster-dd42ca71-kafka-clients-878c8897f-ggmh5
2022-04-04 13:27:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-dd42ca71-kafka-clients-878c8897f-ggmh5 -n namespace-66 -- /opt/kafka/consumer.sh --topic my-topic-1758098417-562417750 --max-messages 100 --group-instance-id instance863787289 --group-id my-consumer-group-651198104 --bootstrap-server my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9092
2022-04-04 13:28:01 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 13:28:01 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 13:28:01 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-04 13:28:01 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-dd42ca71-clients-ca-cert with strimzi.io/force-renew
2022-04-04 13:28:01 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-04 13:28:01 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-dd42ca71-kafka rolling update
2022-04-04 13:29:31 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-dd42ca71-kafka has been successfully rolled
2022-04-04 13:29:31 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-dd42ca71-kafka to be ready
2022-04-04 13:29:57 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-04 13:29:57 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-dd42ca71-kafka-clients-878c8897f-ggmh5
2022-04-04 13:29:57 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6102b9bb, messages=[], arguments=[--topic, my-topic-1758098417-562417750, --max-messages, 100, --group-instance-id, instance732165501, --group-id, my-consumer-group-900824477, --bootstrap-server, my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-dd42ca71-kafka-clients-878c8897f-ggmh5', podNamespace='namespace-66', bootstrapServer='my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-1758098417-562417750', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-900824477', consumerInstanceId='instance732165501', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@10295010}
2022-04-04 13:29:57 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9092#my-topic-1758098417-562417750 from pod my-cluster-dd42ca71-kafka-clients-878c8897f-ggmh5
2022-04-04 13:29:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-dd42ca71-kafka-clients-878c8897f-ggmh5 -n namespace-66 -- /opt/kafka/consumer.sh --topic my-topic-1758098417-562417750 --max-messages 100 --group-instance-id instance732165501 --group-id my-consumer-group-900824477 --bootstrap-server my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9092
2022-04-04 13:30:03 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 13:30:03 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 13:30:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-dd42ca71 in namespace namespace-66
2022-04-04 13:30:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-04 13:30:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-dd42ca71 will have desired state: Ready
2022-04-04 13:30:04 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-dd42ca71 is in desired state: Ready
2022-04-04 13:30:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-dd42ca71-kafka-clients-tls in namespace namespace-66
2022-04-04 13:30:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-04 13:30:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-dd42ca71-kafka-clients-tls will be ready
2022-04-04 13:30:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-dd42ca71-kafka-clients-tls is ready
2022-04-04 13:30:06 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-dd42ca71-kafka-clients-tls-5cc5648d5d-5nlwc
2022-04-04 13:30:06 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3162e222, messages=[], arguments=[--topic, my-topic-1758098417-562417750, --max-messages, 100, --group-instance-id, instance755115069, --group-id, my-consumer-group-1800389954, USER=bob_my_cluster_dd42ca71, --bootstrap-server, my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-dd42ca71-kafka-clients-tls-5cc5648d5d-5nlwc', podNamespace='namespace-66', bootstrapServer='my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9093', topicName='my-topic-1758098417-562417750', maxMessages=100, kafkaUsername='bob-my-cluster-dd42ca71', consumerGroupName='my-consumer-group-1800389954', consumerInstanceId='instance755115069', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6b118680}
2022-04-04 13:30:06 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9093#my-topic-1758098417-562417750 from pod my-cluster-dd42ca71-kafka-clients-tls-5cc5648d5d-5nlwc
2022-04-04 13:30:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-dd42ca71-kafka-clients-tls-5cc5648d5d-5nlwc -n namespace-66 -- /opt/kafka/consumer.sh --topic my-topic-1758098417-562417750 --max-messages 100 --group-instance-id instance755115069 --group-id my-consumer-group-1800389954 USER=bob_my_cluster_dd42ca71 --bootstrap-server my-cluster-dd42ca71-kafka-bootstrap.namespace-66.svc:9093
2022-04-04 13:30:13 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 13:30:13 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 13:30:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 13:30:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-04 13:30:13 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-dd42ca71-kafka-clients in namespace namespace-66
2022-04-04 13:30:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-dd42ca71-kafka-clients-tls in namespace namespace-66
2022-04-04 13:30:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-114123489-1610539277 in namespace namespace-66
2022-04-04 13:30:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-dd42ca71 in namespace namespace-66
2022-04-04 13:30:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1758098417-562417750 in namespace namespace-66
2022-04-04 13:30:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-dd42ca71 in namespace namespace-66
2022-04-04 13:30:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-66, for cruise control Kafka cluster my-cluster-dd42ca71
2022-04-04 13:30:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 13:30:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-66 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-04 13:31:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-FINISHED
2022-04-04 13:31:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 13:31:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 13:31:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-STARTED
2022-04-04 13:31:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 13:31:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-67 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-04 13:31:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-67
2022-04-04 13:31:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-67
2022-04-04 13:31:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-67
2022-04-04 13:31:20 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 13:31:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c27aca8d in namespace namespace-67
2022-04-04 13:31:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-04 13:31:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c27aca8d will have desired state: Ready
2022-04-04 13:33:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c27aca8d is in desired state: Ready
2022-04-04 13:33:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1227519684-1210190961 in namespace namespace-67
2022-04-04 13:33:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-04 13:33:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1227519684-1210190961 will have desired state: Ready
2022-04-04 13:33:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1227519684-1210190961 is in desired state: Ready
2022-04-04 13:33:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1313342786-1912067514 in namespace namespace-67
2022-04-04 13:33:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-04 13:33:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1313342786-1912067514 will have desired state: Ready
2022-04-04 13:33:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1313342786-1912067514 is in desired state: Ready
2022-04-04 13:33:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c27aca8d-kafka-clients in namespace namespace-67
2022-04-04 13:33:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-04 13:33:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c27aca8d-kafka-clients will be ready
2022-04-04 13:33:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c27aca8d-kafka-clients is ready
2022-04-04 13:33:51 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 13:33:51 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-c27aca8d-kafka-clients-6d676f68bf-pdx72
2022-04-04 13:33:51 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3e972130, messages=[], arguments=[--topic, my-topic-1313342786-1912067514, --max-messages, 100, --bootstrap-server, my-cluster-c27aca8d-kafka-bootstrap.namespace-67.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-c27aca8d-kafka-clients-6d676f68bf-pdx72', podNamespace='namespace-67', bootstrapServer='my-cluster-c27aca8d-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1313342786-1912067514', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7912724}
2022-04-04 13:33:51 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-c27aca8d-kafka-bootstrap.namespace-67.svc:9092:my-topic-1313342786-1912067514 from pod my-cluster-c27aca8d-kafka-clients-6d676f68bf-pdx72
2022-04-04 13:33:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c27aca8d-kafka-clients-6d676f68bf-pdx72 -n namespace-67 -- /opt/kafka/producer.sh --topic my-topic-1313342786-1912067514 --max-messages 100 --bootstrap-server my-cluster-c27aca8d-kafka-bootstrap.namespace-67.svc:9092
2022-04-04 13:33:53 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 13:33:53 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 13:33:53 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3ce42d3d, messages=[], arguments=[--topic, my-topic-1313342786-1912067514, --max-messages, 100, --group-instance-id, instance836106737, --group-id, my-consumer-group-886903049, --bootstrap-server, my-cluster-c27aca8d-kafka-bootstrap.namespace-67.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c27aca8d-kafka-clients-6d676f68bf-pdx72', podNamespace='namespace-67', bootstrapServer='my-cluster-c27aca8d-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1313342786-1912067514', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-886903049', consumerInstanceId='instance836106737', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@32429456}
2022-04-04 13:33:53 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-c27aca8d-kafka-bootstrap.namespace-67.svc:9092#my-topic-1313342786-1912067514 from pod my-cluster-c27aca8d-kafka-clients-6d676f68bf-pdx72
2022-04-04 13:33:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c27aca8d-kafka-clients-6d676f68bf-pdx72 -n namespace-67 -- /opt/kafka/consumer.sh --topic my-topic-1313342786-1912067514 --max-messages 100 --group-instance-id instance836106737 --group-id my-consumer-group-886903049 --bootstrap-server my-cluster-c27aca8d-kafka-bootstrap.namespace-67.svc:9092
2022-04-04 13:33:59 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 13:33:59 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 13:33:59 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-04 13:33:59 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-c27aca8d-cluster-ca with strimzi.io/force-replace
2022-04-04 13:33:59 [main] [32mINFO [m [SecurityST:484] Wait for zk to rolling restart (1)...
2022-04-04 13:33:59 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c27aca8d-zookeeper rolling update
2022-04-04 13:35:24 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c27aca8d-zookeeper has been successfully rolled
2022-04-04 13:35:24 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-04 13:35:24 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c27aca8d-kafka rolling update
2022-04-04 13:36:49 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c27aca8d-kafka has been successfully rolled
2022-04-04 13:36:49 [main] [32mINFO [m [SecurityST:494] Wait for EO to rolling restart (1)...
2022-04-04 13:36:49 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c27aca8d-entity-operator rolling update
2022-04-04 13:37:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c27aca8d-entity-operator will be ready
2022-04-04 13:43:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c27aca8d-entity-operator is ready
2022-04-04 13:43:10 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-c27aca8d-entity-operator rolling update finished
2022-04-04 13:43:10 [main] [32mINFO [m [SecurityST:499] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-04-04 13:43:10 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c27aca8d-kafka-exporter rolling update
2022-04-04 13:47:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c27aca8d-kafka-exporter will be ready
2022-04-04 13:47:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c27aca8d-kafka-exporter is ready
2022-04-04 13:47:35 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-c27aca8d-kafka-exporter rolling update finished
2022-04-04 13:47:35 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c27aca8d-cruise-control rolling update
2022-04-04 13:47:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c27aca8d-cruise-control will be ready
2022-04-04 13:47:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c27aca8d-cruise-control is ready
2022-04-04 13:47:45 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-c27aca8d-cruise-control rolling update finished
2022-04-04 13:47:45 [main] [32mINFO [m [SecurityST:505] Wait for zk to rolling restart (2)...
2022-04-04 13:47:45 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c27aca8d-zookeeper rolling update
2022-04-04 13:47:45 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c27aca8d-zookeeper has been successfully rolled
2022-04-04 13:47:45 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-c27aca8d-zookeeper to be ready
2022-04-04 13:47:55 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-04 13:47:55 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c27aca8d-kafka rolling update
2022-04-04 13:47:55 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c27aca8d-kafka has been successfully rolled
2022-04-04 13:47:55 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-c27aca8d-kafka to be ready
2022-04-04 13:48:05 [main] [32mINFO [m [SecurityST:515] Wait for EO to rolling restart (2)...
2022-04-04 13:48:05 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c27aca8d-entity-operator rolling update
2022-04-04 13:48:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c27aca8d-entity-operator will be ready
2022-04-04 13:48:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c27aca8d-entity-operator is ready
2022-04-04 13:48:15 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-c27aca8d-entity-operator rolling update finished
2022-04-04 13:48:15 [main] [32mINFO [m [SecurityST:520] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-04-04 13:48:15 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c27aca8d-kafka-exporter rolling update
io.strimzi.test.WaitException: Timeout after 300000 ms waiting for Deployment my-cluster-c27aca8d-kafka-exporter rolling update in namespace:namespace-67
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils.waitTillDepHasRolled(DeploymentUtils.java:137)
	at io.strimzi.systemtest.security.SecurityST.autoReplaceSomeKeysTriggeredByAnno(SecurityST.java:521)
	at io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(SecurityST.java:373)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 13:53:15 [main] [1;31mERROR[m [TestExecutionWatcher:28] SecurityST - Exception Timeout after 300000 ms waiting for Deployment my-cluster-c27aca8d-kafka-exporter rolling update in namespace:namespace-67 has been thrown in @Test. Going to collect logs from components.
2022-04-04 13:53:15 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-04 13:53:16 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-04 13:53:16 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-04 13:53:27 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-04 13:53:27 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-04 13:53:27 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-04 13:53:27 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-04 13:53:27 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-04 13:53:27 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace namespace-67
2022-04-04 13:53:28 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace namespace-67
2022-04-04 13:53:28 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace namespace-67
2022-04-04 13:53:31 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace namespace-67
2022-04-04 13:53:31 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace namespace-67
2022-04-04 13:53:31 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace namespace-67
2022-04-04 13:53:31 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace namespace-67
2022-04-04 13:53:31 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-04 13:53:31 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace security-st
2022-04-04 13:53:31 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace security-st
2022-04-04 13:53:31 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace security-st
2022-04-04 13:53:31 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace security-st
2022-04-04 13:53:32 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace security-st
2022-04-04 13:53:32 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace security-st
2022-04-04 13:53:32 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace security-st
2022-04-04 13:53:32 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-04 13:53:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 13:53:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-04 13:53:32 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1313342786-1912067514 in namespace namespace-67
2022-04-04 13:53:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1227519684-1210190961 in namespace namespace-67
2022-04-04 13:53:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c27aca8d-kafka-clients in namespace namespace-67
2022-04-04 13:53:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c27aca8d in namespace namespace-67
2022-04-04 13:53:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-67, for cruise control Kafka cluster my-cluster-c27aca8d
2022-04-04 13:54:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 13:54:22 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-67 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-04 13:54:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-FINISHED
2022-04-04 13:54:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 13:54:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 13:54:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-STARTED
2022-04-04 13:54:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 13:54:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-68 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-04 13:54:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-68
2022-04-04 13:54:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-68
2022-04-04 13:54:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-68
2022-04-04 13:54:29 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-04 13:54:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a74dc06e in namespace namespace-68
2022-04-04 13:54:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-04 13:54:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a74dc06e will have desired state: Ready
2022-04-04 13:56:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a74dc06e is in desired state: Ready
2022-04-04 13:56:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2205750-1572472455 in namespace namespace-68
2022-04-04 13:56:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-04 13:56:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2205750-1572472455 will have desired state: Ready
2022-04-04 13:56:36 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2205750-1572472455 is in desired state: Ready
2022-04-04 13:56:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1822480896-309125236 in namespace namespace-68
2022-04-04 13:56:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-04 13:56:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1822480896-309125236 will have desired state: Ready
2022-04-04 13:56:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1822480896-309125236 is in desired state: Ready
2022-04-04 13:56:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a74dc06e-kafka-clients in namespace namespace-68
2022-04-04 13:56:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-04 13:56:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a74dc06e-kafka-clients will be ready
2022-04-04 13:56:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a74dc06e-kafka-clients is ready
2022-04-04 13:56:39 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 13:56:39 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-a74dc06e-kafka-clients-f99f9d96d-pgqnw
2022-04-04 13:56:39 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3646312f, messages=[], arguments=[--topic, my-topic-1822480896-309125236, --max-messages, 100, --bootstrap-server, my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a74dc06e-kafka-clients-f99f9d96d-pgqnw', podNamespace='namespace-68', bootstrapServer='my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1822480896-309125236', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6bb1d205}
2022-04-04 13:56:39 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092:my-topic-1822480896-309125236 from pod my-cluster-a74dc06e-kafka-clients-f99f9d96d-pgqnw
2022-04-04 13:56:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a74dc06e-kafka-clients-f99f9d96d-pgqnw -n namespace-68 -- /opt/kafka/producer.sh --topic my-topic-1822480896-309125236 --max-messages 100 --bootstrap-server my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092
2022-04-04 13:56:42 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 13:56:42 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 13:56:42 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@49b9aab1, messages=[], arguments=[--topic, my-topic-1822480896-309125236, --max-messages, 100, --group-instance-id, instance63534246, --group-id, my-consumer-group-1210253163, --bootstrap-server, my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a74dc06e-kafka-clients-f99f9d96d-pgqnw', podNamespace='namespace-68', bootstrapServer='my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1822480896-309125236', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1210253163', consumerInstanceId='instance63534246', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2c7d64c1}
2022-04-04 13:56:42 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092#my-topic-1822480896-309125236 from pod my-cluster-a74dc06e-kafka-clients-f99f9d96d-pgqnw
2022-04-04 13:56:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a74dc06e-kafka-clients-f99f9d96d-pgqnw -n namespace-68 -- /opt/kafka/consumer.sh --topic my-topic-1822480896-309125236 --max-messages 100 --group-instance-id instance63534246 --group-id my-consumer-group-1210253163 --bootstrap-server my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092
2022-04-04 13:56:48 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 13:56:48 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 13:56:48 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-04 13:56:48 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-a74dc06e-cluster-ca with strimzi.io/force-replace
2022-04-04 13:56:48 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-a74dc06e-clients-ca with strimzi.io/force-replace
2022-04-04 13:56:48 [main] [32mINFO [m [SecurityST:484] Wait for zk to rolling restart (1)...
2022-04-04 13:56:48 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a74dc06e-zookeeper rolling update
2022-04-04 13:58:28 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a74dc06e-zookeeper has been successfully rolled
2022-04-04 13:58:28 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-04 13:58:28 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a74dc06e-kafka rolling update
2022-04-04 13:59:58 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a74dc06e-kafka has been successfully rolled
2022-04-04 13:59:58 [main] [32mINFO [m [SecurityST:494] Wait for EO to rolling restart (1)...
2022-04-04 13:59:58 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a74dc06e-entity-operator rolling update
2022-04-04 14:00:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a74dc06e-entity-operator will be ready
2022-04-04 14:01:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a74dc06e-entity-operator is ready
2022-04-04 14:02:01 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a74dc06e-entity-operator rolling update finished
2022-04-04 14:02:02 [main] [32mINFO [m [SecurityST:499] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-04-04 14:02:02 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a74dc06e-kafka-exporter rolling update
2022-04-04 14:02:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a74dc06e-kafka-exporter will be ready
2022-04-04 14:02:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a74dc06e-kafka-exporter is ready
2022-04-04 14:02:29 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a74dc06e-kafka-exporter rolling update finished
2022-04-04 14:02:29 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a74dc06e-cruise-control rolling update
2022-04-04 14:02:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a74dc06e-cruise-control will be ready
2022-04-04 14:02:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a74dc06e-cruise-control is ready
2022-04-04 14:02:51 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a74dc06e-cruise-control rolling update finished
2022-04-04 14:02:51 [main] [32mINFO [m [SecurityST:505] Wait for zk to rolling restart (2)...
2022-04-04 14:02:51 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a74dc06e-zookeeper rolling update
2022-04-04 14:03:46 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a74dc06e-zookeeper has been successfully rolled
2022-04-04 14:03:46 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-a74dc06e-zookeeper to be ready
2022-04-04 14:04:18 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-04 14:04:18 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a74dc06e-kafka rolling update
2022-04-04 14:05:28 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a74dc06e-kafka has been successfully rolled
2022-04-04 14:05:28 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-a74dc06e-kafka to be ready
2022-04-04 14:05:59 [main] [32mINFO [m [SecurityST:515] Wait for EO to rolling restart (2)...
2022-04-04 14:05:59 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a74dc06e-entity-operator rolling update
2022-04-04 14:05:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a74dc06e-entity-operator will be ready
2022-04-04 14:06:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a74dc06e-entity-operator is ready
2022-04-04 14:06:54 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a74dc06e-entity-operator rolling update finished
2022-04-04 14:06:54 [main] [32mINFO [m [SecurityST:520] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-04-04 14:06:54 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a74dc06e-kafka-exporter rolling update
2022-04-04 14:07:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a74dc06e-kafka-exporter will be ready
2022-04-04 14:07:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a74dc06e-kafka-exporter is ready
2022-04-04 14:07:59 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a74dc06e-kafka-exporter rolling update finished
2022-04-04 14:07:59 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a74dc06e-cruise-control rolling update
2022-04-04 14:07:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a74dc06e-cruise-control will be ready
2022-04-04 14:07:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a74dc06e-cruise-control is ready
2022-04-04 14:08:09 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a74dc06e-cruise-control rolling update finished
2022-04-04 14:08:09 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-04 14:08:09 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-a74dc06e-kafka-clients-f99f9d96d-pgqnw
2022-04-04 14:08:09 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1b118bcb, messages=[], arguments=[--topic, my-topic-1822480896-309125236, --max-messages, 100, --group-instance-id, instance1282543090, --group-id, my-consumer-group-339226819, --bootstrap-server, my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a74dc06e-kafka-clients-f99f9d96d-pgqnw', podNamespace='namespace-68', bootstrapServer='my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1822480896-309125236', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-339226819', consumerInstanceId='instance1282543090', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@22cfbbd4}
2022-04-04 14:08:09 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092#my-topic-1822480896-309125236 from pod my-cluster-a74dc06e-kafka-clients-f99f9d96d-pgqnw
2022-04-04 14:08:09 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a74dc06e-kafka-clients-f99f9d96d-pgqnw -n namespace-68 -- /opt/kafka/consumer.sh --topic my-topic-1822480896-309125236 --max-messages 100 --group-instance-id instance1282543090 --group-id my-consumer-group-339226819 --bootstrap-server my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092
2022-04-04 14:08:15 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 14:08:15 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 14:08:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-348781527-670338830 in namespace namespace-68
2022-04-04 14:08:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-04 14:08:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-348781527-670338830 will have desired state: Ready
2022-04-04 14:08:16 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-348781527-670338830 is in desired state: Ready
2022-04-04 14:08:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a74dc06e-kafka-clients-tls in namespace namespace-68
2022-04-04 14:08:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-04 14:08:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a74dc06e-kafka-clients-tls will be ready
2022-04-04 14:08:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a74dc06e-kafka-clients-tls is ready
2022-04-04 14:08:17 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-a74dc06e-kafka-clients-tls-546d855f7d-bchzt
2022-04-04 14:08:17 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6948c86c, messages=[], arguments=[--topic, my-topic-1822480896-309125236, --max-messages, 100, --group-instance-id, instance505700330, --group-id, my-consumer-group-2052067639, --bootstrap-server, my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a74dc06e-kafka-clients-tls-546d855f7d-bchzt', podNamespace='namespace-68', bootstrapServer='my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1822480896-309125236', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2052067639', consumerInstanceId='instance505700330', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3606d463}
2022-04-04 14:08:17 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092#my-topic-1822480896-309125236 from pod my-cluster-a74dc06e-kafka-clients-tls-546d855f7d-bchzt
2022-04-04 14:08:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a74dc06e-kafka-clients-tls-546d855f7d-bchzt -n namespace-68 -- /opt/kafka/consumer.sh --topic my-topic-1822480896-309125236 --max-messages 100 --group-instance-id instance505700330 --group-id my-consumer-group-2052067639 --bootstrap-server my-cluster-a74dc06e-kafka-bootstrap.namespace-68.svc:9092
2022-04-04 14:08:23 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 14:08:23 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 14:08:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:08:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-04 14:08:23 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a74dc06e-kafka-clients in namespace namespace-68
2022-04-04 14:08:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2205750-1572472455 in namespace namespace-68
2022-04-04 14:08:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a74dc06e-kafka-clients-tls in namespace namespace-68
2022-04-04 14:08:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-348781527-670338830 in namespace namespace-68
2022-04-04 14:08:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1822480896-309125236 in namespace namespace-68
2022-04-04 14:08:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a74dc06e in namespace namespace-68
2022-04-04 14:08:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-68, for cruise control Kafka cluster my-cluster-a74dc06e
2022-04-04 14:09:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:09:03 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-68 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-04 14:09:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-FINISHED
2022-04-04 14:09:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:09:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:09:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-STARTED
2022-04-04 14:09:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:09:31 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-69 for test case:testClusterCACertRenew
2022-04-04 14:09:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-69
2022-04-04 14:09:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-69
2022-04-04 14:09:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-69
2022-04-04 14:09:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bc5ab6b3 in namespace namespace-69
2022-04-04 14:09:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-69
2022-04-04 14:09:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bc5ab6b3 will have desired state: Ready
2022-04-04 14:10:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bc5ab6b3 is in desired state: Ready
2022-04-04 14:10:53 [main] [32mINFO [m [SecurityST:1512] Change of kafka validity and renewal days - reconciliation should start.
2022-04-04 14:10:53 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-bc5ab6b3-zookeeper rolling update
2022-04-04 14:11:58 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-bc5ab6b3-zookeeper has been successfully rolled
2022-04-04 14:11:58 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-bc5ab6b3-zookeeper to be ready
2022-04-04 14:12:27 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-bc5ab6b3-kafka rolling update
2022-04-04 14:13:22 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-bc5ab6b3-kafka has been successfully rolled
2022-04-04 14:13:22 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-bc5ab6b3-kafka to be ready
2022-04-04 14:13:45 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-bc5ab6b3-entity-operator rolling update
2022-04-04 14:13:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bc5ab6b3-entity-operator will be ready
2022-04-04 14:14:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bc5ab6b3-entity-operator is ready
2022-04-04 14:14:36 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-bc5ab6b3-entity-operator rolling update finished
2022-04-04 14:14:36 [main] [32mINFO [m [SecurityST:1545] Initial ClusterCA cert dates: Mon Apr 04 14:09:31 UTC 2022 --> Sun Apr 24 14:09:31 UTC 2022
2022-04-04 14:14:36 [main] [32mINFO [m [SecurityST:1546] Changed ClusterCA cert dates: Mon Apr 04 14:10:54 UTC 2022 --> Fri Oct 21 14:10:54 UTC 2022
2022-04-04 14:14:36 [main] [32mINFO [m [SecurityST:1547] KafkaBroker cert creation dates: Mon Apr 04 14:10:00 UTC 2022 --> Sun Apr 24 14:10:00 UTC 2022
2022-04-04 14:14:36 [main] [32mINFO [m [SecurityST:1548] KafkaBroker cert changed dates:  Mon Apr 04 14:12:18 UTC 2022 --> Fri Oct 21 14:12:18 UTC 2022
2022-04-04 14:14:36 [main] [32mINFO [m [SecurityST:1549] Zookeeper cert creation dates: Mon Apr 04 14:09:34 UTC 2022 --> Sun Apr 24 14:09:34 UTC 2022
2022-04-04 14:14:36 [main] [32mINFO [m [SecurityST:1550] Zookeeper cert changed dates:  Mon Apr 04 14:10:55 UTC 2022 --> Fri Oct 21 14:10:55 UTC 2022
2022-04-04 14:14:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:14:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClusterCACertRenew
2022-04-04 14:14:36 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bc5ab6b3 in namespace namespace-69
2022-04-04 14:14:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:14:46 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-69 for test case:testClusterCACertRenew
2022-04-04 14:15:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-FINISHED
2022-04-04 14:15:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:15:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:15:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-STARTED
2022-04-04 14:15:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:15:30 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-70 for test case:testKafkaAndKafkaConnectTlsVersion
2022-04-04 14:15:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-70
2022-04-04 14:15:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-70
2022-04-04 14:15:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-70
2022-04-04 14:15:30 [main] [32mINFO [m [SecurityST:1287] Deploying Kafka cluster with the support TLSv1.2 TLS
2022-04-04 14:15:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cd339251 in namespace namespace-70
2022-04-04 14:15:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-04 14:15:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cd339251 will have desired state: Ready
2022-04-04 14:16:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cd339251 is in desired state: Ready
2022-04-04 14:16:44 [main] [32mINFO [m [SecurityST:1299] Verifying that Kafka cluster has the accepted configuration:
ssl.enabled.protocols -> TLSv1.2
ssl.protocol -> TLSv1.3
2022-04-04 14:16:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-cd339251-kafka-clients in namespace namespace-70
2022-04-04 14:16:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-04 14:16:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-cd339251-kafka-clients will be ready
2022-04-04 14:16:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-cd339251-kafka-clients is ready
2022-04-04 14:16:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-cd339251-scraper in namespace namespace-70
2022-04-04 14:16:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-04 14:16:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-cd339251-scraper will be ready
2022-04-04 14:16:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-cd339251-scraper is ready
2022-04-04 14:16:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-cd339251-scraper to be ready
2022-04-04 14:16:58 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-cd339251-scraper is ready
2022-04-04 14:16:58 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-cd339251-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 14:16:58 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-cd339251-allow in namespace namespace-70
2022-04-04 14:16:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-04 14:16:58 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 14:16:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-cd339251 in namespace namespace-70
2022-04-04 14:16:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-04 14:16:58 [main] [32mINFO [m [SecurityST:1322] Verifying that Kafka Connect status is NotReady because of different TLS version
2022-04-04 14:16:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-cd339251 will have desired state: NotReady
2022-04-04 14:22:00 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-cd339251 is in desired state: NotReady
2022-04-04 14:22:00 [main] [32mINFO [m [SecurityST:1326] Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.
2022-04-04 14:22:00 [main] [32mINFO [m [SecurityST:1330] Verifying that Kafka Connect has the accepted configuration:
 ssl.enabled.protocols -> TLSv1.2
 ssl.protocol -> TLSv1.3
2022-04-04 14:22:00 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-04-04 14:22:00 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-04-04 14:22:00 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-04-04 14:22:00 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-04-04 14:22:00 [main] [32mINFO [m [SecurityST:1339] Verifying that Kafka Connect is stable
2022-04-04 14:22:00 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-cd339251-connect are stable
2022-04-04 14:22:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 14:22:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 14:22:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 14:22:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 14:22:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 14:22:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 14:22:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 14:22:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 14:22:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 14:22:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 14:22:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 14:22:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 14:22:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 14:22:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 14:22:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 14:22:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 14:22:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 14:22:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 14:22:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 14:22:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 14:22:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 14:22:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 14:22:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 14:22:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 14:22:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 14:22:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 14:22:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 14:22:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 14:22:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 14:22:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 14:22:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 14:22:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 14:22:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 14:22:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 14:22:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 14:22:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 14:22:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 14:22:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 14:22:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 14:22:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 14:22:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 14:22:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 14:22:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 14:22:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 14:22:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 14:22:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 14:22:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 14:22:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 14:22:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 14:22:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cd339251-connect-5f798b85bb-kv4rd is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 14:22:49 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-cd339251-connect-5f798b85bb-kv4rd
2022-04-04 14:22:49 [main] [32mINFO [m [SecurityST:1343] Verifying that Kafka Connect status is Ready because of same TLS version
2022-04-04 14:22:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-cd339251 will have desired state: Ready
2022-04-04 14:28:20 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-cd339251 is in desired state: Ready
2022-04-04 14:28:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:28:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndKafkaConnectTlsVersion
2022-04-04 14:28:20 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-cd339251-scraper in namespace namespace-70
2022-04-04 14:28:20 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-cd339251-kafka-clients in namespace namespace-70
2022-04-04 14:28:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-cd339251 in namespace namespace-70
2022-04-04 14:28:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-cd339251-allow in namespace namespace-70
2022-04-04 14:28:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cd339251 in namespace namespace-70
2022-04-04 14:29:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:29:10 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-70 for test case:testKafkaAndKafkaConnectTlsVersion
2022-04-04 14:29:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-FINISHED
2022-04-04 14:29:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:29:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:29:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-STARTED
2022-04-04 14:29:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:29:16 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-71 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-04-04 14:29:16 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-71
2022-04-04 14:29:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-71
2022-04-04 14:29:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-71
2022-04-04 14:29:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ffe35772 in namespace namespace-71
2022-04-04 14:29:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-04 14:29:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ffe35772 will have desired state: Ready
2022-04-04 14:30:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ffe35772 is in desired state: Ready
2022-04-04 14:30:36 [main] [32mINFO [m [SecurityST:838] Getting IP of the bootstrap service
2022-04-04 14:30:36 [main] [32mINFO [m [SecurityST:842] KafkaConnect without config ssl.endpoint.identification.algorithm will not connect to 10.100.69.227:9093
2022-04-04 14:30:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ffe35772-kafka-clients in namespace namespace-71
2022-04-04 14:30:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-04 14:30:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ffe35772-kafka-clients will be ready
2022-04-04 14:30:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ffe35772-kafka-clients is ready
2022-04-04 14:30:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ffe35772-scraper in namespace namespace-71
2022-04-04 14:30:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-04 14:30:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ffe35772-scraper will be ready
2022-04-04 14:30:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ffe35772-scraper is ready
2022-04-04 14:30:38 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-ffe35772-scraper to be ready
2022-04-04 14:30:48 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-ffe35772-scraper is ready
2022-04-04 14:30:48 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-ffe35772-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 14:30:48 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-ffe35772-allow in namespace namespace-71
2022-04-04 14:30:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-04 14:30:48 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 14:30:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-ffe35772 in namespace namespace-71
2022-04-04 14:30:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-04 14:30:48 [main] [32mINFO [m [PodUtils:245] Wait until Pod my-cluster-ffe35772-connect is present
2022-04-04 14:30:49 [main] [32mINFO [m [PodUtils:249] Pod my-cluster-ffe35772-connect is present
2022-04-04 14:30:49 [main] [32mINFO [m [PodUtils:236] Wait until Pod my-cluster-ffe35772-connect-864cb49cb4-7tc95 is in CrashLoopBackOff state
2022-04-04 14:31:10 [main] [32mINFO [m [PodUtils:241] Pod my-cluster-ffe35772-connect-864cb49cb4-7tc95 is in CrashLoopBackOff state
2022-04-04 14:31:10 [main] [32mINFO [m [SecurityST:872] KafkaConnect with config ssl.endpoint.identification.algorithm will connect to 10.100.69.227:9093
2022-04-04 14:31:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-ffe35772 will have desired state: Ready
2022-04-04 14:36:56 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-ffe35772 is in desired state: Ready
2022-04-04 14:36:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:36:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsHostnameVerificationWithKafkaConnect
2022-04-04 14:36:56 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ffe35772-scraper in namespace namespace-71
2022-04-04 14:36:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ffe35772-kafka-clients in namespace namespace-71
2022-04-04 14:36:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-ffe35772 in namespace namespace-71
2022-04-04 14:36:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-ffe35772-allow in namespace namespace-71
2022-04-04 14:36:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ffe35772 in namespace namespace-71
2022-04-04 14:37:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:37:37 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-71 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-04-04 14:37:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-FINISHED
2022-04-04 14:37:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:37:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:37:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-STARTED
2022-04-04 14:37:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:37:47 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-72 for test case:testClientsCACertRenew
2022-04-04 14:37:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-72
2022-04-04 14:37:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-72
2022-04-04 14:37:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-72
2022-04-04 14:37:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0d840e6a in namespace namespace-72
2022-04-04 14:37:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-72
2022-04-04 14:37:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0d840e6a will have desired state: Ready
2022-04-04 14:39:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0d840e6a is in desired state: Ready
2022-04-04 14:39:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser strimzi-tls-user-833761729 in namespace namespace-72
2022-04-04 14:39:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-72
2022-04-04 14:39:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: strimzi-tls-user-833761729 will have desired state: Ready
2022-04-04 14:39:04 [main] [32mINFO [m [ResourceManager:444] KafkaUser: strimzi-tls-user-833761729 is in desired state: Ready
2022-04-04 14:39:04 [main] [32mINFO [m [SecurityST:1596] Change of kafka validity and renewal days - reconciliation should start.
2022-04-04 14:39:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 14:39:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 14:39:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 14:39:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 14:39:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 14:39:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 14:39:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 14:39:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 14:39:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 14:39:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 14:39:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 14:39:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 14:39:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 14:39:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 14:39:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 14:39:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 14:39:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 14:39:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 14:39:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 14:39:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 14:39:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 14:39:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 14:39:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 14:39:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 14:39:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 14:39:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 14:39:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 14:39:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 14:39:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 14:39:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 14:39:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 14:39:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 14:39:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 14:39:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 14:39:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 14:39:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 14:39:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 14:39:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 14:39:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 14:39:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 14:39:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 14:39:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 14:39:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 14:39:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 14:39:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 14:39:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 14:39:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 14:39:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 14:39:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 14:39:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 14:39:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-0d840e6a-zookeeper-1=a4d3f17e-46d7-4612-9e28-a39adf244ac1, my-cluster-0d840e6a-zookeeper-0=b4331f71-3728-4786-a87b-b47f82cd740a, my-cluster-0d840e6a-zookeeper-2=3548fc1d-28a3-4b6d-a8c8-ff567093a174} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 14:39:54 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-0d840e6a-kafka rolling update
2022-04-04 14:40:19 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-0d840e6a-kafka has been successfully rolled
2022-04-04 14:40:19 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-0d840e6a-kafka to be ready
2022-04-04 14:40:43 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-0d840e6a-entity-operator rolling update
2022-04-04 14:40:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0d840e6a-entity-operator will be ready
2022-04-04 14:41:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0d840e6a-entity-operator is ready
2022-04-04 14:41:36 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-0d840e6a-entity-operator rolling update finished
2022-04-04 14:41:36 [main] [32mINFO [m [SecurityST:1624] Initial ClientsCA cert dates: Mon Apr 04 14:37:48 UTC 2022 --> Sun Apr 24 14:37:48 UTC 2022
2022-04-04 14:41:36 [main] [32mINFO [m [SecurityST:1625] Changed ClientsCA cert dates: Mon Apr 04 14:39:04 UTC 2022 --> Fri Oct 21 14:39:04 UTC 2022
2022-04-04 14:41:36 [main] [32mINFO [m [SecurityST:1626] Initial userCert dates: Mon Apr 04 14:39:03 UTC 2022 --> Sun Apr 24 14:39:03 UTC 2022
2022-04-04 14:41:36 [main] [32mINFO [m [SecurityST:1627] Changed userCert dates: Mon Apr 04 14:40:42 UTC 2022 --> Fri Oct 21 14:40:42 UTC 2022
2022-04-04 14:41:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:41:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientsCACertRenew
2022-04-04 14:41:36 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser strimzi-tls-user-833761729 in namespace namespace-72
2022-04-04 14:41:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0d840e6a in namespace namespace-72
2022-04-04 14:41:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:41:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-72 for test case:testClientsCACertRenew
2022-04-04 14:42:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-FINISHED
2022-04-04 14:42:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:42:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:42:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertificates-STARTED
2022-04-04 14:42:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:42:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-73 for test case:testCertificates
2022-04-04 14:42:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-73
2022-04-04 14:42:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-73
2022-04-04 14:42:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-73
2022-04-04 14:42:22 [main] [32mINFO [m [SecurityST:118] Running testCertificates my-cluster-45cecc2e
2022-04-04 14:42:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-45cecc2e in namespace namespace-73
2022-04-04 14:42:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-73
2022-04-04 14:42:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-45cecc2e will have desired state: Ready
2022-04-04 14:43:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-45cecc2e is in desired state: Ready
2022-04-04 14:43:44 [main] [32mINFO [m [SecurityST:122] Check Kafka bootstrap certificate
2022-04-04 14:43:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-kafka-bootstrap:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-kafka-bootstrap
2022-04-04 14:43:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:45 [main] [32mINFO [m [SecurityST:125] OPENSSL OUTPUT: 

CONNECTED(00000003)
---
Certificate chain
 0 s:O = io.strimzi, CN = my-cluster-45cecc2e-kafka
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----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-----END CERTIFICATE-----
 1 s:O = io.strimzi, CN = cluster-ca v0
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUQMLlExERnydWn/Ip8YtuqRKqUtgwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDQxNDQyMjJaFw0yMzA0MDQxNDQyMjJaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQC257mU7DVaIvuxCJ4R6owcjeBFS1S1SzG9RrCBi0+W
IaKlRBjBYyg9jpgiwQ8wqfdmj+oeZO2F0CW7qZRQov2HLuI/rNbOovwl7dCid+hn
m//sKjpzXhSKNUkiqfxYqC97e+VvKfrF8CV7JYMVKY+/ASCJH9NqD2uhPP3QvUMB
Z+ztszYbCkLHBvNr/rdYZXtArizE8qpMyLj1H7tI9lHJ+5g3shQNMzktEcdgvtTK
RpF7bS50JUaNOuceKNk2vLuRGbboEjwOq7MuTcbENqwMcfZhEwp8mpfsF6d74bKA
8tICjnsUd1v2Vr4MsAXzJ60HF421Bcf40GSZwj5KpF70mioMCjDRZV/oRVg7W6TH
05WjoeRlhIlAOZx3aOr5Yjn4643LtQgCkHbL3WAiiHMGfYoFWST09RCmS/guMLm+
DyoUZbGMGGv67IwXjulnLuJ6WISppkiHbLf6J+F+YOlSsum0otL8Ky4uOdvemWId
dopu+5ThMnk02ZSieVzmz6LquEjVnXaVfXpiwfkr+mB0Qzt14PhOTPGux3vVZXcw
WCrbMzr3j/7B759fOpaUS6hsWtwIVJrx9iwV/t5QRuELN7a40XhmSZVrwAjaBpfk
KVFpH+/yOqzhMlJkFILBtJeUY6+Fi5rIZt2DtJLyaPsvzIdnUKqQOjwLaMp+0WcO
OQIDAQABo0UwQzAdBgNVHQ4EFgQUAXe4l92lnV0OiIteLhZKEa+aiWswEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AFzuj2hP0ed7+GqJKw3QaZmzcakMlkTYnspMEKtHju8Cx4bfzQiqT+HEIm/VFybU
ifqjIx4yweSQRqkEBgu/FOpQokXQyuIlSMW0qmFxPaMZS9F7ZSjIHVFlYrx4e+SW
X1ffxqGfx9wr7Yt706A/hXlsfI4rdGEf2Gye1iGWiwAib3K/CIveRXJftkBYg+iB
9ktq8kHC8qJurNa3yVxg5hVEFEDzKOf+4LD077ROAzBqsxpjD1HQqjUCsFXQ3je+
kv54/tt+4x0y8rYNriFQ6LMkaSa10zcQpSSjrZNWls7EyKN13cbJk1F1UjGD9EgH
/IpdFAsWePPKO2OmEI4wr5vJv8EGilKGiXZww2iwAIJ0nJNXajYBVT7ggNc5kkC8
fXOybAaOtQJFRhJr5JS1iwaelrPciAqrIogCSTbvru9ltM99ep5fiZCVlq6FbnBN
v81X1W9od0aJNfoks6AVid4M0hZoVRsARMseGc6Zz5OnEICDh3mlynSwpqWKbZru
h2CWr0P0jh6Nn9nZ8UM7hP5Jz60TKEA8HVfZDhVSVNJm5n5eefgIuGUv7pmwUGSE
8u8M6fsFyuEZtwkzZKIopamLkPJiOOydUtPwJjWWkynhoOxdDmOTLydavGTYv9aA
AVlcnHHs9DWwWDJsqyMTGbUVxIunHJKT9BRtzTLCZuJd
-----END CERTIFICATE-----
---
Server certificate
subject=O = io.strimzi, CN = my-cluster-45cecc2e-kafka

issuer=O = io.strimzi, CN = cluster-ca v0

---
No client certificate CA names sent
Peer signing digest: SHA256
Peer signature type: RSA-PSS
Server Temp Key: X25519, 253 bits
---
SSL handshake has read 3489 bytes and written 369 bytes
Verification: OK
Verified peername: my-cluster-45cecc2e-kafka-bootstrap
---
New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384
Server public key is 2048 bit
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
Early data was not sent
Verify return code: 0 (ok)
---



2022-04-04 14:43:45 [main] [32mINFO [m [SecurityST:128] Check zookeeper client certificate
2022-04-04 14:43:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-zookeeper-client:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-zookeeper-client -cert /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-0.key
2022-04-04 14:43:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:45 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 0
2022-04-04 14:43:45 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-04 14:43:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-kafka-0.my-cluster-45cecc2e-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-kafka-0.my-cluster-45cecc2e-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-0.key
2022-04-04 14:43:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:46 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-04 14:43:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-kafka-0.my-cluster-45cecc2e-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-kafka-0.my-cluster-45cecc2e-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-0.key
2022-04-04 14:43:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:46 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-04 14:43:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-zookeeper-0.my-cluster-45cecc2e-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-zookeeper-0.my-cluster-45cecc2e-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-45cecc2e-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-45cecc2e-zookeeper-0.key
2022-04-04 14:43:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:46 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-04 14:43:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-zookeeper-0.my-cluster-45cecc2e-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-zookeeper-0.my-cluster-45cecc2e-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-45cecc2e-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-45cecc2e-zookeeper-0.key
2022-04-04 14:43:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:46 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 1
2022-04-04 14:43:46 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-04 14:43:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-kafka-1.my-cluster-45cecc2e-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-kafka-1.my-cluster-45cecc2e-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-1.key
2022-04-04 14:43:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:46 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-04 14:43:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-kafka-1.my-cluster-45cecc2e-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-kafka-1.my-cluster-45cecc2e-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-1.key
2022-04-04 14:43:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:47 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-04 14:43:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-zookeeper-1.my-cluster-45cecc2e-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-zookeeper-1.my-cluster-45cecc2e-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-45cecc2e-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-45cecc2e-zookeeper-1.key
2022-04-04 14:43:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:47 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-04 14:43:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-zookeeper-1.my-cluster-45cecc2e-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-zookeeper-1.my-cluster-45cecc2e-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-45cecc2e-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-45cecc2e-zookeeper-1.key
2022-04-04 14:43:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:47 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 2
2022-04-04 14:43:47 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-04 14:43:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-kafka-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-kafka-2.my-cluster-45cecc2e-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-kafka-2.my-cluster-45cecc2e-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-2.crt -key /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-2.key
2022-04-04 14:43:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:47 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-04 14:43:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-kafka-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-kafka-2.my-cluster-45cecc2e-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-kafka-2.my-cluster-45cecc2e-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-2.crt -key /opt/kafka/broker-certs/my-cluster-45cecc2e-kafka-2.key
2022-04-04 14:43:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:48 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-04 14:43:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-zookeeper-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-zookeeper-2.my-cluster-45cecc2e-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-zookeeper-2.my-cluster-45cecc2e-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-45cecc2e-zookeeper-2.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-45cecc2e-zookeeper-2.key
2022-04-04 14:43:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:48 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-04 14:43:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-45cecc2e-zookeeper-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-45cecc2e-zookeeper-2.my-cluster-45cecc2e-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-45cecc2e-zookeeper-2.my-cluster-45cecc2e-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-45cecc2e-zookeeper-2.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-45cecc2e-zookeeper-2.key
2022-04-04 14:43:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 14:43:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:43:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificates
2022-04-04 14:43:48 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-45cecc2e in namespace namespace-73
2022-04-04 14:43:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:43:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-73 for test case:testCertificates
2022-04-04 14:44:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertificates-FINISHED
2022-04-04 14:44:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:44:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:44:41 [main] [32mINFO [m [ResourceManager:346] In context SecurityST is everything deleted.
2022-04-04 14:44:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 18, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 10,403.259 s <<< FAILURE! - in io.strimzi.systemtest.security.SecurityST
[[1;31mERROR[m] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(ExtensionContext)  Time elapsed: 1,388.657 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 300000 ms waiting for Deployment my-cluster-c27aca8d-kafka-exporter rolling update in namespace:namespace-67
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils.waitTillDepHasRolled(DeploymentUtils.java:137)
	at io.strimzi.systemtest.security.SecurityST.autoReplaceSomeKeysTriggeredByAnno(SecurityST.java:521)
	at io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(SecurityST.java:373)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.security.custom.CustomAuthorizerST
2022-04-04 14:44:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: custom-authorizer-st
2022-04-04 14:44:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: custom-authorizer-st
2022-04-04 14:44:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: custom-authorizer-st
2022-04-04 14:44:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka custom-authorizer in namespace custom-authorizer-st
2022-04-04 14:44:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: custom-authorizer will have desired state: Ready
2022-04-04 14:45:57 [main] [32mINFO [m [ResourceManager:444] Kafka: custom-authorizer is in desired state: Ready
2022-04-04 14:45:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:45:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclWithSuperUser-STARTED
2022-04-04 14:45:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:45:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-451576491-63277910 in namespace custom-authorizer-st
2022-04-04 14:45:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-451576491-63277910 will have desired state: Ready
2022-04-04 14:45:58 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-451576491-63277910 is in desired state: Ready
2022-04-04 14:45:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sre-admin in namespace custom-authorizer-st
2022-04-04 14:45:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sre-admin will have desired state: Ready
2022-04-04 14:45:59 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sre-admin is in desired state: Ready
2022-04-04 14:45:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b57a9c8c-kafka-clients in namespace custom-authorizer-st
2022-04-04 14:45:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b57a9c8c-kafka-clients will be ready
2022-04-04 14:46:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b57a9c8c-kafka-clients is ready
2022-04-04 14:46:00 [main] [32mINFO [m [CustomAuthorizerST:173] Checking kafka super user:sre-admin that is able to send messages to topic:my-topic-451576491-63277910
2022-04-04 14:46:00 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 14:46:00 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5800c7c9, messages=[], arguments=[--topic, my-topic-451576491-63277910, --max-messages, 100, USER=sre_admin, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b57a9c8c-kafka-clients-7845d9b76b-dzbxx', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-451576491-63277910', maxMessages=100, kafkaUsername='sre-admin', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6b297d6f}
2022-04-04 14:46:00 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-451576491-63277910 from pod my-cluster-b57a9c8c-kafka-clients-7845d9b76b-dzbxx
2022-04-04 14:46:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b57a9c8c-kafka-clients-7845d9b76b-dzbxx -n custom-authorizer-st -- /opt/kafka/producer.sh --topic my-topic-451576491-63277910 --max-messages 100 USER=sre_admin --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-04 14:46:04 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 14:46:04 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 14:46:04 [main] [32mINFO [m [CustomAuthorizerST:187] Checking kafka super user:sre-admin that is able to read messages to topic:my-topic-1670769365-1601814202 regardless that we configured Acls with only write operation
2022-04-04 14:46:04 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6b7b595b, messages=[], arguments=[--topic, my-topic-451576491-63277910, --max-messages, 100, --group-instance-id, instance1811008201, --group-id, my-consumer-group-1881399587, USER=sre_admin, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b57a9c8c-kafka-clients-7845d9b76b-dzbxx', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-451576491-63277910', maxMessages=100, kafkaUsername='sre-admin', consumerGroupName='my-consumer-group-1881399587', consumerInstanceId='instance1811008201', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4b998742}
2022-04-04 14:46:04 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-451576491-63277910 from pod my-cluster-b57a9c8c-kafka-clients-7845d9b76b-dzbxx
2022-04-04 14:46:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b57a9c8c-kafka-clients-7845d9b76b-dzbxx -n custom-authorizer-st -- /opt/kafka/consumer.sh --topic my-topic-451576491-63277910 --max-messages 100 --group-instance-id instance1811008201 --group-id my-consumer-group-1881399587 USER=sre_admin --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-04 14:46:11 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 14:46:11 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 14:46:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:46:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAclWithSuperUser
2022-04-04 14:46:11 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sre-admin in namespace custom-authorizer-st
2022-04-04 14:46:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b57a9c8c-kafka-clients in namespace custom-authorizer-st
2022-04-04 14:46:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-451576491-63277910 in namespace custom-authorizer-st
2022-04-04 14:46:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:46:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclWithSuperUser-FINISHED
2022-04-04 14:46:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:46:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:46:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclRuleReadAndWrite-STARTED
2022-04-04 14:46:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:46:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-384958141-1750174600 in namespace custom-authorizer-st
2022-04-04 14:46:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-384958141-1750174600 will have desired state: Ready
2022-04-04 14:46:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-384958141-1750174600 is in desired state: Ready
2022-04-04 14:46:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser kafka-user-write in namespace custom-authorizer-st
2022-04-04 14:46:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: kafka-user-write will have desired state: Ready
2022-04-04 14:46:53 [main] [32mINFO [m [ResourceManager:444] KafkaUser: kafka-user-write is in desired state: Ready
2022-04-04 14:46:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser kafka-user-read in namespace custom-authorizer-st
2022-04-04 14:46:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: kafka-user-read will have desired state: Ready
2022-04-04 14:46:54 [main] [32mINFO [m [ResourceManager:444] KafkaUser: kafka-user-read is in desired state: Ready
2022-04-04 14:46:54 [main] [32mINFO [m [CustomAuthorizerST:105] Checking KafkaUser kafka-user-write that is able to send messages to topic 'my-topic-384958141-1750174600'
2022-04-04 14:46:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-319fbf41-kafka-clients in namespace custom-authorizer-st
2022-04-04 14:46:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-319fbf41-kafka-clients will be ready
2022-04-04 14:46:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-319fbf41-kafka-clients is ready
2022-04-04 14:46:56 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 14:46:56 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@58ac4675, messages=[], arguments=[--topic, my-topic-384958141-1750174600, --max-messages, 500, USER=kafka_user_write, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-319fbf41-kafka-clients-fcdf69ddb-8xn8x', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-384958141-1750174600', maxMessages=500, kafkaUsername='kafka-user-write', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@d08b73b}
2022-04-04 14:46:56 [main] [32mINFO [m [InternalKafkaClient:124] Producing 500 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-384958141-1750174600 from pod my-cluster-319fbf41-kafka-clients-fcdf69ddb-8xn8x
2022-04-04 14:46:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-319fbf41-kafka-clients-fcdf69ddb-8xn8x -n custom-authorizer-st -- /opt/kafka/producer.sh --topic my-topic-384958141-1750174600 --max-messages 500 USER=kafka_user_write --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-04 14:47:00 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 14:47:00 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 500 messages
2022-04-04 14:47:00 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@22a760c7, messages=[], arguments=[--topic, my-topic-384958141-1750174600, --max-messages, 500, --group-instance-id, instance347944374, --group-id, my-consumer-group-1454622878, USER=kafka_user_write, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-319fbf41-kafka-clients-fcdf69ddb-8xn8x', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-384958141-1750174600', maxMessages=500, kafkaUsername='kafka-user-write', consumerGroupName='my-consumer-group-1454622878', consumerInstanceId='instance347944374', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4065b4ab}
2022-04-04 14:47:00 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 500 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-384958141-1750174600 from pod my-cluster-319fbf41-kafka-clients-fcdf69ddb-8xn8x
2022-04-04 14:47:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-319fbf41-kafka-clients-fcdf69ddb-8xn8x -n custom-authorizer-st -- /opt/kafka/consumer.sh --topic my-topic-384958141-1750174600 --max-messages 500 --group-instance-id instance347944374 --group-id my-consumer-group-1454622878 USER=kafka_user_write --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-04 14:47:04 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 14:47:04 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 0 messages
2022-04-04 14:47:04 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@50fbc617, messages=[], arguments=[--topic, my-topic-384958141-1750174600, --max-messages, 500, --group-instance-id, instance832420795, --group-id, consumer-group-name-1, USER=kafka_user_read, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-319fbf41-kafka-clients-fcdf69ddb-8xn8x', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-384958141-1750174600', maxMessages=500, kafkaUsername='kafka-user-read', consumerGroupName='consumer-group-name-1', consumerInstanceId='instance832420795', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6a5ebac7}
2022-04-04 14:47:04 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 500 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-384958141-1750174600 from pod my-cluster-319fbf41-kafka-clients-fcdf69ddb-8xn8x
2022-04-04 14:47:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-319fbf41-kafka-clients-fcdf69ddb-8xn8x -n custom-authorizer-st -- /opt/kafka/consumer.sh --topic my-topic-384958141-1750174600 --max-messages 500 --group-instance-id instance832420795 --group-id consumer-group-name-1 USER=kafka_user_read --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-04 14:47:10 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 14:47:10 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 500 messages
2022-04-04 14:47:10 [main] [32mINFO [m [CustomAuthorizerST:137] Checking KafkaUser kafka-user-read that is not able to send messages to topic 'my-topic-384958141-1750174600'
2022-04-04 14:47:10 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@24ee1e7a, messages=[], arguments=[--topic, my-topic-384958141-1750174600, --max-messages, 500, USER=kafka_user_read, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-319fbf41-kafka-clients-fcdf69ddb-8xn8x', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-384958141-1750174600', maxMessages=500, kafkaUsername='kafka-user-read', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3d56e04f}
2022-04-04 14:47:10 [main] [32mINFO [m [InternalKafkaClient:124] Producing 500 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-384958141-1750174600 from pod my-cluster-319fbf41-kafka-clients-fcdf69ddb-8xn8x
2022-04-04 14:47:10 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-319fbf41-kafka-clients-fcdf69ddb-8xn8x -n custom-authorizer-st -- /opt/kafka/producer.sh --topic my-topic-384958141-1750174600 --max-messages 500 USER=kafka_user_read --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093
2022-04-04 14:47:14 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 14:47:14 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced -1 messages
2022-04-04 14:47:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:47:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAclRuleReadAndWrite
2022-04-04 14:47:14 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser kafka-user-read in namespace custom-authorizer-st
2022-04-04 14:47:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser kafka-user-write in namespace custom-authorizer-st
2022-04-04 14:47:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-319fbf41-kafka-clients in namespace custom-authorizer-st
2022-04-04 14:47:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-384958141-1750174600 in namespace custom-authorizer-st
2022-04-04 14:48:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:48:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclRuleReadAndWrite-FINISHED
2022-04-04 14:48:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:48:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:48:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for CustomAuthorizerST
2022-04-04 14:48:04 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka custom-authorizer in namespace custom-authorizer-st
2022-04-04 14:48:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 234.423 s - in io.strimzi.systemtest.security.custom.CustomAuthorizerST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
2022-04-04 14:48:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: alternative-reconcile-triggers-st
2022-04-04 14:48:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: alternative-reconcile-triggers-st
2022-04-04 14:48:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: alternative-reconcile-triggers-st
2022-04-04 14:48:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:48:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualRollingUpdateForSinglePod-STARTED
2022-04-04 14:48:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:48:41 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-74 for test case:testManualRollingUpdateForSinglePod
2022-04-04 14:48:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-74
2022-04-04 14:48:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-74
2022-04-04 14:48:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-74
2022-04-04 14:48:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-15df2ebf in namespace namespace-74
2022-04-04 14:48:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-74
2022-04-04 14:48:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-15df2ebf will have desired state: Ready
2022-04-04 14:49:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-15df2ebf is in desired state: Ready
2022-04-04 14:49:56 [main] [32mINFO [m [AlternativeReconcileTriggersST:290] Trying to roll just single Kafka and single ZK pod
2022-04-04 14:49:56 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-15df2ebf-kafka rolling update
2022-04-04 14:50:11 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-15df2ebf-kafka has been successfully rolled
2022-04-04 14:50:11 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-15df2ebf-kafka to be ready
2022-04-04 14:50:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-15df2ebf will have desired state: Ready
2022-04-04 14:50:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-15df2ebf is in desired state: Ready
2022-04-04 14:50:32 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-15df2ebf is ready
2022-04-04 14:50:32 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-15df2ebf-zookeeper rolling update
2022-04-04 14:50:52 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-15df2ebf-zookeeper has been successfully rolled
2022-04-04 14:50:52 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-15df2ebf-zookeeper to be ready
2022-04-04 14:51:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-15df2ebf will have desired state: Ready
2022-04-04 14:51:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-15df2ebf is in desired state: Ready
2022-04-04 14:51:18 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-15df2ebf is ready
2022-04-04 14:51:18 [main] [32mINFO [m [AlternativeReconcileTriggersST:311] Adding anno to all ZK and Kafka pods
2022-04-04 14:51:18 [main] [32mINFO [m [AlternativeReconcileTriggersST:320] Checking if the rolling update will be successful for Kafka
2022-04-04 14:51:18 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-15df2ebf-kafka rolling update
2022-04-04 14:52:58 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-15df2ebf-kafka has been successfully rolled
2022-04-04 14:52:58 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-15df2ebf-kafka to be ready
2022-04-04 14:53:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-15df2ebf will have desired state: Ready
2022-04-04 14:53:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-15df2ebf is in desired state: Ready
2022-04-04 14:53:27 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-15df2ebf is ready
2022-04-04 14:53:28 [main] [32mINFO [m [AlternativeReconcileTriggersST:331] Checking if the rolling update will be successful for ZK
2022-04-04 14:53:28 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-15df2ebf-zookeeper rolling update
2022-04-04 14:54:58 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-15df2ebf-zookeeper has been successfully rolled
2022-04-04 14:54:58 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-15df2ebf-zookeeper to be ready
2022-04-04 14:55:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-15df2ebf will have desired state: Ready
2022-04-04 14:55:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-15df2ebf is in desired state: Ready
2022-04-04 14:55:28 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-15df2ebf is ready
2022-04-04 14:55:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 14:55:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualRollingUpdateForSinglePod
2022-04-04 14:55:28 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-15df2ebf in namespace namespace-74
2022-04-04 14:55:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 14:55:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-74 for test case:testManualRollingUpdateForSinglePod
2022-04-04 14:56:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualRollingUpdateForSinglePod-FINISHED
2022-04-04 14:56:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 14:56:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 14:56:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualTriggeringRollingUpdate-STARTED
2022-04-04 14:56:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 14:56:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-75 for test case:testManualTriggeringRollingUpdate
2022-04-04 14:56:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-75
2022-04-04 14:56:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-75
2022-04-04 14:56:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-75
2022-04-04 14:56:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2c8c5343 in namespace namespace-75
2022-04-04 14:56:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:56:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2c8c5343 will have desired state: Ready
2022-04-04 14:57:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2c8c5343 is in desired state: Ready
2022-04-04 14:57:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1361240296-816468593 in namespace namespace-75
2022-04-04 14:57:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:57:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1361240296-816468593 will have desired state: Ready
2022-04-04 14:57:41 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1361240296-816468593 is in desired state: Ready
2022-04-04 14:57:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic continuous-topic in namespace namespace-75
2022-04-04 14:57:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:57:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: continuous-topic will have desired state: Ready
2022-04-04 14:57:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: continuous-topic is in desired state: Ready
2022-04-04 14:57:42 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 14:57:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace namespace-75
2022-04-04 14:57:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:57:42 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-04 14:57:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace namespace-75
2022-04-04 14:57:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:57:43 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-04 14:57:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1307713587-1552667770 in namespace namespace-75
2022-04-04 14:57:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:57:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1307713587-1552667770 will have desired state: Ready
2022-04-04 14:57:45 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1307713587-1552667770 is in desired state: Ready
2022-04-04 14:57:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2c8c5343-kafka-clients in namespace namespace-75
2022-04-04 14:57:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 14:57:55 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 14:57:55 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@66140c8b, messages=[], arguments=[--topic, my-topic-1361240296-816468593, --max-messages, 100, USER=my_user_1307713587_1552667770, --bootstrap-server, my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5', podNamespace='namespace-75', bootstrapServer='my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-1361240296-816468593', maxMessages=100, kafkaUsername='my-user-1307713587-1552667770', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5033eb1b}
2022-04-04 14:57:55 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093:my-topic-1361240296-816468593 from pod my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5
2022-04-04 14:57:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5 -n namespace-75 -- /opt/kafka/producer.sh --topic my-topic-1361240296-816468593 --max-messages 100 USER=my_user_1307713587_1552667770 --bootstrap-server my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093
2022-04-04 14:57:59 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 14:57:59 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 14:57:59 [main] [32mINFO [m [AlternativeReconcileTriggersST:145] Annotate Kafka StatefulSet my-cluster-2c8c5343-kafka with manual rolling update annotation
2022-04-04 14:57:59 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-2c8c5343-kafka rolling update
2022-04-04 14:59:39 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-2c8c5343-kafka has been successfully rolled
2022-04-04 14:59:39 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-2c8c5343-kafka to be ready
2022-04-04 15:00:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2c8c5343 will have desired state: Ready
2022-04-04 15:00:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2c8c5343 is in desired state: Ready
2022-04-04 15:00:10 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2c8c5343 is ready
2022-04-04 15:00:10 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7df2624f, messages=[], arguments=[--topic, my-topic-1361240296-816468593, --max-messages, 100, --group-instance-id, instance347649148, --group-id, my-consumer-group-1048248140, USER=my_user_1307713587_1552667770, --bootstrap-server, my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5', podNamespace='namespace-75', bootstrapServer='my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-1361240296-816468593', maxMessages=100, kafkaUsername='my-user-1307713587-1552667770', consumerGroupName='my-consumer-group-1048248140', consumerInstanceId='instance347649148', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3bf1321d}
2022-04-04 15:00:10 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093:my-topic-1361240296-816468593 from pod my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5
2022-04-04 15:00:10 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5 -n namespace-75 -- /opt/kafka/consumer.sh --topic my-topic-1361240296-816468593 --max-messages 100 --group-instance-id instance347649148 --group-id my-consumer-group-1048248140 USER=my_user_1307713587_1552667770 --bootstrap-server my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093
2022-04-04 15:00:17 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:00:17 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:00:17 [main] [32mINFO [m [AlternativeReconcileTriggersST:166] Annotate Zookeeper StatefulSet my-cluster-2c8c5343-zookeeper with manual rolling update annotation
2022-04-04 15:00:17 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-2c8c5343-zookeeper rolling update
2022-04-04 15:01:37 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-2c8c5343-zookeeper has been successfully rolled
2022-04-04 15:01:37 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-2c8c5343-zookeeper to be ready
2022-04-04 15:02:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2c8c5343 will have desired state: Ready
2022-04-04 15:02:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2c8c5343 is in desired state: Ready
2022-04-04 15:02:00 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2c8c5343 is ready
2022-04-04 15:02:00 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4b22e312, messages=[], arguments=[--topic, my-topic-1361240296-816468593, --max-messages, 100, --group-instance-id, instance1376130300, --group-id, my-consumer-group-582347942, USER=my_user_1307713587_1552667770, --bootstrap-server, my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5', podNamespace='namespace-75', bootstrapServer='my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-1361240296-816468593', maxMessages=100, kafkaUsername='my-user-1307713587-1552667770', consumerGroupName='my-consumer-group-582347942', consumerInstanceId='instance1376130300', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@24f1b8f}
2022-04-04 15:02:00 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093:my-topic-1361240296-816468593 from pod my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5
2022-04-04 15:02:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5 -n namespace-75 -- /opt/kafka/consumer.sh --topic my-topic-1361240296-816468593 --max-messages 100 --group-instance-id instance1376130300 --group-id my-consumer-group-582347942 USER=my_user_1307713587_1552667770 --bootstrap-server my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093
2022-04-04 15:02:06 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:02:06 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:02:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2084711664-1772064498 in namespace namespace-75
2022-04-04 15:02:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-04 15:02:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2084711664-1772064498 will have desired state: Ready
2022-04-04 15:02:07 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2084711664-1772064498 is in desired state: Ready
2022-04-04 15:02:08 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@610a19e6, messages=[], arguments=[--topic, my-topic-2084711664-1772064498, --max-messages, 100, USER=my_user_1307713587_1552667770, --bootstrap-server, my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5', podNamespace='namespace-75', bootstrapServer='my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-2084711664-1772064498', maxMessages=100, kafkaUsername='my-user-1307713587-1552667770', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1be3ea76}
2022-04-04 15:02:08 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093:my-topic-2084711664-1772064498 from pod my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5
2022-04-04 15:02:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5 -n namespace-75 -- /opt/kafka/producer.sh --topic my-topic-2084711664-1772064498 --max-messages 100 USER=my_user_1307713587_1552667770 --bootstrap-server my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093
2022-04-04 15:02:11 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 15:02:11 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 15:02:11 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@25f2d73b, messages=[], arguments=[--topic, my-topic-2084711664-1772064498, --max-messages, 100, --group-instance-id, instance295867884, --group-id, my-consumer-group-1892284225, USER=my_user_1307713587_1552667770, --bootstrap-server, my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5', podNamespace='namespace-75', bootstrapServer='my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-2084711664-1772064498', maxMessages=100, kafkaUsername='my-user-1307713587-1552667770', consumerGroupName='my-consumer-group-1892284225', consumerInstanceId='instance295867884', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3dec5ca6}
2022-04-04 15:02:11 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093:my-topic-2084711664-1772064498 from pod my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5
2022-04-04 15:02:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2c8c5343-kafka-clients-7fcc486f66-gt6v5 -n namespace-75 -- /opt/kafka/consumer.sh --topic my-topic-2084711664-1772064498 --max-messages 100 --group-instance-id instance295867884 --group-id my-consumer-group-1892284225 USER=my_user_1307713587_1552667770 --bootstrap-server my-cluster-2c8c5343-kafka-bootstrap.namespace-75.svc:9093
2022-04-04 15:02:18 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:02:18 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:02:18 [main] [32mINFO [m [ClientUtils:61] Waiting till producer hello-world-producer and consumer hello-world-consumer finish
2022-04-04 15:06:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:06:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualTriggeringRollingUpdate
2022-04-04 15:06:29 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1307713587-1552667770 in namespace namespace-75
2022-04-04 15:06:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic continuous-topic in namespace namespace-75
2022-04-04 15:06:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2084711664-1772064498 in namespace namespace-75
2022-04-04 15:06:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace namespace-75
2022-04-04 15:06:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1361240296-816468593 in namespace namespace-75
2022-04-04 15:06:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace namespace-75
2022-04-04 15:06:39 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2c8c5343-kafka-clients in namespace namespace-75
2022-04-04 15:06:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2c8c5343 in namespace namespace-75
2022-04-04 15:07:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:07:29 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-75 for test case:testManualTriggeringRollingUpdate
2022-04-04 15:07:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualTriggeringRollingUpdate-FINISHED
2022-04-04 15:07:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:07:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:07:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testAddingAndRemovingJbodVolumes-STARTED
2022-04-04 15:07:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:07:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-76 for test case:testAddingAndRemovingJbodVolumes
2022-04-04 15:07:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-76
2022-04-04 15:07:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-76
2022-04-04 15:07:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-76
2022-04-04 15:07:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2240048e in namespace namespace-76
2022-04-04 15:07:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:07:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2240048e will have desired state: Ready
2022-04-04 15:08:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2240048e is in desired state: Ready
2022-04-04 15:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-588220212-580156627 in namespace namespace-76
2022-04-04 15:08:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:08:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-588220212-580156627 will have desired state: Ready
2022-04-04 15:08:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-588220212-580156627 is in desired state: Ready
2022-04-04 15:08:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic continuous-topic in namespace namespace-76
2022-04-04 15:08:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:08:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: continuous-topic will have desired state: Ready
2022-04-04 15:08:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: continuous-topic is in desired state: Ready
2022-04-04 15:08:52 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 15:08:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace namespace-76
2022-04-04 15:08:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:08:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-04 15:08:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace namespace-76
2022-04-04 15:08:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:08:53 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-04 15:08:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-341757507-954178044 in namespace namespace-76
2022-04-04 15:08:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:08:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-341757507-954178044 will have desired state: Ready
2022-04-04 15:08:56 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-341757507-954178044 is in desired state: Ready
2022-04-04 15:08:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2240048e-kafka-clients in namespace namespace-76
2022-04-04 15:08:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-04 15:09:06 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 15:09:06 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6948f680, messages=[], arguments=[--topic, my-topic-588220212-580156627, --max-messages, 100, USER=my_user_341757507_954178044, --bootstrap-server, my-cluster-2240048e-kafka-bootstrap.namespace-76.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-2240048e-kafka-clients-7c6984b4-4prfg', podNamespace='namespace-76', bootstrapServer='my-cluster-2240048e-kafka-bootstrap.namespace-76.svc:9093', topicName='my-topic-588220212-580156627', maxMessages=100, kafkaUsername='my-user-341757507-954178044', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2c3bdbe}
2022-04-04 15:09:06 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-2240048e-kafka-bootstrap.namespace-76.svc:9093:my-topic-588220212-580156627 from pod my-cluster-2240048e-kafka-clients-7c6984b4-4prfg
2022-04-04 15:09:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-2240048e-kafka-clients-7c6984b4-4prfg -n namespace-76 -- /opt/kafka/producer.sh --topic my-topic-588220212-580156627 --max-messages 100 USER=my_user_341757507_954178044 --bootstrap-server my-cluster-2240048e-kafka-bootstrap.namespace-76.svc:9093
2022-04-04 15:09:10 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 15:09:10 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 15:09:10 [main] [32mINFO [m [AlternativeReconcileTriggersST:408] Add JBOD volume to the Kafka cluster my-cluster-2240048e-kafka
2022-04-04 15:09:10 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-2240048e-kafka rolling update
2022-04-04 15:10:20 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-2240048e-kafka has been successfully rolled
2022-04-04 15:10:20 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-2240048e-kafka to be ready
2022-04-04 15:10:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2240048e will have desired state: Ready
2022-04-04 15:10:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2240048e is in desired state: Ready
2022-04-04 15:10:51 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2240048e is ready
2022-04-04 15:10:51 [main] [32mINFO [m [AlternativeReconcileTriggersST:419] Remove JBOD volume to the Kafka cluster my-cluster-2240048e-kafka
2022-04-04 15:10:51 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-2240048e-kafka rolling update
2022-04-04 15:12:11 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-2240048e-kafka has been successfully rolled
2022-04-04 15:12:11 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-2240048e-kafka to be ready
2022-04-04 15:12:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2240048e will have desired state: Ready
2022-04-04 15:12:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2240048e is in desired state: Ready
2022-04-04 15:12:38 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-2240048e is ready
2022-04-04 15:12:38 [main] [32mINFO [m [ClientUtils:61] Waiting till producer hello-world-producer and consumer hello-world-consumer finish
2022-04-04 15:18:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:18:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAddingAndRemovingJbodVolumes
2022-04-04 15:18:11 [main] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace namespace-76
2022-04-04 15:18:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-588220212-580156627 in namespace namespace-76
2022-04-04 15:18:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2240048e in namespace namespace-76
2022-04-04 15:18:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic continuous-topic in namespace namespace-76
2022-04-04 15:18:11 [main] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace namespace-76
2022-04-04 15:18:11 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2240048e-kafka-clients in namespace namespace-76
2022-04-04 15:18:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-341757507-954178044 in namespace namespace-76
2022-04-04 15:19:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:19:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-76 for test case:testAddingAndRemovingJbodVolumes
2022-04-04 15:19:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testAddingAndRemovingJbodVolumes-FINISHED
2022-04-04 15:19:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:19:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:19:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testTriggerRollingUpdateAfterOverrideBootstrap-STARTED
2022-04-04 15:19:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:19:12 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-77 for test case:testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-04 15:19:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-77
2022-04-04 15:19:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-77
2022-04-04 15:19:13 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-77
2022-04-04 15:19:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a5f128ea in namespace namespace-77
2022-04-04 15:19:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-77
2022-04-04 15:19:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a5f128ea will have desired state: Ready
2022-04-04 15:20:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a5f128ea is in desired state: Ready
2022-04-04 15:20:23 [main] [32mINFO [m [AlternativeReconcileTriggersST:228] Adding new bootstrap dns: kafka-test.XXXX.azure.XXXX.net to external listeners
2022-04-04 15:20:23 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a5f128ea-kafka rolling update
2022-04-04 15:21:38 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a5f128ea-kafka has been successfully rolled
2022-04-04 15:21:38 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-a5f128ea-kafka to be ready
2022-04-04 15:22:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a5f128ea will have desired state: Ready
2022-04-04 15:22:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a5f128ea is in desired state: Ready
2022-04-04 15:22:11 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-a5f128ea is ready
2022-04-04 15:22:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a5f128ea will have desired state: Ready
2022-04-04 15:22:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a5f128ea is in desired state: Ready
2022-04-04 15:22:11 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-a5f128ea-kafka-0.crt cert
2022-04-04 15:22:11 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-04 15:22:11 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-a5f128ea-kafka-1.crt cert
2022-04-04 15:22:11 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-04 15:22:11 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-a5f128ea-kafka-2.crt cert
2022-04-04 15:22:11 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-04 15:22:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:22:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-04 15:22:11 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a5f128ea in namespace namespace-77
2022-04-04 15:22:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:22:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-77 for test case:testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-04 15:23:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testTriggerRollingUpdateAfterOverrideBootstrap-FINISHED
2022-04-04 15:23:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:23:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:23:04 [main] [32mINFO [m [ResourceManager:346] In context AlternativeReconcileTriggersST is everything deleted.
2022-04-04 15:23:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,068.715 s - in io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-04 15:23:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: rolling-update-st
2022-04-04 15:23:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: rolling-update-st
2022-04-04 15:23:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: rolling-update-st
2022-04-04 15:23:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:23:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testMetricsChange-STARTED
2022-04-04 15:23:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:23:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-aca5f99a in namespace rolling-update-st
2022-04-04 15:23:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-aca5f99a will have desired state: Ready
2022-04-04 15:25:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-aca5f99a is in desired state: Ready
2022-04-04 15:25:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-aca5f99a-kafka-clients in namespace rolling-update-st
2022-04-04 15:25:21 [main] [32mINFO [m [RollingUpdateST:755] Check if metrics are present in pod of Kafka and Zookeeper
2022-04-04 15:25:21 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 0
2022-04-04 15:25:22 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 0
2022-04-04 15:25:23 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 0
2022-04-04 15:25:23 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 0
2022-04-04 15:25:24 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 0
2022-04-04 15:25:24 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 0
2022-04-04 15:25:24 [main] [32mINFO [m [RollingUpdateST:765] Changing metrics to something else
2022-04-04 15:25:24 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-aca5f99a-zookeeper are stable
2022-04-04 15:25:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:25:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:25:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:25:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:25:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:25:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:25:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:25:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:25:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:25:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:25:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:25:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:25:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:25:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:25:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:25:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:25:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:25:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:25:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:25:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:25:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:25:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:25:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:25:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:25:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:25:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:25:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:25:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:25:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:25:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:25:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:25:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:25:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:25:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:25:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:25:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:25:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:25:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:25:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:25:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:25:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:25:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:25:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:25:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:25:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:25:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:25:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:25:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:25:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:25:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:25:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:25:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:25:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:25:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:25:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:25:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:25:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:25:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:25:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:25:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:25:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:25:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:25:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:25:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:25:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:25:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:25:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:25:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:25:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:25:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:25:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:25:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:25:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:25:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:25:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:25:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:25:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:25:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:25:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:25:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:25:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:25:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:25:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:25:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:25:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:25:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:25:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:25:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:25:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:25:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:25:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:25:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:25:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:25:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:25:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:25:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:25:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:25:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:25:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:25:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:25:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:25:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:25:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:25:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:25:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:26:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:26:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:26:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:26:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:26:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:26:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:26:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:26:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:26:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:26:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:26:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:26:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:26:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:26:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:26:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:26:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:26:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:26:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:26:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:26:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:26:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:26:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:26:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:26:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:26:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:26:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:26:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:26:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:26:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:26:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:26:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:26:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:26:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:26:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:26:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:26:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:26:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:26:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:26:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:26:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:26:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:26:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:26:14 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-aca5f99a-zookeeper-0 ,my-cluster-aca5f99a-zookeeper-1 ,my-cluster-aca5f99a-zookeeper-2
2022-04-04 15:26:14 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-aca5f99a-kafka are stable
2022-04-04 15:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:26:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:26:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:26:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:26:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:26:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:26:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:26:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:26:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:26:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:26:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:26:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:26:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:26:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:26:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:26:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:26:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:26:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:26:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:26:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:26:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:26:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:26:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:26:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:26:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:26:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:26:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:26:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:26:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:26:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:26:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:26:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:26:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:26:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:26:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:26:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:26:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:26:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:26:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:26:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:26:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:26:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:26:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:26:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:26:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:26:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:26:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:26:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:26:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:26:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:26:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:26:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:26:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:26:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:26:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:26:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:26:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:26:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:26:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:26:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:26:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:26:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:26:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:26:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:26:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:26:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:26:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:26:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:26:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:26:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:26:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:26:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:26:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:26:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:26:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:26:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:26:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:26:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:26:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:26:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:26:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:26:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:26:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:26:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:26:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:26:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:26:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:26:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:26:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:26:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:26:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:26:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:26:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:26:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:26:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:26:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:26:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:26:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:26:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:26:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:26:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:26:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:26:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:26:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:26:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:26:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:26:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:26:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:26:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:26:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:26:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:26:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:26:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:26:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:26:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:26:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:26:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:26:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:26:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:26:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:26:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:26:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:26:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:26:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:26:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:26:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:26:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:26:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:26:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:26:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:26:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:26:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:26:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:26:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:26:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:26:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:26:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:26:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:26:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:26:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:26:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:26:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:26:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:26:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:26:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:26:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:26:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:26:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:26:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:26:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:26:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:26:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:26:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:26:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:26:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:26:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:26:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:26:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:26:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:26:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:26:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:26:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:26:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:26:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:26:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:26:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:26:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:26:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:26:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:26:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:26:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:26:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:26:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:26:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:26:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:26:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:26:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:26:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:26:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:26:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:26:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:26:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:26:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:26:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:26:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:26:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:26:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:26:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:26:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:26:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:26:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:26:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:26:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:26:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:26:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:26:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:26:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:26:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:26:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:26:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:26:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:26:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:26:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:26:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:26:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:26:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:26:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:26:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:26:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:26:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:26:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:26:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:26:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:26:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:26:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:26:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:26:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:26:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:26:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:26:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:26:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:26:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:27:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:27:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:27:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:27:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:27:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:27:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:27:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:27:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:27:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:27:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:27:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:27:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:27:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:27:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:27:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:27:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:27:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:27:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:27:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:27:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:27:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:27:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:27:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:27:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:27:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:27:04 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-aca5f99a-kafka-0 ,my-cluster-aca5f99a-kafka-1 ,my-cluster-aca5f99a-kafka-2 ,my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh ,my-cluster-aca5f99a-kafka-exporter-d464545b-qzcww
2022-04-04 15:27:04 [main] [32mINFO [m [RollingUpdateST:800] Check if Kafka and Zookeeper pods didn't roll
2022-04-04 15:27:04 [main] [32mINFO [m [RollingUpdateST:804] Check if Kafka and Zookeeper metrics are changed
2022-04-04 15:27:04 [main] [32mINFO [m [RollingUpdateST:818] Check if metrics are present in pod of Kafka and Zookeeper
2022-04-04 15:27:04 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 0
2022-04-04 15:27:05 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 0
2022-04-04 15:27:05 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 0
2022-04-04 15:27:05 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 0
2022-04-04 15:27:06 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 0
2022-04-04 15:27:06 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 0
2022-04-04 15:27:06 [main] [32mINFO [m [RollingUpdateST:829] Removing metrics from Kafka and Zookeeper and setting them to null
2022-04-04 15:27:06 [main] [32mINFO [m [RollingUpdateST:836] Wait if Kafka and Zookeeper pods will roll
2022-04-04 15:27:06 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-aca5f99a-zookeeper rolling update
2022-04-04 15:28:06 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-aca5f99a-zookeeper has been successfully rolled
2022-04-04 15:28:06 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-aca5f99a-zookeeper to be ready
2022-04-04 15:28:38 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-aca5f99a-kafka rolling update
2022-04-04 15:29:38 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-aca5f99a-kafka has been successfully rolled
2022-04-04 15:29:38 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-aca5f99a-kafka to be ready
2022-04-04 15:30:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-aca5f99a will have desired state: Ready
2022-04-04 15:30:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-aca5f99a is in desired state: Ready
2022-04-04 15:30:06 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-aca5f99a is ready
2022-04-04 15:30:06 [main] [32mINFO [m [RollingUpdateST:840] Check if metrics are not existing in pods
2022-04-04 15:30:07 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 7
2022-04-04 15:30:07 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 7
2022-04-04 15:30:07 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 7
2022-04-04 15:30:07 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 7
2022-04-04 15:30:07 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 7
2022-04-04 15:30:08 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-aca5f99a-kafka-clients-759c98b8d7-47wsh finished with return code: 7
2022-04-04 15:30:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:30:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMetricsChange
2022-04-04 15:30:08 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-aca5f99a-kafka-clients in namespace rolling-update-st
2022-04-04 15:30:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-aca5f99a in namespace rolling-update-st
2022-04-04 15:30:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:30:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testMetricsChange-FINISHED
2022-04-04 15:30:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:30:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:30:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testExternalLoggingChangeTriggerRollingUpdate-STARTED
2022-04-04 15:30:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:30:58 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-78 for test case:testExternalLoggingChangeTriggerRollingUpdate
2022-04-04 15:30:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-78
2022-04-04 15:30:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-78
2022-04-04 15:30:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-78
2022-04-04 15:30:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-37061199 in namespace namespace-78
2022-04-04 15:30:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-78
2022-04-04 15:30:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-37061199 will have desired state: Ready
2022-04-04 15:32:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-37061199 is in desired state: Ready
2022-04-04 15:32:14 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-37061199-zookeeper rolling update
2022-04-04 15:33:29 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-37061199-zookeeper has been successfully rolled
2022-04-04 15:33:29 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-37061199-zookeeper to be ready
2022-04-04 15:34:00 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-37061199-kafka rolling update
2022-04-04 15:35:15 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-37061199-kafka has been successfully rolled
2022-04-04 15:35:15 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-37061199-kafka to be ready
2022-04-04 15:35:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-37061199 will have desired state: Ready
2022-04-04 15:35:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-37061199 is in desired state: Ready
2022-04-04 15:35:47 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-37061199 is ready
2022-04-04 15:35:47 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-37061199-zookeeper rolling update
2022-04-04 15:38:07 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-37061199-zookeeper has been successfully rolled
2022-04-04 15:38:07 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-37061199-zookeeper to be ready
2022-04-04 15:38:39 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-37061199-kafka rolling update
2022-04-04 15:38:39 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-37061199-kafka has been successfully rolled
2022-04-04 15:38:39 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-37061199-kafka to be ready
2022-04-04 15:38:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-37061199 will have desired state: Ready
2022-04-04 15:38:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-37061199 is in desired state: Ready
2022-04-04 15:38:49 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-37061199 is ready
2022-04-04 15:38:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:38:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testExternalLoggingChangeTriggerRollingUpdate
2022-04-04 15:38:49 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-37061199 in namespace namespace-78
2022-04-04 15:38:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:38:59 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-78 for test case:testExternalLoggingChangeTriggerRollingUpdate
2022-04-04 15:39:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testExternalLoggingChangeTriggerRollingUpdate-FINISHED
2022-04-04 15:39:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:39:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:39:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testBrokerConfigurationChangeTriggerRollingUpdate-STARTED
2022-04-04 15:39:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:39:42 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-79 for test case:testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-04 15:39:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-79
2022-04-04 15:39:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-79
2022-04-04 15:39:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-79
2022-04-04 15:39:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d6ff3d57 in namespace namespace-79
2022-04-04 15:39:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-79
2022-04-04 15:39:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d6ff3d57 will have desired state: Ready
2022-04-04 15:41:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d6ff3d57 is in desired state: Ready
2022-04-04 15:41:05 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d6ff3d57-kafka rolling update
2022-04-04 15:42:30 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d6ff3d57-kafka has been successfully rolled
2022-04-04 15:42:30 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d6ff3d57-kafka to be ready
2022-04-04 15:42:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d6ff3d57 will have desired state: Ready
2022-04-04 15:42:54 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d6ff3d57 is in desired state: Ready
2022-04-04 15:42:54 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d6ff3d57 is ready
2022-04-04 15:42:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:42:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-04 15:42:54 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d6ff3d57 in namespace namespace-79
2022-04-04 15:43:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:43:04 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-79 for test case:testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-04 15:43:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testBrokerConfigurationChangeTriggerRollingUpdate-FINISHED
2022-04-04 15:43:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:43:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:43:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testManualKafkaConfigMapChangeDontTriggerRollingUpdate-STARTED
2022-04-04 15:43:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:43:47 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-80 for test case:testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-04 15:43:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-80
2022-04-04 15:43:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-80
2022-04-04 15:43:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-80
2022-04-04 15:43:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3befa12e in namespace namespace-80
2022-04-04 15:43:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-80
2022-04-04 15:43:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3befa12e will have desired state: Ready
2022-04-04 15:45:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3befa12e is in desired state: Ready
2022-04-04 15:45:06 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-3befa12e are stable
2022-04-04 15:45:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:45:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:45:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:45:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:45:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:45:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:45:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:45:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:45:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:45:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:45:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:45:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:45:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:45:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:45:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:45:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:45:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:45:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:45:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:45:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:45:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:45:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:45:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:45:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:45:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:45:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:45:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:45:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:45:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:45:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:45:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:45:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:45:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:45:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:45:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:45:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:45:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:45:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:45:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:45:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:45:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:45:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:45:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:45:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:45:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:45:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:45:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:45:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:45:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:45:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:45:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:45:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:45:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:45:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:45:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:45:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:45:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:45:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:45:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:45:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:45:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:45:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:45:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:45:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:45:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:45:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:45:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:45:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:45:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:45:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:45:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:45:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:45:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:45:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:45:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:45:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:45:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:45:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:45:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:45:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:45:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:45:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:45:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:45:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:45:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:45:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:45:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:45:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:45:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:45:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:45:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:45:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:45:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:45:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:45:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:45:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:45:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:45:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:45:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:45:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:45:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:45:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:45:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:45:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:45:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:45:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:45:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:45:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:45:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:45:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:45:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:45:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:45:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:45:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:45:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:45:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:45:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:45:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:45:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:45:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:45:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:45:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:45:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:45:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:45:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:45:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:45:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:45:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:45:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:45:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:45:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:45:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:45:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:45:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:45:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:45:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:45:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:45:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:45:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:45:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:45:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:45:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:45:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:45:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:45:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:45:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:45:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:45:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:45:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:45:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:45:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:45:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:45:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:45:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:45:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:45:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:45:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:45:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:45:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:45:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:45:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:45:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:45:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:45:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:45:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:45:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:45:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:45:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:45:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:45:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:45:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:45:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:45:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:45:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:45:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:45:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:45:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:45:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:45:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:45:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:45:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:45:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:45:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:45:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:45:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:45:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:45:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:45:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:45:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:45:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:45:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:45:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:45:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:45:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:45:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:45:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:45:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:45:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:45:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:45:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:45:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:45:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:45:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:45:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:45:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:45:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:45:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:45:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:45:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:45:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:45:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:45:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:45:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:45:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:45:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:45:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:45:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:45:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:45:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:45:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:45:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:45:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:45:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:45:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:45:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:45:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:45:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:45:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:45:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:45:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:45:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:45:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:45:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:45:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:45:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:45:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:45:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:45:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:45:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:45:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:45:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:45:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:45:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:45:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:45:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:45:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:45:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:45:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:45:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:45:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:45:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:45:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:45:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:45:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:45:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:45:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:45:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:45:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:45:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:45:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:45:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:45:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:45:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:45:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:45:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:45:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:45:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:45:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:45:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:45:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:45:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:45:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:45:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:45:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:45:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:45:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:45:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:45:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:45:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:45:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:45:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:45:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:45:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:45:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:45:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:45:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:45:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:45:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:45:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:45:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:45:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:45:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:45:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:45:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:45:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:45:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:45:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:45:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:45:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:45:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:45:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:45:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:45:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:45:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:45:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:45:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:45:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:45:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:45:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:45:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:45:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:45:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:45:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:45:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:45:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:45:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:45:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:45:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:45:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:45:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:45:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:45:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:45:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:45:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:45:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:45:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:45:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:45:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:45:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:45:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:45:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:45:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:45:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:45:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:45:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:45:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:45:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:45:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:45:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:45:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:45:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:45:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:45:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:45:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:45:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:45:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:45:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:45:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:45:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:45:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3befa12e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:45:56 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-3befa12e-entity-operator-fffd86c54-9xkmk ,my-cluster-3befa12e-kafka-0 ,my-cluster-3befa12e-kafka-1 ,my-cluster-3befa12e-kafka-2 ,my-cluster-3befa12e-zookeeper-0 ,my-cluster-3befa12e-zookeeper-1 ,my-cluster-3befa12e-zookeeper-2
2022-04-04 15:45:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:45:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-04 15:45:56 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3befa12e in namespace namespace-80
2022-04-04 15:46:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:46:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-80 for test case:testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-04 15:46:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testManualKafkaConfigMapChangeDontTriggerRollingUpdate-FINISHED
2022-04-04 15:46:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:46:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:46:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testZookeeperScaleUpScaleDown-STARTED
2022-04-04 15:46:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:46:49 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-81 for test case:testZookeeperScaleUpScaleDown
2022-04-04 15:46:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-81
2022-04-04 15:46:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-81
2022-04-04 15:46:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-81
2022-04-04 15:46:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-681bac14 in namespace namespace-81
2022-04-04 15:46:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-04 15:46:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-681bac14 will have desired state: Ready
2022-04-04 15:48:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-681bac14 is in desired state: Ready
2022-04-04 15:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1915048563-1975150680 in namespace namespace-81
2022-04-04 15:48:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-04 15:48:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1915048563-1975150680 will have desired state: Ready
2022-04-04 15:48:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1915048563-1975150680 is in desired state: Ready
2022-04-04 15:48:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1479150584-801908851 in namespace namespace-81
2022-04-04 15:48:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-04 15:48:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1479150584-801908851 will have desired state: Ready
2022-04-04 15:48:11 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1479150584-801908851 is in desired state: Ready
2022-04-04 15:48:11 [main] [32mINFO [m [RollingUpdateST:398] Running zookeeperScaleUpScaleDown with cluster my-cluster-681bac14
2022-04-04 15:48:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-681bac14-kafka-clients in namespace namespace-81
2022-04-04 15:48:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-04 15:48:22 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 15:48:22 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3c2a6908, messages=[], arguments=[--topic, my-topic-1915048563-1975150680, --max-messages, 100, USER=my_user_1479150584_801908851, --bootstrap-server, my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-681bac14-kafka-clients-768d798974-sc4hq', podNamespace='namespace-81', bootstrapServer='my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1915048563-1975150680', maxMessages=100, kafkaUsername='my-user-1479150584-801908851', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@548e0f04}
2022-04-04 15:48:22 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093:my-topic-1915048563-1975150680 from pod my-cluster-681bac14-kafka-clients-768d798974-sc4hq
2022-04-04 15:48:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-681bac14-kafka-clients-768d798974-sc4hq -n namespace-81 -- /opt/kafka/producer.sh --topic my-topic-1915048563-1975150680 --max-messages 100 USER=my_user_1479150584_801908851 --bootstrap-server my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:48:25 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 15:48:25 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 15:48:25 [main] [32mINFO [m [RollingUpdateST:426] Scale up Zookeeper to 7
2022-04-04 15:48:25 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6ffed2d3, messages=[], arguments=[--topic, my-topic-1915048563-1975150680, --max-messages, 100, --group-instance-id, instance1305053053, --group-id, my-consumer-group-1707706589, USER=my_user_1479150584_801908851, --bootstrap-server, my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-681bac14-kafka-clients-768d798974-sc4hq', podNamespace='namespace-81', bootstrapServer='my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1915048563-1975150680', maxMessages=100, kafkaUsername='my-user-1479150584-801908851', consumerGroupName='my-consumer-group-1707706589', consumerInstanceId='instance1305053053', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6815d598}
2022-04-04 15:48:25 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093:my-topic-1915048563-1975150680 from pod my-cluster-681bac14-kafka-clients-768d798974-sc4hq
2022-04-04 15:48:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-681bac14-kafka-clients-768d798974-sc4hq -n namespace-81 -- /opt/kafka/consumer.sh --topic my-topic-1915048563-1975150680 --max-messages 100 --group-instance-id instance1305053053 --group-id my-consumer-group-1707706589 USER=my_user_1479150584_801908851 --bootstrap-server my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:48:33 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:48:33 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:48:33 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 7 Pod(s) of my-cluster-681bac14-zookeeper to be ready
2022-04-04 15:51:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-681bac14 will have desired state: Ready
2022-04-04 15:51:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-681bac14 is in desired state: Ready
2022-04-04 15:51:33 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-681bac14 is ready
2022-04-04 15:51:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-681bac14-zookeeper-0 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:51:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:51:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-681bac14-zookeeper-1 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:51:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:51:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-681bac14-zookeeper-2 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:51:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:51:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-681bac14-zookeeper-3 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:51:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:51:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-681bac14-zookeeper-4 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:51:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:51:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-681bac14-zookeeper-5 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:51:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:51:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-681bac14-zookeeper-6 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:51:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:51:34 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@8e769e8, messages=[], arguments=[--topic, my-topic-1915048563-1975150680, --max-messages, 100, --group-instance-id, instance1135981356, --group-id, my-consumer-group-511961912, USER=my_user_1479150584_801908851, --bootstrap-server, my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-681bac14-kafka-clients-768d798974-sc4hq', podNamespace='namespace-81', bootstrapServer='my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1915048563-1975150680', maxMessages=100, kafkaUsername='my-user-1479150584-801908851', consumerGroupName='my-consumer-group-511961912', consumerInstanceId='instance1135981356', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7420357d}
2022-04-04 15:51:34 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093:my-topic-1915048563-1975150680 from pod my-cluster-681bac14-kafka-clients-768d798974-sc4hq
2022-04-04 15:51:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-681bac14-kafka-clients-768d798974-sc4hq -n namespace-81 -- /opt/kafka/consumer.sh --topic my-topic-1915048563-1975150680 --max-messages 100 --group-instance-id instance1135981356 --group-id my-consumer-group-511961912 USER=my_user_1479150584_801908851 --bootstrap-server my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:51:41 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:51:41 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:51:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1135250337-1013018388 in namespace namespace-81
2022-04-04 15:51:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-04 15:51:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1135250337-1013018388 will have desired state: Ready
2022-04-04 15:51:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1135250337-1013018388 is in desired state: Ready
2022-04-04 15:51:42 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1889fe06, messages=[], arguments=[--topic, my-topic-1135250337-1013018388, --max-messages, 100, USER=my_user_1479150584_801908851, --bootstrap-server, my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-681bac14-kafka-clients-768d798974-sc4hq', podNamespace='namespace-81', bootstrapServer='my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1135250337-1013018388', maxMessages=100, kafkaUsername='my-user-1479150584-801908851', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4fdd53f9}
2022-04-04 15:51:42 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093:my-topic-1135250337-1013018388 from pod my-cluster-681bac14-kafka-clients-768d798974-sc4hq
2022-04-04 15:51:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-681bac14-kafka-clients-768d798974-sc4hq -n namespace-81 -- /opt/kafka/producer.sh --topic my-topic-1135250337-1013018388 --max-messages 100 USER=my_user_1479150584_801908851 --bootstrap-server my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:51:46 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 15:51:46 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 15:51:46 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5eec27d8, messages=[], arguments=[--topic, my-topic-1135250337-1013018388, --max-messages, 100, --group-instance-id, instance95816507, --group-id, my-consumer-group-1463136205, USER=my_user_1479150584_801908851, --bootstrap-server, my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-681bac14-kafka-clients-768d798974-sc4hq', podNamespace='namespace-81', bootstrapServer='my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1135250337-1013018388', maxMessages=100, kafkaUsername='my-user-1479150584-801908851', consumerGroupName='my-consumer-group-1463136205', consumerInstanceId='instance95816507', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6d77abb7}
2022-04-04 15:51:46 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093:my-topic-1135250337-1013018388 from pod my-cluster-681bac14-kafka-clients-768d798974-sc4hq
2022-04-04 15:51:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-681bac14-kafka-clients-768d798974-sc4hq -n namespace-81 -- /opt/kafka/consumer.sh --topic my-topic-1135250337-1013018388 --max-messages 100 --group-instance-id instance95816507 --group-id my-consumer-group-1463136205 USER=my_user_1479150584_801908851 --bootstrap-server my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:51:54 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:51:54 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:51:54 [main] [32mINFO [m [RollingUpdateST:453] Scale down Zookeeper to 3
2022-04-04 15:51:54 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-681bac14-zookeeper to be ready
2022-04-04 15:52:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-681bac14 will have desired state: Ready
2022-04-04 15:52:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-681bac14 is in desired state: Ready
2022-04-04 15:52:37 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-681bac14 is ready
2022-04-04 15:52:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-681bac14-zookeeper-0 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:52:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:52:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-681bac14-zookeeper-1 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:52:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:52:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-681bac14-zookeeper-2 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-04 15:52:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 15:52:37 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7c5f71ee, messages=[], arguments=[--topic, my-topic-1135250337-1013018388, --max-messages, 100, --group-instance-id, instance135473788, --group-id, my-consumer-group-54233166, USER=my_user_1479150584_801908851, --bootstrap-server, my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-681bac14-kafka-clients-768d798974-sc4hq', podNamespace='namespace-81', bootstrapServer='my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1135250337-1013018388', maxMessages=100, kafkaUsername='my-user-1479150584-801908851', consumerGroupName='my-consumer-group-54233166', consumerInstanceId='instance135473788', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2ca54dde}
2022-04-04 15:52:37 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093:my-topic-1135250337-1013018388 from pod my-cluster-681bac14-kafka-clients-768d798974-sc4hq
2022-04-04 15:52:37 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-681bac14-kafka-clients-768d798974-sc4hq -n namespace-81 -- /opt/kafka/consumer.sh --topic my-topic-1135250337-1013018388 --max-messages 100 --group-instance-id instance135473788 --group-id my-consumer-group-54233166 USER=my_user_1479150584_801908851 --bootstrap-server my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:52:44 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:52:44 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:52:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2121893973-2136445304 in namespace namespace-81
2022-04-04 15:52:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-04 15:52:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2121893973-2136445304 will have desired state: Ready
2022-04-04 15:52:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2121893973-2136445304 is in desired state: Ready
2022-04-04 15:52:46 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@67b6ae86, messages=[], arguments=[--topic, my-topic-2121893973-2136445304, --max-messages, 100, USER=my_user_1479150584_801908851, --bootstrap-server, my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-681bac14-kafka-clients-768d798974-sc4hq', podNamespace='namespace-81', bootstrapServer='my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-2121893973-2136445304', maxMessages=100, kafkaUsername='my-user-1479150584-801908851', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@43b25b5a}
2022-04-04 15:52:46 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093:my-topic-2121893973-2136445304 from pod my-cluster-681bac14-kafka-clients-768d798974-sc4hq
2022-04-04 15:52:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-681bac14-kafka-clients-768d798974-sc4hq -n namespace-81 -- /opt/kafka/producer.sh --topic my-topic-2121893973-2136445304 --max-messages 100 USER=my_user_1479150584_801908851 --bootstrap-server my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:52:50 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 15:52:50 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 15:52:50 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@66ac09d3, messages=[], arguments=[--topic, my-topic-2121893973-2136445304, --max-messages, 100, --group-instance-id, instance1713435368, --group-id, my-consumer-group-1045331620, USER=my_user_1479150584_801908851, --bootstrap-server, my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-681bac14-kafka-clients-768d798974-sc4hq', podNamespace='namespace-81', bootstrapServer='my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-2121893973-2136445304', maxMessages=100, kafkaUsername='my-user-1479150584-801908851', consumerGroupName='my-consumer-group-1045331620', consumerInstanceId='instance1713435368', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@617bc413}
2022-04-04 15:52:50 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093:my-topic-2121893973-2136445304 from pod my-cluster-681bac14-kafka-clients-768d798974-sc4hq
2022-04-04 15:52:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-681bac14-kafka-clients-768d798974-sc4hq -n namespace-81 -- /opt/kafka/consumer.sh --topic my-topic-2121893973-2136445304 --max-messages 100 --group-instance-id instance1713435368 --group-id my-consumer-group-1045331620 USER=my_user_1479150584_801908851 --bootstrap-server my-cluster-681bac14-kafka-bootstrap.namespace-81.svc:9093
2022-04-04 15:52:57 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:52:57 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:52:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 15:52:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testZookeeperScaleUpScaleDown
2022-04-04 15:52:57 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-681bac14-kafka-clients in namespace namespace-81
2022-04-04 15:52:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2121893973-2136445304 in namespace namespace-81
2022-04-04 15:52:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1915048563-1975150680 in namespace namespace-81
2022-04-04 15:52:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-681bac14 in namespace namespace-81
2022-04-04 15:53:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1479150584-801908851 in namespace namespace-81
2022-04-04 15:53:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1135250337-1013018388 in namespace namespace-81
2022-04-04 15:53:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 15:53:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-81 for test case:testZookeeperScaleUpScaleDown
2022-04-04 15:53:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testZookeeperScaleUpScaleDown-FINISHED
2022-04-04 15:53:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 15:53:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 15:53:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringZookeeperRollingUpdate-STARTED
2022-04-04 15:53:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 15:53:53 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-82 for test case:testRecoveryDuringZookeeperRollingUpdate
2022-04-04 15:53:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-82
2022-04-04 15:53:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-82
2022-04-04 15:53:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-82
2022-04-04 15:53:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-96ce790f in namespace namespace-82
2022-04-04 15:53:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-04 15:53:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-305261261-2017630873 in namespace namespace-82
2022-04-04 15:53:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-04 15:53:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-96ce790f will have desired state: Ready
2022-04-04 15:55:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-96ce790f is in desired state: Ready
2022-04-04 15:55:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-305261261-2017630873 will have desired state: Ready
2022-04-04 15:55:08 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-305261261-2017630873 is in desired state: Ready
2022-04-04 15:55:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2061512759-50708982 in namespace namespace-82
2022-04-04 15:55:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-04 15:55:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2061512759-50708982 will have desired state: Ready
2022-04-04 15:55:09 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2061512759-50708982 is in desired state: Ready
2022-04-04 15:55:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-96ce790f-kafka-clients in namespace namespace-82
2022-04-04 15:55:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-04 15:55:19 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 15:55:19 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@432fe1d7, messages=[], arguments=[--topic, my-topic-305261261-2017630873, --max-messages, 100, USER=my_user_2061512759_50708982, --bootstrap-server, my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c', podNamespace='namespace-82', bootstrapServer='my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-305261261-2017630873', maxMessages=100, kafkaUsername='my-user-2061512759-50708982', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@31c80bb7}
2022-04-04 15:55:19 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093:my-topic-305261261-2017630873 from pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c
2022-04-04 15:55:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c -n namespace-82 -- /opt/kafka/producer.sh --topic my-topic-305261261-2017630873 --max-messages 100 USER=my_user_2061512759_50708982 --bootstrap-server my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093
2022-04-04 15:55:23 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 15:55:23 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 15:55:23 [main] [32mINFO [m [RollingUpdateST:117] Update resources for pods
2022-04-04 15:55:23 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@464ffcd9, messages=[], arguments=[--topic, my-topic-305261261-2017630873, --max-messages, 100, --group-instance-id, instance738149004, --group-id, my-consumer-group-479863157, USER=my_user_2061512759_50708982, --bootstrap-server, my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c', podNamespace='namespace-82', bootstrapServer='my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-305261261-2017630873', maxMessages=100, kafkaUsername='my-user-2061512759-50708982', consumerGroupName='my-consumer-group-479863157', consumerInstanceId='instance738149004', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7a528b1d}
2022-04-04 15:55:23 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093:my-topic-305261261-2017630873 from pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c
2022-04-04 15:55:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c -n namespace-82 -- /opt/kafka/consumer.sh --topic my-topic-305261261-2017630873 --max-messages 100 --group-instance-id instance738149004 --group-id my-consumer-group-479863157 USER=my_user_2061512759_50708982 --bootstrap-server my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093
2022-04-04 15:55:30 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 15:55:30 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 15:55:30 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-04 15:55:30 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-96ce790f-zookeeper will be in pending phase
2022-04-04 15:55:37 [main] [32mINFO [m [RollingUpdateST:130] Verifying stability of zookeeper pods except the one, which is in pending phase
2022-04-04 15:55:37 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-96ce790f-zookeeper are stable
2022-04-04 15:55:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:55:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:55:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:55:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:55:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:55:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:55:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:55:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:55:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:55:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:55:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:55:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:55:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:55:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:55:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:55:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:55:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:55:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:55:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:55:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:55:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:55:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:55:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:55:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:55:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:55:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:55:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:55:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:55:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:55:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:55:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:55:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:55:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:55:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:55:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:55:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:55:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:55:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:55:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:55:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:55:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:55:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:55:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:55:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:56:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:56:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:56:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:56:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:56:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:56:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:56:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:56:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:56:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:56:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:56:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:56:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:56:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:56:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:56:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:56:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:56:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:56:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:56:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:56:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:56:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:56:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:56:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:56:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:56:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:56:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:56:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:56:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:56:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:56:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:56:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:56:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:56:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:56:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:56:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:56:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:56:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:56:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:56:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:56:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:56:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:56:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:56:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:56:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:56:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:56:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:56:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:56:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:56:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:56:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:56:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:56:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:56:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:56:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:56:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:56:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:56:27 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-96ce790f-zookeeper-1 ,my-cluster-96ce790f-zookeeper-2
2022-04-04 15:56:27 [main] [32mINFO [m [RollingUpdateST:133] Verifying stability of kafka pods
2022-04-04 15:56:27 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-96ce790f-kafka are stable
2022-04-04 15:56:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:56:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:56:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:56:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 15:56:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:56:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:56:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:56:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 15:56:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:56:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:56:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:56:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 15:56:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:56:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:56:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:56:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 15:56:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:56:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:56:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:56:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 15:56:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:56:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:56:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:56:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 15:56:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:56:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:56:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:56:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 15:56:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:56:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:56:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:56:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 15:56:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:56:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:56:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:56:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 15:56:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:56:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:56:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:56:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 15:56:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:56:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:56:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:56:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 15:56:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:56:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:56:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:56:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 15:56:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:56:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:56:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:56:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 15:56:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:56:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:56:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:56:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 15:56:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:56:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:56:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:56:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 15:56:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:56:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:56:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:56:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 15:56:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:56:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:56:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:56:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 15:56:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:56:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:56:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:56:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 15:56:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:56:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:56:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:56:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 15:56:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:56:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:56:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:56:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 15:56:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:56:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:56:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:56:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 15:56:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:56:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:56:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:56:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 15:56:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:56:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:56:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:56:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 15:56:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:56:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:56:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:56:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 15:56:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:56:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:56:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:56:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 15:56:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:56:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:56:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:56:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 15:56:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:56:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:56:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:56:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 15:56:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:56:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:56:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:56:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 15:56:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:56:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:56:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:56:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 15:56:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:56:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:56:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:56:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 15:56:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:56:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:56:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:56:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 15:56:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:56:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:56:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:56:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 15:56:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:56:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:56:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:56:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 15:57:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:57:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:57:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:57:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 15:57:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:57:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:57:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:57:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 15:57:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:57:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:57:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:57:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 15:57:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:57:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:57:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:57:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 15:57:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:57:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:57:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:57:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 15:57:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:57:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:57:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:57:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 15:57:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:57:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:57:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:57:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 15:57:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:57:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:57:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:57:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 15:57:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:57:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:57:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:57:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 15:57:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:57:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:57:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:57:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 15:57:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:57:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:57:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:57:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 15:57:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:57:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:57:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:57:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 15:57:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:57:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:57:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:57:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 15:57:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:57:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:57:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:57:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 15:57:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:57:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:57:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:57:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 15:57:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:57:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:57:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:57:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 15:57:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:57:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:57:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:57:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 15:57:17 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-96ce790f-kafka-0 ,my-cluster-96ce790f-kafka-1 ,my-cluster-96ce790f-kafka-2 ,my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c
2022-04-04 15:57:17 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-96ce790f-zookeeper to be ready
2022-04-04 16:02:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-96ce790f will have desired state: Ready
2022-04-04 16:02:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-96ce790f is in desired state: Ready
2022-04-04 16:02:34 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-96ce790f is ready
2022-04-04 16:02:34 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@daf5692, messages=[], arguments=[--topic, my-topic-305261261-2017630873, --max-messages, 100, --group-instance-id, instance2079951324, --group-id, my-consumer-group-888715063, USER=my_user_2061512759_50708982, --bootstrap-server, my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c', podNamespace='namespace-82', bootstrapServer='my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-305261261-2017630873', maxMessages=100, kafkaUsername='my-user-2061512759-50708982', consumerGroupName='my-consumer-group-888715063', consumerInstanceId='instance2079951324', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@12436267}
2022-04-04 16:02:34 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093:my-topic-305261261-2017630873 from pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c
2022-04-04 16:02:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c -n namespace-82 -- /opt/kafka/consumer.sh --topic my-topic-305261261-2017630873 --max-messages 100 --group-instance-id instance2079951324 --group-id my-consumer-group-888715063 USER=my_user_2061512759_50708982 --bootstrap-server my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093
2022-04-04 16:02:41 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:02:41 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:02:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-401906255-781033797 in namespace namespace-82
2022-04-04 16:02:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-04 16:02:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-401906255-781033797 will have desired state: Ready
2022-04-04 16:02:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-401906255-781033797 is in desired state: Ready
2022-04-04 16:02:42 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@495180e5, messages=[], arguments=[--topic, my-topic-401906255-781033797, --max-messages, 100, USER=my_user_2061512759_50708982, --bootstrap-server, my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c', podNamespace='namespace-82', bootstrapServer='my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-401906255-781033797', maxMessages=100, kafkaUsername='my-user-2061512759-50708982', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@400882d9}
2022-04-04 16:02:42 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093:my-topic-401906255-781033797 from pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c
2022-04-04 16:02:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c -n namespace-82 -- /opt/kafka/producer.sh --topic my-topic-401906255-781033797 --max-messages 100 USER=my_user_2061512759_50708982 --bootstrap-server my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093
2022-04-04 16:02:46 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 16:02:46 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 16:02:46 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@d202f4a, messages=[], arguments=[--topic, my-topic-401906255-781033797, --max-messages, 100, --group-instance-id, instance710011743, --group-id, my-consumer-group-1223614005, USER=my_user_2061512759_50708982, --bootstrap-server, my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c', podNamespace='namespace-82', bootstrapServer='my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-401906255-781033797', maxMessages=100, kafkaUsername='my-user-2061512759-50708982', consumerGroupName='my-consumer-group-1223614005', consumerInstanceId='instance710011743', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3ebd549b}
2022-04-04 16:02:46 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093:my-topic-401906255-781033797 from pod my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c
2022-04-04 16:02:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-96ce790f-kafka-clients-76df9dbf75-8zv6c -n namespace-82 -- /opt/kafka/consumer.sh --topic my-topic-401906255-781033797 --max-messages 100 --group-instance-id instance710011743 --group-id my-consumer-group-1223614005 USER=my_user_2061512759_50708982 --bootstrap-server my-cluster-96ce790f-kafka-bootstrap.namespace-82.svc:9093
2022-04-04 16:02:53 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:02:53 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:02:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:02:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryDuringZookeeperRollingUpdate
2022-04-04 16:02:53 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2061512759-50708982 in namespace namespace-82
2022-04-04 16:02:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-305261261-2017630873 in namespace namespace-82
2022-04-04 16:02:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-96ce790f in namespace namespace-82
2022-04-04 16:02:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-401906255-781033797 in namespace namespace-82
2022-04-04 16:03:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-96ce790f-kafka-clients in namespace namespace-82
2022-04-04 16:03:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:03:43 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-82 for test case:testRecoveryDuringZookeeperRollingUpdate
2022-04-04 16:03:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringZookeeperRollingUpdate-FINISHED
2022-04-04 16:03:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:03:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:03:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringKafkaRollingUpdate-STARTED
2022-04-04 16:03:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:03:48 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-83 for test case:testRecoveryDuringKafkaRollingUpdate
2022-04-04 16:03:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-83
2022-04-04 16:03:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-83
2022-04-04 16:03:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-83
2022-04-04 16:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-15eeb368 in namespace namespace-83
2022-04-04 16:03:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-04 16:03:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-15eeb368 will have desired state: Ready
2022-04-04 16:05:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-15eeb368 is in desired state: Ready
2022-04-04 16:05:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-618773421-244432574 in namespace namespace-83
2022-04-04 16:05:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-04 16:05:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-618773421-244432574 will have desired state: Ready
2022-04-04 16:05:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-618773421-244432574 is in desired state: Ready
2022-04-04 16:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1207680767-1575947361 in namespace namespace-83
2022-04-04 16:05:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-04 16:05:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1207680767-1575947361 will have desired state: Ready
2022-04-04 16:05:10 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1207680767-1575947361 is in desired state: Ready
2022-04-04 16:05:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-15eeb368-kafka-clients in namespace namespace-83
2022-04-04 16:05:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-04 16:05:20 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 16:05:20 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2b139963, messages=[], arguments=[--topic, my-topic-618773421-244432574, --max-messages, 100, USER=my_user_1207680767_1575947361, --bootstrap-server, my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp', podNamespace='namespace-83', bootstrapServer='my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-618773421-244432574', maxMessages=100, kafkaUsername='my-user-1207680767-1575947361', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@f060454}
2022-04-04 16:05:20 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093:my-topic-618773421-244432574 from pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp
2022-04-04 16:05:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp -n namespace-83 -- /opt/kafka/producer.sh --topic my-topic-618773421-244432574 --max-messages 100 USER=my_user_1207680767_1575947361 --bootstrap-server my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093
2022-04-04 16:05:24 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 16:05:24 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 16:05:24 [main] [32mINFO [m [RollingUpdateST:203] Update resources for pods
2022-04-04 16:05:24 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4a78a61b, messages=[], arguments=[--topic, my-topic-618773421-244432574, --max-messages, 100, --group-instance-id, instance1467312237, --group-id, my-consumer-group-185461070, USER=my_user_1207680767_1575947361, --bootstrap-server, my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp', podNamespace='namespace-83', bootstrapServer='my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-618773421-244432574', maxMessages=100, kafkaUsername='my-user-1207680767-1575947361', consumerGroupName='my-consumer-group-185461070', consumerInstanceId='instance1467312237', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7d97f04b}
2022-04-04 16:05:24 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093:my-topic-618773421-244432574 from pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp
2022-04-04 16:05:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp -n namespace-83 -- /opt/kafka/consumer.sh --topic my-topic-618773421-244432574 --max-messages 100 --group-instance-id instance1467312237 --group-id my-consumer-group-185461070 USER=my_user_1207680767_1575947361 --bootstrap-server my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093
2022-04-04 16:05:32 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:05:32 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:05:32 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-04 16:05:32 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-15eeb368-kafka will be in pending phase
2022-04-04 16:05:37 [main] [32mINFO [m [RollingUpdateST:220] Verifying stability of kafka pods except the one, which is in pending phase
2022-04-04 16:05:37 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-15eeb368-kafka are stable
2022-04-04 16:05:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 16:05:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 16:05:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 16:05:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 16:05:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 16:05:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 16:05:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 16:05:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 16:05:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 16:05:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 16:05:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 16:05:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 16:05:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 16:05:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 16:05:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 16:05:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 16:05:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 16:05:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 16:05:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 16:05:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 16:05:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 16:05:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 16:05:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 16:05:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 16:05:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 16:05:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 16:05:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 16:05:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 16:05:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 16:05:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 16:05:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 16:05:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 16:05:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 16:05:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 16:05:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 16:05:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 16:05:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 16:05:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 16:05:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 16:05:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 16:05:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 16:05:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 16:05:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 16:05:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 16:05:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 16:05:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 16:05:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 16:05:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 16:05:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 16:05:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 16:05:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 16:05:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 16:05:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 16:05:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 16:05:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 16:05:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 16:05:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 16:05:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 16:05:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 16:05:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 16:05:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 16:05:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 16:05:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 16:05:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 16:05:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 16:05:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 16:05:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 16:05:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 16:05:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 16:06:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 16:06:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 16:06:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 16:06:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 16:06:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 16:06:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 16:06:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 16:06:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 16:06:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 16:06:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 16:06:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 16:06:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 16:06:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 16:06:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 16:06:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 16:06:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 16:06:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 16:06:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 16:06:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 16:06:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 16:06:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 16:06:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 16:06:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 16:06:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 16:06:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 16:06:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 16:06:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 16:06:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 16:06:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 16:06:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 16:06:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 16:06:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 16:06:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 16:06:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 16:06:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 16:06:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 16:06:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 16:06:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 16:06:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 16:06:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 16:06:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 16:06:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 16:06:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 16:06:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 16:06:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 16:06:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 16:06:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 16:06:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 16:06:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 16:06:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 16:06:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 16:06:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 16:06:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 16:06:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 16:06:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 16:06:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 16:06:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 16:06:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 16:06:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 16:06:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 16:06:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 16:06:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 16:06:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 16:06:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 16:06:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 16:06:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 16:06:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 16:06:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 16:06:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 16:06:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 16:06:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 16:06:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 16:06:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 16:06:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 16:06:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 16:06:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 16:06:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 16:06:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 16:06:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 16:06:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 16:06:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 16:06:26 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-15eeb368-kafka-1 ,my-cluster-15eeb368-kafka-2 ,my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp
2022-04-04 16:06:26 [main] [32mINFO [m [RollingUpdateST:223] Verifying stability of zookeeper pods
2022-04-04 16:06:26 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-15eeb368-zookeeper are stable
2022-04-04 16:06:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 16:06:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 16:06:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 16:06:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 16:06:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 16:06:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 16:06:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 16:06:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 16:06:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 16:06:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 16:06:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 16:06:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 16:06:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 16:06:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 16:06:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 16:06:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 16:06:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 16:06:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 16:06:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 16:06:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 16:06:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 16:06:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 16:06:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 16:06:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 16:06:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 16:06:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 16:06:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 16:06:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 16:06:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 16:06:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 16:06:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 16:06:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 16:06:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 16:06:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 16:06:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 16:06:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 16:06:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 16:06:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 16:06:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 16:06:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 16:06:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 16:06:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 16:06:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 16:06:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 16:06:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 16:06:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 16:06:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 16:06:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 16:06:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 16:06:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 16:06:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 16:06:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 16:06:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 16:06:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 16:06:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 16:06:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 16:06:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 16:06:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 16:06:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 16:06:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 16:06:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 16:06:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 16:06:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 16:06:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 16:06:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 16:06:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 16:06:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 16:06:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 16:06:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 16:06:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 16:06:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 16:06:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 16:06:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 16:06:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 16:06:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 16:06:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 16:06:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 16:06:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 16:06:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 16:06:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 16:06:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 16:06:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 16:06:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 16:06:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 16:06:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 16:06:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 16:06:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 16:06:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 16:06:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 16:06:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 16:06:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 16:06:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 16:06:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 16:06:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 16:06:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 16:06:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 16:06:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 16:06:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 16:06:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 16:07:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 16:07:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 16:07:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 16:07:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 16:07:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 16:07:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 16:07:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 16:07:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 16:07:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 16:07:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 16:07:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 16:07:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 16:07:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 16:07:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 16:07:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 16:07:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 16:07:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 16:07:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 16:07:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 16:07:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 16:07:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 16:07:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 16:07:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 16:07:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 16:07:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 16:07:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 16:07:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 16:07:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 16:07:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 16:07:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 16:07:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 16:07:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 16:07:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 16:07:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 16:07:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 16:07:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 16:07:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 16:07:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 16:07:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 16:07:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 16:07:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 16:07:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 16:07:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 16:07:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 16:07:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 16:07:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 16:07:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 16:07:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 16:07:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 16:07:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 16:07:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15eeb368-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 16:07:16 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-15eeb368-zookeeper-0 ,my-cluster-15eeb368-zookeeper-1 ,my-cluster-15eeb368-zookeeper-2
2022-04-04 16:07:16 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@322c3bbd, messages=[], arguments=[--topic, my-topic-618773421-244432574, --max-messages, 100, --group-instance-id, instance1563072844, --group-id, my-consumer-group-389503016, USER=my_user_1207680767_1575947361, --bootstrap-server, my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp', podNamespace='namespace-83', bootstrapServer='my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-618773421-244432574', maxMessages=100, kafkaUsername='my-user-1207680767-1575947361', consumerGroupName='my-consumer-group-389503016', consumerInstanceId='instance1563072844', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@13c6ca87}
2022-04-04 16:07:16 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093:my-topic-618773421-244432574 from pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp
2022-04-04 16:07:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp -n namespace-83 -- /opt/kafka/consumer.sh --topic my-topic-618773421-244432574 --max-messages 100 --group-instance-id instance1563072844 --group-id my-consumer-group-389503016 USER=my_user_1207680767_1575947361 --bootstrap-server my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093
2022-04-04 16:07:23 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:07:23 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:07:23 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-04 16:07:23 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-15eeb368-kafka to be ready
2022-04-04 16:12:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-15eeb368 will have desired state: Ready
2022-04-04 16:12:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-15eeb368 is in desired state: Ready
2022-04-04 16:12:36 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-15eeb368 is ready
2022-04-04 16:12:36 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@9a9eecc, messages=[], arguments=[--topic, my-topic-618773421-244432574, --max-messages, 100, --group-instance-id, instance35150551, --group-id, my-consumer-group-435584123, USER=my_user_1207680767_1575947361, --bootstrap-server, my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp', podNamespace='namespace-83', bootstrapServer='my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-618773421-244432574', maxMessages=100, kafkaUsername='my-user-1207680767-1575947361', consumerGroupName='my-consumer-group-435584123', consumerInstanceId='instance35150551', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5a8bd7f3}
2022-04-04 16:12:36 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093:my-topic-618773421-244432574 from pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp
2022-04-04 16:12:36 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp -n namespace-83 -- /opt/kafka/consumer.sh --topic my-topic-618773421-244432574 --max-messages 100 --group-instance-id instance35150551 --group-id my-consumer-group-435584123 USER=my_user_1207680767_1575947361 --bootstrap-server my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093
2022-04-04 16:12:43 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:12:43 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:12:43 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-04 16:12:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-505347104-354047970 in namespace namespace-83
2022-04-04 16:12:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-04 16:12:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-505347104-354047970 will have desired state: Ready
2022-04-04 16:12:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-505347104-354047970 is in desired state: Ready
2022-04-04 16:12:44 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3bab7b9b, messages=[], arguments=[--topic, my-topic-505347104-354047970, --max-messages, 100, USER=my_user_1207680767_1575947361, --bootstrap-server, my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp', podNamespace='namespace-83', bootstrapServer='my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-505347104-354047970', maxMessages=100, kafkaUsername='my-user-1207680767-1575947361', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3f1b17c4}
2022-04-04 16:12:44 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093:my-topic-505347104-354047970 from pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp
2022-04-04 16:12:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp -n namespace-83 -- /opt/kafka/producer.sh --topic my-topic-505347104-354047970 --max-messages 100 USER=my_user_1207680767_1575947361 --bootstrap-server my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093
2022-04-04 16:12:48 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 16:12:48 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 16:12:48 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2efa352c, messages=[], arguments=[--topic, my-topic-505347104-354047970, --max-messages, 100, --group-instance-id, instance456717360, --group-id, my-consumer-group-495113511, USER=my_user_1207680767_1575947361, --bootstrap-server, my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp', podNamespace='namespace-83', bootstrapServer='my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-505347104-354047970', maxMessages=100, kafkaUsername='my-user-1207680767-1575947361', consumerGroupName='my-consumer-group-495113511', consumerInstanceId='instance456717360', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7d322dac}
2022-04-04 16:12:48 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093:my-topic-505347104-354047970 from pod my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp
2022-04-04 16:12:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-15eeb368-kafka-clients-587dd74798-4z9kp -n namespace-83 -- /opt/kafka/consumer.sh --topic my-topic-505347104-354047970 --max-messages 100 --group-instance-id instance456717360 --group-id my-consumer-group-495113511 USER=my_user_1207680767_1575947361 --bootstrap-server my-cluster-15eeb368-kafka-bootstrap.namespace-83.svc:9093
2022-04-04 16:12:55 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:12:55 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:12:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:12:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryDuringKafkaRollingUpdate
2022-04-04 16:12:55 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1207680767-1575947361 in namespace namespace-83
2022-04-04 16:12:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-618773421-244432574 in namespace namespace-83
2022-04-04 16:12:55 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-505347104-354047970 in namespace namespace-83
2022-04-04 16:12:55 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-15eeb368 in namespace namespace-83
2022-04-04 16:13:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-15eeb368-kafka-clients in namespace namespace-83
2022-04-04 16:13:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:13:45 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-83 for test case:testRecoveryDuringKafkaRollingUpdate
2022-04-04 16:13:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringKafkaRollingUpdate-FINISHED
2022-04-04 16:13:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:13:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:13:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-STARTED
2022-04-04 16:13:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:13:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1e363b60 in namespace rolling-update-st
2022-04-04 16:13:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1e363b60 will have desired state: Ready
2022-04-04 16:16:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1e363b60 is in desired state: Ready
io.strimzi.test.WaitException: Timeout after 180000 ms waiting for rolling update starts
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates(RollingUpdateST.java:625)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 16:19:10 [main] [1;31mERROR[m [TestExecutionWatcher:28] RollingUpdateST - Exception Timeout after 180000 ms waiting for rolling update starts has been thrown in @Test. Going to collect logs from components.
2022-04-04 16:19:10 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-04 16:19:10 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-04 16:19:10 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-04 16:19:24 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-04 16:19:25 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-04 16:19:25 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-04 16:19:25 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-04 16:19:25 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-04 16:19:25 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace rolling-update-st
2022-04-04 16:19:25 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace rolling-update-st
2022-04-04 16:19:25 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace rolling-update-st
2022-04-04 16:19:27 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace rolling-update-st
2022-04-04 16:19:27 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace rolling-update-st
2022-04-04 16:19:27 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace rolling-update-st
2022-04-04 16:19:27 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace rolling-update-st
2022-04-04 16:19:27 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-04 16:19:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:19:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClusterOperatorFinishAllRollingUpdates
2022-04-04 16:19:28 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1e363b60 in namespace rolling-update-st
2022-04-04 16:19:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:19:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-FINISHED
2022-04-04 16:19:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:19:38 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:19:38 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testKafkaAndZookeeperScaleUpScaleDown-STARTED
2022-04-04 16:19:38 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:19:38 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-84 for test case:testKafkaAndZookeeperScaleUpScaleDown
2022-04-04 16:19:38 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-84
2022-04-04 16:19:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-84
2022-04-04 16:19:38 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-84
2022-04-04 16:19:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0972c513 in namespace namespace-84
2022-04-04 16:19:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-04 16:19:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0972c513 will have desired state: Ready
2022-04-04 16:21:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0972c513 is in desired state: Ready
2022-04-04 16:21:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-784773423-1288390733 in namespace namespace-84
2022-04-04 16:21:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-04 16:21:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-784773423-1288390733 will have desired state: Ready
2022-04-04 16:21:32 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-784773423-1288390733 is in desired state: Ready
2022-04-04 16:21:32 [main] [32mINFO [m [AbstractST:489] Verifying docker image names
2022-04-04 16:21:32 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-04 16:21:32 [main] [32mINFO [m [AbstractST:525] Docker images verified
2022-04-04 16:21:32 [main] [32mINFO [m [RollingUpdateST:292] Running kafkaScaleUpScaleDown my-cluster-0972c513
2022-04-04 16:21:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1532855825-261653339 in namespace namespace-84
2022-04-04 16:21:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-04 16:21:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1532855825-261653339 will have desired state: Ready
2022-04-04 16:21:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1532855825-261653339 is in desired state: Ready
2022-04-04 16:21:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0972c513-kafka-clients in namespace namespace-84
2022-04-04 16:21:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-04 16:21:43 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 16:21:43 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1ef5f5b6, messages=[], arguments=[--topic, my-topic-1532855825-261653339, --max-messages, 100, USER=my_user_784773423_1288390733, --bootstrap-server, my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv', podNamespace='namespace-84', bootstrapServer='my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1532855825-261653339', maxMessages=100, kafkaUsername='my-user-784773423-1288390733', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@20768912}
2022-04-04 16:21:43 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093:my-topic-1532855825-261653339 from pod my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv
2022-04-04 16:21:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv -n namespace-84 -- /opt/kafka/producer.sh --topic my-topic-1532855825-261653339 --max-messages 100 USER=my_user_784773423_1288390733 --bootstrap-server my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:21:47 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 16:21:47 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 16:21:47 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3cc22903, messages=[], arguments=[--topic, my-topic-1532855825-261653339, --max-messages, 100, --group-instance-id, instance1521824781, --group-id, my-consumer-group-245447285, USER=my_user_784773423_1288390733, --bootstrap-server, my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv', podNamespace='namespace-84', bootstrapServer='my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1532855825-261653339', maxMessages=100, kafkaUsername='my-user-784773423-1288390733', consumerGroupName='my-consumer-group-245447285', consumerInstanceId='instance1521824781', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@971a08b}
2022-04-04 16:21:47 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093:my-topic-1532855825-261653339 from pod my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv
2022-04-04 16:21:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv -n namespace-84 -- /opt/kafka/consumer.sh --topic my-topic-1532855825-261653339 --max-messages 100 --group-instance-id instance1521824781 --group-id my-consumer-group-245447285 USER=my_user_784773423_1288390733 --bootstrap-server my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:21:54 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:21:54 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:21:54 [main] [32mINFO [m [RollingUpdateST:317] Scale up Kafka to 7
2022-04-04 16:21:54 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-0972c513-kafka rolling update
2022-04-04 16:23:09 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-0972c513-kafka has been successfully rolled
2022-04-04 16:23:09 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 7 Pod(s) of my-cluster-0972c513-kafka to be ready
2022-04-04 16:23:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0972c513 will have desired state: Ready
2022-04-04 16:23:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0972c513 is in desired state: Ready
2022-04-04 16:23:58 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-0972c513 is ready
2022-04-04 16:23:58 [main] [32mINFO [m [RollingUpdateST:327] Kafka scale up to 7 finished
2022-04-04 16:23:58 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@45eb7d42, messages=[], arguments=[--topic, my-topic-1532855825-261653339, --max-messages, 100, --group-instance-id, instance2102057896, --group-id, my-consumer-group-330427595, USER=my_user_784773423_1288390733, --bootstrap-server, my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv', podNamespace='namespace-84', bootstrapServer='my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1532855825-261653339', maxMessages=100, kafkaUsername='my-user-784773423-1288390733', consumerGroupName='my-consumer-group-330427595', consumerInstanceId='instance2102057896', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@fa7b722}
2022-04-04 16:23:58 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093:my-topic-1532855825-261653339 from pod my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv
2022-04-04 16:23:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv -n namespace-84 -- /opt/kafka/consumer.sh --topic my-topic-1532855825-261653339 --max-messages 100 --group-instance-id instance2102057896 --group-id my-consumer-group-330427595 USER=my_user_784773423_1288390733 --bootstrap-server my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:24:05 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:24:05 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:24:05 [main] [32mINFO [m [RollingUpdateST:339] Scale up Zookeeper to 5
2022-04-04 16:24:05 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 5 Pod(s) of my-cluster-0972c513-zookeeper to be ready
2022-04-04 16:25:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0972c513 will have desired state: Ready
2022-04-04 16:25:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0972c513 is in desired state: Ready
2022-04-04 16:25:10 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-0972c513 is ready
2022-04-04 16:25:10 [main] [32mINFO [m [RollingUpdateST:342] Kafka scale up to 5 finished
2022-04-04 16:25:10 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@41af99, messages=[], arguments=[--topic, my-topic-1532855825-261653339, --max-messages, 100, --group-instance-id, instance1861122026, --group-id, my-consumer-group-903071351, USER=my_user_784773423_1288390733, --bootstrap-server, my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv', podNamespace='namespace-84', bootstrapServer='my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1532855825-261653339', maxMessages=100, kafkaUsername='my-user-784773423-1288390733', consumerGroupName='my-consumer-group-903071351', consumerInstanceId='instance1861122026', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6c336b5}
2022-04-04 16:25:10 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093:my-topic-1532855825-261653339 from pod my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv
2022-04-04 16:25:10 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv -n namespace-84 -- /opt/kafka/consumer.sh --topic my-topic-1532855825-261653339 --max-messages 100 --group-instance-id instance1861122026 --group-id my-consumer-group-903071351 USER=my_user_784773423_1288390733 --bootstrap-server my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:25:17 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:25:17 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:25:17 [main] [32mINFO [m [RollingUpdateST:351] Scale down Kafka to 3
2022-04-04 16:25:17 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-0972c513-kafka rolling update
2022-04-04 16:26:57 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-0972c513-kafka has been successfully rolled
2022-04-04 16:26:57 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-0972c513-kafka to be ready
2022-04-04 16:27:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0972c513 will have desired state: Ready
2022-04-04 16:27:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0972c513 is in desired state: Ready
2022-04-04 16:27:24 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-0972c513 is ready
2022-04-04 16:27:24 [main] [32mINFO [m [RollingUpdateST:356] Kafka scale down to 3 finished
2022-04-04 16:27:24 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@11c1f62d, messages=[], arguments=[--topic, my-topic-1532855825-261653339, --max-messages, 100, --group-instance-id, instance789330086, --group-id, my-consumer-group-1781964552, USER=my_user_784773423_1288390733, --bootstrap-server, my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv', podNamespace='namespace-84', bootstrapServer='my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1532855825-261653339', maxMessages=100, kafkaUsername='my-user-784773423-1288390733', consumerGroupName='my-consumer-group-1781964552', consumerInstanceId='instance789330086', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4e9e4cd9}
2022-04-04 16:27:24 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093:my-topic-1532855825-261653339 from pod my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv
2022-04-04 16:27:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv -n namespace-84 -- /opt/kafka/consumer.sh --topic my-topic-1532855825-261653339 --max-messages 100 --group-instance-id instance789330086 --group-id my-consumer-group-1781964552 USER=my_user_784773423_1288390733 --bootstrap-server my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:27:31 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:27:31 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:27:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-496765191-1325611333 in namespace namespace-84
2022-04-04 16:27:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-04 16:27:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-496765191-1325611333 will have desired state: Ready
2022-04-04 16:29:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-496765191-1325611333 is in desired state: Ready
2022-04-04 16:29:23 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@ebe96d8, messages=[], arguments=[--topic, my-topic-496765191-1325611333, --max-messages, 100, USER=my_user_784773423_1288390733, --bootstrap-server, my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv', podNamespace='namespace-84', bootstrapServer='my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-496765191-1325611333', maxMessages=100, kafkaUsername='my-user-784773423-1288390733', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@10507a61}
2022-04-04 16:29:23 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093:my-topic-496765191-1325611333 from pod my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv
2022-04-04 16:29:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv -n namespace-84 -- /opt/kafka/producer.sh --topic my-topic-496765191-1325611333 --max-messages 100 USER=my_user_784773423_1288390733 --bootstrap-server my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:29:27 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 16:29:27 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 16:29:27 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7f654df6, messages=[], arguments=[--topic, my-topic-496765191-1325611333, --max-messages, 100, --group-instance-id, instance423622477, --group-id, my-consumer-group-1737846282, USER=my_user_784773423_1288390733, --bootstrap-server, my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv', podNamespace='namespace-84', bootstrapServer='my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-496765191-1325611333', maxMessages=100, kafkaUsername='my-user-784773423-1288390733', consumerGroupName='my-consumer-group-1737846282', consumerInstanceId='instance423622477', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6c75b16b}
2022-04-04 16:29:27 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093:my-topic-496765191-1325611333 from pod my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv
2022-04-04 16:29:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-0972c513-kafka-clients-5b85cbf59d-tstnv -n namespace-84 -- /opt/kafka/consumer.sh --topic my-topic-496765191-1325611333 --max-messages 100 --group-instance-id instance423622477 --group-id my-consumer-group-1737846282 USER=my_user_784773423_1288390733 --bootstrap-server my-cluster-0972c513-kafka-bootstrap.namespace-84.svc:9093
2022-04-04 16:29:34 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 16:29:34 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 16:29:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:29:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndZookeeperScaleUpScaleDown
2022-04-04 16:29:34 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1532855825-261653339 in namespace namespace-84
2022-04-04 16:29:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-496765191-1325611333 in namespace namespace-84
2022-04-04 16:29:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-784773423-1288390733 in namespace namespace-84
2022-04-04 16:29:34 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0972c513-kafka-clients in namespace namespace-84
2022-04-04 16:29:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0972c513 in namespace namespace-84
2022-04-04 16:30:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:30:24 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-84 for test case:testKafkaAndZookeeperScaleUpScaleDown
2022-04-04 16:30:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testKafkaAndZookeeperScaleUpScaleDown-FINISHED
2022-04-04 16:30:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:30:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:30:29 [main] [32mINFO [m [ResourceManager:346] In context RollingUpdateST is everything deleted.
2022-04-04 16:30:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 9, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 4,044.981 s <<< FAILURE! - in io.strimzi.systemtest.rollingupdate.RollingUpdateST
[[1;31mERROR[m] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates(ExtensionContext)  Time elapsed: 346.862 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 180000 ms waiting for rolling update starts
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates(RollingUpdateST.java:625)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.log.LoggingChangeST
2022-04-04 16:30:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: logging-change-st
2022-04-04 16:30:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: logging-change-st
2022-04-04 16:30:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: logging-change-st
2022-04-04 16:30:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:30:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetClusterOperatorLoggingLevels-STARTED
2022-04-04 16:30:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:30:35 [main] [32mINFO [m [LoggingChangeST:617] Checking that original logging config is different from the new one
2022-04-04 16:30:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:35 [main] [32mINFO [m [LoggingChangeST:620] Changing logging for cluster-operator
2022-04-04 16:30:35 [main] [32mINFO [m [LoggingChangeST:623] Waiting for log4j2.properties will contain desired settings
2022-04-04 16:30:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:30:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:30:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:31 [main] [32mINFO [m [LoggingChangeST:628] Checking log4j2.properties in CO pod
2022-04-04 16:31:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:31 [main] [32mINFO [m [LoggingChangeST:632] Checking if CO rolled its pod
2022-04-04 16:31:34 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-04 16:31:16 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-04 16:31:38 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-04 16:31:16 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-04 16:31:41 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-04 16:31:16 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-04 16:31:45 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-04 16:31:16 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-04 16:31:48 [main] [33mWARN [m [LoggingChangeST:638] 2022-04-04 16:31:16 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *

2022-04-04 16:31:51 [main] [33mWARN [m [LoggingChangeST:638] 
2022-04-04 16:31:51 [main] [32mINFO [m [LoggingChangeST:642] Changing all levels from OFF to INFO/WARN
2022-04-04 16:31:51 [main] [32mINFO [m [LoggingChangeST:646] Changing logging for cluster-operator
2022-04-04 16:31:51 [main] [32mINFO [m [LoggingChangeST:649] Waiting for log4j2.properties will contain desired settings
2022-04-04 16:31:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:31:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:31:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:56 [main] [32mINFO [m [LoggingChangeST:654] Checking log4j2.properties in CO pod
2022-04-04 16:32:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-xwt56 -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-04 16:32:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:32:57 [main] [32mINFO [m [LoggingChangeST:658] Checking if CO rolled its pod
2022-04-04 16:33:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:33:17 [main] [32mINFO [m [ResourceManager:346] In context testDynamicallySetClusterOperatorLoggingLevels is everything deleted.
2022-04-04 16:33:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:33:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetClusterOperatorLoggingLevels-FINISHED
2022-04-04 16:33:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:33:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:33:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLogger-STARTED
2022-04-04 16:33:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:33:17 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-85 for test case:testDynamicallySetUnknownKafkaLogger
2022-04-04 16:33:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-85
2022-04-04 16:33:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-85
2022-04-04 16:33:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-85
2022-04-04 16:33:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-be015480 in namespace namespace-85
2022-04-04 16:33:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-85
2022-04-04 16:33:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-be015480 will have desired state: Ready
2022-04-04 16:34:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-be015480 is in desired state: Ready
2022-04-04 16:34:39 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-be015480-kafka rolling update
2022-04-04 16:35:54 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-be015480-kafka has been successfully rolled
2022-04-04 16:35:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:35:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetUnknownKafkaLogger
2022-04-04 16:35:57 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-be015480 in namespace namespace-85
2022-04-04 16:36:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:36:07 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-85 for test case:testDynamicallySetUnknownKafkaLogger
2022-04-04 16:36:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLogger-FINISHED
2022-04-04 16:36:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:36:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:36:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaExternalLogging-STARTED
2022-04-04 16:36:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:36:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-86 for test case:testDynamicallySetKafkaExternalLogging
2022-04-04 16:36:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-86
2022-04-04 16:36:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-86
2022-04-04 16:36:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-86
2022-04-04 16:36:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3a021cd8 in namespace namespace-86
2022-04-04 16:36:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-86
2022-04-04 16:36:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3a021cd8 will have desired state: Ready
2022-04-04 16:38:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3a021cd8 is in desired state: Ready
2022-04-04 16:38:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 16:38:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 16:38:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 16:38:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 16:38:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 16:38:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 16:38:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 16:38:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 16:38:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 16:38:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 16:38:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 16:38:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 16:38:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 16:38:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 16:38:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 16:38:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 16:38:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 16:38:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 16:38:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 16:38:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 16:38:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 16:38:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 16:38:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 16:38:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 16:38:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 16:38:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 16:38:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 16:38:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 16:38:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 16:38:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 16:38:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 16:38:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 16:38:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 16:38:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 16:38:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 16:38:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 16:38:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 16:38:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 16:38:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 16:38:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 16:38:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 16:38:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 16:38:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 16:38:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 16:38:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 16:38:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 16:38:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 16:38:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 16:38:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 16:38:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 16:38:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3a021cd8-kafka-0=0646a50a-23eb-49d7-a59f-fe54971b76a4, my-cluster-3a021cd8-kafka-1=78956aff-97af-471a-abff-9395b240cd32, my-cluster-3a021cd8-kafka-2=538249e5-8ed9-455c-990b-289f2f5427c9} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 16:38:59 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-3a021cd8-kafka rolling update
2022-04-04 16:40:29 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-3a021cd8-kafka has been successfully rolled
2022-04-04 16:40:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:40:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetKafkaExternalLogging
2022-04-04 16:40:35 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3a021cd8 in namespace namespace-86
2022-04-04 16:40:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:40:45 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-86 for test case:testDynamicallySetKafkaExternalLogging
2022-04-04 16:41:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaExternalLogging-FINISHED
2022-04-04 16:41:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:41:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:41:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testNotExistingCMSetsDefaultLogging-STARTED
2022-04-04 16:41:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:41:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-87 for test case:testNotExistingCMSetsDefaultLogging
2022-04-04 16:41:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-87
2022-04-04 16:41:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-87
2022-04-04 16:41:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-87
2022-04-04 16:41:29 [main] [32mINFO [m [TestUtils:197] /home/ec2-user/strimzi-kafka-operator/systemtest/../cluster-operator/src/main/resources/kafkaDefaultLoggingProperties
2022-04-04 16:41:29 [main] [32mINFO [m [LoggingChangeST:1321] Deploying Kafka with custom logging
2022-04-04 16:41:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-892a5e9e in namespace namespace-87
2022-04-04 16:41:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-87
2022-04-04 16:41:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-892a5e9e will have desired state: Ready
2022-04-04 16:42:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-892a5e9e is in desired state: Ready
2022-04-04 16:42:47 [main] [32mINFO [m [LoggingChangeST:1345] Changing external logging's CM to not existing one
2022-04-04 16:42:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 16:42:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 16:42:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 16:42:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 16:42:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 16:42:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 16:42:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 16:42:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 16:42:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 16:42:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 16:42:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 16:42:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 16:42:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 16:43:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 16:43:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 16:43:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 16:43:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 16:43:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 16:43:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 16:43:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 16:43:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 16:43:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 16:43:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 16:43:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 16:43:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 16:43:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 16:43:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 16:43:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 16:43:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 16:43:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 16:43:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 16:43:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 16:43:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 16:43:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 16:43:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 16:43:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 16:43:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 16:43:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 16:43:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 16:43:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 16:43:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 16:43:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 16:43:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 16:43:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 16:43:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 16:43:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 16:43:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 16:43:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 16:43:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 16:43:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 16:43:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-892a5e9e-kafka-0=f900335f-5843-4906-8706-519f4a980e0e, my-cluster-892a5e9e-kafka-1=10369e2e-0610-4c75-ba16-10f158543da8, my-cluster-892a5e9e-kafka-2=12ba0c5f-f71d-4df1-bf74-697cf2769acd} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 16:43:37 [main] [32mINFO [m [LoggingChangeST:1359] Checking that log4j.properties in custom-config isn't empty and configuration is default
2022-04-04 16:43:38 [main] [32mINFO [m [LoggingChangeST:1367] Checking if Kafka:my-cluster-892a5e9e contains error about non-existing CM
2022-04-04 16:43:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:43:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNotExistingCMSetsDefaultLogging
2022-04-04 16:43:38 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-892a5e9e in namespace namespace-87
2022-04-04 16:43:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:43:48 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-87 for test case:testNotExistingCMSetsDefaultLogging
2022-04-04 16:44:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testNotExistingCMSetsDefaultLogging-FINISHED
2022-04-04 16:44:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:44:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:44:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetConnectLoggingLevels-STARTED
2022-04-04 16:44:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:44:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-88 for test case:testDynamicallySetConnectLoggingLevels
2022-04-04 16:44:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-88
2022-04-04 16:44:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-88
2022-04-04 16:44:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-88
2022-04-04 16:44:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-97dd4310 in namespace namespace-88
2022-04-04 16:44:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-04 16:44:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-97dd4310-kafka-clients in namespace namespace-88
2022-04-04 16:44:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-04 16:44:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-97dd4310 will have desired state: Ready
2022-04-04 16:45:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-97dd4310 is in desired state: Ready
2022-04-04 16:45:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-97dd4310-scraper in namespace namespace-88
2022-04-04 16:45:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-04 16:45:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-97dd4310-scraper will be ready
2022-04-04 16:45:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-97dd4310-scraper is ready
2022-04-04 16:45:35 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-97dd4310-scraper to be ready
2022-04-04 16:45:45 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-97dd4310-scraper is ready
2022-04-04 16:45:45 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-97dd4310-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 16:45:45 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-97dd4310-allow in namespace namespace-88
2022-04-04 16:45:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-04 16:45:45 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 16:45:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-97dd4310 in namespace namespace-88
2022-04-04 16:45:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-04 16:45:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-97dd4310 will have desired state: Ready
2022-04-04 16:46:47 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-97dd4310 is in desired state: Ready
2022-04-04 16:46:47 [main] [32mINFO [m [LoggingChangeST:704] Asserting if log is without records
2022-04-04 16:46:48 [main] [32mINFO [m [LoggingChangeST:707] Changing rootLogger level to DEBUG with inline logging
2022-04-04 16:46:48 [main] [32mINFO [m [LoggingChangeST:716] Waiting for log4j.properties will contain desired settings
2022-04-04 16:46:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-88 exec my-cluster-97dd4310-kafka-clients-645454c99-cmpmw -- curl http://my-cluster-97dd4310-connect-api:8083/admin/loggers/root
2022-04-04 16:46:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-88 exec my-cluster-97dd4310-kafka-clients-645454c99-cmpmw -- curl http://my-cluster-97dd4310-connect-api:8083/admin/loggers/root
2022-04-04 16:46:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:46:49 [main] [32mINFO [m [LoggingChangeST:761] Setting log level of Connect to OFF
2022-04-04 16:46:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-88 exec my-cluster-97dd4310-kafka-clients-645454c99-cmpmw -- curl http://my-cluster-97dd4310-connect-api:8083/admin/loggers/root
2022-04-04 16:46:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:47:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:47:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetConnectLoggingLevels
2022-04-04 16:47:19 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-97dd4310-scraper in namespace namespace-88
2022-04-04 16:47:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-97dd4310-kafka-clients in namespace namespace-88
2022-04-04 16:47:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-97dd4310 in namespace namespace-88
2022-04-04 16:47:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-97dd4310 in namespace namespace-88
2022-04-04 16:47:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-97dd4310-allow in namespace namespace-88
2022-04-04 16:48:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:48:09 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-88 for test case:testDynamicallySetConnectLoggingLevels
2022-04-04 16:48:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetConnectLoggingLevels-FINISHED
2022-04-04 16:48:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:48:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:48:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testMM2LoggingLevelsHierarchy-STARTED
2022-04-04 16:48:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:48:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-89 for test case:testMM2LoggingLevelsHierarchy
2022-04-04 16:48:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-89
2022-04-04 16:48:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-89
2022-04-04 16:48:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-89
2022-04-04 16:48:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e8d599f8-source in namespace namespace-89
2022-04-04 16:48:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-04 16:48:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e8d599f8-source will have desired state: Ready
2022-04-04 16:49:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e8d599f8-source is in desired state: Ready
2022-04-04 16:49:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e8d599f8-target in namespace namespace-89
2022-04-04 16:49:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-04 16:49:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e8d599f8-target will have desired state: Ready
2022-04-04 16:50:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e8d599f8-target is in desired state: Ready
2022-04-04 16:50:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e8d599f8-kafka-clients in namespace namespace-89
2022-04-04 16:50:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-04 16:50:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-e8d599f8 in namespace namespace-89
2022-04-04 16:50:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-04 16:50:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-e8d599f8 will have desired state: Ready
2022-04-04 16:52:05 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-e8d599f8 is in desired state: Ready
2022-04-04 16:52:05 [main] [32mINFO [m [LoggingChangeST:1254] Waiting for log4j.properties will contain desired settings
2022-04-04 16:52:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:52:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:05 [main] [32mINFO [m [LoggingChangeST:1259] Changing log levels
2022-04-04 16:52:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:52:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:52:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:52:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:52:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:52:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:52:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:52:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:52:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:52:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:52:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/root
2022-04-04 16:52:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/org.eclipse.jetty.util.thread.strategy.EatWhatYouKill
2022-04-04 16:52:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-e8d599f8-mirrormaker2-5bd9947574-hl2d5 -- curl http://localhost:8083/admin/loggers/org.apache.kafka.connect.runtime.WorkerTask
2022-04-04 16:52:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:52:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:52:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMM2LoggingLevelsHierarchy
2022-04-04 16:52:18 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e8d599f8-kafka-clients in namespace namespace-89
2022-04-04 16:52:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-e8d599f8 in namespace namespace-89
2022-04-04 16:52:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e8d599f8-target in namespace namespace-89
2022-04-04 16:52:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e8d599f8-source in namespace namespace-89
2022-04-04 16:53:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:53:09 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-89 for test case:testMM2LoggingLevelsHierarchy
2022-04-04 16:53:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testMM2LoggingLevelsHierarchy-FINISHED
2022-04-04 16:53:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:53:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:53:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testLoggingHierarchy-STARTED
2022-04-04 16:53:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:53:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-90 for test case:testLoggingHierarchy
2022-04-04 16:53:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-90
2022-04-04 16:53:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-90
2022-04-04 16:53:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-90
2022-04-04 16:53:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1ed3f4f9 in namespace namespace-90
2022-04-04 16:53:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-04 16:53:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1ed3f4f9-kafka-clients in namespace namespace-90
2022-04-04 16:53:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-04 16:53:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1ed3f4f9 will have desired state: Ready
2022-04-04 16:54:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1ed3f4f9 is in desired state: Ready
2022-04-04 16:54:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1ed3f4f9-kafka-clients will be ready
2022-04-04 16:54:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1ed3f4f9-kafka-clients is ready
2022-04-04 16:54:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1ed3f4f9-scraper in namespace namespace-90
2022-04-04 16:54:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-04 16:54:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1ed3f4f9-scraper will be ready
2022-04-04 16:54:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1ed3f4f9-scraper is ready
2022-04-04 16:54:39 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-1ed3f4f9-scraper to be ready
2022-04-04 16:54:49 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-1ed3f4f9-scraper is ready
2022-04-04 16:54:49 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-1ed3f4f9-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 16:54:49 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-1ed3f4f9-allow in namespace namespace-90
2022-04-04 16:54:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-04 16:54:49 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 16:54:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-1ed3f4f9 in namespace namespace-90
2022-04-04 16:54:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-04 16:54:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-1ed3f4f9 in namespace namespace-90
2022-04-04 16:54:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-04 16:54:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-1ed3f4f9 will have desired state: Ready
2022-04-04 16:55:59 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-1ed3f4f9 is in desired state: Ready
2022-04-04 16:55:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-1ed3f4f9 will have desired state: Ready
2022-04-04 16:55:59 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-1ed3f4f9 is in desired state: Ready
2022-04-04 16:55:59 [main] [32mINFO [m [LoggingChangeST:1401] Changing rootLogger level in KafkaConnector to ERROR with inline logging
2022-04-04 16:55:59 [main] [32mINFO [m [LoggingChangeST:1407] Waiting for Connect API loggers will contain desired settings
2022-04-04 16:55:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:55:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:01 [main] [32mINFO [m [LoggingChangeST:1413] Restarting Kafka connector my-cluster-1ed3f4f9 with class name org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl -X POST http://my-cluster-1ed3f4f9-connect-api:8083/connectors/my-cluster-1ed3f4f9/restart
2022-04-04 16:56:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:01 [main] [32mINFO [m [KafkaConnectorUtils:168] Wait until KafkaConnector my-cluster-1ed3f4f9's worker will be in RUNNING state
2022-04-04 16:56:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl GET http://my-cluster-1ed3f4f9-connect-api:8083/connectors/my-cluster-1ed3f4f9/status
2022-04-04 16:56:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:01 [main] [32mINFO [m [LoggingChangeST:1420] Checking that logger is same for connector with class name org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:01 [main] [32mINFO [m [LoggingChangeST:1426] Changing KafkaConnect's root logger to WARN, KafkaConnector: my-cluster-1ed3f4f9 shouldn't inherit it
2022-04-04 16:56:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/root
2022-04-04 16:56:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:01 [main] [32mINFO [m [LoggingChangeST:1440] Checking if KafkaConnector org.apache.kafka.connect.file.FileStreamSourceConnector doesn't inherit logger from KafkaConnect
2022-04-04 16:56:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:02 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 49
2022-04-04 16:56:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:03 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 48
2022-04-04 16:56:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:04 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 47
2022-04-04 16:56:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:05 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 46
2022-04-04 16:56:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:06 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 45
2022-04-04 16:56:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:08 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 44
2022-04-04 16:56:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:09 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 43
2022-04-04 16:56:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:10 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 42
2022-04-04 16:56:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:11 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 41
2022-04-04 16:56:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:12 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 40
2022-04-04 16:56:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:14 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 39
2022-04-04 16:56:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:15 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 38
2022-04-04 16:56:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:16 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 37
2022-04-04 16:56:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:17 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 36
2022-04-04 16:56:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:18 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 35
2022-04-04 16:56:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:20 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 34
2022-04-04 16:56:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:21 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 33
2022-04-04 16:56:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:22 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 32
2022-04-04 16:56:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:23 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 31
2022-04-04 16:56:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:24 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 30
2022-04-04 16:56:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:26 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 29
2022-04-04 16:56:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:27 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 28
2022-04-04 16:56:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:28 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 27
2022-04-04 16:56:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:29 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 26
2022-04-04 16:56:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:30 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 25
2022-04-04 16:56:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:31 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 24
2022-04-04 16:56:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:33 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 23
2022-04-04 16:56:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:34 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 22
2022-04-04 16:56:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:35 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 21
2022-04-04 16:56:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:36 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 20
2022-04-04 16:56:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:37 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 19
2022-04-04 16:56:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:39 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 18
2022-04-04 16:56:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:40 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 17
2022-04-04 16:56:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:41 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 16
2022-04-04 16:56:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:42 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 15
2022-04-04 16:56:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:43 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 14
2022-04-04 16:56:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:45 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 13
2022-04-04 16:56:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:46 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 12
2022-04-04 16:56:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:47 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 11
2022-04-04 16:56:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:48 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 10
2022-04-04 16:56:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:49 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 9
2022-04-04 16:56:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:51 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 8
2022-04-04 16:56:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:52 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 7
2022-04-04 16:56:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:53 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 6
2022-04-04 16:56:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:54 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 5
2022-04-04 16:56:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:55 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 4
2022-04-04 16:56:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:56 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 3
2022-04-04 16:56:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:58 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 2
2022-04-04 16:56:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:56:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:56:59 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 1
2022-04-04 16:57:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-1ed3f4f9-kafka-clients-784bc469b8-lq4v5 -- curl http://my-cluster-1ed3f4f9-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-04 16:57:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 16:57:00 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 0
2022-04-04 16:57:00 [main] [32mINFO [m [KafkaConnectorUtils:196] Logger for connector org.apache.kafka.connect.file.FileStreamSourceConnector is stable
2022-04-04 16:57:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 16:57:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLoggingHierarchy
2022-04-04 16:57:00 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-1ed3f4f9-allow in namespace namespace-90
2022-04-04 16:57:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1ed3f4f9-kafka-clients in namespace namespace-90
2022-04-04 16:57:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-1ed3f4f9 in namespace namespace-90
2022-04-04 16:57:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1ed3f4f9 in namespace namespace-90
2022-04-04 16:57:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1ed3f4f9-scraper in namespace namespace-90
2022-04-04 16:57:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-1ed3f4f9 in namespace namespace-90
2022-04-04 16:57:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 16:57:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-90 for test case:testLoggingHierarchy
2022-04-04 16:57:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testLoggingHierarchy-FINISHED
2022-04-04 16:57:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 16:57:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 16:57:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testJSONFormatLogging-STARTED
2022-04-04 16:57:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 16:57:56 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-91 for test case:testJSONFormatLogging
2022-04-04 16:57:56 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-91
2022-04-04 16:57:56 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-91
2022-04-04 16:57:56 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-91
2022-04-04 16:57:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5f19a8e7 in namespace namespace-91
2022-04-04 16:57:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-91
2022-04-04 16:57:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5f19a8e7 will have desired state: Ready
2022-04-04 17:00:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5f19a8e7 is in desired state: Ready
2022-04-04 17:00:16 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: strimzi-cluster-operator-78689684d4-xwt56
2022-04-04 17:00:17 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-5f19a8e7-kafka-2
2022-04-04 17:00:17 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-5f19a8e7-kafka-0
2022-04-04 17:00:17 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-5f19a8e7-kafka-1
2022-04-04 17:00:17 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-5f19a8e7-zookeeper-2
2022-04-04 17:00:17 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-5f19a8e7-zookeeper-0
2022-04-04 17:00:17 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-5f19a8e7-zookeeper-1
2022-04-04 17:00:17 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-5f19a8e7-entity-operator-8d7759ccc-dslkl
2022-04-04 17:00:17 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-5f19a8e7-entity-operator-8d7759ccc-dslkl
2022-04-04 17:00:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:00:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJSONFormatLogging
2022-04-04 17:00:17 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5f19a8e7 in namespace namespace-91
2022-04-04 17:00:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:00:27 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-91 for test case:testJSONFormatLogging
2022-04-04 17:01:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testJSONFormatLogging-FINISHED
2022-04-04 17:01:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:01:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:01:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaLoggingLevels-STARTED
2022-04-04 17:01:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:01:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-92 for test case:testDynamicallySetKafkaLoggingLevels
2022-04-04 17:01:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-92
2022-04-04 17:01:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-92
2022-04-04 17:01:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-92
2022-04-04 17:01:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f78c906f in namespace namespace-92
2022-04-04 17:01:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-92
2022-04-04 17:01:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f78c906f will have desired state: Ready
2022-04-04 17:02:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f78c906f is in desired state: Ready
2022-04-04 17:02:20 [main] [32mINFO [m [LoggingChangeST:829] Changing rootLogger level to DEBUG with inline logging
2022-04-04 17:02:20 [main] [32mINFO [m [LoggingChangeST:836] Waiting for dynamic change in the kafka pod
2022-04-04 17:02:24 [main] [32mINFO [m [LoggingChangeST:854] Setting external logging INFO
2022-04-04 17:02:24 [main] [32mINFO [m [LoggingChangeST:890] Setting log level of kafka INFO
2022-04-04 17:02:24 [main] [32mINFO [m [LoggingChangeST:896] Waiting for dynamic change in the kafka pod
2022-04-04 17:02:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:02:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetKafkaLoggingLevels
2022-04-04 17:02:31 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f78c906f in namespace namespace-92
2022-04-04 17:02:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:02:41 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-92 for test case:testDynamicallySetKafkaLoggingLevels
2022-04-04 17:03:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaLoggingLevels-FINISHED
2022-04-04 17:03:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:03:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:03:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetEOloggingLevels-STARTED
2022-04-04 17:03:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:03:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-93 for test case:testDynamicallySetEOloggingLevels
2022-04-04 17:03:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-93
2022-04-04 17:03:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-93
2022-04-04 17:03:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-93
2022-04-04 17:03:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-05dc41f3 in namespace namespace-93
2022-04-04 17:03:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-93
2022-04-04 17:03:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-05dc41f3 will have desired state: Ready
2022-04-04 17:04:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-05dc41f3 is in desired state: Ready
2022-04-04 17:04:31 [main] [32mINFO [m [LoggingChangeST:284] Checking if EO pod contains any log (except configuration)
2022-04-04 17:04:31 [main] [32mINFO [m [LoggingChangeST:287] Changing rootLogger level to DEBUG with inline logging
2022-04-04 17:04:31 [main] [32mINFO [m [LoggingChangeST:295] Waiting for log4j2.properties will contain desired settings
2022-04-04 17:05:48 [main] [32mINFO [m [LoggingChangeST:312] Setting external logging OFF
2022-04-04 17:05:48 [main] [32mINFO [m [LoggingChangeST:370] Setting log level of TO and UO to OFF - records should not appear in log
2022-04-04 17:05:48 [main] [32mINFO [m [LoggingChangeST:377] Waiting for log4j2.properties will contain desired settings
2022-04-04 17:07:12 [main] [32mINFO [m [LoggingChangeST:395] Setting external logging OFF
2022-04-04 17:07:12 [main] [32mINFO [m [LoggingChangeST:431] Waiting for log4j2.properties will contain desired settings
2022-04-04 17:07:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:07:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetEOloggingLevels
2022-04-04 17:07:48 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-05dc41f3 in namespace namespace-93
2022-04-04 17:07:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:07:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-93 for test case:testDynamicallySetEOloggingLevels
2022-04-04 17:08:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetEOloggingLevels-FINISHED
2022-04-04 17:08:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:08:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:08:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLoggerValue-STARTED
2022-04-04 17:08:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:08:09 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-94 for test case:testDynamicallySetUnknownKafkaLoggerValue
2022-04-04 17:08:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-94
2022-04-04 17:08:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-94
2022-04-04 17:08:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-94
2022-04-04 17:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d702f987 in namespace namespace-94
2022-04-04 17:08:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-94
2022-04-04 17:08:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d702f987 will have desired state: Ready
2022-04-04 17:09:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d702f987 is in desired state: Ready
2022-04-04 17:09:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 50
2022-04-04 17:09:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 49
2022-04-04 17:09:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 48
2022-04-04 17:09:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 47
2022-04-04 17:09:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 46
2022-04-04 17:09:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 45
2022-04-04 17:09:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 44
2022-04-04 17:09:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 43
2022-04-04 17:09:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 42
2022-04-04 17:09:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 41
2022-04-04 17:09:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 40
2022-04-04 17:09:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 39
2022-04-04 17:09:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 38
2022-04-04 17:09:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 37
2022-04-04 17:09:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 36
2022-04-04 17:09:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 35
2022-04-04 17:09:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 34
2022-04-04 17:09:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 33
2022-04-04 17:09:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 32
2022-04-04 17:09:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 31
2022-04-04 17:09:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 30
2022-04-04 17:09:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 29
2022-04-04 17:09:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 28
2022-04-04 17:09:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 27
2022-04-04 17:09:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 26
2022-04-04 17:09:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 25
2022-04-04 17:09:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 24
2022-04-04 17:09:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 23
2022-04-04 17:09:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 22
2022-04-04 17:09:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 21
2022-04-04 17:09:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 20
2022-04-04 17:09:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 19
2022-04-04 17:09:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 18
2022-04-04 17:09:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 17
2022-04-04 17:09:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 16
2022-04-04 17:09:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 15
2022-04-04 17:10:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 14
2022-04-04 17:10:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 13
2022-04-04 17:10:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 12
2022-04-04 17:10:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 11
2022-04-04 17:10:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 10
2022-04-04 17:10:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 9
2022-04-04 17:10:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 8
2022-04-04 17:10:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 7
2022-04-04 17:10:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 6
2022-04-04 17:10:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 5
2022-04-04 17:10:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 4
2022-04-04 17:10:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 3
2022-04-04 17:10:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 2
2022-04-04 17:10:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 1
2022-04-04 17:10:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-d702f987-kafka-1=fc3e2a41-3198-4487-8b81-223c023f79e6, my-cluster-d702f987-kafka-2=a92654c1-6436-446b-a0bc-4514c65df3c5, my-cluster-d702f987-kafka-0=3d804d91-cdb6-4fcb-9f1c-0b1f0dc1f677} pods didn't roll. Remaining seconds for stability: 0
2022-04-04 17:10:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:10:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetUnknownKafkaLoggerValue
2022-04-04 17:10:14 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d702f987 in namespace namespace-94
2022-04-04 17:10:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:10:24 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-94 for test case:testDynamicallySetUnknownKafkaLoggerValue
2022-04-04 17:10:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLoggerValue-FINISHED
2022-04-04 17:10:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:10:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:10:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetBridgeLoggingLevels-STARTED
2022-04-04 17:10:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:10:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-95 for test case:testDynamicallySetBridgeLoggingLevels
2022-04-04 17:10:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-95
2022-04-04 17:10:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-95
2022-04-04 17:10:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-95
2022-04-04 17:10:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0609cfcf in namespace namespace-95
2022-04-04 17:10:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-04 17:10:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0609cfcf-kafka-clients in namespace namespace-95
2022-04-04 17:10:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-04 17:10:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-0609cfcf in namespace namespace-95
2022-04-04 17:10:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-04 17:10:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0609cfcf will have desired state: Ready
2022-04-04 17:12:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0609cfcf is in desired state: Ready
2022-04-04 17:12:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0609cfcf-kafka-clients will be ready
2022-04-04 17:12:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0609cfcf-kafka-clients is ready
2022-04-04 17:12:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-0609cfcf will have desired state: Ready
2022-04-04 17:12:01 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-0609cfcf is in desired state: Ready
2022-04-04 17:12:01 [main] [32mINFO [m [LoggingChangeST:484] Asserting if log is without records
2022-04-04 17:12:02 [main] [32mINFO [m [LoggingChangeST:487] Changing rootLogger level to DEBUG with inline logging
2022-04-04 17:12:02 [main] [32mINFO [m [LoggingChangeST:499] Waiting for log4j2.properties will contain desired settings
2022-04-04 17:13:00 [main] [32mINFO [m [LoggingChangeST:556] Setting log level of Bridge to OFF - records should not appear in the log
2022-04-04 17:13:00 [main] [32mINFO [m [LoggingChangeST:562] Waiting for log4j2.properties will contain desired settings
2022-04-04 17:15:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:15:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetBridgeLoggingLevels
2022-04-04 17:15:00 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0609cfcf-kafka-clients in namespace namespace-95
2022-04-04 17:15:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0609cfcf in namespace namespace-95
2022-04-04 17:15:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-0609cfcf in namespace namespace-95
2022-04-04 17:15:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:15:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-95 for test case:testDynamicallySetBridgeLoggingLevels
2022-04-04 17:15:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetBridgeLoggingLevels-FINISHED
2022-04-04 17:15:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:15:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:15:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetMM2LoggingLevels-STARTED
2022-04-04 17:15:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:15:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-96 for test case:testDynamicallySetMM2LoggingLevels
2022-04-04 17:15:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-96
2022-04-04 17:15:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-96
2022-04-04 17:15:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-96
2022-04-04 17:15:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-76a4b3ac-source in namespace namespace-96
2022-04-04 17:15:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-04 17:15:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-76a4b3ac-source will have desired state: Ready
2022-04-04 17:17:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-76a4b3ac-source is in desired state: Ready
2022-04-04 17:17:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-76a4b3ac-target in namespace namespace-96
2022-04-04 17:17:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-04 17:17:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-76a4b3ac-target will have desired state: Ready
2022-04-04 17:18:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-76a4b3ac-target is in desired state: Ready
2022-04-04 17:18:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-76a4b3ac-kafka-clients in namespace namespace-96
2022-04-04 17:18:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-04 17:18:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-76a4b3ac in namespace namespace-96
2022-04-04 17:18:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-04 17:18:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-76a4b3ac will have desired state: Ready
2022-04-04 17:19:34 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-76a4b3ac is in desired state: Ready
2022-04-04 17:19:35 [main] [32mINFO [m [LoggingChangeST:1124] Changing rootLogger level to DEBUG with inline logging
2022-04-04 17:19:35 [main] [32mINFO [m [LoggingChangeST:1133] Waiting for log4j.properties will contain desired settings
2022-04-04 17:19:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-76a4b3ac-mirrormaker2-6479d8777f-jctsh -- curl http://localhost:8083/admin/loggers/root
2022-04-04 17:19:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:19:35 [main] [32mINFO [m [LoggingChangeST:1177] Setting log level of MM2 to OFF
2022-04-04 17:19:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-76a4b3ac-mirrormaker2-6479d8777f-jctsh -- curl http://localhost:8083/admin/loggers/root
2022-04-04 17:19:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:19:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-76a4b3ac-mirrormaker2-6479d8777f-jctsh -- curl http://localhost:8083/admin/loggers/root
2022-04-04 17:19:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:19:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:19:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetMM2LoggingLevels
2022-04-04 17:19:37 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-76a4b3ac-kafka-clients in namespace namespace-96
2022-04-04 17:19:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-76a4b3ac-target in namespace namespace-96
2022-04-04 17:19:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-76a4b3ac in namespace namespace-96
2022-04-04 17:19:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-76a4b3ac-source in namespace namespace-96
2022-04-04 17:20:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:20:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-96 for test case:testDynamicallySetMM2LoggingLevels
2022-04-04 17:20:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetMM2LoggingLevels-FINISHED
2022-04-04 17:20:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:20:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:20:34 [main] [32mINFO [m [ResourceManager:346] In context LoggingChangeST is everything deleted.
2022-04-04 17:20:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3,004.654 s - in io.strimzi.systemtest.log.LoggingChangeST
[[1;34mINFO[m] Running io.strimzi.systemtest.log.LogSettingST
2022-04-04 17:20:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: log-setting-st
2022-04-04 17:20:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: log-setting-st
2022-04-04 17:20:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: log-setting-st
2022-04-04 17:20:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka log-setting-cluster-name in namespace log-setting-st
2022-04-04 17:20:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka gc-set-logging in namespace log-setting-st
2022-04-04 17:20:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment shared-kafka-clients in namespace log-setting-st
2022-04-04 17:20:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: log-setting-cluster-name will have desired state: Ready
2022-04-04 17:22:42 [main] [32mINFO [m [ResourceManager:444] Kafka: log-setting-cluster-name is in desired state: Ready
2022-04-04 17:22:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: gc-set-logging will have desired state: Ready
2022-04-04 17:22:42 [main] [32mINFO [m [ResourceManager:444] Kafka: gc-set-logging is in desired state: Ready
2022-04-04 17:22:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: shared-kafka-clients will be ready
2022-04-04 17:22:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: shared-kafka-clients is ready
2022-04-04 17:22:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:22:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testMirrorMaker2LogSetting-STARTED
2022-04-04 17:22:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:22:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-c167587c-mirror-maker-2 in namespace log-setting-st
2022-04-04 17:22:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-c167587c-mirror-maker-2 will have desired state: Ready
2022-04-04 17:23:51 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-c167587c-mirror-maker-2 is in desired state: Ready
2022-04-04 17:23:51 [main] [32mINFO [m [LogSettingST:357] Checking if MirrorMaker2 has log level set properly
2022-04-04 17:23:51 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: mirrormaker.root.logger Expected: TRACE
2022-04-04 17:23:51 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.mirrormaker.logger.level Expected: TRACE
2022-04-04 17:23:51 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-c167587c-mirror-maker-2-mirrormaker2
2022-04-04 17:23:51 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-c167587c-mirror-maker-2-mirrormaker2
2022-04-04 17:23:51 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:23:52 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-c167587c-mirror-maker-2-mirrormaker2 rolling update
2022-04-04 17:25:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c167587c-mirror-maker-2-mirrormaker2 will be ready
2022-04-04 17:25:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c167587c-mirror-maker-2-mirrormaker2 is ready
2022-04-04 17:25:17 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-c167587c-mirror-maker-2-mirrormaker2 rolling update finished
2022-04-04 17:25:17 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-c167587c-mirror-maker-2-mirrormaker2
2022-04-04 17:25:17 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-c167587c-mirror-maker-2-mirrormaker2
2022-04-04 17:25:17 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:25:17 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-c167587c-mirror-maker-2-mirrormaker2-69fd764ff9jfblr container my-cluster-c167587c-mirror-maker-2-mirrormaker2 will be ready
2022-04-04 17:25:17 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-c167587c-mirror-maker-2-mirrormaker2-69fd764ff9jfblr container my-cluster-c167587c-mirror-maker-2-mirrormaker2 is ready
2022-04-04 17:25:17 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-c167587c-mirror-maker-2-mirrormaker2-69fd764ff9jfblr with container my-cluster-c167587c-mirror-maker-2-mirrormaker2
2022-04-04 17:25:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:25:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2LogSetting
2022-04-04 17:25:18 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-c167587c-mirror-maker-2 in namespace log-setting-st
2022-04-04 17:25:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:25:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testMirrorMaker2LogSetting-FINISHED
2022-04-04 17:25:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:25:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:25:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testCruiseControlLogChange-STARTED
2022-04-04 17:25:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:25:28 [main] [32mINFO [m [LogSettingST:409] Check that default/actual root logging level is info
2022-04-04 17:25:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:25:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:25:28 [main] [32mINFO [m [LogSettingST:414] Check logs in CruiseControl - make sure no DEBUG is found there.
2022-04-04 17:25:28 [main] [32mINFO [m [LogSettingST:422] Wait for change of root logger in log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f.
2022-04-04 17:25:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:25:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:25:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:25:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:25:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:25:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:25:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:25:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:25:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:25:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:25:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:25:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:25:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:25:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:26:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:26:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:26:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-04 17:26:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 17:26:10 [main] [32mINFO [m [LogSettingST:428] Check cruise control logs in pod log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f and it's container cruise-control .
2022-04-04 17:26:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:26:35 [main] [32mINFO [m [ResourceManager:346] In context testCruiseControlLogChange is everything deleted.
2022-04-04 17:26:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:26:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testCruiseControlLogChange-FINISHED
2022-04-04 17:26:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:26:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:26:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testMirrorMakerLogSetting-STARTED
2022-04-04 17:26:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:26:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-b419708f-mirror-maker in namespace log-setting-st
2022-04-04 17:26:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-b419708f-mirror-maker will have desired state: Ready
2022-04-04 17:27:44 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-b419708f-mirror-maker is in desired state: Ready
2022-04-04 17:27:44 [main] [32mINFO [m [LogSettingST:322] Checking if MirrorMaker has log level set properly
2022-04-04 17:27:44 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: mirrormaker.root.logger Expected: TRACE
2022-04-04 17:27:44 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.mirrormaker.logger.level Expected: TRACE
2022-04-04 17:27:44 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-b419708f-mirror-maker-mirror-maker
2022-04-04 17:27:44 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-b419708f-mirror-maker-mirror-maker
2022-04-04 17:27:44 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:27:44 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-b419708f-mirror-maker-mirror-maker rolling update
2022-04-04 17:28:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b419708f-mirror-maker-mirror-maker will be ready
2022-04-04 17:28:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b419708f-mirror-maker-mirror-maker is ready
2022-04-04 17:29:09 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-b419708f-mirror-maker-mirror-maker rolling update finished
2022-04-04 17:29:09 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-b419708f-mirror-maker-mirror-maker
2022-04-04 17:29:09 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-b419708f-mirror-maker-mirror-maker
2022-04-04 17:29:09 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:29:09 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-b419708f-mirror-maker-mirror-maker-7f5bb8b7b7-8znss container my-cluster-b419708f-mirror-maker-mirror-maker will be ready
2022-04-04 17:29:09 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-b419708f-mirror-maker-mirror-maker-7f5bb8b7b7-8znss container my-cluster-b419708f-mirror-maker-mirror-maker is ready
2022-04-04 17:29:09 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-b419708f-mirror-maker-mirror-maker-7f5bb8b7b7-8znss with container my-cluster-b419708f-mirror-maker-mirror-maker
2022-04-04 17:29:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:29:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerLogSetting
2022-04-04 17:29:09 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-b419708f-mirror-maker in namespace log-setting-st
2022-04-04 17:29:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:29:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testMirrorMakerLogSetting-FINISHED
2022-04-04 17:29:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:29:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:29:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testConnectLogSetting-STARTED
2022-04-04 17:29:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:29:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-87645ae1-connect-scraper in namespace log-setting-st
2022-04-04 17:29:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-87645ae1-connect-scraper will be ready
2022-04-04 17:29:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-87645ae1-connect-scraper is ready
2022-04-04 17:29:21 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-87645ae1-connect-scraper to be ready
2022-04-04 17:29:31 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-87645ae1-connect-scraper is ready
2022-04-04 17:29:31 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-87645ae1-connect-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 17:29:31 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-87645ae1-connect-allow in namespace log-setting-st
2022-04-04 17:29:31 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 17:29:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-87645ae1-connect in namespace log-setting-st
2022-04-04 17:29:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-87645ae1-connect will have desired state: Ready
2022-04-04 17:30:34 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-87645ae1-connect is in desired state: Ready
2022-04-04 17:30:34 [main] [32mINFO [m [LogSettingST:287] Checking if Connect has log level set properly
2022-04-04 17:30:34 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.I0Itec.zkclient Expected: ERROR
2022-04-04 17:30:34 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: connect.root.logger.level Expected: INFO
2022-04-04 17:30:34 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.connect.logger.level Expected: DEBUG
2022-04-04 17:30:34 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.reflections Expected: WARN
2022-04-04 17:30:34 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-87645ae1-connect-connect
2022-04-04 17:30:34 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-87645ae1-connect-connect
2022-04-04 17:30:34 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:30:34 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-87645ae1-connect-connect rolling update
2022-04-04 17:31:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-87645ae1-connect-connect will be ready
2022-04-04 17:31:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-87645ae1-connect-connect is ready
2022-04-04 17:31:54 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-87645ae1-connect-connect rolling update finished
2022-04-04 17:31:54 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-87645ae1-connect-connect
2022-04-04 17:31:54 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-87645ae1-connect-connect
2022-04-04 17:31:54 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:31:54 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-87645ae1-connect-connect-66789945c6-vjfkx container my-cluster-87645ae1-connect-connect will be ready
2022-04-04 17:31:54 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-87645ae1-connect-connect-66789945c6-vjfkx container my-cluster-87645ae1-connect-connect is ready
2022-04-04 17:31:54 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-87645ae1-connect-connect-66789945c6-vjfkx with container my-cluster-87645ae1-connect-connect
2022-04-04 17:31:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:31:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConnectLogSetting
2022-04-04 17:31:54 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-87645ae1-connect-allow in namespace log-setting-st
2022-04-04 17:31:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-87645ae1-connect-scraper in namespace log-setting-st
2022-04-04 17:31:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-87645ae1-connect in namespace log-setting-st
2022-04-04 17:32:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:32:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testConnectLogSetting-FINISHED
2022-04-04 17:32:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:32:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:32:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testKafkaLogSetting-STARTED
2022-04-04 17:32:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:32:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-420586644-579132049 in namespace log-setting-st
2022-04-04 17:32:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-420586644-579132049 will have desired state: Ready
2022-04-04 17:32:35 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-420586644-579132049 is in desired state: Ready
2022-04-04 17:32:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-897423581-961233835 in namespace log-setting-st
2022-04-04 17:32:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-897423581-961233835 will have desired state: Ready
2022-04-04 17:32:36 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-897423581-961233835 is in desired state: Ready
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:217] Checking if Kafka, Zookeeper, TO and UO of cluster:log-setting-cluster-name has log level set properly
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.apache.zookeeper Expected: WARN
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.network.Processor Expected: OFF
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.request.logger Expected: FATAL
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.controller Expected: WARN
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: kafka.root.logger.level Expected: INFO
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.state.change.logger Expected: DEBUG
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.network.RequestChannel$ Expected: ERROR
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.server.KafkaApis Expected: INFO
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka Expected: TRACE
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.apache.kafka Expected: DEBUG
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.authorizer.logger Expected: FATAL
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.log.LogCleaner Expected: TRACE
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.I0Itec.zkclient.ZkClient Expected: ERROR
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.kafka.logger.level Expected: INFO
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: zookeeper.root.logger Expected: OFF
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.zookeeper.logger.level Expected: DEBUG
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: rootLogger.level Expected: DEBUG
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.operator.logger.level Expected: DEBUG
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: rootLogger.level Expected: DEBUG
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.operator.logger.level Expected: DEBUG
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:226] Checking if Kafka, Zookeeper, TO and UO of cluster:log-setting-cluster-name has GC logging enabled in stateful sets/deployments
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-04 17:32:36 [main] [32mINFO [m [LogSettingST:232] Changing JVM options - setting GC logging to false
2022-04-04 17:32:36 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: log-setting-cluster-name-zookeeper rolling update
2022-04-04 17:32:42 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: log-setting-cluster-name-zookeeper has been successfully rolled
2022-04-04 17:32:42 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 1 Pod(s) of log-setting-cluster-name-zookeeper to be ready
2022-04-04 17:33:09 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: log-setting-cluster-name-kafka rolling update
2022-04-04 17:34:29 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: log-setting-cluster-name-kafka has been successfully rolled
2022-04-04 17:34:29 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of log-setting-cluster-name-kafka to be ready
2022-04-04 17:34:59 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment log-setting-cluster-name-entity-operator rolling update
2022-04-04 17:34:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: log-setting-cluster-name-entity-operator will be ready
2022-04-04 17:35:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: log-setting-cluster-name-entity-operator is ready
2022-04-04 17:35:48 [main] [32mINFO [m [DeploymentUtils:141] Deployment log-setting-cluster-name-entity-operator rolling update finished
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:244] Checking if Kafka, Zookeeper, TO and UO of cluster: log-setting-cluster-name has GC logging disabled in stateful sets/deployments
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:250] Checking if Kafka, Zookeeper, TO and UO of cluster: gc-set-logging has GC logging disabled in stateful sets/deployments
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-04 17:35:48 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-04 17:35:49 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f container cruise-control will be ready
2022-04-04 17:35:49 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f container cruise-control is ready
2022-04-04 17:35:49 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f with container cruise-control
2022-04-04 17:35:49 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f container tls-sidecar will be ready
2022-04-04 17:35:49 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f container tls-sidecar is ready
2022-04-04 17:35:49 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-cruise-control-578cdbfc94-gsr7f with container tls-sidecar
2022-04-04 17:35:49 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-b55lg container topic-operator will be ready
2022-04-04 17:35:49 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-b55lg container topic-operator is ready
2022-04-04 17:35:49 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-b55lg with container topic-operator
2022-04-04 17:35:50 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-b55lg container user-operator will be ready
2022-04-04 17:35:50 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-b55lg container user-operator is ready
2022-04-04 17:35:50 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-b55lg with container user-operator
2022-04-04 17:35:50 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-b55lg container tls-sidecar will be ready
2022-04-04 17:35:50 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-b55lg container tls-sidecar is ready
2022-04-04 17:35:50 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-b55lg with container tls-sidecar
2022-04-04 17:35:50 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-0 container kafka will be ready
2022-04-04 17:35:50 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-0 container kafka is ready
2022-04-04 17:35:50 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-0 with container kafka
2022-04-04 17:35:50 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-1 container kafka will be ready
2022-04-04 17:35:50 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-1 container kafka is ready
2022-04-04 17:35:50 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-1 with container kafka
2022-04-04 17:35:50 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-2 container kafka will be ready
2022-04-04 17:35:50 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-2 container kafka is ready
2022-04-04 17:35:50 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-2 with container kafka
2022-04-04 17:35:51 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-6q4ht container log-setting-cluster-name-kafka-exporter will be ready
2022-04-04 17:35:51 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-6q4ht container log-setting-cluster-name-kafka-exporter is ready
2022-04-04 17:35:51 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-6q4ht with container log-setting-cluster-name-kafka-exporter
2022-04-04 17:35:51 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-zookeeper-0 container zookeeper will be ready
2022-04-04 17:35:51 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-zookeeper-0 container zookeeper is ready
2022-04-04 17:35:51 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-zookeeper-0 with container zookeeper
2022-04-04 17:35:51 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-nfzhf container topic-operator will be ready
2022-04-04 17:35:51 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-nfzhf container topic-operator is ready
2022-04-04 17:35:51 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-nfzhf with container topic-operator
2022-04-04 17:35:51 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-nfzhf container user-operator will be ready
2022-04-04 17:35:51 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-nfzhf container user-operator is ready
2022-04-04 17:35:51 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-nfzhf with container user-operator
2022-04-04 17:35:51 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-nfzhf container tls-sidecar will be ready
2022-04-04 17:35:51 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-nfzhf container tls-sidecar is ready
2022-04-04 17:35:51 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-nfzhf with container tls-sidecar
2022-04-04 17:35:51 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-kafka-0 container kafka will be ready
2022-04-04 17:35:52 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-kafka-0 container kafka is ready
2022-04-04 17:35:52 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-kafka-0 with container kafka
2022-04-04 17:35:52 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-zookeeper-0 container zookeeper will be ready
2022-04-04 17:35:52 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-zookeeper-0 container zookeeper is ready
2022-04-04 17:35:52 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-zookeeper-0 with container zookeeper
2022-04-04 17:35:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:35:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaLogSetting
2022-04-04 17:35:52 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-897423581-961233835 in namespace log-setting-st
2022-04-04 17:35:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-420586644-579132049 in namespace log-setting-st
2022-04-04 17:36:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:36:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testKafkaLogSetting-FINISHED
2022-04-04 17:36:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:36:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:36:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testBridgeLogSetting-STARTED
2022-04-04 17:36:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:36:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-6d280c66-bridge in namespace log-setting-st
2022-04-04 17:36:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-6d280c66-bridge will have desired state: Ready
2022-04-04 17:36:26 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-6d280c66-bridge is in desired state: Ready
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:392] Checking if Bridge has log level set properly
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.subscribe.name Expected: http.openapi.operation.subscribe
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.createConsumer.name Expected: http.openapi.operation.createConsumer
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.createConsumer.level Expected: INFO
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.deleteConsumer.name Expected: http.openapi.operation.deleteConsumer
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.poll.name Expected: http.openapi.operation.poll
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.sendToPartition.level Expected: TRACE
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.unsubscribe.name Expected: http.openapi.operation.unsubscribe
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.unsubscribe.level Expected: DEBUG
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.ready.level Expected: WARN
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.assign.name Expected: http.openapi.operation.assign
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToEnd.name Expected: http.openapi.operation.seekToEnd
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.poll.level Expected: INFO
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.deleteConsumer.level Expected: DEBUG
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.subscribe.level Expected: TRACE
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.openapi.level Expected: TRACE
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.commit.name Expected: http.openapi.operation.commit
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.send.level Expected: ERROR
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seek.name Expected: http.openapi.operation.seek
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.healthy.level Expected: ERROR
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.ready.name Expected: http.openapi.operation.ready
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.logger.bridge.level Expected: ERROR
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seek.level Expected: INFO
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.assign.level Expected: TRACE
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.sendToPartition.name Expected: http.openapi.operation.sendToPartition
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.send.name Expected: http.openapi.operation.send
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.openapi.name Expected: http.openapi.operation.openapi
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.healthy.name Expected: http.openapi.operation.healthy
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.commit.level Expected: DEBUG
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToEnd.level Expected: WARN
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToBeginning.name Expected: http.openapi.operation.seekToBeginning
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToBeginning.level Expected: DEBUG
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-6d280c66-bridge-bridge
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-6d280c66-bridge-bridge
2022-04-04 17:36:26 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-04 17:36:26 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-6d280c66-bridge-bridge rolling update
2022-04-04 17:36:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6d280c66-bridge-bridge will be ready
2022-04-04 17:36:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6d280c66-bridge-bridge is ready
2022-04-04 17:37:06 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-6d280c66-bridge-bridge rolling update finished
2022-04-04 17:37:06 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-6d280c66-bridge-bridge
2022-04-04 17:37:06 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-6d280c66-bridge-bridge
2022-04-04 17:37:06 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-04 17:37:06 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-6d280c66-bridge-bridge-69989fdbc8-vx99r container my-cluster-6d280c66-bridge-bridge will be ready
2022-04-04 17:37:06 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-6d280c66-bridge-bridge-69989fdbc8-vx99r container my-cluster-6d280c66-bridge-bridge is ready
2022-04-04 17:37:06 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-6d280c66-bridge-bridge-69989fdbc8-vx99r with container my-cluster-6d280c66-bridge-bridge
2022-04-04 17:37:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:37:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBridgeLogSetting
2022-04-04 17:37:07 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-6d280c66-bridge in namespace log-setting-st
2022-04-04 17:37:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:37:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testBridgeLogSetting-FINISHED
2022-04-04 17:37:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:37:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:37:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for LogSettingST
2022-04-04 17:37:17 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka gc-set-logging in namespace log-setting-st
2022-04-04 17:37:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment shared-kafka-clients in namespace log-setting-st
2022-04-04 17:37:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka log-setting-cluster-name in namespace log-setting-st
2022-04-04 17:37:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace log-setting-st, for cruise control Kafka cluster log-setting-cluster-name
2022-04-04 17:38:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,063.747 s - in io.strimzi.systemtest.log.LogSettingST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.FeatureGatesIsolatedST
2022-04-04 17:38:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 17:38:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:38:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testSwitchingStrimziPodSetFeatureGateOnAndOff-STARTED
2022-04-04 17:38:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:38:48 [main] [32mINFO [m [FeatureGatesIsolatedST:270] Deploying CO with STS - SPS is disabled
2022-04-04 17:38:48 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 17:38:48 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 17:38:48 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 17:38:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:38:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 17:38:48 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:38:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:38:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:38:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:38:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:38:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:38:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:38:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 17:38:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:38:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:38:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:38:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:38:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:38:58 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:38:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:38:58 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:38:58 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:38:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:38:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:38:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:38:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:38:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:08 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:39:24 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=-UseStrimziPodSets, valueFrom=null, additionalProperties={})]
2022-04-04 17:39:24 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 17:39:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 17:39:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 17:39:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:39:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:39:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:39:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:39:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:39:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:39:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:39:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:39:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 17:39:25 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:39:25 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:39:25 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:39:25 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:39:25 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:39:25 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 17:39:25 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 17:39:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:39:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 17:39:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 17:39:56 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 17:40:06 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 17:40:06 [main] [32mINFO [m [FeatureGatesIsolatedST:281] Deploying Kafka
2022-04-04 17:40:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1d860eeb in namespace infra-namespace
2022-04-04 17:40:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1d860eeb will have desired state: Ready
2022-04-04 17:41:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1d860eeb is in desired state: Ready
2022-04-04 17:41:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1605235161-22002459 in namespace infra-namespace
2022-04-04 17:41:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1605235161-22002459 will have desired state: Ready
2022-04-04 17:41:33 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1605235161-22002459 is in desired state: Ready
2022-04-04 17:41:33 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 17:41:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-1268741957 in namespace infra-namespace
2022-04-04 17:41:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-1405749497 in namespace infra-namespace
2022-04-04 17:41:33 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-1268741957 will be in active state
2022-04-04 17:41:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1405749497 will be in active state
2022-04-04 17:41:34 [main] [32mINFO [m [FeatureGatesIsolatedST:304] Changing FG env variable to enable SPS
2022-04-04 17:41:34 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-04 17:41:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 17:42:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 17:42:36 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-04 17:42:36 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1d860eeb-zookeeper rolling update
2022-04-04 17:43:01 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1d860eeb-zookeeper has been successfully rolled
2022-04-04 17:43:01 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-1d860eeb-zookeeper to be ready
2022-04-04 17:43:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1d860eeb will have desired state: Ready
2022-04-04 17:43:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1d860eeb is in desired state: Ready
2022-04-04 17:43:26 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-1d860eeb is ready
2022-04-04 17:43:26 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1d860eeb-kafka rolling update
2022-04-04 17:44:51 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1d860eeb-kafka has been successfully rolled
2022-04-04 17:44:51 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-1d860eeb-kafka to be ready
2022-04-04 17:45:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1d860eeb will have desired state: Ready
2022-04-04 17:45:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1d860eeb is in desired state: Ready
2022-04-04 17:45:22 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-1d860eeb is ready
2022-04-04 17:45:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1d860eeb will have desired state: Ready
2022-04-04 17:45:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1d860eeb is in desired state: Ready
2022-04-04 17:45:22 [main] [32mINFO [m [FeatureGatesIsolatedST:319] Changing FG env variable to disable again SPS
2022-04-04 17:45:22 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-04 17:45:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 17:45:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 17:46:05 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-04 17:46:05 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1d860eeb-zookeeper rolling update
2022-04-04 17:46:50 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1d860eeb-zookeeper has been successfully rolled
2022-04-04 17:46:50 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-1d860eeb-zookeeper to be ready
2022-04-04 17:47:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1d860eeb will have desired state: Ready
2022-04-04 17:47:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1d860eeb is in desired state: Ready
2022-04-04 17:47:15 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-1d860eeb is ready
2022-04-04 17:47:15 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-1d860eeb-kafka rolling update
2022-04-04 17:48:20 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-1d860eeb-kafka has been successfully rolled
2022-04-04 17:48:20 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-1d860eeb-kafka to be ready
2022-04-04 17:48:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1d860eeb will have desired state: Ready
2022-04-04 17:48:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1d860eeb is in desired state: Ready
2022-04-04 17:48:49 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-1d860eeb is ready
2022-04-04 17:48:49 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-test-1268741957 and consumer consumer-test-1405749497 finish
2022-04-04 17:50:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:50:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSwitchingStrimziPodSetFeatureGateOnAndOff
2022-04-04 17:50:38 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-1268741957 in namespace infra-namespace
2022-04-04 17:50:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1605235161-22002459 in namespace infra-namespace
2022-04-04 17:50:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-1405749497 in namespace infra-namespace
2022-04-04 17:50:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1d860eeb in namespace infra-namespace
2022-04-04 17:50:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:50:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testSwitchingStrimziPodSetFeatureGateOnAndOff-FINISHED
2022-04-04 17:50:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:50:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:50:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testControlPlaneListenerFeatureGate-STARTED
2022-04-04 17:50:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:50:48 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 17:50:48 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 17:50:48 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 17:50:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:50:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 17:50:48 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:50:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:50:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:50:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:50:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:50:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:50:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:50:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 17:50:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:50:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:50:58 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:50:58 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:50:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:50:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:50:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:50:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:50:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:50:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:50:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:50:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:50:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:50:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:51:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:51:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:51:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:51:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:51:24 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=-ControlPlaneListener, valueFrom=null, additionalProperties={})]
2022-04-04 17:51:24 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 17:51:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 17:51:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 17:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:51:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:51:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:51:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:51:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:51:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:51:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:51:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 17:51:25 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:51:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:51:25 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 17:51:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:51:25 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 17:51:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:51:25 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:51:25 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:51:25 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 17:51:25 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:51:25 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 17:51:25 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 17:51:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:51:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 17:51:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:51:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 17:51:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 17:51:50 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 17:52:00 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 17:52:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-be5f7715 in namespace infra-namespace
2022-04-04 17:52:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-be5f7715 will have desired state: Ready
2022-04-04 17:53:54 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-be5f7715 is in desired state: Ready
2022-04-04 17:53:54 [main] [32mINFO [m [FeatureGatesIsolatedST:96] Check for presence of ContainerPort 9090/tcp (tcp-ctrlplane) in first Kafka pod.
2022-04-04 17:53:54 [main] [32mINFO [m [FeatureGatesIsolatedST:104] Try to send some messages to Kafka over next few minutes.
2022-04-04 17:53:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2108940017-1457476549 in namespace infra-namespace
2022-04-04 17:53:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2108940017-1457476549 will have desired state: Ready
2022-04-04 17:53:55 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2108940017-1457476549 is in desired state: Ready
2022-04-04 17:53:55 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 17:53:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-240207205 in namespace infra-namespace
2022-04-04 17:53:55 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-240207205 will be in active state
2022-04-04 17:53:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-861217679 in namespace infra-namespace
2022-04-04 17:53:55 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-861217679 will be in active state
2022-04-04 17:53:56 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-861217679 will be in active state
2022-04-04 17:53:56 [main] [32mINFO [m [FeatureGatesIsolatedST:127] Delete first found Kafka broker pod.
2022-04-04 17:53:56 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-be5f7715-zookeeper to be ready
2022-04-04 17:54:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-be5f7715 will have desired state: Ready
2022-04-04 17:54:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-be5f7715 is in desired state: Ready
2022-04-04 17:54:06 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-be5f7715 is ready
2022-04-04 17:54:06 [main] [32mINFO [m [FeatureGatesIsolatedST:131] Force Rolling Update of Kafka via annotation.
2022-04-04 17:54:06 [main] [32mINFO [m [FeatureGatesIsolatedST:139] Wait for next reconciliation to happen.
2022-04-04 17:54:06 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-be5f7715-zookeeper rolling update
2022-04-04 17:55:21 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-be5f7715-zookeeper has been successfully rolled
2022-04-04 17:55:21 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-be5f7715-zookeeper to be ready
2022-04-04 17:55:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-be5f7715 will have desired state: Ready
2022-04-04 17:55:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-be5f7715 is in desired state: Ready
2022-04-04 17:55:42 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-be5f7715 is ready
2022-04-04 17:55:42 [main] [32mINFO [m [FeatureGatesIsolatedST:142] Waiting for clients to finish sending/receiving messages.
2022-04-04 17:55:42 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-test-240207205 to finished
2022-04-04 17:56:37 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-test-861217679 to finished
2022-04-04 17:56:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:56:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testControlPlaneListenerFeatureGate
2022-04-04 17:56:42 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-240207205 in namespace infra-namespace
2022-04-04 17:56:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2108940017-1457476549 in namespace infra-namespace
2022-04-04 17:56:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-861217679 in namespace infra-namespace
2022-04-04 17:56:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-be5f7715 in namespace infra-namespace
2022-04-04 17:56:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:56:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testControlPlaneListenerFeatureGate-FINISHED
2022-04-04 17:56:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 17:56:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 17:56:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testStrimziPodSetsFeatureGate-STARTED
2022-04-04 17:56:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 17:56:52 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 17:56:52 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 17:56:52 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 17:56:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 17:56:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 17:56:52 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:56:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:56:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:56:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:56:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:56:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 17:56:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:57:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:03 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:57:03 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:57:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:57:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:57:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:57:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:57:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:57:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:57:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:57:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:57:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:57:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:57:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 17:57:29 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=+UseStrimziPodSets, valueFrom=null, additionalProperties={})]
2022-04-04 17:57:29 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 17:57:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 17:57:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 17:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 17:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 17:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 17:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 17:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 17:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 17:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:57:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 17:57:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 17:57:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 17:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 17:57:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 17:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 17:57:30 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 17:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:57:30 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 17:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 17:57:30 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 17:57:30 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 17:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 17:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 17:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 17:57:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 17:57:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 17:57:51 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 17:58:01 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 17:58:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5d97c603 in namespace infra-namespace
2022-04-04 17:58:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5d97c603 will have desired state: Ready
2022-04-04 18:00:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5d97c603 is in desired state: Ready
2022-04-04 18:00:01 [main] [32mINFO [m [FeatureGatesIsolatedST:182] Try to send some messages to Kafka over next few minutes.
2022-04-04 18:00:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-595636325-142861681 in namespace infra-namespace
2022-04-04 18:00:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-595636325-142861681 will have desired state: Ready
2022-04-04 18:00:02 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-595636325-142861681 is in desired state: Ready
2022-04-04 18:00:02 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 18:00:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-822566649 in namespace infra-namespace
2022-04-04 18:00:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-822566649 will be in active state
2022-04-04 18:00:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-96073731 in namespace infra-namespace
2022-04-04 18:00:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-96073731 will be in active state
2022-04-04 18:00:03 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-96073731 will be in active state
2022-04-04 18:00:03 [main] [32mINFO [m [FeatureGatesIsolatedST:207] Delete first found ZooKeeper pod my-cluster-5d97c603-zookeeper-0
2022-04-04 18:00:03 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-5d97c603-zookeeper to be ready
2022-04-04 18:00:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5d97c603 will have desired state: Ready
2022-04-04 18:00:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5d97c603 is in desired state: Ready
2022-04-04 18:00:41 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-5d97c603 is ready
2022-04-04 18:00:41 [main] [32mINFO [m [FeatureGatesIsolatedST:213] Delete first found Kafka broker pod my-cluster-5d97c603-kafka-0
2022-04-04 18:00:41 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-5d97c603-kafka to be ready
2022-04-04 18:01:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5d97c603 will have desired state: Ready
2022-04-04 18:01:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5d97c603 is in desired state: Ready
2022-04-04 18:01:27 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-5d97c603 is ready
2022-04-04 18:01:27 [main] [32mINFO [m [FeatureGatesIsolatedST:218] Force Rolling Update of ZooKeeper via annotation.
2022-04-04 18:01:27 [main] [32mINFO [m [FeatureGatesIsolatedST:228] Wait for next reconciliation to happen.
2022-04-04 18:01:27 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-5d97c603-zookeeper rolling update
2022-04-04 18:02:47 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-5d97c603-zookeeper has been successfully rolled
2022-04-04 18:02:47 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-5d97c603-zookeeper to be ready
2022-04-04 18:03:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5d97c603 will have desired state: Ready
2022-04-04 18:03:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5d97c603 is in desired state: Ready
2022-04-04 18:03:16 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-5d97c603 is ready
2022-04-04 18:03:16 [main] [32mINFO [m [FeatureGatesIsolatedST:232] Force Rolling Update of Kafka via annotation.
2022-04-04 18:03:16 [main] [32mINFO [m [FeatureGatesIsolatedST:242] Wait for next reconciliation to happen.
2022-04-04 18:03:16 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-5d97c603-kafka rolling update
2022-04-04 18:05:01 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-5d97c603-kafka has been successfully rolled
2022-04-04 18:05:01 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-5d97c603-kafka to be ready
2022-04-04 18:05:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5d97c603 will have desired state: Ready
2022-04-04 18:05:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5d97c603 is in desired state: Ready
2022-04-04 18:05:31 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-5d97c603 is ready
2022-04-04 18:05:31 [main] [32mINFO [m [FeatureGatesIsolatedST:245] Waiting for clients to finish sending/receiving messages.
2022-04-04 18:05:31 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-test-822566649 to finished
2022-04-04 18:05:36 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-test-96073731 to finished
2022-04-04 18:05:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:05:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziPodSetsFeatureGate
2022-04-04 18:05:41 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-822566649 in namespace infra-namespace
2022-04-04 18:05:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-595636325-142861681 in namespace infra-namespace
2022-04-04 18:05:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5d97c603 in namespace infra-namespace
2022-04-04 18:05:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-96073731 in namespace infra-namespace
2022-04-04 18:05:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:05:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testStrimziPodSetsFeatureGate-FINISHED
2022-04-04 18:05:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:05:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:05:51 [main] [32mINFO [m [ResourceManager:346] In context FeatureGatesIsolatedST is everything deleted.
2022-04-04 18:05:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,647.432 s - in io.strimzi.systemtest.operators.FeatureGatesIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
2022-04-04 18:05:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:06:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:06:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST.testNamespacedRbacScopeDeploysRoles-STARTED
2022-04-04 18:06:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:06:16 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:06:16 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:06:16 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:06:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:06:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:06:16 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:06:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:06:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 18:06:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:06:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:26 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:06:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:06:26 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:06:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:06:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:06:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:06:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:06:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:06:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:06:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:06:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:06:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:06:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:06:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:07:02 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_RBAC_SCOPE, value=NAMESPACE, valueFrom=null, additionalProperties={})]
2022-04-04 18:07:02 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:07:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:07:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:07:02 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 18:07:02 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 18:07:02 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 18:07:02 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 18:07:02 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:07:03 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-04 18:07:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator4256134114344889520.yaml in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-04 18:07:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation14405796090638178943.yaml in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:07:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:07:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:07:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:07:39 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:07:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-93beeff5 in namespace infra-namespace
2022-04-04 18:07:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-93beeff5 will have desired state: Ready
2022-04-04 18:08:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-93beeff5 is in desired state: Ready
2022-04-04 18:08:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-93beeff5 will have desired state: Ready
2022-04-04 18:08:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-93beeff5 is in desired state: Ready
2022-04-04 18:08:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:08:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNamespacedRbacScopeDeploysRoles
2022-04-04 18:08:56 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-93beeff5 in namespace infra-namespace
2022-04-04 18:09:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:09:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST.testNamespacedRbacScopeDeploysRoles-FINISHED
2022-04-04 18:09:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:09:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:09:06 [main] [32mINFO [m [ResourceManager:346] In context NamespaceRbacScopeOperatorIsolatedST is everything deleted.
2022-04-04 18:09:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 194.846 s - in io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.RecoveryIsolatedST
2022-04-04 18:09:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:09:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:09:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperMetricsConfigDeletion-STARTED
2022-04-04 18:09:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:09:31 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:09:31 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:09:31 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:09:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:09:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:09:31 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 18:09:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 18:09:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:09:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 18:09:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 18:09:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:09:41 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:09:41 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:41 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 18:09:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:09:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:09:51 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:51 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:09:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:09:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:09:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:09:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:09:56 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:09:56 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:09:56 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:09:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:09:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:09:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:09:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:09:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:09:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:10:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:10:24 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:10:34 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:10:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1972233493 in namespace infra-namespace
2022-04-04 18:10:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1972233493 will have desired state: Ready
2022-04-04 18:11:53 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1972233493 is in desired state: Ready
2022-04-04 18:11:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1972233493 in namespace infra-namespace
2022-04-04 18:11:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1972233493 will be ready
2022-04-04 18:11:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1972233493 is ready
2022-04-04 18:11:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1972233493 in namespace infra-namespace
2022-04-04 18:11:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1972233493 will have desired state: Ready
2022-04-04 18:12:19 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1972233493 is in desired state: Ready
2022-04-04 18:12:19 [main] [32mINFO [m [RecoveryIsolatedST:191] Running deleteZookeeperMetricsConfig with cluster recovery-cluster-1972233493
2022-04-04 18:12:19 [main] [32mINFO [m [RecoveryIsolatedST:199] Waiting for creation recovery-cluster-1972233493-zookeeper-config
2022-04-04 18:12:19 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-1972233493-zookeeper-config-39056d96-2cea-44e9-90ef-d22444256a9e recovery in namespace infra-namespace
2022-04-04 18:12:35 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-1972233493-zookeeper-config was recovered
2022-04-04 18:12:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:12:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperMetricsConfigDeletion
2022-04-04 18:12:35 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1972233493 in namespace infra-namespace
2022-04-04 18:12:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1972233493 in namespace infra-namespace
2022-04-04 18:12:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1972233493 in namespace infra-namespace
2022-04-04 18:13:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:13:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperMetricsConfigDeletion-FINISHED
2022-04-04 18:13:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:13:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:13:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeServiceDeletion-STARTED
2022-04-04 18:13:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:13:25 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:13:25 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:13:25 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:13:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:13:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:13:25 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:13:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:13:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:13:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:13:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:13:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:13:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:13:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:13:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:13:35 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:13:35 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:13:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:13:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:13:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:13:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:13:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:13:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:13:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:13:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:13:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:13:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:13:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:13:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:13:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:14:01 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:14:01 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:14:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:14:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:14:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:14:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:14:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:14:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:14:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:14:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:14:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:14:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:14:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:14:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:14:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:14:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:14:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:14:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:14:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:14:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:14:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:14:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:14:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:14:26 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:14:36 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:14:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1909196868 in namespace infra-namespace
2022-04-04 18:14:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1909196868 will have desired state: Ready
2022-04-04 18:16:04 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1909196868 is in desired state: Ready
2022-04-04 18:16:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1909196868 in namespace infra-namespace
2022-04-04 18:16:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1909196868 will be ready
2022-04-04 18:16:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1909196868 is ready
2022-04-04 18:16:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1909196868 in namespace infra-namespace
2022-04-04 18:16:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1909196868 will have desired state: Ready
2022-04-04 18:16:32 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1909196868 is in desired state: Ready
2022-04-04 18:16:32 [main] [32mINFO [m [RecoveryIsolatedST:222] Running deleteKafkaBridgeService with cluster recovery-cluster-1909196868
2022-04-04 18:16:32 [main] [32mINFO [m [RecoveryIsolatedST:227] Waiting for service recovery-cluster-1909196868-bridge-service recovery
2022-04-04 18:16:32 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-1909196868-bridge-service-d31eb737-a3c3-4d6e-b2bd-f948ceb1b512 in namespace infra-namespace will be recovered
2022-04-04 18:16:39 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-1909196868-bridge-service in namespace infra-namespace is recovered
2022-04-04 18:16:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:16:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeServiceDeletion
2022-04-04 18:16:39 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1909196868 in namespace infra-namespace
2022-04-04 18:16:39 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1909196868 in namespace infra-namespace
2022-04-04 18:16:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1909196868 in namespace infra-namespace
2022-04-04 18:17:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:17:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeServiceDeletion-FINISHED
2022-04-04 18:17:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:17:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:17:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaHeadlessServiceDeletion-STARTED
2022-04-04 18:17:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:17:19 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:17:19 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:17:19 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:17:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:17:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:17:19 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:17:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:17:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:17:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:17:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:17:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:17:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:17:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:17:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:17:29 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:17:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:17:29 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:17:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:17:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:17:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:39 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:17:54 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:17:54 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:17:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:17:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:17:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:17:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:17:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:17:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:17:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:17:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:18:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:18:11 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:18:21 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:18:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-554965418 in namespace infra-namespace
2022-04-04 18:18:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-554965418 will have desired state: Ready
2022-04-04 18:20:18 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-554965418 is in desired state: Ready
2022-04-04 18:20:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-554965418 in namespace infra-namespace
2022-04-04 18:20:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-554965418 will be ready
2022-04-04 18:20:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-554965418 is ready
2022-04-04 18:20:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-554965418 in namespace infra-namespace
2022-04-04 18:20:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-554965418 will have desired state: Ready
2022-04-04 18:20:39 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-554965418 is in desired state: Ready
2022-04-04 18:20:39 [main] [32mINFO [m [RecoveryIsolatedST:143] Running deleteKafkaHeadlessService with cluster recovery-cluster-554965418
2022-04-04 18:20:39 [main] [32mINFO [m [RecoveryIsolatedST:150] Waiting for creation recovery-cluster-554965418-kafka-brokers
2022-04-04 18:20:39 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-554965418-kafka-brokers-5f4f17e6-cf11-4a1b-b22b-399b1b2edbb5 in namespace infra-namespace will be recovered
2022-04-04 18:21:04 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-554965418-kafka-brokers in namespace infra-namespace is recovered
2022-04-04 18:21:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:21:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaHeadlessServiceDeletion
2022-04-04 18:21:04 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-554965418 in namespace infra-namespace
2022-04-04 18:21:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-554965418 in namespace infra-namespace
2022-04-04 18:21:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-554965418 in namespace infra-namespace
2022-04-04 18:22:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:22:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaHeadlessServiceDeletion-FINISHED
2022-04-04 18:22:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:22:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:22:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaStatefulSetDeletion-STARTED
2022-04-04 18:22:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:22:04 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:22:04 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:22:04 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:22:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:22:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:22:04 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:22:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:22:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:22:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:22:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:22:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:22:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:22:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:22:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:22:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:22:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:22:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:22:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:22:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:22:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:22:40 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:22:40 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:22:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:22:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:22:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:22:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:22:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:22:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:22:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:22:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:22:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:22:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:22:41 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:22:41 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:22:41 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:22:41 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:22:41 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:22:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:22:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:23:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:23:21 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:23:31 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:23:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-246059257 in namespace infra-namespace
2022-04-04 18:23:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-246059257 will have desired state: Ready
2022-04-04 18:24:58 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-246059257 is in desired state: Ready
2022-04-04 18:24:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-246059257 in namespace infra-namespace
2022-04-04 18:24:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-246059257 will be ready
2022-04-04 18:25:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-246059257 is ready
2022-04-04 18:25:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-246059257 in namespace infra-namespace
2022-04-04 18:25:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-246059257 will have desired state: Ready
2022-04-04 18:25:21 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-246059257 is in desired state: Ready
2022-04-04 18:25:21 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-246059257-kafka will be deleted
2022-04-04 18:25:21 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-246059257-kafka-0 will be deleted
2022-04-04 18:25:31 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-246059257-kafka-0 deleted
2022-04-04 18:25:31 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-246059257-kafka-1 will be deleted
2022-04-04 18:25:41 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-246059257-kafka-1 deleted
2022-04-04 18:25:41 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-246059257-kafka-2 will be deleted
2022-04-04 18:25:41 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-246059257-kafka-2 deleted
2022-04-04 18:25:42 [main] [32mINFO [m [RecoveryIsolatedST:90] Waiting for recovery recovery-cluster-246059257-kafka
2022-04-04 18:25:42 [main] [32mINFO [m [StatefulSetUtils:73] Waiting for StatefulSet recovery-cluster-246059257-kafka-5193dd38-ef1a-4fc1-b3ab-b16b66aad386 recovery in namespace infra-namespace
2022-04-04 18:25:55 [main] [32mINFO [m [StatefulSetUtils:76] StatefulSet recovery-cluster-246059257-kafka was recovered
2022-04-04 18:25:55 [main] [32mINFO [m [StatefulSetUtils:39] Waiting for StatefulSet recovery-cluster-246059257-kafka to be ready
2022-04-04 18:26:18 [main] [32mINFO [m [StatefulSetUtils:44] Waiting for 3 Pod(s) of StatefulSet recovery-cluster-246059257-kafka to be ready
2022-04-04 18:26:28 [main] [32mINFO [m [StatefulSetUtils:47] StatefulSet recovery-cluster-246059257-kafka is ready
2022-04-04 18:26:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:26:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaStatefulSetDeletion
2022-04-04 18:26:28 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-246059257 in namespace infra-namespace
2022-04-04 18:26:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-246059257 in namespace infra-namespace
2022-04-04 18:26:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-246059257 in namespace infra-namespace
2022-04-04 18:27:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:27:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaStatefulSetDeletion-FINISHED
2022-04-04 18:27:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:27:18 [main] [32mINFO [m [StrimziPodSetTestCondition:23] According to STRIMZI_FEATURE_GATES env variable with value: , the StatefulSets are used, skipping this StrimziPodSet related test
2022-04-04 18:27:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:27:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromEntityOperatorDeletion-STARTED
2022-04-04 18:27:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:27:18 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:27:18 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:27:18 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:27:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:27:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:27:18 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:27:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:27:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:27:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:27:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:27:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:27:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:27:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:27:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:27:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:27:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:27:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:28 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:27:28 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:27:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:27:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:27:44 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:27:44 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:27:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:27:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:27:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:27:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:27:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:27:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:27:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:27:44 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:27:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:27:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:44 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:27:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:27:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:27:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:27:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:27:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:27:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:27:45 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:27:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:27:45 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:27:45 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:27:45 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:27:45 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:27:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:27:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:28:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:28:16 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:28:26 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:28:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-555958433 in namespace infra-namespace
2022-04-04 18:28:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-555958433 will have desired state: Ready
2022-04-04 18:29:55 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-555958433 is in desired state: Ready
2022-04-04 18:29:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-555958433 in namespace infra-namespace
2022-04-04 18:29:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-555958433 will be ready
2022-04-04 18:29:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-555958433 is ready
2022-04-04 18:29:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-555958433 in namespace infra-namespace
2022-04-04 18:29:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-555958433 will have desired state: Ready
2022-04-04 18:30:21 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-555958433 is in desired state: Ready
2022-04-04 18:30:21 [main] [32mINFO [m [RecoveryIsolatedST:64] Running testRecoveryFromEntityOperatorDeletion with cluster recovery-cluster-555958433
2022-04-04 18:30:21 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-555958433-entity-operator will be deleted
2022-04-04 18:30:21 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-555958433-entity-operator-6f8dcc7599-vx9g9 will be deleted
2022-04-04 18:30:31 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-555958433-entity-operator-6f8dcc7599-vx9g9 deleted
2022-04-04 18:30:31 [main] [32mINFO [m [RecoveryIsolatedST:72] Waiting for recovery recovery-cluster-555958433-entity-operator
2022-04-04 18:30:31 [main] [32mINFO [m [DeploymentUtils:154] Waiting for Deployment recovery-cluster-555958433-entity-operator-57ae5208-2c5e-476f-b8e3-004dae9dfdab recovery in namespace infra-namespace
2022-04-04 18:35:27 [main] [32mINFO [m [DeploymentUtils:157] Deployment recovery-cluster-555958433-entity-operator was recovered
2022-04-04 18:35:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: recovery-cluster-555958433-entity-operator will be ready
2022-04-04 18:35:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: recovery-cluster-555958433-entity-operator is ready
2022-04-04 18:35:44 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment recovery-cluster-555958433-entity-operator to be ready
2022-04-04 18:35:54 [main] [32mINFO [m [DeploymentUtils:197] Deployment recovery-cluster-555958433-entity-operator is ready
2022-04-04 18:35:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:35:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromEntityOperatorDeletion
2022-04-04 18:35:54 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-555958433 in namespace infra-namespace
2022-04-04 18:35:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-555958433 in namespace infra-namespace
2022-04-04 18:35:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-555958433 in namespace infra-namespace
2022-04-04 18:36:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:36:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromEntityOperatorDeletion-FINISHED
2022-04-04 18:36:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:36:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:36:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeDeploymentDeletion-STARTED
2022-04-04 18:36:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:36:34 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:36:34 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:36:34 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:36:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:36:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:36:34 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:36:34 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:36:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:36:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:36:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:36:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:36:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:36:44 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:36:44 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:36:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:36:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:36:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:36:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:36:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:36:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:36:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:36:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:36:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:36:54 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:36:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:36:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:36:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:36:55 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:37:10 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:37:10 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:37:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:37:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:37:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:37:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:37:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:37:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:37:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:37:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:37:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:37:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:37:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:37:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:37:11 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:37:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:37:11 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:37:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:37:11 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:37:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:37:11 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:37:11 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:37:11 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:37:11 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:37:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:37:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:37:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:37:22 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:37:32 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:37:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-2134974389 in namespace infra-namespace
2022-04-04 18:37:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-2134974389 will have desired state: Ready
2022-04-04 18:38:58 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-2134974389 is in desired state: Ready
2022-04-04 18:38:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-2134974389 in namespace infra-namespace
2022-04-04 18:38:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-2134974389 will be ready
2022-04-04 18:39:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-2134974389 is ready
2022-04-04 18:39:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-2134974389 in namespace infra-namespace
2022-04-04 18:39:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-2134974389 will have desired state: Ready
2022-04-04 18:39:25 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-2134974389 is in desired state: Ready
2022-04-04 18:39:25 [main] [32mINFO [m [RecoveryIsolatedST:206] Running deleteKafkaBridgeDeployment with cluster recovery-cluster-2134974389
2022-04-04 18:39:25 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-2134974389-bridge will be deleted
2022-04-04 18:39:25 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-2134974389-bridge-585bf87585-mzhsx will be deleted
2022-04-04 18:39:30 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-2134974389-bridge-585bf87585-mzhsx deleted
2022-04-04 18:39:30 [main] [32mINFO [m [RecoveryIsolatedST:215] Waiting for deployment recovery-cluster-2134974389-bridge recovery
2022-04-04 18:39:30 [main] [32mINFO [m [DeploymentUtils:154] Waiting for Deployment recovery-cluster-2134974389-bridge-fed2889c-d5e4-43dd-aa48-9d5ed10ab474 recovery in namespace infra-namespace
2022-04-04 18:39:48 [main] [32mINFO [m [DeploymentUtils:157] Deployment recovery-cluster-2134974389-bridge was recovered
2022-04-04 18:39:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:39:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeDeploymentDeletion
2022-04-04 18:39:48 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-2134974389 in namespace infra-namespace
2022-04-04 18:39:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-2134974389 in namespace infra-namespace
2022-04-04 18:39:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-2134974389 in namespace infra-namespace
2022-04-04 18:40:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:40:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeDeploymentDeletion-FINISHED
2022-04-04 18:40:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:40:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:40:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaServiceDeletion-STARTED
2022-04-04 18:40:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:40:28 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:40:28 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:40:28 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:40:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:40:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:40:28 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:40:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:40:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:40:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:40:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:40:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:40:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:40:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:40:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:40:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:40:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:40:38 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:40:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:40:38 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:40:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:40:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:40:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:40:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:40:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:40:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:40:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:40:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:40:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:40:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:41:04 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:41:04 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:41:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:41:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:04 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:05 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:41:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:41:05 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:41:05 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:41:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:41:05 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:41:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:41:05 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:41:05 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:41:05 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:41:05 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:41:05 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:41:05 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:41:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:41:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:41:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:41:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:41:39 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:41:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1620550110 in namespace infra-namespace
2022-04-04 18:41:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1620550110 will have desired state: Ready
2022-04-04 18:43:05 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1620550110 is in desired state: Ready
2022-04-04 18:43:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1620550110 in namespace infra-namespace
2022-04-04 18:43:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1620550110 will be ready
2022-04-04 18:43:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1620550110 is ready
2022-04-04 18:43:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1620550110 in namespace infra-namespace
2022-04-04 18:43:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1620550110 will have desired state: Ready
2022-04-04 18:43:29 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1620550110 is in desired state: Ready
2022-04-04 18:43:29 [main] [32mINFO [m [RecoveryIsolatedST:115] Running deleteKafkaService with cluster recovery-cluster-1620550110
2022-04-04 18:43:29 [main] [32mINFO [m [RecoveryIsolatedST:122] Waiting for creation recovery-cluster-1620550110-kafka-bootstrap
2022-04-04 18:43:29 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-1620550110-kafka-bootstrap-ee1243ea-cc45-4f56-aca6-97c4615310fc in namespace infra-namespace will be recovered
2022-04-04 18:43:43 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-1620550110-kafka-bootstrap in namespace infra-namespace is recovered
2022-04-04 18:43:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:43:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaServiceDeletion
2022-04-04 18:43:43 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1620550110 in namespace infra-namespace
2022-04-04 18:43:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1620550110 in namespace infra-namespace
2022-04-04 18:43:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1620550110 in namespace infra-namespace
2022-04-04 18:44:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:44:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaServiceDeletion-FINISHED
2022-04-04 18:44:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:44:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:44:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperStatefulSetDeletion-STARTED
2022-04-04 18:44:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:44:44 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:44:44 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:44:44 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:44:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:44:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:44:44 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:44:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:44:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:44:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:44:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:44:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:44:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:44:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:44:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:44:54 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:44:54 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:44:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:44:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:45:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:45:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:45:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:45:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:45:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:45:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:45:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:45:19 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:45:19 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:45:19 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:45:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:45:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:45:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:45:20 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:45:20 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:45:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:45:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:45:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:45:53 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:46:03 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:46:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-101621446 in namespace infra-namespace
2022-04-04 18:46:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-101621446 will have desired state: Ready
2022-04-04 18:47:30 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-101621446 is in desired state: Ready
2022-04-04 18:47:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-101621446 in namespace infra-namespace
2022-04-04 18:47:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-101621446 will be ready
2022-04-04 18:47:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-101621446 is ready
2022-04-04 18:47:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-101621446 in namespace infra-namespace
2022-04-04 18:47:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-101621446 will have desired state: Ready
2022-04-04 18:47:51 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-101621446 is in desired state: Ready
2022-04-04 18:47:51 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-101621446-zookeeper will be deleted
2022-04-04 18:47:51 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-101621446-zookeeper-0 will be deleted
2022-04-04 18:48:01 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-101621446-zookeeper-0 deleted
2022-04-04 18:48:01 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-101621446-zookeeper-1 will be deleted
2022-04-04 18:48:01 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-101621446-zookeeper-1 deleted
2022-04-04 18:48:01 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-101621446-zookeeper-2 will be deleted
2022-04-04 18:48:01 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-101621446-zookeeper-2 deleted
2022-04-04 18:48:01 [main] [32mINFO [m [RecoveryIsolatedST:107] Waiting for recovery recovery-cluster-101621446-zookeeper
2022-04-04 18:48:01 [main] [32mINFO [m [StatefulSetUtils:73] Waiting for StatefulSet recovery-cluster-101621446-zookeeper-5623a536-34bc-4314-9db1-e6aef79da4ae recovery in namespace infra-namespace
2022-04-04 18:48:10 [main] [32mINFO [m [StatefulSetUtils:76] StatefulSet recovery-cluster-101621446-zookeeper was recovered
2022-04-04 18:48:10 [main] [32mINFO [m [StatefulSetUtils:39] Waiting for StatefulSet recovery-cluster-101621446-zookeeper to be ready
2022-04-04 18:48:34 [main] [32mINFO [m [StatefulSetUtils:44] Waiting for 3 Pod(s) of StatefulSet recovery-cluster-101621446-zookeeper to be ready
2022-04-04 18:48:45 [main] [32mINFO [m [StatefulSetUtils:47] StatefulSet recovery-cluster-101621446-zookeeper is ready
2022-04-04 18:48:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:48:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperStatefulSetDeletion
2022-04-04 18:48:45 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-101621446 in namespace infra-namespace
2022-04-04 18:48:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-101621446 in namespace infra-namespace
2022-04-04 18:48:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-101621446 in namespace infra-namespace
2022-04-04 18:49:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:49:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperStatefulSetDeletion-FINISHED
2022-04-04 18:49:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:49:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:49:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeMetricsConfigDeletion-STARTED
2022-04-04 18:49:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:49:35 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:49:35 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:49:35 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:49:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:49:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:49:35 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:49:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:49:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:49:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:49:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:49:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:49:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:49:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:49:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:49:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:49:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:49:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:45 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:49:45 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:45 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:49:55 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:49:55 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:50:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:50:10 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:50:10 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:50:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:50:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:50:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:50:11 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:50:11 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:50:11 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:50:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:50:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:50:30 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:50:40 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:50:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-2030827487 in namespace infra-namespace
2022-04-04 18:50:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-2030827487 will have desired state: Ready
2022-04-04 18:51:54 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-2030827487 is in desired state: Ready
2022-04-04 18:51:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-2030827487 in namespace infra-namespace
2022-04-04 18:51:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-2030827487 will be ready
2022-04-04 18:51:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-2030827487 is ready
2022-04-04 18:51:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-2030827487 in namespace infra-namespace
2022-04-04 18:51:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-2030827487 will have desired state: Ready
2022-04-04 18:52:13 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-2030827487 is in desired state: Ready
2022-04-04 18:52:13 [main] [32mINFO [m [RecoveryIsolatedST:234] Running deleteKafkaBridgeMetricsConfig with cluster recovery-cluster-2030827487
2022-04-04 18:52:13 [main] [32mINFO [m [RecoveryIsolatedST:239] Waiting for metric config recovery-cluster-2030827487-bridge-config re-creation
2022-04-04 18:52:13 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-2030827487-bridge-config-12af80b1-bbcf-4a3b-900a-129c456136a7 recovery in namespace infra-namespace
2022-04-04 18:52:18 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-2030827487-bridge-config was recovered
2022-04-04 18:52:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:52:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeMetricsConfigDeletion
2022-04-04 18:52:18 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-2030827487 in namespace infra-namespace
2022-04-04 18:52:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-2030827487 in namespace infra-namespace
2022-04-04 18:52:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-2030827487 in namespace infra-namespace
2022-04-04 18:52:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:52:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeMetricsConfigDeletion-FINISHED
2022-04-04 18:52:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:52:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:52:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperHeadlessServiceDeletion-STARTED
2022-04-04 18:52:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:52:58 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:52:58 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:52:58 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:52:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:52:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:52:58 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:52:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:52:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:52:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:52:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:53:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:53:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:53:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:53:08 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:53:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:53:08 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:53:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:53:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:53:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:53:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:53:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:53:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:53:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:53:34 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:53:34 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:53:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:53:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:53:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:53:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:53:35 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:53:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:53:35 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:53:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:53:35 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:53:35 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:53:35 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:53:35 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:53:35 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:53:35 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:53:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:53:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:54:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:54:08 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:54:18 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:54:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1275566756 in namespace infra-namespace
2022-04-04 18:54:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1275566756 will have desired state: Ready
2022-04-04 18:55:46 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1275566756 is in desired state: Ready
2022-04-04 18:55:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1275566756 in namespace infra-namespace
2022-04-04 18:55:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1275566756 will be ready
2022-04-04 18:55:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1275566756 is ready
2022-04-04 18:55:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1275566756 in namespace infra-namespace
2022-04-04 18:55:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1275566756 will have desired state: Ready
2022-04-04 18:56:14 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1275566756 is in desired state: Ready
2022-04-04 18:56:14 [main] [32mINFO [m [RecoveryIsolatedST:157] Running deleteKafkaHeadlessService with cluster recovery-cluster-1275566756
2022-04-04 18:56:14 [main] [32mINFO [m [RecoveryIsolatedST:164] Waiting for creation recovery-cluster-1275566756-zookeeper-nodes
2022-04-04 18:56:14 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-1275566756-zookeeper-nodes-1dd2aebd-9f09-4d1a-b99d-5e7480427cad in namespace infra-namespace will be recovered
2022-04-04 18:56:42 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-1275566756-zookeeper-nodes in namespace infra-namespace is recovered
2022-04-04 18:56:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:56:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperHeadlessServiceDeletion
2022-04-04 18:56:42 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1275566756 in namespace infra-namespace
2022-04-04 18:56:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1275566756 in namespace infra-namespace
2022-04-04 18:56:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1275566756 in namespace infra-namespace
2022-04-04 18:57:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:57:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperHeadlessServiceDeletion-FINISHED
2022-04-04 18:57:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 18:57:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 18:57:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaMetricsConfigDeletion-STARTED
2022-04-04 18:57:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 18:57:32 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 18:57:32 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 18:57:32 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 18:57:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 18:57:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 18:57:32 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:57:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:57:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:57:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:57:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:57:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:57:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:57:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:57:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:57:42 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:57:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:57:42 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:57:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:57:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:57:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:57:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:57:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:57:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:57:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:57:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:57:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:57:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:57:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:58:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 18:58:07 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 18:58:07 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 18:58:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 18:58:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:58:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 18:58:08 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 18:58:08 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:58:08 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 18:58:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 18:58:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 18:58:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 18:58:22 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 18:58:32 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 18:58:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1452655952 in namespace infra-namespace
2022-04-04 18:58:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1452655952 will have desired state: Ready
2022-04-04 18:59:55 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1452655952 is in desired state: Ready
2022-04-04 18:59:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1452655952 in namespace infra-namespace
2022-04-04 18:59:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1452655952 will be ready
2022-04-04 18:59:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1452655952 is ready
2022-04-04 18:59:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1452655952 in namespace infra-namespace
2022-04-04 18:59:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1452655952 will have desired state: Ready
2022-04-04 19:00:18 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1452655952 is in desired state: Ready
2022-04-04 19:00:18 [main] [32mINFO [m [RecoveryIsolatedST:171] Running deleteKafkaMetricsConfig with cluster recovery-cluster-1452655952
2022-04-04 19:00:18 [main] [32mINFO [m [RecoveryIsolatedST:185] Waiting for creation recovery-cluster-1452655952-kafka-config
2022-04-04 19:00:18 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-1452655952-kafka-config-8c07cabd-bb2e-4131-a9a1-2c5ad09342a2 recovery in namespace infra-namespace
2022-04-04 19:00:47 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-1452655952-kafka-config was recovered
2022-04-04 19:00:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:00:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaMetricsConfigDeletion
2022-04-04 19:00:47 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1452655952 in namespace infra-namespace
2022-04-04 19:00:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1452655952 in namespace infra-namespace
2022-04-04 19:00:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1452655952 in namespace infra-namespace
2022-04-04 19:01:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:01:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaMetricsConfigDeletion-FINISHED
2022-04-04 19:01:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:01:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:01:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperServiceDeletion-STARTED
2022-04-04 19:01:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:01:37 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 19:01:37 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 19:01:37 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 19:01:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:01:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 19:01:37 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:01:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:01:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:01:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:01:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:01:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:01:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:01:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:01:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:01:47 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:01:47 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:01:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:01:47 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:01:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:01:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:01:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:01:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:01:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:01:58 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:01:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:01:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:01:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:01:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:02:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:02:13 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 19:02:13 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 19:02:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 19:02:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 19:02:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:02:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:02:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:02:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:02:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:02:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:02:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:02:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:02:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:02:14 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 19:02:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:02:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:02:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:02:14 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:02:14 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:02:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:02:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 19:02:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 19:02:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 19:02:39 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 19:02:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-690924424 in namespace infra-namespace
2022-04-04 19:02:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-690924424 will have desired state: Ready
2022-04-04 19:04:08 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-690924424 is in desired state: Ready
2022-04-04 19:04:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-690924424 in namespace infra-namespace
2022-04-04 19:04:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-690924424 will be ready
2022-04-04 19:04:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-690924424 is ready
2022-04-04 19:04:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-690924424 in namespace infra-namespace
2022-04-04 19:04:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-690924424 will have desired state: Ready
2022-04-04 19:04:32 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-690924424 is in desired state: Ready
2022-04-04 19:04:32 [main] [32mINFO [m [RecoveryIsolatedST:129] Running deleteKafkaService with cluster recovery-cluster-690924424
2022-04-04 19:04:32 [main] [32mINFO [m [RecoveryIsolatedST:136] Waiting for creation recovery-cluster-690924424-zookeeper-client
2022-04-04 19:04:32 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-690924424-zookeeper-client-27a0032d-0d9c-410a-aa71-61c6483b89b4 in namespace infra-namespace will be recovered
2022-04-04 19:04:51 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-690924424-zookeeper-client in namespace infra-namespace is recovered
2022-04-04 19:04:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:04:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperServiceDeletion
2022-04-04 19:04:51 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-690924424 in namespace infra-namespace
2022-04-04 19:04:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-690924424 in namespace infra-namespace
2022-04-04 19:04:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-690924424 in namespace infra-namespace
2022-04-04 19:05:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:05:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperServiceDeletion-FINISHED
2022-04-04 19:05:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:05:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:05:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromImpossibleMemoryRequest-STARTED
2022-04-04 19:05:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:05:31 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 19:05:31 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 19:05:31 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 19:05:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:05:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 19:05:31 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:05:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:05:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:05:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:05:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:05:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:05:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:05:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:05:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:05:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:05:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:05:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:41 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:05:41 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:05:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:05:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:05:57 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 19:05:57 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 19:05:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 19:05:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 19:05:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:05:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:05:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:05:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:05:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:05:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:05:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:05:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:05:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:05:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 19:05:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 19:05:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:05:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 19:05:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:05:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 19:05:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:05:58 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 19:05:58 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:05:58 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 19:05:58 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:05:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:05:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 19:06:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 19:06:34 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 19:06:44 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 19:06:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-90317454 in namespace infra-namespace
2022-04-04 19:06:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-90317454 will have desired state: Ready
2022-04-04 19:08:08 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-90317454 is in desired state: Ready
2022-04-04 19:08:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-90317454 in namespace infra-namespace
2022-04-04 19:08:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-90317454 will be ready
2022-04-04 19:08:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-90317454 is ready
2022-04-04 19:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-90317454 in namespace infra-namespace
2022-04-04 19:08:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-90317454 will have desired state: Ready
2022-04-04 19:08:35 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-90317454 is in desired state: Ready
2022-04-04 19:08:35 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: recovery-cluster-90317454-kafka will be in pending phase
2022-04-04 19:08:47 [main] [32mINFO [m [PodUtils:306] Verify that all pods with prefix: recovery-cluster-90317454-kafka are stable in pending phase
2022-04-04 19:08:47 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 50
2022-04-04 19:08:48 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 49
2022-04-04 19:08:49 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 48
2022-04-04 19:08:50 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 47
2022-04-04 19:08:51 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 46
2022-04-04 19:08:52 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 45
2022-04-04 19:08:53 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 44
2022-04-04 19:08:54 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 43
2022-04-04 19:08:55 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 42
2022-04-04 19:08:56 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 41
2022-04-04 19:08:57 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 40
2022-04-04 19:08:58 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 39
2022-04-04 19:08:59 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 38
2022-04-04 19:09:00 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 37
2022-04-04 19:09:01 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 36
2022-04-04 19:09:02 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 35
2022-04-04 19:09:03 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 34
2022-04-04 19:09:04 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 33
2022-04-04 19:09:05 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 32
2022-04-04 19:09:06 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 31
2022-04-04 19:09:07 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 30
2022-04-04 19:09:08 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 29
2022-04-04 19:09:09 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 28
2022-04-04 19:09:10 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 27
2022-04-04 19:09:11 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 26
2022-04-04 19:09:12 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 25
2022-04-04 19:09:13 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 24
2022-04-04 19:09:14 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 23
2022-04-04 19:09:15 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 22
2022-04-04 19:09:16 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 21
2022-04-04 19:09:17 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 20
2022-04-04 19:09:18 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 19
2022-04-04 19:09:19 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 18
2022-04-04 19:09:20 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 17
2022-04-04 19:09:21 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 16
2022-04-04 19:09:22 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 15
2022-04-04 19:09:23 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 14
2022-04-04 19:09:24 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 13
2022-04-04 19:09:25 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 12
2022-04-04 19:09:26 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 11
2022-04-04 19:09:27 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 10
2022-04-04 19:09:28 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 9
2022-04-04 19:09:29 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 8
2022-04-04 19:09:30 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 7
2022-04-04 19:09:31 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 6
2022-04-04 19:09:32 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 5
2022-04-04 19:09:33 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 4
2022-04-04 19:09:34 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 3
2022-04-04 19:09:35 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 2
2022-04-04 19:09:36 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-90317454-kafka-1 is in the Pending state. Remaining seconds pod to be stable 1
2022-04-04 19:09:36 [main] [32mINFO [m [PodUtils:335] All pods are stable recovery-cluster-90317454-kafka-1
2022-04-04 19:09:36 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of recovery-cluster-90317454-kafka to be ready
2022-04-04 19:15:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-90317454 will have desired state: Ready
2022-04-04 19:15:49 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-90317454 is in desired state: Ready
2022-04-04 19:15:49 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: recovery-cluster-90317454 is ready
2022-04-04 19:15:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-90317454 will have desired state: Ready
2022-04-04 19:15:49 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-90317454 is in desired state: Ready
2022-04-04 19:15:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:15:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromImpossibleMemoryRequest
2022-04-04 19:15:49 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-90317454 in namespace infra-namespace
2022-04-04 19:15:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-90317454 in namespace infra-namespace
2022-04-04 19:15:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-90317454 in namespace infra-namespace
2022-04-04 19:16:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:16:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromImpossibleMemoryRequest-FINISHED
2022-04-04 19:16:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:16:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:16:39 [main] [32mINFO [m [ResourceManager:346] In context RecoveryIsolatedST is everything deleted.
2022-04-04 19:16:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 14, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 4,052.996 s - in io.strimzi.systemtest.operators.RecoveryIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
2022-04-04 19:16:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 19:17:04 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 19:17:04 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 19:17:04 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 19:17:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:17:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 19:17:04 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:17:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:17:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:14 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:17:14 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:17:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:17:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:17:40 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 19:17:40 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 19:17:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 19:17:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:17:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 19:17:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:17:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:17:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:17:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 19:18:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 19:18:10 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 19:18:20 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 19:18:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:18:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:19:46 [main] [32mINFO [m [ResourceManager:444] Kafka: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:19:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1670769365-1601814202 in namespace infra-namespace
2022-04-04 19:19:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1670769365-1601814202 will have desired state: Ready
2022-04-04 19:19:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1670769365-1601814202 is in desired state: Ready
2022-04-04 19:19:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-04 19:19:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-shared-kafka-clients will be ready
2022-04-04 19:19:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-shared-kafka-clients is ready
2022-04-04 19:19:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:19:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicChangingInSyncReplicasStatus-STARTED
2022-04-04 19:19:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:19:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1194884531-1869257504 in namespace infra-namespace
2022-04-04 19:19:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1194884531-1869257504 will have desired state: Ready
2022-04-04 19:19:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1194884531-1869257504 is in desired state: Ready
2022-04-04 19:19:50 [main] [32mINFO [m [CustomResourceStatusIsolatedST:481] Changing min.insync.replicas to random char
2022-04-04 19:19:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1194884531-1869257504 will have desired state: NotReady
2022-04-04 19:19:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1194884531-1869257504 is in desired state: NotReady
2022-04-04 19:19:51 [main] [32mINFO [m [CustomResourceStatusIsolatedST:488] Wait 245000 ms for next reconciliation
2022-04-04 19:23:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:23:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicChangingInSyncReplicasStatus
2022-04-04 19:23:56 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1194884531-1869257504 in namespace infra-namespace
2022-04-04 19:24:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:24:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicChangingInSyncReplicasStatus-FINISHED
2022-04-04 19:24:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:24:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:24:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatusNotReady-STARTED
2022-04-04 19:24:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:24:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace infra-namespace
2022-04-04 19:24:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef will have desired state: NotReady
2022-04-04 19:24:07 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: NotReady
2022-04-04 19:24:07 [main] [32mINFO [m [CustomResourceStatusIsolatedST:179] Checking status of deployed KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef
2022-04-04 19:24:07 [main] [32mINFO [m [CustomResourceStatusIsolatedST:181] KafkaUser Status: True
2022-04-04 19:24:07 [main] [32mINFO [m [CustomResourceStatusIsolatedST:182] KafkaUser Type: NotReady
2022-04-04 19:24:07 [main] [32mINFO [m [CustomResourceStatusIsolatedST:183] KafkaUser Message: Spec cannot be null
2022-04-04 19:24:07 [main] [32mINFO [m [CustomResourceStatusIsolatedST:184] KafkaUser Reason: InvalidResourceException
2022-04-04 19:24:07 [main] [32mINFO [m [CustomResourceStatusIsolatedST:186] KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: NotReady
2022-04-04 19:24:07 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef
2022-04-04 19:24:07 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef deleted
2022-04-04 19:24:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:24:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaUserStatusNotReady
2022-04-04 19:24:07 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace infra-namespace
2022-04-04 19:24:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:24:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatusNotReady-FINISHED
2022-04-04 19:24:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:24:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:24:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatus-STARTED
2022-04-04 19:24:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:24:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-80725459-480484875 in namespace infra-namespace
2022-04-04 19:24:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-80725459-480484875 will have desired state: Ready
2022-04-04 19:24:08 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-80725459-480484875 is in desired state: Ready
2022-04-04 19:24:08 [main] [32mINFO [m [CustomResourceStatusIsolatedST:162] Checking status of deployed KafkaUser
2022-04-04 19:24:08 [main] [32mINFO [m [CustomResourceStatusIsolatedST:164] KafkaUser Status: True
2022-04-04 19:24:08 [main] [32mINFO [m [CustomResourceStatusIsolatedST:165] KafkaUser Type: Ready
2022-04-04 19:24:08 [main] [32mINFO [m [CustomResourceStatusIsolatedST:167] KafkaUser is in desired state: Ready
2022-04-04 19:24:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:24:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaUserStatus
2022-04-04 19:24:08 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-80725459-480484875 in namespace infra-namespace
2022-04-04 19:24:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:24:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatus-FINISHED
2022-04-04 19:24:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:24:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:24:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatusNotReady-STARTED
2022-04-04 19:24:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:24:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1438572249-746981190 in namespace infra-namespace
2022-04-04 19:24:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1438572249-746981190 will have desired state: NotReady
2022-04-04 19:24:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1438572249-746981190 is in desired state: NotReady
2022-04-04 19:24:20 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-1438572249-746981190 deletion
2022-04-04 19:24:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:24:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicStatusNotReady
2022-04-04 19:24:20 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1438572249-746981190 in namespace infra-namespace
2022-04-04 19:24:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:24:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatusNotReady-FINISHED
2022-04-04 19:24:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:24:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:24:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaStatusCertificate-STARTED
2022-04-04 19:24:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:24:20 [main] [32mINFO [m [CustomResourceStatusIsolatedST:381] Check if KafkaStatus certificates are the same as secret certificates
2022-04-04 19:24:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:24:20 [main] [32mINFO [m [ResourceManager:346] In context testKafkaStatusCertificate is everything deleted.
2022-04-04 19:24:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:24:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaStatusCertificate-FINISHED
2022-04-04 19:24:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:24:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:24:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaBridgeStatus-STARTED
2022-04-04 19:24:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:24:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:24:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:24:41 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:24:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:24:41 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:24:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-04 19:25:12 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-04 19:25:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:26:08 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:26:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:26:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeStatus
2022-04-04 19:26:08 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:26:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:26:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaBridgeStatus-FINISHED
2022-04-04 19:26:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:26:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:26:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatus-STARTED
2022-04-04 19:26:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:26:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-960542306-1732680556 in namespace infra-namespace
2022-04-04 19:26:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-960542306-1732680556 will have desired state: Ready
2022-04-04 19:26:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-960542306-1732680556 is in desired state: Ready
2022-04-04 19:26:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-960542306-1732680556 will have desired state: Ready
2022-04-04 19:26:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-960542306-1732680556 is in desired state: Ready
2022-04-04 19:26:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:26:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicStatus
2022-04-04 19:26:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-960542306-1732680556 in namespace infra-namespace
2022-04-04 19:26:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:26:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatus-FINISHED
2022-04-04 19:26:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:26:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:26:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2Status-STARTED
2022-04-04 19:26:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:26:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-03dd0ea3 in namespace infra-namespace
2022-04-04 19:26:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-03dd0ea3 will have desired state: Ready
2022-04-04 19:27:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-03dd0ea3 is in desired state: Ready
2022-04-04 19:27:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-03dd0ea3-mirror-maker-2 in namespace infra-namespace
2022-04-04 19:27:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-03dd0ea3-mirror-maker-2 will have desired state: Ready
2022-04-04 19:28:50 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-03dd0ea3-mirror-maker-2 is in desired state: Ready
2022-04-04 19:28:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-03dd0ea3-mirror-maker-2 will have desired state: Ready
2022-04-04 19:28:50 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-03dd0ea3-mirror-maker-2 is in desired state: Ready
2022-04-04 19:28:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-03dd0ea3-mirror-maker-2 will have desired state: NotReady
2022-04-04 19:29:22 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-03dd0ea3-mirror-maker-2 is in desired state: NotReady
2022-04-04 19:29:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-03dd0ea3-mirror-maker-2 will have desired state: Ready
2022-04-04 19:30:59 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-03dd0ea3-mirror-maker-2 is in desired state: Ready
2022-04-04 19:31:18 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2 are stable
2022-04-04 19:31:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 19:31:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 19:31:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 19:31:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 19:31:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 19:31:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 19:31:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 19:31:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 19:31:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 19:31:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 19:31:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 19:31:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 19:31:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 19:31:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 19:31:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 19:31:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 19:31:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 19:31:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 19:31:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 19:31:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 19:31:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 19:31:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 19:31:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 19:31:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 19:31:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 19:31:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 19:31:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 19:31:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 19:31:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 19:31:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 19:31:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 19:31:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 19:31:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 19:31:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 19:31:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 19:31:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 19:31:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 19:31:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 19:31:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 19:31:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 19:31:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 19:31:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 19:32:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 19:32:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 19:32:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 19:32:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 19:32:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 19:32:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 19:32:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 19:32:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 19:32:07 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-03dd0ea3-mirror-maker-2-mirrormaker2-6c8fc4fb6f9pj4f
2022-04-04 19:32:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:32:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2Status
2022-04-04 19:32:07 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-03dd0ea3-mirror-maker-2 in namespace infra-namespace
2022-04-04 19:32:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-03dd0ea3 in namespace infra-namespace
2022-04-04 19:32:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:32:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2Status-FINISHED
2022-04-04 19:32:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:32:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:32:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectorWithoutClusterConfig-STARTED
2022-04-04 19:32:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:32:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-fc43189d in namespace infra-namespace
2022-04-04 19:32:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-fc43189d will have desired state: NotReady
2022-04-04 19:32:18 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-fc43189d is in desired state: NotReady
2022-04-04 19:32:18 [main] [32mINFO [m [KafkaConnectorUtils:98] KafkaConnector: my-cluster-fc43189d is not deleted yet, triggering force delete
2022-04-04 19:32:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:32:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectorWithoutClusterConfig
2022-04-04 19:32:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-fc43189d in namespace infra-namespace
2022-04-04 19:32:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:32:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectorWithoutClusterConfig-FINISHED
2022-04-04 19:32:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:32:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:32:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatusWrongBootstrap-STARTED
2022-04-04 19:32:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:32:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-32d9570a in namespace infra-namespace
2022-04-04 19:32:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-32d9570a will have desired state: Ready
2022-04-04 19:33:27 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-32d9570a is in desired state: Ready
2022-04-04 19:33:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-32d9570a will have desired state: Ready
2022-04-04 19:33:27 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-32d9570a is in desired state: Ready
2022-04-04 19:33:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-32d9570a will have desired state: NotReady
2022-04-04 19:33:58 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-32d9570a is in desired state: NotReady
2022-04-04 19:33:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-32d9570a will have desired state: Ready
2022-04-04 19:34:49 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-32d9570a is in desired state: Ready
2022-04-04 19:34:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:34:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMakerStatusWrongBootstrap
2022-04-04 19:34:49 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-32d9570a in namespace infra-namespace
2022-04-04 19:34:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:34:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatusWrongBootstrap-FINISHED
2022-04-04 19:34:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:34:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:34:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectAndConnectorStatus-STARTED
2022-04-04 19:34:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:34:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment custom-resource-status-cluster-name-scraper in namespace infra-namespace
2022-04-04 19:34:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: custom-resource-status-cluster-name-scraper will be ready
2022-04-04 19:35:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: custom-resource-status-cluster-name-scraper is ready
2022-04-04 19:35:01 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment custom-resource-status-cluster-name-scraper to be ready
2022-04-04 19:35:11 [main] [32mINFO [m [DeploymentUtils:197] Deployment custom-resource-status-cluster-name-scraper is ready
2022-04-04 19:35:11 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to custom-resource-status-cluster-name-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 19:35:11 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy custom-resource-status-cluster-name-allow in namespace infra-namespace
2022-04-04 19:35:11 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 19:35:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:35:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:36:21 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:36:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:36:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:36:22 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:36:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-04 19:36:53 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-04 19:36:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:38:34 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:38:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-04 19:38:35 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-04 19:38:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:38:36 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:38:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-04 19:38:37 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-04 19:38:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-04 19:38:38 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-04 19:38:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:38:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndConnectorStatus
2022-04-04 19:38:38 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:38:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy custom-resource-status-cluster-name-allow in namespace infra-namespace
2022-04-04 19:38:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:38:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment custom-resource-status-cluster-name-scraper in namespace infra-namespace
2022-04-04 19:39:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:39:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectAndConnectorStatus-FINISHED
2022-04-04 19:39:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:39:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:39:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2WrongBootstrap-STARTED
2022-04-04 19:39:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:39:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-893ac997-mirror-maker-2 in namespace infra-namespace
2022-04-04 19:39:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-893ac997-mirror-maker-2 will have desired state: NotReady
2022-04-04 19:39:48 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-893ac997-mirror-maker-2 is in desired state: NotReady
2022-04-04 19:39:48 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-893ac997-mirror-maker-2-mirrormaker2 is not deleted yet! Triggering force delete by cmd client!
2022-04-04 19:39:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:39:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2WrongBootstrap
2022-04-04 19:39:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-893ac997-mirror-maker-2 in namespace infra-namespace
2022-04-04 19:39:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:39:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2WrongBootstrap-FINISHED
2022-04-04 19:39:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:39:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:39:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicDecreaseStatus-STARTED
2022-04-04 19:39:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:39:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-275555577-149483969 in namespace infra-namespace
2022-04-04 19:39:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-275555577-149483969 will have desired state: Ready
2022-04-04 19:39:55 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-275555577-149483969 is in desired state: Ready
2022-04-04 19:39:55 [main] [32mINFO [m [CustomResourceStatusIsolatedST:457] Decreasing number of partitions to 1
2022-04-04 19:39:55 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-275555577-149483969
2022-04-04 19:39:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-275555577-149483969 will have desired state: NotReady
2022-04-04 19:39:56 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-275555577-149483969 is in desired state: NotReady
2022-04-04 19:39:56 [main] [32mINFO [m [CustomResourceStatusIsolatedST:465] Wait 245000 ms for next reconciliation
2022-04-04 19:44:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:44:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicDecreaseStatus
2022-04-04 19:44:01 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-275555577-149483969 in namespace infra-namespace
2022-04-04 19:44:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:44:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicDecreaseStatus-FINISHED
2022-04-04 19:44:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:44:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:44:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus-STARTED
2022-04-04 19:44:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:44:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-64599322-mirror-maker in namespace infra-namespace
2022-04-04 19:44:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-64599322-mirror-maker will have desired state: Ready
2022-04-04 19:45:21 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-64599322-mirror-maker is in desired state: Ready
2022-04-04 19:45:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-64599322-mirror-maker will have desired state: Ready
2022-04-04 19:45:21 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-64599322-mirror-maker is in desired state: Ready
2022-04-04 19:45:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-64599322-mirror-maker will have desired state: NotReady
2022-04-04 19:45:53 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-64599322-mirror-maker is in desired state: NotReady
2022-04-04 19:45:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-64599322-mirror-maker will have desired state: Ready
2022-04-04 19:47:25 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-64599322-mirror-maker is in desired state: Ready
2022-04-04 19:47:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:47:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMakerStatus
2022-04-04 19:47:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-64599322-mirror-maker in namespace infra-namespace
2022-04-04 19:47:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:47:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus-FINISHED
2022-04-04 19:47:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 19:47:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:47:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for CustomResourceStatusIsolatedST
2022-04-04 19:47:35 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1670769365-1601814202 in namespace infra-namespace
2022-04-04 19:47:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka custom-resource-status-cluster-name in namespace infra-namespace
2022-04-04 19:47:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-04 19:48:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,896.251 s - in io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-04 19:48:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 19:48:40 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 19:48:40 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 19:48:40 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 19:48:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 19:48:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 19:48:40 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:48:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:48:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:48:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:48:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:48:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:48:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:48:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:48:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:48:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:48:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 19:48:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:48:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:48:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:48:50 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 19:48:50 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:48:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:48:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:48:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:49:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:49:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 19:49:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 19:49:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-STARTED
2022-04-04 19:49:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 19:49:16 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating first-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-04 19:49:16 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@307794e7, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@445e4f1f, clusterOperatorName='first-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=first-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=first-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-04 19:49:16 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 19:49:16 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-co-cluster-test
2022-04-04 19:49:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-04 19:49:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:49:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:49:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:49:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:49:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:49:16 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:49:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:16 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:49:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-04 19:49:17 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:49:17 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:49:17 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:49:17 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:49:17 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-04 19:49:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:49:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: first-strimzi-cluster-operator will be ready
2022-04-04 19:49:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: first-strimzi-cluster-operator is ready
2022-04-04 19:49:39 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment first-strimzi-cluster-operator to be ready
2022-04-04 19:49:49 [main] [32mINFO [m [DeploymentUtils:197] Deployment first-strimzi-cluster-operator is ready
2022-04-04 19:49:49 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating second-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-04 19:49:49 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@307794e7, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@445e4f1f, clusterOperatorName='second-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=second-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=second-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-04 19:49:49 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 19:49:49 [main] [32mINFO [m [SetupClusterOperator:254] Environment for ClusterOperator was already prepared! Going to install it now.
2022-04-04 19:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 19:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 19:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 19:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 19:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 19:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:49:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-04 19:49:50 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 19:49:50 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 19:49:50 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 19:49:50 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:49:50 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-04 19:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 19:49:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-strimzi-cluster-operator will be ready
2022-04-04 19:50:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-strimzi-cluster-operator is ready
2022-04-04 19:50:27 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment second-strimzi-cluster-operator to be ready
2022-04-04 19:50:37 [main] [32mINFO [m [DeploymentUtils:197] Deployment second-strimzi-cluster-operator is ready
2022-04-04 19:50:37 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:171] Deploying Kafka with {app.kubernetes.io/operator=first-strimzi-cluster-operator} selector of first-strimzi-cluster-operator
2022-04-04 19:50:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-53dbaec2 in namespace multiple-co-cluster-test
2022-04-04 19:50:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-53dbaec2 will have desired state: Ready
2022-04-04 19:52:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-53dbaec2 is in desired state: Ready
2022-04-04 19:52:31 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:180] Removing CR selector from Kafka and increasing number of replicas to 4, new pod should not appear
2022-04-04 19:52:31 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:188] Creating KafkaRebalance when CC doesn't have label for CO, the KR should be ignored
2022-04-04 19:52:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-53dbaec2 in namespace multiple-co-cluster-test
2022-04-04 19:52:31 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-04 19:53:33 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-04 19:53:33 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:204] Checking if KafkaRebalance is still ignored, after the cluster stability wait
2022-04-04 19:53:33 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:209] Adding {app.kubernetes.io/operator=second-strimzi-cluster-operator} selector of second-strimzi-cluster-operator to Kafka
2022-04-04 19:53:33 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:212] Waiting for Kafka to scales pods to 4
2022-04-04 19:53:33 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-53dbaec2-kafka to be ready
2022-04-04 19:57:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-53dbaec2 will have desired state: Ready
2022-04-04 19:57:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-53dbaec2 is in desired state: Ready
2022-04-04 19:57:13 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-53dbaec2 is ready
2022-04-04 19:57:13 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-53dbaec2): ============================================================================
2022-04-04 19:57:13 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-53dbaec2): NotReady
2022-04-04 19:57:13 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-53dbaec2): ============================================================================
2022-04-04 19:57:13 [main] [32mINFO [m [KafkaRebalanceUtils:81] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-53dbaec2): Verifying that KafkaRebalance resource is in PendingProposal state
2022-04-04 19:57:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-53dbaec2 will have desired state: PendingProposal
2022-04-04 20:03:13 [main] [32mINFO [m [ResourceManager:414] KafkaRebalance status:

Conditions:

Pods with conditions and messages:

my-cluster-53dbaec2-cruise-control-846bfbb68f-7mgb6:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-53dbaec2-entity-operator-54b7bfc8d6-4n6pg:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-53dbaec2-kafka-0:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-53dbaec2-kafka-1:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-53dbaec2-kafka-2:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-53dbaec2-kafka-3:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-53dbaec2-zookeeper-0:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-53dbaec2-zookeeper-1:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-53dbaec2-zookeeper-2:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>
io.strimzi.test.WaitException: Timeout after 360000 ms waiting for KafkaRebalance: my-cluster-53dbaec2 will have desired state: PendingProposal
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:435)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:428)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaRebalanceUtils.waitForKafkaRebalanceCustomResourceState(KafkaRebalanceUtils.java:55)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaRebalanceUtils.doRebalancingProcess(KafkaRebalanceUtils.java:83)
	at io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs(MultipleClusterOperatorsIsolatedST.java:217)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 20:03:13 [main] [1;31mERROR[m [TestExecutionWatcher:28] MultipleClusterOperatorsIsolatedST - Exception Timeout after 360000 ms waiting for KafkaRebalance: my-cluster-53dbaec2 will have desired state: PendingProposal has been thrown in @Test. Going to collect logs from components.
2022-04-04 20:03:13 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace multiple-co-cluster-test
2022-04-04 20:03:13 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace multiple-co-cluster-test
2022-04-04 20:03:13 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace multiple-co-cluster-test
2022-04-04 20:03:17 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace multiple-co-cluster-test
2022-04-04 20:03:17 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace multiple-co-cluster-test
2022-04-04 20:03:17 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace multiple-co-cluster-test
2022-04-04 20:03:17 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace multiple-co-cluster-test
2022-04-04 20:03:17 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-04 20:03:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:03:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaCCAndRebalanceWithMultipleCOs
2022-04-04 20:03:17 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:03:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:03:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:03:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 20:03:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:03:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:03:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 20:03:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:03:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:28 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:03:28 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:28 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:28 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:03:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-04 20:03:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 20:03:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:03:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:03:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 20:03:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:03:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 20:03:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-04 20:03:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 20:03:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:38 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:38 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:03:38 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:03:38 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:38 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:03:38 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:03:38 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:03:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 20:03:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-04 20:03:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:03:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:03:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-53dbaec2 in namespace multiple-co-cluster-test
2022-04-04 20:03:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace multiple-co-cluster-test, for cruise control Kafka cluster my-cluster-53dbaec2
io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: GET at: https://192.168.49.2:8443/apis/kafka.strimzi.io/v1beta2/namespaces/multiple-co-cluster-test/kafkatopics. Message: Not Found.
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:683)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:662)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:613)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:556)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:519)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:503)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.listRequestHelper(BaseOperation.java:133)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:415)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:404)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:83)
	at io.strimzi.systemtest.resources.crd.KafkaResource.delete(KafkaResource.java:65)
	at io.strimzi.systemtest.resources.crd.KafkaResource.delete(KafkaResource.java:32)
	at io.strimzi.systemtest.resources.ResourceManager.deleteResource(ResourceManager.java:244)
	at io.strimzi.systemtest.resources.ResourceManager.lambda$createResource$1(ResourceManager.java:217)
	at io.strimzi.systemtest.resources.ResourceManager.lambda$deleteResources$3(ResourceManager.java:360)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.Vector$VectorSpliterator.forEachRemaining(Vector.java:1492)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.base/java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:746)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
2022-04-04 20:03:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-53dbaec2 in namespace multiple-co-cluster-test
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:03:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-FINISHED
2022-04-04 20:03:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:03:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:03:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testMultipleCOsInDifferentNamespaces-STARTED
2022-04-04 20:03:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:03:48 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding first-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding first-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating first-strimzi-cluster-operator in first-co-namespace namespace
2022-04-04 20:03:48 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@307794e7, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@416ce98e, clusterOperatorName='first-strimzi-cluster-operator', namespaceInstallTo='first-co-namespace', namespaceToWatch='*', bindingsNamespaces=[first-co-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=first-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=first-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-04 20:03:48 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:03:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: first-co-namespace
2022-04-04 20:03:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: first-co-namespace
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 20:03:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: first-co-namespace
2022-04-04 20:03:48 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace first-co-namespace
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:03:48 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace first-co-namespace
2022-04-04 20:03:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:03:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace first-co-namespace
2022-04-04 20:03:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:03:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace first-co-namespace
2022-04-04 20:03:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 20:03:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace first-co-namespace
2022-04-04 20:03:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace first-co-namespace
2022-04-04 20:03:49 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:03:49 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:03:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:03:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:03:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment first-strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 20:03:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: first-strimzi-cluster-operator will be ready
2022-04-04 20:04:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: first-strimzi-cluster-operator is ready
2022-04-04 20:04:22 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment first-strimzi-cluster-operator to be ready
2022-04-04 20:04:32 [main] [32mINFO [m [DeploymentUtils:197] Deployment first-strimzi-cluster-operator is ready
2022-04-04 20:04:32 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding second-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding second-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating second-strimzi-cluster-operator in second-co-namespace namespace
2022-04-04 20:04:32 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@307794e7, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@416ce98e, clusterOperatorName='second-strimzi-cluster-operator', namespaceInstallTo='second-co-namespace', namespaceToWatch='*', bindingsNamespaces=[second-co-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=second-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=second-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-04 20:04:32 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:04:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-co-namespace
2022-04-04 20:04:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-co-namespace
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:04:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:04:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 20:04:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-co-namespace
2022-04-04 20:04:33 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace second-co-namespace
2022-04-04 20:04:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:04:33 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace second-co-namespace
2022-04-04 20:04:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:04:33 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace second-co-namespace
2022-04-04 20:04:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:04:33 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace second-co-namespace
2022-04-04 20:04:33 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 20:04:33 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace second-co-namespace
2022-04-04 20:04:33 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-co-namespace
2022-04-04 20:04:33 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:04:33 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:04:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:04:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:04:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 20:04:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-strimzi-cluster-operator will be ready
2022-04-04 20:05:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-strimzi-cluster-operator is ready
2022-04-04 20:05:04 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment second-strimzi-cluster-operator to be ready
2022-04-04 20:05:14 [main] [32mINFO [m [DeploymentUtils:197] Deployment second-strimzi-cluster-operator is ready
2022-04-04 20:05:14 [main] [33mWARN [m [KubeClusterResource:151] Namespace multiple-co-cluster-test is already created, going to delete it
2022-04-04 20:05:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-co-cluster-test
2022-04-04 20:05:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-04 20:05:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-04 20:05:21 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:100] Deploying Kafka without CR selector
2022-04-04 20:05:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-157e9516 in namespace multiple-co-cluster-test
2022-04-04 20:05:21 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-157e9516 will have stable 0 replicas
2022-04-04 20:05:21 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-04 20:05:22 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-04 20:05:23 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-04 20:05:24 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-04 20:05:25 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-04 20:05:26 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-04 20:05:27 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-04 20:05:28 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-04 20:05:29 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-04 20:05:30 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-04 20:05:31 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-04 20:05:32 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-04 20:05:33 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-04 20:05:34 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-04 20:05:35 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-04 20:05:36 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-04 20:05:37 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-04 20:05:38 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-04 20:05:39 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-04 20:05:40 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-04 20:05:40 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-157e9516 has 0 replicas
2022-04-04 20:05:40 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:110] Adding {app.kubernetes.io/operator=first-strimzi-cluster-operator} selector of first-strimzi-cluster-operator into Kafka CR
2022-04-04 20:05:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-157e9516 will have desired state: Ready
2022-04-04 20:06:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-157e9516 is in desired state: Ready
2022-04-04 20:06:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-218215626-44656263 in namespace multiple-co-cluster-test
2022-04-04 20:06:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-157e9516 in namespace multiple-co-cluster-test
2022-04-04 20:06:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-218215626-44656263 will have desired state: Ready
2022-04-04 20:06:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-218215626-44656263 is in desired state: Ready
2022-04-04 20:06:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-157e9516 will have desired state: Ready
2022-04-04 20:08:08 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-157e9516 is in desired state: Ready
2022-04-04 20:08:08 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:130] Deploying KafkaConnector with file sink and CR selector - {app.kubernetes.io/operator=second-strimzi-cluster-operator} - different than selector in Kafka
2022-04-04 20:08:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-157e9516 in namespace multiple-co-cluster-test
2022-04-04 20:08:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-157e9516 will have desired state: Ready
2022-04-04 20:08:09 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-157e9516 is in desired state: Ready
2022-04-04 20:08:09 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace multiple-co-cluster-test
2022-04-04 20:08:09 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-04 20:08:10 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:hello-world-producer to finished
2022-04-04 20:08:18 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-157e9516-connect-657cdc4db8-kxkms
2022-04-04 20:08:19 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-157e9516-connect-657cdc4db8-kxkms
2022-04-04 20:08:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:08:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultipleCOsInDifferentNamespaces
2022-04-04 20:08:19 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:08:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:08:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:08:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:08:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:08:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding first-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:08:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding first-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:08:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 20:08:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:29 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:08:29 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment first-strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding second-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding second-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace first-co-namespace
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace first-co-namespace
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment second-strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-157e9516 in namespace multiple-co-cluster-test
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-218215626-44656263 in namespace multiple-co-cluster-test
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-157e9516 in namespace multiple-co-cluster-test
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-157e9516 in namespace multiple-co-cluster-test
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:39 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:39 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace multiple-co-cluster-test
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-co-namespace
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace second-co-namespace
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:39 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:08:49 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:49 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:49 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:08:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:08:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testMultipleCOsInDifferentNamespaces-FINISHED
2022-04-04 20:08:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:08:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:08:49 [main] [32mINFO [m [ResourceManager:346] In context MultipleClusterOperatorsIsolatedST is everything deleted.
2022-04-04 20:08:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 1,234.169 s <<< FAILURE! - in io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs(ExtensionContext)  Time elapsed: 871.51 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 360000 ms waiting for KafkaRebalance: my-cluster-53dbaec2 will have desired state: PendingProposal
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:435)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:428)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaRebalanceUtils.waitForKafkaRebalanceCustomResourceState(KafkaRebalanceUtils.java:55)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaRebalanceUtils.doRebalancingProcess(KafkaRebalanceUtils.java:83)
	at io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs(MultipleClusterOperatorsIsolatedST.java:217)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
2022-04-04 20:08:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:09:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:09:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorsWhenRackAwarenessIsEnabled-STARTED
2022-04-04 20:09:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:09:14 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:09:14 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:09:14 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:09:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:09:14 [main] [32mINFO [m [ResourceManager:346] In context JUnit Jupiter is everything deleted.
2022-04-04 20:09:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:09:56 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@307794e7, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=NAMESPACE, testClassName='null', testMethodName='null'}
2022-04-04 20:09:56 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:09:56 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:09:56 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:09:56 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 20:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 20:09:56 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 20:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 20:09:56 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-04 20:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 20:09:56 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-04 20:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 20:09:56 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-04 20:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 20:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 20:09:57 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/020-Role-strimzi-cluster-operator-role14678200345255433319.yaml in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 20:09:57 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/021-Role-strimzi-cluster-operator-role11462809133451014798.yaml in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-04 20:09:57 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/030-Role-strimzi-kafka-broker2150843322857203828.yaml in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-04 20:09:57 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/031-Role-strimzi-entity-operator14840353062428573646.yaml in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-04 20:09:57 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/033-Role-strimzi-kafka-client4776019847510139768.yaml in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-04 20:09:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator10113225409015686593.yaml in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-04 20:09:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation16927029257980494306.yaml in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-04 20:09:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator14254542184525343190.yaml in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-04 20:09:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation7879667336869445065.yaml in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:09:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:10:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:10:17 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:10:27 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:10:27 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:99] Deploying Kafka: my-cluster-41ae3101, which should not be deployed and error should be present in CR status message
2022-04-04 20:10:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-41ae3101 in namespace infra-namespace
2022-04-04 20:11:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-41ae3101-kafka-clients in namespace infra-namespace
2022-04-04 20:11:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-41ae3101-kafka-clients will be ready
2022-04-04 20:11:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-41ae3101-kafka-clients is ready
2022-04-04 20:11:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-41ae3101-scraper in namespace infra-namespace
2022-04-04 20:11:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-41ae3101-scraper will be ready
2022-04-04 20:11:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-41ae3101-scraper is ready
2022-04-04 20:11:03 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-41ae3101-scraper to be ready
2022-04-04 20:11:13 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-41ae3101-scraper is ready
2022-04-04 20:11:13 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-41ae3101-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 20:11:13 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-41ae3101-allow in namespace infra-namespace
2022-04-04 20:11:13 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 20:11:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-41ae3101 in namespace infra-namespace
2022-04-04 20:11:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:11:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCRBDeletionErrorsWhenRackAwarenessIsEnabled
2022-04-04 20:11:14 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-41ae3101-scraper in namespace infra-namespace
2022-04-04 20:11:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-41ae3101-kafka-clients in namespace infra-namespace
2022-04-04 20:11:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-41ae3101 in namespace infra-namespace
2022-04-04 20:11:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-41ae3101 in namespace infra-namespace
2022-04-04 20:11:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-41ae3101-allow in namespace infra-namespace
2022-04-04 20:12:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:12:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorsWhenRackAwarenessIsEnabled-FINISHED
2022-04-04 20:12:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:12:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:12:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled-STARTED
2022-04-04 20:12:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:12:04 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:12:04 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:12:04 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:12:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:12:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:12:04 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:12:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:12:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 20:12:04 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 20:12:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:12:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 20:12:04 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 20:12:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:12:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 20:12:04 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 20:12:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:12:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 20:12:05 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 20:12:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:12:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:12:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 20:12:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:12:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 20:12:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:15 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:12:40 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@307794e7, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=NAMESPACE, testClassName='null', testMethodName='null'}
2022-04-04 20:12:40 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:12:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:12:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:12:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:12:40 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 20:12:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 20:12:40 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 20:12:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 20:12:40 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-04 20:12:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 20:12:40 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-04 20:12:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 20:12:40 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-04 20:12:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 20:12:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 20:12:41 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/020-Role-strimzi-cluster-operator-role10125238765440367351.yaml in namespace infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-04 20:12:41 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/021-Role-strimzi-cluster-operator-role12570538650734362928.yaml in namespace infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-04 20:12:41 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/030-Role-strimzi-kafka-broker5297852507498068327.yaml in namespace infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-04 20:12:41 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/031-Role-strimzi-entity-operator1150429547524488613.yaml in namespace infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-04 20:12:41 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/033-Role-strimzi-kafka-client11740940810494227972.yaml in namespace infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-04 20:12:41 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator12101880208249261248.yaml in namespace infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:12:41 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-04 20:12:41 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation17439972792316409739.yaml in namespace infra-namespace
2022-04-04 20:12:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:12:42 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-04 20:12:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator12210561353981575636.yaml in namespace infra-namespace
2022-04-04 20:12:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:12:42 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-04 20:12:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation7001421356975424999.yaml in namespace infra-namespace
2022-04-04 20:12:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:12:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:12:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:13:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:13:11 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:13:21 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:13:21 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:63] Deploying Kafka: my-cluster-41904458, which should be deployed even the CRBs are not present
2022-04-04 20:13:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-41904458 in namespace infra-namespace
2022-04-04 20:13:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-41904458 will have desired state: Ready
2022-04-04 20:14:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-41904458 is in desired state: Ready
2022-04-04 20:14:45 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:67] CO log should contain some information about ignoring forbidden access to CRB for Kafka
2022-04-04 20:14:45 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:71] Deploying KafkaConnect: my-cluster-41904458 without rack awareness, the CR should be deployed without error
2022-04-04 20:14:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-41904458 in namespace infra-namespace
2022-04-04 20:14:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-41904458 will have desired state: Ready
2022-04-04 20:15:49 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-41904458 is in desired state: Ready
2022-04-04 20:15:49 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:74] CO log should contain some information about ignoring forbidden access to CRB for KafkaConnect
2022-04-04 20:15:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:15:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled
2022-04-04 20:15:49 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-41904458 in namespace infra-namespace
2022-04-04 20:15:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-41904458 in namespace infra-namespace
2022-04-04 20:15:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:15:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled-FINISHED
2022-04-04 20:15:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:15:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:15:59 [main] [32mINFO [m [ResourceManager:346] In context ClusterOperatorRbacIsolatedST is everything deleted.
2022-04-04 20:15:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 429.754 s - in io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
2022-04-04 20:15:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:16:24 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:16:24 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:16:24 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:16:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:16:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:16:24 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:16:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:16:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 20:16:24 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 20:16:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 20:16:24 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 20:16:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:16:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 20:16:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-04 20:16:24 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-04 20:16:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:16:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:16:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-04 20:16:24 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:16:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:34 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:16:34 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-04 20:16:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:16:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-04 20:16:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:16:54 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:17:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:17:10 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_KAFKA_BRIDGE_SERVICE_LABELS, value=app=bar, valueFrom=null, additionalProperties={}), EnvVar(name=STRIMZI_CUSTOM_KAFKA_BRIDGE_SERVICE_ANNOTATIONS, value=bar=app, valueFrom=null, additionalProperties={})]
2022-04-04 20:17:10 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:17:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:17:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:17:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:17:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:17:11 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:17:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:17:11 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:17:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:17:11 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:17:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:17:11 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:17:11 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:17:11 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:17:11 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:17:11 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:17:11 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:17:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:17:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:17:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:17:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:17:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:17:27 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:17:37 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:17:37 [main] [32mINFO [m [HttpBridgeIsolatedST:434] Deploy Kafka and KafkaBridge before tests
2022-04-04 20:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-cluster-name in namespace infra-namespace
2022-04-04 20:17:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-cluster-name will have desired state: Ready
2022-04-04 20:18:53 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-cluster-name is in desired state: Ready
2022-04-04 20:18:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-04 20:18:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-shared-kafka-clients will be ready
2022-04-04 20:18:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-shared-kafka-clients is ready
2022-04-04 20:18:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-cluster-name in namespace infra-namespace
2022-04-04 20:18:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-cluster-name will have desired state: Ready
2022-04-04 20:19:18 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-cluster-name is in desired state: Ready
2022-04-04 20:19:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:19:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testReceiveSimpleMessage-STARTED
2022-04-04 20:19:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:19:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1234949578-714988558 in namespace infra-namespace
2022-04-04 20:19:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1234949578-714988558 will have desired state: Ready
2022-04-04 20:19:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1234949578-714988558 is in desired state: Ready
2022-04-04 20:19:19 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:19:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-33781980 in namespace infra-namespace
2022-04-04 20:19:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-33781980 will be in active state
2022-04-04 20:19:20 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:19:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1226388248 in namespace infra-namespace
2022-04-04 20:19:20 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1226388248 will be in active state
2022-04-04 20:19:21 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-1226388248 and consumer consumer-33781980 finish
2022-04-04 20:19:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:19:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessage
2022-04-04 20:19:37 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-33781980 in namespace infra-namespace
2022-04-04 20:19:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job producer-1226388248 in namespace infra-namespace
2022-04-04 20:19:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1234949578-714988558 in namespace infra-namespace
2022-04-04 20:19:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:19:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testReceiveSimpleMessage-FINISHED
2022-04-04 20:19:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:19:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:19:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-04 20:19:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:19:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge example-bridge in namespace infra-namespace
2022-04-04 20:19:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: example-bridge will have desired state: Ready
2022-04-04 20:20:13 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: example-bridge is in desired state: Ready
2022-04-04 20:20:13 [main] [32mINFO [m [HttpBridgeIsolatedST:351] Adding label to KafkaBridge resource, the CR should be recreated
2022-04-04 20:20:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: example-bridge-bridge will be ready
2022-04-04 20:20:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: example-bridge-bridge is ready
2022-04-04 20:20:13 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment example-bridge-bridge to be ready
2022-04-04 20:20:57 [main] [32mINFO [m [DeploymentUtils:197] Deployment example-bridge-bridge is ready
2022-04-04 20:20:57 [main] [32mINFO [m [HttpBridgeIsolatedST:358] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-04 20:20:57 [main] [32mINFO [m [HttpBridgeIsolatedST:363] Changing deployment strategy to ROLLING_UPDATE
2022-04-04 20:20:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: example-bridge will have desired state: Ready
2022-04-04 20:20:57 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: example-bridge is in desired state: Ready
2022-04-04 20:20:57 [main] [32mINFO [m [HttpBridgeIsolatedST:368] Adding another label to KafkaBridge resource, pods should be rolled
2022-04-04 20:20:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: example-bridge-bridge will be ready
2022-04-04 20:20:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: example-bridge-bridge is ready
2022-04-04 20:20:57 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment example-bridge-bridge to be ready
2022-04-04 20:21:27 [main] [32mINFO [m [DeploymentUtils:197] Deployment example-bridge-bridge is ready
2022-04-04 20:21:27 [main] [32mINFO [m [HttpBridgeIsolatedST:372] Checking that observed gen. higher (rolling update) and label is changed
2022-04-04 20:21:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:21:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-04 20:21:27 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge example-bridge in namespace infra-namespace
2022-04-04 20:21:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:21:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-04 20:21:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:21:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:21:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeToZero-STARTED
2022-04-04 20:21:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:21:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge scaling-bridge-down in namespace infra-namespace
2022-04-04 20:21:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: scaling-bridge-down will have desired state: Ready
2022-04-04 20:21:55 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: scaling-bridge-down is in desired state: Ready
2022-04-04 20:21:55 [main] [32mINFO [m [HttpBridgeIsolatedST:285] Scaling KafkaBridge to zero replicas
2022-04-04 20:21:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-cluster-name will have desired state: Ready
2022-04-04 20:21:55 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-cluster-name is in desired state: Ready
2022-04-04 20:22:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:22:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleBridgeToZero
2022-04-04 20:22:07 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge scaling-bridge-down in namespace infra-namespace
2022-04-04 20:22:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:22:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeToZero-FINISHED
2022-04-04 20:22:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:22:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:22:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testDiscoveryAnnotation-STARTED
2022-04-04 20:22:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:22:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:22:17 [main] [32mINFO [m [ResourceManager:346] In context testDiscoveryAnnotation is everything deleted.
2022-04-04 20:22:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:22:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testDiscoveryAnnotation-FINISHED
2022-04-04 20:22:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:22:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:22:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomBridgeLabelsAreProperlySet-STARTED
2022-04-04 20:22:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:22:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge bridge-my-cluster-9ad86177 in namespace infra-namespace
2022-04-04 20:22:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: bridge-my-cluster-9ad86177 will have desired state: Ready
2022-04-04 20:22:37 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: bridge-my-cluster-9ad86177 is in desired state: Ready
2022-04-04 20:22:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:22:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomBridgeLabelsAreProperlySet
2022-04-04 20:22:37 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge bridge-my-cluster-9ad86177 in namespace infra-namespace
2022-04-04 20:22:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:22:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomBridgeLabelsAreProperlySet-FINISHED
2022-04-04 20:22:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:22:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:22:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeSubresource-STARTED
2022-04-04 20:22:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:22:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge scaling-bridge-up in namespace infra-namespace
2022-04-04 20:22:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: scaling-bridge-up will have desired state: Ready
2022-04-04 20:23:10 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: scaling-bridge-up is in desired state: Ready
2022-04-04 20:23:10 [main] [32mINFO [m [HttpBridgeIsolatedST:312] -------> Scaling KafkaBridge subresource <-------
2022-04-04 20:23:10 [main] [32mINFO [m [HttpBridgeIsolatedST:313] Scaling subresource replicas to 4
2022-04-04 20:23:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: scaling-bridge-up-bridge will be ready
2022-04-04 20:23:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: scaling-bridge-up-bridge is ready
2022-04-04 20:23:10 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment scaling-bridge-up-bridge to be ready
2022-04-04 20:23:46 [main] [32mINFO [m [DeploymentUtils:197] Deployment scaling-bridge-up-bridge is ready
2022-04-04 20:23:46 [main] [32mINFO [m [HttpBridgeIsolatedST:317] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-04 20:23:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:23:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleBridgeSubresource
2022-04-04 20:23:46 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge scaling-bridge-up in namespace infra-namespace
2022-04-04 20:23:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:23:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeSubresource-FINISHED
2022-04-04 20:23:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:23:56 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:23:56 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-04 20:23:56 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:23:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge custom-bridge in namespace infra-namespace
2022-04-04 20:23:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-bridge will have desired state: Ready
2022-04-04 20:24:29 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-bridge is in desired state: Ready
2022-04-04 20:24:29 [main] [32mINFO [m [HttpBridgeIsolatedST:225] Verify values before update
2022-04-04 20:24:29 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix custom-bridge-bridge in pod name
2022-04-04 20:24:29 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container custom-bridge-bridge
2022-04-04 20:24:29 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name custom-bridge-bridge
2022-04-04 20:24:29 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container custom-bridge-bridge
2022-04-04 20:24:29 [main] [32mINFO [m [HttpBridgeIsolatedST:230] Check if actual env variable KAFKA_BRIDGE_PRODUCER_CONFIG has different value than test.value
2022-04-04 20:24:29 [main] [32mINFO [m [HttpBridgeIsolatedST:236] Updating values in Bridge container
2022-04-04 20:24:29 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment custom-bridge-bridge rolling update
2022-04-04 20:25:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: custom-bridge-bridge will be ready
2022-04-04 20:25:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: custom-bridge-bridge is ready
2022-04-04 20:25:29 [main] [32mINFO [m [DeploymentUtils:141] Deployment custom-bridge-bridge rolling update finished
2022-04-04 20:25:29 [main] [32mINFO [m [HttpBridgeIsolatedST:253] Verify values after update
2022-04-04 20:25:29 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix custom-bridge-bridge in pod name
2022-04-04 20:25:29 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container custom-bridge-bridge
2022-04-04 20:25:29 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name custom-bridge-bridge
2022-04-04 20:25:29 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container custom-bridge-bridge
2022-04-04 20:25:29 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name custom-bridge-bridge
2022-04-04 20:25:29 [main] [32mINFO [m [AbstractST:194] Testing configuration for container custom-bridge-bridge
2022-04-04 20:25:29 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name custom-bridge-bridge
2022-04-04 20:25:29 [main] [32mINFO [m [AbstractST:194] Testing configuration for container custom-bridge-bridge
2022-04-04 20:25:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:25:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-04 20:25:29 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge custom-bridge in namespace infra-namespace
2022-04-04 20:25:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:25:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-04 20:25:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:25:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:25:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testSendSimpleMessage-STARTED
2022-04-04 20:25:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:25:39 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:25:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1732473963-808142068 in namespace infra-namespace
2022-04-04 20:25:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1732473963-808142068 will have desired state: Ready
2022-04-04 20:25:40 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1732473963-808142068 is in desired state: Ready
2022-04-04 20:25:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1663088005 in namespace infra-namespace
2022-04-04 20:25:40 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1663088005 will be in active state
2022-04-04 20:25:41 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-1663088005 to finished
2022-04-04 20:27:30 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:27:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-94183718 in namespace infra-namespace
2022-04-04 20:27:30 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-94183718 will be in active state
2022-04-04 20:27:31 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-94183718 to finished
2022-04-04 20:27:41 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type my-bridge
2022-04-04 20:27:41 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-04 20:27:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:27:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessage
2022-04-04 20:27:41 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-1663088005 in namespace infra-namespace
2022-04-04 20:27:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1732473963-808142068 in namespace infra-namespace
2022-04-04 20:27:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job consumer-94183718 in namespace infra-namespace
2022-04-04 20:27:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:27:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testSendSimpleMessage-FINISHED
2022-04-04 20:27:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:27:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:27:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeIsolatedST
2022-04-04 20:27:51 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-04 20:27:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-cluster-name in namespace infra-namespace
2022-04-04 20:27:51 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-cluster-name in namespace infra-namespace
2022-04-04 20:28:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 751.864 s - in io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-04 20:28:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:28:56 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:28:56 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:28:56 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:28:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:28:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:28:56 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:28:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:28:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:28:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:28:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:28:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:28:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:28:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:28:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:28:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:29:06 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:29:06 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:29:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:29:06 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:29:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:29:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:29:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:29:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:29:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:29:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:29:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:29:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:29:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:29:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:29:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:29:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:29:42 [main] [32mINFO [m [HelmChartIsolatedST:67] Creating resources before the test class
2022-04-04 20:29:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:29:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:29:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kube-system
2022-04-04 20:29:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace kube-system apply -f -
2022-04-04 20:29:42 [main] [32mINFO [m [Exec:417] Input: apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
2022-04-04 20:29:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:29:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:29:42 [main] [32mINFO [m [HelmClient:44] Installing helm-chart strimzi-systemtests
2022-04-04 20:30:24 [main] [32mINFO [m [Exec:417] Command: helm install strimzi-systemtests --set defaultImageRegistry=quay.io,defaultImageRepository=strimzi,fullReconciliationIntervalMs=30000,kafkaBridge.image.tag=latest,resources.limits.memory=512Mi,kafkaBridge.image.repository=strimzi,featureGates=,image.imagePullPolicy=Always,watchAnyNamespace=false,resources.requests.memory=512Mi,operationTimeoutMs=300000,resources.limits.cpu=1000m,logLevelOverride=DEBUG,defaultImageTag=latest,resources.requests.cpu=200m,kafkaBridge.image.registry=quay.io --timeout 120s --debug /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/helm-charts/helm3/strimzi-kafka-operator --namespace infra-namespace --wait
2022-04-04 20:30:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:30:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:30:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:30:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:30:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.HelmChartIsolatedST.testStrimziComponentsViaHelmChart-STARTED
2022-04-04 20:30:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:30:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d228fb3a-kafka-clients in namespace infra-namespace
2022-04-04 20:30:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d228fb3a-kafka-clients will be ready
2022-04-04 20:30:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d228fb3a-kafka-clients is ready
2022-04-04 20:30:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d228fb3a in namespace infra-namespace
2022-04-04 20:30:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d228fb3a will have desired state: Ready
2022-04-04 20:31:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d228fb3a is in desired state: Ready
2022-04-04 20:31:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d228fb3a-scraper in namespace infra-namespace
2022-04-04 20:31:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d228fb3a-scraper will be ready
2022-04-04 20:31:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d228fb3a-scraper is ready
2022-04-04 20:31:59 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-d228fb3a-scraper to be ready
2022-04-04 20:32:10 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-d228fb3a-scraper is ready
2022-04-04 20:32:10 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-d228fb3a-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 20:32:10 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-d228fb3a-allow in namespace infra-namespace
2022-04-04 20:32:10 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 20:32:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-452717466-747156591 in namespace infra-namespace
2022-04-04 20:32:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-d228fb3a in namespace infra-namespace
2022-04-04 20:32:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-d228fb3a in namespace infra-namespace
2022-04-04 20:32:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-452717466-747156591 will have desired state: Ready
2022-04-04 20:32:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-452717466-747156591 is in desired state: Ready
2022-04-04 20:32:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-d228fb3a will have desired state: Ready
2022-04-04 20:33:16 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-d228fb3a is in desired state: Ready
2022-04-04 20:33:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-d228fb3a will have desired state: Ready
2022-04-04 20:33:16 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-d228fb3a is in desired state: Ready
2022-04-04 20:33:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-d228fb3a in namespace infra-namespace
2022-04-04 20:33:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-d228fb3a will have desired state: Ready
2022-04-04 20:33:17 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-d228fb3a is in desired state: Ready
2022-04-04 20:33:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:33:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziComponentsViaHelmChart
2022-04-04 20:33:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-d228fb3a in namespace infra-namespace
2022-04-04 20:33:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-d228fb3a in namespace infra-namespace
2022-04-04 20:33:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d228fb3a-scraper in namespace infra-namespace
2022-04-04 20:33:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d228fb3a in namespace infra-namespace
2022-04-04 20:33:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d228fb3a-kafka-clients in namespace infra-namespace
2022-04-04 20:33:27 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-452717466-747156591 in namespace infra-namespace
2022-04-04 20:33:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-d228fb3a in namespace infra-namespace
2022-04-04 20:33:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-d228fb3a-allow in namespace infra-namespace
2022-04-04 20:34:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:34:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.HelmChartIsolatedST.testStrimziComponentsViaHelmChart-FINISHED
2022-04-04 20:34:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:34:07 [main] [32mINFO [m [HelmClient:71] Deleting helm-chart:strimzi-systemtests in namespace:infra-namespace
2022-04-04 20:34:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:34:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HelmChartIsolatedST
2022-04-04 20:34:08 [main] [32mINFO [m [HelmClient:71] Deleting helm-chart:strimzi-systemtests in namespace:infra-namespace
2022-04-04 20:34:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:34:08 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 20:34:08 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:34:08 [main] [33mWARN [m [KubeClusterResource:151] Namespace infra-namespace is already created, going to delete it
2022-04-04 20:34:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:34:19 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:34:19 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:34:19 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:34:19 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:34:19 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:34:19 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:34:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:34:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:34:57 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:35:08 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 396.853 s - in io.strimzi.systemtest.specific.HelmChartIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.SpecificIsolatedST
2022-04-04 20:35:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:35:33 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:35:33 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:35:33 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:35:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:35:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:35:33 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:35:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:35:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:35:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:35:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:35:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:35:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:35:43 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:35:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:35:43 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:35:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:35:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:35:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:35:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:35:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:35:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:35:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:35:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:35:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:35:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:35:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:35:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:35:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:35:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:36:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:36:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:36:18 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 20:36:18 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:36:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:36:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:36:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:36:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:36:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:36:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:36:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:36:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:36:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:36:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:36:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:36:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:36:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:36:19 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:36:19 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:36:19 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:36:19 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:36:19 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:36:19 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:36:19 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:36:19 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:36:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:36:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:36:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:36:57 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:37:07 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:37:07 [main] [32mINFO [m [SpecificIsolatedST:508] 0.21.4
2022-04-04 20:37:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:37:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAware-STARTED
2022-04-04 20:37:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:37:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c1ff7d3c in namespace infra-namespace
2022-04-04 20:37:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c1ff7d3c will have desired state: Ready
2022-04-04 20:38:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c1ff7d3c is in desired state: Ready
2022-04-04 20:38:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-c1ff7d3c-kafka-0 -- /bin/bash -c cat /opt/kafka/init/rack.id
2022-04-04 20:38:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:38:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-c1ff7d3c-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties | grep broker.rack
2022-04-04 20:38:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:38:14 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 20:38:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace infra-namespace
2022-04-04 20:38:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-04 20:38:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace infra-namespace
2022-04-04 20:38:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-04 20:38:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:38:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRackAware
2022-04-04 20:38:15 [main] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace infra-namespace
2022-04-04 20:38:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace infra-namespace
2022-04-04 20:38:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c1ff7d3c in namespace infra-namespace
2022-04-04 20:38:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:38:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAware-FINISHED
2022-04-04 20:38:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:38:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:38:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAwareConnectWrongDeployment-STARTED
2022-04-04 20:38:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:38:25 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:38:25 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:38:25 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:38:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:38:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:38:25 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:38:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:38:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:38:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:38:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:38:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:38:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:38:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:38:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:38:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:38:35 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:38:35 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:38:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:38:35 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:38:35 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:38:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:38:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:38:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:38:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:38:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:38:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:38:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:38:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:38:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:38:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:38:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:39:00 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@307794e7, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=30000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-04 20:39:00 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:39:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:39:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:39:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:39:01 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:39:01 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:39:01 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:39:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:39:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:39:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:39:16 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:39:27 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:39:27 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-04 20:39:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:39:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:39:37 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-04 20:39:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5dbe5d04 in namespace infra-namespace
2022-04-04 20:39:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5dbe5d04 will have desired state: Ready
2022-04-04 20:41:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5dbe5d04 is in desired state: Ready
2022-04-04 20:41:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5dbe5d04-kafka-clients in namespace infra-namespace
2022-04-04 20:41:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5dbe5d04-kafka-clients will be ready
2022-04-04 20:41:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5dbe5d04-kafka-clients is ready
2022-04-04 20:41:02 [main] [32mINFO [m [SpecificIsolatedST:196] Deploy KafkaConnect with wrong rack-aware topology key: wrong-key
2022-04-04 20:41:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5dbe5d04-scraper in namespace infra-namespace
2022-04-04 20:41:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5dbe5d04-scraper will be ready
2022-04-04 20:41:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5dbe5d04-scraper is ready
2022-04-04 20:41:04 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-5dbe5d04-scraper to be ready
2022-04-04 20:41:14 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-5dbe5d04-scraper is ready
2022-04-04 20:41:14 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-5dbe5d04-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 20:41:14 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-5dbe5d04-allow in namespace infra-namespace
2022-04-04 20:41:14 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 20:41:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-5dbe5d04 in namespace infra-namespace
2022-04-04 20:41:14 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-5dbe5d04-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 20:41:14 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-5dbe5d04-allow in namespace infra-namespace
2022-04-04 20:41:14 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 20:41:14 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-5dbe5d04-connect will be in pending phase
2022-04-04 20:41:15 [main] [32mINFO [m [SpecificIsolatedST:227] Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect
2022-04-04 20:41:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-5dbe5d04 will have desired state: Ready
2022-04-04 20:43:30 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-5dbe5d04 is in desired state: Ready
2022-04-04 20:43:30 [main] [32mINFO [m [SpecificIsolatedST:238] KafkaConnect is ready with changed rack key: 'rack-key'.
2022-04-04 20:43:30 [main] [32mINFO [m [SpecificIsolatedST:239] Verify KafkaConnect rack key update
2022-04-04 20:43:30 [main] [32mINFO [m [KafkaConnectUtils:156] Send and receive messages through KafkaConnect
2022-04-04 20:43:30 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-04 20:43:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-5dbe5d04-connect-999879799-9vjwq -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-04 20:43:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:43:30 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-04 20:43:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-5dbe5d04-scraper-554468998-kxgp2 -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-1670769365-1601814202", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-5dbe5d04-connect-api.infra-namespace.svc:8083/connectors
2022-04-04 20:43:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:43:30 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 20:43:30 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3f8b88b0, messages=[], arguments=[--topic, my-topic-1670769365-1601814202, --max-messages, 100, --bootstrap-server, my-cluster-5dbe5d04-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5dbe5d04-kafka-clients-6b4f98dc57-w7cdx', podNamespace='infra-namespace', bootstrapServer='my-cluster-5dbe5d04-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-1670769365-1601814202', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@408a855b}
2022-04-04 20:43:30 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-5dbe5d04-kafka-bootstrap.infra-namespace.svc:9092:my-topic-1670769365-1601814202 from pod my-cluster-5dbe5d04-kafka-clients-6b4f98dc57-w7cdx
2022-04-04 20:43:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5dbe5d04-kafka-clients-6b4f98dc57-w7cdx -n infra-namespace -- /opt/kafka/producer.sh --topic my-topic-1670769365-1601814202 --max-messages 100 --bootstrap-server my-cluster-5dbe5d04-kafka-bootstrap.infra-namespace.svc:9092
2022-04-04 20:43:34 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 20:43:34 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 20:43:34 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@24063bec, messages=[], arguments=[--topic, my-topic-1670769365-1601814202, --max-messages, 100, --group-instance-id, instance271181170, --group-id, my-consumer-group-2137044674, --bootstrap-server, my-cluster-5dbe5d04-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5dbe5d04-kafka-clients-6b4f98dc57-w7cdx', podNamespace='infra-namespace', bootstrapServer='my-cluster-5dbe5d04-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-1670769365-1601814202', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2137044674', consumerInstanceId='instance271181170', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@15e35361}
2022-04-04 20:43:34 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-5dbe5d04-kafka-bootstrap.infra-namespace.svc:9092#my-topic-1670769365-1601814202 from pod my-cluster-5dbe5d04-kafka-clients-6b4f98dc57-w7cdx
2022-04-04 20:43:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5dbe5d04-kafka-clients-6b4f98dc57-w7cdx -n infra-namespace -- /opt/kafka/consumer.sh --topic my-topic-1670769365-1601814202 --max-messages 100 --group-instance-id instance271181170 --group-id my-consumer-group-2137044674 --bootstrap-server my-cluster-5dbe5d04-kafka-bootstrap.infra-namespace.svc:9092
2022-04-04 20:43:40 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-04 20:43:40 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-04 20:43:40 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-5dbe5d04-connect-999879799-9vjwq
2022-04-04 20:43:40 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-5dbe5d04-connect-999879799-9vjwq
2022-04-04 20:43:40 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:43:40 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:43:40 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:43:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:43:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:43:40 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:43:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:43:51 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:51 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:43:51 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:43:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:43:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:43:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:43:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:43:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:44:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:44:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:44:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:44:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:44:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:44:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:01 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:44:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:44:57 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@307794e7, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-04 20:44:57 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:44:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:44:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:44:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:44:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:44:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:44:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:44:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:44:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:44:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:44:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:44:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:44:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:44:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:44:58 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:44:58 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:44:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:44:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:45:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:45:31 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:45:41 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:45:41 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-04 20:45:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:45:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:45:51 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-04 20:45:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:45:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRackAwareConnectWrongDeployment
2022-04-04 20:45:51 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-5dbe5d04-allow in namespace infra-namespace
2022-04-04 20:45:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-5dbe5d04-allow in namespace infra-namespace
2022-04-04 20:45:51 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5dbe5d04-kafka-clients in namespace infra-namespace
2022-04-04 20:45:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5dbe5d04 in namespace infra-namespace
2022-04-04 20:45:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5dbe5d04-scraper in namespace infra-namespace
2022-04-04 20:45:51 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-5dbe5d04 in namespace infra-namespace
2022-04-04 20:45:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:45:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAwareConnectWrongDeployment-FINISHED
2022-04-04 20:45:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:45:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:45:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testDeployUnsupportedKafka-STARTED
2022-04-04 20:45:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-030e7ea4 in namespace infra-namespace
2022-04-04 20:45:51 [main] [32mINFO [m [SpecificIsolatedST:414] Kafka with version 6.6.6 deployed.
2022-04-04 20:45:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-030e7ea4 will have desired state: NotReady
2022-04-04 20:45:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-030e7ea4 is in desired state: NotReady
2022-04-04 20:45:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:45:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployUnsupportedKafka
2022-04-04 20:45:54 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-030e7ea4 in namespace infra-namespace
2022-04-04 20:45:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:45:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testDeployUnsupportedKafka-FINISHED
2022-04-04 20:45:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:45:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:45:54 [main] [32mINFO [m [ResourceManager:346] In context SpecificIsolatedST is everything deleted.
2022-04-04 20:45:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 646.808 s - in io.strimzi.systemtest.specific.SpecificIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.DrainCleanerIsolatedST
2022-04-04 20:45:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:46:19 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:46:19 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:46:19 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:46:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:46:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:46:19 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:46:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:46:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:46:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:46:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:46:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:46:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:46:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:46:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:46:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:46:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:46:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:30 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:46:30 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:30 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:46:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:46:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:46:55 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=strimzi-drain-cleaner
namespaceToWatch=strimzi-drain-cleaner
bindingsNamespaces=[strimzi-drain-cleaner]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 20:46:55 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:46:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: strimzi-drain-cleaner
2022-04-04 20:46:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: strimzi-drain-cleaner
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:46:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: strimzi-drain-cleaner
2022-04-04 20:46:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace strimzi-drain-cleaner
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:46:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace strimzi-drain-cleaner
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:46:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace strimzi-drain-cleaner
2022-04-04 20:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:46:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:47:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:47:22 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:47:32 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:47:32 [main] [32mINFO [m [RequiredMinKubeApiVersionCondition:30] testDrainCleanerWithComponents is @RequiredMinKubeApiVersion with version 1.17, but the running on cluster with 1.16: Ignoring testDrainCleanerWithComponents
2022-04-04 20:47:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:47:32 [main] [32mINFO [m [ResourceManager:346] In context DrainCleanerIsolatedST is everything deleted.
2022-04-04 20:47:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 97.495 s - in io.strimzi.systemtest.specific.DrainCleanerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
2022-04-04 20:47:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:47:57 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:47:57 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:47:57 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:47:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:47:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:47:57 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:47:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:47:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:47:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:47:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:47:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:47:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace strimzi-drain-cleaner
2022-04-04 20:47:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:47:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:47:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:07 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:48:07 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:48:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:48:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:48:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:48:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-04 20:48:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:48:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:48:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:48:28 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace,second-namespace-test
bindingsNamespaces=[infra-namespace, second-namespace-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 20:48:28 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:48:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:48:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-namespace-test
2022-04-04 20:48:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-namespace-test
2022-04-04 20:48:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:48:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:48:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:48:29 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:48:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:48:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:48:29 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-04 20:48:29 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-04 20:48:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:48:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:48:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:48:42 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:48:52 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:48:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:48:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster in namespace second-namespace-test
2022-04-04 20:48:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster will have desired state: Ready
2022-04-04 20:50:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster is in desired state: Ready
2022-04-04 20:50:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:50:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:50:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-STARTED
2022-04-04 20:50:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:50:16 [main] [32mINFO [m [MultipleNamespaceIsolatedST:59] Deploying Kafka in different namespace than CO when CO watches multiple namespaces
2022-04-04 20:50:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:50:16 [main] [32mINFO [m [AbstractNamespaceST:46] Check if Kafka Cluster my-cluster in namespace second-namespace-test
2022-04-04 20:50:16 [main] [32mINFO [m [AbstractNamespaceST:51] Kafka condition status: True
2022-04-04 20:50:16 [main] [32mINFO [m [AbstractNamespaceST:52] Kafka condition type: Ready
2022-04-04 20:50:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:50:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:50:16 [main] [32mINFO [m [ResourceManager:346] In context testKafkaInDifferentNsThanClusterOperator is everything deleted.
2022-04-04 20:50:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:50:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-FINISHED
2022-04-04 20:50:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:50:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:50:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-STARTED
2022-04-04 20:50:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:50:16 [main] [32mINFO [m [MultipleNamespaceIsolatedST:45] Deploying TO to watch a different namespace that it is deployed in
2022-04-04 20:50:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:50:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace second-namespace-test exec my-cluster-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 20:50:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:50:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-121280155-1060746082 in namespace infra-namespace
2022-04-04 20:50:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-121280155-1060746082 will have desired state: Ready
2022-04-04 20:50:21 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-121280155-1060746082 is in desired state: Ready
2022-04-04 20:50:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:50:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicOperatorWatchingOtherNamespace
2022-04-04 20:50:21 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-121280155-1060746082 in namespace infra-namespace
2022-04-04 20:50:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:50:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-FINISHED
2022-04-04 20:50:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:50:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:50:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-STARTED
2022-04-04 20:50:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:50:31 [main] [32mINFO [m [MultipleNamespaceIsolatedST:69] Deploying KafkaMirrorMaker in different namespace than CO when CO watches multiple namespaces
2022-04-04 20:50:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:50:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-target in namespace second-namespace-test
2022-04-04 20:50:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-target will have desired state: Ready
2022-04-04 20:51:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-target is in desired state: Ready
2022-04-04 20:51:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-04 20:51:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-04 20:52:47 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-04 20:52:47 [main] [32mINFO [m [AbstractNamespaceST:71] Waiting for creation my-cluster-mirror-maker in namespace second-namespace-test
2022-04-04 20:52:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-04 20:52:47 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-04 20:52:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:52:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:52:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployMirrorMakerAcrossMultipleNamespace
2022-04-04 20:52:47 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-04 20:52:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-target in namespace second-namespace-test
2022-04-04 20:52:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:52:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-FINISHED
2022-04-04 20:52:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:52:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:52:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for MultipleNamespaceIsolatedST
2022-04-04 20:52:57 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster in namespace second-namespace-test
2022-04-04 20:53:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 335.367 s - in io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
2022-04-04 20:53:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:53:32 [main] [32mINFO [m [AllNamespaceIsolatedST:190] Creating resources before the test class
2022-04-04 20:53:32 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 20:53:32 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 20:53:32 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 20:53:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:53:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 20:53:32 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:53:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:53:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:53:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:53:32 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:53:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:53:32 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:53:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:53:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:53:32 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:53:32 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:53:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:53:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:53:43 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:53:43 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:53:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:53:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:53:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:53:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:53:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:53:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-04 20:53:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-04 20:53:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:53:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:53:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:53:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:53:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:54:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:54:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:54:08 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace, second-namespace-test, third-namespace-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 20:54:08 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 20:54:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 20:54:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-namespace-test
2022-04-04 20:54:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: third-namespace-test
2022-04-04 20:54:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 20:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 20:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 20:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 20:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 20:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 20:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 20:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 20:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-namespace-test
2022-04-04 20:54:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: third-namespace-test
2022-04-04 20:54:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-04 20:54:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-04 20:54:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace third-namespace-test
2022-04-04 20:54:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace third-namespace-test
2022-04-04 20:54:09 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:54:09 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 20:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 20:54:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 20:54:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 20:54:35 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 20:54:45 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 20:54:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-04 20:54:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster in namespace third-namespace-test
2022-04-04 20:54:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster will have desired state: Ready
2022-04-04 20:56:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster is in desired state: Ready
2022-04-04 20:56:05 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:56:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-second in namespace second-namespace-test
2022-04-04 20:56:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-second will have desired state: Ready
2022-04-04 20:57:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-second is in desired state: Ready
2022-04-04 20:57:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:57:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:57:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-STARTED
2022-04-04 20:57:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:57:21 [main] [32mINFO [m [AllNamespaceIsolatedST:82] Deploying Kafka cluster in different namespace than CO when CO watches all namespaces
2022-04-04 20:57:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:57:21 [main] [32mINFO [m [AbstractNamespaceST:46] Check if Kafka Cluster my-cluster-second in namespace second-namespace-test
2022-04-04 20:57:21 [main] [32mINFO [m [AbstractNamespaceST:51] Kafka condition status: True
2022-04-04 20:57:21 [main] [32mINFO [m [AbstractNamespaceST:52] Kafka condition type: Ready
2022-04-04 20:57:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:57:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:57:21 [main] [32mINFO [m [ResourceManager:346] In context testKafkaInDifferentNsThanClusterOperator is everything deleted.
2022-04-04 20:57:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:57:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-FINISHED
2022-04-04 20:57:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:57:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:57:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-STARTED
2022-04-04 20:57:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:57:21 [main] [32mINFO [m [AllNamespaceIsolatedST:66] Deploying TO to watch a different namespace that it is deployed in
2022-04-04 20:57:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-04 20:57:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace third-namespace-test exec my-cluster-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-04 20:57:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 20:57:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-300748687-1089513053 in namespace second-namespace-test
2022-04-04 20:57:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-300748687-1089513053 will have desired state: Ready
2022-04-04 20:57:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-300748687-1089513053 is in desired state: Ready
2022-04-04 20:57:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:57:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:57:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicOperatorWatchingOtherNamespace
2022-04-04 20:57:26 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-300748687-1089513053 in namespace second-namespace-test
2022-04-04 20:57:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:57:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-FINISHED
2022-04-04 20:57:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:57:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:57:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUOWatchingOtherNamespace-STARTED
2022-04-04 20:57:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:57:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:57:36 [main] [32mINFO [m [AllNamespaceIsolatedST:121] Creating user in other namespace than CO and Kafka cluster with UO
2022-04-04 20:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-658059026-1656359126 in namespace second-namespace-test
2022-04-04 20:57:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-658059026-1656359126 will have desired state: Ready
2022-04-04 20:57:37 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-658059026-1656359126 is in desired state: Ready
2022-04-04 20:57:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:57:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:57:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUOWatchingOtherNamespace
2022-04-04 20:57:37 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-658059026-1656359126 in namespace second-namespace-test
2022-04-04 20:57:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:57:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUOWatchingOtherNamespace-FINISHED
2022-04-04 20:57:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:57:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:57:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUserInDifferentNamespace-STARTED
2022-04-04 20:57:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:57:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:57:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-658059026-1656359126 in namespace second-namespace-test
2022-04-04 20:57:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-658059026-1656359126 will have desired state: Ready
2022-04-04 20:57:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-658059026-1656359126 is in desired state: Ready
2022-04-04 20:57:48 [main] [32mINFO [m [AllNamespaceIsolatedST:137] KafkaUser condition status: True
2022-04-04 20:57:48 [main] [32mINFO [m [AllNamespaceIsolatedST:138] KafkaUser condition type: Ready
2022-04-04 20:57:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-04 20:57:48 [main] [32mINFO [m [AllNamespaceIsolatedST:148] Copying secret Secret(apiVersion=v1, data={ca.crt=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, user.crt=LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVJVENDQWdtZ0F3SUJBZ0lVVjVwN3Y5TnV5RGJNM2Q1VWVhQmcvaUN3ZHU4d0RRWUpLb1pJaHZjTkFRRU4KQlFBd0xURVRNQkVHQTFVRUNnd0thVzh1YzNSeWFXMTZhVEVXTUJRR0ExVUVBd3dOWTJ4cFpXNTBjeTFqWVNCMgpNREFlRncweU1qQTBNRFF5TURVM05EZGFGdzB5TXpBME1EUXlNRFUzTkRkYU1DY3hKVEFqQmdOVkJBTU1IRzE1CkxYVnpaWEl0TmpVNE1EVTVNREkyTFRFMk5UWXpOVGt4TWpZd2dnRWlNQTBHQ1NxR1NJYjNEUUVCQVFVQUE0SUIKRHdBd2dnRUtBb0lCQVFEQkx6ZDkxVzhWOUJ0SzBkNVloV203MUs0V3dRcm5vazQ2T3ZNQWw1YUM3YnRNNkZHVApiSGR0N2d4TDU3dVk0dWpKeTZzVG54VFpUQzlBb2xIZGJwZGp3VndSZ3B2UXZHU29HK3grS0IxRXh5SVRkMFZRClpVNFp0VDF6UTJsaUVyVWR4NnpVRnFCamw4VkFabVU2MG5zZERrU0lLbGNzV3I3NE9IN1U0cFpHUVpiSFpvQlkKM1BsM0ljUUpGV1ZlMVNtOGVmZnk2eXd2Y0ZJVWpzYXpWQndjZmV1Rm9Wdk13L1J5WnN1N2xSTElodDJrcEFwZQo2UlY1ODk0a2xVdXAwMVovRG1xK2RCNmxBU3BLaHN6RDE2QTRaazdMZ2JabkE1ak16TnFwajl3MGp2TjZLZ2tyCmd1L1kxVmsySk9yQW9ydGVPWkJURVNOTXY0MEVTb0I2V2NIMUFnTUJBQUdqUHpBOU1CMEdBMVVkRGdRV0JCUSsKRXRoSTFOWlk3aE43Njg5Y2hzQUNHczBhOVRBTUJnTlZIUk1CQWY4RUFqQUFNQTRHQTFVZER3RUIvd1FFQXdJRgpvREFOQmdrcWhraUc5dzBCQVEwRkFBT0NBZ0VBa1Z4OUROaUI3MGp5aENQWFZRbEQ3M2h1OHAxcGxJR0pxc0JjClBSVW1tZmRPSlJPc2dRR29KOFdBQ2pUdlNxdnF6RlhiUzlIWDB1ZEllTzhDaGYvTElGcmErd01pdFNpNjFYekIKRWlUbnZ6MnhlUW1tSXFCVituN2tpWTBFWGhWYjJYd2NkUm9waitYOFcvbHF4eXQ4WjJ0TndWelcxbnJlVzZzRQpmZVpna3hKbWtmWlRtSjk3K0YxSkZja2pET1hRSkpRdVl4NFY4RGlEZFduQXVvYnFNN1BhdHlRVHB3WXR2dWhyCkIxWDBsejBIcmc4VTZ3dm8vRTFzSXg3aU5vQno2dXY1YktrWVcwN2UwUHNQWWs3OUI5Q293bmRxQ2c1MEJLdkgKSlU0SkFoY3dnZFdnUjZyWk9DTzNFWjlEamJHV2V4Z3o5dUxkRHJEb0pORGFKR1BXcllQSXNyNkZwb091K2Zscwo2VUd4Um85WHFRRStPS0VYeCtsNitwaHIxdVZBSlBYWGZEeHRCdEwrbUFVK0NZbVF0S0dOQ2dZMHZITGpCeGwzCm9DdEZOaEJTQXBuRjBaa0gyejZkSjNCbGRvTFZZOGoyellXNHNSc1NNWHpBa2YxWTNZNHhWaHEzNXArREVGZDMKeG41ak5mOVlBTTloM09UcjRydlkzZUhoNVVxaHE2ZmE0SnlXWi85UU5sYVVZWFptUWc5MXVPVlRKRWZEVS9ybgpWdFlOdytieVlFOUlvY1c3K0VaNWJPYVNlS01jOUpVL054VFVST3c0cS9ZaUcvRTdzZ3g2emF3RTFQeVdsQ1JPCkhrZE5MQStrNnRTdjd5S2tKQmdXRG0xL1RuWWZkSUhseTZ4RlZ3M2M3eHd1SkJDMmNvdURDVWQva2lIelJIa3EKNE4yMTNhcz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=, user.key=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, user.p12=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, user.password=TEZjQ1N6SFBQUW5J}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2022-04-04T20:57:47Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-user-658059026-1656359126, app.kubernetes.io/managed-by=strimzi-user-operator, app.kubernetes.io/name=strimzi-user-operator, app.kubernetes.io/part-of=strimzi-my-user-658059026-1656359126, strimzi.io/cluster=my-cluster, strimzi.io/kind=KafkaUser, test.case=testUserInDifferentNamespace}, managedFields=[], name=my-user-658059026-1656359126, namespace=second-namespace-test, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=KafkaUser, name=my-user-658059026-1656359126, uid=5c30e747-4257-4945-90c8-9df77e2804d8, additionalProperties={})], resourceVersion=583442, selfLink=/api/v1/namespaces/second-namespace-test/secrets/my-user-658059026-1656359126, uid=c3973c58-39f6-4d49-bcc9-784760e23ae1, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) from namespace second-namespace-test to namespace third-namespace-test
2022-04-04 20:57:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-kafka-clients in namespace third-namespace-test
2022-04-04 20:57:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-kafka-clients will be ready
2022-04-04 20:57:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-kafka-clients is ready
2022-04-04 20:57:50 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 20:57:50 [main] [32mINFO [m [AllNamespaceIsolatedST:168] Checking produced and consumed messages to pod:my-cluster-kafka-clients-f7cc5b9cc-45b2z
2022-04-04 20:57:50 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4386d5df, messages=[], arguments=[--topic, my-topic-1670769365-1601814202, --max-messages, 100, USER=my_user_658059026_1656359126, --bootstrap-server, my-cluster-kafka-bootstrap.third-namespace-test.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-kafka-clients-f7cc5b9cc-45b2z', podNamespace='third-namespace-test', bootstrapServer='my-cluster-kafka-bootstrap.third-namespace-test.svc:9093', topicName='my-topic-1670769365-1601814202', maxMessages=100, kafkaUsername='my-user-658059026-1656359126', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6fdf0b8a}
2022-04-04 20:57:50 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-kafka-bootstrap.third-namespace-test.svc:9093:my-topic-1670769365-1601814202 from pod my-cluster-kafka-clients-f7cc5b9cc-45b2z
2022-04-04 20:57:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-kafka-clients-f7cc5b9cc-45b2z -n third-namespace-test -- /opt/kafka/producer.sh --topic my-topic-1670769365-1601814202 --max-messages 100 USER=my_user_658059026_1656359126 --bootstrap-server my-cluster-kafka-bootstrap.third-namespace-test.svc:9093
2022-04-04 20:57:54 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-04 20:57:54 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-04 20:57:54 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@66119cb9, messages=[], arguments=[--topic, my-topic-1670769365-1601814202, --max-messages, 100, --group-instance-id, instance1758923997, --group-id, my-consumer-group-1345531318, USER=my_user_658059026_1656359126, --bootstrap-server, my-cluster-kafka-bootstrap.third-namespace-test.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-kafka-clients-f7cc5b9cc-45b2z', podNamespace='third-namespace-test', bootstrapServer='my-cluster-kafka-bootstrap.third-namespace-test.svc:9093', topicName='my-topic-1670769365-1601814202', maxMessages=100, kafkaUsername='my-user-658059026-1656359126', consumerGroupName='my-consumer-group-1345531318', consumerInstanceId='instance1758923997', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@111c3d38}
2022-04-04 20:57:54 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-kafka-bootstrap.third-namespace-test.svc:9093:my-topic-1670769365-1601814202 from pod my-cluster-kafka-clients-f7cc5b9cc-45b2z
2022-04-04 20:57:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-kafka-clients-f7cc5b9cc-45b2z -n third-namespace-test -- /opt/kafka/consumer.sh --topic my-topic-1670769365-1601814202 --max-messages 100 --group-instance-id instance1758923997 --group-id my-consumer-group-1345531318 USER=my_user_658059026_1656359126 --bootstrap-server my-cluster-kafka-bootstrap.third-namespace-test.svc:9093
2022-04-04 20:58:01 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-04 20:58:01 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-04 20:58:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 20:58:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 20:58:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserInDifferentNamespace
2022-04-04 20:58:01 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-kafka-clients in namespace third-namespace-test
2022-04-04 20:58:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-658059026-1656359126 in namespace second-namespace-test
2022-04-04 20:58:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 20:58:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUserInDifferentNamespace-FINISHED
2022-04-04 20:58:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 20:58:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 20:58:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-STARTED
2022-04-04 20:58:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 20:58:41 [main] [32mINFO [m [AllNamespaceIsolatedST:92] Deploying KafkaMirrorMaker in different namespace than CO when CO watches all namespaces
2022-04-04 20:58:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 20:58:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-target in namespace second-namespace-test
2022-04-04 20:58:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-target will have desired state: Ready
2022-04-04 20:59:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-target is in desired state: Ready
2022-04-04 20:59:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-04 20:59:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-04 21:01:03 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-04 21:01:03 [main] [32mINFO [m [AbstractNamespaceST:71] Waiting for creation my-cluster-mirror-maker in namespace second-namespace-test
2022-04-04 21:01:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-04 21:01:03 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-04 21:01:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 21:01:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:01:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployMirrorMakerAcrossMultipleNamespace
2022-04-04 21:01:03 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-04 21:01:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-target in namespace second-namespace-test
2022-04-04 21:01:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:01:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-FINISHED
2022-04-04 21:01:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:01:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:01:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO-STARTED
2022-04-04 21:01:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:01:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-04 21:01:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5a1575c8-kafka-clients in namespace second-namespace-test
2022-04-04 21:01:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5a1575c8-kafka-clients will be ready
2022-04-04 21:01:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5a1575c8-kafka-clients is ready
2022-04-04 21:01:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5a1575c8kafka-connect-scraper in namespace second-namespace-test
2022-04-04 21:01:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5a1575c8kafka-connect-scraper will be ready
2022-04-04 21:01:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5a1575c8kafka-connect-scraper is ready
2022-04-04 21:01:17 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-5a1575c8kafka-connect-scraper to be ready
2022-04-04 21:01:27 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-5a1575c8kafka-connect-scraper is ready
2022-04-04 21:01:27 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-5a1575c8kafka-connect-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 21:01:27 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-5a1575c8kafka-connect-allow in namespace second-namespace-test
2022-04-04 21:01:27 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 21:01:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-5a1575c8kafka-connect in namespace second-namespace-test
2022-04-04 21:01:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-5a1575c8kafka-connect will have desired state: Ready
2022-04-04 21:02:38 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-5a1575c8kafka-connect is in desired state: Ready
2022-04-04 21:02:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-5a1575c8kafka-connect in namespace second-namespace-test
2022-04-04 21:02:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-5a1575c8kafka-connect will have desired state: Ready
2022-04-04 21:02:39 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-5a1575c8kafka-connect is in desired state: Ready
2022-04-04 21:02:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-5a1575c8kafka-connect will have desired state: Ready
2022-04-04 21:02:39 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-5a1575c8kafka-connect is in desired state: Ready
2022-04-04 21:02:39 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-04 21:02:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace second-namespace-test exec my-cluster-5a1575c8kafka-connect-connect-79bc7c4d94-xtvt4 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-04 21:02:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:02:39 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-04 21:02:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5a1575c8kafka-connect-kafka-clients in namespace second-namespace-test
2022-04-04 21:02:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5a1575c8kafka-connect-kafka-clients will be ready
2022-04-04 21:02:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5a1575c8kafka-connect-kafka-clients is ready
2022-04-04 21:02:41 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-04 21:02:41 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3bcdbc7b, messages=[], arguments=[--topic, my-topic-1670769365-1601814202, --max-messages, 100, --bootstrap-server, my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5a1575c8-kafka-clients-86b569b7f8-49zz2', podNamespace='second-namespace-test', bootstrapServer='my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092', topicName='my-topic-1670769365-1601814202', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@35517a03}
2022-04-04 21:02:41 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092:my-topic-1670769365-1601814202 from pod my-cluster-5a1575c8-kafka-clients-86b569b7f8-49zz2
2022-04-04 21:02:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5a1575c8-kafka-clients-86b569b7f8-49zz2 -n second-namespace-test -- /opt/kafka/producer.sh --topic my-topic-1670769365-1601814202 --max-messages 100 --bootstrap-server my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092
2022-04-04 21:02:43 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-04 21:02:43 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-04 21:02:43 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-5a1575c8kafka-connect-connect-79bc7c4d94-xtvt4
2022-04-04 21:02:46 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-5a1575c8kafka-connect-connect-79bc7c4d94-xtvt4
2022-04-04 21:02:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 21:02:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:02:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO
2022-04-04 21:02:46 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-5a1575c8kafka-connect in namespace second-namespace-test
2022-04-04 21:02:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5a1575c8kafka-connect-scraper in namespace second-namespace-test
2022-04-04 21:02:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5a1575c8kafka-connect-kafka-clients in namespace second-namespace-test
2022-04-04 21:02:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-5a1575c8kafka-connect in namespace second-namespace-test
2022-04-04 21:02:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5a1575c8-kafka-clients in namespace second-namespace-test
2022-04-04 21:03:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-5a1575c8kafka-connect-allow in namespace second-namespace-test
2022-04-04 21:03:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:03:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO-FINISHED
2022-04-04 21:03:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:03:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:03:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for AllNamespaceIsolatedST
2022-04-04 21:03:36 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-second in namespace second-namespace-test
2022-04-04 21:03:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster in namespace third-namespace-test
2022-04-04 21:03:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 639.06 s - in io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-04 21:03:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 21:04:11 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 21:04:11 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 21:04:11 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 21:04:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:04:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 21:04:11 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 21:04:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:04:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace third-namespace-test
2022-04-04 21:04:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 21:04:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 21:04:11 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 21:04:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace third-namespace-test
2022-04-04 21:04:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 21:04:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 21:04:11 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 21:04:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:04:11 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-04 21:04:11 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 21:04:11 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 21:04:12 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:04:12 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 21:04:12 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 21:04:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:04:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:04:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 21:04:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 21:04:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-04 21:04:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 21:04:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 21:04:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 21:04:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:04:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:04:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 21:04:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 21:04:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 21:04:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 21:04:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 21:04:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 21:04:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:04:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 21:04:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:05:02 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 21:05:02 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 21:05:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 21:05:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 21:05:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:05:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 21:05:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:05:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 21:05:03 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 21:05:03 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 21:05:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:05:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 21:05:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 21:05:33 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 21:05:43 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 21:05:43 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 21:05:43 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-04 21:05:43 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 21:07:39 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 21:07:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:07:39 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-04 21:07:39 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-04 21:07:39 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-04 21:07:39 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-04 21:07:39 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-04 21:07:39 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-04 21:07:39 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-04 21:07:39 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-04 21:07:39 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-04 21:07:39 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-04 21:07:39 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-04 21:07:39 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-04 21:07:39 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-04 21:07:39 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-04 21:07:39 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-04 21:07:39 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-04 21:07:39 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-04 21:07:39 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-04 21:07:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 21:07:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-plain-name will have desired state: Ready
2022-04-04 21:08:51 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-plain-name is in desired state: Ready
2022-04-04 21:08:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:08:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainProducerConsumer-STARTED
2022-04-04 21:08:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:08:52 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:08:52 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:08:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-2a72b78b in namespace infra-namespace
2022-04-04 21:08:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-2a72b78b will be in active state
2022-04-04 21:08:53 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-producer-my-cluster-2a72b78b to finished
2022-04-04 21:09:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-2a72b78b in namespace infra-namespace
2022-04-04 21:09:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-2a72b78b will be in active state
2022-04-04 21:09:02 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-2a72b78b to finished
2022-04-04 21:09:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:09:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSaslPlainProducerConsumer
2022-04-04 21:09:12 [main] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-2a72b78b in namespace infra-namespace
2022-04-04 21:09:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-2a72b78b in namespace infra-namespace
2022-04-04 21:09:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:09:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainProducerConsumer-FINISHED
2022-04-04 21:09:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:09:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:09:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth-STARTED
2022-04-04 21:09:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:09:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-03b6cb62-kafka-clients in namespace infra-namespace
2022-04-04 21:09:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-03b6cb62-kafka-clients will be ready
2022-04-04 21:09:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-03b6cb62-kafka-clients is ready
2022-04-04 21:09:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-03b6cb62-scraper in namespace infra-namespace
2022-04-04 21:09:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-03b6cb62-scraper will be ready
2022-04-04 21:09:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-03b6cb62-scraper is ready
2022-04-04 21:09:16 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-03b6cb62-scraper to be ready
2022-04-04 21:09:26 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-03b6cb62-scraper is ready
2022-04-04 21:09:26 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-03b6cb62-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 21:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-03b6cb62-allow in namespace infra-namespace
2022-04-04 21:09:26 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 21:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-03b6cb62 in namespace infra-namespace
2022-04-04 21:09:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-03b6cb62 will have desired state: Ready
2022-04-04 21:10:35 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-03b6cb62 is in desired state: Ready
2022-04-04 21:10:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:10:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth
2022-04-04 21:10:35 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-03b6cb62-allow in namespace infra-namespace
2022-04-04 21:10:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-03b6cb62-scraper in namespace infra-namespace
2022-04-04 21:10:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-03b6cb62-kafka-clients in namespace infra-namespace
2022-04-04 21:10:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-03b6cb62 in namespace infra-namespace
2022-04-04 21:11:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:11:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth-FINISHED
2022-04-04 21:11:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:11:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:11:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker-STARTED
2022-04-04 21:11:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:11:25 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:11:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-281348770-1975602189 in namespace infra-namespace
2022-04-04 21:11:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-281348770-1975602189 will have desired state: Ready
2022-04-04 21:11:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-281348770-1975602189 is in desired state: Ready
2022-04-04 21:11:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-21b56cc0 in namespace infra-namespace
2022-04-04 21:11:26 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-21b56cc0 will be in active state
2022-04-04 21:11:27 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-21b56cc0 to finished
2022-04-04 21:11:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-21b56cc0 in namespace infra-namespace
2022-04-04 21:11:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-21b56cc0 will be in active state
2022-04-04 21:11:36 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-21b56cc0 to finished
2022-04-04 21:11:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-21b56cc0-target in namespace infra-namespace
2022-04-04 21:11:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-21b56cc0-target will have desired state: Ready
2022-04-04 21:12:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-21b56cc0-target is in desired state: Ready
2022-04-04 21:12:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 21:12:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: oauth-cluster-plain-name will have desired state: Ready
2022-04-04 21:13:56 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: oauth-cluster-plain-name is in desired state: Ready
2022-04-04 21:13:56 [main] [32mINFO [m [OauthPlainIsolatedST:443] Deleting the Job
2022-04-04 21:13:56 [main] [32mINFO [m [OauthPlainIsolatedST:446] Creating new client with new consumer-group and also to point on my-cluster-21b56cc0-target cluster
2022-04-04 21:13:56 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:13:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer in namespace infra-namespace
2022-04-04 21:13:56 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer will be in active state
2022-04-04 21:13:57 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer to finished
2022-04-04 21:14:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:14:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker
2022-04-04 21:14:08 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-21b56cc0-target in namespace infra-namespace
2022-04-04 21:14:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-21b56cc0 in namespace infra-namespace
2022-04-04 21:14:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer in namespace infra-namespace
2022-04-04 21:14:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-281348770-1975602189 in namespace infra-namespace
2022-04-04 21:14:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-21b56cc0 in namespace infra-namespace
2022-04-04 21:14:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 21:14:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:14:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker-FINISHED
2022-04-04 21:14:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:14:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:14:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerBridge-STARTED
2022-04-04 21:14:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:14:18 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:14:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1545573923-847552844 in namespace infra-namespace
2022-04-04 21:14:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1545573923-847552844 will have desired state: Ready
2022-04-04 21:14:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1545573923-847552844 is in desired state: Ready
2022-04-04 21:14:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-7c242943 in namespace infra-namespace
2022-04-04 21:14:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-7c242943 will be in active state
2022-04-04 21:14:20 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-7c242943 to finished
2022-04-04 21:14:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-7c242943 in namespace infra-namespace
2022-04-04 21:14:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-7c242943 will be in active state
2022-04-04 21:14:29 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-7c242943 to finished
2022-04-04 21:14:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7c242943-kafka-clients in namespace infra-namespace
2022-04-04 21:14:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7c242943-kafka-clients will be ready
2022-04-04 21:14:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7c242943-kafka-clients is ready
2022-04-04 21:14:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 21:14:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: oauth-cluster-plain-name will have desired state: Ready
2022-04-04 21:15:06 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: oauth-cluster-plain-name is in desired state: Ready
2022-04-04 21:15:06 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:15:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer-my-cluster-7c242943 in namespace infra-namespace
2022-04-04 21:15:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer-my-cluster-7c242943 will be in active state
2022-04-04 21:15:07 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer-my-cluster-7c242943 to finished
2022-04-04 21:16:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:16:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerBridge
2022-04-04 21:16:57 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7c242943-kafka-clients in namespace infra-namespace
2022-04-04 21:16:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-7c242943 in namespace infra-namespace
2022-04-04 21:16:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1545573923-847552844 in namespace infra-namespace
2022-04-04 21:16:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-7c242943 in namespace infra-namespace
2022-04-04 21:16:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer-my-cluster-7c242943 in namespace infra-namespace
2022-04-04 21:16:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 21:17:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:17:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerBridge-FINISHED
2022-04-04 21:17:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:17:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:17:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumer-STARTED
2022-04-04 21:17:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1635648428-2029420716 in namespace infra-namespace
2022-04-04 21:17:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1635648428-2029420716 will have desired state: Ready
2022-04-04 21:17:38 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1635648428-2029420716 is in desired state: Ready
2022-04-04 21:17:38 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-9e183a3c in namespace infra-namespace
2022-04-04 21:17:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-9e183a3c will be in active state
2022-04-04 21:17:38 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-9e183a3c to finished
2022-04-04 21:17:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-9e183a3c in namespace infra-namespace
2022-04-04 21:17:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-9e183a3c will be in active state
2022-04-04 21:17:48 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-9e183a3c to finished
2022-04-04 21:17:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:17:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumer
2022-04-04 21:17:58 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-9e183a3c in namespace infra-namespace
2022-04-04 21:17:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1635648428-2029420716 in namespace infra-namespace
2022-04-04 21:17:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-9e183a3c in namespace infra-namespace
2022-04-04 21:18:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:18:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumer-FINISHED
2022-04-04 21:18:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:18:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:18:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker2-STARTED
2022-04-04 21:18:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:18:08 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1479316882-2140334142 in namespace infra-namespace
2022-04-04 21:18:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1479316882-2140334142 will have desired state: Ready
2022-04-04 21:18:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1479316882-2140334142 is in desired state: Ready
2022-04-04 21:18:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-3134e193 in namespace infra-namespace
2022-04-04 21:18:09 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-3134e193 will be in active state
2022-04-04 21:18:10 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-3134e193 to finished
2022-04-04 21:18:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-3134e193 in namespace infra-namespace
2022-04-04 21:18:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-3134e193 will be in active state
2022-04-04 21:18:20 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-3134e193 to finished
2022-04-04 21:18:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3134e193-target in namespace infra-namespace
2022-04-04 21:18:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3134e193-target will have desired state: Ready
2022-04-04 21:19:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3134e193-target is in desired state: Ready
2022-04-04 21:19:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 21:19:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: oauth-cluster-plain-name will have desired state: Ready
2022-04-04 21:20:53 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: oauth-cluster-plain-name is in desired state: Ready
2022-04-04 21:20:54 [main] [32mINFO [m [OauthPlainIsolatedST:593] Deleting the Job oauth-consumer-my-cluster-3134e193
2022-04-04 21:20:54 [main] [32mINFO [m [OauthPlainIsolatedST:596] Creating new client with new consumer-group and also to point on my-cluster-3134e193-target cluster
2022-04-04 21:20:54 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:20:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-3134e193 in namespace infra-namespace
2022-04-04 21:20:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-3134e193 will be in active state
2022-04-04 21:20:55 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-3134e193 to finished
2022-04-04 21:21:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:21:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker2
2022-04-04 21:21:06 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3134e193-target in namespace infra-namespace
2022-04-04 21:21:06 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-3134e193 in namespace infra-namespace
2022-04-04 21:21:06 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-3134e193 in namespace infra-namespace
2022-04-04 21:21:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1479316882-2140334142 in namespace infra-namespace
2022-04-04 21:21:06 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-3134e193 in namespace infra-namespace
2022-04-04 21:21:06 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 21:21:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:21:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker2-FINISHED
2022-04-04 21:21:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:21:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:21:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks-STARTED
2022-04-04 21:21:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:21:26 [main] [32mINFO [m [OauthPlainIsolatedST:161] Setting producer and consumer properties
2022-04-04 21:21:26 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:21:26 [main] [32mINFO [m [OauthPlainIsolatedST:174] Use clients without access token containing audience token
2022-04-04 21:21:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-b6e2212c in namespace infra-namespace
2022-04-04 21:21:26 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-b6e2212c will be in active state
2022-04-04 21:21:27 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-producer-my-cluster-b6e2212c to finish with failure.
2022-04-04 21:25:07 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testProducerConsumerAudienceTokenChecks$0(OauthPlainIsolatedST.java:176)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks(OauthPlainIsolatedST.java:176)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 21:25:07 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-producer-my-cluster-b6e2212c' finished with expected timeout.
2022-04-04 21:25:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-b6e2212c in namespace infra-namespace
2022-04-04 21:25:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-b6e2212c will be in active state
2022-04-04 21:25:08 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-consumer-my-cluster-b6e2212c to finish with failure.
2022-04-04 21:28:48 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testProducerConsumerAudienceTokenChecks$1(OauthPlainIsolatedST.java:178)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks(OauthPlainIsolatedST.java:178)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 21:28:48 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-consumer-my-cluster-b6e2212c' finished with expected timeout.
2022-04-04 21:28:58 [main] [32mINFO [m [OauthPlainIsolatedST:183] Use clients with Access token containing audience token
2022-04-04 21:28:58 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:28:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-b6e2212c in namespace infra-namespace
2022-04-04 21:28:58 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-b6e2212c will be in active state
2022-04-04 21:28:59 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-producer-my-cluster-b6e2212c to finished
2022-04-04 21:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-b6e2212c in namespace infra-namespace
2022-04-04 21:29:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-b6e2212c will be in active state
2022-04-04 21:29:08 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-b6e2212c to finished
2022-04-04 21:29:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:29:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerAudienceTokenChecks
2022-04-04 21:29:19 [main] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-b6e2212c in namespace infra-namespace
2022-04-04 21:29:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-b6e2212c in namespace infra-namespace
2022-04-04 21:29:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-b6e2212c in namespace infra-namespace
2022-04-04 21:29:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-b6e2212c in namespace infra-namespace
2022-04-04 21:29:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:29:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks-FINISHED
2022-04-04 21:29:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:29:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:29:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-STARTED
2022-04-04 21:29:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:29:19 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:29:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-958813803-1247749084 in namespace infra-namespace
2022-04-04 21:29:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-958813803-1247749084 will have desired state: Ready
2022-04-04 21:29:20 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-958813803-1247749084 is in desired state: Ready
2022-04-04 21:29:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-69c6795b in namespace infra-namespace
2022-04-04 21:29:20 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-69c6795b will be in active state
2022-04-04 21:29:21 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-69c6795b to finished
2022-04-04 21:29:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-69c6795b in namespace infra-namespace
2022-04-04 21:29:29 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-69c6795b will be in active state
2022-04-04 21:29:30 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-69c6795b to finished
2022-04-04 21:29:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-69c6795b-kafka-clients in namespace infra-namespace
2022-04-04 21:29:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-69c6795b-kafka-clients will be ready
2022-04-04 21:29:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-69c6795b-kafka-clients is ready
2022-04-04 21:29:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-69c6795b-scraper in namespace infra-namespace
2022-04-04 21:29:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-69c6795b-scraper will be ready
2022-04-04 21:29:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-69c6795b-scraper is ready
2022-04-04 21:29:46 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-69c6795b-scraper to be ready
2022-04-04 21:29:56 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-69c6795b-scraper is ready
2022-04-04 21:29:56 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-69c6795b-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 21:29:56 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-69c6795b-allow in namespace infra-namespace
2022-04-04 21:29:56 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 21:29:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-69c6795b in namespace infra-namespace
2022-04-04 21:29:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-69c6795b will have desired state: Ready
2022-04-04 21:39:56 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for KafkaConnect: my-cluster-69c6795b will have desired state: Ready, null
2022-04-04 21:39:56 [main] [32mINFO [m [ResourceManager:414] KafkaConnect status:

Conditions:
	Type: NotReady
	Message: Exceeded timeout of 300000ms while waiting for Deployment resource my-cluster-69c6795b-connect in namespace infra-namespace to be ready

Pods with conditions and messages:

my-cluster-69c6795b-connect-c7cc697dd-8g47q:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: Ready
	Message: containers with unready status: [my-cluster-69c6795b-connect]

	Type: ContainersReady
	Message: containers with unready status: [my-cluster-69c6795b-connect]

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-69c6795b-kafka-clients-b96c5cb44-sjsz5:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-69c6795b-scraper-8544985969-nxmqx:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for KafkaConnect: my-cluster-69c6795b will have desired state: Ready
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:435)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForConnectStatus(KafkaConnectUtils.java:42)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForConnectReady(KafkaConnectUtils.java:47)
	at io.strimzi.systemtest.resources.crd.KafkaConnectResource.waitForReadiness(KafkaConnectResource.java:42)
	at io.strimzi.systemtest.resources.crd.KafkaConnectResource.waitForReadiness(KafkaConnectResource.java:19)
	at io.strimzi.systemtest.resources.ResourceManager.lambda$waitResourceCondition$2(ResourceManager.java:268)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:142)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(OauthPlainIsolatedST.java:287)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-69c6795b
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(OauthPlainIsolatedST.java:287)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 21:39:56 [main] [1;31mERROR[m [TestExecutionWatcher:28] OauthPlainIsolatedST - Exception Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-69c6795b has been thrown in @Test. Going to collect logs from components.
2022-04-04 21:39:56 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-04 21:39:56 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-04 21:39:56 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-04 21:39:56 [main] [33mWARN [m [LogCollector:247] Searching for logs in all pods failed! Some of the logs will not be stored. Exception messagenull
2022-04-04 21:39:56 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-04 21:39:56 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-04 21:39:56 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-04 21:39:56 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-04 21:39:56 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-04 21:39:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:39:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-04 21:39:57 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-69c6795b-scraper in namespace infra-namespace
2022-04-04 21:39:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-69c6795b in namespace infra-namespace
2022-04-04 21:39:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-69c6795b in namespace infra-namespace
2022-04-04 21:39:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-69c6795b-kafka-clients in namespace infra-namespace
2022-04-04 21:39:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-69c6795b in namespace infra-namespace
2022-04-04 21:39:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-958813803-1247749084 in namespace infra-namespace
2022-04-04 21:40:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-69c6795b-allow in namespace infra-namespace
2022-04-04 21:40:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:40:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-04 21:40:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:40:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:40:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck-STARTED
2022-04-04 21:40:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:40:37 [main] [32mINFO [m [OauthPlainIsolatedST:213] Use clients with clientId not containing 'hello-world' in access token.
2022-04-04 21:40:37 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:40:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-8e6b7e57 in namespace infra-namespace
2022-04-04 21:40:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-8e6b7e57 will be in active state
2022-04-04 21:40:38 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:kafka-audience-producer-my-cluster-8e6b7e57 to finish with failure.
2022-04-04 21:44:18 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testAccessTokenClaimCheck$2(OauthPlainIsolatedST.java:229)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck(OauthPlainIsolatedST.java:229)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 21:44:18 [main] [32mINFO [m [ClientUtils:100] Client job 'kafka-audience-producer-my-cluster-8e6b7e57' finished with expected timeout.
2022-04-04 21:44:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-8e6b7e57 in namespace infra-namespace
2022-04-04 21:44:18 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-8e6b7e57 will be in active state
2022-04-04 21:44:19 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-8e6b7e57 to finish with failure.
2022-04-04 21:47:59 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testAccessTokenClaimCheck$3(OauthPlainIsolatedST.java:231)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck(OauthPlainIsolatedST.java:231)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 21:47:59 [main] [32mINFO [m [ClientUtils:100] Client job 'kafka-audience-consumer-my-cluster-8e6b7e57' finished with expected timeout.
2022-04-04 21:48:09 [main] [32mINFO [m [OauthPlainIsolatedST:236] Use clients with clientId containing 'hello-world' in access token.
2022-04-04 21:48:09 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 21:48:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-8e6b7e57 in namespace infra-namespace
2022-04-04 21:48:09 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-8e6b7e57 will be in active state
2022-04-04 21:48:10 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-8e6b7e57 to finished
2022-04-04 21:48:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-8e6b7e57 in namespace infra-namespace
2022-04-04 21:48:18 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-8e6b7e57 will be in active state
2022-04-04 21:48:19 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-8e6b7e57 to finished
2022-04-04 21:48:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:48:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAccessTokenClaimCheck
2022-04-04 21:48:30 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-8e6b7e57 in namespace infra-namespace
2022-04-04 21:48:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-8e6b7e57 in namespace infra-namespace
2022-04-04 21:48:30 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-8e6b7e57 in namespace infra-namespace
2022-04-04 21:48:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-8e6b7e57 in namespace infra-namespace
2022-04-04 21:48:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:48:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck-FINISHED
2022-04-04 21:48:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:48:30 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 21:48:34 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 21:48:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:48:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:48:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthPlainIsolatedST
2022-04-04 21:48:34 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-04 21:48:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 21:48:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:48:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:48:44 [main] [32mINFO [m [ResourceManager:346] In context OauthPlainIsolatedST is everything deleted.
2022-04-04 21:48:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 9, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 2,697.328 s <<< FAILURE! - in io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(ExtensionContext)  Time elapsed: 677.285 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-69c6795b
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(OauthPlainIsolatedST.java:287)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
2022-04-04 21:48:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 21:49:09 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 21:49:09 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 21:49:09 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 21:49:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:49:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 21:49:09 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 21:49:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 21:49:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:49:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:49:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 21:49:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 21:49:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:49:19 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:49:19 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 21:49:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 21:49:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 21:49:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 21:49:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 21:49:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:49:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 21:49:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:49:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:49:45 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 21:49:45 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 21:49:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 21:49:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 21:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 21:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 21:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 21:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 21:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 21:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 21:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:49:46 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 21:49:46 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 21:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 21:49:46 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 21:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 21:49:46 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 21:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 21:49:46 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 21:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:49:46 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 21:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 21:49:46 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 21:49:46 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 21:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 21:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 21:49:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 21:49:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 21:50:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 21:50:03 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 21:50:13 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 21:50:13 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 21:50:13 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-04 21:50:13 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 21:52:01 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 21:52:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:52:01 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-04 21:52:01 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-04 21:52:01 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-04 21:52:01 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-04 21:52:01 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-04 21:52:01 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-04 21:52:01 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-04 21:52:01 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-04 21:52:01 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-04 21:52:01 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-04 21:52:01 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-04 21:52:01 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-04 21:52:01 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-04 21:52:01 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-04 21:52:01 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to kafka-authz realm
2022-04-04 21:52:01 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to kafka-authz realm
2022-04-04 21:52:01 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to kafka-authz realm
2022-04-04 21:52:01 [main] [32mINFO [m [KeycloakInstance:55] Using HTTPS endpoints
2022-04-04 21:52:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-authz-name in namespace infra-namespace
2022-04-04 21:52:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-04 21:53:15 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-04 21:53:15 [main] [32mINFO [m [OauthAuthorizationIsolatedST:680] Setting producer and consumer properties
2022-04-04 21:53:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-a-client in namespace infra-namespace
2022-04-04 21:53:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-a-client will have desired state: Ready
2022-04-04 21:53:16 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-a-client is in desired state: Ready
2022-04-04 21:53:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-b-client in namespace infra-namespace
2022-04-04 21:53:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-b-client will have desired state: Ready
2022-04-04 21:53:17 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-b-client is in desired state: Ready
2022-04-04 21:53:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:53:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.smokeTestForClients-STARTED
2022-04-04 21:53:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:53:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-1072397618-384258401 in namespace infra-namespace
2022-04-04 21:53:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-1072397618-384258401 will have desired state: Ready
2022-04-04 21:53:18 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-1072397618-384258401 is in desired state: Ready
2022-04-04 21:53:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-682e4d57 in namespace infra-namespace
2022-04-04 21:53:18 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-682e4d57 will be in active state
2022-04-04 21:53:19 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-682e4d57 to finished
2022-04-04 21:53:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-682e4d57 in namespace infra-namespace
2022-04-04 21:53:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-682e4d57 will be in active state
2022-04-04 21:53:29 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-682e4d57 to finished
2022-04-04 21:53:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:53:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for smokeTestForClients
2022-04-04 21:53:35 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-682e4d57 in namespace infra-namespace
2022-04-04 21:53:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-1072397618-384258401 in namespace infra-namespace
2022-04-04 21:53:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-682e4d57 in namespace infra-namespace
2022-04-04 21:53:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:53:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.smokeTestForClients-FINISHED
2022-04-04 21:53:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:53:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:53:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopic-STARTED
2022-04-04 21:53:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:53:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-239093528-1216547261 in namespace infra-namespace
2022-04-04 21:53:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-239093528-1216547261 will have desired state: Ready
2022-04-04 21:53:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-239093528-1216547261 is in desired state: Ready
2022-04-04 21:53:46 [main] [32mINFO [m [OauthAuthorizationIsolatedST:146] Sending 100 messages to broker with topic name my-topic-239093528-1216547261
2022-04-04 21:53:46 [main] [32mINFO [m [OauthAuthorizationIsolatedST:147] Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'
2022-04-04 21:53:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-e4e052c9 in namespace infra-namespace
2022-04-04 21:53:46 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-e4e052c9 will be in active state
2022-04-04 21:53:47 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-producer-my-cluster-e4e052c9 will be in error state
2022-04-04 21:54:06 [main] [32mINFO [m [OauthAuthorizationIsolatedST:154] Sending 100 messages to broker with topic name x-topic-my-cluster-e4e052c9
2022-04-04 21:54:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-e4e052c9 in namespace infra-namespace
2022-04-04 21:54:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-e4e052c9 will be in active state
2022-04-04 21:54:07 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-producer-my-cluster-e4e052c9 will be in error state
2022-04-04 21:54:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topic-my-cluster-e4e052c9 in namespace infra-namespace
2022-04-04 21:54:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topic-my-cluster-e4e052c9 will have desired state: Ready
2022-04-04 21:54:27 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topic-my-cluster-e4e052c9 is in desired state: Ready
2022-04-04 21:54:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-e4e052c9 in namespace infra-namespace
2022-04-04 21:54:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-e4e052c9 will be in active state
2022-04-04 21:54:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-e4e052c9 to finished
2022-04-04 21:54:32 [main] [32mINFO [m [OauthAuthorizationIsolatedST:172] Sending 100 messages to broker with topic name a-topic-my-cluster-e4e052c9
2022-04-04 21:54:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-e4e052c9 in namespace infra-namespace
2022-04-04 21:54:33 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-e4e052c9 will be in active state
2022-04-04 21:54:34 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-e4e052c9 to finished
2022-04-04 21:54:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:54:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAWriteToTopic
2022-04-04 21:54:43 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topic-my-cluster-e4e052c9 in namespace infra-namespace
2022-04-04 21:54:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-e4e052c9 in namespace infra-namespace
2022-04-04 21:54:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-e4e052c9 in namespace infra-namespace
2022-04-04 21:54:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-239093528-1216547261 in namespace infra-namespace
2022-04-04 21:54:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-e4e052c9 in namespace infra-namespace
2022-04-04 21:54:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-e4e052c9 in namespace infra-namespace
2022-04-04 21:54:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:54:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopic-FINISHED
2022-04-04 21:54:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:54:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:54:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAReadFromTopic-STARTED
2022-04-04 21:54:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:54:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-1868777345-1091275260 in namespace infra-namespace
2022-04-04 21:54:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-1868777345-1091275260 will have desired state: Ready
2022-04-04 21:54:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-1868777345-1091275260 is in desired state: Ready
2022-04-04 21:54:54 [main] [32mINFO [m [OauthAuthorizationIsolatedST:208] Sending 100 messages to broker with topic name a-topic-my-topic-1868777345-1091275260
2022-04-04 21:54:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-bbef6e4a in namespace infra-namespace
2022-04-04 21:54:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-bbef6e4a will be in active state
2022-04-04 21:54:55 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-bbef6e4a to finished
2022-04-04 21:55:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-bbef6e4a in namespace infra-namespace
2022-04-04 21:55:03 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-bbef6e4a will be in active state
2022-04-04 21:55:04 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-consumer-my-cluster-bbef6e4a will be in error state
2022-04-04 21:55:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-bbef6e4a in namespace infra-namespace
2022-04-04 21:55:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-bbef6e4a will be in active state
2022-04-04 21:55:08 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-bbef6e4a to finished
2022-04-04 21:55:16 [main] [32mINFO [m [OauthAbstractST:153] Deleting team-a-client-consumer-my-cluster-bbef6e4a job
2022-04-04 21:55:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:55:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAReadFromTopic
2022-04-04 21:55:21 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-bbef6e4a in namespace infra-namespace
2022-04-04 21:55:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-bbef6e4a in namespace infra-namespace
2022-04-04 21:55:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-1868777345-1091275260 in namespace infra-namespace
2022-04-04 21:55:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-bbef6e4a in namespace infra-namespace
2022-04-04 21:55:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:55:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAReadFromTopic-FINISHED
2022-04-04 21:55:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:55:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:55:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamBWriteToTopic-STARTED
2022-04-04 21:55:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:55:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-107318619-591921739 in namespace infra-namespace
2022-04-04 21:55:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-107318619-591921739 will have desired state: Ready
2022-04-04 21:55:32 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-107318619-591921739 is in desired state: Ready
2022-04-04 21:55:32 [main] [32mINFO [m [OauthAuthorizationIsolatedST:259] Sending 100 messages to broker with topic name my-topic-1670769365-1601814202
2022-04-04 21:55:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-dd76bb6a in namespace infra-namespace
2022-04-04 21:55:32 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-dd76bb6a will be in active state
2022-04-04 21:55:33 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-b-client-producer-my-cluster-dd76bb6a will be in error state
2022-04-04 21:55:52 [main] [32mINFO [m [OauthAuthorizationIsolatedST:265] Sending 100 messages to broker with topic name b-topic
2022-04-04 21:55:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-dd76bb6a in namespace infra-namespace
2022-04-04 21:55:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-dd76bb6a will be in active state
2022-04-04 21:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-consumer-my-cluster-dd76bb6a in namespace infra-namespace
2022-04-04 21:55:53 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-consumer-my-cluster-dd76bb6a will be in active state
2022-04-04 21:55:54 [main] [32mINFO [m [ClientUtils:61] Waiting till producer team-b-client-producer-my-cluster-dd76bb6a and consumer team-b-client-consumer-my-cluster-dd76bb6a finish
2022-04-04 21:56:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:56:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamBWriteToTopic
2022-04-04 21:56:11 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-dd76bb6a in namespace infra-namespace
2022-04-04 21:56:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-consumer-my-cluster-dd76bb6a in namespace infra-namespace
2022-04-04 21:56:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-dd76bb6a in namespace infra-namespace
2022-04-04 21:56:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-107318619-591921739 in namespace infra-namespace
2022-04-04 21:56:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:56:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamBWriteToTopic-FINISHED
2022-04-04 21:56:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:56:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:56:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX-STARTED
2022-04-04 21:56:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:56:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topicmy-topic-451781571-51460357 in namespace infra-namespace
2022-04-04 21:56:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topicmy-topic-451781571-51460357 will have desired state: Ready
2022-04-04 21:56:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topicmy-topic-451781571-51460357 is in desired state: Ready
2022-04-04 21:56:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-a86e7436 in namespace infra-namespace
2022-04-04 21:56:22 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-a86e7436 will be in active state
2022-04-04 21:56:23 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-a86e7436 to finished
2022-04-04 21:56:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-consumer-my-cluster-a86e7436 in namespace infra-namespace
2022-04-04 21:56:32 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-consumer-my-cluster-a86e7436 will be in active state
2022-04-04 21:56:33 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-b-client-consumer-my-cluster-a86e7436 to finished
2022-04-04 21:56:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:56:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX
2022-04-04 21:56:45 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-a86e7436 in namespace infra-namespace
2022-04-04 21:56:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topicmy-topic-451781571-51460357 in namespace infra-namespace
2022-04-04 21:56:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-consumer-my-cluster-a86e7436 in namespace infra-namespace
2022-04-04 21:56:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:56:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX-FINISHED
2022-04-04 21:56:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:56:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:56:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSuperUserWithOauthAuthorization-STARTED
2022-04-04 21:56:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:56:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topicmy-topic-18188787-171638137 in namespace infra-namespace
2022-04-04 21:56:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topicmy-topic-18188787-171638137 will have desired state: Ready
2022-04-04 21:56:56 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topicmy-topic-18188787-171638137 is in desired state: Ready
2022-04-04 21:56:56 [main] [32mINFO [m [OauthAuthorizationIsolatedST:347] Verifying that team B is not able write to topic starting with 'x-' because in kafka clusterdoes not have super-users to break authorization rules
2022-04-04 21:56:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1778766919-1365888843 in namespace infra-namespace
2022-04-04 21:56:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1778766919-1365888843 will have desired state: Ready
2022-04-04 21:56:57 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1778766919-1365888843 is in desired state: Ready
2022-04-04 21:56:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-99a39e4c in namespace infra-namespace
2022-04-04 21:56:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-99a39e4c will be in active state
2022-04-04 21:56:58 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-b-client-producer-my-cluster-99a39e4c will be in error state
2022-04-04 21:57:07 [main] [32mINFO [m [OauthAuthorizationIsolatedST:370] Verifying that team A is not able read to topic starting with 'x-' because in kafka clusterdoes not have super-users to break authorization rules
2022-04-04 21:57:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-99a39e4c in namespace infra-namespace
2022-04-04 21:57:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-99a39e4c will be in active state
2022-04-04 21:57:07 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-consumer-my-cluster-99a39e4c will be in error state
2022-04-04 21:57:16 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: oauth-cluster-authz-name-kafka rolling update
2022-04-04 21:57:31 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: oauth-cluster-authz-name-kafka has been successfully rolled
2022-04-04 21:57:31 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-authz-name-kafka to be ready
2022-04-04 21:57:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-04 21:57:59 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-04 21:57:59 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-authz-name is ready
2022-04-04 21:57:59 [main] [32mINFO [m [OauthAuthorizationIsolatedST:404] Verifying that team B is able to write to topic starting with 'x-' and break authorization rule
2022-04-04 21:57:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-99a39e4c in namespace infra-namespace
2022-04-04 21:57:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-99a39e4c will be in active state
2022-04-04 21:58:01 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-b-client-producer-my-cluster-99a39e4c to finished
2022-04-04 21:58:10 [main] [32mINFO [m [OauthAuthorizationIsolatedST:409] Verifying that team A is able to write to topic starting with 'x-' and break authorization rule
2022-04-04 21:58:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-99a39e4c in namespace infra-namespace
2022-04-04 21:58:10 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-99a39e4c will be in active state
2022-04-04 21:58:11 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-99a39e4c to finished
2022-04-04 21:58:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 21:58:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSuperUserWithOauthAuthorization
2022-04-04 21:58:23 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-99a39e4c in namespace infra-namespace
2022-04-04 21:58:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-99a39e4c in namespace infra-namespace
2022-04-04 21:58:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1778766919-1365888843 in namespace infra-namespace
2022-04-04 21:58:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-99a39e4c in namespace infra-namespace
2022-04-04 21:58:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topicmy-topic-18188787-171638137 in namespace infra-namespace
2022-04-04 21:58:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-99a39e4c in namespace infra-namespace
2022-04-04 21:58:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 21:58:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSuperUserWithOauthAuthorization-FINISHED
2022-04-04 21:58:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 21:58:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 21:58:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication-STARTED
2022-04-04 21:58:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 21:58:33 [main] [32mINFO [m [OauthAuthorizationIsolatedST:443] Verifying that team A producer is able to send messages to the x-topic-example-topic topic -> the topic starting with 'x'
2022-04-04 21:58:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topic-example-topic in namespace infra-namespace
2022-04-04 21:58:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topic-example-topic will have desired state: Ready
2022-04-04 21:58:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topic-example-topic is in desired state: Ready
2022-04-04 21:58:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-example-topic in namespace infra-namespace
2022-04-04 21:58:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-example-topic will have desired state: Ready
2022-04-04 21:58:35 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-example-topic is in desired state: Ready
2022-04-04 21:58:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-b90bc52e in namespace infra-namespace
2022-04-04 21:58:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-b90bc52e will be in active state
2022-04-04 21:58:36 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-b90bc52e to finished
2022-04-04 21:58:39 [main] [32mINFO [m [OauthAuthorizationIsolatedST:465] Adding the maxSecondsWithoutReauthentication to Kafka listener with OAuth authentication
2022-04-04 21:58:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-04 21:58:39 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-04 21:58:39 [main] [32mINFO [m [OauthAuthorizationIsolatedST:493] Setting the master realm token's lifespan to 3600s
2022-04-04 21:58:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-5pq7h -- curl -v --insecure -X POST -d client_id=admin-cli&client_secret=aGVsbG8td29ybGQtcHJvZHVjZXItc2VjcmV0&grant_type=password&username=admin&password=6n9OLXbGBMlIsQ== https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/master/protocol/openid-connect/token
2022-04-04 21:58:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:58:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-5pq7h -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/master -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJSUzAtQnlmeTl1VGtBVkNITUtJa0oxei0yRWhPWGl4a1dONzRQWlR0SHVZIn0.eyJleHAiOjE2NDkxMDk1NzksImlhdCI6MTY0OTEwOTUxOSwianRpIjoiNTE0ZWI1ODEtMjM5Yy00NjlhLWIzNzEtMjUxNjAyMWMzM2U3IiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI0ZTQ5YzdiYi05YmRiLTQzOTItYTY0MC1hYTUxYmJiMTBmNDIiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiZjFiZmFkODktYTAyZi00MGJmLWJkZmUtZTFlZDI0OGYxMzA1IiwiYWNyIjoiMSIsInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.iR5FRwL9Ne8D3dwSg3b810QBYRVrKWnreFFDgVJKSuTNBXN71xzwkL_8RDVLuGyg5Z60awiBD_aMAo07Fp9d1X2gZ4AzniH2d0iUXEDZi4RF2_Co2-S_BJnDODyfJrTIjzXW03uXknfqUT7YuOsQkGUgsNW9TNx2NE2S4yEKHdbZaumOax0k0SX497XadTsxHQTKjozWQXnSvbr_blNc4DNO3qx-owkRzhdhd9Oa8aXX1IACv82UfwuZnoZ4VfY844MfzdFOI1iZ1lih3RyplctLJHVsfV6hDwT-a220BVp3s0jaaSy4CQ_wAJCdPnWX1LWfr9Qo28gM_yN5-zZp3g
2022-04-04 21:58:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:58:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-5pq7h -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/master -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJSUzAtQnlmeTl1VGtBVkNITUtJa0oxei0yRWhPWGl4a1dONzRQWlR0SHVZIn0.eyJleHAiOjE2NDkxMDk1NzksImlhdCI6MTY0OTEwOTUxOSwianRpIjoiNTE0ZWI1ODEtMjM5Yy00NjlhLWIzNzEtMjUxNjAyMWMzM2U3IiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI0ZTQ5YzdiYi05YmRiLTQzOTItYTY0MC1hYTUxYmJiMTBmNDIiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiZjFiZmFkODktYTAyZi00MGJmLWJkZmUtZTFlZDI0OGYxMzA1IiwiYWNyIjoiMSIsInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.iR5FRwL9Ne8D3dwSg3b810QBYRVrKWnreFFDgVJKSuTNBXN71xzwkL_8RDVLuGyg5Z60awiBD_aMAo07Fp9d1X2gZ4AzniH2d0iUXEDZi4RF2_Co2-S_BJnDODyfJrTIjzXW03uXknfqUT7YuOsQkGUgsNW9TNx2NE2S4yEKHdbZaumOax0k0SX497XadTsxHQTKjozWQXnSvbr_blNc4DNO3qx-owkRzhdhd9Oa8aXX1IACv82UfwuZnoZ4VfY844MfzdFOI1iZ1lih3RyplctLJHVsfV6hDwT-a220BVp3s0jaaSy4CQ_wAJCdPnWX1LWfr9Qo28gM_yN5-zZp3g -d {"id":"master","realm":"master","displayName":"Keycloak","displayNameHtml":"<div class=\"kc-logo-text\"><span>Keycloak</span></div>","notBefore":0,"revokeRefreshToken":false,"refreshTokenMaxReuse":0,"accessTokenLifespan":"3600","accessTokenLifespanForImplicitFlow":900,"ssoSessionIdleTimeout":1800,"ssoSessionMaxLifespan":36000,"ssoSessionIdleTimeoutRememberMe":0,"ssoSessionMaxLifespanRememberMe":0,"offlineSessionIdleTimeout":2592000,"offlineSessionMaxLifespanEnabled":false,"offlineSessionMaxLifespan":5184000,"clientSessionIdleTimeout":0,"clientSessionMaxLifespan":0,"clientOfflineSessionIdleTimeout":0,"clientOfflineSessionMaxLifespan":0,"accessCodeLifespan":60,"accessCodeLifespanUserAction":300,"accessCodeLifespanLogin":1800,"actionTokenGeneratedByAdminLifespan":43200,"actionTokenGeneratedByUserLifespan":300,"enabled":true,"sslRequired":"external","registrationAllowed":false,"registrationEmailAsUsername":false,"rememberMe":false,"verifyEmail":false,"loginWithEmailAllowed":true,"duplicateEmailsAllowed":false,"resetPasswordAllowed":false,"editUsernameAllowed":false,"bruteForceProtected":false,"permanentLockout":false,"maxFailureWaitSeconds":900,"minimumQuickLoginWaitSeconds":60,"waitIncrementSeconds":60,"quickLoginCheckMilliSeconds":1000,"maxDeltaTimeSeconds":43200,"failureFactor":30,"defaultRoles":["offline_access","uma_authorization"],"requiredCredentials":["password"],"otpPolicyType":"totp","otpPolicyAlgorithm":"HmacSHA1","otpPolicyInitialCounter":0,"otpPolicyDigits":6,"otpPolicyLookAheadWindow":1,"otpPolicyPeriod":30,"otpSupportedApplications":["FreeOTP","Google Authenticator"],"webAuthnPolicyRpEntityName":"keycloak","webAuthnPolicySignatureAlgorithms":["ES256"],"webAuthnPolicyRpId":"","webAuthnPolicyAttestationConveyancePreference":"not specified","webAuthnPolicyAuthenticatorAttachment":"not specified","webAuthnPolicyRequireResidentKey":"not specified","webAuthnPolicyUserVerificationRequirement":"not specified","webAuthnPolicyCreateTimeout":0,"webAuthnPolicyAvoidSameAuthenticatorRegister":false,"webAuthnPolicyAcceptableAaguids":[],"webAuthnPolicyPasswordlessRpEntityName":"keycloak","webAuthnPolicyPasswordlessSignatureAlgorithms":["ES256"],"webAuthnPolicyPasswordlessRpId":"","webAuthnPolicyPasswordlessAttestationConveyancePreference":"not specified","webAuthnPolicyPasswordlessAuthenticatorAttachment":"not specified","webAuthnPolicyPasswordlessRequireResidentKey":"not specified","webAuthnPolicyPasswordlessUserVerificationRequirement":"not specified","webAuthnPolicyPasswordlessCreateTimeout":0,"webAuthnPolicyPasswordlessAvoidSameAuthenticatorRegister":false,"webAuthnPolicyPasswordlessAcceptableAaguids":[],"browserSecurityHeaders":{"contentSecurityPolicyReportOnly":"","xContentTypeOptions":"nosniff","xRobotsTag":"none","xFrameOptions":"SAMEORIGIN","xXSSProtection":"1; mode=block","contentSecurityPolicy":"frame-src 'self'; frame-ancestors 'self'; object-src 'none';","strictTransportSecurity":"max-age=31536000; includeSubDomains"},"smtpServer":{},"eventsEnabled":false,"eventsListeners":["jboss-logging"],"enabledEventTypes":[],"adminEventsEnabled":false,"adminEventsDetailsEnabled":false,"internationalizationEnabled":false,"supportedLocales":[],"browserFlow":"browser","registrationFlow":"registration","directGrantFlow":"direct grant","resetCredentialsFlow":"reset credentials","clientAuthenticationFlow":"clients","dockerAuthenticationFlow":"docker auth","attributes":{},"userManagedAccessAllowed":false} -H Content-Type: application/json
2022-04-04 21:58:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:58:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-5pq7h -- curl -v --insecure -X POST -d client_id=admin-cli&client_secret=aGVsbG8td29ybGQtcHJvZHVjZXItc2VjcmV0&grant_type=password&username=admin&password=6n9OLXbGBMlIsQ== https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/master/protocol/openid-connect/token
2022-04-04 21:58:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:58:40 [main] [32mINFO [m [OauthAuthorizationIsolatedST:508] Getting the kafka-authz kafka client for obtaining the Dev A Team policy for the x topics
2022-04-04 21:58:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-5pq7h -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJSUzAtQnlmeTl1VGtBVkNITUtJa0oxei0yRWhPWGl4a1dONzRQWlR0SHVZIn0.eyJleHAiOjE2NDkxMTMxMjAsImlhdCI6MTY0OTEwOTUyMCwianRpIjoiMTMyNzRlMzAtMDc1OC00ZTU5LWJjN2EtZWI3MGJlYzEyMjA3IiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI0ZTQ5YzdiYi05YmRiLTQzOTItYTY0MC1hYTUxYmJiMTBmNDIiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiZmM5YjA0YjctMmMxMS00NjFmLWI4OTEtY2UxMDNmNmNmNjZlIiwiYWNyIjoiMSIsInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.VpJBLad_d1mcjMTTa3kZNUUIe8Wq5i2e_RKcQcj0w-OaVwyt1B3LS5xODMa0bakfxZAmDPN-ndlkcCTda0pwYdhya11KyfPrdl8wL2eUuackwhZuK8OrJ7QF7QOmX3iOQhEDyrdlxTQotr76nyCVooe-fAN1B6-DQSOmtdcFNJZ43yTYDT_5h4MtZm9YGGl5mSAbGis3cASQHQL5At57gtI-0I2MaQWN6T7gbo5hdunM7_sjOsduLBic24G_qTdg_wfUo-kx6afUDzhgDzJ3dVDuJyofDy-JPVgA1-i44oJJzKo-UK_HS54yFTc8LInCYqWBrI0Pse7SKvIjk6cRPw
2022-04-04 21:58:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:58:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-5pq7h -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/32c21036-4700-4264-a79b-ca6a849c89a7/authz/resource-server/policy -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJSUzAtQnlmeTl1VGtBVkNITUtJa0oxei0yRWhPWGl4a1dONzRQWlR0SHVZIn0.eyJleHAiOjE2NDkxMTMxMjAsImlhdCI6MTY0OTEwOTUyMCwianRpIjoiMTMyNzRlMzAtMDc1OC00ZTU5LWJjN2EtZWI3MGJlYzEyMjA3IiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI0ZTQ5YzdiYi05YmRiLTQzOTItYTY0MC1hYTUxYmJiMTBmNDIiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiZmM5YjA0YjctMmMxMS00NjFmLWI4OTEtY2UxMDNmNmNmNjZlIiwiYWNyIjoiMSIsInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.VpJBLad_d1mcjMTTa3kZNUUIe8Wq5i2e_RKcQcj0w-OaVwyt1B3LS5xODMa0bakfxZAmDPN-ndlkcCTda0pwYdhya11KyfPrdl8wL2eUuackwhZuK8OrJ7QF7QOmX3iOQhEDyrdlxTQotr76nyCVooe-fAN1B6-DQSOmtdcFNJZ43yTYDT_5h4MtZm9YGGl5mSAbGis3cASQHQL5At57gtI-0I2MaQWN6T7gbo5hdunM7_sjOsduLBic24G_qTdg_wfUo-kx6afUDzhgDzJ3dVDuJyofDy-JPVgA1-i44oJJzKo-UK_HS54yFTc8LInCYqWBrI0Pse7SKvIjk6cRPw
2022-04-04 21:58:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:58:41 [main] [32mINFO [m [OauthAuthorizationIsolatedST:539] Changing the Dev Team A policy for topics starting with x- and checking that job will not be successful
2022-04-04 21:58:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-5pq7h -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/32c21036-4700-4264-a79b-ca6a849c89a7/authz/resource-server/policy/4fb400e1-c0be-431e-a942-68b3403ede84 -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJSUzAtQnlmeTl1VGtBVkNITUtJa0oxei0yRWhPWGl4a1dONzRQWlR0SHVZIn0.eyJleHAiOjE2NDkxMTMxMjAsImlhdCI6MTY0OTEwOTUyMCwianRpIjoiMTMyNzRlMzAtMDc1OC00ZTU5LWJjN2EtZWI3MGJlYzEyMjA3IiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI0ZTQ5YzdiYi05YmRiLTQzOTItYTY0MC1hYTUxYmJiMTBmNDIiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiZmM5YjA0YjctMmMxMS00NjFmLWI4OTEtY2UxMDNmNmNmNjZlIiwiYWNyIjoiMSIsInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.VpJBLad_d1mcjMTTa3kZNUUIe8Wq5i2e_RKcQcj0w-OaVwyt1B3LS5xODMa0bakfxZAmDPN-ndlkcCTda0pwYdhya11KyfPrdl8wL2eUuackwhZuK8OrJ7QF7QOmX3iOQhEDyrdlxTQotr76nyCVooe-fAN1B6-DQSOmtdcFNJZ43yTYDT_5h4MtZm9YGGl5mSAbGis3cASQHQL5At57gtI-0I2MaQWN6T7gbo5hdunM7_sjOsduLBic24G_qTdg_wfUo-kx6afUDzhgDzJ3dVDuJyofDy-JPVgA1-i44oJJzKo-UK_HS54yFTc8LInCYqWBrI0Pse7SKvIjk6cRPw -d {"id":"4fb400e1-c0be-431e-a942-68b3403ede84","name":"Dev Team A can write to topics that start with x- on any cluster","type":"scope","logic":"POSITIVE","decisionStrategy":"UNANIMOUS","config":{"resources":"[\"Topic:x-*\"]","scopes":"[\"Describe\"]","applyPolicies":"[\"Dev Team A\"]"}} -H Content-Type: application/json
2022-04-04 21:58:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 21:58:41 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-b90bc52e to finished
2022-04-04 22:02:21 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for job finished, null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for job finished
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientSuccess(ClientUtils.java:77)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientSuccess(ClientUtils.java:72)
	at io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.lambda$testSessionReAuthentication$2(OauthAuthorizationIsolatedST.java:541)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:55)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:37)
	at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3082)
	at io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication(OauthAuthorizationIsolatedST.java:541)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 22:02:21 [main] [32mINFO [m [OauthAuthorizationIsolatedST:545] Sending messages to topic starting with a- -> the messages should be successfully sent
2022-04-04 22:02:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-b90bc52e in namespace infra-namespace
2022-04-04 22:02:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-b90bc52e will be in active state
2022-04-04 22:02:22 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-b90bc52e to finished
2022-04-04 22:02:30 [main] [32mINFO [m [OauthAuthorizationIsolatedST:554] Changing back to the original settings and checking, if the producer will be successful
2022-04-04 22:02:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-5pq7h -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/32c21036-4700-4264-a79b-ca6a849c89a7/authz/resource-server/policy/4fb400e1-c0be-431e-a942-68b3403ede84 -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJSUzAtQnlmeTl1VGtBVkNITUtJa0oxei0yRWhPWGl4a1dONzRQWlR0SHVZIn0.eyJleHAiOjE2NDkxMTMxMjAsImlhdCI6MTY0OTEwOTUyMCwianRpIjoiMTMyNzRlMzAtMDc1OC00ZTU5LWJjN2EtZWI3MGJlYzEyMjA3IiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiI0ZTQ5YzdiYi05YmRiLTQzOTItYTY0MC1hYTUxYmJiMTBmNDIiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiZmM5YjA0YjctMmMxMS00NjFmLWI4OTEtY2UxMDNmNmNmNjZlIiwiYWNyIjoiMSIsInNjb3BlIjoiZW1haWwgcHJvZmlsZSIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.VpJBLad_d1mcjMTTa3kZNUUIe8Wq5i2e_RKcQcj0w-OaVwyt1B3LS5xODMa0bakfxZAmDPN-ndlkcCTda0pwYdhya11KyfPrdl8wL2eUuackwhZuK8OrJ7QF7QOmX3iOQhEDyrdlxTQotr76nyCVooe-fAN1B6-DQSOmtdcFNJZ43yTYDT_5h4MtZm9YGGl5mSAbGis3cASQHQL5At57gtI-0I2MaQWN6T7gbo5hdunM7_sjOsduLBic24G_qTdg_wfUo-kx6afUDzhgDzJ3dVDuJyofDy-JPVgA1-i44oJJzKo-UK_HS54yFTc8LInCYqWBrI0Pse7SKvIjk6cRPw -d {"id":"4fb400e1-c0be-431e-a942-68b3403ede84","name":"Dev Team A can write to topics that start with x- on any cluster","type":"scope","logic":"POSITIVE","decisionStrategy":"UNANIMOUS","config":{"resources":"[\"Topic:x-*\"]","scopes":"[\"Describe\",\"Write\"]","applyPolicies":"[\"Dev Team A\"]"}} -H Content-Type: application/json
2022-04-04 22:02:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 22:02:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-b90bc52e in namespace infra-namespace
2022-04-04 22:02:31 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-b90bc52e will be in active state
2022-04-04 22:02:32 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-b90bc52e to finished
2022-04-04 22:04:20 [main] [32mINFO [m [OauthAuthorizationIsolatedST:568] Changing configuration of Kafka back to it's original form
2022-04-04 22:04:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-04 22:04:20 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-04 22:04:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:04:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSessionReAuthentication
2022-04-04 22:04:20 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-b90bc52e in namespace infra-namespace
2022-04-04 22:04:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-b90bc52e in namespace infra-namespace
2022-04-04 22:04:20 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-example-topic in namespace infra-namespace
2022-04-04 22:04:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topic-example-topic in namespace infra-namespace
2022-04-04 22:04:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-b90bc52e in namespace infra-namespace
2022-04-04 22:04:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:04:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication-FINISHED
2022-04-04 22:04:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:04:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:04:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testKeycloakAuthorizerToDelegateToSimpleAuthorizer-STARTED
2022-04-04 22:04:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:04:30 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-97 for test case:testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-04 22:04:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-97
2022-04-04 22:04:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-97
2022-04-04 22:04:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-97
2022-04-04 22:04:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret sso-x509-https-secret in namespace infra-namespace
2022-04-04 22:04:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 22:04:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret team-a-client-secret in namespace infra-namespace
2022-04-04 22:04:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 22:04:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret team-b-client-secret in namespace infra-namespace
2022-04-04 22:04:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 22:04:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ff5c26ed in namespace namespace-97
2022-04-04 22:04:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 22:04:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ff5c26ed will have desired state: Ready
2022-04-04 22:05:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ff5c26ed is in desired state: Ready
2022-04-04 22:05:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-a-client in namespace namespace-97
2022-04-04 22:05:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 22:05:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-a-client will have desired state: Ready
2022-04-04 22:05:46 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-a-client is in desired state: Ready
2022-04-04 22:05:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-b-client in namespace namespace-97
2022-04-04 22:05:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 22:05:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-b-client will have desired state: Ready
2022-04-04 22:05:47 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-b-client is in desired state: Ready
2022-04-04 22:05:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-775738260-817238408 in namespace namespace-97
2022-04-04 22:05:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 22:05:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-775738260-817238408 will have desired state: Ready
2022-04-04 22:05:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-775738260-817238408 is in desired state: Ready
2022-04-04 22:05:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-ff5c26ed in namespace namespace-97
2022-04-04 22:05:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 22:05:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-ff5c26ed will be in active state
2022-04-04 22:05:49 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-ff5c26ed to finished
2022-04-04 22:05:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-ff5c26ed in namespace namespace-97
2022-04-04 22:05:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-04 22:05:58 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-ff5c26ed will be in active state
2022-04-04 22:05:59 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-ff5c26ed to finished
2022-04-04 22:06:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:06:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-04 22:06:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-b-client in namespace namespace-97
2022-04-04 22:06:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-ff5c26ed in namespace namespace-97
2022-04-04 22:06:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Secret team-b-client-secret in namespace namespace-97
2022-04-04 22:06:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-775738260-817238408 in namespace namespace-97
2022-04-04 22:06:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-ff5c26ed in namespace namespace-97
2022-04-04 22:06:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-a-client in namespace namespace-97
2022-04-04 22:06:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Secret team-a-client-secret in namespace namespace-97
2022-04-04 22:06:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ff5c26ed in namespace namespace-97
2022-04-04 22:06:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Secret sso-x509-https-secret in namespace namespace-97
2022-04-04 22:06:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:06:25 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-97 for test case:testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-04 22:06:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testKeycloakAuthorizerToDelegateToSimpleAuthorizer-FINISHED
2022-04-04 22:06:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:06:52 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 22:06:57 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 22:06:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 22:06:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:06:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthAuthorizationIsolatedST
2022-04-04 22:06:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-a-client in namespace infra-namespace
2022-04-04 22:06:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-authz-name in namespace infra-namespace
2022-04-04 22:06:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-b-client in namespace infra-namespace
2022-04-04 22:06:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 22:07:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:07:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:07:07 [main] [32mINFO [m [ResourceManager:346] In context OauthAuthorizationIsolatedST is everything deleted.
2022-04-04 22:07:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 10, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 1,103.416 s - in io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
2022-04-04 22:07:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 22:07:32 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 22:07:32 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 22:07:32 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 22:07:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:07:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 22:07:32 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:07:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:07:42 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:07:42 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 22:07:42 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 22:07:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 22:07:42 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 22:07:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 22:07:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:07:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 22:07:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 22:08:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:08:08 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 22:08:08 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 22:08:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 22:08:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 22:08:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:08:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:08:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 22:08:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 22:08:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 22:08:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 22:08:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:08:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 22:08:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:08:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 22:08:09 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 22:08:09 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 22:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:08:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 22:08:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 22:08:39 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 22:08:49 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 22:08:49 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 22:08:49 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-04 22:08:49 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 22:10:22 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 22:10:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 22:10:22 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-04 22:10:22 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-04 22:10:22 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-04 22:10:22 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-04 22:10:22 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-04 22:10:22 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-04 22:10:22 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-04 22:10:22 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-04 22:10:22 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-04 22:10:22 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-04 22:10:22 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-04 22:10:22 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-04 22:10:22 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-04 22:10:22 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-04 22:10:22 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to scope-test realm
2022-04-04 22:10:22 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to scope-test realm
2022-04-04 22:10:22 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to scope-test realm
2022-04-04 22:10:22 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-04 22:10:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-scope-name in namespace infra-namespace
2022-04-04 22:10:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-04 22:11:40 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-04 22:11:40 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:11:40 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetCorrectly-STARTED
2022-04-04 22:11:40 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:11:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-260e884c-kafka-clients in namespace infra-namespace
2022-04-04 22:11:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-260e884c-kafka-clients will be ready
2022-04-04 22:11:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-260e884c-kafka-clients is ready
2022-04-04 22:11:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-260e884c-scraper in namespace infra-namespace
2022-04-04 22:11:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-260e884c-scraper will be ready
2022-04-04 22:11:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-260e884c-scraper is ready
2022-04-04 22:11:44 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-260e884c-scraper to be ready
2022-04-04 22:11:54 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-260e884c-scraper is ready
2022-04-04 22:11:54 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-260e884c-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 22:11:54 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-260e884c-allow in namespace infra-namespace
2022-04-04 22:11:54 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 22:11:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-260e884c in namespace infra-namespace
2022-04-04 22:11:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-260e884c will have desired state: Ready
2022-04-04 22:13:01 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-260e884c is in desired state: Ready
2022-04-04 22:13:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:13:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScopeKafkaConnectSetCorrectly
2022-04-04 22:13:01 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-260e884c-allow in namespace infra-namespace
2022-04-04 22:13:01 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-260e884c-scraper in namespace infra-namespace
2022-04-04 22:13:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-260e884c-kafka-clients in namespace infra-namespace
2022-04-04 22:13:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-260e884c in namespace infra-namespace
2022-04-04 22:13:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:13:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetCorrectly-FINISHED
2022-04-04 22:13:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:13:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:13:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetIncorrectly-STARTED
2022-04-04 22:13:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:13:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8e0b0dbd-kafka-clients in namespace infra-namespace
2022-04-04 22:13:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8e0b0dbd-kafka-clients will be ready
2022-04-04 22:13:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8e0b0dbd-kafka-clients is ready
2022-04-04 22:13:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-8e0b0dbd-scraper in namespace infra-namespace
2022-04-04 22:13:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-8e0b0dbd-scraper will be ready
2022-04-04 22:13:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-8e0b0dbd-scraper is ready
2022-04-04 22:13:44 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-8e0b0dbd-scraper to be ready
2022-04-04 22:13:54 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-8e0b0dbd-scraper is ready
2022-04-04 22:13:54 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-8e0b0dbd-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 22:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-8e0b0dbd-allow in namespace infra-namespace
2022-04-04 22:13:54 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 22:13:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-8e0b0dbd in namespace infra-namespace
2022-04-04 22:14:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:14:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScopeKafkaConnectSetIncorrectly
2022-04-04 22:14:08 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-8e0b0dbd-allow in namespace infra-namespace
2022-04-04 22:14:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-8e0b0dbd in namespace infra-namespace
2022-04-04 22:14:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8e0b0dbd-kafka-clients in namespace infra-namespace
2022-04-04 22:14:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-8e0b0dbd-scraper in namespace infra-namespace
2022-04-04 22:14:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:14:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetIncorrectly-FINISHED
2022-04-04 22:14:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:14:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:14:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetCorrectly-STARTED
2022-04-04 22:14:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:14:48 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:14:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-393811498-1455052026 in namespace infra-namespace
2022-04-04 22:14:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-393811498-1455052026 will have desired state: Ready
2022-04-04 22:14:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-393811498-1455052026 is in desired state: Ready
2022-04-04 22:14:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-cae9dabd in namespace infra-namespace
2022-04-04 22:14:49 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-cae9dabd will be in active state
2022-04-04 22:14:50 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-cae9dabd to finished
2022-04-04 22:14:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:14:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientScopeKafkaSetCorrectly
2022-04-04 22:14:58 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-cae9dabd in namespace infra-namespace
2022-04-04 22:14:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-393811498-1455052026 in namespace infra-namespace
2022-04-04 22:15:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:15:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetCorrectly-FINISHED
2022-04-04 22:15:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:15:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:15:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly-STARTED
2022-04-04 22:15:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:15:08 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:15:08 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-scope-name-kafka to be ready
2022-04-04 22:15:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-04 22:15:48 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-04 22:15:48 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-scope-name is ready
2022-04-04 22:15:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-591021640-1710436098 in namespace infra-namespace
2022-04-04 22:15:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-591021640-1710436098 will have desired state: Ready
2022-04-04 22:15:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-591021640-1710436098 is in desired state: Ready
2022-04-04 22:15:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-dd80a6e9 in namespace infra-namespace
2022-04-04 22:15:49 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-dd80a6e9 will be in active state
2022-04-04 22:15:50 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-producer-my-cluster-dd80a6e9 to finish with failure.
2022-04-04 22:19:30 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly(OauthScopeIsolatedST.java:224)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 22:19:30 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-producer-my-cluster-dd80a6e9' finished with expected timeout.
2022-04-04 22:19:35 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-scope-name-kafka to be ready
2022-04-04 22:20:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-04 22:20:15 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-04 22:20:15 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-scope-name is ready
2022-04-04 22:20:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:20:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientScopeKafkaSetIncorrectly
2022-04-04 22:20:15 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-dd80a6e9 in namespace infra-namespace
2022-04-04 22:20:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-591021640-1710436098 in namespace infra-namespace
2022-04-04 22:20:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:20:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly-FINISHED
2022-04-04 22:20:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:20:25 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 22:20:30 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 22:20:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 22:20:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:20:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthScopeIsolatedST
2022-04-04 22:20:30 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-scope-name in namespace infra-namespace
2022-04-04 22:20:30 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 22:20:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:20:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:20:40 [main] [32mINFO [m [ResourceManager:346] In context OauthScopeIsolatedST is everything deleted.
2022-04-04 22:20:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 812.596 s - in io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
2022-04-04 22:20:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 22:21:05 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 22:21:05 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 22:21:05 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 22:21:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:21:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 22:21:05 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 22:21:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 22:21:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 22:21:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:21:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 22:21:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 22:21:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:21:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:21:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 22:21:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:21:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:15 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:21:15 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 22:21:15 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:15 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 22:21:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 22:21:25 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:21:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 22:21:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:21:41 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 22:21:41 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 22:21:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 22:21:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:21:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 22:21:41 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 22:21:41 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 22:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 22:21:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 22:21:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 22:21:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 22:21:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:21:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 22:21:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 22:21:42 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 22:21:42 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 22:21:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:21:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 22:21:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:21:42 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 22:21:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 22:21:59 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 22:22:09 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 22:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 22:22:09 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-04 22:22:09 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 22:23:46 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 22:23:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 22:23:46 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-04 22:23:46 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-04 22:23:46 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-04 22:23:46 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-04 22:23:46 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-04 22:23:46 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-04 22:23:46 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-04 22:23:46 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-04 22:23:46 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-04 22:23:46 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-04 22:23:46 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-04 22:23:46 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-04 22:23:46 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-04 22:23:46 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-04 22:23:46 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-04 22:23:46 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-04 22:23:46 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-04 22:23:46 [main] [32mINFO [m [KeycloakInstance:55] Using HTTPS endpoints
2022-04-04 22:23:46 [main] [32mINFO [m [OauthTlsIsolatedST:480] Keycloak settings KeycloakInstance{jwksExpireSeconds=500, jwksRefreshSeconds=400, username='admin', password='nWQOCOb9XMmW5Q==', httpsUri='keycloak.infra-namespace.svc.cluster.local:8443', httpUri='keycloak-discovery.infra-namespace.svc.cluster.local:8080', validIssuerUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal', jwksEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs', oauthTokenEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token', introspectionEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token/introspect', userNameClaim='preferred_username', keystorePattern=<tls>\s*<key-stores>\s*<key-store name="kcKeyStore">\s*<credential-reference clear-text=".*"\/>, keystorePasswordPattern=\".*\"}
2022-04-04 22:23:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name in namespace infra-namespace
2022-04-04 22:23:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name will have desired state: Ready
2022-04-04 22:25:04 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name is in desired state: Ready
2022-04-04 22:25:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser hello-world-producer in namespace infra-namespace
2022-04-04 22:25:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: hello-world-producer will have desired state: Ready
2022-04-04 22:25:05 [main] [32mINFO [m [ResourceManager:444] KafkaUser: hello-world-producer is in desired state: Ready
2022-04-04 22:25:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:25:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerBridge-STARTED
2022-04-04 22:25:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:25:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-930890339-1239040254 in namespace infra-namespace
2022-04-04 22:25:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-930890339-1239040254 will have desired state: Ready
2022-04-04 22:25:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-930890339-1239040254 is in desired state: Ready
2022-04-04 22:25:06 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:25:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-0b003615 in namespace infra-namespace
2022-04-04 22:25:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-0b003615 will be in active state
2022-04-04 22:25:07 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-0b003615 to finished
2022-04-04 22:25:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-0b003615 in namespace infra-namespace
2022-04-04 22:25:16 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-0b003615 will be in active state
2022-04-04 22:25:17 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-0b003615 to finished
2022-04-04 22:25:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0b003615-kafka-clients in namespace infra-namespace
2022-04-04 22:25:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0b003615-kafka-clients will be ready
2022-04-04 22:25:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0b003615-kafka-clients is ready
2022-04-04 22:25:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge oauth-cluster-tls-name in namespace infra-namespace
2022-04-04 22:25:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: oauth-cluster-tls-name will have desired state: Ready
2022-04-04 22:25:50 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: oauth-cluster-tls-name is in desired state: Ready
2022-04-04 22:25:50 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:25:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer-my-cluster-0b003615 in namespace infra-namespace
2022-04-04 22:25:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer-my-cluster-0b003615 will be in active state
2022-04-04 22:25:51 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer-my-cluster-0b003615 to finished
2022-04-04 22:26:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:26:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerBridge
2022-04-04 22:26:09 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0b003615-kafka-clients in namespace infra-namespace
2022-04-04 22:26:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-0b003615 in namespace infra-namespace
2022-04-04 22:26:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer-my-cluster-0b003615 in namespace infra-namespace
2022-04-04 22:26:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-930890339-1239040254 in namespace infra-namespace
2022-04-04 22:26:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-0b003615 in namespace infra-namespace
2022-04-04 22:26:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge oauth-cluster-tls-name in namespace infra-namespace
2022-04-04 22:26:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:26:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerBridge-FINISHED
2022-04-04 22:26:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:26:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:26:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumer-STARTED
2022-04-04 22:26:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:26:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1007174227-1744117423 in namespace infra-namespace
2022-04-04 22:26:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1007174227-1744117423 will have desired state: Ready
2022-04-04 22:26:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1007174227-1744117423 is in desired state: Ready
2022-04-04 22:26:50 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:26:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-c0e91c04 in namespace infra-namespace
2022-04-04 22:26:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-c0e91c04 will be in active state
2022-04-04 22:26:50 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-c0e91c04 to finished
2022-04-04 22:27:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-c0e91c04 in namespace infra-namespace
2022-04-04 22:27:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-c0e91c04 will be in active state
2022-04-04 22:27:01 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-c0e91c04 to finished
2022-04-04 22:27:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:27:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumer
2022-04-04 22:27:13 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-c0e91c04 in namespace infra-namespace
2022-04-04 22:27:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1007174227-1744117423 in namespace infra-namespace
2022-04-04 22:27:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-c0e91c04 in namespace infra-namespace
2022-04-04 22:27:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:27:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumer-FINISHED
2022-04-04 22:27:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:27:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:27:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testIntrospectionEndpoint-STARTED
2022-04-04 22:27:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:27:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1514643845-245631326 in namespace infra-namespace
2022-04-04 22:27:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1514643845-245631326 will have desired state: Ready
2022-04-04 22:27:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1514643845-245631326 is in desired state: Ready
2022-04-04 22:27:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name-intro in namespace infra-namespace
2022-04-04 22:27:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name-intro will have desired state: Ready
2022-04-04 22:28:24 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name-intro is in desired state: Ready
2022-04-04 22:28:24 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:28:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-5c5736b8 in namespace infra-namespace
2022-04-04 22:28:24 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-5c5736b8 will be in active state
2022-04-04 22:28:25 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-5c5736b8 to finished
2022-04-04 22:28:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-5c5736b8 in namespace infra-namespace
2022-04-04 22:28:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-5c5736b8 will be in active state
2022-04-04 22:28:36 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-5c5736b8 to finished
2022-04-04 22:28:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:28:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIntrospectionEndpoint
2022-04-04 22:28:43 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-5c5736b8 in namespace infra-namespace
2022-04-04 22:28:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-5c5736b8 in namespace infra-namespace
2022-04-04 22:28:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name-intro in namespace infra-namespace
2022-04-04 22:28:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1514643845-245631326 in namespace infra-namespace
2022-04-04 22:28:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:28:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testIntrospectionEndpoint-FINISHED
2022-04-04 22:28:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:28:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:28:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerConnect-STARTED
2022-04-04 22:28:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:28:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-661131322-1777248637 in namespace infra-namespace
2022-04-04 22:28:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-661131322-1777248637 will have desired state: Ready
2022-04-04 22:28:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-661131322-1777248637 is in desired state: Ready
2022-04-04 22:28:54 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:28:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-54f32c9e in namespace infra-namespace
2022-04-04 22:28:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-54f32c9e will be in active state
2022-04-04 22:28:55 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-54f32c9e to finished
2022-04-04 22:29:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-54f32c9e in namespace infra-namespace
2022-04-04 22:29:03 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-54f32c9e will be in active state
2022-04-04 22:29:04 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-54f32c9e to finished
2022-04-04 22:29:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment oauth-cluster-tls-name-kafka-clients in namespace infra-namespace
2022-04-04 22:29:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: oauth-cluster-tls-name-kafka-clients will be ready
2022-04-04 22:29:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: oauth-cluster-tls-name-kafka-clients is ready
2022-04-04 22:29:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-54f32c9e-scraper in namespace infra-namespace
2022-04-04 22:29:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-54f32c9e-scraper will be ready
2022-04-04 22:29:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-54f32c9e-scraper is ready
2022-04-04 22:29:20 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-54f32c9e-scraper to be ready
2022-04-04 22:29:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-54f32c9e-scraper is ready
2022-04-04 22:29:30 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-54f32c9e-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 22:29:30 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-54f32c9e-allow in namespace infra-namespace
2022-04-04 22:29:30 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 22:29:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-54f32c9e in namespace infra-namespace
2022-04-04 22:29:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-54f32c9e will have desired state: Ready
2022-04-04 22:30:38 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-54f32c9e is in desired state: Ready
2022-04-04 22:30:38 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-04 22:30:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-54f32c9e-connect-844994944-wq9gx -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-04 22:30:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 22:30:38 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-04 22:30:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec oauth-cluster-tls-name-kafka-clients-8cb45f87d-56tmf -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-661131322-1777248637", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-54f32c9e-connect-api.infra-namespace.svc:8083/connectors
2022-04-04 22:30:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 22:30:38 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-54f32c9e-connect-844994944-wq9gx
2022-04-04 22:30:42 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-54f32c9e-connect-844994944-wq9gx
2022-04-04 22:30:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:30:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-04 22:30:42 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-54f32c9e-scraper in namespace infra-namespace
2022-04-04 22:30:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-54f32c9e in namespace infra-namespace
2022-04-04 22:30:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-54f32c9e in namespace infra-namespace
2022-04-04 22:30:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-54f32c9e-allow in namespace infra-namespace
2022-04-04 22:30:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-54f32c9e in namespace infra-namespace
2022-04-04 22:30:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-661131322-1777248637 in namespace infra-namespace
2022-04-04 22:30:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment oauth-cluster-tls-name-kafka-clients in namespace infra-namespace
2022-04-04 22:31:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:31:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-04 22:31:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:31:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:31:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testMirrorMaker-STARTED
2022-04-04 22:31:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:31:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-685106303-960118905 in namespace infra-namespace
2022-04-04 22:31:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-685106303-960118905 will have desired state: Ready
2022-04-04 22:31:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-685106303-960118905 is in desired state: Ready
2022-04-04 22:31:23 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:31:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-10afc9ea in namespace infra-namespace
2022-04-04 22:31:23 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-10afc9ea will be in active state
2022-04-04 22:31:24 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-10afc9ea to finished
2022-04-04 22:31:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-10afc9ea in namespace infra-namespace
2022-04-04 22:31:32 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-10afc9ea will be in active state
2022-04-04 22:31:33 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-10afc9ea to finished
2022-04-04 22:31:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name-target in namespace infra-namespace
2022-04-04 22:31:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name-target will have desired state: Ready
2022-04-04 22:33:03 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name-target is in desired state: Ready
2022-04-04 22:33:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker oauth-cluster-tls-name in namespace infra-namespace
2022-04-04 22:33:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: oauth-cluster-tls-name will have desired state: Ready
2022-04-04 22:34:13 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: oauth-cluster-tls-name is in desired state: Ready
2022-04-04 22:34:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-658059026-1656359126 in namespace infra-namespace
2022-04-04 22:34:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-658059026-1656359126 will have desired state: Ready
2022-04-04 22:34:14 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-658059026-1656359126 is in desired state: Ready
2022-04-04 22:34:14 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-user-658059026-1656359126
2022-04-04 22:34:14 [main] [32mINFO [m [SecretUtils:50] Secret my-user-658059026-1656359126 created
2022-04-04 22:34:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-658059026-1656359126 will have desired state: Ready
2022-04-04 22:34:14 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-658059026-1656359126 is in desired state: Ready
2022-04-04 22:34:14 [main] [32mINFO [m [OauthTlsIsolatedST:390] Creating new client with new consumer-group and also to point on oauth-cluster-tls-name-target cluster
2022-04-04 22:34:14 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 22:34:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-10afc9ea in namespace infra-namespace
2022-04-04 22:34:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-10afc9ea will be in active state
2022-04-04 22:34:15 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-10afc9ea to finished
2022-04-04 22:34:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:34:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker
2022-04-04 22:34:26 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker oauth-cluster-tls-name in namespace infra-namespace
2022-04-04 22:34:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-10afc9ea in namespace infra-namespace
2022-04-04 22:34:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-10afc9ea in namespace infra-namespace
2022-04-04 22:34:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-685106303-960118905 in namespace infra-namespace
2022-04-04 22:34:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-10afc9ea in namespace infra-namespace
2022-04-04 22:34:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-658059026-1656359126 in namespace infra-namespace
2022-04-04 22:34:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name-target in namespace infra-namespace
2022-04-04 22:34:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:34:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testMirrorMaker-FINISHED
2022-04-04 22:34:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:34:36 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-04 22:34:41 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-04 22:34:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 22:34:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:34:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthTlsIsolatedST
2022-04-04 22:34:41 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name in namespace infra-namespace
2022-04-04 22:34:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser hello-world-producer in namespace infra-namespace
2022-04-04 22:34:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-04 22:34:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:34:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:34:51 [main] [32mINFO [m [ResourceManager:346] In context OauthTlsIsolatedST is everything deleted.
2022-04-04 22:34:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 851.296 s - in io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
2022-04-04 22:34:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 22:35:16 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 22:35:16 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 22:35:16 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 22:35:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:35:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 22:35:16 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 22:35:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 22:35:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 22:35:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:35:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 22:35:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 22:35:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:35:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:35:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 22:35:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:35:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:26 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:35:26 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 22:35:26 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 22:35:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 22:35:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:35:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 22:35:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:35:52 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=120000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 22:35:52 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 22:35:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 22:35:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 22:35:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:35:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:35:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 22:35:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 22:35:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 22:35:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 22:35:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 22:35:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:35:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 22:35:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 22:35:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 22:35:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 22:35:53 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:35:53 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 22:35:53 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 22:35:53 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 22:35:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 22:35:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 22:36:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 22:36:08 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 22:36:18 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 22:36:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:36:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaRollsWhenTopicIsUnderReplicated-STARTED
2022-04-04 22:36:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:36:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-98 for test case:testKafkaRollsWhenTopicIsUnderReplicated
2022-04-04 22:36:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-98
2022-04-04 22:36:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-98
2022-04-04 22:36:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-98
2022-04-04 22:36:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d47b4bfd in namespace namespace-98
2022-04-04 22:36:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-98
2022-04-04 22:36:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d47b4bfd will have desired state: Ready
2022-04-04 22:38:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d47b4bfd is in desired state: Ready
2022-04-04 22:38:13 [main] [32mINFO [m [KafkaRollerIsolatedST:105] Running kafkaScaleUpScaleDown my-cluster-d47b4bfd
2022-04-04 22:38:13 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d47b4bfd-kafka rolling update
2022-04-04 22:39:38 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d47b4bfd-kafka has been successfully rolled
2022-04-04 22:39:38 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-d47b4bfd-kafka to be ready
2022-04-04 22:40:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d47b4bfd will have desired state: Ready
2022-04-04 22:40:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d47b4bfd is in desired state: Ready
2022-04-04 22:40:25 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d47b4bfd is ready
2022-04-04 22:40:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-288841286-312762042 in namespace namespace-98
2022-04-04 22:40:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-98
2022-04-04 22:40:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-288841286-312762042 will have desired state: Ready
2022-04-04 22:40:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-288841286-312762042 is in desired state: Ready
2022-04-04 22:40:26 [main] [32mINFO [m [KafkaRollerIsolatedST:124] Scaling down to 3
2022-04-04 22:40:26 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d47b4bfd-kafka rolling update
2022-04-04 22:41:31 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d47b4bfd-kafka has been successfully rolled
2022-04-04 22:41:31 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d47b4bfd-kafka to be ready
2022-04-04 22:41:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d47b4bfd will have desired state: Ready
2022-04-04 22:41:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d47b4bfd is in desired state: Ready
2022-04-04 22:41:58 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d47b4bfd is ready
2022-04-04 22:41:58 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-d47b4bfd are stable
2022-04-04 22:41:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:41:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:41:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:41:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:41:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:41:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:41:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-04 22:41:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:41:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:41:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:41:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:41:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:41:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:41:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-04 22:42:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:42:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:42:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:42:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:42:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:42:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:42:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-04 22:42:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:42:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:42:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:42:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:42:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:42:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:42:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-04 22:42:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:42:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:42:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:42:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:42:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:42:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:42:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-04 22:42:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:42:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:42:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:42:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:42:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:42:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:42:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-04 22:42:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:42:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:42:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:42:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:42:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:42:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:42:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-04 22:42:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:42:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:42:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:42:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:42:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:42:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:42:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-04 22:42:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:42:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:42:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:42:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:42:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:42:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:42:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-04 22:42:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:42:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:42:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:42:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:42:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:42:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:42:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-04 22:42:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:42:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:42:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:42:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:42:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:42:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:42:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-04 22:42:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:42:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:42:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:42:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:42:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:42:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:42:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-04 22:42:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:42:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:42:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:42:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:42:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:42:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:42:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-04 22:42:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:42:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:42:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:42:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:42:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:42:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:42:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-04 22:42:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:42:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:42:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:42:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:42:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:42:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:42:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-04 22:42:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:42:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:42:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:42:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:42:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:42:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:42:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-04 22:42:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:42:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:42:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:42:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:42:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:42:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:42:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-04 22:42:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:42:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:42:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:42:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:42:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:42:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:42:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-04 22:42:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:42:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:42:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:42:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:42:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:42:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:42:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-04 22:42:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:42:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:42:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:42:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:42:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:42:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:42:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-04 22:42:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:42:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:42:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:42:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:42:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:42:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:42:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-04 22:42:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:42:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:42:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:42:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:42:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:42:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:42:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-04 22:42:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:42:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:42:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:42:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:42:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:42:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:42:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-04 22:42:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:42:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:42:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:42:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:42:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:42:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:42:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-04 22:42:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:42:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:42:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:42:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:42:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:42:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:42:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-04 22:42:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:42:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:42:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:42:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:42:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:42:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:42:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-04 22:42:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:42:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:42:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:42:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:42:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:42:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:42:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-04 22:42:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:42:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:42:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:42:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:42:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:42:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:42:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-04 22:42:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:42:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:42:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:42:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:42:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:42:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:42:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-04 22:42:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:42:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:42:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:42:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:42:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:42:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:42:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-04 22:42:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:42:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:42:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:42:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:42:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:42:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:42:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-04 22:42:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:42:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:42:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:42:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:42:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:42:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:42:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-04 22:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:42:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-04 22:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:42:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-04 22:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:42:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-04 22:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:42:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-04 22:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:42:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-04 22:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:42:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-04 22:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:42:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-04 22:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:42:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-04 22:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:42:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-04 22:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:42:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-04 22:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:42:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-04 22:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:42:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-04 22:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:42:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-04 22:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:42:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-04 22:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:42:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-04 22:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:42:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-04 22:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:42:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-04 22:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:42:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-d47b4bfd-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-04 22:42:48 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-d47b4bfd-entity-operator-c9bd8fd46-b27sb ,my-cluster-d47b4bfd-kafka-0 ,my-cluster-d47b4bfd-kafka-1 ,my-cluster-d47b4bfd-kafka-2 ,my-cluster-d47b4bfd-zookeeper-0 ,my-cluster-d47b4bfd-zookeeper-1 ,my-cluster-d47b4bfd-zookeeper-2
2022-04-04 22:42:48 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d47b4bfd-kafka rolling update
2022-04-04 22:44:29 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d47b4bfd-kafka has been successfully rolled
2022-04-04 22:44:29 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d47b4bfd-kafka to be ready
2022-04-04 22:44:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d47b4bfd will have desired state: Ready
2022-04-04 22:44:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d47b4bfd is in desired state: Ready
2022-04-04 22:44:56 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d47b4bfd is ready
2022-04-04 22:44:56 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 517 seconds
2022-04-04 22:44:56 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-04 22:44:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:44:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaRollsWhenTopicIsUnderReplicated
2022-04-04 22:44:56 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-288841286-312762042 in namespace namespace-98
2022-04-04 22:44:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d47b4bfd in namespace namespace-98
2022-04-04 22:45:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:45:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-98 for test case:testKafkaRollsWhenTopicIsUnderReplicated
2022-04-04 22:45:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaRollsWhenTopicIsUnderReplicated-FINISHED
2022-04-04 22:45:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:45:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:45:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPendingDueToRack-STARTED
2022-04-04 22:45:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:45:49 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-99 for test case:testKafkaPodPendingDueToRack
2022-04-04 22:45:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-99
2022-04-04 22:45:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-99
2022-04-04 22:45:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-99
2022-04-04 22:45:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1a033de2 in namespace namespace-99
2022-04-04 22:45:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-99
2022-04-04 22:45:49 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-1a033de2-kafka will have stable 3 replicas
2022-04-04 22:45:49 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:45:50 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:45:51 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:45:52 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:45:53 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:45:54 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:45:55 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:45:56 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:45:57 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:45:58 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:45:59 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:00 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:01 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:02 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:03 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:04 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:05 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:06 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:07 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:08 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:09 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:10 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:11 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:12 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:13 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:14 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:15 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-04 22:46:16 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-04 22:46:17 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-04 22:46:18 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-04 22:46:19 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-04 22:46:20 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-04 22:46:21 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-04 22:46:22 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-04 22:46:23 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-04 22:46:24 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-04 22:46:25 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-04 22:46:26 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-04 22:46:27 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-04 22:46:28 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-04 22:46:29 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-04 22:46:30 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-04 22:46:31 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-04 22:46:32 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-04 22:46:33 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-04 22:46:34 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-04 22:46:35 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-04 22:46:35 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-1a033de2-kafka has 3 replicas
2022-04-04 22:46:35 [main] [32mINFO [m [KafkaRollerIsolatedST:309] Removing requirement for the affinity
2022-04-04 22:46:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1a033de2 will have desired state: Ready
2022-04-04 22:50:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1a033de2 is in desired state: Ready
2022-04-04 22:50:13 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-cluster-1a033de2
2022-04-04 22:50:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:50:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodPendingDueToRack
2022-04-04 22:50:16 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1a033de2 in namespace namespace-99
2022-04-04 22:50:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:50:16 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-99 for test case:testKafkaPodPendingDueToRack
2022-04-04 22:51:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPendingDueToRack-FINISHED
2022-04-04 22:51:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:51:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:51:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodImagePullBackOff-STARTED
2022-04-04 22:51:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:51:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-100 for test case:testKafkaPodImagePullBackOff
2022-04-04 22:51:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-100
2022-04-04 22:51:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-100
2022-04-04 22:51:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-100
2022-04-04 22:51:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d3bcc910 in namespace namespace-100
2022-04-04 22:51:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-100
2022-04-04 22:51:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d3bcc910 will have desired state: Ready
2022-04-04 22:52:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d3bcc910 is in desired state: Ready
2022-04-04 22:52:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d3bcc910 will have desired state: NotReady
2022-04-04 22:54:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d3bcc910 is in desired state: NotReady
2022-04-04 22:54:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d3bcc910 will have desired state: Ready
2022-04-04 22:58:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d3bcc910 is in desired state: Ready
2022-04-04 22:58:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 22:58:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodImagePullBackOff
2022-04-04 22:58:56 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d3bcc910 in namespace namespace-100
2022-04-04 22:59:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 22:59:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-100 for test case:testKafkaPodImagePullBackOff
2022-04-04 22:59:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodImagePullBackOff-FINISHED
2022-04-04 22:59:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 22:59:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 22:59:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPending-STARTED
2022-04-04 22:59:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 22:59:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-101 for test case:testKafkaPodPending
2022-04-04 22:59:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-101
2022-04-04 22:59:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-101
2022-04-04 22:59:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-101
2022-04-04 22:59:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e2ac67f5 in namespace namespace-101
2022-04-04 22:59:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-101
2022-04-04 22:59:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e2ac67f5 will have desired state: Ready
2022-04-04 23:01:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e2ac67f5 is in desired state: Ready
2022-04-04 23:01:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e2ac67f5 will have desired state: NotReady
2022-04-04 23:03:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e2ac67f5 is in desired state: NotReady
2022-04-04 23:03:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e2ac67f5 will have desired state: Ready
2022-04-04 23:05:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e2ac67f5 is in desired state: Ready
2022-04-04 23:05:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:05:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodPending
2022-04-04 23:05:12 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e2ac67f5 in namespace namespace-101
2022-04-04 23:05:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:05:22 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-101 for test case:testKafkaPodPending
2022-04-04 23:06:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPending-FINISHED
2022-04-04 23:06:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:06:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:06:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaTopicRFLowerThanMinInSyncReplicas-STARTED
2022-04-04 23:06:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:06:05 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-102 for test case:testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-04 23:06:05 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-102
2022-04-04 23:06:05 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-102
2022-04-04 23:06:05 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-102
2022-04-04 23:06:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cd423fde in namespace namespace-102
2022-04-04 23:06:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-102
2022-04-04 23:06:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cd423fde will have desired state: Ready
2022-04-04 23:07:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cd423fde is in desired state: Ready
2022-04-04 23:07:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1153959423-177605812 in namespace namespace-102
2022-04-04 23:07:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-102
2022-04-04 23:07:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1153959423-177605812 will have desired state: Ready
2022-04-04 23:07:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1153959423-177605812 is in desired state: Ready
2022-04-04 23:07:28 [main] [32mINFO [m [KafkaRollerIsolatedST:155] Setting KafkaTopic's min.insync.replicas to be higher than replication factor
2022-04-04 23:07:28 [main] [32mINFO [m [KafkaRollerIsolatedST:159] Annotate Kafka StatefulSet my-cluster-cd423fde-kafka with manual rolling update annotation
2022-04-04 23:07:28 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-cd423fde-kafka rolling update
2022-04-04 23:08:33 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-cd423fde-kafka has been successfully rolled
2022-04-04 23:08:33 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-cd423fde-kafka to be ready
2022-04-04 23:09:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cd423fde will have desired state: Ready
2022-04-04 23:09:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cd423fde is in desired state: Ready
2022-04-04 23:09:03 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-cd423fde is ready
2022-04-04 23:09:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:09:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-04 23:09:03 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1153959423-177605812 in namespace namespace-102
2022-04-04 23:09:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cd423fde in namespace namespace-102
2022-04-04 23:09:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:09:13 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-102 for test case:testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-04 23:09:40 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaTopicRFLowerThanMinInSyncReplicas-FINISHED
2022-04-04 23:09:40 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:09:40 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:09:40 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodCrashLooping-STARTED
2022-04-04 23:09:40 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:09:40 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-103 for test case:testKafkaPodCrashLooping
2022-04-04 23:09:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-103
2022-04-04 23:09:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-103
2022-04-04 23:09:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-103
2022-04-04 23:09:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e8b5ff6c in namespace namespace-103
2022-04-04 23:09:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-103
2022-04-04 23:09:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e8b5ff6c will have desired state: Ready
2022-04-04 23:11:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e8b5ff6c is in desired state: Ready
2022-04-04 23:11:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e8b5ff6c will have desired state: NotReady
2022-04-04 23:13:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e8b5ff6c is in desired state: NotReady
2022-04-04 23:13:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e8b5ff6c will have desired state: Ready
2022-04-04 23:18:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e8b5ff6c is in desired state: Ready
2022-04-04 23:18:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:18:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodCrashLooping
2022-04-04 23:18:31 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e8b5ff6c in namespace namespace-103
2022-04-04 23:18:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:18:41 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-103 for test case:testKafkaPodCrashLooping
2022-04-04 23:19:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodCrashLooping-FINISHED
2022-04-04 23:19:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:19:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:19:08 [main] [32mINFO [m [ResourceManager:346] In context KafkaRollerIsolatedST is everything deleted.
2022-04-04 23:19:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,657.374 s - in io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.connect.ConnectIsolatedST
2022-04-04 23:19:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 23:19:33 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-04 23:19:33 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-04 23:19:33 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-04 23:19:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:19:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-04 23:19:33 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:19:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 23:19:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 23:19:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 23:19:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 23:19:43 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:19:43 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 23:19:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 23:19:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 23:19:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 23:19:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 23:20:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:20:09 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-04 23:20:09 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-04 23:20:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-04 23:20:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:20:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-04 23:20:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-04 23:20:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-04 23:20:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:20:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-04 23:20:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-04 23:20:10 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 23:20:10 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-04 23:20:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-04 23:20:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-04 23:20:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-04 23:20:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-04 23:20:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-04 23:20:41 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-04 23:20:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-04 23:20:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:20:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testMultiNodeKafkaConnectWithConnectorCreation-STARTED
2022-04-04 23:20:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:20:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-104 for test case:testMultiNodeKafkaConnectWithConnectorCreation
2022-04-04 23:20:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-104
2022-04-04 23:20:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-104
2022-04-04 23:20:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-104
2022-04-04 23:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4d7a6c30 in namespace namespace-104
2022-04-04 23:20:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:20:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4d7a6c30 will have desired state: Ready
2022-04-04 23:22:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4d7a6c30 is in desired state: Ready
2022-04-04 23:22:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4d7a6c30-scraper in namespace namespace-104
2022-04-04 23:22:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:22:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4d7a6c30-scraper will be ready
2022-04-04 23:22:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4d7a6c30-scraper is ready
2022-04-04 23:22:14 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-4d7a6c30-scraper to be ready
2022-04-04 23:22:24 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-4d7a6c30-scraper is ready
2022-04-04 23:22:24 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-4d7a6c30-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 23:22:24 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-4d7a6c30-allow in namespace namespace-104
2022-04-04 23:22:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:22:24 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 23:22:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-4d7a6c30 in namespace namespace-104
2022-04-04 23:22:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:22:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-4d7a6c30 will have desired state: Ready
2022-04-04 23:23:33 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-4d7a6c30 is in desired state: Ready
2022-04-04 23:23:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-4d7a6c30 in namespace namespace-104
2022-04-04 23:23:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:23:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-4d7a6c30 will have desired state: Ready
2022-04-04 23:23:34 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-4d7a6c30 is in desired state: Ready
2022-04-04 23:23:34 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 23:23:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-104 exec my-cluster-4d7a6c30-connect-76945ffb7d-b25zn -- curl -X GET http://localhost:8083/connectors/my-cluster-4d7a6c30/status
2022-04-04 23:23:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:23:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-4d7a6c30-hello-world-producer in namespace namespace-104
2022-04-04 23:23:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:23:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-4d7a6c30-hello-world-consumer in namespace namespace-104
2022-04-04 23:23:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-04 23:23:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-4d7a6c30-hello-world-producer will be in active state
2022-04-04 23:23:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-4d7a6c30-hello-world-consumer will be in active state
2022-04-04 23:23:35 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-4d7a6c30-hello-world-producer and consumer my-cluster-4d7a6c30-hello-world-consumer finish
2022-04-04 23:23:53 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-4d7a6c30-connect-76945ffb7d-ffjqk
2022-04-04 23:23:53 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-4d7a6c30-connect-76945ffb7d-ffjqk
2022-04-04 23:23:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:23:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultiNodeKafkaConnectWithConnectorCreation
2022-04-04 23:23:53 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-4d7a6c30 in namespace namespace-104
2022-04-04 23:23:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4d7a6c30-scraper in namespace namespace-104
2022-04-04 23:23:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-4d7a6c30-hello-world-consumer in namespace namespace-104
2022-04-04 23:23:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-4d7a6c30 in namespace namespace-104
2022-04-04 23:23:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-4d7a6c30-hello-world-producer in namespace namespace-104
2022-04-04 23:23:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4d7a6c30 in namespace namespace-104
2022-04-04 23:24:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-4d7a6c30-allow in namespace namespace-104
2022-04-04 23:24:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:24:33 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-104 for test case:testMultiNodeKafkaConnectWithConnectorCreation
2022-04-04 23:24:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testMultiNodeKafkaConnectWithConnectorCreation-FINISHED
2022-04-04 23:24:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:24:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:24:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectScaleUpScaleDown-STARTED
2022-04-04 23:24:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:24:39 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-105 for test case:testKafkaConnectScaleUpScaleDown
2022-04-04 23:24:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-105
2022-04-04 23:24:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-105
2022-04-04 23:24:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-105
2022-04-04 23:24:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-96d70c71 in namespace namespace-105
2022-04-04 23:24:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-105
2022-04-04 23:24:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-96d70c71 will have desired state: Ready
2022-04-04 23:26:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-96d70c71 is in desired state: Ready
2022-04-04 23:26:00 [main] [32mINFO [m [ConnectIsolatedST:395] Running kafkaConnectScaleUP namespace-105 in namespace
2022-04-04 23:26:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-96d70c71 in namespace namespace-105
2022-04-04 23:26:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-105
2022-04-04 23:26:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-96d70c71 will have desired state: Ready
2022-04-04 23:27:04 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-96d70c71 is in desired state: Ready
2022-04-04 23:27:04 [main] [32mINFO [m [ConnectIsolatedST:407] Scaling up to 4
2022-04-04 23:27:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-96d70c71-connect will be ready
2022-04-04 23:27:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-96d70c71-connect is ready
2022-04-04 23:27:04 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-96d70c71-connect to be ready
2022-04-04 23:28:24 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-96d70c71-connect is ready
2022-04-04 23:28:24 [main] [32mINFO [m [ConnectIsolatedST:414] Scaling down to 1
2022-04-04 23:28:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-96d70c71-connect will be ready
2022-04-04 23:28:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-96d70c71-connect is ready
2022-04-04 23:28:24 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-96d70c71-connect to be ready
2022-04-04 23:28:47 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-96d70c71-connect is ready
2022-04-04 23:28:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:28:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectScaleUpScaleDown
2022-04-04 23:28:47 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-96d70c71 in namespace namespace-105
2022-04-04 23:28:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-96d70c71 in namespace namespace-105
2022-04-04 23:28:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:28:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-105 for test case:testKafkaConnectScaleUpScaleDown
2022-04-04 23:29:40 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectScaleUpScaleDown-FINISHED
2022-04-04 23:29:40 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:29:40 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:29:40 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectAndConnectorSubresource-STARTED
2022-04-04 23:29:40 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:29:40 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-106 for test case:testScaleConnectAndConnectorSubresource
2022-04-04 23:29:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-106
2022-04-04 23:29:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-106
2022-04-04 23:29:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-106
2022-04-04 23:29:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7b5f07af in namespace namespace-106
2022-04-04 23:29:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-04 23:29:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7b5f07af will have desired state: Ready
2022-04-04 23:30:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7b5f07af is in desired state: Ready
2022-04-04 23:30:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-7b5f07af in namespace namespace-106
2022-04-04 23:30:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-04 23:30:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-7b5f07af will have desired state: Ready
2022-04-04 23:32:04 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-7b5f07af is in desired state: Ready
2022-04-04 23:32:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-7b5f07af in namespace namespace-106
2022-04-04 23:32:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-04 23:32:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-7b5f07af will have desired state: Ready
2022-04-04 23:32:05 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-7b5f07af is in desired state: Ready
2022-04-04 23:32:05 [main] [32mINFO [m [ConnectIsolatedST:979] -------> Scaling KafkaConnect subresource <-------
2022-04-04 23:32:05 [main] [32mINFO [m [ConnectIsolatedST:980] Scaling subresource replicas to 4
2022-04-04 23:32:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7b5f07af-connect will be ready
2022-04-04 23:32:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7b5f07af-connect is ready
2022-04-04 23:32:05 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-7b5f07af-connect to be ready
2022-04-04 23:33:23 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-7b5f07af-connect is ready
2022-04-04 23:33:23 [main] [32mINFO [m [ConnectIsolatedST:984] Check if replicas is set to 4, observed generation is higher - for spec and status - naming prefix should be same
2022-04-04 23:33:23 [main] [32mINFO [m [ConnectIsolatedST:998] -------> Scaling KafkaConnector subresource <-------
2022-04-04 23:33:23 [main] [32mINFO [m [ConnectIsolatedST:999] Scaling subresource task max to 4
2022-04-04 23:33:24 [main] [32mINFO [m [ConnectIsolatedST:1003] Check if taskMax is set to 4
2022-04-04 23:33:24 [main] [32mINFO [m [ConnectIsolatedST:1007] Check taskMax on Connect pods API
2022-04-04 23:33:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-7b5f07af-connect-75bcb55b7-62w9t -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-7b5f07af
2022-04-04 23:33:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:33:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-7b5f07af-connect-75bcb55b7-85jnp -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-7b5f07af
2022-04-04 23:33:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:33:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-7b5f07af-connect-75bcb55b7-shs89 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-7b5f07af
2022-04-04 23:33:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:33:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-7b5f07af-connect-75bcb55b7-wsnp9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-7b5f07af
2022-04-04 23:33:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:33:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:33:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectAndConnectorSubresource
2022-04-04 23:33:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-7b5f07af in namespace namespace-106
2022-04-04 23:33:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-7b5f07af in namespace namespace-106
2022-04-04 23:33:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7b5f07af in namespace namespace-106
2022-04-04 23:33:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:33:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-106 for test case:testScaleConnectAndConnectorSubresource
2022-04-04 23:34:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectAndConnectorSubresource-FINISHED
2022-04-04 23:34:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:34:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:34:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin-STARTED
2022-04-04 23:34:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:34:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-107 for test case:testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-04 23:34:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-107
2022-04-04 23:34:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-107
2022-04-04 23:34:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-107
2022-04-04 23:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cdbb92d4 in namespace namespace-107
2022-04-04 23:34:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:34:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cdbb92d4 will have desired state: Ready
2022-04-04 23:35:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cdbb92d4 is in desired state: Ready
2022-04-04 23:35:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2107957616-779617645 in namespace namespace-107
2022-04-04 23:35:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:35:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2107957616-779617645 will have desired state: Ready
2022-04-04 23:35:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2107957616-779617645 is in desired state: Ready
2022-04-04 23:35:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-cdbb92d4-scraper in namespace namespace-107
2022-04-04 23:35:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:35:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-cdbb92d4-scraper will be ready
2022-04-04 23:35:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-cdbb92d4-scraper is ready
2022-04-04 23:35:39 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-cdbb92d4-scraper to be ready
2022-04-04 23:35:49 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-cdbb92d4-scraper is ready
2022-04-04 23:35:49 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-cdbb92d4-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 23:35:49 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-cdbb92d4-allow in namespace namespace-107
2022-04-04 23:35:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:35:49 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 23:35:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-cdbb92d4 in namespace namespace-107
2022-04-04 23:35:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:35:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-cdbb92d4 will have desired state: Ready
2022-04-04 23:36:56 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-cdbb92d4 is in desired state: Ready
2022-04-04 23:36:56 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-04 23:36:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-107 exec my-cluster-cdbb92d4-connect-588946cbd6-ppvnl -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-04 23:36:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:36:56 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-04 23:36:56 [main] [32mINFO [m [ConnectIsolatedST:181] Creating KafkaConnector with 'pause: true'
2022-04-04 23:36:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-cdbb92d4 in namespace namespace-107
2022-04-04 23:36:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:36:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-cdbb92d4 will have desired state: Ready
2022-04-04 23:36:57 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-cdbb92d4 is in desired state: Ready
2022-04-04 23:36:57 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 23:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-cdbb92d4-hello-world-producer in namespace namespace-107
2022-04-04 23:36:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-cdbb92d4-hello-world-consumer in namespace namespace-107
2022-04-04 23:36:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:36:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-cdbb92d4-hello-world-producer will be in active state
2022-04-04 23:36:58 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-cdbb92d4-hello-world-consumer will be in active state
2022-04-04 23:36:58 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-cdbb92d4-hello-world-producer and consumer my-cluster-cdbb92d4-hello-world-consumer finish
2022-04-04 23:37:14 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-cdbb92d4-connect-588946cbd6-ppvnl
2022-04-04 23:37:14 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-cdbb92d4-connect-588946cbd6-ppvnl
2022-04-04 23:37:14 [main] [32mINFO [m [ConnectIsolatedST:207] Pausing KafkaConnector: my-cluster-cdbb92d4
2022-04-04 23:37:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-cdbb92d4 will have desired state: Ready
2022-04-04 23:37:14 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-cdbb92d4 is in desired state: Ready
2022-04-04 23:37:14 [main] [32mINFO [m [ConnectIsolatedST:213] Clearing FileSink file to check if KafkaConnector will be really paused
2022-04-04 23:37:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-107 exec my-cluster-cdbb92d4-connect-588946cbd6-ppvnl -- /bin/bash -c truncate -s 0 /tmp/test-file-sink.txt
2022-04-04 23:37:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:37:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-cdbb92d4-hello-world-producer in namespace namespace-107
2022-04-04 23:37:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:37:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-cdbb92d4-hello-world-consumer in namespace namespace-107
2022-04-04 23:37:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-04 23:37:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-cdbb92d4-hello-world-producer will be in active state
2022-04-04 23:37:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-cdbb92d4-hello-world-consumer will be in active state
2022-04-04 23:37:15 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-cdbb92d4-hello-world-producer and consumer my-cluster-cdbb92d4-hello-world-consumer finish
2022-04-04 23:38:00 [main] [32mINFO [m [ConnectIsolatedST:219] Because KafkaConnector is paused, no messages should appear to FileSink file
2022-04-04 23:38:00 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-cdbb92d4-connect-588946cbd6-ppvnl
io.strimzi.test.WaitException: Timeout after 60000 ms waiting for messages in file sink
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(KafkaConnectUtils.java:75)
	at io.strimzi.systemtest.connect.ConnectIsolatedST.lambda$testKafkaConnectAndPausedConnectorWithFileSinkPlugin$1(ConnectIsolatedST.java:220)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:55)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:37)
	at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3082)
	at io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin(ConnectIsolatedST.java:220)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-04 23:39:00 [main] [32mINFO [m [ConnectIsolatedST:222] Unpausing KafkaConnector, messages should again appear to FileSink file
2022-04-04 23:39:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-cdbb92d4 will have desired state: Ready
2022-04-04 23:39:00 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-cdbb92d4 is in desired state: Ready
2022-04-04 23:39:00 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-cdbb92d4-connect-588946cbd6-ppvnl
2022-04-04 23:39:00 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-cdbb92d4-connect-588946cbd6-ppvnl
2022-04-04 23:39:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:39:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-04 23:39:00 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-cdbb92d4-hello-world-producer in namespace namespace-107
2022-04-04 23:39:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-cdbb92d4-scraper in namespace namespace-107
2022-04-04 23:39:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2107957616-779617645 in namespace namespace-107
2022-04-04 23:39:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-cdbb92d4-hello-world-producer in namespace namespace-107
2022-04-04 23:39:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-cdbb92d4-hello-world-consumer in namespace namespace-107
2022-04-04 23:39:00 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-cdbb92d4 in namespace namespace-107
2022-04-04 23:39:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-cdbb92d4-hello-world-consumer in namespace namespace-107
2022-04-04 23:39:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-cdbb92d4 in namespace namespace-107
2022-04-04 23:39:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-cdbb92d4-allow in namespace namespace-107
2022-04-04 23:39:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cdbb92d4 in namespace namespace-107
2022-04-04 23:39:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:39:40 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-107 for test case:testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-04 23:39:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin-FINISHED
2022-04-04 23:39:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:39:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:39:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged-STARTED
2022-04-04 23:39:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:39:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-108 for test case:testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-04 23:39:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-108
2022-04-04 23:39:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-108
2022-04-04 23:39:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-108
2022-04-04 23:39:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f9063481 in namespace namespace-108
2022-04-04 23:39:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-04 23:39:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f9063481 will have desired state: Ready
2022-04-04 23:41:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f9063481 is in desired state: Ready
2022-04-04 23:41:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-546536090-545563930 in namespace namespace-108
2022-04-04 23:41:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-04 23:41:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-546536090-545563930 will have desired state: Ready
2022-04-04 23:41:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-546536090-545563930 is in desired state: Ready
2022-04-04 23:41:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-546536090-545563930 in namespace namespace-108
2022-04-04 23:41:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-04 23:41:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-546536090-545563930 will have desired state: Ready
2022-04-04 23:41:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-546536090-545563930 is in desired state: Ready
2022-04-04 23:41:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-544944419-724232751 in namespace namespace-108
2022-04-04 23:41:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-04 23:41:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-544944419-724232751 will have desired state: Ready
2022-04-04 23:41:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-544944419-724232751 is in desired state: Ready
2022-04-04 23:41:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-f9063481 in namespace namespace-108
2022-04-04 23:41:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-04 23:41:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-f9063481 will have desired state: Ready
2022-04-04 23:42:19 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-f9063481 is in desired state: Ready
2022-04-04 23:42:19 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-04 23:42:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-108 exec my-cluster-f9063481-connect-5b558b9c64-hpqfm -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-04 23:42:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:42:19 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-04 23:42:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-546536090-545563930 in namespace namespace-108
2022-04-04 23:42:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-04 23:42:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-546536090-545563930 will have desired state: Ready
2022-04-04 23:42:19 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-546536090-545563930 is in desired state: Ready
2022-04-04 23:42:19 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f9063481-connect rolling update
2022-04-04 23:44:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f9063481-connect will be ready
2022-04-04 23:44:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f9063481-connect is ready
2022-04-04 23:44:10 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f9063481-connect rolling update finished
2022-04-04 23:44:10 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-04 23:44:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-108 exec my-cluster-f9063481-connect-856644d757-ml6ls -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-04 23:44:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:44:10 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-04 23:44:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:44:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-04 23:44:10 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-544944419-724232751 in namespace namespace-108
2022-04-04 23:44:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-546536090-545563930 in namespace namespace-108
2022-04-04 23:44:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-546536090-545563930 in namespace namespace-108
2022-04-04 23:44:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f9063481 in namespace namespace-108
2022-04-04 23:44:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-546536090-545563930 in namespace namespace-108
2022-04-04 23:44:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-f9063481 in namespace namespace-108
2022-04-04 23:44:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:44:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-108 for test case:testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-04 23:44:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged-FINISHED
2022-04-04 23:44:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:44:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:44:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication-STARTED
2022-04-04 23:44:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:44:57 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-109 for test case:testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-04 23:44:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-109
2022-04-04 23:44:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-109
2022-04-04 23:44:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-109
2022-04-04 23:44:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-098ca521 in namespace namespace-109
2022-04-04 23:44:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:44:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-098ca521 will have desired state: Ready
2022-04-04 23:46:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-098ca521 is in desired state: Ready
2022-04-04 23:46:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-098ca521-user in namespace namespace-109
2022-04-04 23:46:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:46:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-098ca521-user will have desired state: Ready
2022-04-04 23:46:19 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-098ca521-user is in desired state: Ready
2022-04-04 23:46:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1839594187-1232915388 in namespace namespace-109
2022-04-04 23:46:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:46:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1839594187-1232915388 will have desired state: Ready
2022-04-04 23:46:20 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1839594187-1232915388 is in desired state: Ready
2022-04-04 23:46:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-098ca521-scraper in namespace namespace-109
2022-04-04 23:46:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:46:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-098ca521-scraper will be ready
2022-04-04 23:46:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-098ca521-scraper is ready
2022-04-04 23:46:21 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-098ca521-scraper to be ready
2022-04-04 23:46:32 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-098ca521-scraper is ready
2022-04-04 23:46:32 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-098ca521-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 23:46:32 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-098ca521-allow in namespace namespace-109
2022-04-04 23:46:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:46:32 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 23:46:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-098ca521 in namespace namespace-109
2022-04-04 23:46:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:46:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-098ca521 will have desired state: Ready
2022-04-04 23:47:34 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-098ca521 is in desired state: Ready
2022-04-04 23:47:34 [main] [32mINFO [m [ConnectIsolatedST:547] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-04 23:47:34 [main] [32mINFO [m [ConnectIsolatedST:550] Creating FileStreamSink connector via pod my-cluster-098ca521-scraper-54f65c996b-lhdd2 with topic my-topic-1839594187-1232915388
2022-04-04 23:47:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-109 exec my-cluster-098ca521-scraper-54f65c996b-lhdd2 -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-1839594187-1232915388", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-098ca521-connect-api.namespace-109.svc:8083/connectors
2022-04-04 23:47:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:47:34 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 23:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-098ca521-hello-world-producer in namespace namespace-109
2022-04-04 23:47:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-098ca521-hello-world-consumer in namespace namespace-109
2022-04-04 23:47:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-04 23:47:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-098ca521-hello-world-producer will be in active state
2022-04-04 23:47:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-098ca521-hello-world-consumer will be in active state
2022-04-04 23:47:35 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-098ca521-hello-world-producer and consumer my-cluster-098ca521-hello-world-consumer finish
2022-04-04 23:47:48 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-098ca521-connect-7c6fcc9778-slmkh
2022-04-04 23:47:48 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-098ca521-connect-7c6fcc9778-slmkh
2022-04-04 23:47:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:47:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-04 23:47:48 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-098ca521 in namespace namespace-109
2022-04-04 23:47:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-098ca521-hello-world-consumer in namespace namespace-109
2022-04-04 23:47:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1839594187-1232915388 in namespace namespace-109
2022-04-04 23:47:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-098ca521-allow in namespace namespace-109
2022-04-04 23:47:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-098ca521-hello-world-producer in namespace namespace-109
2022-04-04 23:47:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-098ca521-user in namespace namespace-109
2022-04-04 23:47:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-098ca521 in namespace namespace-109
2022-04-04 23:47:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-098ca521-scraper in namespace namespace-109
2022-04-04 23:48:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:48:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-109 for test case:testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-04 23:48:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication-FINISHED
2022-04-04 23:48:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:48:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:48:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-04 23:48:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:48:43 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-110 for test case:testConfigureDeploymentStrategy
2022-04-04 23:48:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-110
2022-04-04 23:48:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-110
2022-04-04 23:48:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-110
2022-04-04 23:48:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d996aded in namespace namespace-110
2022-04-04 23:48:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-110
2022-04-04 23:48:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d996aded will have desired state: Ready
2022-04-04 23:50:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d996aded is in desired state: Ready
2022-04-04 23:50:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-d996aded in namespace namespace-110
2022-04-04 23:50:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-110
2022-04-04 23:50:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-d996aded will have desired state: Ready
2022-04-04 23:51:07 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-d996aded is in desired state: Ready
2022-04-04 23:51:07 [main] [32mINFO [m [ConnectIsolatedST:1191] Adding label to Connect resource, the CR should be recreated
2022-04-04 23:51:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d996aded-connect will be ready
2022-04-04 23:51:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d996aded-connect is ready
2022-04-04 23:51:07 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-d996aded-connect to be ready
2022-04-04 23:52:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-d996aded-connect is ready
2022-04-04 23:52:30 [main] [32mINFO [m [ConnectIsolatedST:1198] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-04 23:52:30 [main] [32mINFO [m [ConnectIsolatedST:1203] Changing deployment strategy to ROLLING_UPDATE
2022-04-04 23:52:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-d996aded will have desired state: Ready
2022-04-04 23:52:30 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-d996aded is in desired state: Ready
2022-04-04 23:52:30 [main] [32mINFO [m [ConnectIsolatedST:1208] Adding another label to Connect resource, pods should be rolled
2022-04-04 23:52:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d996aded-connect will be ready
2022-04-04 23:52:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d996aded-connect is ready
2022-04-04 23:52:30 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-d996aded-connect to be ready
2022-04-04 23:53:56 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-d996aded-connect is ready
2022-04-04 23:53:56 [main] [32mINFO [m [ConnectIsolatedST:1212] Checking that observed gen. higher (rolling update) and label is changed
2022-04-04 23:53:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:53:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-04 23:53:56 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-d996aded in namespace namespace-110
2022-04-04 23:53:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d996aded in namespace namespace-110
2022-04-04 23:54:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:54:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-110 for test case:testConfigureDeploymentStrategy
2022-04-04 23:54:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-04 23:54:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:54:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:54:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndConnectorFileSinkPlugin-STARTED
2022-04-04 23:54:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:54:49 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-111 for test case:testKafkaConnectAndConnectorFileSinkPlugin
2022-04-04 23:54:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-111
2022-04-04 23:54:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-111
2022-04-04 23:54:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-111
2022-04-04 23:54:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-dd1152b5 in namespace namespace-111
2022-04-04 23:54:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-04 23:54:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-dd1152b5 will have desired state: Ready
2022-04-04 23:56:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-dd1152b5 is in desired state: Ready
2022-04-04 23:56:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-dd1152b5-scraper in namespace namespace-111
2022-04-04 23:56:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-04 23:56:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-dd1152b5-scraper will be ready
2022-04-04 23:56:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-dd1152b5-scraper is ready
2022-04-04 23:56:11 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-dd1152b5-scraper to be ready
2022-04-04 23:56:21 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-dd1152b5-scraper is ready
2022-04-04 23:56:21 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-dd1152b5-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 23:56:21 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-dd1152b5-allow in namespace namespace-111
2022-04-04 23:56:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-04 23:56:21 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 23:56:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-dd1152b5 in namespace namespace-111
2022-04-04 23:56:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-04 23:56:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-dd1152b5 will have desired state: Ready
2022-04-04 23:57:23 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-dd1152b5 is in desired state: Ready
2022-04-04 23:57:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector license-source in namespace namespace-111
2022-04-04 23:57:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-04 23:57:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: license-source will have desired state: Ready
2022-04-04 23:57:24 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: license-source is in desired state: Ready
2022-04-04 23:57:24 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-04 23:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-dd1152b5-hello-world-consumer in namespace namespace-111
2022-04-04 23:57:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-04 23:57:24 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-dd1152b5-hello-world-consumer will be in active state
2022-04-04 23:57:25 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-dd1152b5-hello-world-consumer to finished
2022-04-04 23:57:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-111 exec my-cluster-dd1152b5-scraper-5bcbd45dc9-k7rpq -- /bin/bash -c curl http://my-cluster-dd1152b5-connect-api.namespace-111.svc:8083/connectors/license-source
2022-04-04 23:57:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-04 23:57:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-04 23:57:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndConnectorFileSinkPlugin
2022-04-04 23:57:36 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-dd1152b5 in namespace namespace-111
2022-04-04 23:57:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-dd1152b5-scraper in namespace namespace-111
2022-04-04 23:57:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-dd1152b5-hello-world-consumer in namespace namespace-111
2022-04-04 23:57:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector license-source in namespace namespace-111
2022-04-04 23:57:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-dd1152b5 in namespace namespace-111
2022-04-04 23:57:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-dd1152b5-allow in namespace namespace-111
2022-04-04 23:58:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-04 23:58:16 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-111 for test case:testKafkaConnectAndConnectorFileSinkPlugin
2022-04-04 23:58:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndConnectorFileSinkPlugin-FINISHED
2022-04-04 23:58:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-04 23:58:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-04 23:58:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testDeployUndeploy-STARTED
2022-04-04 23:58:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-04 23:58:27 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-112 for test case:testDeployUndeploy
2022-04-04 23:58:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-112
2022-04-04 23:58:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-112
2022-04-04 23:58:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-112
2022-04-04 23:58:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1f19ec35 in namespace namespace-112
2022-04-04 23:58:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-04 23:58:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1f19ec35 will have desired state: Ready
2022-04-04 23:59:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1f19ec35 is in desired state: Ready
2022-04-04 23:59:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1f19ec35-scraper in namespace namespace-112
2022-04-04 23:59:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-04 23:59:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1f19ec35-scraper will be ready
2022-04-04 23:59:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1f19ec35-scraper is ready
2022-04-04 23:59:42 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-1f19ec35-scraper to be ready
2022-04-04 23:59:52 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-1f19ec35-scraper is ready
2022-04-04 23:59:52 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-1f19ec35-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-04 23:59:52 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-1f19ec35-allow in namespace namespace-112
2022-04-04 23:59:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-04 23:59:52 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-04 23:59:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-1f19ec35 in namespace namespace-112
2022-04-04 23:59:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-04 23:59:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-1f19ec35 will have desired state: Ready
2022-04-05 00:01:01 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-1f19ec35 is in desired state: Ready
2022-04-05 00:01:01 [main] [32mINFO [m [ConnectIsolatedST:123] Looks like the connect cluster my-cluster deployed OK
2022-04-05 00:01:01 [main] [32mINFO [m [ConnectIsolatedST:140] Verifying docker image names
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-05 00:01:01 [main] [32mINFO [m [ConnectIsolatedST:152] Docker images verified
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type connect
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-1f19ec35-connect-7465c568d7-mqjgf
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:362] Verifying labels for service my-cluster-1f19ec35-connect-api
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1f19ec35-connect-config
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1f19ec35-entity-topic-operator-config
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:407] CM my-cluster-1f19ec35-entity-topic-operator-config is not related to current test
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1f19ec35-entity-user-operator-config
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:407] CM my-cluster-1f19ec35-entity-user-operator-config is not related to current test
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1f19ec35-kafka-config
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1f19ec35-zookeeper-config
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:407] CM my-cluster-1f19ec35-zookeeper-config is not related to current test
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-1f19ec35-connect
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-1f19ec35-entity-operator
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-1f19ec35-kafka
2022-04-05 00:01:01 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-1f19ec35-zookeeper
2022-04-05 00:01:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:01:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployUndeploy
2022-04-05 00:01:01 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-1f19ec35-allow in namespace namespace-112
2022-04-05 00:01:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1f19ec35-scraper in namespace namespace-112
2022-04-05 00:01:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1f19ec35 in namespace namespace-112
2022-04-05 00:01:01 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-1f19ec35 in namespace namespace-112
2022-04-05 00:01:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:01:51 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-112 for test case:testDeployUndeploy
2022-04-05 00:01:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testDeployUndeploy-FINISHED
2022-04-05 00:01:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:01:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:01:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testMountingSecretAndConfigMapAsVolumesAndEnvVars-STARTED
2022-04-05 00:01:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:01:57 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-113 for test case:testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-05 00:01:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-113
2022-04-05 00:01:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-113
2022-04-05 00:01:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-113
2022-04-05 00:01:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-32456266 in namespace namespace-113
2022-04-05 00:01:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-113
2022-04-05 00:01:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-32456266 will have desired state: Ready
2022-04-05 00:03:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-32456266 is in desired state: Ready
2022-04-05 00:03:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-32456266 in namespace namespace-113
2022-04-05 00:03:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-113
2022-04-05 00:03:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-32456266 will have desired state: Ready
2022-04-05 00:04:24 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-32456266 is in desired state: Ready
2022-04-05 00:04:24 [main] [32mINFO [m [ConnectIsolatedST:1148] Check if the ENVs contains desired values
2022-04-05 00:04:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-32456266-connect-868799f5b9-98qft -- /bin/bash -c printenv MY_CONNECT_SECRET
2022-04-05 00:04:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:04:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-32456266-connect-868799f5b9-98qft -- /bin/bash -c printenv MY_CONNECT_CONFIG_MAP
2022-04-05 00:04:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:04:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-32456266-connect-868799f5b9-98qft -- /bin/bash -c printenv MY_DOTED_CONNECT_SECRET
2022-04-05 00:04:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:04:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-32456266-connect-868799f5b9-98qft -- /bin/bash -c printenv MY_DOTED_CONNECT_CONFIG_MAP
2022-04-05 00:04:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:04:25 [main] [32mINFO [m [ConnectIsolatedST:1154] Check if volumes contains desired values
2022-04-05 00:04:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-32456266-connect-868799f5b9-98qft -- /bin/bash -c cat external-configuration/connect-config-map/my-key
2022-04-05 00:04:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:04:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-32456266-connect-868799f5b9-98qft -- /bin/bash -c cat external-configuration/connect-secret/my-secret-key
2022-04-05 00:04:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:04:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-32456266-connect-868799f5b9-98qft -- /bin/bash -c cat external-configuration/connect.config.map/my-key
2022-04-05 00:04:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:04:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-32456266-connect-868799f5b9-98qft -- /bin/bash -c cat external-configuration/connect.secret/my-secret-key
2022-04-05 00:04:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:04:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:04:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-05 00:04:26 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-32456266 in namespace namespace-113
2022-04-05 00:04:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-32456266 in namespace namespace-113
2022-04-05 00:04:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:04:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-113 for test case:testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-05 00:05:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testMountingSecretAndConfigMapAsVolumesAndEnvVars-FINISHED
2022-04-05 00:05:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:05:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:05:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testJvmAndResources-STARTED
2022-04-05 00:05:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:05:19 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-114 for test case:testJvmAndResources
2022-04-05 00:05:19 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-114
2022-04-05 00:05:19 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-114
2022-04-05 00:05:19 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-114
2022-04-05 00:05:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f7e6db3d in namespace namespace-114
2022-04-05 00:05:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-05 00:05:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f7e6db3d will have desired state: Ready
2022-04-05 00:06:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f7e6db3d is in desired state: Ready
2022-04-05 00:06:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f7e6db3d-kafka-clients in namespace namespace-114
2022-04-05 00:06:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-05 00:06:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f7e6db3d-kafka-clients will be ready
2022-04-05 00:06:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f7e6db3d-kafka-clients is ready
2022-04-05 00:06:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f7e6db3d-scraper in namespace namespace-114
2022-04-05 00:06:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-05 00:06:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f7e6db3d-scraper will be ready
2022-04-05 00:06:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f7e6db3d-scraper is ready
2022-04-05 00:06:41 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-f7e6db3d-scraper to be ready
2022-04-05 00:06:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-f7e6db3d-scraper is ready
2022-04-05 00:06:51 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-f7e6db3d-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 00:06:51 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-f7e6db3d-allow in namespace namespace-114
2022-04-05 00:06:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-05 00:06:51 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 00:06:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-f7e6db3d in namespace namespace-114
2022-04-05 00:06:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-05 00:06:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-f7e6db3d will have desired state: Ready
2022-04-05 00:07:59 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-f7e6db3d is in desired state: Ready
2022-04-05 00:07:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-114 exec my-cluster-f7e6db3d-connect-7c8b649658-z7wts -c my-cluster-f7e6db3d-connect -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-05 00:07:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:07:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:07:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJvmAndResources
2022-04-05 00:07:59 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f7e6db3d-scraper in namespace namespace-114
2022-04-05 00:07:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f7e6db3d-kafka-clients in namespace namespace-114
2022-04-05 00:07:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-f7e6db3d in namespace namespace-114
2022-04-05 00:07:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f7e6db3d in namespace namespace-114
2022-04-05 00:08:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-f7e6db3d-allow in namespace namespace-114
2022-04-05 00:08:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:08:39 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-114 for test case:testJvmAndResources
2022-04-05 00:08:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testJvmAndResources-FINISHED
2022-04-05 00:08:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:08:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:08:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication-STARTED
2022-04-05 00:08:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:08:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-115 for test case:testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-05 00:08:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-115
2022-04-05 00:08:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-115
2022-04-05 00:08:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-115
2022-04-05 00:08:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9fd63358 in namespace namespace-115
2022-04-05 00:08:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-05 00:08:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9fd63358 will have desired state: Ready
2022-04-05 00:10:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9fd63358 is in desired state: Ready
2022-04-05 00:10:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-9fd63358-user in namespace namespace-115
2022-04-05 00:10:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-05 00:10:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-9fd63358-user will have desired state: Ready
2022-04-05 00:10:03 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-9fd63358-user is in desired state: Ready
2022-04-05 00:10:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-826753631-51461160 in namespace namespace-115
2022-04-05 00:10:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-05 00:10:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-826753631-51461160 will have desired state: Ready
2022-04-05 00:10:04 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-826753631-51461160 is in desired state: Ready
2022-04-05 00:10:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-9fd63358-scraper in namespace namespace-115
2022-04-05 00:10:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-05 00:10:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9fd63358-scraper will be ready
2022-04-05 00:10:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9fd63358-scraper is ready
2022-04-05 00:10:06 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-9fd63358-scraper to be ready
2022-04-05 00:10:16 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-9fd63358-scraper is ready
2022-04-05 00:10:16 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-9fd63358-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 00:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-9fd63358-allow in namespace namespace-115
2022-04-05 00:10:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-05 00:10:16 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 00:10:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-9fd63358 in namespace namespace-115
2022-04-05 00:10:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-05 00:10:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-9fd63358 will have desired state: Ready
2022-04-05 00:11:19 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-9fd63358 is in desired state: Ready
2022-04-05 00:11:19 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-05 00:11:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-115 exec my-cluster-9fd63358-connect-bc684767-qfq4g -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-05 00:11:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:11:19 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-05 00:11:19 [main] [32mINFO [m [ConnectIsolatedST:474] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-05 00:11:19 [main] [32mINFO [m [ConnectIsolatedST:477] Creating FileStreamSink connector via pod my-cluster-9fd63358-scraper-f8b75f54-hwgc5 with topic my-topic-826753631-51461160
2022-04-05 00:11:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-115 exec my-cluster-9fd63358-scraper-f8b75f54-hwgc5 -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-826753631-51461160", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-9fd63358-connect-api.namespace-115.svc:8083/connectors
2022-04-05 00:11:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:11:19 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 00:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-9fd63358-hello-world-producer in namespace namespace-115
2022-04-05 00:11:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-05 00:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-9fd63358-hello-world-consumer in namespace namespace-115
2022-04-05 00:11:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-05 00:11:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-9fd63358-hello-world-producer will be in active state
2022-04-05 00:11:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-9fd63358-hello-world-consumer will be in active state
2022-04-05 00:11:19 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-9fd63358-hello-world-producer and consumer my-cluster-9fd63358-hello-world-consumer finish
2022-04-05 00:11:39 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-9fd63358-connect-bc684767-qfq4g
2022-04-05 00:11:39 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-9fd63358-connect-bc684767-qfq4g
2022-04-05 00:11:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:11:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-05 00:11:39 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-9fd63358 in namespace namespace-115
2022-04-05 00:11:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-9fd63358-hello-world-consumer in namespace namespace-115
2022-04-05 00:11:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-826753631-51461160 in namespace namespace-115
2022-04-05 00:11:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-9fd63358-allow in namespace namespace-115
2022-04-05 00:11:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-9fd63358-hello-world-producer in namespace namespace-115
2022-04-05 00:11:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-9fd63358-user in namespace namespace-115
2022-04-05 00:11:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9fd63358 in namespace namespace-115
2022-04-05 00:11:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-9fd63358-scraper in namespace namespace-115
2022-04-05 00:12:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:12:29 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-115 for test case:testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-05 00:12:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication-FINISHED
2022-04-05 00:12:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:12:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:12:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithoutConnectorToZero-STARTED
2022-04-05 00:12:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:12:34 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-116 for test case:testScaleConnectWithoutConnectorToZero
2022-04-05 00:12:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-116
2022-04-05 00:12:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-116
2022-04-05 00:12:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-116
2022-04-05 00:12:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6146c706 in namespace namespace-116
2022-04-05 00:12:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-116
2022-04-05 00:12:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6146c706 will have desired state: Ready
2022-04-05 00:13:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6146c706 is in desired state: Ready
2022-04-05 00:13:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-6146c706 in namespace namespace-116
2022-04-05 00:13:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-116
2022-04-05 00:13:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-6146c706 will have desired state: Ready
2022-04-05 00:15:04 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-6146c706 is in desired state: Ready
2022-04-05 00:15:04 [main] [32mINFO [m [ConnectIsolatedST:891] Scaling KafkaConnect down to zero
2022-04-05 00:15:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-6146c706 will have desired state: Ready
2022-04-05 00:15:04 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-6146c706 is in desired state: Ready
2022-04-05 00:15:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:15:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectWithoutConnectorToZero
2022-04-05 00:15:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-6146c706 in namespace namespace-116
2022-04-05 00:15:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6146c706 in namespace namespace-116
2022-04-05 00:15:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:15:27 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-116 for test case:testScaleConnectWithoutConnectorToZero
2022-04-05 00:15:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithoutConnectorToZero-FINISHED
2022-04-05 00:15:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:15:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:15:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithConnectorToZero-STARTED
2022-04-05 00:15:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:15:54 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-117 for test case:testScaleConnectWithConnectorToZero
2022-04-05 00:15:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-117
2022-04-05 00:15:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-117
2022-04-05 00:15:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-117
2022-04-05 00:15:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-033df4ec in namespace namespace-117
2022-04-05 00:15:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-05 00:15:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-033df4ec will have desired state: Ready
2022-04-05 00:17:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-033df4ec is in desired state: Ready
2022-04-05 00:17:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-033df4ec in namespace namespace-117
2022-04-05 00:17:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-05 00:17:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-033df4ec will have desired state: Ready
2022-04-05 00:18:23 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-033df4ec is in desired state: Ready
2022-04-05 00:18:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-033df4ec in namespace namespace-117
2022-04-05 00:18:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-05 00:18:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-033df4ec will have desired state: Ready
2022-04-05 00:18:24 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-033df4ec is in desired state: Ready
2022-04-05 00:18:24 [main] [32mINFO [m [ConnectIsolatedST:934] Scaling KafkaConnect down to zero
2022-04-05 00:18:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-033df4ec will have desired state: Ready
2022-04-05 00:18:24 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-033df4ec is in desired state: Ready
2022-04-05 00:18:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:18:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectWithConnectorToZero
2022-04-05 00:18:37 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-033df4ec in namespace namespace-117
2022-04-05 00:18:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-033df4ec in namespace namespace-117
2022-04-05 00:18:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-033df4ec in namespace namespace-117
2022-04-05 00:18:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:18:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-117 for test case:testScaleConnectWithConnectorToZero
2022-04-05 00:19:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithConnectorToZero-FINISHED
2022-04-05 00:19:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:19:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:19:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithPlainAndScramShaAuthentication-STARTED
2022-04-05 00:19:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:19:30 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-118 for test case:testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-05 00:19:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-118
2022-04-05 00:19:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-118
2022-04-05 00:19:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-118
2022-04-05 00:19:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4e4116a9 in namespace namespace-118
2022-04-05 00:19:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:19:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4e4116a9 will have desired state: Ready
2022-04-05 00:20:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4e4116a9 is in desired state: Ready
2022-04-05 00:20:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-4e4116a9-user in namespace namespace-118
2022-04-05 00:20:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:20:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-4e4116a9-user will have desired state: Ready
2022-04-05 00:20:45 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-4e4116a9-user is in desired state: Ready
2022-04-05 00:20:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1505547598-1304897866 in namespace namespace-118
2022-04-05 00:20:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:20:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1505547598-1304897866 will have desired state: Ready
2022-04-05 00:20:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1505547598-1304897866 is in desired state: Ready
2022-04-05 00:20:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4e4116a9-scraper in namespace namespace-118
2022-04-05 00:20:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:20:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4e4116a9-scraper will be ready
2022-04-05 00:20:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4e4116a9-scraper is ready
2022-04-05 00:20:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-4e4116a9-scraper to be ready
2022-04-05 00:20:58 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-4e4116a9-scraper is ready
2022-04-05 00:20:58 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-4e4116a9-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 00:20:58 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-4e4116a9-allow in namespace namespace-118
2022-04-05 00:20:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:20:58 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 00:20:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-4e4116a9 in namespace namespace-118
2022-04-05 00:20:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:20:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-4e4116a9 will have desired state: Ready
2022-04-05 00:22:03 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-4e4116a9 is in desired state: Ready
2022-04-05 00:22:03 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-05 00:22:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-118 exec my-cluster-4e4116a9-connect-7f587f6f7f-mwzgk -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-05 00:22:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:22:03 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-05 00:22:03 [main] [32mINFO [m [ConnectIsolatedST:280] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-05 00:22:03 [main] [32mINFO [m [ConnectIsolatedST:283] Creating FileStreamSink connector via pod my-cluster-4e4116a9-scraper-58bc5677cb-g7k25 with topic my-topic-1505547598-1304897866
2022-04-05 00:22:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-118 exec my-cluster-4e4116a9-scraper-58bc5677cb-g7k25 -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-1505547598-1304897866", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-4e4116a9-connect-api.namespace-118.svc:8083/connectors
2022-04-05 00:22:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:22:04 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 00:22:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-4e4116a9-hello-world-producer in namespace namespace-118
2022-04-05 00:22:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:22:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-4e4116a9-hello-world-consumer in namespace namespace-118
2022-04-05 00:22:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-05 00:22:04 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-4e4116a9-hello-world-producer will be in active state
2022-04-05 00:22:04 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-4e4116a9-hello-world-consumer will be in active state
2022-04-05 00:22:04 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-4e4116a9-hello-world-producer and consumer my-cluster-4e4116a9-hello-world-consumer finish
2022-04-05 00:22:17 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-4e4116a9-connect-7f587f6f7f-mwzgk
2022-04-05 00:22:17 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-4e4116a9-connect-7f587f6f7f-mwzgk
2022-04-05 00:22:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:22:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-05 00:22:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-4e4116a9 in namespace namespace-118
2022-04-05 00:22:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-4e4116a9-hello-world-consumer in namespace namespace-118
2022-04-05 00:22:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1505547598-1304897866 in namespace namespace-118
2022-04-05 00:22:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-4e4116a9-allow in namespace namespace-118
2022-04-05 00:22:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-4e4116a9-hello-world-producer in namespace namespace-118
2022-04-05 00:22:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-4e4116a9-user in namespace namespace-118
2022-04-05 00:22:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4e4116a9-scraper in namespace namespace-118
2022-04-05 00:22:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4e4116a9 in namespace namespace-118
2022-04-05 00:22:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:22:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-118 for test case:testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-05 00:23:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithPlainAndScramShaAuthentication-FINISHED
2022-04-05 00:23:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:23:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:23:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-05 00:23:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:23:03 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-119 for test case:testCustomAndUpdatedValues
2022-04-05 00:23:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-119
2022-04-05 00:23:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-119
2022-04-05 00:23:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-119
2022-04-05 00:23:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d7244e43 in namespace namespace-119
2022-04-05 00:23:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-119
2022-04-05 00:23:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d7244e43 will have desired state: Ready
2022-04-05 00:24:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d7244e43 is in desired state: Ready
2022-04-05 00:24:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-d7244e43 in namespace namespace-119
2022-04-05 00:24:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-119
2022-04-05 00:24:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-d7244e43 will have desired state: Ready
2022-04-05 00:24:53 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-d7244e43 is in desired state: Ready
2022-04-05 00:24:53 [main] [32mINFO [m [ConnectIsolatedST:629] Verify values before update
2022-04-05 00:24:53 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-d7244e43-connect in pod name
2022-04-05 00:24:53 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-d7244e43-connect
2022-04-05 00:24:53 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-d7244e43-connect
2022-04-05 00:24:53 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-d7244e43-connect
2022-04-05 00:24:53 [main] [32mINFO [m [ConnectIsolatedST:634] Check if actual env variable KAFKA_CONNECT_CONFIGURATION has different value than test.value
2022-04-05 00:24:53 [main] [32mINFO [m [ConnectIsolatedST:640] Updating values in MirrorMaker container
2022-04-05 00:24:53 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-d7244e43-connect rolling update
2022-04-05 00:25:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d7244e43-connect will be ready
2022-04-05 00:25:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d7244e43-connect is ready
2022-04-05 00:25:43 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-d7244e43-connect rolling update finished
2022-04-05 00:25:43 [main] [32mINFO [m [ConnectIsolatedST:657] Verify values after update
2022-04-05 00:25:43 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-d7244e43-connect in pod name
2022-04-05 00:25:43 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-d7244e43-connect
2022-04-05 00:25:43 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-d7244e43-connect
2022-04-05 00:25:43 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-d7244e43-connect
2022-04-05 00:25:43 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-d7244e43-connect
2022-04-05 00:25:43 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-d7244e43-connect
2022-04-05 00:25:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:25:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-05 00:25:43 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-d7244e43 in namespace namespace-119
2022-04-05 00:25:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d7244e43 in namespace namespace-119
2022-04-05 00:25:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:25:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-119 for test case:testCustomAndUpdatedValues
2022-04-05 00:26:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-05 00:26:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:26:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:26:37 [main] [32mINFO [m [ResourceManager:346] In context ConnectIsolatedST is everything deleted.
2022-04-05 00:26:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4,048.469 s - in io.strimzi.systemtest.connect.ConnectIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
2022-04-05 00:26:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 00:27:02 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 00:27:02 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 00:27:02 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 00:27:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:27:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 00:27:02 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 00:27:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:27:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 00:27:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:27:12 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:27:12 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 00:27:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:12 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 00:27:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 00:27:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:27:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 00:27:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 00:27:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 00:27:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 00:27:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:27:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 00:27:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:27:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:27:38 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 00:27:38 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 00:27:38 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 00:27:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:27:38 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 00:27:38 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:27:38 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 00:27:38 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 00:27:38 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 00:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:27:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 00:27:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 00:27:56 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 00:28:06 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 00:28:06 [main] [33mWARN [m [ConnectBuilderIsolatedST:546] For running these tests on K8s you have to have internal registry deployed using `minikube start --insecure-registry '10.0.0.0/24'` and `minikube addons enable registry`
2022-04-05 00:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka infra-namespace in namespace infra-namespace
2022-04-05 00:28:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: infra-namespace will have desired state: Ready
2022-04-05 00:29:22 [main] [32mINFO [m [ResourceManager:444] Kafka: infra-namespace is in desired state: Ready
2022-04-05 00:29:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:29:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildWithJarTgzAndZip-STARTED
2022-04-05 00:29:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:29:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-925367562-247743555 in namespace infra-namespace
2022-04-05 00:29:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-925367562-247743555 will have desired state: Ready
2022-04-05 00:29:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-925367562-247743555 is in desired state: Ready
2022-04-05 00:29:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-d24fdcf5 in namespace infra-namespace
2022-04-05 00:29:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-d24fdcf5 will have desired state: Ready
2022-04-05 00:31:16 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-d24fdcf5 is in desired state: Ready
2022-04-05 00:31:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-d24fdcf5 in namespace infra-namespace
2022-04-05 00:31:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-d24fdcf5 will have desired state: Ready
2022-04-05 00:31:17 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-d24fdcf5 is in desired state: Ready
2022-04-05 00:31:17 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 00:31:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-d24fdcf5-hello-world-producer in namespace infra-namespace
2022-04-05 00:31:17 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-d24fdcf5-hello-world-producer will be in active state
2022-04-05 00:31:18 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-d24fdcf5-hello-world-producer to finished
2022-04-05 00:31:26 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 00:31:27 [main] [32mINFO [m [PodUtils:189] Message Received message with key 'null' and value '"Hello-world - 99"' found in my-cluster-d24fdcf5-connect-6dfb8b7b55-pwlw9 log
2022-04-05 00:31:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:31:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildWithJarTgzAndZip
2022-04-05 00:31:27 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-d24fdcf5 in namespace infra-namespace
2022-04-05 00:31:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-d24fdcf5-hello-world-producer in namespace infra-namespace
2022-04-05 00:31:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-d24fdcf5 in namespace infra-namespace
2022-04-05 00:31:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-925367562-247743555 in namespace infra-namespace
2022-04-05 00:31:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:31:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildWithJarTgzAndZip-FINISHED
2022-04-05 00:31:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:31:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:31:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildFailsWithWrongChecksumOfArtifact-STARTED
2022-04-05 00:31:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:31:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5ef46615-scraper in namespace infra-namespace
2022-04-05 00:31:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5ef46615-scraper will be ready
2022-04-05 00:31:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5ef46615-scraper is ready
2022-04-05 00:31:39 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-5ef46615-scraper to be ready
2022-04-05 00:31:49 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-5ef46615-scraper is ready
2022-04-05 00:31:49 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-5ef46615-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 00:31:49 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-5ef46615-allow in namespace infra-namespace
2022-04-05 00:31:49 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 00:31:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-5ef46615 in namespace infra-namespace
2022-04-05 00:31:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-5ef46615 will have desired state: NotReady
2022-04-05 00:32:13 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-5ef46615 is in desired state: NotReady
2022-04-05 00:32:13 [main] [32mINFO [m [ConnectBuilderIsolatedST:186] Checking if KafkaConnect status condition contains message about build failure
2022-04-05 00:32:13 [main] [32mINFO [m [ConnectBuilderIsolatedST:189] Deploying network policies for KafkaConnect
2022-04-05 00:32:13 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-5ef46615-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 00:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-5ef46615-allow in namespace infra-namespace
2022-04-05 00:32:13 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 00:32:13 [main] [32mINFO [m [ConnectBuilderIsolatedST:197] Replacing plugin's checksum with right one
2022-04-05 00:32:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-5ef46615 will have desired state: Ready
2022-04-05 00:34:29 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-5ef46615 is in desired state: Ready
2022-04-05 00:34:29 [main] [32mINFO [m [ConnectBuilderIsolatedST:215] Checking if KafkaConnect API contains EchoSink connector
2022-04-05 00:34:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-5ef46615-scraper-78d7c64f57-6g5mm -- curl -X GET http://my-cluster-5ef46615-connect-api:8083/connector-plugins
2022-04-05 00:34:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:34:29 [main] [32mINFO [m [ConnectBuilderIsolatedST:220] Checking if KafkaConnect resource contains EchoSink connector in status
2022-04-05 00:34:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:34:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildFailsWithWrongChecksumOfArtifact
2022-04-05 00:34:29 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-5ef46615 in namespace infra-namespace
2022-04-05 00:34:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-5ef46615-allow in namespace infra-namespace
2022-04-05 00:34:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-5ef46615-allow in namespace infra-namespace
2022-04-05 00:34:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5ef46615-scraper in namespace infra-namespace
2022-04-05 00:35:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:35:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildFailsWithWrongChecksumOfArtifact-FINISHED
2022-04-05 00:35:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:35:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:35:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildOtherPluginTypeWithAndWithoutFileName-STARTED
2022-04-05 00:35:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:35:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-322115825-177334229 in namespace infra-namespace
2022-04-05 00:35:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-322115825-177334229 will have desired state: Ready
2022-04-05 00:35:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-322115825-177334229 is in desired state: Ready
2022-04-05 00:35:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4eac065f-scraper in namespace infra-namespace
2022-04-05 00:35:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4eac065f-scraper will be ready
2022-04-05 00:35:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4eac065f-scraper is ready
2022-04-05 00:35:13 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-4eac065f-scraper to be ready
2022-04-05 00:35:23 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-4eac065f-scraper is ready
2022-04-05 00:35:23 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-4eac065f-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 00:35:23 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-4eac065f-allow in namespace infra-namespace
2022-04-05 00:35:23 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 00:35:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-4eac065f in namespace infra-namespace
2022-04-05 00:35:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-4eac065f will have desired state: Ready
2022-04-05 00:37:16 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-4eac065f is in desired state: Ready
2022-04-05 00:37:16 [main] [32mINFO [m [ConnectBuilderIsolatedST:448] Checking that plugin has correct file name: echo-sink-test.jar
2022-04-05 00:37:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-4eac065f-connect-65789b749c-qh489 -- /bin/bash -c ls plugins/plugin-with-other-type/*
2022-04-05 00:37:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:37:16 [main] [32mINFO [m [ConnectBuilderIsolatedST:461] Removing file name from the plugin, hash should be used
2022-04-05 00:37:16 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-4eac065f-connect rolling update
2022-04-05 00:38:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4eac065f-connect will be ready
2022-04-05 00:38:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4eac065f-connect is ready
2022-04-05 00:39:07 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-4eac065f-connect rolling update finished
2022-04-05 00:39:07 [main] [32mINFO [m [ConnectBuilderIsolatedST:468] Checking that plugin has different name than before
2022-04-05 00:39:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-4eac065f-connect-9ddf88b78-d6gpk -- /bin/bash -c ls plugins/plugin-with-other-type/*
2022-04-05 00:39:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:39:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:39:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildOtherPluginTypeWithAndWithoutFileName
2022-04-05 00:39:07 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-4eac065f-allow in namespace infra-namespace
2022-04-05 00:39:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4eac065f-scraper in namespace infra-namespace
2022-04-05 00:39:07 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-322115825-177334229 in namespace infra-namespace
2022-04-05 00:39:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-4eac065f in namespace infra-namespace
2022-04-05 00:39:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:39:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildOtherPluginTypeWithAndWithoutFileName-FINISHED
2022-04-05 00:39:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:39:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:39:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testUpdateConnectWithAnotherPlugin-STARTED
2022-04-05 00:39:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:39:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1747200070-106876242 in namespace infra-namespace
2022-04-05 00:39:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1747200070-106876242 will have desired state: Ready
2022-04-05 00:39:58 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1747200070-106876242 is in desired state: Ready
2022-04-05 00:39:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-493202d8-scraper in namespace infra-namespace
2022-04-05 00:39:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-493202d8-scraper will be ready
2022-04-05 00:40:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-493202d8-scraper is ready
2022-04-05 00:40:00 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-493202d8-scraper to be ready
2022-04-05 00:40:10 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-493202d8-scraper is ready
2022-04-05 00:40:10 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-493202d8-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 00:40:10 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-493202d8-allow in namespace infra-namespace
2022-04-05 00:40:10 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 00:40:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-493202d8 in namespace infra-namespace
2022-04-05 00:40:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-493202d8 will have desired state: Ready
2022-04-05 00:41:46 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-493202d8 is in desired state: Ready
2022-04-05 00:41:46 [main] [32mINFO [m [ConnectBuilderIsolatedST:370] Creating EchoSink connector
2022-04-05 00:41:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector echo-sink-connector in namespace infra-namespace
2022-04-05 00:41:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: echo-sink-connector will have desired state: Ready
2022-04-05 00:41:47 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: echo-sink-connector is in desired state: Ready
2022-04-05 00:41:47 [main] [32mINFO [m [ConnectBuilderIsolatedST:382] Checking that KafkaConnect API contains EchoSink connector and not Camel-Telegram Connector class name
2022-04-05 00:41:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-493202d8-scraper-b56f8d79d-xkc5w -- curl -X GET http://my-cluster-493202d8-connect-api:8083/connector-plugins
2022-04-05 00:41:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:41:48 [main] [32mINFO [m [ConnectBuilderIsolatedST:388] Adding one more connector to the KafkaConnect
2022-04-05 00:41:48 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-493202d8-connect rolling update
2022-04-05 00:43:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-493202d8-connect will be ready
2022-04-05 00:43:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-493202d8-connect is ready
2022-04-05 00:43:48 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-493202d8-connect rolling update finished
2022-04-05 00:43:48 [main] [32mINFO [m [ConnectBuilderIsolatedST:399] Creating Camel-HTTP-Sink connector
2022-04-05 00:43:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector camel-http-connector in namespace infra-namespace
2022-04-05 00:43:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: camel-http-connector will have desired state: Ready
2022-04-05 00:43:49 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: camel-http-connector is in desired state: Ready
2022-04-05 00:43:49 [main] [32mINFO [m [ConnectBuilderIsolatedST:409] Checking if both Connectors were created and Connect contains both plugins
2022-04-05 00:43:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:43:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateConnectWithAnotherPlugin
2022-04-05 00:43:49 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-493202d8 in namespace infra-namespace
2022-04-05 00:43:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector camel-http-connector in namespace infra-namespace
2022-04-05 00:43:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-493202d8-scraper in namespace infra-namespace
2022-04-05 00:43:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1747200070-106876242 in namespace infra-namespace
2022-04-05 00:43:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector echo-sink-connector in namespace infra-namespace
2022-04-05 00:44:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-493202d8-allow in namespace infra-namespace
2022-04-05 00:44:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:44:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testUpdateConnectWithAnotherPlugin-FINISHED
2022-04-05 00:44:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:44:29 [main] [32mINFO [m [OpenShiftOnlyCondition:25] testPushIntoImageStream is @OpenShiftOnly, but the running cluster is not OpenShift: Ignoring testPushIntoImageStream
2022-04-05 00:44:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:44:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts-STARTED
2022-04-05 00:44:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:44:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1672606119-1441065653 in namespace infra-namespace
2022-04-05 00:44:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-0f5fcf2a in namespace infra-namespace
2022-04-05 00:44:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1672606119-1441065653 will have desired state: Ready
2022-04-05 00:44:30 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1672606119-1441065653 is in desired state: Ready
2022-04-05 00:44:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-0f5fcf2a will have desired state: Ready
2022-04-05 00:54:30 [main] [32mINFO [m [ResourceManager:414] KafkaConnect status:

Conditions:
	Type: NotReady
	Message: Exceeded timeout of 30000ms while waiting for Deployment resource my-cluster-0f5fcf2a-connect in namespace infra-namespace to be ready

Pods with conditions and messages:

my-cluster-0f5fcf2a-connect-7d4bf4478c-cbtnw:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for KafkaConnect: my-cluster-0f5fcf2a will have desired state: Ready
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:435)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForConnectStatus(KafkaConnectUtils.java:42)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForConnectReady(KafkaConnectUtils.java:47)
	at io.strimzi.systemtest.resources.crd.KafkaConnectResource.waitForReadiness(KafkaConnectResource.java:42)
	at io.strimzi.systemtest.resources.crd.KafkaConnectResource.waitForReadiness(KafkaConnectResource.java:19)
	at io.strimzi.systemtest.resources.ResourceManager.lambda$waitResourceCondition$2(ResourceManager.java:268)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:142)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts(ConnectBuilderIsolatedST.java:482)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-0f5fcf2a
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts(ConnectBuilderIsolatedST.java:482)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-05 00:54:30 [main] [1;31mERROR[m [TestExecutionWatcher:28] ConnectBuilderIsolatedST - Exception Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-0f5fcf2a has been thrown in @Test. Going to collect logs from components.
2022-04-05 00:54:30 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-05 00:54:30 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-05 00:54:30 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-05 00:54:36 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-05 00:54:36 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-05 00:54:36 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-05 00:54:37 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-05 00:54:37 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-05 00:54:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:54:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildPluginUsingMavenCoordinatesArtifacts
2022-04-05 00:54:37 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-0f5fcf2a in namespace infra-namespace
2022-04-05 00:54:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1672606119-1441065653 in namespace infra-namespace
2022-04-05 00:54:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:54:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts-FINISHED
2022-04-05 00:54:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 00:54:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:54:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for ConnectBuilderIsolatedST
2022-04-05 00:54:47 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka infra-namespace in namespace infra-namespace
2022-04-05 00:54:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 6, Failures: 0, Errors: 1, Skipped: 1, Time elapsed: 1,700.217 s <<< FAILURE! - in io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts(ExtensionContext)  Time elapsed: 617.878 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-0f5fcf2a
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts(ConnectBuilderIsolatedST.java:482)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-05 00:54:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 00:55:22 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 00:55:22 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 00:55:22 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 00:55:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:55:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 00:55:22 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 00:55:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:55:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 00:55:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 00:55:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 00:55:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:55:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:32 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:55:32 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 00:55:32 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 00:55:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 00:55:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:55:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 00:55:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:55:42 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 00:55:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:55:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 00:55:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 00:55:58 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 00:55:58 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 00:55:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 00:55:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 00:55:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:55:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:55:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 00:55:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 00:55:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 00:55:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 00:55:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:55:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 00:55:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:55:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 00:55:59 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 00:55:59 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 00:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:55:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 00:56:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 00:56:11 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 00:56:21 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 00:56:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 00:56:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-STARTED
2022-04-05 00:56:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 00:56:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c8dc98e3 in namespace infra-namespace
2022-04-05 00:56:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c8dc98e3 will have desired state: Ready
2022-04-05 00:57:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c8dc98e3 is in desired state: Ready
2022-04-05 00:57:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-c8dc98e3-producer in namespace infra-namespace
2022-04-05 00:57:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-c8dc98e3-consumer in namespace infra-namespace
2022-04-05 00:57:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-c8dc98e3-producer will be in active state
2022-04-05 00:57:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-c8dc98e3-consumer will be in active state
2022-04-05 00:57:34 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-c8dc98e3-producer and consumer my-cluster-c8dc98e3-consumer finish
2022-04-05 00:57:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-c8dc98e3-kafka-0 -- /opt/kafka/bin/kafka-consumer-groups.sh --describe --bootstrap-server localhost:9092 --group my-group
2022-04-05 00:57:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:57:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-c8dc98e3-producer in namespace infra-namespace
2022-04-05 00:57:54 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-c8dc98e3-producer will be in active state
2022-04-05 00:57:55 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-c8dc98e3-producer to finished
2022-04-05 00:58:03 [main] [32mINFO [m [ColdBackupScriptIsolatedST:95] Running backup procedure for infra-namespace/my-cluster-c8dc98e3
2022-04-05 00:59:48 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh backup -n infra-namespace -c my-cluster-c8dc98e3 -t /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-c8dc98e3.tgz -y
2022-04-05 00:59:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 00:59:48 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 00:59:48 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 00:59:48 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 00:59:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 00:59:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 00:59:48 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 00:59:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 00:59:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 00:59:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 00:59:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:59:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:59:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 00:59:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 00:59:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:59:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 00:59:58 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:59:58 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 00:59:58 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 00:59:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 00:59:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 00:59:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 00:59:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 00:59:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 00:59:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 00:59:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 00:59:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:00:39 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 01:00:39 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 01:00:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 01:00:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:39 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 01:00:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 01:00:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 01:00:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 01:00:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 01:00:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 01:00:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 01:00:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 01:00:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 01:00:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 01:00:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 01:00:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 01:00:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 01:00:40 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 01:00:40 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 01:00:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 01:00:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 01:00:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 01:00:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 01:01:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 01:01:05 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 01:01:15 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 01:01:15 [main] [32mINFO [m [ColdBackupScriptIsolatedST:109] Running restore procedure for infra-namespace/my-cluster-c8dc98e3
2022-04-05 01:02:39 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh restore -n infra-namespace -c my-cluster-c8dc98e3 -s /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-c8dc98e3.tgz -y
2022-04-05 01:02:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 01:02:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c8dc98e3 will have desired state: Ready
2022-04-05 01:03:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c8dc98e3 is in desired state: Ready
2022-04-05 01:03:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-c8dc98e3-kafka-0 -- /opt/kafka/bin/kafka-consumer-groups.sh --describe --bootstrap-server localhost:9092 --group my-group
2022-04-05 01:03:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 01:03:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-c8dc98e3-consumer in namespace infra-namespace
2022-04-05 01:03:26 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-c8dc98e3-consumer will be in active state
2022-04-05 01:03:27 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-c8dc98e3-consumer to finished
2022-04-05 01:03:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-c8dc98e3-consumer in namespace infra-namespace
2022-04-05 01:03:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-c8dc98e3-consumer will be in active state
2022-04-05 01:03:38 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-c8dc98e3-consumer to finished
2022-04-05 01:03:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:03:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for backupAndRestore
2022-04-05 01:03:48 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-c8dc98e3-producer in namespace infra-namespace
2022-04-05 01:03:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-c8dc98e3-producer in namespace infra-namespace
2022-04-05 01:03:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-c8dc98e3-consumer in namespace infra-namespace
2022-04-05 01:03:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-c8dc98e3-consumer in namespace infra-namespace
2022-04-05 01:03:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c8dc98e3 in namespace infra-namespace
2022-04-05 01:03:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-c8dc98e3-consumer in namespace infra-namespace
2022-04-05 01:03:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:03:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-FINISHED
2022-04-05 01:03:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 01:03:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:03:58 [main] [32mINFO [m [ResourceManager:346] In context ColdBackupScriptIsolatedST is everything deleted.
2022-04-05 01:03:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 540.749 s - in io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
2022-04-05 01:03:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 01:04:23 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 01:04:23 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 01:04:23 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 01:04:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:04:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 01:04:23 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 01:04:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 01:04:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 01:04:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 01:04:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 01:04:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 01:04:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 01:04:33 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 01:04:33 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 01:04:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 01:04:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 01:04:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 01:04:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 01:04:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 01:04:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 01:04:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 01:04:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 01:04:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 01:04:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 01:04:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 01:04:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 01:04:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 01:04:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 01:04:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 01:04:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 01:05:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:05:09 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 01:05:09 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 01:05:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 01:05:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 01:05:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 01:05:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 01:05:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 01:05:09 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 01:05:09 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 01:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 01:05:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 01:05:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 01:05:41 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 01:05:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 01:05:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 01:05:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup-STARTED
2022-04-05 01:05:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 01:05:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-120 for test case:testRestoreOffsetsInConsumerGroup
2022-04-05 01:05:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-120
2022-04-05 01:05:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-120
2022-04-05 01:05:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-120
2022-04-05 01:05:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c95f4c67-source in namespace namespace-120
2022-04-05 01:05:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:05:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c95f4c67-target in namespace namespace-120
2022-04-05 01:05:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:05:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c95f4c67-source will have desired state: Ready
2022-04-05 01:07:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c95f4c67-source is in desired state: Ready
2022-04-05 01:07:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c95f4c67-target will have desired state: Ready
2022-04-05 01:07:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c95f4c67-target is in desired state: Ready
2022-04-05 01:07:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-c95f4c67-trg-src in namespace namespace-120
2022-04-05 01:07:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:07:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-c95f4c67-src-trg in namespace namespace-120
2022-04-05 01:07:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:07:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic test-sync-offset-1255883692 in namespace namespace-120
2022-04-05 01:07:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:07:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-c95f4c67-trg-src will have desired state: Ready
2022-04-05 01:08:28 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-c95f4c67-trg-src is in desired state: Ready
2022-04-05 01:08:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-c95f4c67-src-trg will have desired state: Ready
2022-04-05 01:08:28 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-c95f4c67-src-trg is in desired state: Ready
2022-04-05 01:08:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: test-sync-offset-1255883692 will have desired state: Ready
2022-04-05 01:08:28 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: test-sync-offset-1255883692 is in desired state: Ready
2022-04-05 01:08:28 [main] [32mINFO [m [MirrorMaker2IsolatedST:1090] Send & receive 100 messages to/from Source cluster.
2022-04-05 01:08:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-62761776 in namespace namespace-120
2022-04-05 01:08:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:08:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-1995625793 in namespace namespace-120
2022-04-05 01:08:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:08:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-62761776 will be in active state
2022-04-05 01:08:29 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-1995625793 will be in active state
2022-04-05 01:08:29 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-62761776 to finished
2022-04-05 01:08:40 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-1995625793 to finished
2022-04-05 01:08:45 [main] [32mINFO [m [MirrorMaker2IsolatedST:1098] Send 100 messages to Source cluster.
2022-04-05 01:08:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-62761776 in namespace namespace-120
2022-04-05 01:08:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:08:45 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-62761776 will be in active state
2022-04-05 01:08:46 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-62761776 to finished
2022-04-05 01:08:51 [main] [32mINFO [m [MirrorMaker2IsolatedST:1105] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-05 01:08:51 [main] [32mINFO [m [MirrorMaker2IsolatedST:1107] Receive 100 messages from mirrored topic on Target cluster.
2022-04-05 01:08:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-841354223 in namespace namespace-120
2022-04-05 01:08:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:08:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-841354223 will be in active state
2022-04-05 01:08:52 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-841354223 to finished
2022-04-05 01:09:03 [main] [32mINFO [m [MirrorMaker2IsolatedST:1112] Send 50 messages to Source cluster
2022-04-05 01:09:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-62761776 in namespace namespace-120
2022-04-05 01:09:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:09:03 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-62761776 will be in active state
2022-04-05 01:09:04 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-62761776 to finished
2022-04-05 01:09:12 [main] [32mINFO [m [MirrorMaker2IsolatedST:1118] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-05 01:09:12 [main] [32mINFO [m [MirrorMaker2IsolatedST:1119] Receive 10 msgs from source cluster
2022-04-05 01:09:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-1995625793 in namespace namespace-120
2022-04-05 01:09:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:09:12 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-1995625793 will be in active state
2022-04-05 01:09:13 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-1995625793 to finished
2022-04-05 01:09:27 [main] [32mINFO [m [MirrorMaker2IsolatedST:1125] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-05 01:09:27 [main] [32mINFO [m [MirrorMaker2IsolatedST:1127] Receive 40 msgs from mirrored topic on Target cluster
2022-04-05 01:09:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-841354223 in namespace namespace-120
2022-04-05 01:09:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:09:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-841354223 will be in active state
2022-04-05 01:09:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-841354223 to finished
2022-04-05 01:09:43 [main] [32mINFO [m [MirrorMaker2IsolatedST:1133] There should be no more messages to read. Try to consume at least 1 message. This client job should fail on timeout.
2022-04-05 01:09:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-841354223 in namespace namespace-120
2022-04-05 01:09:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:09:43 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-841354223 will be in active state
2022-04-05 01:09:44 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-841354223 to finish with failure.
2022-04-05 01:11:45 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 121000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.lambda$testRestoreOffsetsInConsumerGroup$13(MirrorMaker2IsolatedST.java:1137)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup(MirrorMaker2IsolatedST.java:1137)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-05 01:11:45 [main] [32mINFO [m [ClientUtils:100] Client job 'mm2-consumer-target-my-consumer-group-841354223' finished with expected timeout.
2022-04-05 01:11:45 [main] [32mINFO [m [MirrorMaker2IsolatedST:1139] As it's Active-Active MM2 mode, there should be no more messages to read from Source cluster topic. This client job should fail on timeout.
2022-04-05 01:11:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-1995625793 in namespace namespace-120
2022-04-05 01:11:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-05 01:11:45 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-1995625793 will be in active state
2022-04-05 01:11:46 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-1995625793 to finish with failure.
2022-04-05 01:13:47 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 121000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.lambda$testRestoreOffsetsInConsumerGroup$14(MirrorMaker2IsolatedST.java:1143)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup(MirrorMaker2IsolatedST.java:1143)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-05 01:13:47 [main] [32mINFO [m [ClientUtils:100] Client job 'mm2-consumer-source-my-consumer-group-1995625793' finished with expected timeout.
2022-04-05 01:13:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:13:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRestoreOffsetsInConsumerGroup
2022-04-05 01:13:47 [main] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-841354223 in namespace namespace-120
2022-04-05 01:13:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic test-sync-offset-1255883692 in namespace namespace-120
2022-04-05 01:13:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c95f4c67-target in namespace namespace-120
2022-04-05 01:13:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c95f4c67-source in namespace namespace-120
2022-04-05 01:13:47 [main] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-62761776 in namespace namespace-120
2022-04-05 01:13:47 [main] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-62761776 in namespace namespace-120
2022-04-05 01:13:47 [main] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-841354223 in namespace namespace-120
2022-04-05 01:13:47 [main] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-1995625793 in namespace namespace-120
2022-04-05 01:13:47 [main] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-841354223 in namespace namespace-120
2022-04-05 01:13:47 [main] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-1995625793 in namespace namespace-120
2022-04-05 01:13:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-c95f4c67-trg-src in namespace namespace-120
2022-04-05 01:14:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-1995625793 in namespace namespace-120
2022-04-05 01:14:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-62761776 in namespace namespace-120
2022-04-05 01:14:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-c95f4c67-src-trg in namespace namespace-120
2022-04-05 01:14:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:14:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-120 for test case:testRestoreOffsetsInConsumerGroup
2022-04-05 01:14:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup-FINISHED
2022-04-05 01:14:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 01:14:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 01:14:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2-STARTED
2022-04-05 01:14:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 01:14:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-121 for test case:testMirrorMaker2
2022-04-05 01:14:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-121
2022-04-05 01:14:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-121
2022-04-05 01:14:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-121
2022-04-05 01:14:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b373ce13-source in namespace namespace-121
2022-04-05 01:14:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-05 01:14:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b373ce13-source will have desired state: Ready
2022-04-05 01:15:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b373ce13-source is in desired state: Ready
2022-04-05 01:15:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b373ce13-target in namespace namespace-121
2022-04-05 01:15:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-05 01:15:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b373ce13-target will have desired state: Ready
2022-04-05 01:16:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b373ce13-target is in desired state: Ready
2022-04-05 01:16:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-1549331958 in namespace namespace-121
2022-04-05 01:16:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-05 01:16:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-1549331958 will have desired state: Ready
2022-04-05 01:16:32 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-1549331958 is in desired state: Ready
2022-04-05 01:16:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b373ce13-kafka-clients in namespace namespace-121
2022-04-05 01:16:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-05 01:16:42 [main] [32mINFO [m [MirrorMaker2IsolatedST:155] Sending messages to - topic availability-topic-source-my-topic-1264517481-1260224656, cluster my-cluster-b373ce13-source and message count of 100
2022-04-05 01:16:42 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5c974b40, messages=[], arguments=[--topic, availability-topic-source-my-topic-1264517481-1260224656, --max-messages, 100, --bootstrap-server, my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz', podNamespace='namespace-121', bootstrapServer='my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-source-my-topic-1264517481-1260224656', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1919c870}
2022-04-05 01:16:42 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092:availability-topic-source-my-topic-1264517481-1260224656 from pod my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz
2022-04-05 01:16:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz -n namespace-121 -- /opt/kafka/producer.sh --topic availability-topic-source-my-topic-1264517481-1260224656 --max-messages 100 --bootstrap-server my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 01:16:45 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 01:16:45 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 01:16:45 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@18040d65, messages=[], arguments=[--topic, availability-topic-source-my-topic-1264517481-1260224656, --max-messages, 100, --group-instance-id, instance627623599, --group-id, my-consumer-group-58810290, --bootstrap-server, my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz', podNamespace='namespace-121', bootstrapServer='my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-source-my-topic-1264517481-1260224656', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-58810290', consumerInstanceId='instance627623599', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4f0906bc}
2022-04-05 01:16:45 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092#availability-topic-source-my-topic-1264517481-1260224656 from pod my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz
2022-04-05 01:16:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz -n namespace-121 -- /opt/kafka/consumer.sh --topic availability-topic-source-my-topic-1264517481-1260224656 --max-messages 100 --group-instance-id instance627623599 --group-id my-consumer-group-58810290 --bootstrap-server my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 01:16:51 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 01:16:51 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 01:16:51 [main] [32mINFO [m [MirrorMaker2IsolatedST:160] Setting topic to availability-topic-target-my-topic-1264517481-1260224656, cluster to my-cluster-b373ce13-target and changing consumer group
2022-04-05 01:16:51 [main] [32mINFO [m [MirrorMaker2IsolatedST:168] Sending messages to - topic availability-topic-target-my-topic-1264517481-1260224656, cluster my-cluster-b373ce13-target and message count of 100
2022-04-05 01:16:51 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@8ac8c55, messages=[], arguments=[--topic, availability-topic-target-my-topic-1264517481-1260224656, --max-messages, 100, --bootstrap-server, my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz', podNamespace='namespace-121', bootstrapServer='my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-target-my-topic-1264517481-1260224656', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7eaf986e}
2022-04-05 01:16:51 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092:availability-topic-target-my-topic-1264517481-1260224656 from pod my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz
2022-04-05 01:16:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz -n namespace-121 -- /opt/kafka/producer.sh --topic availability-topic-target-my-topic-1264517481-1260224656 --max-messages 100 --bootstrap-server my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 01:16:54 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 01:16:54 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 01:16:54 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@37c00cb8, messages=[], arguments=[--topic, availability-topic-target-my-topic-1264517481-1260224656, --max-messages, 100, --group-instance-id, instance1226910278, --group-id, my-consumer-group-1145549762, --bootstrap-server, my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz', podNamespace='namespace-121', bootstrapServer='my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-target-my-topic-1264517481-1260224656', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1145549762', consumerInstanceId='instance1226910278', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@f17571a}
2022-04-05 01:16:54 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092#availability-topic-target-my-topic-1264517481-1260224656 from pod my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz
2022-04-05 01:16:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz -n namespace-121 -- /opt/kafka/consumer.sh --topic availability-topic-target-my-topic-1264517481-1260224656 --max-messages 100 --group-instance-id instance1226910278 --group-id my-consumer-group-1145549762 --bootstrap-server my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 01:17:00 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 01:17:00 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 01:17:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-b373ce13 in namespace namespace-121
2022-04-05 01:17:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-05 01:17:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-b373ce13 will have desired state: Ready
2022-04-05 01:18:19 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-b373ce13 is in desired state: Ready
2022-04-05 01:18:19 [main] [32mINFO [m [MirrorMaker2IsolatedST:183] Looks like the mirrormaker2 cluster my-cluster deployed OK
2022-04-05 01:18:19 [main] [32mINFO [m [MirrorMaker2IsolatedST:640] Verifying docker image names
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-05 01:18:19 [main] [32mINFO [m [MirrorMaker2IsolatedST:653] Docker images verified
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type mirrormaker2
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-b373ce13-mirrormaker2-bfdb57775-h6qgz
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:362] Verifying labels for service my-cluster-b373ce13-mirrormaker2-api
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b373ce13-mirrormaker2-config
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b373ce13-source-entity-topic-operator-config
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:407] CM my-cluster-b373ce13-source-entity-topic-operator-config is not related to current test
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b373ce13-source-entity-user-operator-config
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:407] CM my-cluster-b373ce13-source-entity-user-operator-config is not related to current test
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b373ce13-source-kafka-config
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b373ce13-source-zookeeper-config
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:407] CM my-cluster-b373ce13-source-zookeeper-config is not related to current test
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b373ce13-target-entity-topic-operator-config
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:407] CM my-cluster-b373ce13-target-entity-topic-operator-config is not related to current test
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b373ce13-target-entity-user-operator-config
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:407] CM my-cluster-b373ce13-target-entity-user-operator-config is not related to current test
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b373ce13-target-kafka-config
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-b373ce13-target-zookeeper-config
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:407] CM my-cluster-b373ce13-target-zookeeper-config is not related to current test
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-b373ce13-source-entity-operator
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-b373ce13-source-kafka
2022-04-05 01:18:19 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-b373ce13-source-zookeeper
2022-04-05 01:18:19 [main] [32mINFO [m [MirrorMaker2IsolatedST:198] Setting topic to mirrormaker2-topic-example-1549331958, cluster to my-cluster-b373ce13-source and changing consumer group
2022-04-05 01:18:19 [main] [32mINFO [m [MirrorMaker2IsolatedST:206] Sending messages to - topic mirrormaker2-topic-example-1549331958, cluster my-cluster-b373ce13-source and message count of 100
2022-04-05 01:18:19 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2a647e83, messages=[], arguments=[--topic, mirrormaker2-topic-example-1549331958, --max-messages, 100, --bootstrap-server, my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz', podNamespace='namespace-121', bootstrapServer='my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092', topicName='mirrormaker2-topic-example-1549331958', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@517e31c5}
2022-04-05 01:18:19 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092:mirrormaker2-topic-example-1549331958 from pod my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz
2022-04-05 01:18:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz -n namespace-121 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-1549331958 --max-messages 100 --bootstrap-server my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 01:18:21 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 01:18:21 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 01:18:21 [main] [32mINFO [m [MirrorMaker2IsolatedST:210] Consumer in source cluster and topic should receive 100 messages
2022-04-05 01:18:21 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1768de70, messages=[], arguments=[--topic, mirrormaker2-topic-example-1549331958, --max-messages, 100, --group-instance-id, instance616524471, --group-id, my-consumer-group-1441629782, --bootstrap-server, my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz', podNamespace='namespace-121', bootstrapServer='my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092', topicName='mirrormaker2-topic-example-1549331958', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1441629782', consumerInstanceId='instance616524471', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1e713b5b}
2022-04-05 01:18:21 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092#mirrormaker2-topic-example-1549331958 from pod my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz
2022-04-05 01:18:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz -n namespace-121 -- /opt/kafka/consumer.sh --topic mirrormaker2-topic-example-1549331958 --max-messages 100 --group-instance-id instance616524471 --group-id my-consumer-group-1441629782 --bootstrap-server my-cluster-b373ce13-source-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 01:18:27 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 01:18:27 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 01:18:27 [main] [32mINFO [m [MirrorMaker2IsolatedST:214] Now setting topic to my-cluster-b373ce13-source.mirrormaker2-topic-example-1549331958 and cluster to my-cluster-b373ce13-target - the messages should be mirrored
2022-04-05 01:18:27 [main] [32mINFO [m [MirrorMaker2IsolatedST:222] Consumer in target cluster and topic should receive 100 messages
2022-04-05 01:18:27 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@31427320, messages=[], arguments=[--topic, my-cluster-b373ce13-source.mirrormaker2-topic-example-1549331958, --max-messages, 100, --group-instance-id, instance1366694880, --group-id, my-consumer-group-566190028, --bootstrap-server, my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz', podNamespace='namespace-121', bootstrapServer='my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092', topicName='my-cluster-b373ce13-source.mirrormaker2-topic-example-1549331958', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-566190028', consumerInstanceId='instance1366694880', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@179b501}
2022-04-05 01:18:27 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092#my-cluster-b373ce13-source.mirrormaker2-topic-example-1549331958 from pod my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz
2022-04-05 01:18:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz -n namespace-121 -- /opt/kafka/consumer.sh --topic my-cluster-b373ce13-source.mirrormaker2-topic-example-1549331958 --max-messages 100 --group-instance-id instance1366694880 --group-id my-consumer-group-566190028 --bootstrap-server my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 01:18:33 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 01:18:33 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 01:18:33 [main] [32mINFO [m [MirrorMaker2IsolatedST:227] Changing topic to my-cluster-b373ce13-source.availability-topic-source-my-topic-1264517481-1260224656
2022-04-05 01:18:33 [main] [32mINFO [m [MirrorMaker2IsolatedST:233] Check if mm2 mirror automatically created topic
2022-04-05 01:18:33 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7734fc41, messages=[], arguments=[--topic, my-cluster-b373ce13-source.availability-topic-source-my-topic-1264517481-1260224656, --max-messages, 100, --group-instance-id, instance1042796581, --group-id, my-consumer-group-1481424940, --bootstrap-server, my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz', podNamespace='namespace-121', bootstrapServer='my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092', topicName='my-cluster-b373ce13-source.availability-topic-source-my-topic-1264517481-1260224656', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1481424940', consumerInstanceId='instance1042796581', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@26fe3db0}
2022-04-05 01:18:33 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092#my-cluster-b373ce13-source.availability-topic-source-my-topic-1264517481-1260224656 from pod my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz
2022-04-05 01:18:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b373ce13-kafka-clients-787df7cc6f-clzvz -n namespace-121 -- /opt/kafka/consumer.sh --topic my-cluster-b373ce13-source.availability-topic-source-my-topic-1264517481-1260224656 --max-messages 100 --group-instance-id instance1042796581 --group-id my-consumer-group-1481424940 --bootstrap-server my-cluster-b373ce13-target-kafka-bootstrap.namespace-121.svc:9092
2022-04-05 01:18:39 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 01:18:39 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 01:18:39 [main] [32mINFO [m [MirrorMaker2IsolatedST:236] Mirrored successful
2022-04-05 01:18:39 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-cluster-b373ce13-source.mirrormaker2-topic-example-1549331958
2022-04-05 01:19:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:19:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2
2022-04-05 01:19:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-1549331958 in namespace namespace-121
2022-04-05 01:19:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-b373ce13 in namespace namespace-121
2022-04-05 01:19:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b373ce13-target in namespace namespace-121
2022-04-05 01:19:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b373ce13-source in namespace namespace-121
2022-04-05 01:19:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b373ce13-kafka-clients in namespace namespace-121
2022-04-05 01:20:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:20:19 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-121 for test case:testMirrorMaker2
2022-04-05 01:20:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2-FINISHED
2022-04-05 01:20:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 01:20:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 01:20:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKafkaMirrorMaker2ReflectsConnectorsState-STARTED
2022-04-05 01:20:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 01:20:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-122 for test case:testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-05 01:20:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-122
2022-04-05 01:20:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-122
2022-04-05 01:20:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-122
2022-04-05 01:20:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8364528e-source in namespace namespace-122
2022-04-05 01:20:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-05 01:20:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8364528e-target in namespace namespace-122
2022-04-05 01:20:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-05 01:20:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8364528e-source will have desired state: Ready
2022-04-05 01:21:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8364528e-source is in desired state: Ready
2022-04-05 01:21:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8364528e-target will have desired state: Ready
2022-04-05 01:21:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8364528e-target is in desired state: Ready
2022-04-05 01:21:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-8364528e in namespace namespace-122
2022-04-05 01:21:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-05 01:21:41 [main] [32mINFO [m [ResourceManager:481] Wait for KafkaMirrorMaker2: my-cluster-8364528e will contain desired status message: One or more connectors are in FAILED state
2022-04-05 01:22:48 [main] [32mINFO [m [ResourceManager:492] KafkaMirrorMaker2: my-cluster-8364528e contains desired message in status: One or more connectors are in FAILED state
2022-04-05 01:22:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-8364528e will have desired state: Ready
2022-04-05 01:22:49 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-8364528e is in desired state: Ready
2022-04-05 01:22:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:22:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-05 01:22:49 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8364528e-target in namespace namespace-122
2022-04-05 01:22:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-8364528e in namespace namespace-122
2022-04-05 01:22:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8364528e-source in namespace namespace-122
2022-04-05 01:23:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:23:09 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-122 for test case:testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-05 01:23:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKafkaMirrorMaker2ReflectsConnectorsState-FINISHED
2022-04-05 01:23:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 01:23:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 01:23:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateTLS-STARTED
2022-04-05 01:23:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 01:23:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-123 for test case:testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-05 01:23:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-123
2022-04-05 01:23:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-123
2022-04-05 01:23:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-123
2022-04-05 01:23:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ab9c640e-source in namespace namespace-123
2022-04-05 01:23:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 01:23:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ab9c640e-source will have desired state: Ready
2022-04-05 01:24:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ab9c640e-source is in desired state: Ready
2022-04-05 01:24:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ab9c640e-target in namespace namespace-123
2022-04-05 01:24:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 01:24:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ab9c640e-target will have desired state: Ready
2022-04-05 01:25:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ab9c640e-target is in desired state: Ready
2022-04-05 01:25:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-a-1200513152 in namespace namespace-123
2022-04-05 01:25:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 01:25:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-a-1200513152 will have desired state: Ready
2022-04-05 01:25:58 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-a-1200513152 is in desired state: Ready
2022-04-05 01:25:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-b-1460175146 in namespace namespace-123
2022-04-05 01:25:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 01:25:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-b-1460175146 will have desired state: Ready
2022-04-05 01:25:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-b-1460175146 is in desired state: Ready
2022-04-05 01:25:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-ab9c640e-my-user-source in namespace namespace-123
2022-04-05 01:25:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 01:25:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-ab9c640e-my-user-source will have desired state: Ready
2022-04-05 01:26:00 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-ab9c640e-my-user-source is in desired state: Ready
2022-04-05 01:26:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-ab9c640e-my-user-target in namespace namespace-123
2022-04-05 01:26:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 01:26:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-ab9c640e-my-user-target will have desired state: Ready
2022-04-05 01:26:01 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-ab9c640e-my-user-target is in desired state: Ready
2022-04-05 01:26:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-97303cf9-kafka-clients in namespace namespace-123
2022-04-05 01:26:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 01:26:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-599102100-1299420527-test-1 in namespace namespace-123
2022-04-05 01:26:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 01:26:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-599102100-1299420527-test-1 will have desired state: Ready
2022-04-05 01:26:12 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-599102100-1299420527-test-1 is in desired state: Ready
2022-04-05 01:26:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-599102100-1299420527-test-2 in namespace namespace-123
2022-04-05 01:26:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 01:26:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-599102100-1299420527-test-2 will have desired state: Ready
2022-04-05 01:26:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-599102100-1299420527-test-2 is in desired state: Ready
2022-04-05 01:26:13 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 01:26:13 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@270e37af, messages=[], arguments=[--topic, my-topic-599102100-1299420527-test-2, --max-messages, 200, USER=my_cluster_ab9c640e_my_user_target, --bootstrap-server, my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t', podNamespace='namespace-123', bootstrapServer='my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-topic-599102100-1299420527-test-2', maxMessages=200, kafkaUsername='my-cluster-ab9c640e-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3538c5fc}
2022-04-05 01:26:13 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093:my-topic-599102100-1299420527-test-2 from pod my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t
2022-04-05 01:26:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t -n namespace-123 -- /opt/kafka/producer.sh --topic my-topic-599102100-1299420527-test-2 --max-messages 200 USER=my_cluster_ab9c640e_my_user_target --bootstrap-server my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:26:17 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 01:26:17 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 01:26:17 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3578b49c, messages=[], arguments=[--topic, my-topic-599102100-1299420527-test-2, --max-messages, 200, --group-instance-id, instance1341152216, --group-id, my-consumer-group-1215756550, USER=my_cluster_ab9c640e_my_user_target, --bootstrap-server, my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t', podNamespace='namespace-123', bootstrapServer='my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-topic-599102100-1299420527-test-2', maxMessages=200, kafkaUsername='my-cluster-ab9c640e-my-user-target', consumerGroupName='my-consumer-group-1215756550', consumerInstanceId='instance1341152216', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@461c9e86}
2022-04-05 01:26:17 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093:my-topic-599102100-1299420527-test-2 from pod my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t
2022-04-05 01:26:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t -n namespace-123 -- /opt/kafka/consumer.sh --topic my-topic-599102100-1299420527-test-2 --max-messages 200 --group-instance-id instance1341152216 --group-id my-consumer-group-1215756550 USER=my_cluster_ab9c640e_my_user_target --bootstrap-server my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:26:25 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:26:25 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:26:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-ab9c640e in namespace namespace-123
2022-04-05 01:26:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-05 01:26:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-ab9c640e will have desired state: Ready
2022-04-05 01:27:50 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-ab9c640e is in desired state: Ready
2022-04-05 01:27:50 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1a68eb79, messages=[], arguments=[--topic, mirrormaker2-topic-example-a-1200513152, --max-messages, 200, USER=my_cluster_ab9c640e_my_user_source, --bootstrap-server, my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t', podNamespace='namespace-123', bootstrapServer='my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-1200513152', maxMessages=200, kafkaUsername='my-cluster-ab9c640e-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@209aeddc}
2022-04-05 01:27:50 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-1200513152 from pod my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t
2022-04-05 01:27:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t -n namespace-123 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-a-1200513152 --max-messages 200 USER=my_cluster_ab9c640e_my_user_source --bootstrap-server my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:27:54 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 01:27:54 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 01:27:54 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4d17542, messages=[], arguments=[--topic, mirrormaker2-topic-example-a-1200513152, --max-messages, 200, --group-instance-id, instance846280977, --group-id, my-consumer-group-1215756550, USER=my_cluster_ab9c640e_my_user_source, --bootstrap-server, my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t', podNamespace='namespace-123', bootstrapServer='my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-1200513152', maxMessages=200, kafkaUsername='my-cluster-ab9c640e-my-user-source', consumerGroupName='my-consumer-group-1215756550', consumerInstanceId='instance846280977', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@73d292e9}
2022-04-05 01:27:54 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-1200513152 from pod my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t
2022-04-05 01:27:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t -n namespace-123 -- /opt/kafka/consumer.sh --topic mirrormaker2-topic-example-a-1200513152 --max-messages 200 --group-instance-id instance846280977 --group-id my-consumer-group-1215756550 USER=my_cluster_ab9c640e_my_user_source --bootstrap-server my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:28:02 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:28:02 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:28:02 [main] [32mINFO [m [MirrorMaker2IsolatedST:1551] Consumer in target cluster and topic should receive 200 messages
2022-04-05 01:28:02 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@e8e4c33, messages=[], arguments=[--topic, my-cluster-ab9c640e-source.mirrormaker2-topic-example-a-1200513152, --max-messages, 200, --group-instance-id, instance284476944, --group-id, my-consumer-group-1215756550, USER=my_cluster_ab9c640e_my_user_target, --bootstrap-server, my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t', podNamespace='namespace-123', bootstrapServer='my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-ab9c640e-source.mirrormaker2-topic-example-a-1200513152', maxMessages=200, kafkaUsername='my-cluster-ab9c640e-my-user-target', consumerGroupName='my-consumer-group-1215756550', consumerInstanceId='instance284476944', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@593f6582}
2022-04-05 01:28:02 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-ab9c640e-source.mirrormaker2-topic-example-a-1200513152 from pod my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t
2022-04-05 01:28:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t -n namespace-123 -- /opt/kafka/consumer.sh --topic my-cluster-ab9c640e-source.mirrormaker2-topic-example-a-1200513152 --max-messages 200 --group-instance-id instance284476944 --group-id my-consumer-group-1215756550 USER=my_cluster_ab9c640e_my_user_target --bootstrap-server my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:28:09 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:28:09 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:28:09 [main] [32mINFO [m [MirrorMaker2IsolatedST:1553] Messages successfully mirrored
2022-04-05 01:28:09 [main] [32mINFO [m [MirrorMaker2IsolatedST:1567] Renew Clients CA secret for Source cluster via annotation
2022-04-05 01:28:09 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-ab9c640e-source-clients-ca-cert with annotation strimzi.io/force-renew=true
2022-04-05 01:28:09 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ab9c640e-source-kafka rolling update
2022-04-05 01:29:34 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ab9c640e-source-kafka has been successfully rolled
2022-04-05 01:29:34 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-ab9c640e-source-kafka to be ready
2022-04-05 01:30:06 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-ab9c640e-mirrormaker2 rolling update
2022-04-05 01:31:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ab9c640e-mirrormaker2 will be ready
2022-04-05 01:31:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ab9c640e-mirrormaker2 is ready
2022-04-05 01:31:32 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-ab9c640e-mirrormaker2 rolling update finished
2022-04-05 01:31:32 [main] [32mINFO [m [MirrorMaker2IsolatedST:1573] Renew Clients CA secret for Target cluster via annotation
2022-04-05 01:31:32 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-ab9c640e-target-clients-ca-cert with annotation strimzi.io/force-renew=true
2022-04-05 01:31:32 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ab9c640e-target-kafka rolling update
2022-04-05 01:32:57 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ab9c640e-target-kafka has been successfully rolled
2022-04-05 01:32:57 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-ab9c640e-target-kafka to be ready
2022-04-05 01:33:30 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-ab9c640e-mirrormaker2 rolling update
2022-04-05 01:35:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ab9c640e-mirrormaker2 will be ready
2022-04-05 01:35:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ab9c640e-mirrormaker2 is ready
2022-04-05 01:35:20 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-ab9c640e-mirrormaker2 rolling update finished
2022-04-05 01:35:20 [main] [32mINFO [m [MirrorMaker2IsolatedST:1579] Send and receive messages after clients certs were removed
2022-04-05 01:35:20 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1f3f4529, messages=[], arguments=[--topic, mirrormaker2-topic-example-a-1200513152, --max-messages, 200, USER=my_cluster_ab9c640e_my_user_source, --bootstrap-server, my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t', podNamespace='namespace-123', bootstrapServer='my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-1200513152', maxMessages=200, kafkaUsername='my-cluster-ab9c640e-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@f799e19}
2022-04-05 01:35:20 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-1200513152 from pod my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t
2022-04-05 01:35:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t -n namespace-123 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-a-1200513152 --max-messages 200 USER=my_cluster_ab9c640e_my_user_source --bootstrap-server my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:35:24 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 01:35:24 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 01:35:24 [main] [32mINFO [m [MirrorMaker2IsolatedST:1595] Consumer in target cluster and topic should receive 200 messages
2022-04-05 01:35:24 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7aadb8b7, messages=[], arguments=[--topic, my-cluster-ab9c640e-source.mirrormaker2-topic-example-a-1200513152, --max-messages, 200, --group-instance-id, instance2131121711, --group-id, my-consumer-group-105320319, USER=my_cluster_ab9c640e_my_user_target, --bootstrap-server, my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t', podNamespace='namespace-123', bootstrapServer='my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-ab9c640e-source.mirrormaker2-topic-example-a-1200513152', maxMessages=200, kafkaUsername='my-cluster-ab9c640e-my-user-target', consumerGroupName='my-consumer-group-105320319', consumerInstanceId='instance2131121711', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@39e770c4}
2022-04-05 01:35:24 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-ab9c640e-source.mirrormaker2-topic-example-a-1200513152 from pod my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t
2022-04-05 01:35:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t -n namespace-123 -- /opt/kafka/consumer.sh --topic my-cluster-ab9c640e-source.mirrormaker2-topic-example-a-1200513152 --max-messages 200 --group-instance-id instance2131121711 --group-id my-consumer-group-105320319 USER=my_cluster_ab9c640e_my_user_target --bootstrap-server my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:35:32 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:35:32 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:35:32 [main] [32mINFO [m [MirrorMaker2IsolatedST:1597] Messages successfully mirrored
2022-04-05 01:35:32 [main] [32mINFO [m [MirrorMaker2IsolatedST:1599] Renew Cluster CA secret for Source clusters via annotation
2022-04-05 01:35:32 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-ab9c640e-source-cluster-ca-cert with annotation strimzi.io/force-renew=true
2022-04-05 01:35:32 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ab9c640e-source-zookeeper rolling update
2022-04-05 01:36:57 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ab9c640e-source-zookeeper has been successfully rolled
2022-04-05 01:36:57 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-ab9c640e-source-zookeeper to be ready
2022-04-05 01:37:30 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ab9c640e-source-kafka rolling update
2022-04-05 01:38:30 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ab9c640e-source-kafka has been successfully rolled
2022-04-05 01:38:30 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-ab9c640e-source-kafka to be ready
2022-04-05 01:38:58 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-ab9c640e-source-entity-operator rolling update
2022-04-05 01:38:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ab9c640e-source-entity-operator will be ready
2022-04-05 01:46:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ab9c640e-source-entity-operator is ready
2022-04-05 01:46:39 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-ab9c640e-source-entity-operator rolling update finished
2022-04-05 01:46:39 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-ab9c640e-mirrormaker2 rolling update
2022-04-05 01:46:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ab9c640e-mirrormaker2 will be ready
2022-04-05 01:46:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ab9c640e-mirrormaker2 is ready
2022-04-05 01:46:49 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-ab9c640e-mirrormaker2 rolling update finished
2022-04-05 01:46:49 [main] [32mINFO [m [MirrorMaker2IsolatedST:1607] Renew Cluster CA secret for Target clusters via annotation
2022-04-05 01:46:49 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-ab9c640e-target-cluster-ca-cert with annotation strimzi.io/force-renew=true
2022-04-05 01:46:49 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ab9c640e-target-zookeeper rolling update
2022-04-05 01:48:29 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ab9c640e-target-zookeeper has been successfully rolled
2022-04-05 01:48:29 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-ab9c640e-target-zookeeper to be ready
2022-04-05 01:48:56 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ab9c640e-target-kafka rolling update
2022-04-05 01:50:11 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ab9c640e-target-kafka has been successfully rolled
2022-04-05 01:50:11 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-ab9c640e-target-kafka to be ready
2022-04-05 01:50:37 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-ab9c640e-target-entity-operator rolling update
2022-04-05 01:50:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ab9c640e-target-entity-operator will be ready
2022-04-05 01:51:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ab9c640e-target-entity-operator is ready
2022-04-05 01:51:23 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-ab9c640e-target-entity-operator rolling update finished
2022-04-05 01:51:23 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-ab9c640e-mirrormaker2 rolling update
2022-04-05 01:51:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ab9c640e-mirrormaker2 will be ready
2022-04-05 01:51:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ab9c640e-mirrormaker2 is ready
2022-04-05 01:51:33 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-ab9c640e-mirrormaker2 rolling update finished
2022-04-05 01:51:33 [main] [32mINFO [m [MirrorMaker2IsolatedST:1615] Send and receive messages after clients certs were removed
2022-04-05 01:51:33 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@57dccc1a, messages=[], arguments=[--topic, mirrormaker2-topic-example-b-1460175146, --max-messages, 200, USER=my_cluster_ab9c640e_my_user_source, --bootstrap-server, my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t', podNamespace='namespace-123', bootstrapServer='my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-b-1460175146', maxMessages=200, kafkaUsername='my-cluster-ab9c640e-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1d8bc4}
2022-04-05 01:51:33 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-b-1460175146 from pod my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t
2022-04-05 01:51:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t -n namespace-123 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-b-1460175146 --max-messages 200 USER=my_cluster_ab9c640e_my_user_source --bootstrap-server my-cluster-ab9c640e-source-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:51:37 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 01:51:37 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 01:51:37 [main] [32mINFO [m [MirrorMaker2IsolatedST:1631] Consumer in target cluster and topic should receive 200 messages
2022-04-05 01:51:37 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3152b357, messages=[], arguments=[--topic, my-cluster-ab9c640e-source.mirrormaker2-topic-example-b-1460175146, --max-messages, 200, --group-instance-id, instance304087806, --group-id, my-consumer-group-1426147259, USER=my_cluster_ab9c640e_my_user_target, --bootstrap-server, my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t', podNamespace='namespace-123', bootstrapServer='my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-ab9c640e-source.mirrormaker2-topic-example-b-1460175146', maxMessages=200, kafkaUsername='my-cluster-ab9c640e-my-user-target', consumerGroupName='my-consumer-group-1426147259', consumerInstanceId='instance304087806', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5dfd5087}
2022-04-05 01:51:37 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-ab9c640e-source.mirrormaker2-topic-example-b-1460175146 from pod my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t
2022-04-05 01:51:37 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97303cf9-kafka-clients-b4fc4776c-fbw5t -n namespace-123 -- /opt/kafka/consumer.sh --topic my-cluster-ab9c640e-source.mirrormaker2-topic-example-b-1460175146 --max-messages 200 --group-instance-id instance304087806 --group-id my-consumer-group-1426147259 USER=my_cluster_ab9c640e_my_user_target --bootstrap-server my-cluster-ab9c640e-target-kafka-bootstrap.namespace-123.svc:9093
2022-04-05 01:51:45 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 01:51:45 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 01:51:45 [main] [32mINFO [m [MirrorMaker2IsolatedST:1633] Messages successfully mirrored
2022-04-05 01:51:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:51:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-05 01:51:45 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-97303cf9-kafka-clients in namespace namespace-123
2022-04-05 01:51:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-a-1200513152 in namespace namespace-123
2022-04-05 01:51:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ab9c640e-target in namespace namespace-123
2022-04-05 01:51:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-599102100-1299420527-test-2 in namespace namespace-123
2022-04-05 01:51:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ab9c640e-source in namespace namespace-123
2022-04-05 01:51:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-ab9c640e in namespace namespace-123
2022-04-05 01:52:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-ab9c640e-my-user-source in namespace namespace-123
2022-04-05 01:52:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-b-1460175146 in namespace namespace-123
2022-04-05 01:52:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-599102100-1299420527-test-1 in namespace namespace-123
2022-04-05 01:52:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-ab9c640e-my-user-target in namespace namespace-123
2022-04-05 01:52:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:52:25 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-123 for test case:testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-05 01:52:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateTLS-FINISHED
2022-04-05 01:52:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 01:52:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 01:52:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testStrimziIdentityReplicationPolicy-STARTED
2022-04-05 01:52:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 01:52:53 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-124 for test case:testStrimziIdentityReplicationPolicy
2022-04-05 01:52:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-124
2022-04-05 01:52:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-124
2022-04-05 01:52:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-124
2022-04-05 01:52:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4188c16e-source in namespace namespace-124
2022-04-05 01:52:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-05 01:52:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4188c16e-source will have desired state: Ready
2022-04-05 01:54:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4188c16e-source is in desired state: Ready
2022-04-05 01:54:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4188c16e-target in namespace namespace-124
2022-04-05 01:54:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-05 01:54:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4188c16e-target will have desired state: Ready
2022-04-05 01:55:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4188c16e-target is in desired state: Ready
2022-04-05 01:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-4188c16e in namespace namespace-124
2022-04-05 01:55:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-05 01:55:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-4188c16e will have desired state: Ready
2022-04-05 01:55:21 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-4188c16e is in desired state: Ready
2022-04-05 01:55:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4188c16e-kafka-clients in namespace namespace-124
2022-04-05 01:55:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-05 01:55:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-4188c16e in namespace namespace-124
2022-04-05 01:55:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-05 01:55:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-4188c16e will have desired state: Ready
2022-04-05 01:57:33 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-4188c16e is in desired state: Ready
2022-04-05 01:57:33 [main] [32mINFO [m [MirrorMaker2IsolatedST:902] Sending and receiving messages via my-cluster-4188c16e-source
2022-04-05 01:57:33 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 01:57:33 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3c9570e4, messages=[], arguments=[--topic, my-cluster-4188c16e, --max-messages, 100, --bootstrap-server, my-cluster-4188c16e-source-kafka-bootstrap.namespace-124.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4188c16e-kafka-clients-df7c9469d-62hjw', podNamespace='namespace-124', bootstrapServer='my-cluster-4188c16e-source-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-4188c16e', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5b9e05e2}
2022-04-05 01:57:33 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-4188c16e-source-kafka-bootstrap.namespace-124.svc:9092:my-cluster-4188c16e from pod my-cluster-4188c16e-kafka-clients-df7c9469d-62hjw
2022-04-05 01:57:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4188c16e-kafka-clients-df7c9469d-62hjw -n namespace-124 -- /opt/kafka/producer.sh --topic my-cluster-4188c16e --max-messages 100 --bootstrap-server my-cluster-4188c16e-source-kafka-bootstrap.namespace-124.svc:9092
2022-04-05 01:57:36 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 01:57:36 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 01:57:36 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@75e62a7a, messages=[], arguments=[--topic, my-cluster-4188c16e, --max-messages, 100, --group-instance-id, instance1095369609, --group-id, my-consumer-group-987076416, --bootstrap-server, my-cluster-4188c16e-source-kafka-bootstrap.namespace-124.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4188c16e-kafka-clients-df7c9469d-62hjw', podNamespace='namespace-124', bootstrapServer='my-cluster-4188c16e-source-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-4188c16e', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-987076416', consumerInstanceId='instance1095369609', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5efc8552}
2022-04-05 01:57:36 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4188c16e-source-kafka-bootstrap.namespace-124.svc:9092#my-cluster-4188c16e from pod my-cluster-4188c16e-kafka-clients-df7c9469d-62hjw
2022-04-05 01:57:36 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4188c16e-kafka-clients-df7c9469d-62hjw -n namespace-124 -- /opt/kafka/consumer.sh --topic my-cluster-4188c16e --max-messages 100 --group-instance-id instance1095369609 --group-id my-consumer-group-987076416 --bootstrap-server my-cluster-4188c16e-source-kafka-bootstrap.namespace-124.svc:9092
2022-04-05 01:57:41 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 01:57:41 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 01:57:41 [main] [32mINFO [m [MirrorMaker2IsolatedST:917] Changing to my-cluster-4188c16e-target and will try to receive messages
2022-04-05 01:57:41 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1509083d, messages=[], arguments=[--topic, my-cluster-4188c16e, --max-messages, 100, --group-instance-id, instance1480743448, --group-id, my-consumer-group-987076416, --bootstrap-server, my-cluster-4188c16e-target-kafka-bootstrap.namespace-124.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4188c16e-kafka-clients-df7c9469d-62hjw', podNamespace='namespace-124', bootstrapServer='my-cluster-4188c16e-target-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-4188c16e', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-987076416', consumerInstanceId='instance1480743448', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@62e37672}
2022-04-05 01:57:41 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4188c16e-target-kafka-bootstrap.namespace-124.svc:9092#my-cluster-4188c16e from pod my-cluster-4188c16e-kafka-clients-df7c9469d-62hjw
2022-04-05 01:57:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4188c16e-kafka-clients-df7c9469d-62hjw -n namespace-124 -- /opt/kafka/consumer.sh --topic my-cluster-4188c16e --max-messages 100 --group-instance-id instance1480743448 --group-id my-consumer-group-987076416 --bootstrap-server my-cluster-4188c16e-target-kafka-bootstrap.namespace-124.svc:9092
2022-04-05 01:57:47 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 01:57:47 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 01:57:47 [main] [32mINFO [m [MirrorMaker2IsolatedST:925] Checking if the mirrored topic name is same as the original one
2022-04-05 01:57:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-124 exec my-cluster-4188c16e-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 01:57:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 01:57:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-124 exec my-cluster-4188c16e-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-cluster-4188c16e
2022-04-05 01:57:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 01:57:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 01:57:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziIdentityReplicationPolicy
2022-04-05 01:57:53 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-4188c16e in namespace namespace-124
2022-04-05 01:57:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-4188c16e in namespace namespace-124
2022-04-05 01:57:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4188c16e-target in namespace namespace-124
2022-04-05 01:57:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4188c16e-kafka-clients in namespace namespace-124
2022-04-05 01:58:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4188c16e-source in namespace namespace-124
2022-04-05 01:58:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 01:58:33 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-124 for test case:testStrimziIdentityReplicationPolicy
2022-04-05 01:58:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testStrimziIdentityReplicationPolicy-FINISHED
2022-04-05 01:58:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 01:58:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 01:58:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2Subresource-STARTED
2022-04-05 01:58:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 01:58:39 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-125 for test case:testScaleMirrorMaker2Subresource
2022-04-05 01:58:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-125
2022-04-05 01:58:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-125
2022-04-05 01:58:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-125
2022-04-05 01:58:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-96d9d328-source in namespace namespace-125
2022-04-05 01:58:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-05 01:58:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-96d9d328-source will have desired state: Ready
2022-04-05 01:59:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-96d9d328-source is in desired state: Ready
2022-04-05 01:59:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-96d9d328-target in namespace namespace-125
2022-04-05 01:59:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-05 01:59:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-96d9d328-target will have desired state: Ready
2022-04-05 02:00:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-96d9d328-target is in desired state: Ready
2022-04-05 02:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-96d9d328 in namespace namespace-125
2022-04-05 02:00:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-05 02:00:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-96d9d328 will have desired state: Ready
2022-04-05 02:02:18 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-96d9d328 is in desired state: Ready
2022-04-05 02:02:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:675] -------> Scaling KafkaMirrorMaker2 subresource <-------
2022-04-05 02:02:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:676] Scaling subresource replicas to 4
2022-04-05 02:02:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-96d9d328-mirrormaker2 will be ready
2022-04-05 02:02:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-96d9d328-mirrormaker2 is ready
2022-04-05 02:02:18 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-96d9d328-mirrormaker2 to be ready
2022-04-05 02:03:34 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-96d9d328-mirrormaker2 is ready
2022-04-05 02:03:34 [main] [32mINFO [m [MirrorMaker2IsolatedST:680] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-05 02:03:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:03:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMaker2Subresource
2022-04-05 02:03:34 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-96d9d328-target in namespace namespace-125
2022-04-05 02:03:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-96d9d328 in namespace namespace-125
2022-04-05 02:03:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-96d9d328-source in namespace namespace-125
2022-04-05 02:03:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:03:54 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-125 for test case:testScaleMirrorMaker2Subresource
2022-04-05 02:03:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2Subresource-FINISHED
2022-04-05 02:03:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:03:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:03:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testIdentityReplicationPolicy-STARTED
2022-04-05 02:03:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:03:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-126 for test case:testIdentityReplicationPolicy
2022-04-05 02:03:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-126
2022-04-05 02:03:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-126
2022-04-05 02:03:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-126
2022-04-05 02:04:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a1c7a34f-source in namespace namespace-126
2022-04-05 02:04:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-05 02:04:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a1c7a34f-source will have desired state: Ready
2022-04-05 02:05:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a1c7a34f-source is in desired state: Ready
2022-04-05 02:05:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a1c7a34f-target in namespace namespace-126
2022-04-05 02:05:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-05 02:05:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a1c7a34f-target will have desired state: Ready
2022-04-05 02:06:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a1c7a34f-target is in desired state: Ready
2022-04-05 02:06:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-a1c7a34f in namespace namespace-126
2022-04-05 02:06:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-05 02:06:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-a1c7a34f will have desired state: Ready
2022-04-05 02:06:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-a1c7a34f is in desired state: Ready
2022-04-05 02:06:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a1c7a34f-kafka-clients in namespace namespace-126
2022-04-05 02:06:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-05 02:06:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-a1c7a34f in namespace namespace-126
2022-04-05 02:06:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-05 02:06:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-a1c7a34f will have desired state: Ready
2022-04-05 02:07:48 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-a1c7a34f is in desired state: Ready
2022-04-05 02:07:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:833] Sending and receiving messages via my-cluster-a1c7a34f-source
2022-04-05 02:07:48 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 02:07:48 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3486994c, messages=[], arguments=[--topic, my-cluster-a1c7a34f, --max-messages, 100, --bootstrap-server, my-cluster-a1c7a34f-source-kafka-bootstrap.namespace-126.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a1c7a34f-kafka-clients-69d4644dd6-czrct', podNamespace='namespace-126', bootstrapServer='my-cluster-a1c7a34f-source-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-a1c7a34f', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@356bdc7a}
2022-04-05 02:07:48 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-a1c7a34f-source-kafka-bootstrap.namespace-126.svc:9092:my-cluster-a1c7a34f from pod my-cluster-a1c7a34f-kafka-clients-69d4644dd6-czrct
2022-04-05 02:07:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a1c7a34f-kafka-clients-69d4644dd6-czrct -n namespace-126 -- /opt/kafka/producer.sh --topic my-cluster-a1c7a34f --max-messages 100 --bootstrap-server my-cluster-a1c7a34f-source-kafka-bootstrap.namespace-126.svc:9092
2022-04-05 02:07:51 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 02:07:51 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 02:07:51 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@286b5ca6, messages=[], arguments=[--topic, my-cluster-a1c7a34f, --max-messages, 100, --group-instance-id, instance1440084023, --group-id, my-consumer-group-1473391971, --bootstrap-server, my-cluster-a1c7a34f-source-kafka-bootstrap.namespace-126.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a1c7a34f-kafka-clients-69d4644dd6-czrct', podNamespace='namespace-126', bootstrapServer='my-cluster-a1c7a34f-source-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-a1c7a34f', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1473391971', consumerInstanceId='instance1440084023', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4388d0a1}
2022-04-05 02:07:51 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-a1c7a34f-source-kafka-bootstrap.namespace-126.svc:9092#my-cluster-a1c7a34f from pod my-cluster-a1c7a34f-kafka-clients-69d4644dd6-czrct
2022-04-05 02:07:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a1c7a34f-kafka-clients-69d4644dd6-czrct -n namespace-126 -- /opt/kafka/consumer.sh --topic my-cluster-a1c7a34f --max-messages 100 --group-instance-id instance1440084023 --group-id my-consumer-group-1473391971 --bootstrap-server my-cluster-a1c7a34f-source-kafka-bootstrap.namespace-126.svc:9092
2022-04-05 02:07:57 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 02:07:57 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 02:07:57 [main] [32mINFO [m [MirrorMaker2IsolatedST:848] Changing to my-cluster-a1c7a34f-target and will try to receive messages
2022-04-05 02:07:57 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@191abf60, messages=[], arguments=[--topic, my-cluster-a1c7a34f, --max-messages, 100, --group-instance-id, instance251581245, --group-id, my-consumer-group-1473391971, --bootstrap-server, my-cluster-a1c7a34f-target-kafka-bootstrap.namespace-126.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a1c7a34f-kafka-clients-69d4644dd6-czrct', podNamespace='namespace-126', bootstrapServer='my-cluster-a1c7a34f-target-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-a1c7a34f', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1473391971', consumerInstanceId='instance251581245', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2827ec1e}
2022-04-05 02:07:57 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-a1c7a34f-target-kafka-bootstrap.namespace-126.svc:9092#my-cluster-a1c7a34f from pod my-cluster-a1c7a34f-kafka-clients-69d4644dd6-czrct
2022-04-05 02:07:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a1c7a34f-kafka-clients-69d4644dd6-czrct -n namespace-126 -- /opt/kafka/consumer.sh --topic my-cluster-a1c7a34f --max-messages 100 --group-instance-id instance251581245 --group-id my-consumer-group-1473391971 --bootstrap-server my-cluster-a1c7a34f-target-kafka-bootstrap.namespace-126.svc:9092
2022-04-05 02:08:02 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 02:08:02 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 02:08:02 [main] [32mINFO [m [MirrorMaker2IsolatedST:856] Checking if the mirrored topic name is same as the original one
2022-04-05 02:08:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-126 exec my-cluster-a1c7a34f-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 02:08:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 02:08:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-126 exec my-cluster-a1c7a34f-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-cluster-a1c7a34f
2022-04-05 02:08:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 02:08:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:08:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIdentityReplicationPolicy
2022-04-05 02:08:08 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-a1c7a34f in namespace namespace-126
2022-04-05 02:08:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-a1c7a34f in namespace namespace-126
2022-04-05 02:08:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a1c7a34f-target in namespace namespace-126
2022-04-05 02:08:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a1c7a34f-source in namespace namespace-126
2022-04-05 02:08:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a1c7a34f-kafka-clients in namespace namespace-126
2022-04-05 02:09:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:09:08 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-126 for test case:testIdentityReplicationPolicy
2022-04-05 02:09:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testIdentityReplicationPolicy-FINISHED
2022-04-05 02:09:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:09:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:09:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateScramsha-STARTED
2022-04-05 02:09:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:09:13 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-127 for test case:testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-05 02:09:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-127
2022-04-05 02:09:14 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-127
2022-04-05 02:09:14 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-127
2022-04-05 02:09:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-14f58889-source in namespace namespace-127
2022-04-05 02:09:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 02:09:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-14f58889-source will have desired state: Ready
2022-04-05 02:10:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-14f58889-source is in desired state: Ready
2022-04-05 02:10:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-14f58889-target in namespace namespace-127
2022-04-05 02:10:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 02:10:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-14f58889-target will have desired state: Ready
2022-04-05 02:11:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-14f58889-target is in desired state: Ready
2022-04-05 02:11:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-a-1895570745 in namespace namespace-127
2022-04-05 02:11:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 02:11:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-b-860256834 in namespace namespace-127
2022-04-05 02:11:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 02:11:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-a-1895570745 will have desired state: Ready
2022-04-05 02:11:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-a-1895570745 is in desired state: Ready
2022-04-05 02:11:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-b-860256834 will have desired state: Ready
2022-04-05 02:11:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-b-860256834 is in desired state: Ready
2022-04-05 02:11:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-14f58889-my-user-source in namespace namespace-127
2022-04-05 02:11:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 02:11:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-14f58889-my-user-target in namespace namespace-127
2022-04-05 02:11:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 02:11:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-14f58889-my-user-source will have desired state: Ready
2022-04-05 02:11:38 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-14f58889-my-user-source is in desired state: Ready
2022-04-05 02:11:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-14f58889-my-user-target will have desired state: Ready
2022-04-05 02:11:38 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-14f58889-my-user-target is in desired state: Ready
2022-04-05 02:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-14f58889-kafka-clients in namespace namespace-127
2022-04-05 02:11:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 02:11:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-14f58889-kafka-clients will be ready
2022-04-05 02:11:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-14f58889-kafka-clients is ready
2022-04-05 02:11:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-14f58889 in namespace namespace-127
2022-04-05 02:11:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 02:11:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-14f58889 will have desired state: Ready
2022-04-05 02:12:49 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-14f58889 is in desired state: Ready
2022-04-05 02:12:49 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 02:12:49 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4d54d507, messages=[], arguments=[--topic, mirrormaker2-topic-example-a-1895570745, --max-messages, 200, USER=my_cluster_14f58889_my_user_source, --bootstrap-server, my-cluster-14f58889-source-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-14f58889-kafka-clients-5c956c8d96-klmdz', podNamespace='namespace-127', bootstrapServer='my-cluster-14f58889-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-a-1895570745', maxMessages=200, kafkaUsername='my-cluster-14f58889-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6a141a13}
2022-04-05 02:12:49 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-14f58889-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-a-1895570745 from pod my-cluster-14f58889-kafka-clients-5c956c8d96-klmdz
2022-04-05 02:12:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-14f58889-kafka-clients-5c956c8d96-klmdz -n namespace-127 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-a-1895570745 --max-messages 200 USER=my_cluster_14f58889_my_user_source --bootstrap-server my-cluster-14f58889-source-kafka-bootstrap.namespace-127.svc:9093
2022-04-05 02:12:53 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:12:53 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:12:53 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@54d910b9, messages=[], arguments=[--topic, mirrormaker2-topic-example-a-1895570745, --max-messages, 200, --group-instance-id, instance1031848742, --group-id, my-consumer-group-99414408, USER=my_cluster_14f58889_my_user_source, --bootstrap-server, my-cluster-14f58889-source-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-14f58889-kafka-clients-5c956c8d96-klmdz', podNamespace='namespace-127', bootstrapServer='my-cluster-14f58889-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-a-1895570745', maxMessages=200, kafkaUsername='my-cluster-14f58889-my-user-source', consumerGroupName='my-consumer-group-99414408', consumerInstanceId='instance1031848742', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1ed745f2}
2022-04-05 02:12:53 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-14f58889-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-a-1895570745 from pod my-cluster-14f58889-kafka-clients-5c956c8d96-klmdz
2022-04-05 02:12:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-14f58889-kafka-clients-5c956c8d96-klmdz -n namespace-127 -- /opt/kafka/consumer.sh --topic mirrormaker2-topic-example-a-1895570745 --max-messages 200 --group-instance-id instance1031848742 --group-id my-consumer-group-99414408 USER=my_cluster_14f58889_my_user_source --bootstrap-server my-cluster-14f58889-source-kafka-bootstrap.namespace-127.svc:9093
2022-04-05 02:13:00 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:13:00 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:13:00 [main] [32mINFO [m [MirrorMaker2IsolatedST:1338] Now messages should be mirrored to target topic and cluster
2022-04-05 02:13:00 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@73d39454, messages=[], arguments=[--topic, my-cluster-14f58889-source.mirrormaker2-topic-example-a-1895570745, --max-messages, 200, --group-instance-id, instance2108451572, --group-id, my-consumer-group-5531602, USER=my_cluster_14f58889_my_user_target, --bootstrap-server, my-cluster-14f58889-target-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-14f58889-kafka-clients-5c956c8d96-klmdz', podNamespace='namespace-127', bootstrapServer='my-cluster-14f58889-target-kafka-bootstrap.namespace-127.svc:9093', topicName='my-cluster-14f58889-source.mirrormaker2-topic-example-a-1895570745', maxMessages=200, kafkaUsername='my-cluster-14f58889-my-user-target', consumerGroupName='my-consumer-group-5531602', consumerInstanceId='instance2108451572', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3f4e0bc8}
2022-04-05 02:13:00 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-14f58889-target-kafka-bootstrap.namespace-127.svc:9093:my-cluster-14f58889-source.mirrormaker2-topic-example-a-1895570745 from pod my-cluster-14f58889-kafka-clients-5c956c8d96-klmdz
2022-04-05 02:13:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-14f58889-kafka-clients-5c956c8d96-klmdz -n namespace-127 -- /opt/kafka/consumer.sh --topic my-cluster-14f58889-source.mirrormaker2-topic-example-a-1895570745 --max-messages 200 --group-instance-id instance2108451572 --group-id my-consumer-group-5531602 USER=my_cluster_14f58889_my_user_target --bootstrap-server my-cluster-14f58889-target-kafka-bootstrap.namespace-127.svc:9093
2022-04-05 02:13:07 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:13:07 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:13:07 [main] [32mINFO [m [MirrorMaker2IsolatedST:1340] Messages successfully mirrored
2022-04-05 02:13:07 [main] [32mINFO [m [MirrorMaker2IsolatedST:1344] Changing KafkaUser sha-password on KMM2 Source and make sure it rolled
2022-04-05 02:13:07 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-14f58889-mirrormaker2 rolling update
2022-04-05 02:14:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-14f58889-mirrormaker2 will be ready
2022-04-05 02:14:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-14f58889-mirrormaker2 is ready
2022-04-05 02:14:37 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-14f58889-mirrormaker2 rolling update finished
2022-04-05 02:14:37 [main] [32mINFO [m [MirrorMaker2IsolatedST:1354] Changing KafkaUser sha-password on KMM2 Target
2022-04-05 02:14:37 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-14f58889-mirrormaker2 rolling update
2022-04-05 02:16:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-14f58889-mirrormaker2 will be ready
2022-04-05 02:16:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-14f58889-mirrormaker2 is ready
2022-04-05 02:16:37 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-14f58889-mirrormaker2 rolling update finished
2022-04-05 02:16:37 [main] [32mINFO [m [MirrorMaker2IsolatedST:1364] Recreate kafkaClients pod with new passwords.
2022-04-05 02:16:37 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-14f58889-kafka-clients in namespace namespace-127
2022-04-05 02:17:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-14f58889-kafka-clients in namespace namespace-127
2022-04-05 02:17:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-05 02:17:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-14f58889-kafka-clients will be ready
2022-04-05 02:17:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-14f58889-kafka-clients is ready
2022-04-05 02:17:18 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@284abe68, messages=[], arguments=[--topic, mirrormaker2-topic-example-b-860256834, --max-messages, 200, USER=my_cluster_14f58889_my_user_source, --bootstrap-server, my-cluster-14f58889-source-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-14f58889-kafka-clients-75c66b748b-nfqbh', podNamespace='namespace-127', bootstrapServer='my-cluster-14f58889-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-b-860256834', maxMessages=200, kafkaUsername='my-cluster-14f58889-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@513f7153}
2022-04-05 02:17:18 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-14f58889-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-b-860256834 from pod my-cluster-14f58889-kafka-clients-75c66b748b-nfqbh
2022-04-05 02:17:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-14f58889-kafka-clients-75c66b748b-nfqbh -n namespace-127 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-b-860256834 --max-messages 200 USER=my_cluster_14f58889_my_user_source --bootstrap-server my-cluster-14f58889-source-kafka-bootstrap.namespace-127.svc:9093
2022-04-05 02:17:22 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:17:22 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:17:22 [main] [32mINFO [m [MirrorMaker2IsolatedST:1385] Now messages should be mirrored to target topic and cluster
2022-04-05 02:17:22 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2a6e6667, messages=[], arguments=[--topic, my-cluster-14f58889-source.mirrormaker2-topic-example-b-860256834, --max-messages, 200, --group-instance-id, instance1619576963, --group-id, my-consumer-group-1411156734, USER=my_cluster_14f58889_my_user_target, --bootstrap-server, my-cluster-14f58889-target-kafka-bootstrap.namespace-127.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-14f58889-kafka-clients-75c66b748b-nfqbh', podNamespace='namespace-127', bootstrapServer='my-cluster-14f58889-target-kafka-bootstrap.namespace-127.svc:9093', topicName='my-cluster-14f58889-source.mirrormaker2-topic-example-b-860256834', maxMessages=200, kafkaUsername='my-cluster-14f58889-my-user-target', consumerGroupName='my-consumer-group-1411156734', consumerInstanceId='instance1619576963', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@713ad3}
2022-04-05 02:17:22 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-14f58889-target-kafka-bootstrap.namespace-127.svc:9093:my-cluster-14f58889-source.mirrormaker2-topic-example-b-860256834 from pod my-cluster-14f58889-kafka-clients-75c66b748b-nfqbh
2022-04-05 02:17:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-14f58889-kafka-clients-75c66b748b-nfqbh -n namespace-127 -- /opt/kafka/consumer.sh --topic my-cluster-14f58889-source.mirrormaker2-topic-example-b-860256834 --max-messages 200 --group-instance-id instance1619576963 --group-id my-consumer-group-1411156734 USER=my_cluster_14f58889_my_user_target --bootstrap-server my-cluster-14f58889-target-kafka-bootstrap.namespace-127.svc:9093
2022-04-05 02:17:30 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:17:30 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:17:30 [main] [32mINFO [m [MirrorMaker2IsolatedST:1387] Messages successfully mirrored
2022-04-05 02:17:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:17:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-05 02:17:30 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-14f58889-my-user-target in namespace namespace-127
2022-04-05 02:17:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-a-1895570745 in namespace namespace-127
2022-04-05 02:17:30 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-14f58889 in namespace namespace-127
2022-04-05 02:17:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-14f58889-target in namespace namespace-127
2022-04-05 02:17:40 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-14f58889-my-user-source in namespace namespace-127
2022-04-05 02:17:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-14f58889-kafka-clients in namespace namespace-127
2022-04-05 02:17:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-14f58889-source in namespace namespace-127
2022-04-05 02:17:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-b-860256834 in namespace namespace-127
2022-04-05 02:17:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-14f58889-kafka-clients in namespace namespace-127
2022-04-05 02:18:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:18:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-127 for test case:testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-05 02:18:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateScramsha-FINISHED
2022-04-05 02:18:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:18:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:18:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndTlsClientAuth-STARTED
2022-04-05 02:18:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:18:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-128 for test case:testMirrorMaker2TlsAndTlsClientAuth
2022-04-05 02:18:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-128
2022-04-05 02:18:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-128
2022-04-05 02:18:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-128
2022-04-05 02:18:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ab3e5fcc-source in namespace namespace-128
2022-04-05 02:18:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 02:18:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ab3e5fcc-source will have desired state: Ready
2022-04-05 02:19:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ab3e5fcc-source is in desired state: Ready
2022-04-05 02:19:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ab3e5fcc-target in namespace namespace-128
2022-04-05 02:19:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 02:19:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ab3e5fcc-target will have desired state: Ready
2022-04-05 02:21:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ab3e5fcc-target is in desired state: Ready
2022-04-05 02:21:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-1961472536 in namespace namespace-128
2022-04-05 02:21:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 02:21:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-1961472536 will have desired state: Ready
2022-04-05 02:21:04 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-1961472536 is in desired state: Ready
2022-04-05 02:21:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-ab3e5fcc-my-user-source in namespace namespace-128
2022-04-05 02:21:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 02:21:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-ab3e5fcc-my-user-source will have desired state: Ready
2022-04-05 02:21:05 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-ab3e5fcc-my-user-source is in desired state: Ready
2022-04-05 02:21:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-ab3e5fcc-my-user-target in namespace namespace-128
2022-04-05 02:21:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 02:21:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-ab3e5fcc-my-user-target will have desired state: Ready
2022-04-05 02:21:06 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-ab3e5fcc-my-user-target is in desired state: Ready
2022-04-05 02:21:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ab3e5fcc-kafka-clients in namespace namespace-128
2022-04-05 02:21:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 02:21:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-641866357-149286715-test-1 in namespace namespace-128
2022-04-05 02:21:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 02:21:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-641866357-149286715-test-1 will have desired state: Ready
2022-04-05 02:21:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-641866357-149286715-test-1 is in desired state: Ready
2022-04-05 02:21:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-641866357-149286715-test-2 in namespace namespace-128
2022-04-05 02:21:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 02:21:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-641866357-149286715-test-2 will have desired state: Ready
2022-04-05 02:21:18 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-641866357-149286715-test-2 is in desired state: Ready
2022-04-05 02:21:18 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 02:21:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-754247784-2034123831 in namespace namespace-128
2022-04-05 02:21:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 02:21:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-754247784-2034123831 will have desired state: Ready
2022-04-05 02:21:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-754247784-2034123831 is in desired state: Ready
2022-04-05 02:21:19 [main] [32mINFO [m [ClientUtils:127] Sending messages to - topic my-topic-641866357-149286715-test-1, cluster my-cluster-ab3e5fcc-source and message count of 200
2022-04-05 02:21:19 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@38b9e8a1, messages=[], arguments=[--topic, my-topic-754247784-2034123831, --max-messages, 200, USER=my_cluster_ab3e5fcc_my_user_source, --bootstrap-server, my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh', podNamespace='namespace-128', bootstrapServer='my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-754247784-2034123831', maxMessages=200, kafkaUsername='my-cluster-ab3e5fcc-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@20a98435}
2022-04-05 02:21:19 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093:my-topic-754247784-2034123831 from pod my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh
2022-04-05 02:21:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh -n namespace-128 -- /opt/kafka/producer.sh --topic my-topic-754247784-2034123831 --max-messages 200 USER=my_cluster_ab3e5fcc_my_user_source --bootstrap-server my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 02:21:23 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:21:23 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:21:23 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@64a1f6b5, messages=[], arguments=[--topic, my-topic-754247784-2034123831, --max-messages, 200, --group-instance-id, instance1018996279, --group-id, my-consumer-group-698936365, USER=my_cluster_ab3e5fcc_my_user_source, --bootstrap-server, my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh', podNamespace='namespace-128', bootstrapServer='my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-754247784-2034123831', maxMessages=200, kafkaUsername='my-cluster-ab3e5fcc-my-user-source', consumerGroupName='my-consumer-group-698936365', consumerInstanceId='instance1018996279', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@84553a4}
2022-04-05 02:21:23 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093:my-topic-754247784-2034123831 from pod my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh
2022-04-05 02:21:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh -n namespace-128 -- /opt/kafka/consumer.sh --topic my-topic-754247784-2034123831 --max-messages 200 --group-instance-id instance1018996279 --group-id my-consumer-group-698936365 USER=my_cluster_ab3e5fcc_my_user_source --bootstrap-server my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 02:21:30 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:21:30 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:21:30 [main] [32mINFO [m [ClientUtils:133] Sent 200 and received 200
2022-04-05 02:21:30 [main] [32mINFO [m [MirrorMaker2IsolatedST:328] Setting topic to my-topic-641866357-149286715-test-2, cluster to my-cluster-ab3e5fcc-target and changing user to my-cluster-ab3e5fcc-my-user-target
2022-04-05 02:21:30 [main] [32mINFO [m [MirrorMaker2IsolatedST:337] Sending messages to - topic my-topic-641866357-149286715-test-2, cluster my-cluster-ab3e5fcc-target and message count of 200
2022-04-05 02:21:30 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5e947d91, messages=[], arguments=[--topic, my-topic-641866357-149286715-test-2, --max-messages, 200, USER=my_cluster_ab3e5fcc_my_user_target, --bootstrap-server, my-cluster-ab3e5fcc-target-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh', podNamespace='namespace-128', bootstrapServer='my-cluster-ab3e5fcc-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-641866357-149286715-test-2', maxMessages=200, kafkaUsername='my-cluster-ab3e5fcc-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@132ae660}
2022-04-05 02:21:30 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-ab3e5fcc-target-kafka-bootstrap.namespace-128.svc:9093:my-topic-641866357-149286715-test-2 from pod my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh
2022-04-05 02:21:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh -n namespace-128 -- /opt/kafka/producer.sh --topic my-topic-641866357-149286715-test-2 --max-messages 200 USER=my_cluster_ab3e5fcc_my_user_target --bootstrap-server my-cluster-ab3e5fcc-target-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 02:21:33 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:21:33 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:21:33 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@171198f2, messages=[], arguments=[--topic, my-topic-641866357-149286715-test-2, --max-messages, 200, --group-instance-id, instance2114016790, --group-id, my-consumer-group-514964804, USER=my_cluster_ab3e5fcc_my_user_target, --bootstrap-server, my-cluster-ab3e5fcc-target-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh', podNamespace='namespace-128', bootstrapServer='my-cluster-ab3e5fcc-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-641866357-149286715-test-2', maxMessages=200, kafkaUsername='my-cluster-ab3e5fcc-my-user-target', consumerGroupName='my-consumer-group-514964804', consumerInstanceId='instance2114016790', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7c6edd94}
2022-04-05 02:21:33 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-ab3e5fcc-target-kafka-bootstrap.namespace-128.svc:9093:my-topic-641866357-149286715-test-2 from pod my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh
2022-04-05 02:21:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh -n namespace-128 -- /opt/kafka/consumer.sh --topic my-topic-641866357-149286715-test-2 --max-messages 200 --group-instance-id instance2114016790 --group-id my-consumer-group-514964804 USER=my_cluster_ab3e5fcc_my_user_target --bootstrap-server my-cluster-ab3e5fcc-target-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 02:21:40 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:21:40 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:21:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-ab3e5fcc in namespace namespace-128
2022-04-05 02:21:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-05 02:21:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-ab3e5fcc will have desired state: Ready
2022-04-05 02:22:52 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-ab3e5fcc is in desired state: Ready
2022-04-05 02:22:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:397] Setting topic to mirrormaker2-topic-example-1961472536, cluster to my-cluster-ab3e5fcc-source and changing user to my-cluster-ab3e5fcc-my-user-source
2022-04-05 02:22:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:407] Sending messages to - topic mirrormaker2-topic-example-1961472536, cluster my-cluster-ab3e5fcc-source and message count of 200
2022-04-05 02:22:52 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3f0cc2d9, messages=[], arguments=[--topic, mirrormaker2-topic-example-1961472536, --max-messages, 200, USER=my_cluster_ab3e5fcc_my_user_source, --bootstrap-server, my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh', podNamespace='namespace-128', bootstrapServer='my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093', topicName='mirrormaker2-topic-example-1961472536', maxMessages=200, kafkaUsername='my-cluster-ab3e5fcc-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@244108ab}
2022-04-05 02:22:52 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093:mirrormaker2-topic-example-1961472536 from pod my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh
2022-04-05 02:22:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh -n namespace-128 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-1961472536 --max-messages 200 USER=my_cluster_ab3e5fcc_my_user_source --bootstrap-server my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 02:22:56 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:22:56 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:22:56 [main] [32mINFO [m [MirrorMaker2IsolatedST:411] Receiving messages from - topic mirrormaker2-topic-example-1961472536, cluster my-cluster-ab3e5fcc-source and message count of 200
2022-04-05 02:22:56 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@42c8df06, messages=[], arguments=[--topic, mirrormaker2-topic-example-1961472536, --max-messages, 200, --group-instance-id, instance717377745, --group-id, my-consumer-group-514964804, USER=my_cluster_ab3e5fcc_my_user_source, --bootstrap-server, my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh', podNamespace='namespace-128', bootstrapServer='my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093', topicName='mirrormaker2-topic-example-1961472536', maxMessages=200, kafkaUsername='my-cluster-ab3e5fcc-my-user-source', consumerGroupName='my-consumer-group-514964804', consumerInstanceId='instance717377745', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6e609631}
2022-04-05 02:22:56 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093:mirrormaker2-topic-example-1961472536 from pod my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh
2022-04-05 02:22:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh -n namespace-128 -- /opt/kafka/consumer.sh --topic mirrormaker2-topic-example-1961472536 --max-messages 200 --group-instance-id instance717377745 --group-id my-consumer-group-514964804 USER=my_cluster_ab3e5fcc_my_user_source --bootstrap-server my-cluster-ab3e5fcc-source-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 02:23:03 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:23:03 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:23:03 [main] [32mINFO [m [MirrorMaker2IsolatedST:418] Now setting topic to my-cluster-ab3e5fcc-source.mirrormaker2-topic-example-1961472536, cluster to my-cluster-ab3e5fcc-target and user to my-cluster-ab3e5fcc-my-user-target - the messages should be mirrored
2022-04-05 02:23:03 [main] [32mINFO [m [MirrorMaker2IsolatedST:427] Consumer in target cluster and topic should receive 200 messages
2022-04-05 02:23:03 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@77b8b32e, messages=[], arguments=[--topic, my-cluster-ab3e5fcc-source.mirrormaker2-topic-example-1961472536, --max-messages, 200, --group-instance-id, instance691177586, --group-id, my-consumer-group-514964804, USER=my_cluster_ab3e5fcc_my_user_target, --bootstrap-server, my-cluster-ab3e5fcc-target-kafka-bootstrap.namespace-128.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh', podNamespace='namespace-128', bootstrapServer='my-cluster-ab3e5fcc-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-cluster-ab3e5fcc-source.mirrormaker2-topic-example-1961472536', maxMessages=200, kafkaUsername='my-cluster-ab3e5fcc-my-user-target', consumerGroupName='my-consumer-group-514964804', consumerInstanceId='instance691177586', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1b8bc78c}
2022-04-05 02:23:03 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-ab3e5fcc-target-kafka-bootstrap.namespace-128.svc:9093:my-cluster-ab3e5fcc-source.mirrormaker2-topic-example-1961472536 from pod my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh
2022-04-05 02:23:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ab3e5fcc-kafka-clients-74b544f998-krlsh -n namespace-128 -- /opt/kafka/consumer.sh --topic my-cluster-ab3e5fcc-source.mirrormaker2-topic-example-1961472536 --max-messages 200 --group-instance-id instance691177586 --group-id my-consumer-group-514964804 USER=my_cluster_ab3e5fcc_my_user_target --bootstrap-server my-cluster-ab3e5fcc-target-kafka-bootstrap.namespace-128.svc:9093
2022-04-05 02:23:10 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:23:10 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:23:10 [main] [32mINFO [m [MirrorMaker2IsolatedST:432] Messages successfully mirrored
2022-04-05 02:23:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:23:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2TlsAndTlsClientAuth
2022-04-05 02:23:10 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-641866357-149286715-test-1 in namespace namespace-128
2022-04-05 02:23:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-1961472536 in namespace namespace-128
2022-04-05 02:23:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-754247784-2034123831 in namespace namespace-128
2022-04-05 02:23:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ab3e5fcc-target in namespace namespace-128
2022-04-05 02:23:20 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ab3e5fcc-kafka-clients in namespace namespace-128
2022-04-05 02:23:20 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ab3e5fcc-source in namespace namespace-128
2022-04-05 02:23:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-ab3e5fcc in namespace namespace-128
2022-04-05 02:23:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-ab3e5fcc-my-user-target in namespace namespace-128
2022-04-05 02:23:30 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-ab3e5fcc-my-user-source in namespace namespace-128
2022-04-05 02:23:30 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-641866357-149286715-test-2 in namespace namespace-128
2022-04-05 02:24:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:24:10 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-128 for test case:testMirrorMaker2TlsAndTlsClientAuth
2022-04-05 02:24:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndTlsClientAuth-FINISHED
2022-04-05 02:24:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:24:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:24:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-05 02:24:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:24:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-129 for test case:testConfigureDeploymentStrategy
2022-04-05 02:24:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-129
2022-04-05 02:24:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-129
2022-04-05 02:24:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-129
2022-04-05 02:24:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-975148f8-source in namespace namespace-129
2022-04-05 02:24:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-05 02:24:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-975148f8-source will have desired state: Ready
2022-04-05 02:25:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-975148f8-source is in desired state: Ready
2022-04-05 02:25:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-975148f8-target in namespace namespace-129
2022-04-05 02:25:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-05 02:25:19 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-975148f8-target will have desired state: Ready
2022-04-05 02:26:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-975148f8-target is in desired state: Ready
2022-04-05 02:26:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-975148f8 in namespace namespace-129
2022-04-05 02:26:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-05 02:26:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-975148f8 will have desired state: Ready
2022-04-05 02:27:48 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-975148f8 is in desired state: Ready
2022-04-05 02:27:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:959] Adding label to MirrorMaker2 resource, the CR should be recreated
2022-04-05 02:27:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-975148f8-mirrormaker2 will be ready
2022-04-05 02:27:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-975148f8-mirrormaker2 is ready
2022-04-05 02:27:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-975148f8-mirrormaker2 to be ready
2022-04-05 02:29:08 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-975148f8-mirrormaker2 is ready
2022-04-05 02:29:08 [main] [32mINFO [m [MirrorMaker2IsolatedST:966] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-05 02:29:08 [main] [32mINFO [m [MirrorMaker2IsolatedST:971] Changing deployment strategy to ROLLING_UPDATE
2022-04-05 02:29:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-975148f8 will have desired state: Ready
2022-04-05 02:29:08 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-975148f8 is in desired state: Ready
2022-04-05 02:29:08 [main] [32mINFO [m [MirrorMaker2IsolatedST:976] Adding another label to MirrorMaker2 resource, pods should be rolled
2022-04-05 02:29:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-975148f8-mirrormaker2 will be ready
2022-04-05 02:29:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-975148f8-mirrormaker2 is ready
2022-04-05 02:29:08 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-975148f8-mirrormaker2 to be ready
2022-04-05 02:30:36 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-975148f8-mirrormaker2 is ready
2022-04-05 02:30:36 [main] [32mINFO [m [MirrorMaker2IsolatedST:980] Checking that observed gen. higher (rolling update) and label is changed
2022-04-05 02:30:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:30:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-05 02:30:36 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-975148f8-target in namespace namespace-129
2022-04-05 02:30:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-975148f8-source in namespace namespace-129
2022-04-05 02:30:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-975148f8 in namespace namespace-129
2022-04-05 02:30:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:30:56 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-129 for test case:testConfigureDeploymentStrategy
2022-04-05 02:31:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-05 02:31:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:31:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:31:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2CorrectlyMirrorsHeaders-STARTED
2022-04-05 02:31:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:31:23 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-130 for test case:testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-05 02:31:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-130
2022-04-05 02:31:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-130
2022-04-05 02:31:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-130
2022-04-05 02:31:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e8553fa2-source in namespace namespace-130
2022-04-05 02:31:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-05 02:31:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e8553fa2-source will have desired state: Ready
2022-04-05 02:32:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e8553fa2-source is in desired state: Ready
2022-04-05 02:32:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e8553fa2-target in namespace namespace-130
2022-04-05 02:32:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-05 02:32:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e8553fa2-target will have desired state: Ready
2022-04-05 02:33:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e8553fa2-target is in desired state: Ready
2022-04-05 02:33:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-e8553fa2-source-example-topic in namespace namespace-130
2022-04-05 02:33:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-05 02:33:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-e8553fa2-source-example-topic will have desired state: Ready
2022-04-05 02:33:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-e8553fa2-source-example-topic is in desired state: Ready
2022-04-05 02:33:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-e8553fa2 in namespace namespace-130
2022-04-05 02:33:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-05 02:33:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-e8553fa2 will have desired state: Ready
2022-04-05 02:34:48 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-e8553fa2 is in desired state: Ready
2022-04-05 02:34:48 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 02:34:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-e8553fa2-target-consumer in namespace namespace-130
2022-04-05 02:34:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-05 02:34:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-e8553fa2-target-consumer will be in active state
2022-04-05 02:34:49 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 02:34:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-e8553fa2-source-producer in namespace namespace-130
2022-04-05 02:34:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-05 02:34:49 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-e8553fa2-source-producer will be in active state
2022-04-05 02:34:50 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-e8553fa2-source-producer and consumer my-cluster-e8553fa2-target-consumer finish
2022-04-05 02:36:34 [main] [32mINFO [m [MirrorMaker2IsolatedST:753] Checking log of my-cluster-e8553fa2-target-consumer job if the headers are correct
2022-04-05 02:36:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:36:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-05 02:36:34 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-e8553fa2 in namespace namespace-130
2022-04-05 02:36:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-e8553fa2-source-producer in namespace namespace-130
2022-04-05 02:36:34 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e8553fa2-target in namespace namespace-130
2022-04-05 02:36:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e8553fa2-source in namespace namespace-130
2022-04-05 02:36:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-e8553fa2-target-consumer in namespace namespace-130
2022-04-05 02:36:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-e8553fa2-source-example-topic in namespace namespace-130
2022-04-05 02:36:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:36:54 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-130 for test case:testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-05 02:37:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2CorrectlyMirrorsHeaders-FINISHED
2022-04-05 02:37:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:37:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:37:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndScramSha512Auth-STARTED
2022-04-05 02:37:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:37:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-131 for test case:testMirrorMaker2TlsAndScramSha512Auth
2022-04-05 02:37:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-131
2022-04-05 02:37:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-131
2022-04-05 02:37:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-131
2022-04-05 02:37:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e6b90d35-source in namespace namespace-131
2022-04-05 02:37:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:37:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e6b90d35-source will have desired state: Ready
2022-04-05 02:38:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e6b90d35-source is in desired state: Ready
2022-04-05 02:38:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e6b90d35-target in namespace namespace-131
2022-04-05 02:38:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:38:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e6b90d35-target will have desired state: Ready
2022-04-05 02:39:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e6b90d35-target is in desired state: Ready
2022-04-05 02:39:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-34724858 in namespace namespace-131
2022-04-05 02:39:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:39:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-34724858 will have desired state: Ready
2022-04-05 02:39:42 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-34724858 is in desired state: Ready
2022-04-05 02:39:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-e6b90d35-my-user-source in namespace namespace-131
2022-04-05 02:39:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:39:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-e6b90d35-my-user-source will have desired state: Ready
2022-04-05 02:39:43 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-e6b90d35-my-user-source is in desired state: Ready
2022-04-05 02:39:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-e6b90d35-my-user-target in namespace namespace-131
2022-04-05 02:39:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:39:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-e6b90d35-my-user-target will have desired state: Ready
2022-04-05 02:39:44 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-e6b90d35-my-user-target is in desired state: Ready
2022-04-05 02:39:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-e6b90d35-kafka-clients in namespace namespace-131
2022-04-05 02:39:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:39:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e6b90d35-kafka-clients will be ready
2022-04-05 02:39:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e6b90d35-kafka-clients is ready
2022-04-05 02:39:46 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 02:39:46 [main] [32mINFO [m [MirrorMaker2IsolatedST:536] Sending messages to - topic availability-topic-source-my-topic-1190822742-1952915659, cluster my-cluster-e6b90d35-source and message count of 200
2022-04-05 02:39:46 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6df2abd8, messages=[], arguments=[--topic, availability-topic-source-my-topic-1190822742-1952915659, --max-messages, 200, USER=my_cluster_e6b90d35_my_user_source, --bootstrap-server, my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg', podNamespace='namespace-131', bootstrapServer='my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-source-my-topic-1190822742-1952915659', maxMessages=200, kafkaUsername='my-cluster-e6b90d35-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7c1b2fa1}
2022-04-05 02:39:46 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093:availability-topic-source-my-topic-1190822742-1952915659 from pod my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg
2022-04-05 02:39:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg -n namespace-131 -- /opt/kafka/producer.sh --topic availability-topic-source-my-topic-1190822742-1952915659 --max-messages 200 USER=my_cluster_e6b90d35_my_user_source --bootstrap-server my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:39:50 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:39:50 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:39:50 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@653ccd37, messages=[], arguments=[--topic, availability-topic-source-my-topic-1190822742-1952915659, --max-messages, 200, --group-instance-id, instance2055416924, --group-id, my-consumer-group-572606408, USER=my_cluster_e6b90d35_my_user_source, --bootstrap-server, my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg', podNamespace='namespace-131', bootstrapServer='my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-source-my-topic-1190822742-1952915659', maxMessages=200, kafkaUsername='my-cluster-e6b90d35-my-user-source', consumerGroupName='my-consumer-group-572606408', consumerInstanceId='instance2055416924', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@407f84be}
2022-04-05 02:39:50 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093:availability-topic-source-my-topic-1190822742-1952915659 from pod my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg
2022-04-05 02:39:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg -n namespace-131 -- /opt/kafka/consumer.sh --topic availability-topic-source-my-topic-1190822742-1952915659 --max-messages 200 --group-instance-id instance2055416924 --group-id my-consumer-group-572606408 USER=my_cluster_e6b90d35_my_user_source --bootstrap-server my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:39:57 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:39:57 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:39:57 [main] [32mINFO [m [MirrorMaker2IsolatedST:544] Setting topic to availability-topic-target-my-topic-1190822742-1952915659, cluster to my-cluster-e6b90d35-target and changing user to my-cluster-e6b90d35-my-user-target
2022-04-05 02:39:57 [main] [32mINFO [m [MirrorMaker2IsolatedST:553] Sending messages to - topic availability-topic-target-my-topic-1190822742-1952915659, cluster my-cluster-e6b90d35-target and message count of 200
2022-04-05 02:39:57 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@686a7b9c, messages=[], arguments=[--topic, availability-topic-target-my-topic-1190822742-1952915659, --max-messages, 200, USER=my_cluster_e6b90d35_my_user_target, --bootstrap-server, my-cluster-e6b90d35-target-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg', podNamespace='namespace-131', bootstrapServer='my-cluster-e6b90d35-target-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-target-my-topic-1190822742-1952915659', maxMessages=200, kafkaUsername='my-cluster-e6b90d35-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1de80623}
2022-04-05 02:39:57 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-e6b90d35-target-kafka-bootstrap.namespace-131.svc:9093:availability-topic-target-my-topic-1190822742-1952915659 from pod my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg
2022-04-05 02:39:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg -n namespace-131 -- /opt/kafka/producer.sh --topic availability-topic-target-my-topic-1190822742-1952915659 --max-messages 200 USER=my_cluster_e6b90d35_my_user_target --bootstrap-server my-cluster-e6b90d35-target-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:40:01 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:40:01 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:40:01 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@575a6288, messages=[], arguments=[--topic, availability-topic-target-my-topic-1190822742-1952915659, --max-messages, 200, --group-instance-id, instance1204266872, --group-id, my-consumer-group-572606408, USER=my_cluster_e6b90d35_my_user_target, --bootstrap-server, my-cluster-e6b90d35-target-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg', podNamespace='namespace-131', bootstrapServer='my-cluster-e6b90d35-target-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-target-my-topic-1190822742-1952915659', maxMessages=200, kafkaUsername='my-cluster-e6b90d35-my-user-target', consumerGroupName='my-consumer-group-572606408', consumerInstanceId='instance1204266872', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@548c585b}
2022-04-05 02:40:01 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-e6b90d35-target-kafka-bootstrap.namespace-131.svc:9093:availability-topic-target-my-topic-1190822742-1952915659 from pod my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg
2022-04-05 02:40:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg -n namespace-131 -- /opt/kafka/consumer.sh --topic availability-topic-target-my-topic-1190822742-1952915659 --max-messages 200 --group-instance-id instance1204266872 --group-id my-consumer-group-572606408 USER=my_cluster_e6b90d35_my_user_target --bootstrap-server my-cluster-e6b90d35-target-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:40:09 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:40:09 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:40:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-e6b90d35 in namespace namespace-131
2022-04-05 02:40:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-05 02:40:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-e6b90d35 will have desired state: Ready
2022-04-05 02:41:21 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-e6b90d35 is in desired state: Ready
2022-04-05 02:41:21 [main] [32mINFO [m [MirrorMaker2IsolatedST:597] Setting topic to mirrormaker2-topic-example-34724858, cluster to my-cluster-e6b90d35-source and changing user to my-cluster-e6b90d35-my-user-source
2022-04-05 02:41:21 [main] [32mINFO [m [MirrorMaker2IsolatedST:606] Sending messages to - topic mirrormaker2-topic-example-34724858, cluster my-cluster-e6b90d35-source and message count of 200
2022-04-05 02:41:21 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@be1e3e9, messages=[], arguments=[--topic, mirrormaker2-topic-example-34724858, --max-messages, 200, USER=my_cluster_e6b90d35_my_user_source, --bootstrap-server, my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg', podNamespace='namespace-131', bootstrapServer='my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093', topicName='mirrormaker2-topic-example-34724858', maxMessages=200, kafkaUsername='my-cluster-e6b90d35-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@262e358a}
2022-04-05 02:41:21 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093:mirrormaker2-topic-example-34724858 from pod my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg
2022-04-05 02:41:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg -n namespace-131 -- /opt/kafka/producer.sh --topic mirrormaker2-topic-example-34724858 --max-messages 200 USER=my_cluster_e6b90d35_my_user_source --bootstrap-server my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:41:25 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:41:25 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:41:25 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2e31b6bb, messages=[], arguments=[--topic, mirrormaker2-topic-example-34724858, --max-messages, 200, --group-instance-id, instance169645584, --group-id, my-consumer-group-572606408, USER=my_cluster_e6b90d35_my_user_source, --bootstrap-server, my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg', podNamespace='namespace-131', bootstrapServer='my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093', topicName='mirrormaker2-topic-example-34724858', maxMessages=200, kafkaUsername='my-cluster-e6b90d35-my-user-source', consumerGroupName='my-consumer-group-572606408', consumerInstanceId='instance169645584', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@79644e78}
2022-04-05 02:41:25 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093:mirrormaker2-topic-example-34724858 from pod my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg
2022-04-05 02:41:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg -n namespace-131 -- /opt/kafka/consumer.sh --topic mirrormaker2-topic-example-34724858 --max-messages 200 --group-instance-id instance169645584 --group-id my-consumer-group-572606408 USER=my_cluster_e6b90d35_my_user_source --bootstrap-server my-cluster-e6b90d35-source-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:41:32 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:41:32 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:41:32 [main] [32mINFO [m [MirrorMaker2IsolatedST:615] Changing to target - topic my-cluster-e6b90d35-source.mirrormaker2-topic-example-34724858, cluster my-cluster-e6b90d35-target, user my-cluster-e6b90d35-my-user-target
2022-04-05 02:41:32 [main] [32mINFO [m [MirrorMaker2IsolatedST:623] Now messages should be mirrored to target topic and cluster
2022-04-05 02:41:32 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5fdbdf9c, messages=[], arguments=[--topic, my-cluster-e6b90d35-source.mirrormaker2-topic-example-34724858, --max-messages, 200, --group-instance-id, instance163155541, --group-id, my-consumer-group-572606408, USER=my_cluster_e6b90d35_my_user_target, --bootstrap-server, my-cluster-e6b90d35-target-kafka-bootstrap.namespace-131.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg', podNamespace='namespace-131', bootstrapServer='my-cluster-e6b90d35-target-kafka-bootstrap.namespace-131.svc:9093', topicName='my-cluster-e6b90d35-source.mirrormaker2-topic-example-34724858', maxMessages=200, kafkaUsername='my-cluster-e6b90d35-my-user-target', consumerGroupName='my-consumer-group-572606408', consumerInstanceId='instance163155541', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2a4be63f}
2022-04-05 02:41:32 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-e6b90d35-target-kafka-bootstrap.namespace-131.svc:9093:my-cluster-e6b90d35-source.mirrormaker2-topic-example-34724858 from pod my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg
2022-04-05 02:41:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-e6b90d35-kafka-clients-77b587856b-c5jwg -n namespace-131 -- /opt/kafka/consumer.sh --topic my-cluster-e6b90d35-source.mirrormaker2-topic-example-34724858 --max-messages 200 --group-instance-id instance163155541 --group-id my-consumer-group-572606408 USER=my_cluster_e6b90d35_my_user_target --bootstrap-server my-cluster-e6b90d35-target-kafka-bootstrap.namespace-131.svc:9093
2022-04-05 02:41:39 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:41:39 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:41:39 [main] [32mINFO [m [MirrorMaker2IsolatedST:628] Messages successfully mirrored
2022-04-05 02:41:39 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-cluster-e6b90d35-source.mirrormaker2-topic-example-34724858 creation 
2022-04-05 02:41:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:41:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2TlsAndScramSha512Auth
2022-04-05 02:41:39 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-e6b90d35-my-user-target in namespace namespace-131
2022-04-05 02:41:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e6b90d35-target in namespace namespace-131
2022-04-05 02:41:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-e6b90d35 in namespace namespace-131
2022-04-05 02:41:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e6b90d35-source in namespace namespace-131
2022-04-05 02:41:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-34724858 in namespace namespace-131
2022-04-05 02:41:49 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-e6b90d35-my-user-source in namespace namespace-131
2022-04-05 02:41:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-e6b90d35-kafka-clients in namespace namespace-131
2022-04-05 02:42:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:42:29 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-131 for test case:testMirrorMaker2TlsAndScramSha512Auth
2022-04-05 02:42:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndScramSha512Auth-FINISHED
2022-04-05 02:42:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:42:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:42:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2ToZero-STARTED
2022-04-05 02:42:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:42:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-132 for test case:testScaleMirrorMaker2ToZero
2022-04-05 02:42:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-132
2022-04-05 02:42:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-132
2022-04-05 02:42:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-132
2022-04-05 02:42:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-61551803-source in namespace namespace-132
2022-04-05 02:42:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-05 02:42:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-61551803-source will have desired state: Ready
2022-04-05 02:43:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-61551803-source is in desired state: Ready
2022-04-05 02:43:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-61551803-target in namespace namespace-132
2022-04-05 02:43:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-05 02:43:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-61551803-target will have desired state: Ready
2022-04-05 02:44:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-61551803-target is in desired state: Ready
2022-04-05 02:44:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-61551803 in namespace namespace-132
2022-04-05 02:44:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-05 02:44:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-61551803 will have desired state: Ready
2022-04-05 02:45:59 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-61551803 is in desired state: Ready
2022-04-05 02:45:59 [main] [32mINFO [m [MirrorMaker2IsolatedST:781] Scaling MirrorMaker2 to zero
2022-04-05 02:46:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:46:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMaker2ToZero
2022-04-05 02:46:02 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-61551803-target in namespace namespace-132
2022-04-05 02:46:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-61551803-source in namespace namespace-132
2022-04-05 02:46:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-61551803 in namespace namespace-132
2022-04-05 02:46:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:46:22 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-132 for test case:testScaleMirrorMaker2ToZero
2022-04-05 02:46:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2ToZero-FINISHED
2022-04-05 02:46:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:46:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:46:33 [main] [32mINFO [m [ResourceManager:346] In context MirrorMaker2IsolatedST is everything deleted.
2022-04-05 02:46:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6,154.855 s - in io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
2022-04-05 02:46:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 02:46:58 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 02:46:58 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 02:46:58 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 02:46:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:46:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 02:46:58 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 02:46:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 02:46:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 02:46:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 02:46:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 02:46:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:46:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 02:46:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 02:46:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 02:46:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:47:08 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:47:08 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 02:47:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 02:47:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 02:47:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 02:47:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 02:47:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 02:47:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 02:47:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:47:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:47:33 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=120000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 02:47:33 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 02:47:33 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 02:47:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 02:47:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:47:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 02:47:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 02:47:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 02:47:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 02:47:33 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 02:47:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:33 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:47:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 02:47:34 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 02:47:34 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 02:47:34 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 02:47:34 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:47:34 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 02:47:34 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 02:47:34 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 02:47:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 02:47:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 02:47:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 02:47:53 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 02:48:03 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 02:48:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:48:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsAuthenticated-STARTED
2022-04-05 02:48:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:48:03 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-133 for test case:testMirrorMakerTlsAuthenticated
2022-04-05 02:48:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-133
2022-04-05 02:48:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-133
2022-04-05 02:48:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-133
2022-04-05 02:48:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-115a2c48-source in namespace namespace-133
2022-04-05 02:48:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:48:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-115a2c48-source will have desired state: Ready
2022-04-05 02:49:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-115a2c48-source is in desired state: Ready
2022-04-05 02:49:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-115a2c48-target in namespace namespace-133
2022-04-05 02:49:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:49:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-115a2c48-target will have desired state: Ready
2022-04-05 02:50:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-115a2c48-target is in desired state: Ready
2022-04-05 02:50:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1670769365-1601814202-source-1243575277 in namespace namespace-133
2022-04-05 02:50:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:50:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1670769365-1601814202-source-1243575277 will have desired state: Ready
2022-04-05 02:50:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1670769365-1601814202-source-1243575277 is in desired state: Ready
2022-04-05 02:50:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-115a2c48-my-user-source in namespace namespace-133
2022-04-05 02:50:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:50:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-115a2c48-my-user-source will have desired state: Ready
2022-04-05 02:50:20 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-115a2c48-my-user-source is in desired state: Ready
2022-04-05 02:50:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-115a2c48-my-user-target in namespace namespace-133
2022-04-05 02:50:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:50:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-115a2c48-my-user-target will have desired state: Ready
2022-04-05 02:50:21 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-115a2c48-my-user-target is in desired state: Ready
2022-04-05 02:50:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-115a2c48-kafka-clients in namespace namespace-133
2022-04-05 02:50:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:50:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-115a2c48-kafka-clients will be ready
2022-04-05 02:50:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-115a2c48-kafka-clients is ready
2022-04-05 02:50:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-445674213-1818290236-test-1 in namespace namespace-133
2022-04-05 02:50:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:50:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-445674213-1818290236-test-1 will have desired state: Ready
2022-04-05 02:50:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-445674213-1818290236-test-1 is in desired state: Ready
2022-04-05 02:50:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-445674213-1818290236-test-2 in namespace namespace-133
2022-04-05 02:50:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:50:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-445674213-1818290236-test-2 will have desired state: Ready
2022-04-05 02:50:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-445674213-1818290236-test-2 is in desired state: Ready
2022-04-05 02:50:25 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 02:50:25 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@406fbe6d, messages=[], arguments=[--topic, my-topic-445674213-1818290236-test-1, --max-messages, 200, USER=my_cluster_115a2c48_my_user_source, --bootstrap-server, my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz', podNamespace='namespace-133', bootstrapServer='my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-445674213-1818290236-test-1', maxMessages=200, kafkaUsername='my-cluster-115a2c48-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4a50a7e5}
2022-04-05 02:50:25 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-445674213-1818290236-test-1 from pod my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz
2022-04-05 02:50:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz -n namespace-133 -- /opt/kafka/producer.sh --topic my-topic-445674213-1818290236-test-1 --max-messages 200 USER=my_cluster_115a2c48_my_user_source --bootstrap-server my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:50:29 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:50:29 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:50:29 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@642d5b9a, messages=[], arguments=[--topic, my-topic-445674213-1818290236-test-1, --max-messages, 200, --group-instance-id, instance1782822592, --group-id, my-consumer-group-47425025, USER=my_cluster_115a2c48_my_user_source, --bootstrap-server, my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz', podNamespace='namespace-133', bootstrapServer='my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-445674213-1818290236-test-1', maxMessages=200, kafkaUsername='my-cluster-115a2c48-my-user-source', consumerGroupName='my-consumer-group-47425025', consumerInstanceId='instance1782822592', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2b0dae91}
2022-04-05 02:50:29 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-445674213-1818290236-test-1 from pod my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz
2022-04-05 02:50:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz -n namespace-133 -- /opt/kafka/consumer.sh --topic my-topic-445674213-1818290236-test-1 --max-messages 200 --group-instance-id instance1782822592 --group-id my-consumer-group-47425025 USER=my_cluster_115a2c48_my_user_source --bootstrap-server my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:50:36 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:50:36 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:50:36 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@775c6e12, messages=[], arguments=[--topic, my-topic-445674213-1818290236-test-2, --max-messages, 200, USER=my_cluster_115a2c48_my_user_target, --bootstrap-server, my-cluster-115a2c48-target-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz', podNamespace='namespace-133', bootstrapServer='my-cluster-115a2c48-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-445674213-1818290236-test-2', maxMessages=200, kafkaUsername='my-cluster-115a2c48-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@598c0da4}
2022-04-05 02:50:36 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-115a2c48-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-445674213-1818290236-test-2 from pod my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz
2022-04-05 02:50:36 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz -n namespace-133 -- /opt/kafka/producer.sh --topic my-topic-445674213-1818290236-test-2 --max-messages 200 USER=my_cluster_115a2c48_my_user_target --bootstrap-server my-cluster-115a2c48-target-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:50:40 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:50:40 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:50:40 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3f9c5363, messages=[], arguments=[--topic, my-topic-445674213-1818290236-test-2, --max-messages, 200, --group-instance-id, instance392776132, --group-id, my-consumer-group-328677883, USER=my_cluster_115a2c48_my_user_target, --bootstrap-server, my-cluster-115a2c48-target-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz', podNamespace='namespace-133', bootstrapServer='my-cluster-115a2c48-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-445674213-1818290236-test-2', maxMessages=200, kafkaUsername='my-cluster-115a2c48-my-user-target', consumerGroupName='my-consumer-group-328677883', consumerInstanceId='instance392776132', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@31e33f4e}
2022-04-05 02:50:40 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-115a2c48-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-445674213-1818290236-test-2 from pod my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz
2022-04-05 02:50:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz -n namespace-133 -- /opt/kafka/consumer.sh --topic my-topic-445674213-1818290236-test-2 --max-messages 200 --group-instance-id instance392776132 --group-id my-consumer-group-328677883 USER=my_cluster_115a2c48_my_user_target --bootstrap-server my-cluster-115a2c48-target-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:50:47 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:50:47 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:50:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-115a2c48 in namespace namespace-133
2022-04-05 02:50:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-05 02:50:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-115a2c48 will have desired state: Ready
2022-04-05 02:51:50 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-115a2c48 is in desired state: Ready
2022-04-05 02:51:50 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@269ee42b, messages=[], arguments=[--topic, my-topic-1670769365-1601814202-source-1243575277, --max-messages, 200, USER=my_cluster_115a2c48_my_user_source, --bootstrap-server, my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz', podNamespace='namespace-133', bootstrapServer='my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-1670769365-1601814202-source-1243575277', maxMessages=200, kafkaUsername='my-cluster-115a2c48-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@77735cdf}
2022-04-05 02:51:50 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-1670769365-1601814202-source-1243575277 from pod my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz
2022-04-05 02:51:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz -n namespace-133 -- /opt/kafka/producer.sh --topic my-topic-1670769365-1601814202-source-1243575277 --max-messages 200 USER=my_cluster_115a2c48_my_user_source --bootstrap-server my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:51:54 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:51:54 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:51:54 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@57bd9e1, messages=[], arguments=[--topic, my-topic-1670769365-1601814202-source-1243575277, --max-messages, 200, --group-instance-id, instance2103898730, --group-id, my-consumer-group-131765726, USER=my_cluster_115a2c48_my_user_source, --bootstrap-server, my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz', podNamespace='namespace-133', bootstrapServer='my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-1670769365-1601814202-source-1243575277', maxMessages=200, kafkaUsername='my-cluster-115a2c48-my-user-source', consumerGroupName='my-consumer-group-131765726', consumerInstanceId='instance2103898730', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6803f59a}
2022-04-05 02:51:54 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-1670769365-1601814202-source-1243575277 from pod my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz
2022-04-05 02:51:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz -n namespace-133 -- /opt/kafka/consumer.sh --topic my-topic-1670769365-1601814202-source-1243575277 --max-messages 200 --group-instance-id instance2103898730 --group-id my-consumer-group-131765726 USER=my_cluster_115a2c48_my_user_source --bootstrap-server my-cluster-115a2c48-source-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:52:01 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:52:01 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:52:01 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@61e88a1d, messages=[], arguments=[--topic, my-topic-1670769365-1601814202-source-1243575277, --max-messages, 200, --group-instance-id, instance621766376, --group-id, my-consumer-group-309332929, USER=my_cluster_115a2c48_my_user_target, --bootstrap-server, my-cluster-115a2c48-target-kafka-bootstrap.namespace-133.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz', podNamespace='namespace-133', bootstrapServer='my-cluster-115a2c48-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-1670769365-1601814202-source-1243575277', maxMessages=200, kafkaUsername='my-cluster-115a2c48-my-user-target', consumerGroupName='my-consumer-group-309332929', consumerInstanceId='instance621766376', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5415dad9}
2022-04-05 02:52:01 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-115a2c48-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-1670769365-1601814202-source-1243575277 from pod my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz
2022-04-05 02:52:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-115a2c48-kafka-clients-b44cc78c4-tc9wz -n namespace-133 -- /opt/kafka/consumer.sh --topic my-topic-1670769365-1601814202-source-1243575277 --max-messages 200 --group-instance-id instance621766376 --group-id my-consumer-group-309332929 USER=my_cluster_115a2c48_my_user_target --bootstrap-server my-cluster-115a2c48-target-kafka-bootstrap.namespace-133.svc:9093
2022-04-05 02:52:08 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:52:08 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:52:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:52:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerTlsAuthenticated
2022-04-05 02:52:08 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-115a2c48-kafka-clients in namespace namespace-133
2022-04-05 02:52:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1670769365-1601814202-source-1243575277 in namespace namespace-133
2022-04-05 02:52:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-445674213-1818290236-test-2 in namespace namespace-133
2022-04-05 02:52:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-115a2c48-my-user-target in namespace namespace-133
2022-04-05 02:52:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-115a2c48 in namespace namespace-133
2022-04-05 02:52:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-445674213-1818290236-test-1 in namespace namespace-133
2022-04-05 02:52:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-115a2c48-target in namespace namespace-133
2022-04-05 02:52:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-115a2c48-source in namespace namespace-133
2022-04-05 02:52:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-115a2c48-my-user-source in namespace namespace-133
2022-04-05 02:52:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:52:48 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-133 for test case:testMirrorMakerTlsAuthenticated
2022-04-05 02:53:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsAuthenticated-FINISHED
2022-04-05 02:53:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:53:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:53:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsScramSha-STARTED
2022-04-05 02:53:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:53:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-134 for test case:testMirrorMakerTlsScramSha
2022-04-05 02:53:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-134
2022-04-05 02:53:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-134
2022-04-05 02:53:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-134
2022-04-05 02:53:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a574f1a4-source in namespace namespace-134
2022-04-05 02:53:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:53:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a574f1a4-source will have desired state: Ready
2022-04-05 02:54:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a574f1a4-source is in desired state: Ready
2022-04-05 02:54:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a574f1a4-target in namespace namespace-134
2022-04-05 02:54:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:54:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a574f1a4-target will have desired state: Ready
2022-04-05 02:55:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a574f1a4-target is in desired state: Ready
2022-04-05 02:55:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1885635797-760449728 in namespace namespace-134
2022-04-05 02:55:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:55:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1885635797-760449728 will have desired state: Ready
2022-04-05 02:55:31 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1885635797-760449728 is in desired state: Ready
2022-04-05 02:55:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-a574f1a4-my-user-source in namespace namespace-134
2022-04-05 02:55:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:55:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-a574f1a4-my-user-source will have desired state: Ready
2022-04-05 02:55:32 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-a574f1a4-my-user-source is in desired state: Ready
2022-04-05 02:55:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-a574f1a4-my-user-target in namespace namespace-134
2022-04-05 02:55:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:55:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-a574f1a4-my-user-target will have desired state: Ready
2022-04-05 02:55:33 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-a574f1a4-my-user-target is in desired state: Ready
2022-04-05 02:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a574f1a4-kafka-clients in namespace namespace-134
2022-04-05 02:55:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:55:33 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a574f1a4-kafka-clients will be ready
2022-04-05 02:55:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a574f1a4-kafka-clients is ready
2022-04-05 02:55:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1885635797-760449728-test-1 in namespace namespace-134
2022-04-05 02:55:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:55:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1885635797-760449728-test-1 will have desired state: Ready
2022-04-05 02:55:35 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1885635797-760449728-test-1 is in desired state: Ready
2022-04-05 02:55:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1885635797-760449728-test-2 in namespace namespace-134
2022-04-05 02:55:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:55:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1885635797-760449728-test-2 will have desired state: Ready
2022-04-05 02:55:36 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1885635797-760449728-test-2 is in desired state: Ready
2022-04-05 02:55:36 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 02:55:36 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6f447953, messages=[], arguments=[--topic, my-topic-1885635797-760449728-test-1, --max-messages, 200, USER=my_cluster_a574f1a4_my_user_source, --bootstrap-server, my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2', podNamespace='namespace-134', bootstrapServer='my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1885635797-760449728-test-1', maxMessages=200, kafkaUsername='my-cluster-a574f1a4-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4fe8d279}
2022-04-05 02:55:36 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1885635797-760449728-test-1 from pod my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2
2022-04-05 02:55:36 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2 -n namespace-134 -- /opt/kafka/producer.sh --topic my-topic-1885635797-760449728-test-1 --max-messages 200 USER=my_cluster_a574f1a4_my_user_source --bootstrap-server my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:55:40 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:55:40 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:55:40 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@595cc4af, messages=[], arguments=[--topic, my-topic-1885635797-760449728-test-1, --max-messages, 200, --group-instance-id, instance324963335, --group-id, my-consumer-group-928583810, USER=my_cluster_a574f1a4_my_user_source, --bootstrap-server, my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2', podNamespace='namespace-134', bootstrapServer='my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1885635797-760449728-test-1', maxMessages=200, kafkaUsername='my-cluster-a574f1a4-my-user-source', consumerGroupName='my-consumer-group-928583810', consumerInstanceId='instance324963335', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@50aeafd9}
2022-04-05 02:55:40 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1885635797-760449728-test-1 from pod my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2
2022-04-05 02:55:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2 -n namespace-134 -- /opt/kafka/consumer.sh --topic my-topic-1885635797-760449728-test-1 --max-messages 200 --group-instance-id instance324963335 --group-id my-consumer-group-928583810 USER=my_cluster_a574f1a4_my_user_source --bootstrap-server my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:55:48 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:55:48 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:55:48 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@56a3ef7, messages=[], arguments=[--topic, my-topic-1885635797-760449728-test-2, --max-messages, 200, USER=my_cluster_a574f1a4_my_user_target, --bootstrap-server, my-cluster-a574f1a4-target-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2', podNamespace='namespace-134', bootstrapServer='my-cluster-a574f1a4-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1885635797-760449728-test-2', maxMessages=200, kafkaUsername='my-cluster-a574f1a4-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@159eb036}
2022-04-05 02:55:48 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-a574f1a4-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-1885635797-760449728-test-2 from pod my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2
2022-04-05 02:55:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2 -n namespace-134 -- /opt/kafka/producer.sh --topic my-topic-1885635797-760449728-test-2 --max-messages 200 USER=my_cluster_a574f1a4_my_user_target --bootstrap-server my-cluster-a574f1a4-target-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:55:52 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:55:52 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:55:52 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1fd948e4, messages=[], arguments=[--topic, my-topic-1885635797-760449728-test-2, --max-messages, 200, --group-instance-id, instance1673399768, --group-id, my-consumer-group-758633655, USER=my_cluster_a574f1a4_my_user_target, --bootstrap-server, my-cluster-a574f1a4-target-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2', podNamespace='namespace-134', bootstrapServer='my-cluster-a574f1a4-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1885635797-760449728-test-2', maxMessages=200, kafkaUsername='my-cluster-a574f1a4-my-user-target', consumerGroupName='my-consumer-group-758633655', consumerInstanceId='instance1673399768', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@209f99e4}
2022-04-05 02:55:52 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-a574f1a4-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-1885635797-760449728-test-2 from pod my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2
2022-04-05 02:55:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2 -n namespace-134 -- /opt/kafka/consumer.sh --topic my-topic-1885635797-760449728-test-2 --max-messages 200 --group-instance-id instance1673399768 --group-id my-consumer-group-758633655 USER=my_cluster_a574f1a4_my_user_target --bootstrap-server my-cluster-a574f1a4-target-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:55:59 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:55:59 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:55:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-a574f1a4 in namespace namespace-134
2022-04-05 02:55:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-05 02:55:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-a574f1a4 will have desired state: Ready
2022-04-05 02:57:03 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-a574f1a4 is in desired state: Ready
2022-04-05 02:57:03 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3ed90cfc, messages=[], arguments=[--topic, my-topic-1885635797-760449728, --max-messages, 200, USER=my_cluster_a574f1a4_my_user_source, --bootstrap-server, my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2', podNamespace='namespace-134', bootstrapServer='my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1885635797-760449728', maxMessages=200, kafkaUsername='my-cluster-a574f1a4-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6f62db9c}
2022-04-05 02:57:03 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1885635797-760449728 from pod my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2
2022-04-05 02:57:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2 -n namespace-134 -- /opt/kafka/producer.sh --topic my-topic-1885635797-760449728 --max-messages 200 USER=my_cluster_a574f1a4_my_user_source --bootstrap-server my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:57:07 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 02:57:07 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-05 02:57:07 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4d9ce295, messages=[], arguments=[--topic, my-topic-1885635797-760449728, --max-messages, 200, --group-instance-id, instance1611896366, --group-id, my-consumer-group-623477759, USER=my_cluster_a574f1a4_my_user_source, --bootstrap-server, my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2', podNamespace='namespace-134', bootstrapServer='my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1885635797-760449728', maxMessages=200, kafkaUsername='my-cluster-a574f1a4-my-user-source', consumerGroupName='my-consumer-group-623477759', consumerInstanceId='instance1611896366', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@34db71a9}
2022-04-05 02:57:07 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-1885635797-760449728 from pod my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2
2022-04-05 02:57:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2 -n namespace-134 -- /opt/kafka/consumer.sh --topic my-topic-1885635797-760449728 --max-messages 200 --group-instance-id instance1611896366 --group-id my-consumer-group-623477759 USER=my_cluster_a574f1a4_my_user_source --bootstrap-server my-cluster-a574f1a4-source-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:57:15 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:57:15 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:57:15 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4d956153, messages=[], arguments=[--topic, my-topic-1885635797-760449728, --max-messages, 200, --group-instance-id, instance2147296364, --group-id, my-consumer-group-765008221, USER=my_cluster_a574f1a4_my_user_target, --bootstrap-server, my-cluster-a574f1a4-target-kafka-bootstrap.namespace-134.svc:9093], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2', podNamespace='namespace-134', bootstrapServer='my-cluster-a574f1a4-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-1885635797-760449728', maxMessages=200, kafkaUsername='my-cluster-a574f1a4-my-user-target', consumerGroupName='my-consumer-group-765008221', consumerInstanceId='instance2147296364', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3b54b936}
2022-04-05 02:57:15 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-a574f1a4-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-1885635797-760449728 from pod my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2
2022-04-05 02:57:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a574f1a4-kafka-clients-6779bc494f-zrbr2 -n namespace-134 -- /opt/kafka/consumer.sh --topic my-topic-1885635797-760449728 --max-messages 200 --group-instance-id instance2147296364 --group-id my-consumer-group-765008221 USER=my_cluster_a574f1a4_my_user_target --bootstrap-server my-cluster-a574f1a4-target-kafka-bootstrap.namespace-134.svc:9093
2022-04-05 02:57:22 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 02:57:22 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-05 02:57:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 02:57:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerTlsScramSha
2022-04-05 02:57:22 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a574f1a4-kafka-clients in namespace namespace-134
2022-04-05 02:57:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1885635797-760449728 in namespace namespace-134
2022-04-05 02:57:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1885635797-760449728-test-2 in namespace namespace-134
2022-04-05 02:57:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1885635797-760449728-test-1 in namespace namespace-134
2022-04-05 02:57:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-a574f1a4 in namespace namespace-134
2022-04-05 02:57:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-a574f1a4-my-user-source in namespace namespace-134
2022-04-05 02:57:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-a574f1a4-my-user-target in namespace namespace-134
2022-04-05 02:57:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a574f1a4-target in namespace namespace-134
2022-04-05 02:57:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a574f1a4-source in namespace namespace-134
2022-04-05 02:58:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 02:58:02 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-134 for test case:testMirrorMakerTlsScramSha
2022-04-05 02:58:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsScramSha-FINISHED
2022-04-05 02:58:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 02:58:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 02:58:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testIncludeList-STARTED
2022-04-05 02:58:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 02:58:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-135 for test case:testIncludeList
2022-04-05 02:58:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-135
2022-04-05 02:58:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-135
2022-04-05 02:58:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-135
2022-04-05 02:58:29 [main] [32mINFO [m [MirrorMakerIsolatedST:471] Creating kafka source cluster my-cluster-a0ad0aa1-source
2022-04-05 02:58:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a0ad0aa1-source in namespace namespace-135
2022-04-05 02:58:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-05 02:58:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a0ad0aa1-source will have desired state: Ready
2022-04-05 02:59:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a0ad0aa1-source is in desired state: Ready
2022-04-05 02:59:42 [main] [32mINFO [m [MirrorMakerIsolatedST:473] Creating kafka target cluster my-cluster-a0ad0aa1-target
2022-04-05 02:59:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a0ad0aa1-target in namespace namespace-135
2022-04-05 02:59:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-05 02:59:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a0ad0aa1-target will have desired state: Ready
2022-04-05 03:00:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a0ad0aa1-target is in desired state: Ready
2022-04-05 03:00:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic included-topic in namespace namespace-135
2022-04-05 03:00:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-05 03:00:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: included-topic will have desired state: Ready
2022-04-05 03:00:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: included-topic is in desired state: Ready
2022-04-05 03:00:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic not-included-topic in namespace namespace-135
2022-04-05 03:00:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-05 03:00:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: not-included-topic will have desired state: Ready
2022-04-05 03:00:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: not-included-topic is in desired state: Ready
2022-04-05 03:00:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a0ad0aa1-kafka-clients in namespace namespace-135
2022-04-05 03:00:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-05 03:00:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a0ad0aa1-kafka-clients will be ready
2022-04-05 03:00:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a0ad0aa1-kafka-clients is ready
2022-04-05 03:00:50 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1adf4095, messages=[], arguments=[--topic, topic-example-10, --max-messages, 200, --bootstrap-server, my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc', podNamespace='namespace-135', bootstrapServer='my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-10', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@f9eb2b2}
2022-04-05 03:00:50 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092:topic-example-10 from pod my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc
2022-04-05 03:00:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc -n namespace-135 -- /opt/kafka/producer.sh --topic topic-example-10 --max-messages 200 --bootstrap-server my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 03:00:52 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 03:00:52 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 03:00:52 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@58209a42, messages=[], arguments=[--topic, topic-example-10, --max-messages, 200, --group-instance-id, instance1608342140, --group-id, my-consumer-group-1433255700, --bootstrap-server, my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc', podNamespace='namespace-135', bootstrapServer='my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-10', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1433255700', consumerInstanceId='instance1608342140', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2251a798}
2022-04-05 03:00:52 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092#topic-example-10 from pod my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc
2022-04-05 03:00:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc -n namespace-135 -- /opt/kafka/consumer.sh --topic topic-example-10 --max-messages 200 --group-instance-id instance1608342140 --group-id my-consumer-group-1433255700 --bootstrap-server my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 03:00:58 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 03:00:58 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 03:00:58 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5fb6b271, messages=[], arguments=[--topic, topic-example-11, --max-messages, 200, --bootstrap-server, my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc', podNamespace='namespace-135', bootstrapServer='my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-11', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@389bb23b}
2022-04-05 03:00:58 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092:topic-example-11 from pod my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc
2022-04-05 03:00:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc -n namespace-135 -- /opt/kafka/producer.sh --topic topic-example-11 --max-messages 200 --bootstrap-server my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 03:01:01 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 03:01:01 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 03:01:01 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2cdac5ae, messages=[], arguments=[--topic, topic-example-11, --max-messages, 200, --group-instance-id, instance920043679, --group-id, my-consumer-group-649647279, --bootstrap-server, my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc', podNamespace='namespace-135', bootstrapServer='my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-11', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-649647279', consumerInstanceId='instance920043679', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@70f4b378}
2022-04-05 03:01:01 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092#topic-example-11 from pod my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc
2022-04-05 03:01:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc -n namespace-135 -- /opt/kafka/consumer.sh --topic topic-example-11 --max-messages 200 --group-instance-id instance920043679 --group-id my-consumer-group-649647279 --bootstrap-server my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 03:01:06 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 03:01:06 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 03:01:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-a0ad0aa1 in namespace namespace-135
2022-04-05 03:01:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-05 03:01:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-a0ad0aa1 will have desired state: Ready
2022-04-05 03:02:14 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-a0ad0aa1 is in desired state: Ready
2022-04-05 03:02:14 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@237ab619, messages=[], arguments=[--topic, included-topic, --max-messages, 200, --bootstrap-server, my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc', podNamespace='namespace-135', bootstrapServer='my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@49b5b064}
2022-04-05 03:02:14 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092:included-topic from pod my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc
2022-04-05 03:02:14 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc -n namespace-135 -- /opt/kafka/producer.sh --topic included-topic --max-messages 200 --bootstrap-server my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 03:02:16 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 03:02:16 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 03:02:16 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@681f45c3, messages=[], arguments=[--topic, included-topic, --max-messages, 200, --group-instance-id, instance461940645, --group-id, my-consumer-group-455752354, --bootstrap-server, my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc', podNamespace='namespace-135', bootstrapServer='my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-455752354', consumerInstanceId='instance461940645', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@c4df2be}
2022-04-05 03:02:16 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092#included-topic from pod my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc
2022-04-05 03:02:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc -n namespace-135 -- /opt/kafka/consumer.sh --topic included-topic --max-messages 200 --group-instance-id instance461940645 --group-id my-consumer-group-455752354 --bootstrap-server my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 03:02:22 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 03:02:22 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 03:02:22 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6d631a58, messages=[], arguments=[--topic, included-topic, --max-messages, 200, --group-instance-id, instance159370594, --group-id, my-consumer-group-1545601491, --bootstrap-server, my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc', podNamespace='namespace-135', bootstrapServer='my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1545601491', consumerInstanceId='instance159370594', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1e23eca7}
2022-04-05 03:02:22 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092#included-topic from pod my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc
2022-04-05 03:02:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc -n namespace-135 -- /opt/kafka/consumer.sh --topic included-topic --max-messages 200 --group-instance-id instance159370594 --group-id my-consumer-group-1545601491 --bootstrap-server my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 03:02:28 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 03:02:28 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 03:02:28 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1c7bb01d, messages=[], arguments=[--topic, not-included-topic, --max-messages, 200, --bootstrap-server, my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc', podNamespace='namespace-135', bootstrapServer='my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@e58dd48}
2022-04-05 03:02:28 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092:not-included-topic from pod my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc
2022-04-05 03:02:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc -n namespace-135 -- /opt/kafka/producer.sh --topic not-included-topic --max-messages 200 --bootstrap-server my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 03:02:30 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 03:02:30 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 03:02:30 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@687849c4, messages=[], arguments=[--topic, not-included-topic, --max-messages, 200, --group-instance-id, instance381778241, --group-id, my-consumer-group-303814516, --bootstrap-server, my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc', podNamespace='namespace-135', bootstrapServer='my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-303814516', consumerInstanceId='instance381778241', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1d3c21e1}
2022-04-05 03:02:30 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092#not-included-topic from pod my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc
2022-04-05 03:02:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc -n namespace-135 -- /opt/kafka/consumer.sh --topic not-included-topic --max-messages 200 --group-instance-id instance381778241 --group-id my-consumer-group-303814516 --bootstrap-server my-cluster-a0ad0aa1-source-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 03:02:36 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 03:02:36 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 03:02:36 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6138dc5b, messages=[], arguments=[--topic, not-included-topic, --max-messages, 200, --group-instance-id, instance100260192, --group-id, my-consumer-group-303814516, --bootstrap-server, my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc', podNamespace='namespace-135', bootstrapServer='my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-303814516', consumerInstanceId='instance100260192', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@20027b1e}
2022-04-05 03:02:36 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092#not-included-topic from pod my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc
2022-04-05 03:02:36 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a0ad0aa1-kafka-clients-64d84dc8dd-kjnjc -n namespace-135 -- /opt/kafka/consumer.sh --topic not-included-topic --max-messages 200 --group-instance-id instance100260192 --group-id my-consumer-group-303814516 --bootstrap-server my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092
2022-04-05 03:04:36 [main] [32mINFO [m [VerifiableClient:199] CLI_KAFKA_VERIFIABLE_CONSUMER RETURN code: 1
2022-04-05 03:04:36 [main] [32mINFO [m [VerifiableClient:201] ======STDOUT START=======
2022-04-05 03:04:36 [main] [33mWARN [m [Exec:358] Executor log is too long. Going to strip it and print only first 20000 characters
2022-04-05 03:04:36 [main] [32mINFO [m [VerifiableClient:202] /tmp/.properties
Starting Consumer with configuration:

[2022-04-05 03:02:38,029] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-303814516-instance100260192
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-303814516
	group.instance.id = instance100260192
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (ConsumerConfig:376)
[2022-04-05 03:02:38,034] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Initializing the Kafka consumer (KafkaConsumer:695)
[2022-04-05 03:02:38,139] INFO Kafka version: 3.1.0 (AppInfoParser:119)
[2022-04-05 03:02:38,140] INFO Kafka commitId: 37edeed0777bacb3 (AppInfoParser:120)
[2022-04-05 03:02:38,140] INFO Kafka startTimeMs: 1649127758136 (AppInfoParser:121)
[2022-04-05 03:02:38,144] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Kafka consumer initialized (KafkaConsumer:815)
{"timestamp":1649127758288,"name":"startup_complete"}
[2022-04-05 03:02:38,327] INFO [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Subscribed to topic(s): not-included-topic (KafkaConsumer:966)
[2022-04-05 03:02:38,328] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Sending FindCoordinator request to broker my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) (ConsumerCoordinator:821)
[2022-04-05 03:02:38,557] DEBUG Resolved host my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc as 10.111.120.93 (ClientUtils:113)
[2022-04-05 03:02:38,557] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Initiating connection to node my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) using address my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc/10.111.120.93 (NetworkClient:985)
[2022-04-05 03:02:38,570] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1 (Selector:531)
[2022-04-05 03:02:38,571] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Completed connection to node -1. Fetching API versions. (NetworkClient:952)
[2022-04-05 03:02:38,571] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Initiating API versions fetch from node -1. (NetworkClient:966)
[2022-04-05 03:02:38,574] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-303814516-instance100260192, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.0') (NetworkClient:521)
[2022-04-05 03:02:38,608] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-303814516-instance100260192, correlationId=1): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=13), ApiVersion(apiKey=2, minVersion=0, maxVersion=7), ApiVersion(apiKey=3, minVersion=0, maxVersion=12), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=8), ApiVersion(apiKey=10, minVersion=0, maxVersion=4), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0), ApiVersion(apiKey=65, minVersion=0, maxVersion=0), ApiVersion(apiKey=66, minVersion=0, maxVersion=0), ApiVersion(apiKey=67, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[]) (NetworkClient:879)
[2022-04-05 03:02:38,678] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Node -1 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 13 [usable: 13], ListOffsets(2): 0 to 7 [usable: 7], Metadata(3): 0 to 12 [usable: 12], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 8 [usable: 8], FindCoordinator(10): 0 to 4 [usable: 4], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): 0 [usable: 0], ListTransactions(66): 0 [usable: 0], AllocateProducerIds(67): 0 [usable: 0]). (NetworkClient:921)
[2022-04-05 03:02:38,682] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='not-included-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node my-cluster-a0ad0aa1-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) (NetworkClient:1139)
[2022-04-05 03:02:38,683] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=consumer-my-consumer-group-303814516-instance100260192, correlationId=2) and timeout 30000 to node -1: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='not-included-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) (NetworkClient:521)
[2022-04-05 03:02:38,684] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-303814516-instance100260192, correlationId=0) and timeout 30000 to node -1: FindCoordinatorRequestData(key='', keyType=0, coordinatorKeys=[my-consumer-group-303814516]) (NetworkClient:521)
[2022-04-05 03:02:38,711] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Received METADATA response from node -1 for request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=consumer-my-consumer-group-303814516-instance100260192, correlationId=2): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=0, host='my-cluster-a0ad0aa1-target-kafka-0.my-cluster-a0ad0aa1-target-kafka-brokers.namespace-135.svc', port=9092, rack=null)], clusterId='9Z0BysqQRNWqUmH1v_yldA', controllerId=0, topics=[MetadataResponseTopic(errorCode=5, name='not-included-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648) (NetworkClient:879)
[2022-04-05 03:02:38,716] WARN [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Error while fetching metadata with correlation id 2 : {not-included-topic=LEADER_NOT_AVAILABLE} (NetworkClient:1099)
[2022-04-05 03:02:38,717] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Requesting metadata update for topic not-included-topic due to error LEADER_NOT_AVAILABLE (Metadata:363)
[2022-04-05 03:02:38,718] INFO [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Cluster ID: 9Z0BysqQRNWqUmH1v_yldA (Metadata:287)
[2022-04-05 03:02:38,719] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='9Z0BysqQRNWqUmH1v_yldA', nodes={0=my-cluster-a0ad0aa1-target-kafka-0.my-cluster-a0ad0aa1-target-kafka-brokers.namespace-135.svc:9092 (id: 0 rack: null)}, partitions=[], controller=my-cluster-a0ad0aa1-target-kafka-0.my-cluster-a0ad0aa1-target-kafka-brokers.namespace-135.svc:9092 (id: 0 rack: null)} (Metadata:291)
[2022-04-05 03:02:38,719] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Received FIND_COORDINATOR response from node -1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-303814516-instance100260192, correlationId=0): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='', nodeId=0, host='', port=0, coordinators=[Coordinator(key='my-consumer-group-303814516', nodeId=0, host='my-cluster-a0ad0aa1-target-kafka-0.my-cluster-a0ad0aa1-target-kafka-brokers.namespace-135.svc', port=9092, errorCode=0, errorMessage='')]) (NetworkClient:879)
[2022-04-05 03:02:38,736] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Received FindCoordinator response ClientResponse(receivedTimeMs=1649127758719, latencyMs=169, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-303814516-instance100260192, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='', nodeId=0, host='', port=0, coordinators=[Coordinator(key='my-consumer-group-303814516', nodeId=0, host='my-cluster-a0ad0aa1-target-kafka-0.my-cluster-a0ad0aa1-target-kafka-brokers.namespace-135.svc', port=9092, errorCode=0, errorMessage='')])) (ConsumerCoordinator:834)
[2022-04-05 03:02:38,737] INFO [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Discovered group coordinator my-cluster-a0ad0aa1-target-kafka-0.my-cluster-a0ad0aa1-target-kafka-brokers.namespace-135.svc:9092 (id: 2147483647 rack: null) (ConsumerCoordinator:853)
[2022-04-05 03:02:38,738] DEBUG Resolved host my-cluster-a0ad0aa1-target-kafka-0.my-cluster-a0ad0aa1-target-kafka-brokers.namespace-135.svc as 172.17.0.11 (ClientUtils:113)
[2022-04-05 03:02:38,739] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Initiating connection to node my-cluster-a0ad0aa1-target-kafka-0.my-cluster-a0ad0aa1-target-kafka-brokers.namespace-135.svc:9092 (id: 2147483647 rack: null) using address my-cluster-a0ad0aa1-target-kafka-0.my-cluster-a0ad0aa1-target-kafka-brokers.namespace-135.svc/172.17.0.11 (NetworkClient:985)
[2022-04-05 03:02:38,751] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Executing onJoinPrepare with generation -1 and memberId  (ConsumerCoordinator:700)
[2022-04-05 03:02:38,751] INFO [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] (Re-)joining group (ConsumerCoordinator:535)
[2022-04-05 03:02:38,752] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-group-303814516-instance100260192, groupId=my-consumer-group-303814516] Joining group with current subscription: [not-included-topic] (ConsumerCoordinator:218)
[2022-04-05 03:02:38,755] DEBUG [Consumer instanceId=instance100260192, clientId=consumer-my-consumer-grou
2022-04-05 03:04:36 [main] [32mINFO [m [VerifiableClient:203] ======STDOUT END======
2022-04-05 03:04:36 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: false
2022-04-05 03:04:36 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 0 messages
2022-04-05 03:04:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:04:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIncludeList
2022-04-05 03:04:36 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic not-included-topic in namespace namespace-135
2022-04-05 03:04:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a0ad0aa1-target in namespace namespace-135
2022-04-05 03:04:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a0ad0aa1-source in namespace namespace-135
2022-04-05 03:04:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic included-topic in namespace namespace-135
2022-04-05 03:04:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-a0ad0aa1 in namespace namespace-135
2022-04-05 03:04:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a0ad0aa1-kafka-clients in namespace namespace-135
2022-04-05 03:05:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:05:26 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-135 for test case:testIncludeList
2022-04-05 03:05:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testIncludeList-FINISHED
2022-04-05 03:05:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:05:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:05:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-05 03:05:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:05:32 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-136 for test case:testConfigureDeploymentStrategy
2022-04-05 03:05:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-136
2022-04-05 03:05:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-136
2022-04-05 03:05:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-136
2022-04-05 03:05:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-94c89bd4-source in namespace namespace-136
2022-04-05 03:05:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-05 03:05:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-94c89bd4-source will have desired state: Ready
2022-04-05 03:06:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-94c89bd4-source is in desired state: Ready
2022-04-05 03:06:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-94c89bd4-target in namespace namespace-136
2022-04-05 03:06:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-05 03:06:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-94c89bd4-target will have desired state: Ready
2022-04-05 03:08:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-94c89bd4-target is in desired state: Ready
2022-04-05 03:08:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-94c89bd4 in namespace namespace-136
2022-04-05 03:08:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-05 03:08:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-94c89bd4 will have desired state: Ready
2022-04-05 03:09:03 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-94c89bd4 is in desired state: Ready
2022-04-05 03:09:03 [main] [32mINFO [m [MirrorMakerIsolatedST:763] Adding label to MirrorMaker resource, the CR should be recreateAndWaitForReadinessd
2022-04-05 03:09:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-94c89bd4-mirror-maker will be ready
2022-04-05 03:09:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-94c89bd4-mirror-maker is ready
2022-04-05 03:09:03 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-94c89bd4-mirror-maker to be ready
2022-04-05 03:10:29 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-94c89bd4-mirror-maker is ready
2022-04-05 03:10:29 [main] [32mINFO [m [MirrorMakerIsolatedST:770] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-05 03:10:29 [main] [32mINFO [m [MirrorMakerIsolatedST:775] Changing deployment strategy to ROLLING_UPDATE
2022-04-05 03:10:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-94c89bd4 will have desired state: Ready
2022-04-05 03:10:29 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-94c89bd4 is in desired state: Ready
2022-04-05 03:10:29 [main] [32mINFO [m [MirrorMakerIsolatedST:780] Adding another label to MirrorMaker resource, pods should be rolled
2022-04-05 03:10:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-94c89bd4-mirror-maker will be ready
2022-04-05 03:10:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-94c89bd4-mirror-maker is ready
2022-04-05 03:10:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-94c89bd4-mirror-maker to be ready
2022-04-05 03:11:46 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-94c89bd4-mirror-maker is ready
2022-04-05 03:11:46 [main] [32mINFO [m [MirrorMakerIsolatedST:784] Checking that observed gen. higher (rolling update) and label is changed
2022-04-05 03:11:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:11:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-05 03:11:46 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-94c89bd4-target in namespace namespace-136
2022-04-05 03:11:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-94c89bd4-source in namespace namespace-136
2022-04-05 03:11:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-94c89bd4 in namespace namespace-136
2022-04-05 03:11:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:11:56 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-136 for test case:testConfigureDeploymentStrategy
2022-04-05 03:12:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-05 03:12:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:12:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:12:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerToZero-STARTED
2022-04-05 03:12:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:12:23 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-137 for test case:testScaleMirrorMakerToZero
2022-04-05 03:12:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-137
2022-04-05 03:12:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-137
2022-04-05 03:12:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-137
2022-04-05 03:12:23 [main] [32mINFO [m [MirrorMakerIsolatedST:713] Creating kafka source cluster my-cluster-9f55d3dd-source
2022-04-05 03:12:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9f55d3dd-source in namespace namespace-137
2022-04-05 03:12:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-05 03:12:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9f55d3dd-source will have desired state: Ready
2022-04-05 03:13:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9f55d3dd-source is in desired state: Ready
2022-04-05 03:13:21 [main] [32mINFO [m [MirrorMakerIsolatedST:715] Creating kafka target cluster my-cluster-9f55d3dd-target
2022-04-05 03:13:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9f55d3dd-target in namespace namespace-137
2022-04-05 03:13:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-05 03:13:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9f55d3dd-target will have desired state: Ready
2022-04-05 03:14:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9f55d3dd-target is in desired state: Ready
2022-04-05 03:14:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-9f55d3dd in namespace namespace-137
2022-04-05 03:14:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-05 03:14:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-9f55d3dd will have desired state: Ready
2022-04-05 03:15:36 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-9f55d3dd is in desired state: Ready
2022-04-05 03:15:36 [main] [32mINFO [m [MirrorMakerIsolatedST:725] Scaling MirrorMaker to zero
2022-04-05 03:15:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:15:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMakerToZero
2022-04-05 03:15:47 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9f55d3dd-target in namespace namespace-137
2022-04-05 03:15:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9f55d3dd-source in namespace namespace-137
2022-04-05 03:15:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-9f55d3dd in namespace namespace-137
2022-04-05 03:15:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:15:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-137 for test case:testScaleMirrorMakerToZero
2022-04-05 03:16:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerToZero-FINISHED
2022-04-05 03:16:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:16:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:16:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerSubresource-STARTED
2022-04-05 03:16:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:16:08 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-138 for test case:testScaleMirrorMakerSubresource
2022-04-05 03:16:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-138
2022-04-05 03:16:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-138
2022-04-05 03:16:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-138
2022-04-05 03:16:08 [main] [32mINFO [m [MirrorMakerIsolatedST:674] Creating kafka source cluster my-cluster-ab6b3cff-source
2022-04-05 03:16:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ab6b3cff-source in namespace namespace-138
2022-04-05 03:16:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-05 03:16:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ab6b3cff-source will have desired state: Ready
2022-04-05 03:17:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ab6b3cff-source is in desired state: Ready
2022-04-05 03:17:21 [main] [32mINFO [m [MirrorMakerIsolatedST:676] Creating kafka target cluster my-cluster-ab6b3cff-target
2022-04-05 03:17:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ab6b3cff-target in namespace namespace-138
2022-04-05 03:17:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-05 03:17:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ab6b3cff-target will have desired state: Ready
2022-04-05 03:18:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ab6b3cff-target is in desired state: Ready
2022-04-05 03:18:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-ab6b3cff in namespace namespace-138
2022-04-05 03:18:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-05 03:18:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-ab6b3cff will have desired state: Ready
2022-04-05 03:19:26 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-ab6b3cff is in desired state: Ready
2022-04-05 03:19:26 [main] [32mINFO [m [MirrorMakerIsolatedST:685] -------> Scaling KafkaMirrorMaker subresource <-------
2022-04-05 03:19:26 [main] [32mINFO [m [MirrorMakerIsolatedST:686] Scaling subresource replicas to 4
2022-04-05 03:19:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ab6b3cff-mirror-maker will be ready
2022-04-05 03:19:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ab6b3cff-mirror-maker is ready
2022-04-05 03:19:26 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-ab6b3cff-mirror-maker to be ready
2022-04-05 03:20:45 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-ab6b3cff-mirror-maker is ready
2022-04-05 03:20:45 [main] [32mINFO [m [MirrorMakerIsolatedST:690] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-05 03:20:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:20:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMakerSubresource
2022-04-05 03:20:45 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ab6b3cff-target in namespace namespace-138
2022-04-05 03:20:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ab6b3cff-source in namespace namespace-138
2022-04-05 03:20:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-ab6b3cff in namespace namespace-138
2022-04-05 03:21:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:21:05 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-138 for test case:testScaleMirrorMakerSubresource
2022-04-05 03:21:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerSubresource-FINISHED
2022-04-05 03:21:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:21:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:21:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-05 03:21:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:21:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-139 for test case:testCustomAndUpdatedValues
2022-04-05 03:21:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-139
2022-04-05 03:21:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-139
2022-04-05 03:21:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-139
2022-04-05 03:21:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a3581172 in namespace namespace-139
2022-04-05 03:21:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-139
2022-04-05 03:21:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a3581172 will have desired state: Ready
2022-04-05 03:22:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a3581172 is in desired state: Ready
2022-04-05 03:22:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-a3581172 in namespace namespace-139
2022-04-05 03:22:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-139
2022-04-05 03:22:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-a3581172 will have desired state: Ready
2022-04-05 03:22:39 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-a3581172 is in desired state: Ready
2022-04-05 03:22:39 [main] [32mINFO [m [MirrorMakerIsolatedST:622] Verify values before update
2022-04-05 03:22:39 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-a3581172-mirror-maker in pod name
2022-04-05 03:22:39 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-a3581172-mirror-maker
2022-04-05 03:22:39 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-a3581172-mirror-maker
2022-04-05 03:22:39 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-a3581172-mirror-maker
2022-04-05 03:22:39 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-a3581172-mirror-maker
2022-04-05 03:22:39 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-a3581172-mirror-maker
2022-04-05 03:22:39 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-a3581172-mirror-maker
2022-04-05 03:22:39 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-a3581172-mirror-maker
2022-04-05 03:22:39 [main] [32mINFO [m [MirrorMakerIsolatedST:633] Check if actual env variable KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER has different value than test.value
2022-04-05 03:22:39 [main] [32mINFO [m [MirrorMakerIsolatedST:637] Updating values in MirrorMaker container
2022-04-05 03:22:39 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a3581172-mirror-maker rolling update
2022-04-05 03:23:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a3581172-mirror-maker will be ready
2022-04-05 03:23:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a3581172-mirror-maker is ready
2022-04-05 03:23:29 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a3581172-mirror-maker rolling update finished
2022-04-05 03:23:29 [main] [32mINFO [m [MirrorMakerIsolatedST:654] Verify values after update
2022-04-05 03:23:29 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-a3581172-mirror-maker in pod name
2022-04-05 03:23:29 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-a3581172-mirror-maker
2022-04-05 03:23:29 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-a3581172-mirror-maker
2022-04-05 03:23:29 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-a3581172-mirror-maker
2022-04-05 03:23:29 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-a3581172-mirror-maker
2022-04-05 03:23:29 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-a3581172-mirror-maker
2022-04-05 03:23:29 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-a3581172-mirror-maker
2022-04-05 03:23:29 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-a3581172-mirror-maker
2022-04-05 03:23:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:23:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-05 03:23:29 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-a3581172 in namespace namespace-139
2022-04-05 03:23:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a3581172 in namespace namespace-139
2022-04-05 03:23:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:23:39 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-139 for test case:testCustomAndUpdatedValues
2022-04-05 03:23:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-05 03:23:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:23:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:23:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMaker-STARTED
2022-04-05 03:23:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:23:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-140 for test case:testMirrorMaker
2022-04-05 03:23:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-140
2022-04-05 03:23:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-140
2022-04-05 03:23:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-140
2022-04-05 03:23:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1d8921c8-source in namespace namespace-140
2022-04-05 03:23:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-05 03:23:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1d8921c8-source will have desired state: Ready
2022-04-05 03:25:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1d8921c8-source is in desired state: Ready
2022-04-05 03:25:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1d8921c8-target in namespace namespace-140
2022-04-05 03:25:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-05 03:25:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1d8921c8-target will have desired state: Ready
2022-04-05 03:26:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1d8921c8-target is in desired state: Ready
2022-04-05 03:26:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1670769365-1601814202-source-1815683545 in namespace namespace-140
2022-04-05 03:26:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-05 03:26:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1670769365-1601814202-source-1815683545 will have desired state: Ready
2022-04-05 03:26:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1670769365-1601814202-source-1815683545 is in desired state: Ready
2022-04-05 03:26:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1d8921c8-kafka-clients in namespace namespace-140
2022-04-05 03:26:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-05 03:26:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1d8921c8-kafka-clients will be ready
2022-04-05 03:26:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1d8921c8-kafka-clients is ready
2022-04-05 03:26:07 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 03:26:07 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2fcc04f4, messages=[], arguments=[--topic, topic-for-test-broker-1, --max-messages, 200, --bootstrap-server, my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf', podNamespace='namespace-140', bootstrapServer='my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-1', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7b092677}
2022-04-05 03:26:07 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092:topic-for-test-broker-1 from pod my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf
2022-04-05 03:26:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf -n namespace-140 -- /opt/kafka/producer.sh --topic topic-for-test-broker-1 --max-messages 200 --bootstrap-server my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 03:26:10 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 03:26:10 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 03:26:10 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4e786c77, messages=[], arguments=[--topic, topic-for-test-broker-1, --max-messages, 200, --group-instance-id, instance2055533718, --group-id, my-consumer-group-605654116, --bootstrap-server, my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf', podNamespace='namespace-140', bootstrapServer='my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-1', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-605654116', consumerInstanceId='instance2055533718', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7cf0c700}
2022-04-05 03:26:10 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092#topic-for-test-broker-1 from pod my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf
2022-04-05 03:26:10 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf -n namespace-140 -- /opt/kafka/consumer.sh --topic topic-for-test-broker-1 --max-messages 200 --group-instance-id instance2055533718 --group-id my-consumer-group-605654116 --bootstrap-server my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 03:26:16 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 03:26:16 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 03:26:16 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@66166124, messages=[], arguments=[--topic, topic-for-test-broker-2, --max-messages, 200, --bootstrap-server, my-cluster-1d8921c8-target-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf', podNamespace='namespace-140', bootstrapServer='my-cluster-1d8921c8-target-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-2', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@15c3ae8}
2022-04-05 03:26:16 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-1d8921c8-target-kafka-bootstrap.namespace-140.svc:9092:topic-for-test-broker-2 from pod my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf
2022-04-05 03:26:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf -n namespace-140 -- /opt/kafka/producer.sh --topic topic-for-test-broker-2 --max-messages 200 --bootstrap-server my-cluster-1d8921c8-target-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 03:26:19 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 03:26:19 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 03:26:19 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1132be06, messages=[], arguments=[--topic, topic-for-test-broker-2, --max-messages, 200, --group-instance-id, instance1945812198, --group-id, my-consumer-group-655216785, --bootstrap-server, my-cluster-1d8921c8-target-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf', podNamespace='namespace-140', bootstrapServer='my-cluster-1d8921c8-target-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-2', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-655216785', consumerInstanceId='instance1945812198', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1c247221}
2022-04-05 03:26:19 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-1d8921c8-target-kafka-bootstrap.namespace-140.svc:9092#topic-for-test-broker-2 from pod my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf
2022-04-05 03:26:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf -n namespace-140 -- /opt/kafka/consumer.sh --topic topic-for-test-broker-2 --max-messages 200 --group-instance-id instance1945812198 --group-id my-consumer-group-655216785 --bootstrap-server my-cluster-1d8921c8-target-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 03:26:24 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 03:26:24 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 03:26:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-1d8921c8 in namespace namespace-140
2022-04-05 03:26:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-05 03:26:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-1d8921c8 will have desired state: Ready
2022-04-05 03:27:30 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-1d8921c8 is in desired state: Ready
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type mirror-maker
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-1d8921c8-mirror-maker-6cb57c9858-85p84
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1d8921c8-mirror-maker-config
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1d8921c8-source-entity-topic-operator-config
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:407] CM my-cluster-1d8921c8-source-entity-topic-operator-config is not related to current test
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1d8921c8-source-entity-user-operator-config
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:407] CM my-cluster-1d8921c8-source-entity-user-operator-config is not related to current test
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1d8921c8-source-kafka-config
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1d8921c8-source-zookeeper-config
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:407] CM my-cluster-1d8921c8-source-zookeeper-config is not related to current test
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1d8921c8-target-entity-topic-operator-config
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:407] CM my-cluster-1d8921c8-target-entity-topic-operator-config is not related to current test
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1d8921c8-target-entity-user-operator-config
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:407] CM my-cluster-1d8921c8-target-entity-user-operator-config is not related to current test
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1d8921c8-target-kafka-config
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-1d8921c8-target-zookeeper-config
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:407] CM my-cluster-1d8921c8-target-zookeeper-config is not related to current test
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-1d8921c8-source-entity-operator
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-1d8921c8-source-kafka
2022-04-05 03:27:30 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-1d8921c8-source-zookeeper
2022-04-05 03:27:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-140 exec my-cluster-1d8921c8-mirror-maker-6cb57c9858-85p84 -c my-cluster-1d8921c8-mirror-maker -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-05 03:27:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:27:31 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4ded2308, messages=[], arguments=[--topic, my-topic-1670769365-1601814202-source-1815683545, --max-messages, 200, --bootstrap-server, my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf', podNamespace='namespace-140', bootstrapServer='my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-1670769365-1601814202-source-1815683545', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1890f6c1}
2022-04-05 03:27:31 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092:my-topic-1670769365-1601814202-source-1815683545 from pod my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf
2022-04-05 03:27:31 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf -n namespace-140 -- /opt/kafka/producer.sh --topic my-topic-1670769365-1601814202-source-1815683545 --max-messages 200 --bootstrap-server my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 03:27:33 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 03:27:33 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-05 03:27:33 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@9f22eb8, messages=[], arguments=[--topic, my-topic-1670769365-1601814202-source-1815683545, --max-messages, 200, --group-instance-id, instance2013252257, --group-id, my-consumer-group-1964930674, --bootstrap-server, my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf', podNamespace='namespace-140', bootstrapServer='my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-1670769365-1601814202-source-1815683545', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1964930674', consumerInstanceId='instance2013252257', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2e9fc212}
2022-04-05 03:27:33 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092#my-topic-1670769365-1601814202-source-1815683545 from pod my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf
2022-04-05 03:27:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf -n namespace-140 -- /opt/kafka/consumer.sh --topic my-topic-1670769365-1601814202-source-1815683545 --max-messages 200 --group-instance-id instance2013252257 --group-id my-consumer-group-1964930674 --bootstrap-server my-cluster-1d8921c8-source-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 03:27:39 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 03:27:39 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 03:27:39 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@329a731b, messages=[], arguments=[--topic, my-topic-1670769365-1601814202-source-1815683545, --max-messages, 200, --group-instance-id, instance684753569, --group-id, my-consumer-group-438058604, --bootstrap-server, my-cluster-1d8921c8-target-kafka-bootstrap.namespace-140.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf', podNamespace='namespace-140', bootstrapServer='my-cluster-1d8921c8-target-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-1670769365-1601814202-source-1815683545', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-438058604', consumerInstanceId='instance684753569', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@164bf7b9}
2022-04-05 03:27:39 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-1d8921c8-target-kafka-bootstrap.namespace-140.svc:9092#my-topic-1670769365-1601814202-source-1815683545 from pod my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf
2022-04-05 03:27:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-1d8921c8-kafka-clients-7df7bfc6c5-kt8tf -n namespace-140 -- /opt/kafka/consumer.sh --topic my-topic-1670769365-1601814202-source-1815683545 --max-messages 200 --group-instance-id instance684753569 --group-id my-consumer-group-438058604 --bootstrap-server my-cluster-1d8921c8-target-kafka-bootstrap.namespace-140.svc:9092
2022-04-05 03:27:45 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 03:27:45 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-05 03:27:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:27:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker
2022-04-05 03:27:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1670769365-1601814202-source-1815683545 in namespace namespace-140
2022-04-05 03:27:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1d8921c8-target in namespace namespace-140
2022-04-05 03:27:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-1d8921c8 in namespace namespace-140
2022-04-05 03:27:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1d8921c8-kafka-clients in namespace namespace-140
2022-04-05 03:27:55 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1d8921c8-source in namespace namespace-140
2022-04-05 03:28:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:28:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-140 for test case:testMirrorMaker
2022-04-05 03:28:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMaker-FINISHED
2022-04-05 03:28:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:28:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:28:41 [main] [32mINFO [m [ResourceManager:346] In context MirrorMakerIsolatedST is everything deleted.
2022-04-05 03:28:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,528.017 s - in io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.metrics.MetricsIsolatedST
2022-04-05 03:28:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:29:06 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 03:29:06 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 03:29:06 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 03:29:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:29:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 03:29:06 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:06 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:29:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:29:06 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:29:06 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:29:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:29:06 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:29:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:06 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:29:16 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:29:16 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:29:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:29:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:29:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:29:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:29:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:29:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:29:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:29:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:29:41 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace,second-metrics-cluster-test
bindingsNamespaces=[infra-namespace, second-metrics-cluster-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 03:29:41 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 03:29:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 03:29:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-metrics-cluster-test
2022-04-05 03:29:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:29:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 03:29:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-metrics-cluster-test
2022-04-05 03:29:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:29:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:29:42 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:29:42 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:29:42 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:29:43 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 03:29:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:29:43 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 03:29:43 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:29:43 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:29:43 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-metrics-cluster-test
2022-04-05 03:29:43 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 03:29:43 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-metrics-cluster-test
2022-04-05 03:29:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:29:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 03:30:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 03:30:21 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 03:30:31 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 03:30:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:30:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka metrics-cluster-name in namespace infra-namespace
2022-04-05 03:30:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka second-kafka-cluster in namespace second-metrics-cluster-test
2022-04-05 03:30:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-kafka-clients in namespace infra-namespace
2022-04-05 03:30:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-metrics-cluster-test-kafka-clients in namespace second-metrics-cluster-test
2022-04-05 03:30:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: metrics-cluster-name will have desired state: Ready
2022-04-05 03:32:39 [main] [32mINFO [m [ResourceManager:444] Kafka: metrics-cluster-name is in desired state: Ready
2022-04-05 03:32:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: second-kafka-cluster will have desired state: Ready
2022-04-05 03:32:39 [main] [32mINFO [m [ResourceManager:444] Kafka: second-kafka-cluster is in desired state: Ready
2022-04-05 03:32:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-kafka-clients will be ready
2022-04-05 03:32:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-kafka-clients is ready
2022-04-05 03:32:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-metrics-cluster-test-kafka-clients will be ready
2022-04-05 03:32:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-metrics-cluster-test-kafka-clients is ready
2022-04-05 03:32:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-bridge in namespace infra-namespace
2022-04-05 03:32:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-bridge will have desired state: Ready
2022-04-05 03:33:05 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-bridge is in desired state: Ready
2022-04-05 03:33:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 mm2-cluster in namespace infra-namespace
2022-04-05 03:33:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: mm2-cluster will have desired state: Ready
2022-04-05 03:34:13 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: mm2-cluster is in desired state: Ready
2022-04-05 03:34:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-364577502-550657255 in namespace infra-namespace
2022-04-05 03:34:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-364577502-550657255 will have desired state: Ready
2022-04-05 03:34:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-364577502-550657255 is in desired state: Ready
2022-04-05 03:34:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1847447149-613986791 in namespace infra-namespace
2022-04-05 03:34:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1847447149-613986791 will have desired state: Ready
2022-04-05 03:34:15 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1847447149-613986791 is in desired state: Ready
2022-04-05 03:34:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-523918068-525401682 in namespace infra-namespace
2022-04-05 03:34:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-523918068-525401682 will have desired state: Ready
2022-04-05 03:34:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-523918068-525401682 is in desired state: Ready
2022-04-05 03:34:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-755295788-1506682478 in namespace infra-namespace
2022-04-05 03:34:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-755295788-1506682478 will have desired state: Ready
2022-04-05 03:34:18 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-755295788-1506682478 is in desired state: Ready
2022-04-05 03:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2097014760-1157528454 in namespace infra-namespace
2022-04-05 03:34:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2097014760-1157528454 will have desired state: Ready
2022-04-05 03:34:19 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2097014760-1157528454 is in desired state: Ready
2022-04-05 03:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect metrics-cluster-name in namespace infra-namespace
2022-04-05 03:34:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: metrics-cluster-name will have desired state: Ready
2022-04-05 03:35:27 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: metrics-cluster-name is in desired state: Ready
2022-04-05 03:35:27 [main] [32mINFO [m [NetworkPolicyResource:72] Apply NetworkPolicy access to cluster-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-05 03:35:27 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy cluster-operator-allow in namespace infra-namespace
2022-04-05 03:35:27 [main] [32mINFO [m [NetworkPolicyResource:90] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-05 03:35:27 [main] [32mINFO [m [NetworkPolicyResource:104] Apply NetworkPolicy access to metrics-cluster-name-entity-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-05 03:35:27 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy metrics-cluster-name-entity-operator-allow in namespace infra-namespace
2022-04-05 03:35:27 [main] [32mINFO [m [NetworkPolicyResource:128] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-05 03:35:27 [main] [32mINFO [m [NetworkPolicyResource:104] Apply NetworkPolicy access to second-kafka-cluster-entity-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-05 03:35:27 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy second-kafka-cluster-entity-operator-allow in namespace second-metrics-cluster-test
2022-04-05 03:35:28 [main] [32mINFO [m [NetworkPolicyResource:128] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-05 03:35:28 [main] [32mINFO [m [NetworkPolicyResource:141] Apply NetworkPolicy access to metrics-cluster-name-kafka-exporter from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-05 03:35:28 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy metrics-cluster-name-kafka-exporter-allow in namespace infra-namespace
2022-04-05 03:35:28 [main] [32mINFO [m [NetworkPolicyResource:161] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-05 03:35:28 [main] [32mINFO [m [NetworkPolicyResource:141] Apply NetworkPolicy access to second-kafka-cluster-kafka-exporter from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-05 03:35:28 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy second-kafka-cluster-kafka-exporter-allow in namespace second-metrics-cluster-test
2022-04-05 03:35:28 [main] [32mINFO [m [NetworkPolicyResource:161] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-05 03:36:50 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.15 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:36:53 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.13 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:36:55 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:36:55 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:36:56 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:36:57 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:36:58 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:36:58 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.21 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:36:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:36:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testUserOperatorMetrics-STARTED
2022-04-05 03:36:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:36:58 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.18 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:36:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:36:58 [main] [32mINFO [m [ResourceManager:346] In context testUserOperatorMetrics is everything deleted.
2022-04-05 03:36:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:36:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testUserOperatorMetrics-FINISHED
2022-04-05 03:36:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:36:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:36:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperWatchersCount-STARTED
2022-04-05 03:36:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:36:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:36:58 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperWatchersCount is everything deleted.
2022-04-05 03:36:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:36:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperWatchersCount-FINISHED
2022-04-05 03:36:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:36:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:36:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectIoNetwork-STARTED
2022-04-05 03:36:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:36:59 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectIoNetwork is everything deleted.
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectIoNetwork-FINISHED
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBrokersCount-STARTED
2022-04-05 03:36:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:346] In context testKafkaBrokersCount is everything deleted.
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBrokersCount-FINISHED
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaActiveControllers-STARTED
2022-04-05 03:36:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:346] In context testKafkaActiveControllers is everything deleted.
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaActiveControllers-FINISHED
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicUnderReplicatedPartitions-STARTED
2022-04-05 03:36:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:346] In context testKafkaTopicUnderReplicatedPartitions is everything deleted.
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicUnderReplicatedPartitions-FINISHED
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperQuorumSize-STARTED
2022-04-05 03:36:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperQuorumSize is everything deleted.
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperQuorumSize-FINISHED
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperAliveConnections-STARTED
2022-04-05 03:36:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperAliveConnections is everything deleted.
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperAliveConnections-FINISHED
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicPartitions-STARTED
2022-04-05 03:36:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:346] In context testKafkaTopicPartitions is everything deleted.
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicPartitions-FINISHED
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:36:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testReconcileStateMetricInTopicOperator-STARTED
2022-04-05 03:36:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:36:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-metrics-cluster-test
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-562473045-519155156 in namespace second-metrics-cluster-test
2022-04-05 03:36:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-562473045-519155156 will have desired state: Ready
2022-04-05 03:37:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-562473045-519155156 is in desired state: Ready
2022-04-05 03:37:00 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.17 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-s8th8 finished with return code: 0
2022-04-05 03:37:00 [main] [32mINFO [m [MetricsIsolatedST:555] Checking if resource state metric reason message is "none" and KafkaTopic is ready
2022-04-05 03:37:00 [main] [32mINFO [m [MetricsIsolatedST:558] Changing topic name in spec.topicName
2022-04-05 03:37:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-562473045-519155156 will have desired state: NotReady
2022-04-05 03:37:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-562473045-519155156 is in desired state: NotReady
2022-04-05 03:37:02 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.17 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-s8th8 finished with return code: 0
2022-04-05 03:37:02 [main] [32mINFO [m [MetricsIsolatedST:566] Changing back to it's original name and scaling replicas to be higher number
2022-04-05 03:37:02 [main] [32mINFO [m [KafkaTopicUtils:132] Waiting for KafkaTopic change my-topic-562473045-519155156
2022-04-05 03:37:02 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.17 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-s8th8 finished with return code: 0
2022-04-05 03:37:02 [main] [32mINFO [m [MetricsIsolatedST:578] Scaling replicas to be higher than before
2022-04-05 03:37:02 [main] [32mINFO [m [KafkaTopicUtils:132] Waiting for KafkaTopic change my-topic-562473045-519155156
2022-04-05 03:37:02 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.17 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-s8th8 finished with return code: 0
2022-04-05 03:37:02 [main] [32mINFO [m [MetricsIsolatedST:586] Changing KafkaTopic's spec to correct state
2022-04-05 03:37:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-562473045-519155156 will have desired state: Ready
2022-04-05 03:37:03 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-562473045-519155156 is in desired state: Ready
2022-04-05 03:37:03 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.17 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-s8th8 finished with return code: 0
2022-04-05 03:37:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:37:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:37:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReconcileStateMetricInTopicOperator
2022-04-05 03:37:03 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-562473045-519155156 in namespace second-metrics-cluster-test
2022-04-05 03:37:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:37:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testReconcileStateMetricInTopicOperator-FINISHED
2022-04-05 03:37:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:37:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:37:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testMirrorMaker2Metrics-STARTED
2022-04-05 03:37:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:37:14 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.23 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:37:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:37:14 [main] [32mINFO [m [ResourceManager:346] In context testMirrorMaker2Metrics is everything deleted.
2022-04-05 03:37:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:37:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testMirrorMaker2Metrics-FINISHED
2022-04-05 03:37:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:37:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:37:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBridgeMetrics-STARTED
2022-04-05 03:37:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:37:14 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 03:37:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer in namespace infra-namespace
2022-04-05 03:37:14 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer will be in active state
2022-04-05 03:37:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-consumer in namespace infra-namespace
2022-04-05 03:37:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-consumer will be in active state
2022-04-05 03:37:16 [main] [32mINFO [m [MetricsIsolatedST:422] Looking for 'strimzi_bridge_kafka_producer_count' in bridge metrics
2022-04-05 03:37:17 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:37:18 [main] [32mINFO [m [MetricsIsolatedST:422] Looking for 'strimzi_bridge_kafka_producer_count' in bridge metrics
2022-04-05 03:37:18 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:37:18 [main] [32mINFO [m [MetricsIsolatedST:430] Looking for 'strimzi_bridge_kafka_consumer_connection_count' in bridge metrics
2022-04-05 03:37:19 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:37:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:37:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeMetrics
2022-04-05 03:37:19 [main] [32mINFO [m [ResourceManager:241] Delete of Job bridge-consumer in namespace infra-namespace
2022-04-05 03:37:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer in namespace infra-namespace
2022-04-05 03:37:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:37:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBridgeMetrics-FINISHED
2022-04-05 03:37:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:37:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:37:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaMetricsSettings-STARTED
2022-04-05 03:37:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:37:19 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: second-kafka-cluster are stable
2022-04-05 03:37:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:37:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:37:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:37:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:37:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:37:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:37:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:37:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:37:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:37:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:37:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:37:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:37:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:37:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:37:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:37:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:37:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:37:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:37:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:37:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:37:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:37:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:37:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:37:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:37:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:37:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:37:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:37:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:37:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:37:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:37:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:37:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:37:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:37:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:37:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:37:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:37:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:37:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:37:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:37:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:37:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:37:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:37:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:37:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:37:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:37:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:37:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:37:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:37:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:37:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:37:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:37:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:37:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:37:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:37:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:37:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:37:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:37:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:37:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:37:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:37:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:37:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:37:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:37:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:37:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:37:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:37:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:37:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:37:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:37:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:37:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:37:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:37:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:37:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:37:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:37:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:37:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:37:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:37:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:37:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:37:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:37:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:37:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:37:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:37:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:37:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:37:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:37:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:37:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:37:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:37:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:37:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:37:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:37:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:37:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:37:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:37:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:37:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:37:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:37:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:37:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:37:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:37:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:37:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:37:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:37:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:37:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:37:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:37:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:37:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:37:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:37:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:37:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:37:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:37:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:37:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:37:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:37:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:37:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:37:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:37:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:37:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:37:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:37:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:37:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:37:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:37:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:37:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:37:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:37:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:37:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:37:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:37:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:37:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:37:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:37:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:37:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:37:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:37:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:37:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:37:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:37:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:37:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:37:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:37:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:37:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:37:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:37:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:37:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:37:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:37:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:37:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:37:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:37:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:37:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:37:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:37:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:37:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:37:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:37:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:38:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:38:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:38:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:38:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:38:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:38:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:38:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:38:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:38:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:38:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:38:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:38:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:38:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:38:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:38:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:38:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:38:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:38:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:38:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:38:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:38:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:38:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:38:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:38:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:38:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:38:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:38:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:38:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:38:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:38:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:38:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:38:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:38:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:38:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:38:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:38:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:38:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:38:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:38:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:38:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:38:09 [main] [32mINFO [m [PodUtils:335] All pods are stable second-kafka-cluster-entity-operator-5f8949dc9c-7j72f ,second-kafka-cluster-kafka-0 ,second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p ,second-kafka-cluster-zookeeper-0
2022-04-05 03:38:09 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: second-kafka-cluster are stable
2022-04-05 03:38:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:38:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:38:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:38:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 03:38:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:38:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:38:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:38:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 03:38:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:38:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:38:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:38:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 03:38:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:38:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:38:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:38:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 03:38:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:38:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:38:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:38:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 03:38:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:38:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:38:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:38:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 03:38:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:38:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:38:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:38:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 03:38:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:38:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:38:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:38:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 03:38:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:38:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:38:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:38:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 03:38:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:38:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:38:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:38:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 03:38:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:38:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:38:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:38:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 03:38:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:38:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:38:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:38:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 03:38:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:38:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:38:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:38:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 03:38:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:38:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:38:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:38:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 03:38:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:38:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:38:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:38:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 03:38:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:38:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:38:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:38:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 03:38:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:38:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:38:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:38:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 03:38:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:38:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:38:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:38:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 03:38:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:38:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:38:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:38:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 03:38:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:38:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:38:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:38:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 03:38:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:38:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:38:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:38:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 03:38:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:38:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:38:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:38:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 03:38:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:38:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:38:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:38:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 03:38:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:38:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:38:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:38:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 03:38:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:38:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:38:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:38:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 03:38:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:38:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:38:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:38:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 03:38:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:38:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:38:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:38:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 03:38:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:38:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:38:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:38:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 03:38:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:38:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:38:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:38:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 03:38:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:38:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:38:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:38:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 03:38:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:38:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:38:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:38:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 03:38:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:38:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:38:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:38:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 03:38:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:38:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:38:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:38:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 03:38:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:38:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:38:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:38:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 03:38:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:38:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:38:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:38:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 03:38:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:38:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:38:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:38:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 03:38:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:38:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:38:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:38:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 03:38:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:38:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:38:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:38:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 03:38:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:38:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:38:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:38:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 03:38:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:38:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:38:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:38:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 03:38:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:38:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:38:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:38:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 03:38:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:38:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:38:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:38:51 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 03:38:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:38:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:38:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:38:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 03:38:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:38:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:38:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:38:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 03:38:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:38:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:38:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:38:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 03:38:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:38:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:38:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:38:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 03:38:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:38:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:38:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:38:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 03:38:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:38:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:38:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:38:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 03:38:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:38:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:38:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:38:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 03:38:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-7j72f is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:38:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:38:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:38:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 03:38:59 [main] [32mINFO [m [PodUtils:335] All pods are stable second-kafka-cluster-entity-operator-5f8949dc9c-7j72f ,second-kafka-cluster-kafka-0 ,second-kafka-cluster-kafka-exporter-6dfb7ccc69-hhx7p ,second-kafka-cluster-zookeeper-0
2022-04-05 03:38:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:38:59 [main] [32mINFO [m [ResourceManager:346] In context testKafkaMetricsSettings is everything deleted.
2022-04-05 03:38:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:38:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaMetricsSettings-FINISHED
2022-04-05 03:38:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:38:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:38:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testClusterOperatorMetrics-STARTED
2022-04-05 03:38:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:38:59 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.5 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:38:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:38:59 [main] [32mINFO [m [ResourceManager:346] In context testClusterOperatorMetrics is everything deleted.
2022-04-05 03:38:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:38:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testClusterOperatorMetrics-FINISHED
2022-04-05 03:38:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:38:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:38:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testCruiseControlMetrics-STARTED
2022-04-05 03:38:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:39:00 [main] [32mINFO [m [MetricsIsolatedST:452] Verifying that we have more than 0 groups
2022-04-05 03:39:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:39:00 [main] [32mINFO [m [ResourceManager:346] In context testCruiseControlMetrics is everything deleted.
2022-04-05 03:39:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:39:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testCruiseControlMetrics-FINISHED
2022-04-05 03:39:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:39:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:39:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDataAfterExchange-STARTED
2022-04-05 03:39:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:39:00 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 03:39:00 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7aa9a0ba, messages=[], arguments=[--topic, my-topic-1847447149-613986791, --max-messages, 5000, --bootstrap-server, metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='infra-namespace-kafka-clients-748578f786-bbxd6', podNamespace='infra-namespace', bootstrapServer='metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-1847447149-613986791', maxMessages=5000, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@42e49c9d}
2022-04-05 03:39:00 [main] [32mINFO [m [InternalKafkaClient:94] Producing 5000 messages to metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092:my-topic-1847447149-613986791 from pod infra-namespace-kafka-clients-748578f786-bbxd6
2022-04-05 03:39:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec infra-namespace-kafka-clients-748578f786-bbxd6 -n infra-namespace -- /opt/kafka/producer.sh --topic my-topic-1847447149-613986791 --max-messages 5000 --bootstrap-server metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092
2022-04-05 03:39:03 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 03:39:03 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 5000 messages
2022-04-05 03:39:03 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5a4e8bf9, messages=[], arguments=[--topic, my-topic-1847447149-613986791, --max-messages, 5000, --group-instance-id, instance17234405, --group-id, my-consumer-group-1662941054, --bootstrap-server, metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='infra-namespace-kafka-clients-748578f786-bbxd6', podNamespace='infra-namespace', bootstrapServer='metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-1847447149-613986791', maxMessages=5000, kafkaUsername='null', consumerGroupName='my-consumer-group-1662941054', consumerInstanceId='instance17234405', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@56417800}
2022-04-05 03:39:03 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 5000 messages from metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092#my-topic-1847447149-613986791 from pod infra-namespace-kafka-clients-748578f786-bbxd6
2022-04-05 03:39:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec infra-namespace-kafka-clients-748578f786-bbxd6 -n infra-namespace -- /opt/kafka/consumer.sh --topic my-topic-1847447149-613986791 --max-messages 5000 --group-instance-id instance17234405 --group-id my-consumer-group-1662941054 --bootstrap-server metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092
2022-04-05 03:39:09 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 03:39:09 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 5000 messages
2022-04-05 03:39:09 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.21 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:39:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:39:09 [main] [32mINFO [m [ResourceManager:346] In context testKafkaExporterDataAfterExchange is everything deleted.
2022-04-05 03:39:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:39:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDataAfterExchange-FINISHED
2022-04-05 03:39:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:39:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:39:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testTopicOperatorMetrics-STARTED
2022-04-05 03:39:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.18 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: consumer-offsets---84e7a678d08f4bd226872e5cdd4eb527fadc1c6a
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: heartbeats
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-config
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-offsets
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-status
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-configs
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-offsets
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-status
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-1847447149-613986791
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-364577502-550657255
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-523918068-525401682
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: second-kafka-cluster.checkpoints.internal
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi-store-topic---effb8e3e057afce1ecf67c3f5d8e4e3ff177fc55
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi-topic-operator-kstreams-topic-store-changelog---b75e702040b99be8a9263134de3507fc0cc4017b
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.metrics
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples
2022-04-05 03:39:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:39:10 [main] [32mINFO [m [ResourceManager:346] In context testTopicOperatorMetrics is everything deleted.
2022-04-05 03:39:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:39:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testTopicOperatorMetrics-FINISHED
2022-04-05 03:39:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:39:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:39:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectRequests-STARTED
2022-04-05 03:39:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:39:10 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:39:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:39:10 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectRequests is everything deleted.
2022-04-05 03:39:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:39:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectRequests-FINISHED
2022-04-05 03:39:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:39:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:39:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectResponse-STARTED
2022-04-05 03:39:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:39:11 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-bbxd6 finished with return code: 0
2022-04-05 03:39:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:39:11 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectResponse is everything deleted.
2022-04-05 03:39:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:39:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectResponse-FINISHED
2022-04-05 03:39:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:39:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:39:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDifferentSetting-STARTED
2022-04-05 03:39:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:39:11 [main] [32mINFO [m [MetricsIsolatedST:610] Metrics collection for pod metrics-cluster-name-kafka-exporter-8454677f49-twdsl return code - 0
2022-04-05 03:39:11 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment metrics-cluster-name-kafka-exporter rolling update
2022-04-05 03:39:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: metrics-cluster-name-kafka-exporter will be ready
2022-04-05 03:39:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: metrics-cluster-name-kafka-exporter is ready
2022-04-05 03:40:01 [main] [32mINFO [m [DeploymentUtils:141] Deployment metrics-cluster-name-kafka-exporter rolling update finished
2022-04-05 03:40:02 [main] [32mINFO [m [MetricsIsolatedST:610] Metrics collection for pod metrics-cluster-name-kafka-exporter-6647b687fd-lm4sm return code - 0
2022-04-05 03:40:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:40:02 [main] [32mINFO [m [ResourceManager:346] In context testKafkaExporterDifferentSetting is everything deleted.
2022-04-05 03:40:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:40:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDifferentSetting-FINISHED
2022-04-05 03:40:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:40:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:40:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for MetricsIsolatedST
2022-04-05 03:40:02 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2097014760-1157528454 in namespace infra-namespace
2022-04-05 03:40:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy second-kafka-cluster-entity-operator-allow in namespace second-metrics-cluster-test
2022-04-05 03:40:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 mm2-cluster in namespace infra-namespace
2022-04-05 03:40:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy metrics-cluster-name-entity-operator-allow in namespace infra-namespace
2022-04-05 03:40:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy second-kafka-cluster-kafka-exporter-allow in namespace second-metrics-cluster-test
2022-04-05 03:40:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy cluster-operator-allow in namespace infra-namespace
2022-04-05 03:40:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy metrics-cluster-name-kafka-exporter-allow in namespace infra-namespace
2022-04-05 03:40:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-755295788-1506682478 in namespace infra-namespace
2022-04-05 03:40:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect metrics-cluster-name in namespace infra-namespace
2022-04-05 03:40:12 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-bridge in namespace infra-namespace
2022-04-05 03:40:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-523918068-525401682 in namespace infra-namespace
2022-04-05 03:40:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-kafka-clients in namespace infra-namespace
2022-04-05 03:40:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1847447149-613986791 in namespace infra-namespace
2022-04-05 03:40:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka second-kafka-cluster in namespace second-metrics-cluster-test
2022-04-05 03:40:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-364577502-550657255 in namespace infra-namespace
2022-04-05 03:40:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka metrics-cluster-name in namespace infra-namespace
2022-04-05 03:40:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace infra-namespace, for cruise control Kafka cluster metrics-cluster-name
2022-04-05 03:40:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment second-metrics-cluster-test-kafka-clients in namespace second-metrics-cluster-test
2022-04-05 03:41:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 761.128 s - in io.strimzi.systemtest.metrics.MetricsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.metrics.JmxIsolatedST
2022-04-05 03:41:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:41:47 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 03:41:47 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 03:41:47 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 03:41:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:41:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 03:41:47 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:41:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:41:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:41:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:41:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-metrics-cluster-test
2022-04-05 03:41:47 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:41:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:41:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-metrics-cluster-test
2022-04-05 03:41:47 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:41:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:41:47 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:41:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:41:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:41:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:41:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:41:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:41:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:42:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:42:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:42:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:42:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:42:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:42:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:42:48 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 03:42:48 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 03:42:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 03:42:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:42:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:42:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 03:42:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:42:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:42:49 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:42:49 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:42:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 03:43:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 03:43:21 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 03:43:31 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 03:43:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:43:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.JmxIsolatedST.testKafkaZookeeperAndKafkaConnectWithJMX-STARTED
2022-04-05 03:43:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:43:31 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-141 for test case:testKafkaZookeeperAndKafkaConnectWithJMX
2022-04-05 03:43:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-141
2022-04-05 03:43:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-141
2022-04-05 03:43:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-141
2022-04-05 03:43:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-633b920e in namespace namespace-141
2022-04-05 03:43:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-05 03:43:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-633b920e will have desired state: Ready
2022-04-05 03:44:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-633b920e is in desired state: Ready
2022-04-05 03:44:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-633b920e-kafka-clients in namespace namespace-141
2022-04-05 03:44:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-05 03:44:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-633b920e-kafka-clients will be ready
2022-04-05 03:44:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-633b920e-kafka-clients is ready
2022-04-05 03:44:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-633b920e-scraper in namespace namespace-141
2022-04-05 03:44:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-05 03:44:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-633b920e-scraper will be ready
2022-04-05 03:44:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-633b920e-scraper is ready
2022-04-05 03:44:56 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-633b920e-scraper to be ready
2022-04-05 03:45:06 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-633b920e-scraper is ready
2022-04-05 03:45:06 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-633b920e-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 03:45:06 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-633b920e-allow in namespace namespace-141
2022-04-05 03:45:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-05 03:45:06 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 03:45:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-633b920e in namespace namespace-141
2022-04-05 03:45:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-141
2022-04-05 03:45:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-633b920e will have desired state: Ready
2022-04-05 03:46:26 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-633b920e is in desired state: Ready
2022-04-05 03:46:26 [main] [32mINFO [m [JmxUtils:54] Getting username and password for service: my-cluster-633b920e-kafka-brokers and secret: my-cluster-633b920e-kafka-jmx
2022-04-05 03:46:26 [main] [32mINFO [m [JmxUtils:58] Creating script file for service: my-cluster-633b920e-kafka-brokers
2022-04-05 03:46:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-633b920e-kafka-clients-74bb5f8cb-tf5rh -- /bin/bash -c echo 'open service:jmx:rmi:///jndi/rmi://my-cluster-633b920e-kafka-brokers:9999/jmxrmi -u ZZ726ukPHHPgl56o -p Gg8HXoRMjzr6lZcq
bean kafka.server:type=app-info
get -i *' > /tmp/my-cluster-633b920e-kafka-brokers.sh
2022-04-05 03:46:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:46:27 [main] [32mINFO [m [JmxUtils:63] Waiting for JMX metrics for service: my-cluster-633b920e-kafka-brokers will be present
2022-04-05 03:46:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-633b920e-kafka-clients-74bb5f8cb-tf5rh -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-633b920e-kafka-brokers.sh
2022-04-05 03:46:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:46:28 [main] [32mINFO [m [JmxUtils:54] Getting username and password for service: my-cluster-633b920e-connect-api and secret: my-cluster-633b920e-kafka-connect-jmx
2022-04-05 03:46:28 [main] [32mINFO [m [JmxUtils:58] Creating script file for service: my-cluster-633b920e-connect-api
2022-04-05 03:46:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-633b920e-kafka-clients-74bb5f8cb-tf5rh -- /bin/bash -c echo 'open service:jmx:rmi:///jndi/rmi://my-cluster-633b920e-connect-api:9999/jmxrmi -u V78cra15thBZzKPi -p kaP0IGIp5sJ5eoab
bean kafka.connect:type=app-info
get -i *' > /tmp/my-cluster-633b920e-connect-api.sh
2022-04-05 03:46:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:46:28 [main] [32mINFO [m [JmxUtils:63] Waiting for JMX metrics for service: my-cluster-633b920e-connect-api will be present
2022-04-05 03:46:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-633b920e-kafka-clients-74bb5f8cb-tf5rh -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-633b920e-connect-api.sh
2022-04-05 03:46:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:46:29 [main] [32mINFO [m [JmxUtils:54] Getting username and password for service: my-cluster-633b920e-zookeeper-nodes and secret: my-cluster-633b920e-zookeeper-jmx
2022-04-05 03:46:29 [main] [32mINFO [m [JmxUtils:58] Creating script file for service: my-cluster-633b920e-zookeeper-nodes
2022-04-05 03:46:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-633b920e-kafka-clients-74bb5f8cb-tf5rh -- /bin/bash -c echo 'open service:jmx:rmi:///jndi/rmi://my-cluster-633b920e-zookeeper-nodes:9999/jmxrmi -u h6bnQ6TfVjgCIxIL -p oClfRWGgHNjmRoFI
domain org.apache.ZooKeeperService
beans' > /tmp/my-cluster-633b920e-zookeeper-nodes.sh
2022-04-05 03:46:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:46:29 [main] [32mINFO [m [JmxUtils:63] Waiting for JMX metrics for service: my-cluster-633b920e-zookeeper-nodes will be present
2022-04-05 03:46:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-633b920e-kafka-clients-74bb5f8cb-tf5rh -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-633b920e-zookeeper-nodes.sh
2022-04-05 03:46:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:46:30 [main] [32mINFO [m [JmxUtils:54] Getting username and password for service: my-cluster-633b920e-zookeeper-nodes and secret: my-cluster-633b920e-zookeeper-jmx
2022-04-05 03:46:30 [main] [32mINFO [m [JmxUtils:58] Creating script file for service: my-cluster-633b920e-zookeeper-nodes
2022-04-05 03:46:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-633b920e-kafka-clients-74bb5f8cb-tf5rh -- /bin/bash -c echo 'open service:jmx:rmi:///jndi/rmi://my-cluster-633b920e-zookeeper-nodes:9999/jmxrmi -u h6bnQ6TfVjgCIxIL -p oClfRWGgHNjmRoFI
bean org.apache.ZooKeeperService:name0=ReplicatedServer_id1
get -i *' > /tmp/my-cluster-633b920e-zookeeper-nodes.sh
2022-04-05 03:46:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:46:30 [main] [32mINFO [m [JmxUtils:63] Waiting for JMX metrics for service: my-cluster-633b920e-zookeeper-nodes will be present
2022-04-05 03:46:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-141 exec my-cluster-633b920e-kafka-clients-74bb5f8cb-tf5rh -- java -jar jmxterm/jmxterm.jar -i /tmp/my-cluster-633b920e-zookeeper-nodes.sh
2022-04-05 03:46:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:46:31 [main] [32mINFO [m [JmxIsolatedST:110] Checking that Zookeeper JMX secret is created with custom labels and annotations
2022-04-05 03:46:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:46:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaZookeeperAndKafkaConnectWithJMX
2022-04-05 03:46:31 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-633b920e-scraper in namespace namespace-141
2022-04-05 03:46:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-633b920e-kafka-clients in namespace namespace-141
2022-04-05 03:46:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-633b920e in namespace namespace-141
2022-04-05 03:46:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-633b920e in namespace namespace-141
2022-04-05 03:46:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-633b920e-allow in namespace namespace-141
2022-04-05 03:47:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:47:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-141 for test case:testKafkaZookeeperAndKafkaConnectWithJMX
2022-04-05 03:47:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.JmxIsolatedST.testKafkaZookeeperAndKafkaConnectWithJMX-FINISHED
2022-04-05 03:47:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:47:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:47:27 [main] [32mINFO [m [ResourceManager:346] In context JmxIsolatedST is everything deleted.
2022-04-05 03:47:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 365.032 s - in io.strimzi.systemtest.metrics.JmxIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-05 03:47:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:47:52 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 03:47:52 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 03:47:52 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 03:47:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:47:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 03:47:52 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:47:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:47:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:47:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:47:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:47:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:47:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:47:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:47:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:47:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:02 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:48:02 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:48:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:48:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:48:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:48:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:48:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:48:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:48:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:48:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:48:28 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@688cb7be
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 03:48:28 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 03:48:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 03:48:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:48:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 03:48:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:48:28 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:48:28 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:48:28 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:48:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:48:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 03:49:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 03:49:00 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 03:49:10 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 03:49:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:49:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-STARTED
2022-04-05 03:49:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:49:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e615cd85 in namespace infra-namespace
2022-04-05 03:49:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e615cd85 will have desired state: Ready
2022-04-05 03:50:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e615cd85 is in desired state: Ready
2022-04-05 03:50:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-e615cd85-hello-world-producer in namespace infra-namespace
2022-04-05 03:50:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-e615cd85-hello-world-consumer in namespace infra-namespace
2022-04-05 03:50:30 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-e615cd85-hello-world-producer will be in active state
2022-04-05 03:50:31 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-e615cd85-hello-world-consumer will be in active state
2022-04-05 03:50:31 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-e615cd85-hello-world-producer and consumer my-cluster-e615cd85-hello-world-consumer finish
2022-04-05 03:50:49 [main] [32mINFO [m [LogDumpScriptIsolatedST:78] Print partition segments from cluster infra-namespace/my-cluster-e615cd85
2022-04-05 03:50:49 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-e615cd85 --topic my-topic-1328785721-132096153 --partition 0 --dry-run
2022-04-05 03:50:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:50:49 [main] [32mINFO [m [LogDumpScriptIsolatedST:87] Dump topic partition from cluster infra-namespace/my-cluster-e615cd85
2022-04-05 03:50:52 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-e615cd85 --topic my-topic-1328785721-132096153 --partition 0 --out-path /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-e615cd85
2022-04-05 03:50:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:50:52 [main] [32mINFO [m [LogDumpScriptIsolatedST:99] Dump consumer offsets partition from cluster infra-namespace/my-cluster-e615cd85
2022-04-05 03:50:57 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh cg_offsets --namespace infra-namespace --cluster my-cluster-e615cd85 --group-id my-group --out-path /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-e615cd85
2022-04-05 03:50:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 03:50:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:50:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for dumpPartitions
2022-04-05 03:50:57 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-e615cd85-hello-world-producer in namespace infra-namespace
2022-04-05 03:50:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e615cd85 in namespace infra-namespace
2022-04-05 03:50:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-e615cd85-hello-world-consumer in namespace infra-namespace
2022-04-05 03:51:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:51:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-FINISHED
2022-04-05 03:51:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:51:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:51:07 [main] [32mINFO [m [ResourceManager:346] In context LogDumpScriptIsolatedST is everything deleted.
2022-04-05 03:51:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 220.167 s - in io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-05 03:51:07 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 03:51:07 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 03:51:07 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 03:51:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:51:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 03:51:07 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:51:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:51:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:51:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:51:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:51:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:51:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:51:17 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:51:17 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:51:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:51:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:51:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:51:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:51:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:51:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:51:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:51:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.SecurityST
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-04-05 03:51:53 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-05 03:51:53 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@33a0f5e6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 03:51:53 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 03:51:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 03:51:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:51:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 03:51:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:51:53 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 03:51:53 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:51:53 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 03:51:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 03:51:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 03:52:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 03:52:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 03:52:39 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 03:52:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: rolling-update-st
2022-04-05 03:52:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: rolling-update-st
2022-04-05 03:52:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: rolling-update-st
2022-04-05 03:52:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:52:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-STARTED
2022-04-05 03:52:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:52:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bd84890e in namespace rolling-update-st
2022-04-05 03:52:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bd84890e will have desired state: Ready
2022-04-05 03:54:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bd84890e is in desired state: Ready
2022-04-05 03:54:07 [main] [32mINFO [m [RollingUpdateST:630] Deleting Cluster Operator pod with labels LabelSelector(matchExpressions=[], matchLabels={name=strimzi-cluster-operator}, additionalProperties={})
2022-04-05 03:54:07 [main] [32mINFO [m [RollingUpdateST:632] Cluster Operator pod deleted
2022-04-05 03:54:07 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-bd84890e-zookeeper rolling update
2022-04-05 03:55:27 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-bd84890e-zookeeper has been successfully rolled
2022-04-05 03:55:27 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-bd84890e-zookeeper to be ready
2022-04-05 03:55:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bd84890e will have desired state: Ready
2022-04-05 03:55:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bd84890e is in desired state: Ready
2022-04-05 03:55:59 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-bd84890e is ready
2022-04-05 03:55:59 [main] [32mINFO [m [RollingUpdateST:639] Deleting Cluster Operator pod with labels LabelSelector(matchExpressions=[], matchLabels={name=strimzi-cluster-operator}, additionalProperties={})
2022-04-05 03:56:00 [main] [32mINFO [m [RollingUpdateST:641] Cluster Operator pod deleted
2022-04-05 03:56:00 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-bd84890e-kafka rolling update
2022-04-05 03:57:00 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-bd84890e-kafka has been successfully rolled
2022-04-05 03:57:00 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-bd84890e-kafka to be ready
2022-04-05 03:57:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bd84890e will have desired state: Ready
2022-04-05 03:57:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bd84890e is in desired state: Ready
2022-04-05 03:57:29 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-bd84890e is ready
2022-04-05 03:57:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:57:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClusterOperatorFinishAllRollingUpdates
2022-04-05 03:57:29 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bd84890e in namespace rolling-update-st
2022-04-05 03:57:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 03:57:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-FINISHED
2022-04-05 03:57:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 03:57:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 03:57:39 [main] [32mINFO [m [ResourceManager:346] In context RollingUpdateST is everything deleted.
2022-04-05 03:57:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 389.561 s - in io.strimzi.systemtest.rollingupdate.RollingUpdateST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.SecurityST
2022-04-05 03:58:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: security-st
2022-04-05 03:58:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: security-st
2022-04-05 03:58:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: security-st
2022-04-05 03:58:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 03:58:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-STARTED
2022-04-05 03:58:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 03:58:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-142 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-05 03:58:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-142
2022-04-05 03:58:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-142
2022-04-05 03:58:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-142
2022-04-05 03:58:22 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 03:58:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7e056f78 in namespace namespace-142
2022-04-05 03:58:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-05 03:58:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7e056f78 will have desired state: Ready
2022-04-05 04:00:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7e056f78 is in desired state: Ready
2022-04-05 04:00:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1686692053-113944379 in namespace namespace-142
2022-04-05 04:00:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-05 04:00:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1686692053-113944379 will have desired state: Ready
2022-04-05 04:00:36 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1686692053-113944379 is in desired state: Ready
2022-04-05 04:00:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1119526086-666142429 in namespace namespace-142
2022-04-05 04:00:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-05 04:00:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1119526086-666142429 will have desired state: Ready
2022-04-05 04:00:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1119526086-666142429 is in desired state: Ready
2022-04-05 04:00:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7e056f78-kafka-clients in namespace namespace-142
2022-04-05 04:00:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-05 04:00:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7e056f78-kafka-clients will be ready
2022-04-05 04:00:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7e056f78-kafka-clients is ready
2022-04-05 04:00:39 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 04:00:39 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-7e056f78-kafka-clients-6dbf4bf86f-bqvzw
2022-04-05 04:00:39 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5f953de9, messages=[], arguments=[--topic, my-topic-1119526086-666142429, --max-messages, 100, --bootstrap-server, my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7e056f78-kafka-clients-6dbf4bf86f-bqvzw', podNamespace='namespace-142', bootstrapServer='my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092', topicName='my-topic-1119526086-666142429', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6d57cb87}
2022-04-05 04:00:39 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092:my-topic-1119526086-666142429 from pod my-cluster-7e056f78-kafka-clients-6dbf4bf86f-bqvzw
2022-04-05 04:00:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7e056f78-kafka-clients-6dbf4bf86f-bqvzw -n namespace-142 -- /opt/kafka/producer.sh --topic my-topic-1119526086-666142429 --max-messages 100 --bootstrap-server my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092
2022-04-05 04:00:42 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 04:00:42 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 04:00:42 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@78488573, messages=[], arguments=[--topic, my-topic-1119526086-666142429, --max-messages, 100, --group-instance-id, instance952725157, --group-id, my-consumer-group-1904710814, --bootstrap-server, my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7e056f78-kafka-clients-6dbf4bf86f-bqvzw', podNamespace='namespace-142', bootstrapServer='my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092', topicName='my-topic-1119526086-666142429', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1904710814', consumerInstanceId='instance952725157', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2b106865}
2022-04-05 04:00:42 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092#my-topic-1119526086-666142429 from pod my-cluster-7e056f78-kafka-clients-6dbf4bf86f-bqvzw
2022-04-05 04:00:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7e056f78-kafka-clients-6dbf4bf86f-bqvzw -n namespace-142 -- /opt/kafka/consumer.sh --topic my-topic-1119526086-666142429 --max-messages 100 --group-instance-id instance952725157 --group-id my-consumer-group-1904710814 --bootstrap-server my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092
2022-04-05 04:00:48 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 04:00:48 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 04:00:48 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-05 04:00:48 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-7e056f78-cluster-ca with strimzi.io/force-replace
2022-04-05 04:00:48 [main] [32mINFO [m [SecurityST:484] Wait for zk to rolling restart (1)...
2022-04-05 04:00:48 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-7e056f78-zookeeper rolling update
2022-04-05 04:02:03 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-7e056f78-zookeeper has been successfully rolled
2022-04-05 04:02:03 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-05 04:02:03 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-7e056f78-kafka rolling update
2022-04-05 04:03:28 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-7e056f78-kafka has been successfully rolled
2022-04-05 04:03:28 [main] [32mINFO [m [SecurityST:494] Wait for EO to rolling restart (1)...
2022-04-05 04:03:28 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7e056f78-entity-operator rolling update
2022-04-05 04:03:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7e056f78-entity-operator will be ready
2022-04-05 04:05:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7e056f78-entity-operator is ready
2022-04-05 04:05:28 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7e056f78-entity-operator rolling update finished
2022-04-05 04:05:28 [main] [32mINFO [m [SecurityST:499] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-04-05 04:05:28 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7e056f78-kafka-exporter rolling update
2022-04-05 04:05:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7e056f78-kafka-exporter will be ready
2022-04-05 04:05:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7e056f78-kafka-exporter is ready
2022-04-05 04:06:02 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7e056f78-kafka-exporter rolling update finished
2022-04-05 04:06:02 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7e056f78-cruise-control rolling update
2022-04-05 04:06:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7e056f78-cruise-control will be ready
2022-04-05 04:06:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7e056f78-cruise-control is ready
2022-04-05 04:06:27 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7e056f78-cruise-control rolling update finished
2022-04-05 04:06:27 [main] [32mINFO [m [SecurityST:505] Wait for zk to rolling restart (2)...
2022-04-05 04:06:27 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-7e056f78-zookeeper rolling update
2022-04-05 04:07:27 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-7e056f78-zookeeper has been successfully rolled
2022-04-05 04:07:27 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-7e056f78-zookeeper to be ready
2022-04-05 04:07:50 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-05 04:07:50 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-7e056f78-kafka rolling update
2022-04-05 04:09:00 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-7e056f78-kafka has been successfully rolled
2022-04-05 04:09:00 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-7e056f78-kafka to be ready
2022-04-05 04:09:28 [main] [32mINFO [m [SecurityST:515] Wait for EO to rolling restart (2)...
2022-04-05 04:09:28 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7e056f78-entity-operator rolling update
2022-04-05 04:09:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7e056f78-entity-operator will be ready
2022-04-05 04:16:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7e056f78-entity-operator is ready
2022-04-05 04:16:58 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7e056f78-entity-operator rolling update finished
2022-04-05 04:16:58 [main] [32mINFO [m [SecurityST:520] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-04-05 04:16:58 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7e056f78-kafka-exporter rolling update
2022-04-05 04:18:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7e056f78-kafka-exporter will be ready
2022-04-05 04:18:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7e056f78-kafka-exporter is ready
2022-04-05 04:18:13 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7e056f78-kafka-exporter rolling update finished
2022-04-05 04:18:13 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7e056f78-cruise-control rolling update
2022-04-05 04:18:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7e056f78-cruise-control will be ready
2022-04-05 04:18:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7e056f78-cruise-control is ready
2022-04-05 04:18:23 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7e056f78-cruise-control rolling update finished
2022-04-05 04:18:23 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-05 04:18:23 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-7e056f78-kafka-clients-6dbf4bf86f-bqvzw
2022-04-05 04:18:23 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6212f34f, messages=[], arguments=[--topic, my-topic-1119526086-666142429, --max-messages, 100, --group-instance-id, instance357511553, --group-id, my-consumer-group-1507468911, --bootstrap-server, my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7e056f78-kafka-clients-6dbf4bf86f-bqvzw', podNamespace='namespace-142', bootstrapServer='my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092', topicName='my-topic-1119526086-666142429', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1507468911', consumerInstanceId='instance357511553', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3e196476}
2022-04-05 04:18:23 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092#my-topic-1119526086-666142429 from pod my-cluster-7e056f78-kafka-clients-6dbf4bf86f-bqvzw
2022-04-05 04:18:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7e056f78-kafka-clients-6dbf4bf86f-bqvzw -n namespace-142 -- /opt/kafka/consumer.sh --topic my-topic-1119526086-666142429 --max-messages 100 --group-instance-id instance357511553 --group-id my-consumer-group-1507468911 --bootstrap-server my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092
2022-04-05 04:18:29 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 04:18:29 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 04:18:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-785223224-1295607522 in namespace namespace-142
2022-04-05 04:18:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-05 04:18:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-785223224-1295607522 will have desired state: Ready
2022-04-05 04:18:30 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-785223224-1295607522 is in desired state: Ready
2022-04-05 04:18:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7e056f78-kafka-clients-tls in namespace namespace-142
2022-04-05 04:18:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-142
2022-04-05 04:18:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7e056f78-kafka-clients-tls will be ready
2022-04-05 04:18:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7e056f78-kafka-clients-tls is ready
2022-04-05 04:18:32 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-7e056f78-kafka-clients-tls-655f95f76b-dvqgw
2022-04-05 04:18:32 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@9c67b92, messages=[], arguments=[--topic, my-topic-1119526086-666142429, --max-messages, 100, --group-instance-id, instance1206585269, --group-id, my-consumer-group-2035771500, --bootstrap-server, my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7e056f78-kafka-clients-tls-655f95f76b-dvqgw', podNamespace='namespace-142', bootstrapServer='my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092', topicName='my-topic-1119526086-666142429', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2035771500', consumerInstanceId='instance1206585269', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7c098ab1}
2022-04-05 04:18:32 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092#my-topic-1119526086-666142429 from pod my-cluster-7e056f78-kafka-clients-tls-655f95f76b-dvqgw
2022-04-05 04:18:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7e056f78-kafka-clients-tls-655f95f76b-dvqgw -n namespace-142 -- /opt/kafka/consumer.sh --topic my-topic-1119526086-666142429 --max-messages 100 --group-instance-id instance1206585269 --group-id my-consumer-group-2035771500 --bootstrap-server my-cluster-7e056f78-kafka-bootstrap.namespace-142.svc:9092
2022-04-05 04:18:38 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 04:18:38 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 04:18:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 04:18:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-05 04:18:38 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7e056f78-kafka-clients in namespace namespace-142
2022-04-05 04:18:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1686692053-113944379 in namespace namespace-142
2022-04-05 04:18:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7e056f78-kafka-clients-tls in namespace namespace-142
2022-04-05 04:18:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7e056f78 in namespace namespace-142
2022-04-05 04:18:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-142, for cruise control Kafka cluster my-cluster-7e056f78
2022-04-05 04:18:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1119526086-666142429 in namespace namespace-142
2022-04-05 04:18:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-785223224-1295607522 in namespace namespace-142
2022-04-05 04:19:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 04:19:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-142 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-05 04:19:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-FINISHED
2022-04-05 04:19:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 04:19:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 04:19:34 [main] [32mINFO [m [ResourceManager:346] In context SecurityST is everything deleted.
2022-04-05 04:19:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,277.622 s - in io.strimzi.systemtest.security.SecurityST
[[1;34mINFO[m] Running io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
2022-04-05 04:19:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 04:20:05 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 04:20:05 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 04:20:05 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 04:20:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 04:20:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 04:20:05 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:05 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 04:20:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 04:20:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:20:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:20:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 04:20:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 04:20:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:20:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:15 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:20:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 04:20:15 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 04:20:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 04:20:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 04:20:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 04:20:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:20:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 04:20:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:20:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 04:20:51 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@33a0f5e6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 04:20:51 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 04:20:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 04:20:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:20:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 04:20:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:20:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 04:20:51 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 04:20:51 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 04:20:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:20:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 04:21:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 04:21:18 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 04:21:28 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 04:21:28 [main] [33mWARN [m [ConnectBuilderIsolatedST:546] For running these tests on K8s you have to have internal registry deployed using `minikube start --insecure-registry '10.0.0.0/24'` and `minikube addons enable registry`
2022-04-05 04:21:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka infra-namespace in namespace infra-namespace
2022-04-05 04:21:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: infra-namespace will have desired state: Ready
2022-04-05 04:22:45 [main] [32mINFO [m [ResourceManager:444] Kafka: infra-namespace is in desired state: Ready
2022-04-05 04:22:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 04:22:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts-STARTED
2022-04-05 04:22:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 04:22:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1388988544-2064411858 in namespace infra-namespace
2022-04-05 04:22:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-b3da60e3 in namespace infra-namespace
2022-04-05 04:22:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1388988544-2064411858 will have desired state: Ready
2022-04-05 04:22:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1388988544-2064411858 is in desired state: Ready
2022-04-05 04:22:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-b3da60e3 will have desired state: Ready
2022-04-05 04:24:58 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-b3da60e3 is in desired state: Ready
2022-04-05 04:24:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-b3da60e3-camel-connector in namespace infra-namespace
2022-04-05 04:24:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-b3da60e3-camel-connector will have desired state: Ready
2022-04-05 04:24:59 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-b3da60e3-camel-connector is in desired state: Ready
2022-04-05 04:24:59 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 04:24:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-b3da60e3-hello-world-consumer in namespace infra-namespace
2022-04-05 04:24:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-b3da60e3-hello-world-consumer will be in active state
2022-04-05 04:25:00 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-b3da60e3-hello-world-consumer to finished
2022-04-05 04:25:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 04:25:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildPluginUsingMavenCoordinatesArtifacts
2022-04-05 04:25:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-b3da60e3-camel-connector in namespace infra-namespace
2022-04-05 04:25:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-b3da60e3 in namespace infra-namespace
2022-04-05 04:25:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-b3da60e3-hello-world-consumer in namespace infra-namespace
2022-04-05 04:25:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1388988544-2064411858 in namespace infra-namespace
2022-04-05 04:26:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 04:26:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts-FINISHED
2022-04-05 04:26:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 04:26:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 04:26:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for ConnectBuilderIsolatedST
2022-04-05 04:26:17 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka infra-namespace in namespace infra-namespace
2022-04-05 04:26:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 406.838 s - in io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-05 04:26:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 04:26:52 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 04:26:52 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 04:26:52 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 04:26:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 04:26:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 04:26:52 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 04:26:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 04:26:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 04:26:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:26:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 04:26:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 04:26:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:26:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 04:26:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:26:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:02 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:27:02 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 04:27:02 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 04:27:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 04:27:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:27:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 04:27:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:27:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 04:27:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:27:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 04:27:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:12 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 04:27:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 04:27:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-STARTED
2022-04-05 04:27:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 04:27:27 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating first-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-05 04:27:27 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@307794e7, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@77330f11, clusterOperatorName='first-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=first-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=first-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-05 04:27:27 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 04:27:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-co-cluster-test
2022-04-05 04:27:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-05 04:27:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:27:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:27:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 04:27:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 04:27:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 04:27:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 04:27:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:27:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-05 04:27:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 04:27:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 04:27:28 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 04:27:28 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:27:28 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-05 04:27:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:27:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: first-strimzi-cluster-operator will be ready
2022-04-05 04:27:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: first-strimzi-cluster-operator is ready
2022-04-05 04:27:57 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment first-strimzi-cluster-operator to be ready
2022-04-05 04:28:07 [main] [32mINFO [m [DeploymentUtils:197] Deployment first-strimzi-cluster-operator is ready
2022-04-05 04:28:07 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating second-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-05 04:28:07 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@307794e7, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@77330f11, clusterOperatorName='second-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=second-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=second-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-05 04:28:07 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 04:28:07 [main] [32mINFO [m [SetupClusterOperator:254] Environment for ClusterOperator was already prepared! Going to install it now.
2022-04-05 04:28:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:28:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:28:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 04:28:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 04:28:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 04:28:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 04:28:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:28:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-05 04:28:08 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 04:28:08 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 04:28:08 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 04:28:08 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:28:08 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-05 04:28:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:28:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-strimzi-cluster-operator will be ready
2022-04-05 04:28:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-strimzi-cluster-operator is ready
2022-04-05 04:28:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment second-strimzi-cluster-operator to be ready
2022-04-05 04:28:39 [main] [32mINFO [m [DeploymentUtils:197] Deployment second-strimzi-cluster-operator is ready
2022-04-05 04:28:39 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:171] Deploying Kafka with {app.kubernetes.io/operator=first-strimzi-cluster-operator} selector of first-strimzi-cluster-operator
2022-04-05 04:28:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-da1599a9 in namespace multiple-co-cluster-test
2022-04-05 04:28:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-da1599a9 will have desired state: Ready
2022-04-05 04:30:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-da1599a9 is in desired state: Ready
2022-04-05 04:30:21 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:180] Removing CR selector from Kafka and increasing number of replicas to 4, new pod should not appear
2022-04-05 04:30:21 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:188] Creating KafkaRebalance when CC doesn't have label for CO, the KR should be ignored
2022-04-05 04:30:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-da1599a9 in namespace multiple-co-cluster-test
2022-04-05 04:30:21 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-05 04:31:23 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-05 04:31:23 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:204] Checking if KafkaRebalance is still ignored, after the cluster stability wait
2022-04-05 04:31:23 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:209] Adding {app.kubernetes.io/operator=second-strimzi-cluster-operator} selector of second-strimzi-cluster-operator to Kafka
2022-04-05 04:31:23 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:212] Waiting for Kafka to scales pods to 4
2022-04-05 04:31:23 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-da1599a9-kafka to be ready
2022-04-05 04:34:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-da1599a9 will have desired state: Ready
2022-04-05 04:34:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-da1599a9 is in desired state: Ready
2022-04-05 04:34:52 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-da1599a9 is ready
2022-04-05 04:34:52 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-da1599a9): ============================================================================
2022-04-05 04:34:52 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-da1599a9): PendingProposal
2022-04-05 04:34:52 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-da1599a9): ============================================================================
2022-04-05 04:34:52 [main] [32mINFO [m [KafkaRebalanceUtils:81] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-da1599a9): Verifying that KafkaRebalance resource is in PendingProposal state
2022-04-05 04:34:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-da1599a9 will have desired state: PendingProposal
2022-04-05 04:34:52 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-da1599a9 is in desired state: PendingProposal
2022-04-05 04:34:52 [main] [32mINFO [m [KafkaRebalanceUtils:85] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-da1599a9): Verifying that KafkaRebalance resource is in ProposalReady state
2022-04-05 04:34:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-da1599a9 will have desired state: ProposalReady
2022-04-05 04:35:15 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-da1599a9 is in desired state: ProposalReady
2022-04-05 04:35:15 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-da1599a9): ============================================================================
2022-04-05 04:35:15 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-da1599a9): ProposalReady
2022-04-05 04:35:15 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-da1599a9): ============================================================================
2022-04-05 04:35:15 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-da1599a9): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-05 04:35:15 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-da1599a9): Annotating KafkaRebalance:my-cluster-da1599a9 with annotation approve
2022-04-05 04:35:16 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-da1599a9): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-da1599a9 annotated
2022-04-05 04:35:16 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-da1599a9): Verifying that annotation triggers the Rebalancing state
2022-04-05 04:35:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-da1599a9 will have desired state: Rebalancing
2022-04-05 04:35:17 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-da1599a9 is in desired state: Rebalancing
2022-04-05 04:35:17 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #9(test) KafkaRebalance(second-co-namespace/my-cluster-da1599a9): Verifying that KafkaRebalance is in the Ready state
2022-04-05 04:35:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-da1599a9 will have desired state: Ready
2022-04-05 04:35:22 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-da1599a9 is in desired state: Ready
2022-04-05 04:35:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 04:35:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaCCAndRebalanceWithMultipleCOs
2022-04-05 04:35:22 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 04:35:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:35:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-05 04:35:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:35:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:35:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 04:35:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:32 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 04:35:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 04:35:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-da1599a9 in namespace multiple-co-cluster-test
2022-04-05 04:35:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace multiple-co-cluster-test, for cruise control Kafka cluster my-cluster-da1599a9
io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: GET at: https://192.168.49.2:8443/apis/kafka.strimzi.io/v1beta2/namespaces/multiple-co-cluster-test/kafkatopics. Message: Not Found.
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:683)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:662)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:613)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:556)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:519)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:503)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.listRequestHelper(BaseOperation.java:133)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:415)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:404)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:83)
	at io.strimzi.systemtest.resources.crd.KafkaResource.delete(KafkaResource.java:65)
	at io.strimzi.systemtest.resources.crd.KafkaResource.delete(KafkaResource.java:32)
	at io.strimzi.systemtest.resources.ResourceManager.deleteResource(ResourceManager.java:244)
	at io.strimzi.systemtest.resources.ResourceManager.lambda$createResource$1(ResourceManager.java:217)
	at io.strimzi.systemtest.resources.ResourceManager.lambda$deleteResources$3(ResourceManager.java:360)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.Vector$VectorSpliterator.forEachRemaining(Vector.java:1492)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:290)
	at java.base/java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:746)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
2022-04-05 04:35:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-da1599a9 in namespace multiple-co-cluster-test
2022-04-05 04:35:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:35:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 04:35:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 04:35:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:42 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:42 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:42 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 04:35:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:35:52 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 04:35:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-05 04:35:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 04:35:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-FINISHED
2022-04-05 04:35:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 04:35:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 04:35:52 [main] [32mINFO [m [ResourceManager:346] In context MultipleClusterOperatorsIsolatedST is everything deleted.
2022-04-05 04:35:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 565.696 s - in io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-05 04:35:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 04:36:17 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 04:36:17 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 04:36:17 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 04:36:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 04:36:17 [main] [32mINFO [m [ResourceManager:346] In context JUnit Jupiter is everything deleted.
2022-04-05 04:36:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 04:36:23 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@33a0f5e6
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 04:36:23 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 04:36:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 04:36:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 04:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 04:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 04:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 04:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 04:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 04:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 04:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 04:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 04:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 04:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 04:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 04:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 04:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:36:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 04:36:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 04:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 04:36:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 04:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 04:36:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 04:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 04:36:24 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 04:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:36:24 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 04:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 04:36:24 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 04:36:24 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 04:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 04:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:36:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 04:36:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 04:36:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 04:36:58 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 04:36:58 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-05 04:36:58 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-05 04:36:58 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-05 04:38:28 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-05 04:38:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 04:38:28 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-05 04:38:28 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-05 04:38:28 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-05 04:38:28 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-05 04:38:28 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-05 04:38:28 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-05 04:38:28 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-05 04:38:28 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-05 04:38:28 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-05 04:38:28 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-05 04:38:28 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-05 04:38:28 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-05 04:38:28 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-05 04:38:28 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-05 04:38:28 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-05 04:38:28 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-05 04:38:28 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-05 04:38:28 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-05 04:38:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-05 04:38:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-plain-name will have desired state: Ready
2022-04-05 04:39:50 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-plain-name is in desired state: Ready
2022-04-05 04:39:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 04:39:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-STARTED
2022-04-05 04:39:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 04:39:50 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 04:39:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1872206298-1045848242 in namespace infra-namespace
2022-04-05 04:39:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1872206298-1045848242 will have desired state: Ready
2022-04-05 04:39:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1872206298-1045848242 is in desired state: Ready
2022-04-05 04:39:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-22a14cea in namespace infra-namespace
2022-04-05 04:39:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-22a14cea will be in active state
2022-04-05 04:39:52 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-22a14cea to finished
2022-04-05 04:40:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-22a14cea in namespace infra-namespace
2022-04-05 04:40:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-22a14cea will be in active state
2022-04-05 04:40:01 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-22a14cea to finished
2022-04-05 04:40:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-22a14cea-kafka-clients in namespace infra-namespace
2022-04-05 04:40:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-22a14cea-kafka-clients will be ready
2022-04-05 04:40:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-22a14cea-kafka-clients is ready
2022-04-05 04:40:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-22a14cea-scraper in namespace infra-namespace
2022-04-05 04:40:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-22a14cea-scraper will be ready
2022-04-05 04:40:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-22a14cea-scraper is ready
2022-04-05 04:40:12 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-22a14cea-scraper to be ready
2022-04-05 04:40:22 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-22a14cea-scraper is ready
2022-04-05 04:40:22 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-22a14cea-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 04:40:22 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-22a14cea-allow in namespace infra-namespace
2022-04-05 04:40:22 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 04:40:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-22a14cea in namespace infra-namespace
2022-04-05 04:40:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-22a14cea will have desired state: Ready
2022-04-05 04:41:32 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-22a14cea is in desired state: Ready
2022-04-05 04:41:32 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-05 04:41:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-22a14cea-connect-86ddcd7cbd-67tb7 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-05 04:41:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 04:41:32 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-05 04:41:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-22a14cea-connect-86ddcd7cbd-67tb7 -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-1872206298-1045848242", "file": "/tmp/test-file-sink.txt" } }' http://localhost:8083/connectors
2022-04-05 04:41:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 04:41:33 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-22a14cea-connect-86ddcd7cbd-67tb7
2022-04-05 04:41:37 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-22a14cea-connect-86ddcd7cbd-67tb7
2022-04-05 04:41:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 04:41:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-05 04:41:37 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-22a14cea-scraper in namespace infra-namespace
2022-04-05 04:41:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-22a14cea in namespace infra-namespace
2022-04-05 04:41:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-22a14cea in namespace infra-namespace
2022-04-05 04:41:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-22a14cea-kafka-clients in namespace infra-namespace
2022-04-05 04:41:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-22a14cea in namespace infra-namespace
2022-04-05 04:41:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1872206298-1045848242 in namespace infra-namespace
2022-04-05 04:41:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-22a14cea-allow in namespace infra-namespace
2022-04-05 04:42:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 04:42:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-05 04:42:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 04:42:17 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-05 04:42:22 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-05 04:42:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 04:42:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 04:42:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthPlainIsolatedST
2022-04-05 04:42:22 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-05 04:42:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-05 04:42:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 04:42:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 04:42:32 [main] [32mINFO [m [ResourceManager:346] In context OauthPlainIsolatedST is everything deleted.
2022-04-05 04:42:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 399.204 s - in io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-05 04:42:32 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-05 04:42:32 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-05 04:42:32 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-05 04:42:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 04:42:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-05 04:42:32 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 04:42:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 04:42:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:42:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 04:42:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 04:42:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 04:42:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:42:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 04:42:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:42:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 04:42:42 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:42:42 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 04:42:42 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 04:42:42 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 04:42:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 04:42:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 04:42:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 04:42:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 04:42:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 04:42:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:42:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 04:42:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 04:42:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 04:42:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 04:42:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 04:43:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 04:43:07 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-04-05 04:43:07 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-04-05 04:43:07 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-04-05 04:43:07 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-04-05 04:43:07 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;33mWARNING[m] Flakes: 
[[1;33mWARNING[m] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts(ExtensionContext)
[[1;31mERROR[m]   Run 1: ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts:482 ? Wait
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs(ExtensionContext)
[[1;31mERROR[m]   Run 1: MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs:217 ? Wait
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates(ExtensionContext)
[[1;31mERROR[m]   Run 1: RollingUpdateST.testClusterOperatorFinishAllRollingUpdates:625 ? Wait Timeout ...
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno(ExtensionContext)
[[1;31mERROR[m]   Run 1: SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno:373->autoReplaceSomeKeysTriggeredByAnno:521 ? Wait
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;33mWARNING[m] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(ExtensionContext)
[[1;31mERROR[m]   Run 1: OauthPlainIsolatedST.testProducerConsumerConnect:287 ? Wait Timeout after 6000...
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;33mWARNING[m] Tests run: 304, Failures: 0, Errors: 0, Skipped: 10, Flakes: 5
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Summary for Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift . [1;32mSUCCESS[m [  2.616 s]
[[1;34mINFO[m] test ............................................... [1;32mSUCCESS[m [  0.952 s]
[[1;34mINFO[m] crd-annotations .................................... [1;32mSUCCESS[m [  1.181 s]
[[1;34mINFO[m] crd-generator ...................................... [1;32mSUCCESS[m [  2.579 s]
[[1;34mINFO[m] api ................................................ [1;32mSUCCESS[m [  7.413 s]
[[1;34mINFO[m] mockkube ........................................... [1;32mSUCCESS[m [  1.115 s]
[[1;34mINFO[m] config-model ....................................... [1;32mSUCCESS[m [  0.810 s]
[[1;34mINFO[m] certificate-manager ................................ [1;32mSUCCESS[m [  0.775 s]
[[1;34mINFO[m] operator-common .................................... [1;32mSUCCESS[m [  2.100 s]
[[1;34mINFO[m] systemtest ......................................... [1;32mSUCCESS[m [  21:48 h]
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1;32mBUILD SUCCESS[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] Total time:  21:48 h
[[1;34mINFO[m] Finished at: 2022-04-05T04:43:08Z
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
