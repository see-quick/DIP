[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Build Order:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift                 [pom]
[[1;34mINFO[m] test                                                               [jar]
[[1;34mINFO[m] crd-annotations                                                    [jar]
[[1;34mINFO[m] crd-generator                                                      [jar]
[[1;34mINFO[m] api                                                                [jar]
[[1;34mINFO[m] mockkube                                                           [jar]
[[1;34mINFO[m] config-model                                                       [jar]
[[1;34mINFO[m] certificate-manager                                                [jar]
[[1;34mINFO[m] operator-common                                                    [jar]
[[1;34mINFO[m] systemtest                                                         [jar]
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------------< [0;36mio.strimzi:strimzi[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT [1/10][m
[[1;34mINFO[m] [1m--------------------------------[ pom ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mstrimzi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mstrimzi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mstrimzi[0;1m ---[m
[[1;34mINFO[m] Skipping pom project
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--------------------------< [0;36mio.strimzi:test[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding test 0.29.0-SNAPSHOT                                     [2/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/test/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/test/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No sources to compile
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/test/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/test/target/test-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No tests to run.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mtest[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:crd-annotations[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding crd-annotations 0.29.0-SNAPSHOT                          [3/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-annotations/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-annotations/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-annotations/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-annotations[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/crd-annotations/target/crd-annotations-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-annotations[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:crd-generator[0;1m >----------------------[m
[[1;34mINFO[m] [1mBuilding crd-generator 0.29.0-SNAPSHOT                            [4/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/crd-generator/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 7 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/crd-generator/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcrd-generator[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-shade-plugin:3.1.0:shade[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] Including io.strimzi:crd-annotations:jar:0.29.0-SNAPSHOT in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-core:jar:2.12.6 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-databind:jar:2.12.6.1 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.12.6 in the shaded jar.
[[1;34mINFO[m] Including org.yaml:snakeyaml:jar:1.27 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-client:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-rbac:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-admissionregistration:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apps:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-autoscaling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-apiextensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-batch:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-certificates:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-coordination:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-discovery:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-events:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-extensions:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-flowcontrol:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-networking:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-metrics:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-policy:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-scheduling:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-storageclass:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-node:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:okhttp:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okio:okio:jar:1.15.0 in the shaded jar.
[[1;34mINFO[m] Including com.squareup.okhttp3:logging-interceptor:jar:3.12.12 in the shaded jar.
[[1;34mINFO[m] Including org.slf4j:slf4j-api:jar:1.7.36 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.datatype:jackson-datatype-jsr310:jar:2.13.1 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:zjsonpatch:jar:0.3.0 in the shaded jar.
[[1;34mINFO[m] Including com.github.mifmif:generex:jar:1.0.2 in the shaded jar.
[[1;34mINFO[m] Including dk.brics.automaton:automaton:jar:1.11-8 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-core:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including io.fabric8:kubernetes-model-common:jar:5.12.0 in the shaded jar.
[[1;34mINFO[m] Including com.fasterxml.jackson.core:jackson-annotations:jar:2.12.6 in the shaded jar.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] Discovered module-info.class. Shading will break its strong encapsulation.
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, generex-1.0.2.jar define 7 overlapping classes: 
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator
[[1;33mWARNING[m]   - com.mifmif.common.regex.Generex
[[1;33mWARNING[m]   - com.mifmif.common.regex.GenerexIterator$Step
[[1;33mWARNING[m]   - com.mifmif.common.regex.Node
[[1;33mWARNING[m]   - com.mifmif.common.regex.Main
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterable
[[1;33mWARNING[m]   - com.mifmif.common.regex.util.Iterator
[[1;33mWARNING[m] kubernetes-model-rbac-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 80 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.RoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.AggregationRuleFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.SubjectFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.ClusterRoleListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.rbac.PolicyRuleFluent
[[1;33mWARNING[m]   - 70 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-annotations-2.12.6.jar define 71 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonAutoDetect
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonInclude
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.ObjectIdGenerators
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Features
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonIgnore
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSetter
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonTypeInfo$None
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonFormat$Shape
[[1;33mWARNING[m]   - com.fasterxml.jackson.annotation.JsonSubTypes
[[1;33mWARNING[m]   - 61 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-extensions-5.12.0.jar define 264 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetConditionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DeploymentStrategyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicySpecFluent$IngressNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.IngressSpecFluent$RulesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.DaemonSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.extensions.NetworkPolicyPeerBuilder
[[1;33mWARNING[m]   - 254 more...
[[1;33mWARNING[m] kubernetes-model-autoscaling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricSpecFluentImpl$ObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.CrossVersionObjectReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.ContainerResourceMetricStatusFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.MetricStatusFluent$ObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta2.HorizontalPodAutoscalerSpecFluent$ScaleTargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.autoscaling.v2beta1.HorizontalPodAutoscalerFluent$SpecNested
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] kubernetes-model-storageclass-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 172 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIStorageCapacityListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.CSINodeDriverFluentImpl$AllocatableNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.StorageClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSourceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.TokenRequestFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSINodeDriverFluent$AllocatableNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.v1beta1.CSIDriverSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.storage.VolumeAttachmentSpecFluent
[[1;33mWARNING[m]   - 162 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-batch-5.12.0.jar define 112 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobStatusFluentImpl$ActiveNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluent$TemplateNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.JobSpecFluentImpl$TemplateNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.Job
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1beta1.CronJobListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.batch.v1.CronJobListFluent
[[1;33mWARNING[m]   - 102 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-apiextensions-5.12.0.jar define 350 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrBoolBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionSpecFluent$ValidationNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersionFluentImpl$SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrStringArraySerDe$Deserializer$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceValidationFluentImpl$OpenAPIV3SchemaNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsFluentImpl$NotNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.WebhookClientConfigFluentImpl$ServiceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1beta1.JSONSchemaPropsOrArrayFluent$SchemaNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apiextensions.v1.JSONSchemaPropsOrBoolSerDe
[[1;33mWARNING[m]   - 340 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-discovery-5.12.0.jar define 88 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.ForZoneBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointFluent$TargetRefNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointFluentImpl$ConditionsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointConditionsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.discovery.v1beta1.EndpointSliceListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 78 more...
[[1;33mWARNING[m] okhttp-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 208 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.WebSocket
[[1;33mWARNING[m]   - okhttp3.Cookie$Builder
[[1;33mWARNING[m]   - okhttp3.internal.http.HttpHeaders
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$ReaderRunnable
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Reader$ContinuationSource
[[1;33mWARNING[m]   - okhttp3.internal.tls.OkHostnameVerifier
[[1;33mWARNING[m]   - okhttp3.Cache$Entry
[[1;33mWARNING[m]   - okhttp3.internal.http2.Http2Connection$3
[[1;33mWARNING[m]   - okhttp3.internal.ws.RealWebSocket$Streams
[[1;33mWARNING[m]   - okhttp3.CacheControl$Builder
[[1;33mWARNING[m]   - 198 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-metrics-5.12.0.jar define 30 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.ContainerMetricsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetrics
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.NodeMetricsFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsFluentImpl$ContainersNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.metrics.v1beta1.PodMetricsListBuilder
[[1;33mWARNING[m]   - 20 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-flowcontrol-5.12.0.jar define 132 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowSchemaConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.FlowDistinguisherMethodBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReferenceBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.QueuingConfigurationFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfiguration
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationReference
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PolicyRulesWithSubjects
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.flowcontrol.v1beta1.PriorityLevelConfigurationListFluent$ItemsNested
[[1;33mWARNING[m]   - 122 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-events-5.12.0.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$SeriesNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent$RegardingNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1.EventSeriesFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.events.v1beta1.EventListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] automaton-1.11-8.jar, crd-generator-0.29.0-SNAPSHOT.jar define 25 overlapping classes: 
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonMatcher
[[1;33mWARNING[m]   - dk.brics.automaton.ShuffleOperations$ShuffleConfiguration
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$Kind
[[1;33mWARNING[m]   - dk.brics.automaton.RunAutomaton
[[1;33mWARNING[m]   - dk.brics.automaton.Automaton
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp
[[1;33mWARNING[m]   - dk.brics.automaton.AutomatonProvider
[[1;33mWARNING[m]   - dk.brics.automaton.RegExp$1
[[1;33mWARNING[m]   - dk.brics.automaton.MinimizationOperations$StateListNode
[[1;33mWARNING[m]   - dk.brics.automaton.State
[[1;33mWARNING[m]   - 15 more...
[[1;33mWARNING[m] jackson-core-2.12.6.jar, crd-generator-0.29.0-SNAPSHOT.jar define 124 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.JsonGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.json.JsonReadFeature
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.ThreadLocalBufferManager$ThreadLocalBufferManagerHolder
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.Separators
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.io.SegmentedStringWriter
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.TreeNode
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.sym.Name
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.RequestPayload
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.util.JsonGeneratorDelegate
[[1;33mWARNING[m]   - com.fasterxml.jackson.core.async.NonBlockingInputFeeder
[[1;33mWARNING[m]   - 114 more...
[[1;33mWARNING[m] kubernetes-model-networking-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 234 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressServiceBackend
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPort
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1beta1.IngressClassSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressStatus
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressClassFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.networking.v1.IngressRuleFluentImpl$HttpNestedImpl
[[1;33mWARNING[m]   - 224 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-coordination-5.12.0.jar define 18 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$SpecNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.coordination.v1.LeaseListFluent
[[1;33mWARNING[m]   - 8 more...
[[1;33mWARNING[m] zjsonpatch-0.3.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.InsertCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Operation
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.CommandVisitor
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.guava.Strings
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.EditCommand
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonDiff$EncodePathFunction
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.sequence.SequencesComparator
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.Diff
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.internal.collections4.ListUtils
[[1;33mWARNING[m]   - io.fabric8.zjsonpatch.JsonPatch
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-common-5.12.0.jar define 16 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Plural
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Group
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer$CancelUnwrapped
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.JsonUnwrappedDeserializer
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.PrinterColumn
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.jackson.UnwrappedTypeResolverBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Singular
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.StatusReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.SpecReplicas
[[1;33mWARNING[m]   - io.fabric8.kubernetes.model.annotation.Version
[[1;33mWARNING[m]   - 6 more...
[[1;33mWARNING[m] kubernetes-model-admissionregistration-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 362 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluent$ObjectSelectorNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1.SubjectAccessReviewSpecFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SubjectRulesReviewStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.ValidatingWebhookConfigurationBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authentication.TokenReviewFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectRulesReviewSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookFluentImpl$NamespaceSelectorNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1beta1.MutatingWebhookConfigurationFluentImpl$WebhooksNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.authorization.v1beta1.SelfSubjectAccessReviewFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.admissionregistration.v1.MutatingWebhookFluent$ClientConfigNested
[[1;33mWARNING[m]   - 352 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, okio-1.15.0.jar define 44 overlapping classes: 
[[1;33mWARNING[m]   - okio.ByteString
[[1;33mWARNING[m]   - okio.Source
[[1;33mWARNING[m]   - okio.ForwardingSink
[[1;33mWARNING[m]   - okio.BufferedSource
[[1;33mWARNING[m]   - okio.Util
[[1;33mWARNING[m]   - okio.AsyncTimeout$1
[[1;33mWARNING[m]   - okio.HashingSource
[[1;33mWARNING[m]   - okio.GzipSink
[[1;33mWARNING[m]   - okio.Okio$1
[[1;33mWARNING[m]   - okio.Pipe$PipeSink
[[1;33mWARNING[m]   - 34 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-certificates-5.12.0.jar define 60 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluent$SpecNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl$StatusNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestFluent$MetadataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestConditionFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestStatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1beta1.CertificateSigningRequestStatusFluent$ConditionsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.certificates.v1.CertificateSigningRequestFluentImpl
[[1;33mWARNING[m]   - 50 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, jackson-datatype-jsr310-2.13.1.jar define 59 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.Jsr310KeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.PackageVersion
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.YearDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.key.Jsr310NullKeySerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.deser.key.LocalDateTimeKeyDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.util.DurationUnitConverter
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.InstantSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.datatype.jsr310.ser.OffsetDateTimeSerializer
[[1;33mWARNING[m]   - 49 more...
[[1;33mWARNING[m] crd-annotations-0.29.0-SNAPSHOT.jar, crd-generator-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$Stability
[[1;33mWARNING[m]   - io.strimzi.api.annotations.ApiVersion$1
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedType
[[1;33mWARNING[m]   - io.strimzi.api.annotations.DeprecatedProperty
[[1;33mWARNING[m]   - io.strimzi.api.annotations.VersionRange$VersionParser
[[1;33mWARNING[m]   - io.strimzi.api.annotations.KubeVersion
[[1;33mWARNING[m] kubernetes-model-apps-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 212 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpec
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetConditionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentStrategyFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluent$DeploymentDataNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetSpecFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.DeploymentFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetStatusFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ControllerRevisionFluentImpl$PersistentVolumeClaimDataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.ReplicaSetCondition
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.apps.StatefulSetSpecFluent$UpdateStrategyNested
[[1;33mWARNING[m]   - 202 more...
[[1;33mWARNING[m] logging-interceptor-3.12.12.jar, crd-generator-0.29.0-SNAPSHOT.jar define 8 overlapping classes: 
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger$1
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$Factory
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Level
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor
[[1;33mWARNING[m]   - okhttp3.logging.package-info
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener
[[1;33mWARNING[m]   - okhttp3.logging.LoggingEventListener$1
[[1;33mWARNING[m]   - okhttp3.logging.HttpLoggingInterceptor$Logger
[[1;33mWARNING[m] jackson-dataformat-yaml-2.12.6.jar, crd-generator-0.29.0-SNAPSHOT.jar define 17 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLMapper$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.snakeyaml.error.Mark
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.UTF8Reader
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.util.StringQuotingChecker
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLGenerator$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.JacksonYAMLParseException
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.YAMLParser$Feature
[[1;33mWARNING[m]   - com.fasterxml.jackson.dataformat.yaml.util.StringQuotingChecker$Default
[[1;33mWARNING[m]   - 7 more...
[[1;33mWARNING[m] kubernetes-model-core-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 2394 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.BaseKubernetesListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.StatusBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.KubeSchemaFluentImpl$APIResourceNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.NodeListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ResourceQuotaListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluentImpl$APIServiceStatusObjectNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.WatchEventFluent$VsphereVirtualDiskVolumeSourceObjectNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ProbeFluentImpl$HttpGetNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.PatchOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.ServerAddressByClientCIDRFluentImpl
[[1;33mWARNING[m]   - 2384 more...
[[1;33mWARNING[m] slf4j-api-1.7.36.jar, crd-generator-0.29.0-SNAPSHOT.jar define 34 overlapping classes: 
[[1;33mWARNING[m]   - org.slf4j.helpers.SubstituteLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.NamedLoggerBase
[[1;33mWARNING[m]   - org.slf4j.helpers.NOPMDCAdapter
[[1;33mWARNING[m]   - org.slf4j.MarkerFactory
[[1;33mWARNING[m]   - org.slf4j.helpers.BasicMarker
[[1;33mWARNING[m]   - org.slf4j.spi.LoggerFactoryBinder
[[1;33mWARNING[m]   - org.slf4j.MDC$MDCCloseable
[[1;33mWARNING[m]   - org.slf4j.spi.LocationAwareLogger
[[1;33mWARNING[m]   - org.slf4j.helpers.MessageFormatter
[[1;33mWARNING[m]   - org.slf4j.helpers.Util$ClassContextSecurityManager
[[1;33mWARNING[m]   - 24 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, kubernetes-model-node-5.12.0.jar define 78 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.OverheadBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.Scheduling
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1beta1.RuntimeClassListBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.SchedulingFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1alpha1.RuntimeClassSpecFluent$OverheadNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.node.v1.RuntimeClassFluentImpl
[[1;33mWARNING[m]   - 68 more...
[[1;33mWARNING[m] jackson-databind-2.12.6.1.jar, crd-generator-0.29.0-SNAPSHOT.jar define 700 overlapping classes: 
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$NoAnnotations
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.jsontype.BasicPolymorphicTypeValidator$Builder
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.BeanDescription
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.deser.impl.BeanAsArrayBuilderDeserializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotatedMethodMap
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.SerializerProvider
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.introspect.AnnotationCollector$OneAnnotation
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.StaticListSerializerBase
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.std.NumberSerializers$ShortSerializer
[[1;33mWARNING[m]   - com.fasterxml.jackson.databind.ser.BeanSerializerFactory
[[1;33mWARNING[m]   - 690 more...
[[1;33mWARNING[m] crd-generator-0.29.0-SNAPSHOT.jar, snakeyaml-1.27.jar define 216 overlapping classes: 
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockNode
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockMappingSimpleValue
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectDocumentEnd
[[1;33mWARNING[m]   - org.yaml.snakeyaml.Yaml$3
[[1;33mWARNING[m]   - org.yaml.snakeyaml.emitter.Emitter$ExpectBlockSequenceItem
[[1;33mWARNING[m]   - org.yaml.snakeyaml.parser.ParserImpl$ParseBlockSequenceEntry
[[1;33mWARNING[m]   - org.yaml.snakeyaml.util.ArrayUtils
[[1;33mWARNING[m]   - org.yaml.snakeyaml.tokens.Token$ID
[[1;33mWARNING[m]   - org.yaml.snakeyaml.reader.StreamReader
[[1;33mWARNING[m]   - 206 more...
[[1;33mWARNING[m] kubernetes-client-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 536 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.CertUtils
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.CustomResource
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.osgi.ManagedKubernetesClient
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.V1beta1ApiextensionAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.internal.PatchUtils$SingletonHolder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.VersionInfo$1
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.utils.ReplaceValueStream
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.CreateFromServerGettable
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.ApiextensionsAPIGroupDSL
[[1;33mWARNING[m]   - io.fabric8.kubernetes.client.dsl.Containerable
[[1;33mWARNING[m]   - 526 more...
[[1;33mWARNING[m] kubernetes-model-scheduling-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 24 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassFluentImpl$MetadataNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent$ItemsNested
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassListFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClass
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1.PriorityClassListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.scheduling.v1beta1.PriorityClassFluent$MetadataNested
[[1;33mWARNING[m]   - 14 more...
[[1;33mWARNING[m] kubernetes-model-policy-5.12.0.jar, crd-generator-0.29.0-SNAPSHOT.jar define 162 overlapping classes: 
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1.PodDisruptionBudgetList
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.HostPortRangeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.EvictionFluentImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$AllowedCSIDriversNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicyListFluentImpl$ItemsNestedImpl
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.AllowedFlexVolumeBuilder
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.IDRangeFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.SELinuxStrategyOptionsFluent
[[1;33mWARNING[m]   - io.fabric8.kubernetes.api.model.policy.v1beta1.PodSecurityPolicySpecFluentImpl$FsGroupNestedImpl
[[1;33mWARNING[m]   - 152 more...
[[1;33mWARNING[m] maven-shade-plugin has detected that some class files are
[[1;33mWARNING[m] present in two or more JARs. When this happens, only one
[[1;33mWARNING[m] single version of the class is copied to the uber jar.
[[1;33mWARNING[m] Usually this is not harmful and you can skip these warnings,
[[1;33mWARNING[m] otherwise try to manually exclude artifacts based on
[[1;33mWARNING[m] mvn dependency:tree -Ddetail=true and the above output.
[[1;33mWARNING[m] See http://maven.apache.org/plugins/maven-shade-plugin/
[[1;34mINFO[m] Replacing original artifact with shaded artifact.
[[1;34mINFO[m] Replacing /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT.jar with /home/ec2-user/strimzi-kafka-operator/crd-generator/target/crd-generator-0.29.0-SNAPSHOT-shaded.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcrd-generator[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------------< [0;36mio.strimzi:api[0;1m >---------------------------[m
[[1;34mINFO[m] [1mBuilding api 0.29.0-SNAPSHOT                                      [5/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/api/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1)[m @ [36mapi[0;1m ---[m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-crd-co-install-v1-eo)[m @ [36mapi[0;1m ---[m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:1.6.0:exec[m [1m(generate-doc)[m @ [36mapi[0;1m ---[m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 99 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-test-compile)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mapi[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/api/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mapi[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mapi[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m------------------------< [0;36mio.strimzi:mockkube[0;1m >-------------------------[m
[[1;34mINFO[m] [1mBuilding mockkube 0.29.0-SNAPSHOT                                 [6/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/mockkube/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mmockkube[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/mockkube/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mmockkube[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/mockkube/target/mockkube-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mmockkube[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m----------------------< [0;36mio.strimzi:config-model[0;1m >-----------------------[m
[[1;34mINFO[m] [1mBuilding config-model 0.29.0-SNAPSHOT                             [7/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/config-model/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/config-model/src/test/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mconfig-model[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/config-model/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mconfig-model[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/config-model/target/config-model-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mconfig-model[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------< [0;36mio.strimzi:certificate-manager[0;1m >-------------------[m
[[1;34mINFO[m] [1mBuilding certificate-manager 0.29.0-SNAPSHOT                      [8/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/certificate-manager/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36mcertificate-manager[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/certificate-manager/target/certificate-manager-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36mcertificate-manager[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mio.strimzi:operator-common[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding operator-common 0.29.0-SNAPSHOT                          [9/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] skip non existing resourceDirectory /home/ec2-user/strimzi-kafka-operator/operator-common/src/main/resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 9 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36moperator-common[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/operator-common/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36moperator-common[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/operator-common/target/operator-common-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:test-jar[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36moperator-common[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-----------------------< [0;36mio.strimzi:systemtest[0;1m >------------------------[m
[[1;34mINFO[m] [1mBuilding systemtest 0.29.0-SNAPSHOT                              [10/10][m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 3 resources
[[1;34mINFO[m] Copying 2 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Changes detected - recompiling the module!
[[1;34mINFO[m] Compiling 149 source files to /home/ec2-user/strimzi-kafka-operator/systemtest/target/classes
[2K  0% Generating: io.strimzi.systemtest.kafkaclients.internalClients.KafkaOauthClients[2K 17% Generating: io.strimzi.systemtest.kafkaclients.internalClients.BridgeClients[2K 33% Generating: io.strimzi.systemtest.kafkaclients.internalClients.BaseClients[2K 50% Generating: io.strimzi.systemtest.kafkaclients.internalClients.KafkaTracingClients[2K 67% Generating: io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients[2K 83% Generating: io.strimzi.systemtest.kafkaclients.internalClients.KafkaAdminClients[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/target/generated-sources/annotations/io/strimzi/systemtest/kafkaclients/internalClients/BaseClientsFluentImpl.java: Some input files use unchecked or unsafe operations.
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/target/generated-sources/annotations/io/strimzi/systemtest/kafkaclients/internalClients/BaseClientsFluentImpl.java: Recompile with -Xlint:unchecked for details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 32 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Changes detected - recompiling the module!
[[1;34mINFO[m] Compiling 68 source files to /home/ec2-user/strimzi-kafka-operator/systemtest/target/test-classes
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainIsolatedST.java: Some input files use or override a deprecated API.
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainIsolatedST.java: Recompile with -Xlint:deprecation for details.
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java: /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java uses unchecked or unsafe operations.
[[1;34mINFO[m] /home/ec2-user/strimzi-kafka-operator/systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java: Recompile with -Xlint:unchecked for details.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M5:test[m [1m(default-test)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] Tests run: 0, Failures: 0, Errors: 0, Skipped: 0
[[1;34mINFO[m] 
[[1;33mWARNING[m] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file /home/ec2-user/strimzi-kafka-operator/systemtest/target/surefire-reports/2022-04-05T15-33-33_959-jvmRun1.dumpstream
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-jar-plugin:3.1.0:jar[m [1m(default-jar)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/systemtest/target/systemtest-0.29.0-SNAPSHOT.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:report[m [1m(report)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping JaCoCo execution due to missing execution data file.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m > [0;1mgenerate-sources[m @ [36msystemtest[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-checkstyle-plugin:3.1.2:check[m [1m(validate)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Starting audit...
Audit done.
[[1;34mINFO[m] You have 0 Checkstyle violations.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-enforcer-plugin:3.0.0-M2:enforce[m [1m(enforce-banned-dependencies)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mjacoco-maven-plugin:0.7.9:prepare-agent[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] surefireArgLine set to -javaagent:/home/ec2-user/.m2/repository/org/jacoco/org.jacoco.agent/0.7.9/org.jacoco.agent-0.7.9-runtime.jar=destfile=/home/ec2-user/strimzi-kafka-operator/systemtest/target/jacoco.exec
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m<<< [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[0;1m < [0;1mgenerate-sources[m @ [36msystemtest[0;1m <<<[m
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-source-plugin:3.0.1:jar[m [1m(attach-sources)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Building jar: /home/ec2-user/strimzi-kafka-operator/systemtest/target/systemtest-0.29.0-SNAPSHOT-sources.jar
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-javadoc-plugin:3.1.0:jar[m [1m(attach-javadocs)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] Skipping javadoc generation
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:integration-test[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;33mWARNING[m] useSystemClassLoader setting has no effect when not forking
[[1;33mWARNING[m] The parameter forkCount should likely not be 0, not forking a JVM for tests reduce test accuracy, ensure to have a <forkCount> >= 1.
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.user.UserST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.topic.TopicST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.ReconciliationST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeScramShaST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeTlsST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.tracing.TracingST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.cruisecontrol.CruiseControlST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.ListenersST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.listeners.MultipleListenersST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.KafkaST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.kafka.ConfigProviderST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.custom.CustomAuthorizerST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.OpaIntegrationST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.SecurityST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.log.LoggingChangeST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.log.LogSettingST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.FeatureGatesIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.RecoveryIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.SpecificIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.specific.DrainCleanerIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.connect.ConnectIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.metrics.MetricsIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.metrics.JmxIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-04-05 15:34:06 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.user.UserST
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:219] Used environment variables:
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:220] CONFIG: /home/ec2-user/strimzi-kafka-operator/systemtest/config.json
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] STRIMZI_RBAC_SCOPE: CLUSTER
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] OLM_APP_BUNDLE_PREFIX: strimzi-cluster-operator
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] TEST_CLIENTS_VERSION: 0.2.0
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] OLM_SOURCE_NAMESPACE: openshift-marketplace
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] CLUSTER_OPERATOR_INSTALL_TYPE: BUNDLE
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] STRIMZI_COMPONENTS_LOG_LEVEL: INFO
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] SKIP_TEARDOWN: false
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] LB_FINALIZERS: false
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_DEPLOYMENT_NAME: strimzi-cluster-operator
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] DOCKER_ORG: strimzi
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] TEST_LOG_DIR: /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/target/logs/
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] COMPONENTS_IMAGE_PULL_POLICY: IfNotPresent
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] DOCKER_REGISTRY: quay.io
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] TEST_CLIENT_IMAGE: quay.io/strimzi/test-client:latest-kafka-3.1.0
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] SYSTEM_TEST_STRIMZI_IMAGE_PULL_SECRET: 
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] TEST_ADMIN_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-admin:0.2.0-kafka-3.1.0
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] TEST_HTTP_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-http-producer:0.2.0
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_NAME: strimzi-kafka-operator
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] DOCKER_TAG: latest
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] OLM_SOURCE_NAME: community-operators
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] STRIMZI_FEATURE_GATES: 
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] CLIENTS_KAFKA_VERSION: 3.1.0
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] TEST_HTTP_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-http-consumer:0.2.0
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] STRIMZI_LOG_LEVEL: DEBUG
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] ST_KAFKA_VERSION: 3.1.0
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] OPERATOR_IMAGE_PULL_POLICY: Always
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] DEFAULT_TO_DENY_NETWORK_POLICIES: true
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] TEST_PRODUCER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-producer:0.2.0-kafka-3.1.0
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] BRIDGE_IMAGE: latest-released
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] TEST_STREAMS_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-streams:0.2.0-kafka-3.1.0
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] TEST_CONSUMER_IMAGE: quay.io/strimzi-test-clients/test-client-kafka-consumer:0.2.0-kafka-3.1.0
2022-04-05 15:34:07 [main] [32mINFO [m [Environment:221] OLM_OPERATOR_VERSION: 
2022-04-05 15:34:08 [main] [32mINFO [m [KubeCluster:87] Using cluster: minikube
2022-04-05 15:34:08 [main] [32mINFO [m [KubeClusterResource:60] Cluster default namespace is 'default'
2022-04-05 15:34:08 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-05 15:34:08 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-05 15:34:08 [main] [33mWARN [m [KubeClusterResource:151] Namespace infra-namespace is already created, going to delete it
2022-04-05 15:34:19 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-05 15:34:19 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-05 15:34:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-05 15:34:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 15:34:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-05 15:34:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-05 15:34:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-05 15:34:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-05 15:34:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-05 15:34:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-05 15:34:21 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-05 15:34:21 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-05 15:34:21 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-05 15:34:21 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-05 15:34:21 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-05 15:34:21 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 15:34:21 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-05 15:34:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-05 15:34:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-05 15:34:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-05 15:34:41 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-05 15:34:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-05 15:34:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: user-st
2022-04-05 15:34:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: user-st
2022-04-05 15:34:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: user-st
2022-04-05 15:34:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka user-cluster-name in namespace user-st
2022-04-05 15:34:51 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkas' with unstable version 'v1beta2'
2022-04-05 15:34:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: user-cluster-name will have desired state: Ready
2022-04-05 15:36:04 [main] [32mINFO [m [ResourceManager:444] Kafka: user-cluster-name is in desired state: Ready
2022-04-05 15:36:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:36:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUserWithQuotas-STARTED
2022-04-05 15:36:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:36:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1676838464-767114619 in namespace user-st
2022-04-05 15:36:04 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkausers' with unstable version 'v1beta2'
2022-04-05 15:36:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1676838464-767114619 will have desired state: Ready
2022-04-05 15:36:06 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1676838464-767114619 is in desired state: Ready
2022-04-05 15:36:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=my-user-1676838464-767114619
2022-04-05 15:36:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 15:36:09 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion my-user-1676838464-767114619
2022-04-05 15:36:09 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser my-user-1676838464-767114619 is not deleted yet! Triggering force delete by cmd client!
2022-04-05 15:36:10 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser my-user-1676838464-767114619 deleted
2022-04-05 15:36:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=my-user-1676838464-767114619
2022-04-05 15:36:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 15:36:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:36:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsExternalUserWithQuotas
2022-04-05 15:36:13 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1676838464-767114619 in namespace user-st
2022-04-05 15:36:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:36:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUserWithQuotas-FINISHED
2022-04-05 15:36:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:36:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:36:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUserTemplate-STARTED
2022-04-05 15:36:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:36:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-613638865-861173706 in namespace user-st
2022-04-05 15:36:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-613638865-861173706 will have desired state: Ready
2022-04-05 15:36:14 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-613638865-861173706 is in desired state: Ready
2022-04-05 15:36:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:36:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserTemplate
2022-04-05 15:36:14 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-613638865-861173706 in namespace user-st
2022-04-05 15:36:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:36:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUserTemplate-FINISHED
2022-04-05 15:36:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:36:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:36:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUpdateUser-STARTED
2022-04-05 15:36:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:36:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1760382916-1571334022 in namespace user-st
2022-04-05 15:36:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1760382916-1571334022 will have desired state: Ready
2022-04-05 15:36:25 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1760382916-1571334022 is in desired state: Ready
2022-04-05 15:36:26 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-user-1760382916-1571334022
2022-04-05 15:36:26 [main] [32mINFO [m [SecretUtils:50] Secret my-user-1760382916-1571334022 created
2022-04-05 15:36:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1760382916-1571334022 will have desired state: Ready
2022-04-05 15:36:26 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1760382916-1571334022 is in desired state: Ready
2022-04-05 15:36:26 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion my-user-1760382916-1571334022
2022-04-05 15:36:26 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser my-user-1760382916-1571334022 deleted
2022-04-05 15:36:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:36:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateUser
2022-04-05 15:36:26 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1760382916-1571334022 in namespace user-st
2022-04-05 15:36:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:36:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUpdateUser-FINISHED
2022-04-05 15:36:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:36:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:36:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUser-STARTED
2022-04-05 15:36:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:36:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-0 for test case:testTlsExternalUser
2022-04-05 15:36:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-0
2022-04-05 15:36:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-0
2022-04-05 15:36:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-0
2022-04-05 15:36:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c010cb08 in namespace namespace-0
2022-04-05 15:36:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-0
2022-04-05 15:36:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c010cb08 will have desired state: Ready
2022-04-05 15:37:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c010cb08 is in desired state: Ready
2022-04-05 15:37:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-728730466-996200677 in namespace namespace-0
2022-04-05 15:37:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-0
2022-04-05 15:37:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-728730466-996200677 will have desired state: Ready
2022-04-05 15:37:36 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-728730466-996200677 is in desired state: Ready
2022-04-05 15:37:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-728730466-996200677 will have desired state: Ready
2022-04-05 15:37:36 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-728730466-996200677 is in desired state: Ready
2022-04-05 15:37:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:37:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsExternalUser
2022-04-05 15:37:36 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-728730466-996200677 in namespace namespace-0
2022-04-05 15:37:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c010cb08 in namespace namespace-0
2022-04-05 15:37:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:37:46 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-0 for test case:testTlsExternalUser
2022-04-05 15:37:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsExternalUser-FINISHED
2022-04-05 15:37:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:37:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:37:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testUserWithNameMoreThan64Chars-STARTED
2022-04-05 15:37:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:37:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq in namespace user-st
2022-04-05 15:37:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq will have desired state: Ready
2022-04-05 15:37:58 [main] [32mINFO [m [ResourceManager:444] KafkaUser: user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq is in desired state: Ready
2022-04-05 15:37:58 [main] [32mINFO [m [KafkaUserUtils:90] Wait until KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq status is available
2022-04-05 15:37:58 [main] [32mINFO [m [KafkaUserUtils:95] KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq status is available
2022-04-05 15:37:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace user-st
2022-04-05 15:37:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef will have desired state: Ready
2022-04-05 15:37:59 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: Ready
2022-04-05 15:37:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk in namespace user-st
2022-04-05 15:37:59 [main] [32mINFO [m [KafkaUserUtils:90] Wait until KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk status is available
2022-04-05 15:38:00 [main] [32mINFO [m [KafkaUserUtils:95] KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk status is available
2022-04-05 15:38:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:38:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserWithNameMoreThan64Chars
2022-04-05 15:38:00 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sasl-userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace user-st
2022-04-05 15:38:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser user-with-correct-nameabcdefghijklmnopqrstuvxyzabcdefghijklmnopq in namespace user-st
2022-04-05 15:38:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser userabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk in namespace user-st
2022-04-05 15:38:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:38:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testUserWithNameMoreThan64Chars-FINISHED
2022-04-05 15:38:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:38:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:38:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testTlsUserWithQuotas-STARTED
2022-04-05 15:38:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:38:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser encrypted-arnost in namespace user-st
2022-04-05 15:38:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: encrypted-arnost will have desired state: Ready
2022-04-05 15:38:12 [main] [32mINFO [m [ResourceManager:444] KafkaUser: encrypted-arnost is in desired state: Ready
2022-04-05 15:38:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=encrypted-arnost
2022-04-05 15:38:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 15:38:14 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion encrypted-arnost
2022-04-05 15:38:14 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser encrypted-arnost is not deleted yet! Triggering force delete by cmd client!
2022-04-05 15:38:15 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser encrypted-arnost deleted
2022-04-05 15:38:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user CN=encrypted-arnost
2022-04-05 15:38:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 15:38:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:38:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsUserWithQuotas
2022-04-05 15:38:18 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser encrypted-arnost in namespace user-st
2022-04-05 15:38:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:38:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testTlsUserWithQuotas-FINISHED
2022-04-05 15:38:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:38:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:38:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testScramUserWithQuotas-STARTED
2022-04-05 15:38:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:38:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser scramed-arnost in namespace user-st
2022-04-05 15:38:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: scramed-arnost will have desired state: Ready
2022-04-05 15:38:19 [main] [32mINFO [m [ResourceManager:444] KafkaUser: scramed-arnost is in desired state: Ready
2022-04-05 15:38:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user scramed-arnost
2022-04-05 15:38:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 15:38:22 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion scramed-arnost
2022-04-05 15:38:22 [main] [33mWARN [m [KafkaUserUtils:68] KafkaUser scramed-arnost is not deleted yet! Triggering force delete by cmd client!
2022-04-05 15:38:23 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser scramed-arnost deleted
2022-04-05 15:38:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace user-st exec user-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user scramed-arnost
2022-04-05 15:38:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 15:38:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:38:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScramUserWithQuotas
2022-04-05 15:38:26 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser scramed-arnost in namespace user-st
2022-04-05 15:38:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:38:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testScramUserWithQuotas-FINISHED
2022-04-05 15:38:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:38:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:38:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.user.UserST.testCreatingUsersWithSecretPrefix-STARTED
2022-04-05 15:38:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:38:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-1 for test case:testCreatingUsersWithSecretPrefix
2022-04-05 15:38:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-1
2022-04-05 15:38:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-1
2022-04-05 15:38:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-1
2022-04-05 15:38:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-418d36e4 in namespace namespace-1
2022-04-05 15:38:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-05 15:38:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-418d36e4 will have desired state: Ready
2022-04-05 15:39:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-418d36e4 is in desired state: Ready
2022-04-05 15:39:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-207788007-145862437 in namespace namespace-1
2022-04-05 15:39:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-05 15:39:46 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkatopics' with unstable version 'v1beta2'
2022-04-05 15:39:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-207788007-145862437 will have desired state: Ready
2022-04-05 15:39:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-207788007-145862437 is in desired state: Ready
2022-04-05 15:39:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser encrypted-leopold in namespace namespace-1
2022-04-05 15:39:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-05 15:39:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: encrypted-leopold will have desired state: Ready
2022-04-05 15:39:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: encrypted-leopold is in desired state: Ready
2022-04-05 15:39:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser scramed-leopold in namespace namespace-1
2022-04-05 15:39:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-05 15:39:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: scramed-leopold will have desired state: Ready
2022-04-05 15:39:49 [main] [32mINFO [m [ResourceManager:444] KafkaUser: scramed-leopold is in desired state: Ready
2022-04-05 15:39:49 [main] [32mINFO [m [UserST:346] Deploying KafkaClients pod for TLS listener
2022-04-05 15:39:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-418d36e4-tls-kafka-clients in namespace namespace-1
2022-04-05 15:39:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-05 15:39:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-418d36e4-tls-kafka-clients will be ready
2022-04-05 15:39:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-418d36e4-tls-kafka-clients is ready
2022-04-05 15:39:51 [main] [32mINFO [m [UserST:350] Deploying KafkaClients pod for PLAIN listener
2022-04-05 15:39:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-418d36e4-plain-kafka-clients in namespace namespace-1
2022-04-05 15:39:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-1
2022-04-05 15:39:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-418d36e4-plain-kafka-clients will be ready
2022-04-05 15:39:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-418d36e4-plain-kafka-clients is ready
2022-04-05 15:39:54 [main] [32mINFO [m [UserST:357] Checking if user secrets with secret prefixes exists
2022-04-05 15:39:54 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 15:39:54 [main] [32mINFO [m [UserST:373] Checking if TLS user is able to send messages
2022-04-05 15:39:54 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@11bba05f, messages=[], arguments=[USER=top_secret_encrypted_leopold, --bootstrap-server, my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9093, --max-messages, 100, --topic, my-topic-609391865-1811347379], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-418d36e4-tls-kafka-clients-6495d9c48-464jw', podNamespace='namespace-1', bootstrapServer='my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9093', topicName='my-topic-609391865-1811347379', maxMessages=100, kafkaUsername='top-secret-encrypted-leopold', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5e1f0eb4}
2022-04-05 15:39:54 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9093:my-topic-609391865-1811347379 from pod my-cluster-418d36e4-tls-kafka-clients-6495d9c48-464jw
2022-04-05 15:39:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-418d36e4-tls-kafka-clients-6495d9c48-464jw -n namespace-1 -- /opt/kafka/producer.sh USER=top_secret_encrypted_leopold --bootstrap-server my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9093 --max-messages 100 --topic my-topic-609391865-1811347379
2022-04-05 15:39:58 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 15:39:58 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 15:39:58 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4bd8c96d, messages=[], arguments=[USER=top_secret_encrypted_leopold, --group-id, my-consumer-group-2025221185, --bootstrap-server, my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9093, --group-instance-id, instance2056605920, --max-messages, 100, --topic, my-topic-609391865-1811347379], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-418d36e4-tls-kafka-clients-6495d9c48-464jw', podNamespace='namespace-1', bootstrapServer='my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9093', topicName='my-topic-609391865-1811347379', maxMessages=100, kafkaUsername='top-secret-encrypted-leopold', consumerGroupName='my-consumer-group-2025221185', consumerInstanceId='instance2056605920', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1b01ec06}
2022-04-05 15:39:58 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9093:my-topic-609391865-1811347379 from pod my-cluster-418d36e4-tls-kafka-clients-6495d9c48-464jw
2022-04-05 15:39:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-418d36e4-tls-kafka-clients-6495d9c48-464jw -n namespace-1 -- /opt/kafka/consumer.sh USER=top_secret_encrypted_leopold --group-id my-consumer-group-2025221185 --bootstrap-server my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9093 --group-instance-id instance2056605920 --max-messages 100 --topic my-topic-609391865-1811347379
2022-04-05 15:40:06 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 15:40:06 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 15:40:06 [main] [32mINFO [m [UserST:386] Checking if SCRAM-SHA user is able to send messages
2022-04-05 15:40:06 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6b47f4d4, messages=[], arguments=[USER=top_secret_scramed_leopold, --bootstrap-server, my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9092, --max-messages, 100, --topic, my-topic-609391865-1811347379], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-418d36e4-plain-kafka-clients-5db7cb644d-l8ltq', podNamespace='namespace-1', bootstrapServer='my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-609391865-1811347379', maxMessages=100, kafkaUsername='top-secret-scramed-leopold', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@75d4e2b4}
2022-04-05 15:40:06 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9092:my-topic-609391865-1811347379 from pod my-cluster-418d36e4-plain-kafka-clients-5db7cb644d-l8ltq
2022-04-05 15:40:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-418d36e4-plain-kafka-clients-5db7cb644d-l8ltq -n namespace-1 -- /opt/kafka/producer.sh USER=top_secret_scramed_leopold --bootstrap-server my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9092 --max-messages 100 --topic my-topic-609391865-1811347379
2022-04-05 15:40:09 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 15:40:09 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 15:40:09 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@72ac794c, messages=[], arguments=[USER=top_secret_scramed_leopold, --group-id, my-consumer-group-2025221185, --bootstrap-server, my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9092, --group-instance-id, instance1433356724, --max-messages, 100, --topic, my-topic-609391865-1811347379], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-418d36e4-plain-kafka-clients-5db7cb644d-l8ltq', podNamespace='namespace-1', bootstrapServer='my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9092', topicName='my-topic-609391865-1811347379', maxMessages=100, kafkaUsername='top-secret-scramed-leopold', consumerGroupName='my-consumer-group-2025221185', consumerInstanceId='instance1433356724', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7f324466}
2022-04-05 15:40:09 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9092#my-topic-609391865-1811347379 from pod my-cluster-418d36e4-plain-kafka-clients-5db7cb644d-l8ltq
2022-04-05 15:40:09 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-418d36e4-plain-kafka-clients-5db7cb644d-l8ltq -n namespace-1 -- /opt/kafka/consumer.sh USER=top_secret_scramed_leopold --group-id my-consumer-group-2025221185 --bootstrap-server my-cluster-418d36e4-kafka-bootstrap.namespace-1.svc:9092 --group-instance-id instance1433356724 --max-messages 100 --topic my-topic-609391865-1811347379
2022-04-05 15:40:36 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 15:40:36 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 15:40:36 [main] [32mINFO [m [UserST:392] Checking owner reference - if the secret will be deleted when we delete KafkaUser
2022-04-05 15:40:36 [main] [32mINFO [m [UserST:394] Deleting KafkaUser:encrypted-leopold
2022-04-05 15:40:36 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion encrypted-leopold
2022-04-05 15:40:36 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser encrypted-leopold deleted
2022-04-05 15:40:36 [main] [32mINFO [m [UserST:398] Deleting KafkaUser:scramed-leopold
2022-04-05 15:40:36 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion scramed-leopold
2022-04-05 15:40:36 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser scramed-leopold deleted
2022-04-05 15:40:36 [main] [32mINFO [m [UserST:402] Checking if secrets are deleted
2022-04-05 15:40:36 [main] [32mINFO [m [SecretUtils:54] Waiting for Secret deletion top-secret-encrypted-leopold
2022-04-05 15:40:37 [main] [32mINFO [m [SecretUtils:58] Secret top-secret-encrypted-leopold deleted
2022-04-05 15:40:37 [main] [32mINFO [m [SecretUtils:54] Waiting for Secret deletion top-secret-scramed-leopold
2022-04-05 15:40:37 [main] [32mINFO [m [SecretUtils:58] Secret top-secret-scramed-leopold deleted
2022-04-05 15:40:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:40:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreatingUsersWithSecretPrefix
2022-04-05 15:40:37 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser scramed-leopold in namespace namespace-1
2022-04-05 15:40:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-418d36e4-plain-kafka-clients in namespace namespace-1
2022-04-05 15:40:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-207788007-145862437 in namespace namespace-1
2022-04-05 15:40:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-418d36e4-tls-kafka-clients in namespace namespace-1
2022-04-05 15:40:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser encrypted-leopold in namespace namespace-1
2022-04-05 15:40:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-418d36e4 in namespace namespace-1
2022-04-05 15:41:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:41:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-1 for test case:testCreatingUsersWithSecretPrefix
2022-04-05 15:41:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.user.UserST.testCreatingUsersWithSecretPrefix-FINISHED
2022-04-05 15:41:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:41:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:41:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for UserST
2022-04-05 15:41:28 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka user-cluster-name in namespace user-st
2022-04-05 15:41:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 12, Failures: 0, Errors: 0, Skipped: 4, Time elapsed: 478.706 s - in io.strimzi.systemtest.operators.user.UserST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
2022-04-05 15:42:05 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: throttling-quota-st
2022-04-05 15:42:05 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: throttling-quota-st
2022-04-05 15:42:05 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: throttling-quota-st
2022-04-05 15:42:05 [main] [32mINFO [m [ThrottlingQuotaST:304] Deploying shared Kafka across all test cases in throttling-quota-st namespace
2022-04-05 15:42:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka quota-cluster in namespace throttling-quota-st
2022-04-05 15:42:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: quota-cluster will have desired state: Ready
2022-04-05 15:43:10 [main] [32mINFO [m [ResourceManager:444] Kafka: quota-cluster is in desired state: Ready
2022-04-05 15:43:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:43:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateAlterPartitions-STARTED
2022-04-05 15:43:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:43:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1577787924-1523826270 in namespace throttling-quota-st
2022-04-05 15:43:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1577787924-1523826270 will have desired state: Ready
2022-04-05 15:43:11 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1577787924-1523826270 is in desired state: Ready
2022-04-05 15:43:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-1362cb3c-kafka-clients in namespace throttling-quota-st
2022-04-05 15:43:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-1362cb3c-kafka-clients will be in active state
2022-04-05 15:43:11 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:47:14 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in create-admin-my-cluster-1362cb3c-kafka-clients-5z8q8 log
2022-04-05 15:47:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-1362cb3c-kafka-clients in namespace throttling-quota-st
2022-04-05 15:47:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-1362cb3c-kafka-clients will be in active state
2022-04-05 15:47:20 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:48:22 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-1362cb3c-kafka-clients-7xlgc log
2022-04-05 15:48:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job alter-admin-my-cluster-1362cb3c-kafka-clients in namespace throttling-quota-st
2022-04-05 15:48:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: alter-admin-my-cluster-1362cb3c-kafka-clients will be in active state
2022-04-05 15:48:28 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:52:29 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in alter-admin-my-cluster-1362cb3c-kafka-clients-cc895 log
2022-04-05 15:52:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job teardown-delete in namespace throttling-quota-st
2022-04-05 15:52:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: teardown-delete will be in active state
2022-04-05 15:52:35 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:teardown-delete to finished
2022-04-05 15:53:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:53:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasCreateAlterPartitions
2022-04-05 15:53:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-1362cb3c-kafka-clients in namespace throttling-quota-st
2022-04-05 15:53:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job teardown-delete in namespace throttling-quota-st
2022-04-05 15:53:43 [main] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-1362cb3c-kafka-clients in namespace throttling-quota-st
2022-04-05 15:53:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job alter-admin-my-cluster-1362cb3c-kafka-clients in namespace throttling-quota-st
2022-04-05 15:53:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1577787924-1523826270 in namespace throttling-quota-st
2022-04-05 15:53:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:53:43 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateAlterPartitions-FINISHED
2022-04-05 15:53:43 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:53:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:53:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testKafkaAdminTopicOperations-STARTED
2022-04-05 15:53:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:53:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1152515842-1351113162 in namespace throttling-quota-st
2022-04-05 15:53:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1152515842-1351113162 will have desired state: Ready
2022-04-05 15:53:44 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1152515842-1351113162 is in desired state: Ready
2022-04-05 15:53:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-9ce47073-kafka-clients in namespace throttling-quota-st
2022-04-05 15:53:44 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-9ce47073-kafka-clients will be in active state
2022-04-05 15:53:45 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:55:15 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-9ce47073-kafka-clients-5bnrs log
2022-04-05 15:55:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Job list-admin-my-cluster-9ce47073-kafka-clients in namespace throttling-quota-st
2022-04-05 15:55:20 [main] [32mINFO [m [JobUtils:81] Waiting for job: list-admin-my-cluster-9ce47073-kafka-clients will be in active state
2022-04-05 15:55:21 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:55:23 [main] [32mINFO [m [PodUtils:189] Message quota-topic-test-simple-99 found in list-admin-my-cluster-9ce47073-kafka-clients-lq9rs log
2022-04-05 15:55:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-9ce47073-kafka-clients in namespace throttling-quota-st
2022-04-05 15:55:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-9ce47073-kafka-clients will be in active state
2022-04-05 15:55:29 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:56:59 [main] [32mINFO [m [PodUtils:189] Message Successfully removed all 100 found in delete-admin-my-cluster-9ce47073-kafka-clients-56qmt log
2022-04-05 15:57:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Job list-admin-my-cluster-9ce47073-kafka-clients in namespace throttling-quota-st
2022-04-05 15:57:09 [main] [32mINFO [m [JobUtils:81] Waiting for job: list-admin-my-cluster-9ce47073-kafka-clients will be in active state
2022-04-05 15:57:10 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:list-admin-my-cluster-9ce47073-kafka-clients to finished
2022-04-05 15:57:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 15:57:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAdminTopicOperations
2022-04-05 15:57:13 [main] [32mINFO [m [ResourceManager:241] Delete of Job list-admin-my-cluster-9ce47073-kafka-clients in namespace throttling-quota-st
2022-04-05 15:57:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-9ce47073-kafka-clients in namespace throttling-quota-st
2022-04-05 15:57:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1152515842-1351113162 in namespace throttling-quota-st
2022-04-05 15:57:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job list-admin-my-cluster-9ce47073-kafka-clients in namespace throttling-quota-st
2022-04-05 15:57:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-9ce47073-kafka-clients in namespace throttling-quota-st
2022-04-05 15:57:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 15:57:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testKafkaAdminTopicOperations-FINISHED
2022-04-05 15:57:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 15:57:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 15:57:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasDeleteTopic-STARTED
2022-04-05 15:57:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 15:57:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1259071573-1267095682 in namespace throttling-quota-st
2022-04-05 15:57:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1259071573-1267095682 will have desired state: Ready
2022-04-05 15:57:24 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1259071573-1267095682 is in desired state: Ready
2022-04-05 15:57:24 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 1/5 iteration.
2022-04-05 15:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 15:57:24 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-33377eb6-kafka-clients will be in active state
2022-04-05 15:57:25 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-33377eb6-kafka-clients to finished
2022-04-05 15:58:57 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 15:58:57 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-33377eb6-kafka-clients-hb2wr log
2022-04-05 15:59:02 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 2/5 iteration.
2022-04-05 15:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 15:59:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-33377eb6-kafka-clients will be in active state
2022-04-05 15:59:03 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-33377eb6-kafka-clients to finished
2022-04-05 16:00:36 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 16:00:36 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-33377eb6-kafka-clients-cst5n log
2022-04-05 16:00:41 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 3/5 iteration.
2022-04-05 16:00:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:00:41 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-33377eb6-kafka-clients will be in active state
2022-04-05 16:00:42 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-33377eb6-kafka-clients to finished
2022-04-05 16:02:16 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 16:02:16 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-33377eb6-kafka-clients-qmd7c log
2022-04-05 16:02:21 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 4/5 iteration.
2022-04-05 16:02:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:02:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-33377eb6-kafka-clients will be in active state
2022-04-05 16:02:22 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-33377eb6-kafka-clients to finished
2022-04-05 16:03:56 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 16:03:56 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-33377eb6-kafka-clients-ljgz8 log
2022-04-05 16:04:01 [main] [32mINFO [m [ThrottlingQuotaST:112] Executing 5/5 iteration.
2022-04-05 16:04:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:04:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-33377eb6-kafka-clients will be in active state
2022-04-05 16:04:02 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:create-admin-my-cluster-33377eb6-kafka-clients to finished
2022-04-05 16:05:36 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 16:05:36 [main] [32mINFO [m [PodUtils:189] Message All topics created found in create-admin-my-cluster-33377eb6-kafka-clients-tmrk7 log
2022-04-05 16:05:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:05:41 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-33377eb6-kafka-clients will be in active state
2022-04-05 16:05:42 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 16:09:44 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in delete-admin-my-cluster-33377eb6-kafka-clients-qfvq9 log
2022-04-05 16:09:49 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 1/5 iteration for delete-admin-my-cluster-33377eb6-kafka-clients.
2022-04-05 16:09:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:09:49 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-33377eb6-kafka-clients will be in active state
2022-04-05 16:09:50 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-33377eb6-kafka-clients to finished
2022-04-05 16:10:58 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 2/5 iteration for delete-admin-my-cluster-33377eb6-kafka-clients.
2022-04-05 16:10:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:10:58 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-33377eb6-kafka-clients will be in active state
2022-04-05 16:10:59 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-33377eb6-kafka-clients to finished
2022-04-05 16:12:06 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 3/5 iteration for delete-admin-my-cluster-33377eb6-kafka-clients.
2022-04-05 16:12:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:12:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-33377eb6-kafka-clients will be in active state
2022-04-05 16:12:07 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-33377eb6-kafka-clients to finished
2022-04-05 16:13:15 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 4/5 iteration for delete-admin-my-cluster-33377eb6-kafka-clients.
2022-04-05 16:13:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:13:15 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-33377eb6-kafka-clients will be in active state
2022-04-05 16:13:16 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-33377eb6-kafka-clients to finished
2022-04-05 16:14:23 [main] [32mINFO [m [ThrottlingQuotaST:144] Executing 5/5 iteration for delete-admin-my-cluster-33377eb6-kafka-clients.
2022-04-05 16:14:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Job delete-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:14:23 [main] [32mINFO [m [JobUtils:81] Waiting for job: delete-admin-my-cluster-33377eb6-kafka-clients will be in active state
2022-04-05 16:14:24 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:delete-admin-my-cluster-33377eb6-kafka-clients to finished
2022-04-05 16:15:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:15:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasDeleteTopic
2022-04-05 16:15:31 [main] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job delete-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-33377eb6-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1259071573-1267095682 in namespace throttling-quota-st
2022-04-05 16:15:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:15:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasDeleteTopic-FINISHED
2022-04-05 16:15:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:15:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:15:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateTopic-STARTED
2022-04-05 16:15:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:15:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1235573166-1136647076 in namespace throttling-quota-st
2022-04-05 16:15:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1235573166-1136647076 will have desired state: Ready
2022-04-05 16:15:43 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1235573166-1136647076 is in desired state: Ready
2022-04-05 16:15:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Job create-admin-my-cluster-4697b900-kafka-clients in namespace throttling-quota-st
2022-04-05 16:15:43 [main] [32mINFO [m [JobUtils:81] Waiting for job: create-admin-my-cluster-4697b900-kafka-clients will be in active state
2022-04-05 16:15:44 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-05 16:19:45 [main] [32mINFO [m [PodUtils:189] Message org.apache.kafka.common.errors.ThrottlingQuotaExceededException: The throttling quota has been exceeded. found in create-admin-my-cluster-4697b900-kafka-clients-nb8vd log
2022-04-05 16:20:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:20:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testThrottlingQuotasCreateTopic
2022-04-05 16:20:24 [main] [32mINFO [m [ResourceManager:241] Delete of Job create-admin-my-cluster-4697b900-kafka-clients in namespace throttling-quota-st
2022-04-05 16:20:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1235573166-1136647076 in namespace throttling-quota-st
2022-04-05 16:20:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:20:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.ThrottlingQuotaST.testThrottlingQuotasCreateTopic-FINISHED
2022-04-05 16:20:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:20:34 [main] [32mINFO [m [ThrottlingQuotaST:353] Tearing down resources after all test
2022-04-05 16:20:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:20:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for ThrottlingQuotaST
2022-04-05 16:20:59 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka quota-cluster in namespace throttling-quota-st
2022-04-05 16:21:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,386.902 s - in io.strimzi.systemtest.operators.topic.ThrottlingQuotaST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.topic.TopicST
2022-04-05 16:21:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: topic-st
2022-04-05 16:21:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: topic-st
2022-04-05 16:21:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: topic-st
2022-04-05 16:21:52 [main] [32mINFO [m [TopicST:494] Deploying shared Kafka across all test cases in topic-st namespace
2022-04-05 16:21:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka topic-cluster-name in namespace topic-st
2022-04-05 16:21:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: topic-cluster-name will have desired state: Ready
2022-04-05 16:22:58 [main] [32mINFO [m [ResourceManager:444] Kafka: topic-cluster-name is in desired state: Ready
2022-04-05 16:22:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:22:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testTopicModificationOfReplicationFactor-STARTED
2022-04-05 16:22:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:22:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-755571582-30755763 in namespace topic-st
2022-04-05 16:22:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-755571582-30755763 will have desired state: Ready
2022-04-05 16:22:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-755571582-30755763 is in desired state: Ready
2022-04-05 16:22:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-755571582-30755763 will have desired state: NotReady
2022-04-05 16:23:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-755571582-30755763 is in desired state: NotReady
2022-04-05 16:23:00 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-755571582-30755763 deletion
2022-04-05 16:23:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:23:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicModificationOfReplicationFactor
2022-04-05 16:23:00 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-755571582-30755763 in namespace topic-st
2022-04-05 16:23:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:23:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testTopicModificationOfReplicationFactor-FINISHED
2022-04-05 16:23:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:23:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:23:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testDeleteTopicEnableFalse-STARTED
2022-04-05 16:23:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:23:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3f9cf43a-isolated in namespace topic-st
2022-04-05 16:23:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3f9cf43a-isolated will have desired state: Ready
2022-04-05 16:24:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3f9cf43a-isolated is in desired state: Ready
2022-04-05 16:24:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3f9cf43a-isolated-kafka-clients in namespace topic-st
2022-04-05 16:24:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3f9cf43a-isolated-kafka-clients will be ready
2022-04-05 16:24:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3f9cf43a-isolated-kafka-clients is ready
2022-04-05 16:24:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-440525752-1614817523 in namespace topic-st
2022-04-05 16:24:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-440525752-1614817523 will have desired state: Ready
2022-04-05 16:24:18 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-440525752-1614817523 is in desired state: Ready
2022-04-05 16:24:18 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 16:24:18 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@46bb4096, messages=[], arguments=[--bootstrap-server, my-cluster-3f9cf43a-isolated-kafka-bootstrap.topic-st.svc:9092, --max-messages, 100, --topic, my-topic-440525752-1614817523], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-3f9cf43a-isolated-kafka-clients-67579b8f58-j9qhn', podNamespace='topic-st', bootstrapServer='my-cluster-3f9cf43a-isolated-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-440525752-1614817523', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1a3d60bd}
2022-04-05 16:24:18 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-3f9cf43a-isolated-kafka-bootstrap.topic-st.svc:9092:my-topic-440525752-1614817523 from pod my-cluster-3f9cf43a-isolated-kafka-clients-67579b8f58-j9qhn
2022-04-05 16:24:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3f9cf43a-isolated-kafka-clients-67579b8f58-j9qhn -n topic-st -- /opt/kafka/producer.sh --bootstrap-server my-cluster-3f9cf43a-isolated-kafka-bootstrap.topic-st.svc:9092 --max-messages 100 --topic my-topic-440525752-1614817523
2022-04-05 16:24:21 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 16:24:21 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 16:24:21 [main] [32mINFO [m [TopicST:398] Deleting KafkaTopic: my-topic-440525752-1614817523
2022-04-05 16:24:21 [main] [32mINFO [m [TopicST:400] KafkaTopic my-topic-440525752-1614817523 deleted
2022-04-05 16:26:04 [main] [32mINFO [m [TopicST:404] Wait KafkaTopic my-topic-440525752-1614817523 recreation
2022-04-05 16:26:04 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-440525752-1614817523 creation 
2022-04-05 16:26:04 [main] [32mINFO [m [TopicST:406] KafkaTopic my-topic-440525752-1614817523 recreated
2022-04-05 16:26:04 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3f210dd7, messages=[], arguments=[--group-id, my-consumer-group-1130896151, --bootstrap-server, my-cluster-3f9cf43a-isolated-kafka-bootstrap.topic-st.svc:9092, --group-instance-id, instance1799192426, --max-messages, 100, --topic, my-topic-440525752-1614817523], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-3f9cf43a-isolated-kafka-clients-67579b8f58-j9qhn', podNamespace='topic-st', bootstrapServer='my-cluster-3f9cf43a-isolated-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-440525752-1614817523', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1130896151', consumerInstanceId='instance1799192426', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@603b09e1}
2022-04-05 16:26:04 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-3f9cf43a-isolated-kafka-bootstrap.topic-st.svc:9092#my-topic-440525752-1614817523 from pod my-cluster-3f9cf43a-isolated-kafka-clients-67579b8f58-j9qhn
2022-04-05 16:26:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3f9cf43a-isolated-kafka-clients-67579b8f58-j9qhn -n topic-st -- /opt/kafka/consumer.sh --group-id my-consumer-group-1130896151 --bootstrap-server my-cluster-3f9cf43a-isolated-kafka-bootstrap.topic-st.svc:9092 --group-instance-id instance1799192426 --max-messages 100 --topic my-topic-440525752-1614817523
2022-04-05 16:26:10 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 16:26:10 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 16:26:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:26:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeleteTopicEnableFalse
2022-04-05 16:26:10 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3f9cf43a-isolated-kafka-clients in namespace topic-st
2022-04-05 16:26:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3f9cf43a-isolated in namespace topic-st
2022-04-05 16:26:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-440525752-1614817523 in namespace topic-st
2022-04-05 16:27:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:27:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testDeleteTopicEnableFalse-FINISHED
2022-04-05 16:27:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:27:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:27:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testSendingMessagesToNonExistingTopic-STARTED
2022-04-05 16:27:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:27:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment topic-cluster-name-kafka-clients in namespace topic-st
2022-04-05 16:27:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: topic-cluster-name-kafka-clients will be ready
2022-04-05 16:27:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: topic-cluster-name-kafka-clients is ready
2022-04-05 16:27:02 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 16:27:02 [main] [32mINFO [m [TopicST:323] Checking if my-topic-66990746-469499296 is on topic list
2022-04-05 16:27:02 [main] [32mINFO [m [TopicST:459] Checking topic my-topic-66990746-469499296 in Kafka
2022-04-05 16:27:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:27:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:27:05 [main] [32mINFO [m [TopicST:326] Topic with name my-topic-66990746-469499296 is not created yet
2022-04-05 16:27:05 [main] [32mINFO [m [TopicST:328] Trying to send messages to non-existing topic my-topic-66990746-469499296
2022-04-05 16:27:05 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@28080bc9, messages=[], arguments=[--bootstrap-server, topic-cluster-name-kafka-bootstrap.topic-st.svc:9092, --max-messages, 100, --topic, my-topic-66990746-469499296], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='topic-cluster-name-kafka-clients-7dd7cb68d4-7znv4', podNamespace='topic-st', bootstrapServer='topic-cluster-name-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-66990746-469499296', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1f5a6734}
2022-04-05 16:27:05 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to topic-cluster-name-kafka-bootstrap.topic-st.svc:9092:my-topic-66990746-469499296 from pod topic-cluster-name-kafka-clients-7dd7cb68d4-7znv4
2022-04-05 16:27:05 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec topic-cluster-name-kafka-clients-7dd7cb68d4-7znv4 -n topic-st -- /opt/kafka/producer.sh --bootstrap-server topic-cluster-name-kafka-bootstrap.topic-st.svc:9092 --max-messages 100 --topic my-topic-66990746-469499296
2022-04-05 16:27:08 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 16:27:08 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 16:27:08 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5ed6c542, messages=[], arguments=[--group-id, my-consumer-group-612598144, --bootstrap-server, topic-cluster-name-kafka-bootstrap.topic-st.svc:9092, --group-instance-id, instance1440983494, --max-messages, 100, --topic, my-topic-66990746-469499296], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='topic-cluster-name-kafka-clients-7dd7cb68d4-7znv4', podNamespace='topic-st', bootstrapServer='topic-cluster-name-kafka-bootstrap.topic-st.svc:9092', topicName='my-topic-66990746-469499296', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-612598144', consumerInstanceId='instance1440983494', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@663029f}
2022-04-05 16:27:08 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from topic-cluster-name-kafka-bootstrap.topic-st.svc:9092#my-topic-66990746-469499296 from pod topic-cluster-name-kafka-clients-7dd7cb68d4-7znv4
2022-04-05 16:27:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec topic-cluster-name-kafka-clients-7dd7cb68d4-7znv4 -n topic-st -- /opt/kafka/consumer.sh --group-id my-consumer-group-612598144 --bootstrap-server topic-cluster-name-kafka-bootstrap.topic-st.svc:9092 --group-instance-id instance1440983494 --max-messages 100 --topic my-topic-66990746-469499296
2022-04-05 16:27:14 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 16:27:14 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 16:27:14 [main] [32mINFO [m [TopicST:344] Checking if my-topic-66990746-469499296 is on topic list
2022-04-05 16:27:14 [main] [32mINFO [m [TopicST:459] Checking topic my-topic-66990746-469499296 in Kafka
2022-04-05 16:27:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:27:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:27:16 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-66990746-469499296 creation 
2022-04-05 16:27:16 [main] [32mINFO [m [TopicST:356] Topic successfully created
2022-04-05 16:27:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:27:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendingMessagesToNonExistingTopic
2022-04-05 16:27:16 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment topic-cluster-name-kafka-clients in namespace topic-st
2022-04-05 16:28:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:28:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testSendingMessagesToNonExistingTopic-FINISHED
2022-04-05 16:28:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:28:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:28:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testMoreReplicasThanAvailableBrokers-STARTED
2022-04-05 16:28:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:28:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-788780270-953319576 in namespace topic-st
2022-04-05 16:28:06 [main] [32mINFO [m [TopicST:464] Checking in KafkaTopic CR that topic my-topic-788780270-953319576 exists
2022-04-05 16:28:06 [main] [32mINFO [m [TopicST:459] Checking topic my-topic-788780270-953319576 in Kafka
2022-04-05 16:28:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:28:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-788780270-953319576 will have desired state: NotReady
2022-04-05 16:28:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-788780270-953319576 is in desired state: NotReady
2022-04-05 16:28:09 [main] [32mINFO [m [TopicST:91] Delete topic my-topic-788780270-953319576
2022-04-05 16:28:09 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-788780270-953319576 deletion
2022-04-05 16:28:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-example-new in namespace topic-st
2022-04-05 16:28:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-example-new will have desired state: Ready
2022-04-05 16:28:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-example-new is in desired state: Ready
2022-04-05 16:28:10 [main] [32mINFO [m [TopicST:459] Checking topic topic-example-new in Kafka
2022-04-05 16:28:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:28:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:13 [main] [32mINFO [m [TopicST:464] Checking in KafkaTopic CR that topic topic-example-new exists
2022-04-05 16:28:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:28:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMoreReplicasThanAvailableBrokers
2022-04-05 16:28:13 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-example-new in namespace topic-st
2022-04-05 16:28:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-788780270-953319576 in namespace topic-st
2022-04-05 16:28:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:28:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testMoreReplicasThanAvailableBrokers-FINISHED
2022-04-05 16:28:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:28:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:28:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaKafka-STARTED
2022-04-05 16:28:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:28:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --create  --topic my-topic-1617154125-309232184 --replication-factor 3 --partitions 3
2022-04-05 16:28:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:26 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-topic-1617154125-309232184 creation 
2022-04-05 16:28:27 [main] [32mINFO [m [TopicST:485] Checking in KafkaTopic CR that topic my-topic-1617154125-309232184 was created with expected settings
2022-04-05 16:28:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:28:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:30 [main] [32mINFO [m [TopicST:122] Editing topic via Kafka, settings to partitions 5
2022-04-05 16:28:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic-1617154125-309232184 --partitions 5
2022-04-05 16:28:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:32 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-1617154125-309232184
2022-04-05 16:28:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-topic-1617154125-309232184
2022-04-05 16:28:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:35 [main] [32mINFO [m [TopicST:473] Checking topic my-topic-1617154125-309232184 in Kafka topic-cluster-name
2022-04-05 16:28:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:28:35 [main] [32mINFO [m [ResourceManager:346] In context testCreateTopicViaKafka is everything deleted.
2022-04-05 16:28:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:28:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicViaKafka-FINISHED
2022-04-05 16:28:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:28:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:28:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicAfterUnsupportedOperation-STARTED
2022-04-05 16:28:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:28:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-with-replication-to-change in namespace topic-st
2022-04-05 16:28:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-with-replication-to-change will have desired state: Ready
2022-04-05 16:28:36 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-with-replication-to-change is in desired state: Ready
2022-04-05 16:28:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: topic-with-replication-to-change will have desired state: NotReady
2022-04-05 16:28:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: topic-with-replication-to-change is in desired state: NotReady
2022-04-05 16:28:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic another-topic in namespace topic-st
2022-04-05 16:28:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: another-topic will have desired state: Ready
2022-04-05 16:28:38 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: another-topic is in desired state: Ready
2022-04-05 16:28:38 [main] [32mINFO [m [TopicST:459] Checking topic topic-with-replication-to-change in Kafka
2022-04-05 16:28:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:28:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:41 [main] [32mINFO [m [TopicST:464] Checking in KafkaTopic CR that topic topic-with-replication-to-change exists
2022-04-05 16:28:41 [main] [32mINFO [m [TopicST:459] Checking topic another-topic in Kafka
2022-04-05 16:28:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace topic-st exec topic-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 16:28:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:28:44 [main] [32mINFO [m [TopicST:464] Checking in KafkaTopic CR that topic another-topic exists
2022-04-05 16:28:44 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic topic-with-replication-to-change deletion
2022-04-05 16:28:44 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic another-topic deletion
2022-04-05 16:28:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:28:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCreateTopicAfterUnsupportedOperation
2022-04-05 16:28:44 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic another-topic in namespace topic-st
2022-04-05 16:28:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-with-replication-to-change in namespace topic-st
2022-04-05 16:28:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:28:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.topic.TopicST.testCreateTopicAfterUnsupportedOperation-FINISHED
2022-04-05 16:28:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:28:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:28:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for TopicST
2022-04-05 16:28:44 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka topic-cluster-name in namespace topic-st
2022-04-05 16:28:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 465.139 s - in io.strimzi.systemtest.operators.topic.TopicST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.ReconciliationST
2022-04-05 16:29:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: reconciliation-st
2022-04-05 16:29:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: reconciliation-st
2022-04-05 16:29:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: reconciliation-st
2022-04-05 16:29:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:29:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaAndKafkaConnectWithConnector-STARTED
2022-04-05 16:29:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:29:37 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-2 for test case:testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-05 16:29:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-2
2022-04-05 16:29:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-2
2022-04-05 16:29:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-2
2022-04-05 16:29:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fe9eb600 in namespace namespace-2
2022-04-05 16:29:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-05 16:29:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fe9eb600 will have desired state: Ready
2022-04-05 16:31:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fe9eb600 is in desired state: Ready
2022-04-05 16:31:00 [main] [32mINFO [m [ReconciliationST:80] Adding pause annotation into Kafka resource and also scaling replicas to 4, new pod should not appear
2022-04-05 16:31:00 [main] [32mINFO [m [ReconciliationST:86] Kafka should contain status with ReconciliationPaused
2022-04-05 16:31:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fe9eb600 will have desired state: ReconciliationPaused
2022-04-05 16:31:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fe9eb600 is in desired state: ReconciliationPaused
2022-04-05 16:31:01 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-fe9eb600-kafka will have stable 3 replicas
2022-04-05 16:31:01 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-05 16:31:02 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-05 16:31:03 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-05 16:31:04 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-05 16:31:05 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-05 16:31:06 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-05 16:31:07 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-05 16:31:08 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-05 16:31:09 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-05 16:31:10 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-05 16:31:11 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-05 16:31:12 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-05 16:31:13 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-05 16:31:14 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-05 16:31:15 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-05 16:31:16 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-05 16:31:17 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-05 16:31:18 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-05 16:31:19 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-05 16:31:20 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-05 16:31:20 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-fe9eb600-kafka has 3 replicas
2022-04-05 16:31:20 [main] [32mINFO [m [ReconciliationST:90] Setting annotation to "false", Kafka should be scaled to 4
2022-04-05 16:31:20 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-fe9eb600-kafka to be ready
2022-04-05 16:33:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fe9eb600 will have desired state: Ready
2022-04-05 16:33:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fe9eb600 is in desired state: Ready
2022-04-05 16:33:24 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-fe9eb600 is ready
2022-04-05 16:33:24 [main] [32mINFO [m [ReconciliationST:94] Deploying KafkaConnect with pause annotation from the start, no pods should appear
2022-04-05 16:33:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fe9eb600-kafka-clients in namespace namespace-2
2022-04-05 16:33:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-05 16:33:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fe9eb600-kafka-clients will be ready
2022-04-05 16:33:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fe9eb600-kafka-clients is ready
2022-04-05 16:33:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fe9eb600-scraper in namespace namespace-2
2022-04-05 16:33:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-05 16:33:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fe9eb600-scraper will be ready
2022-04-05 16:33:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fe9eb600-scraper is ready
2022-04-05 16:33:28 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-fe9eb600-scraper to be ready
2022-04-05 16:33:38 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-fe9eb600-scraper is ready
2022-04-05 16:33:38 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-fe9eb600-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 16:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-fe9eb600-allow in namespace namespace-2
2022-04-05 16:33:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-05 16:33:38 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 16:33:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-fe9eb600 in namespace namespace-2
2022-04-05 16:33:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-05 16:33:38 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkaconnects' with unstable version 'v1beta2'
2022-04-05 16:33:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-fe9eb600 will have desired state: ReconciliationPaused
2022-04-05 16:33:39 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-fe9eb600 is in desired state: ReconciliationPaused
2022-04-05 16:33:39 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-fe9eb600-connect will have stable 0 replicas
2022-04-05 16:33:39 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-05 16:33:40 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-05 16:33:41 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-05 16:33:42 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-05 16:33:43 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-05 16:33:44 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-05 16:33:45 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-05 16:33:46 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-05 16:33:47 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-05 16:33:48 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-05 16:33:49 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-05 16:33:50 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-05 16:33:51 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-05 16:33:52 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-05 16:33:53 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-05 16:33:54 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-05 16:33:55 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-05 16:33:56 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-05 16:33:57 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-05 16:33:58 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-05 16:33:58 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-fe9eb600-connect has 0 replicas
2022-04-05 16:33:58 [main] [32mINFO [m [ReconciliationST:108] Setting annotation to "false" and creating KafkaConnector
2022-04-05 16:33:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fe9eb600-connect will be ready
2022-04-05 16:35:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fe9eb600-connect is ready
2022-04-05 16:35:05 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-fe9eb600-connect to be ready
2022-04-05 16:35:15 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-fe9eb600-connect is ready
2022-04-05 16:35:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-fe9eb600 in namespace namespace-2
2022-04-05 16:35:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-2
2022-04-05 16:35:16 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkaconnectors' with unstable version 'v1beta2'
2022-04-05 16:35:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-fe9eb600 will have desired state: Ready
2022-04-05 16:35:17 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-fe9eb600 is in desired state: Ready
2022-04-05 16:35:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:17 [main] [32mINFO [m [ReconciliationST:118] Adding pause annotation into the KafkaConnector and scaling taskMax to 4
2022-04-05 16:35:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-fe9eb600 will have desired state: ReconciliationPaused
2022-04-05 16:35:18 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-fe9eb600 is in desired state: ReconciliationPaused
2022-04-05 16:35:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:18 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 19 polls
2022-04-05 16:35:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:19 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 18 polls
2022-04-05 16:35:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:21 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 17 polls
2022-04-05 16:35:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:22 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 16 polls
2022-04-05 16:35:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:23 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 15 polls
2022-04-05 16:35:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:24 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 14 polls
2022-04-05 16:35:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:25 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 13 polls
2022-04-05 16:35:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:27 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 12 polls
2022-04-05 16:35:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:28 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 11 polls
2022-04-05 16:35:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:29 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 10 polls
2022-04-05 16:35:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:30 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 9 polls
2022-04-05 16:35:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:31 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 8 polls
2022-04-05 16:35:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:33 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 7 polls
2022-04-05 16:35:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:34 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 6 polls
2022-04-05 16:35:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:35 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 5 polls
2022-04-05 16:35:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:36 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 4 polls
2022-04-05 16:35:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:37 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 3 polls
2022-04-05 16:35:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:39 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 2 polls
2022-04-05 16:35:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:40 [main] [32mINFO [m [KafkaConnectorUtils:162] Connector's spec gonna be stable in 1 polls
2022-04-05 16:35:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600
2022-04-05 16:35:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:41 [main] [32mINFO [m [KafkaConnectorUtils:154] Connector's spec is stable for 20 polls intervals
2022-04-05 16:35:41 [main] [32mINFO [m [ReconciliationST:127] Setting annotation to "false", taskMax should be increased to 4
2022-04-05 16:35:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600/config
2022-04-05 16:35:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-2 exec my-cluster-fe9eb600-connect-9559cd4dc-cmgw9 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-fe9eb600/config
2022-04-05 16:35:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:35:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:35:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-05 16:35:42 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-fe9eb600-allow in namespace namespace-2
2022-04-05 16:35:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-fe9eb600 in namespace namespace-2
2022-04-05 16:35:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fe9eb600-kafka-clients in namespace namespace-2
2022-04-05 16:35:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fe9eb600 in namespace namespace-2
2022-04-05 16:35:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fe9eb600-scraper in namespace namespace-2
2022-04-05 16:35:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-fe9eb600 in namespace namespace-2
2022-04-05 16:36:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:36:32 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-2 for test case:testPauseReconciliationInKafkaAndKafkaConnectWithConnector
2022-04-05 16:36:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaAndKafkaConnectWithConnector-FINISHED
2022-04-05 16:36:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:36:38 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:36:38 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaRebalanceAndTopic-STARTED
2022-04-05 16:36:38 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:36:38 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-3 for test case:testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-05 16:36:38 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-3
2022-04-05 16:36:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-3
2022-04-05 16:36:38 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-3
2022-04-05 16:36:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3bbbcfe4 in namespace namespace-3
2022-04-05 16:36:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-05 16:36:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3bbbcfe4 will have desired state: Ready
2022-04-05 16:38:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3bbbcfe4 is in desired state: Ready
2022-04-05 16:38:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-766586836-1246016169 in namespace namespace-3
2022-04-05 16:38:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-05 16:38:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-766586836-1246016169 will have desired state: Ready
2022-04-05 16:38:16 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-766586836-1246016169 is in desired state: Ready
2022-04-05 16:38:16 [main] [32mINFO [m [ReconciliationST:147] Adding pause annotation into KafkaTopic resource and changing replication factor
2022-04-05 16:38:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-766586836-1246016169 will have desired state: ReconciliationPaused
2022-04-05 16:38:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-766586836-1246016169 is in desired state: ReconciliationPaused
2022-04-05 16:38:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:38:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:38:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:38:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:38:26 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 19 polls
2022-04-05 16:38:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:38:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:38:30 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 18 polls
2022-04-05 16:38:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:38:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:38:41 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 17 polls
2022-04-05 16:38:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:38:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:38:44 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 16 polls
2022-04-05 16:38:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:38:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:38:48 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 15 polls
2022-04-05 16:38:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:38:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:38:55 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 14 polls
2022-04-05 16:38:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:38:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:38:59 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 13 polls
2022-04-05 16:39:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:39:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:03 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 12 polls
2022-04-05 16:39:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:39:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:07 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 11 polls
2022-04-05 16:39:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:39:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:11 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 10 polls
2022-04-05 16:39:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:39:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:18 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 9 polls
2022-04-05 16:39:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:39:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:21 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 8 polls
2022-04-05 16:39:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:39:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:25 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 7 polls
2022-04-05 16:39:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:39:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:29 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 6 polls
2022-04-05 16:39:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:39:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:36 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 5 polls
2022-04-05 16:39:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:39:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:40 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 4 polls
2022-04-05 16:39:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:39:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:44 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 3 polls
2022-04-05 16:39:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:39:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:47 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 2 polls
2022-04-05 16:39:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:39:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:51 [main] [32mINFO [m [KafkaTopicUtils:205] KafkaTopic's spec gonna be stable in 1 polls
2022-04-05 16:39:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-3 exec my-cluster-3bbbcfe4-kafka-0 -- /opt/kafka/bin/kafka-topics.sh --topic my-topic-766586836-1246016169 --describe --bootstrap-server my-cluster-3bbbcfe4-kafka-bootstrap:9092
2022-04-05 16:39:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:39:55 [main] [32mINFO [m [KafkaTopicUtils:197] KafkaTopic's spec is stable for 20 polls intervals
2022-04-05 16:39:55 [main] [32mINFO [m [ReconciliationST:156] Setting annotation to "false", partitions should be scaled to 4
2022-04-05 16:39:55 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-766586836-1246016169
2022-04-05 16:39:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-3bbbcfe4 in namespace namespace-3
2022-04-05 16:39:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-3
2022-04-05 16:39:55 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkarebalances' with unstable version 'v1beta2'
2022-04-05 16:39:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-3bbbcfe4 will have desired state: PendingProposal
2022-04-05 16:39:56 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-3bbbcfe4 is in desired state: PendingProposal
2022-04-05 16:39:56 [main] [32mINFO [m [ReconciliationST:164] Waiting for ProposalReady, then add pause and rebalance annotation, rebalancing should not be triggered
2022-04-05 16:39:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-3bbbcfe4 will have desired state: ProposalReady
2022-04-05 16:46:06 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-3bbbcfe4 is in desired state: ProposalReady
2022-04-05 16:46:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-3bbbcfe4 will have desired state: ReconciliationPaused
2022-04-05 16:46:07 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-3bbbcfe4 is in desired state: ReconciliationPaused
2022-04-05 16:46:07 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #1(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): Annotating KafkaRebalance:my-cluster-3bbbcfe4 with annotation approve
2022-04-05 16:46:07 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 19 polls
2022-04-05 16:46:08 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 18 polls
2022-04-05 16:46:09 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 17 polls
2022-04-05 16:46:10 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 16 polls
2022-04-05 16:46:11 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 15 polls
2022-04-05 16:46:12 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 14 polls
2022-04-05 16:46:13 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 13 polls
2022-04-05 16:46:14 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 12 polls
2022-04-05 16:46:15 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 11 polls
2022-04-05 16:46:16 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 10 polls
2022-04-05 16:46:17 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 9 polls
2022-04-05 16:46:18 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 8 polls
2022-04-05 16:46:19 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 7 polls
2022-04-05 16:46:20 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 6 polls
2022-04-05 16:46:21 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 5 polls
2022-04-05 16:46:22 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 4 polls
2022-04-05 16:46:23 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 3 polls
2022-04-05 16:46:24 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 2 polls
2022-04-05 16:46:25 [main] [32mINFO [m [KafkaRebalanceUtils:126] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status gonna be stable in 1 polls
2022-04-05 16:46:26 [main] [32mINFO [m [KafkaRebalanceUtils:118] Reconciliation #2(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): KafkaRebalance status is stable for 20 polls intervals
2022-04-05 16:46:26 [main] [32mINFO [m [ReconciliationST:178] Setting annotation to "false" and waiting for KafkaRebalance to be in Ready state
2022-04-05 16:46:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-3bbbcfe4 will have desired state: ProposalReady
2022-04-05 16:46:27 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-3bbbcfe4 is in desired state: ProposalReady
2022-04-05 16:46:27 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #3(test) KafkaRebalance(namespace-3/my-cluster-3bbbcfe4): Annotating KafkaRebalance:my-cluster-3bbbcfe4 with annotation approve
2022-04-05 16:46:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-3bbbcfe4 will have desired state: Ready
2022-04-05 16:47:24 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-3bbbcfe4 is in desired state: Ready
2022-04-05 16:47:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:47:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-05 16:47:24 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-766586836-1246016169 in namespace namespace-3
2022-04-05 16:47:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3bbbcfe4 in namespace namespace-3
2022-04-05 16:47:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-3bbbcfe4 in namespace namespace-3
2022-04-05 16:47:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-3, for cruise control Kafka cluster my-cluster-3bbbcfe4
2022-04-05 16:47:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:47:34 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-3 for test case:testPauseReconciliationInKafkaRebalanceAndTopic
2022-04-05 16:48:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ReconciliationST.testPauseReconciliationInKafkaRebalanceAndTopic-FINISHED
2022-04-05 16:48:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:48:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:48:17 [main] [32mINFO [m [ResourceManager:346] In context ReconciliationST is everything deleted.
2022-04-05 16:48:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,125.272 s - in io.strimzi.systemtest.operators.ReconciliationST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeScramShaST
2022-04-05 16:48:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: http-bridge-scram-sha-st
2022-04-05 16:48:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: http-bridge-scram-sha-st
2022-04-05 16:48:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: http-bridge-scram-sha-st
2022-04-05 16:48:23 [main] [32mINFO [m [HttpBridgeScramShaST:123] Deploy Kafka and KafkaBridge before tests
2022-04-05 16:48:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-05 16:48:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-scram-sha-cluster-name will have desired state: Ready
2022-04-05 16:49:35 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-scram-sha-cluster-name is in desired state: Ready
2022-04-05 16:49:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-885117958-1248349747 in namespace http-bridge-scram-sha-st
2022-04-05 16:49:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-885117958-1248349747 will have desired state: Ready
2022-04-05 16:49:36 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-885117958-1248349747 is in desired state: Ready
2022-04-05 16:49:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment http-bridge-scram-sha-st-shared-kafka-clients in namespace http-bridge-scram-sha-st
2022-04-05 16:49:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: http-bridge-scram-sha-st-shared-kafka-clients will be ready
2022-04-05 16:49:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: http-bridge-scram-sha-st-shared-kafka-clients is ready
2022-04-05 16:49:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-05 16:49:37 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkabridges' with unstable version 'v1beta2'
2022-04-05 16:49:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-scram-sha-cluster-name will have desired state: Ready
2022-04-05 16:50:00 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-scram-sha-cluster-name is in desired state: Ready
2022-04-05 16:50:00 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:50:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:50:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testSendSimpleMessageTlsScramSha-STARTED
2022-04-05 16:50:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:50:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1713441892-40387077 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1713441892-40387077 will have desired state: Ready
2022-04-05 16:50:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1713441892-40387077 is in desired state: Ready
2022-04-05 16:50:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-398256072 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-398256072 will be in active state
2022-04-05 16:50:02 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-398256072 to finished
2022-04-05 16:50:11 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-1023193858 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-1023193858 will be in active state
2022-04-05 16:50:12 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-1023193858 to finished
2022-04-05 16:50:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:50:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessageTlsScramSha
2022-04-05 16:50:23 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-398256072 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1713441892-40387077 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job consumer-1023193858 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:50:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testSendSimpleMessageTlsScramSha-FINISHED
2022-04-05 16:50:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:50:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:50:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testReceiveSimpleMessageTlsScramSha-STARTED
2022-04-05 16:50:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:50:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-609391865-1811347379 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-609391865-1811347379 will have desired state: Ready
2022-04-05 16:50:34 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-609391865-1811347379 is in desired state: Ready
2022-04-05 16:50:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-56826624 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-56826624 will be in active state
2022-04-05 16:50:35 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:50:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-318996325 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:35 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-318996325 will be in active state
2022-04-05 16:50:36 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-318996325 and consumer consumer-56826624 finish
2022-04-05 16:50:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:50:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessageTlsScramSha
2022-04-05 16:50:52 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-56826624 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-609391865-1811347379 in namespace http-bridge-scram-sha-st
2022-04-05 16:50:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job producer-318996325 in namespace http-bridge-scram-sha-st
2022-04-05 16:51:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:51:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeScramShaST.testReceiveSimpleMessageTlsScramSha-FINISHED
2022-04-05 16:51:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:51:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:51:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeScramShaST
2022-04-05 16:51:02 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment http-bridge-scram-sha-st-shared-kafka-clients in namespace http-bridge-scram-sha-st
2022-04-05 16:51:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-05 16:51:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-885117958-1248349747 in namespace http-bridge-scram-sha-st
2022-04-05 16:51:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-scram-sha-cluster-name in namespace http-bridge-scram-sha-st
2022-04-05 16:51:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 214.475 s - in io.strimzi.systemtest.bridge.HttpBridgeScramShaST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeTlsST
2022-04-05 16:51:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: http-bridge-tls-st
2022-04-05 16:51:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: http-bridge-tls-st
2022-04-05 16:51:57 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: http-bridge-tls-st
2022-04-05 16:51:57 [main] [32mINFO [m [HttpBridgeTlsST:129] Deploy Kafka and KafkaBridge before tests
2022-04-05 16:51:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-05 16:51:57 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-tls-cluster-name will have desired state: Ready
2022-04-05 16:53:00 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-tls-cluster-name is in desired state: Ready
2022-04-05 16:53:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-925960830-1339668284 in namespace http-bridge-tls-st
2022-04-05 16:53:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-925960830-1339668284 will have desired state: Ready
2022-04-05 16:53:01 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-925960830-1339668284 is in desired state: Ready
2022-04-05 16:53:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment http-bridge-tls-st-kafka-clients in namespace http-bridge-tls-st
2022-04-05 16:53:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: http-bridge-tls-st-kafka-clients will be ready
2022-04-05 16:53:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: http-bridge-tls-st-kafka-clients is ready
2022-04-05 16:53:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-05 16:53:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-tls-cluster-name will have desired state: Ready
2022-04-05 16:53:23 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-tls-cluster-name is in desired state: Ready
2022-04-05 16:53:23 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:53:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:53:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testReceiveSimpleMessageTls-STARTED
2022-04-05 16:53:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:53:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1019064407-2024463353 in namespace http-bridge-tls-st
2022-04-05 16:53:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1019064407-2024463353 will have desired state: Ready
2022-04-05 16:53:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1019064407-2024463353 is in desired state: Ready
2022-04-05 16:53:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-1688167763 in namespace http-bridge-tls-st
2022-04-05 16:53:24 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-1688167763 will be in active state
2022-04-05 16:53:25 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:53:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-231215763 in namespace http-bridge-tls-st
2022-04-05 16:53:25 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-231215763 will be in active state
2022-04-05 16:53:26 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-231215763 and consumer consumer-1688167763 finish
2022-04-05 16:53:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:53:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessageTls
2022-04-05 16:53:41 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-1688167763 in namespace http-bridge-tls-st
2022-04-05 16:53:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1019064407-2024463353 in namespace http-bridge-tls-st
2022-04-05 16:53:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job producer-231215763 in namespace http-bridge-tls-st
2022-04-05 16:53:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:53:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testReceiveSimpleMessageTls-FINISHED
2022-04-05 16:53:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:53:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:53:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testSendSimpleMessageTls-STARTED
2022-04-05 16:53:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:53:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2040697486-2013260196 in namespace http-bridge-tls-st
2022-04-05 16:53:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2040697486-2013260196 will have desired state: Ready
2022-04-05 16:53:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2040697486-2013260196 is in desired state: Ready
2022-04-05 16:53:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-2012626482 in namespace http-bridge-tls-st
2022-04-05 16:53:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-2012626482 will be in active state
2022-04-05 16:53:53 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-2012626482 to finished
2022-04-05 16:54:01 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:54:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-1454469765 in namespace http-bridge-tls-st
2022-04-05 16:54:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-1454469765 will be in active state
2022-04-05 16:54:02 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-1454469765 to finished
2022-04-05 16:54:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:54:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessageTls
2022-04-05 16:54:13 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-2012626482 in namespace http-bridge-tls-st
2022-04-05 16:54:13 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2040697486-2013260196 in namespace http-bridge-tls-st
2022-04-05 16:54:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job consumer-1454469765 in namespace http-bridge-tls-st
2022-04-05 16:54:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:54:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeTlsST.testSendSimpleMessageTls-FINISHED
2022-04-05 16:54:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:54:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:54:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeTlsST
2022-04-05 16:54:23 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment http-bridge-tls-st-kafka-clients in namespace http-bridge-tls-st
2022-04-05 16:54:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-05 16:54:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-925960830-1339668284 in namespace http-bridge-tls-st
2022-04-05 16:54:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-tls-cluster-name in namespace http-bridge-tls-st
2022-04-05 16:55:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 201.456 s - in io.strimzi.systemtest.bridge.HttpBridgeTlsST
[[1;34mINFO[m] Running io.strimzi.systemtest.tracing.TracingST
2022-04-05 16:55:19 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: tracing-st
2022-04-05 16:55:19 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: tracing-st
2022-04-05 16:55:19 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: tracing-st
2022-04-05 16:55:19 [main] [32mINFO [m [TracingST:497] === Applying jaeger operator install files ===
2022-04-05 16:55:19 [main] [32mINFO [m [TracingST:488] Creating jaeger-cluster-role-binding.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-cluster-role-binding.yaml
2022-04-05 16:55:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:19 [main] [32mINFO [m [Exec:417] Input: ---
kind: "ClusterRoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
  namespace: "tracing-st"
roleRef:
  kind: "ClusterRole"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-05 16:55:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:19 [main] [32mINFO [m [TracingST:488] Creating jaeger-cluster-role.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-cluster-role.yaml
2022-04-05 16:55:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:19 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "ClusterRole"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "console.openshift.io"
  resources:
  - "consolelinks"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "namespaces"
  verbs:
  - "get"
  - "list"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  verbs:
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - "clusterrolebindings"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-05 16:55:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:19 [main] [32mINFO [m [TracingST:488] Creating jaeger-crd.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-crd.yaml
2022-04-05 16:55:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:20 [main] [32mINFO [m [TracingST:488] Creating jaeger-operator.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-operator.yaml
2022-04-05 16:55:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:20 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "apps/v1"
kind: "Deployment"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
spec:
  replicas: 1
  selector:
    matchLabels:
      name: "jaeger-operator"
  template:
    metadata:
      labels:
        name: "jaeger-operator"
    spec:
      serviceAccountName: "jaeger-operator"
      containers:
      - name: "jaeger-operator"
        image: "jaegertracing/jaeger-operator:1.20.0"
        ports:
        - containerPort: 8383
          name: "http-metrics"
        - containerPort: 8686
          name: "cr-metrics"
        args:
        - "start"
        - "--kafka-provision=no"
        imagePullPolicy: "Always"
        env:
        - name: "WATCH_NAMESPACE"
          value: ""
        - name: "POD_NAME"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.name"
        - name: "POD_NAMESPACE"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.namespace"
        - name: "OPERATOR_NAME"
          value: "jaeger-operator"
2022-04-05 16:55:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:20 [main] [32mINFO [m [TracingST:488] Creating jaeger-role-binding.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-role-binding.yaml
2022-04-05 16:55:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:20 [main] [32mINFO [m [Exec:417] Input: ---
kind: "RoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
roleRef:
  kind: "Role"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-05 16:55:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:20 [main] [32mINFO [m [TracingST:488] Creating jaeger-role.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-role.yaml
2022-04-05 16:55:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:21 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "Role"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "image.openshift.io"
  resources:
  - "imagestreams"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-05 16:55:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:21 [main] [32mINFO [m [TracingST:488] Creating jaeger-service-account.yaml from /home/ec2-user/strimzi-kafka-operator/systemtest/../systemtest/src/test/resources/tracing/1.20/operator-files/jaeger-service-account.yaml
2022-04-05 16:55:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st apply -f -
2022-04-05 16:55:21 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "v1"
kind: "ServiceAccount"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
2022-04-05 16:55:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: jaeger-operator will be ready
2022-04-05 16:55:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: jaeger-operator is ready
2022-04-05 16:55:24 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment jaeger-operator to be ready
2022-04-05 16:55:34 [main] [32mINFO [m [DeploymentUtils:197] Deployment jaeger-operator is ready
2022-04-05 16:55:34 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy jaeger-allow in namespace tracing-st
2022-04-05 16:55:34 [main] [32mINFO [m [TracingST:524] Network policy for jaeger successfully created
2022-04-05 16:55:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:55:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsConnectService-STARTED
2022-04-05 16:55:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:55:34 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-4 for test case:testProducerConsumerStreamsConnectService
2022-04-05 16:55:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-4
2022-04-05 16:55:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-4
2022-04-05 16:55:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-4
2022-04-05 16:55:34 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-05 16:55:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 apply -f -
2022-04-05 16:55:34 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 16:55:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:55:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-05 16:55:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-05 16:55:37 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-05 16:55:47 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-05 16:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-023d1955-kafka-clients in namespace namespace-4
2022-04-05 16:55:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:55:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-023d1955-kafka-clients will be ready
2022-04-05 16:55:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-023d1955-kafka-clients is ready
2022-04-05 16:55:48 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 16:55:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-023d1955 in namespace namespace-4
2022-04-05 16:55:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:55:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-023d1955 will have desired state: Ready
2022-04-05 16:57:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-023d1955 is in desired state: Ready
2022-04-05 16:57:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-393385696-616334554 in namespace namespace-4
2022-04-05 16:57:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:57:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-393385696-616334554 will have desired state: Ready
2022-04-05 16:57:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-393385696-616334554 is in desired state: Ready
2022-04-05 16:57:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-458131512-383053166 in namespace namespace-4
2022-04-05 16:57:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:57:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-458131512-383053166 will have desired state: Ready
2022-04-05 16:57:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-458131512-383053166 is in desired state: Ready
2022-04-05 16:57:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-023d1955-scraper in namespace namespace-4
2022-04-05 16:57:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:57:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-023d1955-scraper will be ready
2022-04-05 16:57:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-023d1955-scraper is ready
2022-04-05 16:57:13 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-023d1955-scraper to be ready
2022-04-05 16:57:23 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-023d1955-scraper is ready
2022-04-05 16:57:23 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-023d1955-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 16:57:23 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-023d1955-allow in namespace namespace-4
2022-04-05 16:57:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:57:23 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 16:57:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-023d1955 in namespace namespace-4
2022-04-05 16:57:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:57:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-023d1955 will have desired state: Ready
2022-04-05 16:58:31 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-023d1955 is in desired state: Ready
2022-04-05 16:58:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-023d1955 in namespace namespace-4
2022-04-05 16:58:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:58:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-023d1955 will have desired state: Ready
2022-04-05 16:58:32 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-023d1955 is in desired state: Ready
2022-04-05 16:58:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-023d1955-hello-world-producer in namespace namespace-4
2022-04-05 16:58:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:58:32 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-023d1955-hello-world-producer will be in active state
2022-04-05 16:58:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-023d1955-hello-world-consumer in namespace namespace-4
2022-04-05 16:58:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-4
2022-04-05 16:58:33 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-023d1955-hello-world-consumer will be in active state
2022-04-05 16:58:34 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-023d1955-hello-world-producer and consumer my-cluster-023d1955-hello-world-consumer finish
2022-04-05 16:58:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-023d1955-kafka-clients-549c5b4b6-kqfhv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 16:58:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:58:51 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-05 16:58:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-023d1955-kafka-clients-549c5b4b6-kqfhv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-393385696-616334554
2022-04-05 16:58:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:58:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-023d1955-kafka-clients-549c5b4b6-kqfhv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 16:58:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:58:52 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-05 16:58:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-023d1955-kafka-clients-549c5b4b6-kqfhv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-topic-393385696-616334554
2022-04-05 16:58:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:58:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-023d1955-kafka-clients-549c5b4b6-kqfhv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 16:58:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:58:53 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-connect is present
2022-04-05 16:58:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 exec my-cluster-023d1955-kafka-clients-549c5b4b6-kqfhv -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-connect&operation=From_my-topic-393385696-616334554
2022-04-05 16:58:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:58:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 16:58:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerStreamsConnectService
2022-04-05 16:58:53 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-023d1955-allow in namespace namespace-4
2022-04-05 16:58:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-023d1955 in namespace namespace-4
2022-04-05 16:58:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-023d1955-kafka-clients in namespace namespace-4
2022-04-05 16:58:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-023d1955-hello-world-producer in namespace namespace-4
2022-04-05 16:58:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-023d1955-hello-world-consumer in namespace namespace-4
2022-04-05 16:58:53 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-023d1955 in namespace namespace-4
2022-04-05 16:58:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-023d1955 in namespace namespace-4
2022-04-05 16:59:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-458131512-383053166 in namespace namespace-4
2022-04-05 16:59:03 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-023d1955-scraper in namespace namespace-4
2022-04-05 16:59:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-4 delete -f -
2022-04-05 16:59:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 16:59:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:59:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-393385696-616334554 in namespace namespace-4
2022-04-05 16:59:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 16:59:43 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-4 for test case:testProducerConsumerStreamsConnectService
2022-04-05 16:59:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsConnectService-FINISHED
2022-04-05 16:59:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 16:59:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 16:59:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testKafkaBridgeService-STARTED
2022-04-05 16:59:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 16:59:48 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-5 for test case:testKafkaBridgeService
2022-04-05 16:59:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-5
2022-04-05 16:59:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-5
2022-04-05 16:59:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-5
2022-04-05 16:59:49 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-05 16:59:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 apply -f -
2022-04-05 16:59:49 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 16:59:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 16:59:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-05 16:59:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-05 16:59:54 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-05 17:00:04 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-05 17:00:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a7aa9228-kafka-clients in namespace namespace-5
2022-04-05 17:00:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-05 17:00:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a7aa9228-kafka-clients will be ready
2022-04-05 17:00:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a7aa9228-kafka-clients is ready
2022-04-05 17:00:05 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 17:00:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a7aa9228 in namespace namespace-5
2022-04-05 17:00:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-05 17:00:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a7aa9228 will have desired state: Ready
2022-04-05 17:01:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a7aa9228 is in desired state: Ready
2022-04-05 17:01:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-a7aa9228 in namespace namespace-5
2022-04-05 17:01:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-05 17:01:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-a7aa9228 will have desired state: Ready
2022-04-05 17:01:46 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-a7aa9228 is in desired state: Ready
2022-04-05 17:01:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1352206944-1997673252 in namespace namespace-5
2022-04-05 17:01:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-05 17:01:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1352206944-1997673252 will have desired state: Ready
2022-04-05 17:01:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1352206944-1997673252 is in desired state: Ready
2022-04-05 17:01:47 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 17:01:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer in namespace namespace-5
2022-04-05 17:01:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-05 17:01:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer will be in active state
2022-04-05 17:01:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-a7aa9228-hello-world-consumer in namespace namespace-5
2022-04-05 17:01:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-5
2022-04-05 17:01:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-a7aa9228-hello-world-consumer will be in active state
2022-04-05 17:01:49 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer to finished
2022-04-05 17:03:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-a7aa9228-kafka-clients-5bc9b4686d-d9dfg -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:03:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:03:38 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-kafka-bridge is present
2022-04-05 17:03:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 exec my-cluster-a7aa9228-kafka-clients-5bc9b4686d-d9dfg -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-kafka-bridge
2022-04-05 17:03:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:03:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:03:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeService
2022-04-05 17:03:38 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1352206944-1997673252 in namespace namespace-5
2022-04-05 17:03:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a7aa9228-kafka-clients in namespace namespace-5
2022-04-05 17:03:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a7aa9228 in namespace namespace-5
2022-04-05 17:03:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-5 delete -f -
2022-04-05 17:03:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:03:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:03:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-a7aa9228-hello-world-consumer in namespace namespace-5
2022-04-05 17:03:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer in namespace namespace-5
2022-04-05 17:03:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-a7aa9228 in namespace namespace-5
2022-04-05 17:04:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:04:18 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-5 for test case:testKafkaBridgeService
2022-04-05 17:04:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testKafkaBridgeService-FINISHED
2022-04-05 17:04:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:04:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:04:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsService-STARTED
2022-04-05 17:04:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:04:29 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-6 for test case:testProducerConsumerStreamsService
2022-04-05 17:04:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-6
2022-04-05 17:04:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-6
2022-04-05 17:04:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-6
2022-04-05 17:04:29 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-05 17:04:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 apply -f -
2022-04-05 17:04:30 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:04:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:04:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-05 17:04:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-05 17:04:38 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-05 17:04:48 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-05 17:04:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-befe7095-kafka-clients in namespace namespace-6
2022-04-05 17:04:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:04:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-befe7095-kafka-clients will be ready
2022-04-05 17:04:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-befe7095-kafka-clients is ready
2022-04-05 17:04:49 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 17:04:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-befe7095 in namespace namespace-6
2022-04-05 17:04:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:04:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-befe7095 will have desired state: Ready
2022-04-05 17:06:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-befe7095 is in desired state: Ready
2022-04-05 17:06:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-412929076-2116072063 in namespace namespace-6
2022-04-05 17:06:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:06:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-412929076-2116072063 will have desired state: Ready
2022-04-05 17:06:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-412929076-2116072063 is in desired state: Ready
2022-04-05 17:06:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-815269921-954889409 in namespace namespace-6
2022-04-05 17:06:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:06:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-815269921-954889409 will have desired state: Ready
2022-04-05 17:06:07 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-815269921-954889409 is in desired state: Ready
2022-04-05 17:06:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-befe7095-hello-world-producer in namespace namespace-6
2022-04-05 17:06:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:06:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-befe7095-hello-world-producer will be in active state
2022-04-05 17:06:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-befe7095-kafka-clients-57768dd69b-4w2bw -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-befe7095-kafka-clients-57768dd69b-4w2bw -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:10 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-producer is not present. Present services are ["jaeger-query"].
2022-04-05 17:06:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-befe7095-kafka-clients-57768dd69b-4w2bw -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:11 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-05 17:06:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-befe7095-kafka-clients-57768dd69b-4w2bw -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer
2022-04-05 17:06:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-befe7095-hello-world-consumer in namespace namespace-6
2022-04-05 17:06:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:06:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-befe7095-hello-world-consumer will be in active state
2022-04-05 17:06:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-befe7095-kafka-clients-57768dd69b-4w2bw -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:13 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-05 17:06:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-befe7095-kafka-clients-57768dd69b-4w2bw -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:14 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-05 17:06:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-befe7095-kafka-clients-57768dd69b-4w2bw -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:15 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-05 17:06:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-befe7095-kafka-clients-57768dd69b-4w2bw -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:16 [main] [32mINFO [m [TracingUtils:50] Jaeger service hello-world-consumer is not present. Present services are ["jaeger-query","hello-world-producer"].
2022-04-05 17:06:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-befe7095-kafka-clients-57768dd69b-4w2bw -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:06:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:18 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-05 17:06:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 exec my-cluster-befe7095-kafka-clients-57768dd69b-4w2bw -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer
2022-04-05 17:06:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-streams in namespace namespace-6
2022-04-05 17:06:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-6
2022-04-05 17:06:18 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-streams will be in active state
2022-04-05 17:06:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:06:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerStreamsService
2022-04-05 17:06:19 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-befe7095-hello-world-producer in namespace namespace-6
2022-04-05 17:06:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-befe7095 in namespace namespace-6
2022-04-05 17:06:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-streams in namespace namespace-6
2022-04-05 17:06:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-befe7095-kafka-clients in namespace namespace-6
2022-04-05 17:06:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-815269921-954889409 in namespace namespace-6
2022-04-05 17:06:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-befe7095-hello-world-consumer in namespace namespace-6
2022-04-05 17:06:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-6 delete -f -
2022-04-05 17:06:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:06:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:06:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-412929076-2116072063 in namespace namespace-6
2022-04-05 17:07:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:07:09 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-6 for test case:testProducerConsumerStreamsService
2022-04-05 17:07:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerStreamsService-FINISHED
2022-04-05 17:07:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:07:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:07:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMakerService-STARTED
2022-04-05 17:07:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:07:14 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-7 for test case:testProducerConsumerMirrorMakerService
2022-04-05 17:07:14 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-7
2022-04-05 17:07:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-7
2022-04-05 17:07:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-7
2022-04-05 17:07:15 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-05 17:07:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 apply -f -
2022-04-05 17:07:15 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:07:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:07:15 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-05 17:07:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-05 17:07:18 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-05 17:07:28 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-05 17:07:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b16c15ed-kafka-clients in namespace namespace-7
2022-04-05 17:07:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:07:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b16c15ed-kafka-clients will be ready
2022-04-05 17:07:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b16c15ed-kafka-clients is ready
2022-04-05 17:07:30 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 17:07:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b16c15ed in namespace namespace-7
2022-04-05 17:07:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:07:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b16c15ed will have desired state: Ready
2022-04-05 17:08:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b16c15ed is in desired state: Ready
2022-04-05 17:08:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b16c15ed-target in namespace namespace-7
2022-04-05 17:08:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:08:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b16c15ed-target will have desired state: Ready
2022-04-05 17:10:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b16c15ed-target is in desired state: Ready
2022-04-05 17:10:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1602496474-1998545169 in namespace namespace-7
2022-04-05 17:10:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:10:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1602496474-1998545169 will have desired state: Ready
2022-04-05 17:10:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1602496474-1998545169 is in desired state: Ready
2022-04-05 17:10:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1602496474-1998545169-target in namespace namespace-7
2022-04-05 17:10:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:10:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1602496474-1998545169-target will have desired state: Ready
2022-04-05 17:10:02 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1602496474-1998545169-target is in desired state: Ready
2022-04-05 17:10:02 [main] [32mINFO [m [TracingST:267] Setting for kafka source plain bootstrap:my-cluster-b16c15ed-kafka-bootstrap:9092
2022-04-05 17:10:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-b16c15ed-hello-world-producer in namespace namespace-7
2022-04-05 17:10:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:10:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-b16c15ed-hello-world-producer will be in active state
2022-04-05 17:10:02 [main] [32mINFO [m [TracingST:276] Setting for kafka target plain bootstrap:my-cluster-b16c15ed-target-kafka-bootstrap:9092
2022-04-05 17:10:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-b16c15ed-hello-world-consumer in namespace namespace-7
2022-04-05 17:10:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:10:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-b16c15ed-hello-world-consumer will be in active state
2022-04-05 17:10:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-b16c15ed in namespace namespace-7
2022-04-05 17:10:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-7
2022-04-05 17:10:03 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkamirrormakers' with unstable version 'v1beta2'
2022-04-05 17:10:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-b16c15ed will have desired state: Ready
2022-04-05 17:11:05 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-b16c15ed is in desired state: Ready
2022-04-05 17:11:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-b16c15ed-kafka-clients-5459f9655b-2lgd9 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:11:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:05 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-05 17:11:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-b16c15ed-kafka-clients-5459f9655b-2lgd9 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-1602496474-1998545169
2022-04-05 17:11:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-b16c15ed-kafka-clients-5459f9655b-2lgd9 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:11:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:06 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-05 17:11:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-b16c15ed-kafka-clients-5459f9655b-2lgd9 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-topic-1602496474-1998545169
2022-04-05 17:11:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-b16c15ed-kafka-clients-5459f9655b-2lgd9 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:11:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:06 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker is present
2022-04-05 17:11:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-b16c15ed-kafka-clients-5459f9655b-2lgd9 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker&operation=From_my-topic-1602496474-1998545169
2022-04-05 17:11:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-b16c15ed-kafka-clients-5459f9655b-2lgd9 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:11:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:07 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker is present
2022-04-05 17:11:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 exec my-cluster-b16c15ed-kafka-clients-5459f9655b-2lgd9 -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker&operation=To_my-topic-1602496474-1998545169
2022-04-05 17:11:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:11:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMakerService
2022-04-05 17:11:07 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1602496474-1998545169-target in namespace namespace-7
2022-04-05 17:11:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b16c15ed-kafka-clients in namespace namespace-7
2022-04-05 17:11:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b16c15ed in namespace namespace-7
2022-04-05 17:11:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-b16c15ed-hello-world-consumer in namespace namespace-7
2022-04-05 17:11:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-b16c15ed in namespace namespace-7
2022-04-05 17:11:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b16c15ed-target in namespace namespace-7
2022-04-05 17:11:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1602496474-1998545169 in namespace namespace-7
2022-04-05 17:11:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-b16c15ed-hello-world-producer in namespace namespace-7
2022-04-05 17:11:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-7 delete -f -
2022-04-05 17:11:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:11:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:11:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:11:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-7 for test case:testProducerConsumerMirrorMakerService
2022-04-05 17:12:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMakerService-FINISHED
2022-04-05 17:12:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:12:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:12:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMaker2Service-STARTED
2022-04-05 17:12:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:12:03 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-8 for test case:testProducerConsumerMirrorMaker2Service
2022-04-05 17:12:03 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-8
2022-04-05 17:12:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-8
2022-04-05 17:12:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-8
2022-04-05 17:12:03 [main] [32mINFO [m [TracingST:531] === Applying jaeger instance install file ===
2022-04-05 17:12:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 apply -f -
2022-04-05 17:12:03 [main] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:12:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:12:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-jaeger will be ready
2022-04-05 17:12:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-jaeger is ready
2022-04-05 17:12:12 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-jaeger to be ready
2022-04-05 17:12:22 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-jaeger is ready
2022-04-05 17:12:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-28898588-kafka-clients in namespace namespace-8
2022-04-05 17:12:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:12:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-28898588-kafka-clients will be ready
2022-04-05 17:12:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-28898588-kafka-clients is ready
2022-04-05 17:12:24 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 17:12:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-28898588 in namespace namespace-8
2022-04-05 17:12:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:12:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-28898588 will have desired state: Ready
2022-04-05 17:13:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-28898588 is in desired state: Ready
2022-04-05 17:13:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-28898588-target in namespace namespace-8
2022-04-05 17:13:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:13:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-28898588-target will have desired state: Ready
2022-04-05 17:14:54 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-28898588-target is in desired state: Ready
2022-04-05 17:14:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1939510791-773449828 in namespace namespace-8
2022-04-05 17:14:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:14:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1939510791-773449828 will have desired state: Ready
2022-04-05 17:14:55 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1939510791-773449828 is in desired state: Ready
2022-04-05 17:14:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-28898588.my-topic-1939510791-773449828 in namespace namespace-8
2022-04-05 17:14:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:14:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-28898588.my-topic-1939510791-773449828 will have desired state: Ready
2022-04-05 17:14:56 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-28898588.my-topic-1939510791-773449828 is in desired state: Ready
2022-04-05 17:14:56 [main] [32mINFO [m [TracingST:177] Setting for kafka source plain bootstrap:my-cluster-28898588-kafka-bootstrap:9092
2022-04-05 17:14:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-28898588-hello-world-producer in namespace namespace-8
2022-04-05 17:14:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:14:56 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-28898588-hello-world-producer will be in active state
2022-04-05 17:14:57 [main] [32mINFO [m [TracingST:186] Setting for kafka target plain bootstrap:my-cluster-28898588-target-kafka-bootstrap:9092
2022-04-05 17:14:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-28898588-hello-world-consumer in namespace namespace-8
2022-04-05 17:14:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:14:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-28898588-hello-world-consumer will be in active state
2022-04-05 17:14:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-28898588 in namespace namespace-8
2022-04-05 17:14:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-8
2022-04-05 17:14:58 [main] [33mWARN [m [VersionUsageUtils:60] The client is using resource type 'kafkamirrormaker2s' with unstable version 'v1beta2'
2022-04-05 17:14:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-28898588 will have desired state: Ready
2022-04-05 17:16:09 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-28898588 is in desired state: Ready
2022-04-05 17:16:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-28898588-kafka-clients-76c4c78d98-6rgpc -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:16:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:10 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-producer is present
2022-04-05 17:16:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-28898588-kafka-clients-76c4c78d98-6rgpc -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-producer&operation=To_my-topic-1939510791-773449828
2022-04-05 17:16:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-28898588-kafka-clients-76c4c78d98-6rgpc -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:16:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:11 [main] [32mINFO [m [TracingUtils:47] Jaeger service hello-world-consumer is present
2022-04-05 17:16:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-28898588-kafka-clients-76c4c78d98-6rgpc -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=hello-world-consumer&operation=From_my-cluster-28898588.my-topic-1939510791-773449828
2022-04-05 17:16:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-28898588-kafka-clients-76c4c78d98-6rgpc -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:16:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:11 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker2 is present
2022-04-05 17:16:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-28898588-kafka-clients-76c4c78d98-6rgpc -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker2&operation=From_my-topic-1939510791-773449828
2022-04-05 17:16:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-28898588-kafka-clients-76c4c78d98-6rgpc -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/services
2022-04-05 17:16:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:12 [main] [32mINFO [m [TracingUtils:47] Jaeger service my-mirror-maker2 is present
2022-04-05 17:16:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 exec my-cluster-28898588-kafka-clients-76c4c78d98-6rgpc -- /bin/bash -c curl my-jaeger-query:16686/jaeger/api/traces?service=my-mirror-maker2&operation=To_my-cluster-28898588.my-topic-1939510791-773449828
2022-04-05 17:16:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:16:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:16:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker2Service
2022-04-05 17:16:12 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-28898588.my-topic-1939510791-773449828 in namespace namespace-8
2022-04-05 17:16:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-28898588 in namespace namespace-8
2022-04-05 17:16:12 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-28898588-hello-world-consumer in namespace namespace-8
2022-04-05 17:16:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-28898588-hello-world-producer in namespace namespace-8
2022-04-05 17:16:12 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-28898588 in namespace namespace-8
2022-04-05 17:16:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-28898588-kafka-clients in namespace namespace-8
2022-04-05 17:16:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-28898588-target in namespace namespace-8
2022-04-05 17:16:22 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1939510791-773449828 in namespace namespace-8
2022-04-05 17:16:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-8 delete -f -
2022-04-05 17:16:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Input: ---
apiVersion: "jaegertracing.io/v1"
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: "allInOne"
  allInOne:
    image: "jaegertracing/all-in-one:1.20"
    options:
      log-level: "debug"
      query:
        base-path: "/jaeger"
  ingress:
    openshift: {}
    resources: {}
    security: "none"
  ui:
    options:
      dependencies:
        menuEnabled: false
      tracking:
        gaID: "UA-000000-2"
      menu:
      - label: "About Jaeger"
        items:
        - label: "Documentation"
          url: "https://www.jaegertracing.io/docs/latest"
  storage:
    options:
      memory:
        max-traces: 100000
2022-04-05 17:16:22 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:17:02 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-8 for test case:testProducerConsumerMirrorMaker2Service
2022-04-05 17:17:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.tracing.TracingST.testProducerConsumerMirrorMaker2Service-FINISHED
2022-04-05 17:17:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:17:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:17:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for TracingST
2022-04-05 17:17:09 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy jaeger-allow in namespace tracing-st
2022-04-05 17:17:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Input: ---
apiVersion: "v1"
kind: "ServiceAccount"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
2022-04-05 17:17:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "Role"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "image.openshift.io"
  resources:
  - "imagestreams"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-05 17:17:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Input: ---
kind: "RoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
roleRef:
  kind: "Role"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-05 17:17:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Input: ---
apiVersion: "apps/v1"
kind: "Deployment"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
spec:
  replicas: 1
  selector:
    matchLabels:
      name: "jaeger-operator"
  template:
    metadata:
      labels:
        name: "jaeger-operator"
    spec:
      serviceAccountName: "jaeger-operator"
      containers:
      - name: "jaeger-operator"
        image: "jaegertracing/jaeger-operator:1.20.0"
        ports:
        - containerPort: 8383
          name: "http-metrics"
        - containerPort: 8686
          name: "cr-metrics"
        args:
        - "start"
        - "--kafka-provision=no"
        imagePullPolicy: "Always"
        env:
        - name: "WATCH_NAMESPACE"
          value: ""
        - name: "POD_NAME"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.name"
        - name: "POD_NAMESPACE"
          valueFrom:
            fieldRef:
              fieldPath: "metadata.namespace"
        - name: "OPERATOR_NAME"
          value: "jaeger-operator"
2022-04-05 17:17:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Input: ---
apiVersion: "rbac.authorization.k8s.io/v1"
kind: "ClusterRole"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
rules:
- apiGroups:
  - "jaegertracing.io"
  resources:
  - "*"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resourceNames:
  - "jaeger-operator"
  resources:
  - "deployments/finalizers"
  verbs:
  - "update"
- apiGroups:
  - ""
  resources:
  - "configmaps"
  - "persistentvolumeclaims"
  - "pods"
  - "secrets"
  - "serviceaccounts"
  - "services"
  - "services/finalizers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  - "daemonsets"
  - "replicasets"
  - "statefulsets"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "extensions"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "networking.k8s.io"
  resources:
  - "ingresses"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "batch"
  resources:
  - "jobs"
  - "cronjobs"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "route.openshift.io"
  resources:
  - "routes"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "console.openshift.io"
  resources:
  - "consolelinks"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "autoscaling"
  resources:
  - "horizontalpodautoscalers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "monitoring.coreos.com"
  resources:
  - "servicemonitors"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "logging.openshift.io"
  resources:
  - "elasticsearches"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "kafka.strimzi.io"
  resources:
  - "kafkas"
  - "kafkausers"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - ""
  resources:
  - "namespaces"
  verbs:
  - "get"
  - "list"
  - "watch"
- apiGroups:
  - "apps"
  resources:
  - "deployments"
  verbs:
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - "clusterrolebindings"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "watch"
2022-04-05 17:17:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Command: kubectl --namespace tracing-st delete -f -
2022-04-05 17:17:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Input: ---
kind: "ClusterRoleBinding"
apiVersion: "rbac.authorization.k8s.io/v1"
metadata:
  name: "jaeger-operator"
  namespace: "tracing-st"
subjects:
- kind: "ServiceAccount"
  name: "jaeger-operator"
  namespace: "tracing-st"
roleRef:
  kind: "ClusterRole"
  name: "jaeger-operator"
  apiGroup: "rbac.authorization.k8s.io"
2022-04-05 17:17:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:17:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,322.517 s - in io.strimzi.systemtest.tracing.TracingST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
2022-04-05 17:17:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-api-st
2022-04-05 17:17:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-api-st
2022-04-05 17:17:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-api-st
2022-04-05 17:17:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:17:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequests-STARTED
2022-04-05 17:17:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:17:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-9 for test case:testCruiseControlBasicAPIRequests
2022-04-05 17:17:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-9
2022-04-05 17:17:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-9
2022-04-05 17:17:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-9
2022-04-05 17:17:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3104a1b8 in namespace namespace-9
2022-04-05 17:17:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-9
2022-04-05 17:17:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3104a1b8 will have desired state: Ready
2022-04-05 17:19:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3104a1b8 is in desired state: Ready
2022-04-05 17:19:03 [main] [32mINFO [m [CruiseControlApiST:48] ----> CRUISE CONTROL DEPLOYMENT STATE ENDPOINT <----
2022-04-05 17:19:03 [main] [32mINFO [m [CruiseControlApiST:58] Verifying that Cruise Control REST API is available
2022-04-05 17:19:03 [main] [32mINFO [m [CruiseControlApiST:66] ----> KAFKA REBALANCE <----
2022-04-05 17:19:03 [main] [32mINFO [m [CruiseControlApiST:73] Waiting for CC will have for enough metrics to be recorded to make a proposal 
2022-04-05 17:21:00 [main] [32mINFO [m [CruiseControlApiST:97] ----> EXECUTION OF STOP PROPOSAL <----
2022-04-05 17:21:00 [main] [32mINFO [m [CruiseControlApiST:108] ----> USER TASKS <----
2022-04-05 17:21:01 [main] [32mINFO [m [CruiseControlApiST:126] Verifying that Cruise Control REST API doesn't allow HTTP requests
2022-04-05 17:21:01 [main] [32mINFO [m [CruiseControlApiST:132] Verifying that Cruise Control REST API doesn't allow unauthenticated requests
2022-04-05 17:21:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:21:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlBasicAPIRequests
2022-04-05 17:21:01 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3104a1b8 in namespace namespace-9
2022-04-05 17:21:01 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-9, for cruise control Kafka cluster my-cluster-3104a1b8
2022-04-05 17:21:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:21:11 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-9 for test case:testCruiseControlBasicAPIRequests
2022-04-05 17:21:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequests-FINISHED
2022-04-05 17:21:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:21:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:21:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequestsWithSecurityDisabled-STARTED
2022-04-05 17:21:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:21:54 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-10 for test case:testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-05 17:21:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-10
2022-04-05 17:21:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-10
2022-04-05 17:21:54 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-10
2022-04-05 17:21:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka cruise-control-api-cluster-name in namespace namespace-10
2022-04-05 17:21:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-10
2022-04-05 17:21:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: cruise-control-api-cluster-name will have desired state: Ready
2022-04-05 17:23:36 [main] [32mINFO [m [ResourceManager:444] Kafka: cruise-control-api-cluster-name is in desired state: Ready
2022-04-05 17:23:36 [main] [32mINFO [m [CruiseControlApiST:153] ----> CRUISE CONTROL DEPLOYMENT STATE ENDPOINT <----
2022-04-05 17:23:36 [main] [32mINFO [m [CruiseControlApiST:157] Verifying that Cruise Control REST API is available using HTTP request without credentials
2022-04-05 17:23:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:23:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-05 17:23:36 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka cruise-control-api-cluster-name in namespace namespace-10
2022-04-05 17:23:36 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-10, for cruise control Kafka cluster cruise-control-api-cluster-name
2022-04-05 17:23:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:23:46 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-10 for test case:testCruiseControlBasicAPIRequestsWithSecurityDisabled
2022-04-05 17:24:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlApiST.testCruiseControlBasicAPIRequestsWithSecurityDisabled-FINISHED
2022-04-05 17:24:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:24:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:24:29 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlApiST is everything deleted.
2022-04-05 17:24:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 433.882 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlApiST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
2022-04-05 17:24:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-configuration-st
2022-04-05 17:24:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-configuration-st
2022-04-05 17:24:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-configuration-st
2022-04-05 17:24:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:24:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationFileIsCreated-STARTED
2022-04-05 17:24:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:24:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-11 for test case:testConfigurationFileIsCreated
2022-04-05 17:24:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-11
2022-04-05 17:24:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-11
2022-04-05 17:24:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-11
2022-04-05 17:24:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-44baf9cf in namespace namespace-11
2022-04-05 17:24:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-11
2022-04-05 17:24:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-44baf9cf will have desired state: Ready
2022-04-05 17:26:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-44baf9cf is in desired state: Ready
2022-04-05 17:26:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-11 exec my-cluster-44baf9cf-cruise-control-6d568f8b4c-glnmw -- /bin/bash -c cat /tmp/cruisecontrol.properties
2022-04-05 17:26:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:26:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:26:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationFileIsCreated
2022-04-05 17:26:11 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-44baf9cf in namespace namespace-11
2022-04-05 17:26:11 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-11, for cruise control Kafka cluster my-cluster-44baf9cf
2022-04-05 17:26:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:26:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-11 for test case:testConfigurationFileIsCreated
2022-04-05 17:27:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationFileIsCreated-FINISHED
2022-04-05 17:27:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:27:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:27:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl-STARTED
2022-04-05 17:27:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:27:04 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-12 for test case:testDeployAndUnDeployCruiseControl
2022-04-05 17:27:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-12
2022-04-05 17:27:05 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-12
2022-04-05 17:27:05 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-12
2022-04-05 17:27:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c62fcedb in namespace namespace-12
2022-04-05 17:27:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-12
2022-04-05 17:27:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c62fcedb will have desired state: Ready
2022-04-05 17:28:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c62fcedb is in desired state: Ready
2022-04-05 17:28:43 [main] [32mINFO [m [CruiseControlConfigurationST:111] Removing Cruise Control to the classic Kafka.
2022-04-05 17:28:43 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c62fcedb-kafka rolling update
2022-04-05 17:29:53 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c62fcedb-kafka has been successfully rolled
2022-04-05 17:29:53 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-c62fcedb-kafka to be ready
2022-04-05 17:30:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c62fcedb will have desired state: Ready
2022-04-05 17:30:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c62fcedb is in desired state: Ready
2022-04-05 17:30:14 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-c62fcedb is ready
2022-04-05 17:30:14 [main] [32mINFO [m [CruiseControlConfigurationST:117] Verifying that in Cruise Control is not present in the Kafka cluster
2022-04-05 17:30:14 [main] [32mINFO [m [CruiseControlConfigurationST:120] Verifying that my-cluster-c62fcedb-cruise-control- pod is not present
2022-04-05 17:30:14 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-c62fcedb-cruise-control- will have stable 0 replicas
2022-04-05 17:30:14 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 17:30:15 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 17:30:16 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 17:30:17 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-05 17:30:18 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-05 17:30:19 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-05 17:30:20 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-05 17:30:21 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-05 17:30:22 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-05 17:30:23 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-05 17:30:24 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-05 17:30:25 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-05 17:30:26 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-05 17:30:27 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-05 17:30:28 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-05 17:30:29 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-05 17:30:30 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-05 17:30:31 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-05 17:30:32 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-05 17:30:33 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-05 17:30:34 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-05 17:30:35 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-05 17:30:36 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-05 17:30:36 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-c62fcedb-cruise-control- has 0 replicas
2022-04-05 17:30:36 [main] [32mINFO [m [CruiseControlConfigurationST:123] Verifying that in Kafka config map there is no configuration to cruise control metric reporter
2022-04-05 17:32:36 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Verify that kafka configuration {cluster-name=my-cluster-c62fcedb} has correct cruise control metric reporter properties, null
io.strimzi.test.WaitException: Timeout after 120000 ms waiting for Verify that kafka configuration {cluster-name=my-cluster-c62fcedb} has correct cruise control metric reporter properties
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.specific.CruiseControlUtils.verifyCruiseControlMetricReporterConfigurationInKafkaConfigMapIsPresent(CruiseControlUtils.java:83)
	at io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.lambda$testDeployAndUnDeployCruiseControl$1(CruiseControlConfigurationST.java:124)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:55)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:37)
	at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3082)
	at io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl(CruiseControlConfigurationST.java:124)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-05 17:32:36 [main] [32mINFO [m [CruiseControlConfigurationST:126] Cruise Control topics will not be deleted and will stay in the Kafka cluster
2022-04-05 17:32:36 [main] [32mINFO [m [CruiseControlConfigurationST:130] Adding Cruise Control to the classic Kafka.
2022-04-05 17:32:36 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-c62fcedb-kafka rolling update
2022-04-05 17:34:02 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-c62fcedb-kafka has been successfully rolled
2022-04-05 17:34:02 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-c62fcedb-kafka to be ready
2022-04-05 17:34:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c62fcedb will have desired state: Ready
2022-04-05 17:34:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c62fcedb is in desired state: Ready
2022-04-05 17:34:31 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-c62fcedb is ready
2022-04-05 17:34:31 [main] [32mINFO [m [CruiseControlConfigurationST:136] Verifying that in Kafka config map there is configuration to cruise control metric reporter
2022-04-05 17:34:31 [main] [32mINFO [m [CruiseControlConfigurationST:139] Verifying that Cruise Control topics are created after CC is instantiated.
2022-04-05 17:34:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:34:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployAndUnDeployCruiseControl
2022-04-05 17:34:31 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c62fcedb in namespace namespace-12
2022-04-05 17:34:31 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-12, for cruise control Kafka cluster my-cluster-c62fcedb
2022-04-05 17:34:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:34:41 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-12 for test case:testDeployAndUnDeployCruiseControl
2022-04-05 17:35:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testDeployAndUnDeployCruiseControl-FINISHED
2022-04-05 17:35:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:35:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:35:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationPerformanceOptions-STARTED
2022-04-05 17:35:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:35:08 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-13 for test case:testConfigurationPerformanceOptions
2022-04-05 17:35:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-13
2022-04-05 17:35:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-13
2022-04-05 17:35:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-13
2022-04-05 17:35:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ce72cd7d in namespace namespace-13
2022-04-05 17:35:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-13
2022-04-05 17:35:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ce72cd7d will have desired state: Ready
2022-04-05 17:36:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ce72cd7d is in desired state: Ready
2022-04-05 17:36:41 [main] [32mINFO [m [CruiseControlConfigurationST:271] Changing cruise control performance tuning options
2022-04-05 17:36:41 [main] [32mINFO [m [CruiseControlConfigurationST:277] Verifying that CC pod is rolling, after changing options
2022-04-05 17:36:41 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-ce72cd7d-cruise-control rolling update
2022-04-05 17:37:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ce72cd7d-cruise-control will be ready
2022-04-05 17:37:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ce72cd7d-cruise-control is ready
2022-04-05 17:37:27 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-ce72cd7d-cruise-control rolling update finished
2022-04-05 17:37:27 [main] [32mINFO [m [CruiseControlConfigurationST:280] Verifying that Kafka pods did not roll
2022-04-05 17:37:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 50
2022-04-05 17:37:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 49
2022-04-05 17:37:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 48
2022-04-05 17:37:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 47
2022-04-05 17:37:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 46
2022-04-05 17:37:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 45
2022-04-05 17:37:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 44
2022-04-05 17:37:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 43
2022-04-05 17:37:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 42
2022-04-05 17:37:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 41
2022-04-05 17:37:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 40
2022-04-05 17:37:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 39
2022-04-05 17:37:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 38
2022-04-05 17:37:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 37
2022-04-05 17:37:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 36
2022-04-05 17:37:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 35
2022-04-05 17:37:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 34
2022-04-05 17:37:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 33
2022-04-05 17:37:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 32
2022-04-05 17:37:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 31
2022-04-05 17:37:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 30
2022-04-05 17:37:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 29
2022-04-05 17:37:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 28
2022-04-05 17:37:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 27
2022-04-05 17:37:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 26
2022-04-05 17:37:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 25
2022-04-05 17:37:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 24
2022-04-05 17:37:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 23
2022-04-05 17:37:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 22
2022-04-05 17:37:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 21
2022-04-05 17:37:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 20
2022-04-05 17:37:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 19
2022-04-05 17:37:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 18
2022-04-05 17:38:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 17
2022-04-05 17:38:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 16
2022-04-05 17:38:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 15
2022-04-05 17:38:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 14
2022-04-05 17:38:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 13
2022-04-05 17:38:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 12
2022-04-05 17:38:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 11
2022-04-05 17:38:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 10
2022-04-05 17:38:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 9
2022-04-05 17:38:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 8
2022-04-05 17:38:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 7
2022-04-05 17:38:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 6
2022-04-05 17:38:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 5
2022-04-05 17:38:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 4
2022-04-05 17:38:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 3
2022-04-05 17:38:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 2
2022-04-05 17:38:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 1
2022-04-05 17:38:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-ce72cd7d-kafka-2=71b98847-3555-434b-bd3a-b4bdd2c0bd36, my-cluster-ce72cd7d-kafka-1=64b9715c-07ea-4f96-a4f7-361cc8d7e5b7, my-cluster-ce72cd7d-kafka-0=f16194f2-82dd-4372-a4e1-881a74d78ceb} pods didn't roll. Remaining seconds for stability: 0
2022-04-05 17:38:17 [main] [32mINFO [m [CruiseControlConfigurationST:283] Verifying new configuration in the Kafka CR
2022-04-05 17:38:17 [main] [32mINFO [m [CruiseControlConfigurationST:300] Verifying Cruise control performance options are set in Kafka CR
2022-04-05 17:38:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:38:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationPerformanceOptions
2022-04-05 17:38:17 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ce72cd7d in namespace namespace-13
2022-04-05 17:38:17 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-13, for cruise control Kafka cluster my-cluster-ce72cd7d
2022-04-05 17:38:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:38:27 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-13 for test case:testConfigurationPerformanceOptions
2022-04-05 17:39:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationPerformanceOptions-FINISHED
2022-04-05 17:39:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:39:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:39:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationReflection-STARTED
2022-04-05 17:39:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:39:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-14 for test case:testConfigurationReflection
2022-04-05 17:39:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-14
2022-04-05 17:39:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-14
2022-04-05 17:39:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-14
2022-04-05 17:39:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7772b419 in namespace namespace-14
2022-04-05 17:39:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-14
2022-04-05 17:39:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7772b419 will have desired state: Ready
2022-04-05 17:40:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7772b419 is in desired state: Ready
2022-04-05 17:40:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-14 exec my-cluster-7772b419-cruise-control-79495b445b-nkfmk -- /bin/bash -c cat /tmp/cruisecontrol.properties
2022-04-05 17:40:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:40:45 [main] [32mINFO [m [CruiseControlConfigurationST:221] Verifying that all configuration in the cruise control container matching the cruise control file /tmp/cruisecontrol.properties properties
2022-04-05 17:40:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:40:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationReflection
2022-04-05 17:40:45 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7772b419 in namespace namespace-14
2022-04-05 17:40:45 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-14, for cruise control Kafka cluster my-cluster-7772b419
2022-04-05 17:40:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:40:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-14 for test case:testConfigurationReflection
2022-04-05 17:41:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationReflection-FINISHED
2022-04-05 17:41:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:41:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:41:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods-STARTED
2022-04-05 17:41:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:41:39 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-15 for test case:testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-05 17:41:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-15
2022-04-05 17:41:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-15
2022-04-05 17:41:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-15
2022-04-05 17:41:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-45e679d8 in namespace namespace-15
2022-04-05 17:41:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-15
2022-04-05 17:41:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-45e679d8 will have desired state: Ready
2022-04-05 17:43:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-45e679d8 is in desired state: Ready
2022-04-05 17:43:15 [main] [32mINFO [m [CruiseControlConfigurationST:157] Changing the broker capacity of the cruise control
2022-04-05 17:43:15 [main] [32mINFO [m [CruiseControlConfigurationST:168] Verifying that CC pod is rolling, because of change size of disk
2022-04-05 17:43:15 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-45e679d8-cruise-control rolling update
2022-04-05 17:43:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-45e679d8-cruise-control will be ready
2022-04-05 17:43:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-45e679d8-cruise-control is ready
2022-04-05 17:44:00 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-45e679d8-cruise-control rolling update finished
2022-04-05 17:44:00 [main] [32mINFO [m [CruiseControlConfigurationST:171] Verifying that Kafka pods did not roll
2022-04-05 17:44:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 50
2022-04-05 17:44:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 49
2022-04-05 17:44:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 48
2022-04-05 17:44:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 47
2022-04-05 17:44:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 46
2022-04-05 17:44:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 45
2022-04-05 17:44:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 44
2022-04-05 17:44:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 43
2022-04-05 17:44:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 42
2022-04-05 17:44:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 41
2022-04-05 17:44:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 40
2022-04-05 17:44:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 39
2022-04-05 17:44:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 38
2022-04-05 17:44:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 37
2022-04-05 17:44:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 36
2022-04-05 17:44:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 35
2022-04-05 17:44:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 34
2022-04-05 17:44:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 33
2022-04-05 17:44:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 32
2022-04-05 17:44:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 31
2022-04-05 17:44:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 30
2022-04-05 17:44:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 29
2022-04-05 17:44:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 28
2022-04-05 17:44:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 27
2022-04-05 17:44:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 26
2022-04-05 17:44:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 25
2022-04-05 17:44:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 24
2022-04-05 17:44:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 23
2022-04-05 17:44:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 22
2022-04-05 17:44:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 21
2022-04-05 17:44:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 20
2022-04-05 17:44:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 19
2022-04-05 17:44:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 18
2022-04-05 17:44:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 17
2022-04-05 17:44:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 16
2022-04-05 17:44:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 15
2022-04-05 17:44:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 14
2022-04-05 17:44:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 13
2022-04-05 17:44:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 12
2022-04-05 17:44:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 11
2022-04-05 17:44:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 10
2022-04-05 17:44:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 9
2022-04-05 17:44:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 8
2022-04-05 17:44:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 7
2022-04-05 17:44:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 6
2022-04-05 17:44:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 5
2022-04-05 17:44:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 4
2022-04-05 17:44:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 3
2022-04-05 17:44:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 2
2022-04-05 17:44:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 1
2022-04-05 17:44:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-45e679d8-kafka-2=d056a9f1-6ff2-425d-bb98-b4c9400f1e00, my-cluster-45e679d8-kafka-1=47a91e85-6ed9-4cd1-a693-c42772279050, my-cluster-45e679d8-kafka-0=113aeace-4088-400a-8f07-143ee71e0dee} pods didn't roll. Remaining seconds for stability: 0
2022-04-05 17:44:51 [main] [32mINFO [m [CruiseControlConfigurationST:174] Verifying new configuration in the Kafka CR
2022-04-05 17:44:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:44:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-05 17:44:51 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-45e679d8 in namespace namespace-15
2022-04-05 17:44:51 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-15, for cruise control Kafka cluster my-cluster-45e679d8
2022-04-05 17:45:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:45:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-15 for test case:testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods
2022-04-05 17:45:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods-FINISHED
2022-04-05 17:45:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:45:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:45:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testCapacityFile-STARTED
2022-04-05 17:45:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:45:28 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-16 for test case:testCapacityFile
2022-04-05 17:45:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-16
2022-04-05 17:45:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-16
2022-04-05 17:45:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-16
2022-04-05 17:45:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f2777ceb in namespace namespace-16
2022-04-05 17:45:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-16
2022-04-05 17:45:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f2777ceb will have desired state: Ready
2022-04-05 17:47:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f2777ceb is in desired state: Ready
2022-04-05 17:47:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-16 exec my-cluster-f2777ceb-cruise-control-759c7f468f-smwzh -- /bin/bash -c cat /tmp/capacity.json
2022-04-05 17:47:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 17:47:06 [main] [32mINFO [m [CruiseControlConfigurationST:80] We got only one configuration of broker-capacities
2022-04-05 17:47:06 [main] [32mINFO [m [CruiseControlConfigurationST:83] Verifying cruise control configuration.
2022-04-05 17:47:06 [main] [32mINFO [m [CruiseControlConfigurationST:92] Verifying default cruise control capacities
2022-04-05 17:47:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:47:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCapacityFile
2022-04-05 17:47:06 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f2777ceb in namespace namespace-16
2022-04-05 17:47:06 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-16, for cruise control Kafka cluster my-cluster-f2777ceb
2022-04-05 17:47:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:47:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-16 for test case:testCapacityFile
2022-04-05 17:48:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST.testCapacityFile-FINISHED
2022-04-05 17:48:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:48:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:48:00 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlConfigurationST is everything deleted.
2022-04-05 17:48:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,410.418 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlConfigurationST
[[1;34mINFO[m] Running io.strimzi.systemtest.cruisecontrol.CruiseControlST
2022-04-05 17:48:05 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: cruise-control-st
2022-04-05 17:48:05 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: cruise-control-st
2022-04-05 17:48:05 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: cruise-control-st
2022-04-05 17:48:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:48:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlTopicExclusion-STARTED
2022-04-05 17:48:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:48:05 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-17 for test case:testCruiseControlTopicExclusion
2022-04-05 17:48:05 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-17
2022-04-05 17:48:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-17
2022-04-05 17:48:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-17
2022-04-05 17:48:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e43621dc in namespace namespace-17
2022-04-05 17:48:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-05 17:48:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e43621dc will have desired state: Ready
2022-04-05 17:49:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e43621dc is in desired state: Ready
2022-04-05 17:49:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic excluded-topic-1 in namespace namespace-17
2022-04-05 17:49:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-05 17:49:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: excluded-topic-1 will have desired state: Ready
2022-04-05 17:49:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: excluded-topic-1 is in desired state: Ready
2022-04-05 17:49:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic excluded-topic-2 in namespace namespace-17
2022-04-05 17:49:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-05 17:49:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: excluded-topic-2 will have desired state: Ready
2022-04-05 17:49:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: excluded-topic-2 is in desired state: Ready
2022-04-05 17:49:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic included-topic in namespace namespace-17
2022-04-05 17:49:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-05 17:49:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: included-topic will have desired state: Ready
2022-04-05 17:49:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: included-topic is in desired state: Ready
2022-04-05 17:49:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-e43621dc in namespace namespace-17
2022-04-05 17:49:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-17
2022-04-05 17:49:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-e43621dc will have desired state: PendingProposal
2022-04-05 17:49:52 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-e43621dc is in desired state: PendingProposal
2022-04-05 17:49:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-e43621dc will have desired state: ProposalReady
2022-04-05 17:56:42 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-e43621dc is in desired state: ProposalReady
2022-04-05 17:56:42 [main] [32mINFO [m [CruiseControlST:208] Checking status of KafkaRebalance
2022-04-05 17:56:42 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #4(test) KafkaRebalance(cruise-control-st/my-cluster-e43621dc): Annotating KafkaRebalance:my-cluster-e43621dc with annotation approve
2022-04-05 17:56:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-e43621dc will have desired state: Ready
2022-04-05 17:58:18 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-e43621dc is in desired state: Ready
2022-04-05 17:58:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 17:58:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlTopicExclusion
2022-04-05 17:58:18 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic excluded-topic-2 in namespace namespace-17
2022-04-05 17:58:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e43621dc in namespace namespace-17
2022-04-05 17:58:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic excluded-topic-1 in namespace namespace-17
2022-04-05 17:58:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-17, for cruise control Kafka cluster my-cluster-e43621dc
2022-04-05 17:58:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-e43621dc in namespace namespace-17
2022-04-05 17:58:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic included-topic in namespace namespace-17
2022-04-05 17:58:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 17:58:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-17 for test case:testCruiseControlTopicExclusion
2022-04-05 17:59:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlTopicExclusion-FINISHED
2022-04-05 17:59:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 17:59:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 17:59:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage-STARTED
2022-04-05 17:59:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 17:59:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-18 for test case:testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-05 17:59:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-18
2022-04-05 17:59:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-18
2022-04-05 17:59:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-18
2022-04-05 17:59:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-596216b0 in namespace namespace-18
2022-04-05 17:59:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-18
2022-04-05 17:59:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-596216b0 will have desired state: Ready
2022-04-05 18:00:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-596216b0 is in desired state: Ready
2022-04-05 18:00:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-596216b0 in namespace namespace-18
2022-04-05 18:00:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-18
2022-04-05 18:00:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-596216b0 will have desired state: NotReady
2022-04-05 18:00:51 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-596216b0 is in desired state: NotReady
2022-04-05 18:00:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:00:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-05 18:00:51 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-596216b0 in namespace namespace-18
2022-04-05 18:00:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-596216b0 in namespace namespace-18
2022-04-05 18:00:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-18, for cruise control Kafka cluster my-cluster-596216b0
2022-04-05 18:01:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:01:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-18 for test case:testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage
2022-04-05 18:01:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancingWithoutSpecifyingJBODStorage-FINISHED
2022-04-05 18:01:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:01:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:01:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testAutoCreationOfCruiseControlTopics-STARTED
2022-04-05 18:01:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:01:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-be49b808 in namespace cruise-control-st
2022-04-05 18:01:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-be49b808 will have desired state: Ready
2022-04-05 18:03:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-be49b808 is in desired state: Ready
2022-04-05 18:03:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.metrics will have desired state: Ready
2022-04-05 18:03:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.metrics is in desired state: Ready
2022-04-05 18:03:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples will have desired state: Ready
2022-04-05 18:03:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples is in desired state: Ready
2022-04-05 18:03:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples will have desired state: Ready
2022-04-05 18:03:25 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples is in desired state: Ready
2022-04-05 18:03:25 [main] [32mINFO [m [CruiseControlST:96] Checking partitions and replicas for strimzi.cruisecontrol.metrics
2022-04-05 18:03:25 [main] [32mINFO [m [CruiseControlST:100] Checking partitions and replicas for strimzi.cruisecontrol.modeltrainingsamples
2022-04-05 18:03:25 [main] [32mINFO [m [CruiseControlST:104] Checking partitions and replicas for strimzi.cruisecontrol.partitionmetricsamples
2022-04-05 18:03:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:03:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoCreationOfCruiseControlTopics
2022-04-05 18:03:25 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-be49b808 in namespace cruise-control-st
2022-04-05 18:03:25 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-be49b808
2022-04-05 18:03:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:03:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testAutoCreationOfCruiseControlTopics-FINISHED
2022-04-05 18:03:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:03:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:03:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlReplicaMovementStrategy-STARTED
2022-04-05 18:03:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:03:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-19 for test case:testCruiseControlReplicaMovementStrategy
2022-04-05 18:03:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-19
2022-04-05 18:03:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-19
2022-04-05 18:03:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-19
2022-04-05 18:03:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3b182eaa in namespace namespace-19
2022-04-05 18:03:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-19
2022-04-05 18:03:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3b182eaa will have desired state: Ready
2022-04-05 18:05:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3b182eaa is in desired state: Ready
2022-04-05 18:05:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3b182eaa-kafka-clients in namespace namespace-19
2022-04-05 18:05:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-19
2022-04-05 18:05:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3b182eaa-kafka-clients will be ready
2022-04-05 18:05:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3b182eaa-kafka-clients is ready
2022-04-05 18:05:22 [main] [32mINFO [m [CruiseControlST:234] Check for default CruiseControl replicaMovementStrategy in pod configuration file.
2022-04-05 18:05:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-19 exec my-cluster-3b182eaa-cruise-control-79c8b87f6c-xfg9k -c cruise-control -- cat /tmp/cruisecontrol.properties
2022-04-05 18:05:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 18:05:23 [main] [32mINFO [m [CruiseControlST:248] Set non-default CruiseControl replicaMovementStrategies to KafkaRebalance resource.
2022-04-05 18:05:23 [main] [32mINFO [m [CruiseControlST:252] Verifying that CC pod is rolling, because of change size of disk
2022-04-05 18:05:23 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-3b182eaa-cruise-control rolling update
2022-04-05 18:05:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3b182eaa-cruise-control will be ready
2022-04-05 18:05:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3b182eaa-cruise-control is ready
2022-04-05 18:06:08 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-3b182eaa-cruise-control rolling update finished
2022-04-05 18:06:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-19 exec my-cluster-3b182eaa-cruise-control-6f7cddf75-zdp9f -c cruise-control -- cat /tmp/cruisecontrol.properties
2022-04-05 18:06:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 18:06:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:06:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlReplicaMovementStrategy
2022-04-05 18:06:08 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3b182eaa-kafka-clients in namespace namespace-19
2022-04-05 18:06:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3b182eaa in namespace namespace-19
2022-04-05 18:06:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-19, for cruise control Kafka cluster my-cluster-3b182eaa
2022-04-05 18:06:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:06:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-19 for test case:testCruiseControlReplicaMovementStrategy
2022-04-05 18:07:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlReplicaMovementStrategy-FINISHED
2022-04-05 18:07:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:07:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:07:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithSingleNodeKafka-STARTED
2022-04-05 18:07:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:07:04 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-20 for test case:testCruiseControlWithSingleNodeKafka
2022-04-05 18:07:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-20
2022-04-05 18:07:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-20
2022-04-05 18:07:04 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-20
2022-04-05 18:07:04 [main] [32mINFO [m [CruiseControlST:169] Deploying single node Kafka with CruiseControl
2022-04-05 18:07:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1bafa854 in namespace namespace-20
2022-04-05 18:07:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-20
2022-04-05 18:07:08 [main] [32mINFO [m [CruiseControlST:178] Increasing Kafka nodes to 3
2022-04-05 18:07:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1bafa854 will have desired state: Ready
2022-04-05 18:08:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1bafa854 is in desired state: Ready
2022-04-05 18:08:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:08:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithSingleNodeKafka
2022-04-05 18:08:48 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1bafa854 in namespace namespace-20
2022-04-05 18:08:48 [main] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-20, for cruise control Kafka cluster my-cluster-1bafa854
2022-04-05 18:08:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:08:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-20 for test case:testCruiseControlWithSingleNodeKafka
2022-04-05 18:09:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithSingleNodeKafka-FINISHED
2022-04-05 18:09:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:09:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:09:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithRebalanceResourceAndRefreshAnnotation-STARTED
2022-04-05 18:09:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:09:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9f51fb23 in namespace cruise-control-st
2022-04-05 18:09:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9f51fb23 will have desired state: Ready
2022-04-05 18:11:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9f51fb23 is in desired state: Ready
2022-04-05 18:11:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-9f51fb23 in namespace cruise-control-st
2022-04-05 18:11:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-9f51fb23 will have desired state: PendingProposal
2022-04-05 18:11:28 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-9f51fb23 is in desired state: PendingProposal
2022-04-05 18:11:28 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): ============================================================================
2022-04-05 18:11:28 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): PendingProposal
2022-04-05 18:11:28 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): ============================================================================
2022-04-05 18:11:28 [main] [32mINFO [m [KafkaRebalanceUtils:81] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): Verifying that KafkaRebalance resource is in PendingProposal state
2022-04-05 18:11:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-9f51fb23 will have desired state: PendingProposal
2022-04-05 18:11:28 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-9f51fb23 is in desired state: PendingProposal
2022-04-05 18:11:28 [main] [32mINFO [m [KafkaRebalanceUtils:85] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): Verifying that KafkaRebalance resource is in ProposalReady state
2022-04-05 18:11:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-9f51fb23 will have desired state: ProposalReady
2022-04-05 18:16:23 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-9f51fb23 is in desired state: ProposalReady
2022-04-05 18:16:23 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): ============================================================================
2022-04-05 18:16:23 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): ProposalReady
2022-04-05 18:16:23 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): ============================================================================
2022-04-05 18:16:23 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-05 18:16:23 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): Annotating KafkaRebalance:my-cluster-9f51fb23 with annotation approve
2022-04-05 18:16:23 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-9f51fb23 annotated
2022-04-05 18:16:23 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): Verifying that annotation triggers the Rebalancing state
2022-04-05 18:16:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-9f51fb23 will have desired state: Rebalancing
2022-04-05 18:16:24 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-9f51fb23 is in desired state: Rebalancing
2022-04-05 18:16:24 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #5(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): Verifying that KafkaRebalance is in the Ready state
2022-04-05 18:16:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-9f51fb23 will have desired state: Ready
2022-04-05 18:18:09 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-9f51fb23 is in desired state: Ready
2022-04-05 18:18:09 [main] [32mINFO [m [CruiseControlST:152] Annotating KafkaRebalance: my-cluster-9f51fb23 with 'refresh' anno
2022-04-05 18:18:09 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #6(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): Annotating KafkaRebalance:my-cluster-9f51fb23 with annotation refresh
2022-04-05 18:18:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-9f51fb23 will have desired state: ProposalReady
2022-04-05 18:18:10 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-9f51fb23 is in desired state: ProposalReady
2022-04-05 18:18:10 [main] [32mINFO [m [CruiseControlST:156] Trying rebalancing process again
2022-04-05 18:18:10 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): ============================================================================
2022-04-05 18:18:10 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): ProposalReady
2022-04-05 18:18:10 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): ============================================================================
2022-04-05 18:18:10 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): ============================================================================
2022-04-05 18:18:10 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): ProposalReady
2022-04-05 18:18:10 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): ============================================================================
2022-04-05 18:18:10 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-05 18:18:10 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): Annotating KafkaRebalance:my-cluster-9f51fb23 with annotation approve
2022-04-05 18:18:10 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-9f51fb23 annotated
2022-04-05 18:18:10 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): Verifying that annotation triggers the Rebalancing state
2022-04-05 18:18:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-9f51fb23 will have desired state: Rebalancing
2022-04-05 18:18:11 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-9f51fb23 is in desired state: Rebalancing
2022-04-05 18:18:11 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #7(test) KafkaRebalance(cruise-control-st/my-cluster-9f51fb23): Verifying that KafkaRebalance is in the Ready state
2022-04-05 18:18:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-9f51fb23 will have desired state: Ready
2022-04-05 18:18:16 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-9f51fb23 is in desired state: Ready
2022-04-05 18:18:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:18:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithRebalanceResourceAndRefreshAnnotation
2022-04-05 18:18:16 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-9f51fb23 in namespace cruise-control-st
2022-04-05 18:18:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9f51fb23 in namespace cruise-control-st
2022-04-05 18:18:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-9f51fb23
2022-04-05 18:18:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:18:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithRebalanceResourceAndRefreshAnnotation-FINISHED
2022-04-05 18:18:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:18:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:18:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithApiSecurityDisabled-STARTED
2022-04-05 18:18:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:18:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4a9f06fc in namespace cruise-control-st
2022-04-05 18:18:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4a9f06fc will have desired state: Ready
2022-04-05 18:20:03 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4a9f06fc is in desired state: Ready
2022-04-05 18:20:03 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-4a9f06fc in namespace cruise-control-st
2022-04-05 18:20:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-4a9f06fc will have desired state: PendingProposal
2022-04-05 18:20:04 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-4a9f06fc is in desired state: PendingProposal
2022-04-05 18:20:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-4a9f06fc will have desired state: ProposalReady
2022-04-05 18:25:54 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-4a9f06fc is in desired state: ProposalReady
2022-04-05 18:25:54 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:25:54 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlWithApiSecurityDisabled
2022-04-05 18:25:54 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-4a9f06fc in namespace cruise-control-st
2022-04-05 18:25:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4a9f06fc in namespace cruise-control-st
2022-04-05 18:25:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace cruise-control-st, for cruise control Kafka cluster my-cluster-4a9f06fc
2022-04-05 18:26:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:26:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlWithApiSecurityDisabled-FINISHED
2022-04-05 18:26:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:26:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:26:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancing-STARTED
2022-04-05 18:26:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:26:05 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-21 for test case:testCruiseControlIntraBrokerBalancing
2022-04-05 18:26:05 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-21
2022-04-05 18:26:05 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-21
2022-04-05 18:26:05 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-21
2022-04-05 18:26:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-06682694 in namespace namespace-21
2022-04-05 18:26:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-21
2022-04-05 18:26:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-06682694 will have desired state: Ready
2022-04-05 18:27:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-06682694 is in desired state: Ready
2022-04-05 18:27:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-06682694 in namespace namespace-21
2022-04-05 18:27:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-21
2022-04-05 18:27:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-06682694 will have desired state: PendingProposal
2022-04-05 18:27:45 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-06682694 is in desired state: PendingProposal
2022-04-05 18:27:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-06682694 will have desired state: ProposalReady
2022-04-05 18:30:41 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-06682694 is in desired state: ProposalReady
2022-04-05 18:30:41 [main] [32mINFO [m [CruiseControlST:292] Checking status of KafkaRebalance
2022-04-05 18:30:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:30:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCruiseControlIntraBrokerBalancing
2022-04-05 18:30:41 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-06682694 in namespace namespace-21
2022-04-05 18:30:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-06682694 in namespace namespace-21
2022-04-05 18:30:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-21, for cruise control Kafka cluster my-cluster-06682694
2022-04-05 18:30:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:30:51 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-21 for test case:testCruiseControlIntraBrokerBalancing
2022-04-05 18:31:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.cruisecontrol.CruiseControlST.testCruiseControlIntraBrokerBalancing-FINISHED
2022-04-05 18:31:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:31:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:31:34 [main] [32mINFO [m [ResourceManager:346] In context CruiseControlST is everything deleted.
2022-04-05 18:31:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,615.457 s - in io.strimzi.systemtest.cruisecontrol.CruiseControlST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.ListenersST
2022-04-05 18:31:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: listeners-st
2022-04-05 18:31:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: listeners-st
2022-04-05 18:31:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: listeners-st
2022-04-05 18:31:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:31:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsAuthenticated-STARTED
2022-04-05 18:31:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:31:43 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-22 for test case:testSendMessagesTlsAuthenticated
2022-04-05 18:31:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-22
2022-04-05 18:31:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-22
2022-04-05 18:31:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-22
2022-04-05 18:31:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c900fbad in namespace namespace-22
2022-04-05 18:31:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-05 18:31:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c900fbad will have desired state: Ready
2022-04-05 18:32:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c900fbad is in desired state: Ready
2022-04-05 18:32:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2032719329-123694577 in namespace namespace-22
2022-04-05 18:32:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-05 18:32:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2032719329-123694577 will have desired state: Ready
2022-04-05 18:32:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2032719329-123694577 is in desired state: Ready
2022-04-05 18:32:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1097312347-909113204 in namespace namespace-22
2022-04-05 18:32:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-05 18:32:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1097312347-909113204 will have desired state: Ready
2022-04-05 18:33:00 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1097312347-909113204 is in desired state: Ready
2022-04-05 18:33:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c900fbad-kafka-clients in namespace namespace-22
2022-04-05 18:33:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-22
2022-04-05 18:33:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c900fbad-kafka-clients will be ready
2022-04-05 18:33:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c900fbad-kafka-clients is ready
2022-04-05 18:33:02 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:33:02 [main] [32mINFO [m [ListenersST:221] Checking produced and consumed messages to pod:my-cluster-c900fbad-kafka-clients-c84c67876-htnfg
2022-04-05 18:33:02 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1cf6cad5, messages=[], arguments=[USER=my_user_1097312347_909113204, --bootstrap-server, my-cluster-c900fbad-kafka-bootstrap.namespace-22.svc:9093, --max-messages, 100, --topic, my-topic-2032719329-123694577], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-c900fbad-kafka-clients-c84c67876-htnfg', podNamespace='namespace-22', bootstrapServer='my-cluster-c900fbad-kafka-bootstrap.namespace-22.svc:9093', topicName='my-topic-2032719329-123694577', maxMessages=100, kafkaUsername='my-user-1097312347-909113204', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6b9a0014}
2022-04-05 18:33:02 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-c900fbad-kafka-bootstrap.namespace-22.svc:9093:my-topic-2032719329-123694577 from pod my-cluster-c900fbad-kafka-clients-c84c67876-htnfg
2022-04-05 18:33:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c900fbad-kafka-clients-c84c67876-htnfg -n namespace-22 -- /opt/kafka/producer.sh USER=my_user_1097312347_909113204 --bootstrap-server my-cluster-c900fbad-kafka-bootstrap.namespace-22.svc:9093 --max-messages 100 --topic my-topic-2032719329-123694577
2022-04-05 18:33:06 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 18:33:06 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 18:33:06 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2b20b870, messages=[], arguments=[USER=my_user_1097312347_909113204, --group-id, my-consumer-group-296411383, --bootstrap-server, my-cluster-c900fbad-kafka-bootstrap.namespace-22.svc:9093, --group-instance-id, instance1424366162, --max-messages, 100, --topic, my-topic-2032719329-123694577], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-c900fbad-kafka-clients-c84c67876-htnfg', podNamespace='namespace-22', bootstrapServer='my-cluster-c900fbad-kafka-bootstrap.namespace-22.svc:9093', topicName='my-topic-2032719329-123694577', maxMessages=100, kafkaUsername='my-user-1097312347-909113204', consumerGroupName='my-consumer-group-296411383', consumerInstanceId='instance1424366162', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@108190d4}
2022-04-05 18:33:06 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-c900fbad-kafka-bootstrap.namespace-22.svc:9093:my-topic-2032719329-123694577 from pod my-cluster-c900fbad-kafka-clients-c84c67876-htnfg
2022-04-05 18:33:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-c900fbad-kafka-clients-c84c67876-htnfg -n namespace-22 -- /opt/kafka/consumer.sh USER=my_user_1097312347_909113204 --group-id my-consumer-group-296411383 --bootstrap-server my-cluster-c900fbad-kafka-bootstrap.namespace-22.svc:9093 --group-instance-id instance1424366162 --max-messages 100 --topic my-topic-2032719329-123694577
2022-04-05 18:33:13 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 18:33:13 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 18:33:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:33:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesTlsAuthenticated
2022-04-05 18:33:13 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1097312347-909113204 in namespace namespace-22
2022-04-05 18:33:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c900fbad-kafka-clients in namespace namespace-22
2022-04-05 18:33:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2032719329-123694577 in namespace namespace-22
2022-04-05 18:33:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c900fbad in namespace namespace-22
2022-04-05 18:34:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:34:03 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-22 for test case:testSendMessagesTlsAuthenticated
2022-04-05 18:34:09 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsAuthenticated-FINISHED
2022-04-05 18:34:09 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:34:09 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:34:09 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-STARTED
2022-04-05 18:34:09 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:34:09 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-23 for test case:testSendMessagesCustomListenerTlsScramSha
2022-04-05 18:34:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-23
2022-04-05 18:34:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-23
2022-04-05 18:34:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-23
2022-04-05 18:34:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3462131b in namespace namespace-23
2022-04-05 18:34:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-05 18:34:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3462131b will have desired state: Ready
2022-04-05 18:35:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3462131b is in desired state: Ready
2022-04-05 18:35:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1791075934-1249210568 in namespace namespace-23
2022-04-05 18:35:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-05 18:35:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1791075934-1249210568 will have desired state: Ready
2022-04-05 18:35:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1791075934-1249210568 is in desired state: Ready
2022-04-05 18:35:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-753839774-1293208920 in namespace namespace-23
2022-04-05 18:35:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-05 18:35:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-753839774-1293208920 will have desired state: Ready
2022-04-05 18:35:30 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-753839774-1293208920 is in desired state: Ready
2022-04-05 18:35:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3462131b-kafka-clients in namespace namespace-23
2022-04-05 18:35:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-23
2022-04-05 18:35:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3462131b-kafka-clients will be ready
2022-04-05 18:35:32 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3462131b-kafka-clients is ready
2022-04-05 18:35:32 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:35:32 [main] [32mINFO [m [ListenersST:442] Checking produced and consumed messages to pod:my-cluster-3462131b-kafka-clients-6d49d9f59b-fvq4h
2022-04-05 18:35:32 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5a27f4cf, messages=[], arguments=[USER=my_user_753839774_1293208920, --bootstrap-server, my-cluster-3462131b-kafka-bootstrap.namespace-23.svc:9122, --max-messages, 100, --topic, my-topic-1791075934-1249210568], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-3462131b-kafka-clients-6d49d9f59b-fvq4h', podNamespace='namespace-23', bootstrapServer='my-cluster-3462131b-kafka-bootstrap.namespace-23.svc:9122', topicName='my-topic-1791075934-1249210568', maxMessages=100, kafkaUsername='my-user-753839774-1293208920', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7d4832d2}
2022-04-05 18:35:32 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-3462131b-kafka-bootstrap.namespace-23.svc:9122:my-topic-1791075934-1249210568 from pod my-cluster-3462131b-kafka-clients-6d49d9f59b-fvq4h
2022-04-05 18:35:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3462131b-kafka-clients-6d49d9f59b-fvq4h -n namespace-23 -- /opt/kafka/producer.sh USER=my_user_753839774_1293208920 --bootstrap-server my-cluster-3462131b-kafka-bootstrap.namespace-23.svc:9122 --max-messages 100 --topic my-topic-1791075934-1249210568
2022-04-05 18:35:36 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 18:35:36 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 18:35:36 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4b6f749f, messages=[], arguments=[USER=my_user_753839774_1293208920, --group-id, my-consumer-group-1406051293, --bootstrap-server, my-cluster-3462131b-kafka-bootstrap.namespace-23.svc:9122, --group-instance-id, instance1570973513, --max-messages, 100, --topic, my-topic-1791075934-1249210568], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-3462131b-kafka-clients-6d49d9f59b-fvq4h', podNamespace='namespace-23', bootstrapServer='my-cluster-3462131b-kafka-bootstrap.namespace-23.svc:9122', topicName='my-topic-1791075934-1249210568', maxMessages=100, kafkaUsername='my-user-753839774-1293208920', consumerGroupName='my-consumer-group-1406051293', consumerInstanceId='instance1570973513', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@770d060e}
2022-04-05 18:35:36 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-3462131b-kafka-bootstrap.namespace-23.svc:9122:my-topic-1791075934-1249210568 from pod my-cluster-3462131b-kafka-clients-6d49d9f59b-fvq4h
2022-04-05 18:35:36 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3462131b-kafka-clients-6d49d9f59b-fvq4h -n namespace-23 -- /opt/kafka/consumer.sh USER=my_user_753839774_1293208920 --group-id my-consumer-group-1406051293 --bootstrap-server my-cluster-3462131b-kafka-bootstrap.namespace-23.svc:9122 --group-instance-id instance1570973513 --max-messages 100 --topic my-topic-1791075934-1249210568
2022-04-05 18:35:44 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 18:35:44 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 18:35:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:35:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesCustomListenerTlsScramSha
2022-04-05 18:35:44 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-753839774-1293208920 in namespace namespace-23
2022-04-05 18:35:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3462131b-kafka-clients in namespace namespace-23
2022-04-05 18:35:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1791075934-1249210568 in namespace namespace-23
2022-04-05 18:35:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3462131b in namespace namespace-23
2022-04-05 18:36:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:36:34 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-23 for test case:testSendMessagesCustomListenerTlsScramSha
2022-04-05 18:36:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesCustomListenerTlsScramSha-FINISHED
2022-04-05 18:36:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:36:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:36:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataCrt-STARTED
2022-04-05 18:36:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:36:39 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-24 for test case:testCertificateWithNonExistingDataCrt
2022-04-05 18:36:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-24
2022-04-05 18:36:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-24
2022-04-05 18:36:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-24
2022-04-05 18:36:39 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-d0d6d83d-custom-certificate-server-1
2022-04-05 18:36:39 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-d0d6d83d-custom-certificate-server-1 created
2022-04-05 18:36:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d0d6d83d in namespace namespace-24
2022-04-05 18:36:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-24
2022-04-05 18:37:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:37:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificateWithNonExistingDataCrt
2022-04-05 18:37:15 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d0d6d83d in namespace namespace-24
2022-04-05 18:37:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:37:16 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-24 for test case:testCertificateWithNonExistingDataCrt
2022-04-05 18:37:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataCrt-FINISHED
2022-04-05 18:37:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:37:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:37:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataKey-STARTED
2022-04-05 18:37:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:37:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-25 for test case:testCertificateWithNonExistingDataKey
2022-04-05 18:37:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-25
2022-04-05 18:37:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-25
2022-04-05 18:37:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-25
2022-04-05 18:37:21 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-fbf670f4-custom-certificate-server-1
2022-04-05 18:37:21 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-fbf670f4-custom-certificate-server-1 created
2022-04-05 18:37:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fbf670f4 in namespace namespace-25
2022-04-05 18:37:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-25
2022-04-05 18:37:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:37:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificateWithNonExistingDataKey
2022-04-05 18:37:57 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fbf670f4 in namespace namespace-25
2022-04-05 18:37:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:37:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-25 for test case:testCertificateWithNonExistingDataKey
2022-04-05 18:38:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testCertificateWithNonExistingDataKey-FINISHED
2022-04-05 18:38:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:38:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:38:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainAnonymous-STARTED
2022-04-05 18:38:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:38:08 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-26 for test case:testSendMessagesPlainAnonymous
2022-04-05 18:38:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-26
2022-04-05 18:38:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-26
2022-04-05 18:38:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-26
2022-04-05 18:38:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-47068edd in namespace namespace-26
2022-04-05 18:38:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-26
2022-04-05 18:38:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-47068edd will have desired state: Ready
2022-04-05 18:39:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-47068edd is in desired state: Ready
2022-04-05 18:39:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1539442254-1920479978 in namespace namespace-26
2022-04-05 18:39:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-26
2022-04-05 18:39:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1539442254-1920479978 will have desired state: Ready
2022-04-05 18:39:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1539442254-1920479978 is in desired state: Ready
2022-04-05 18:39:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-47068edd-kafka-clients in namespace namespace-26
2022-04-05 18:39:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-26
2022-04-05 18:39:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-47068edd-kafka-clients will be ready
2022-04-05 18:39:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-47068edd-kafka-clients is ready
2022-04-05 18:39:26 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:39:26 [main] [32mINFO [m [ListenersST:152] Checking produced and consumed messages to pod:my-cluster-47068edd-kafka-clients-98bfc788f-pwwpt
2022-04-05 18:39:26 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@da01590, messages=[], arguments=[--bootstrap-server, my-cluster-47068edd-kafka-bootstrap.namespace-26.svc:9092, --max-messages, 100, --topic, my-topic-1539442254-1920479978], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-47068edd-kafka-clients-98bfc788f-pwwpt', podNamespace='namespace-26', bootstrapServer='my-cluster-47068edd-kafka-bootstrap.namespace-26.svc:9092', topicName='my-topic-1539442254-1920479978', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2edbe9f4}
2022-04-05 18:39:26 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-47068edd-kafka-bootstrap.namespace-26.svc:9092:my-topic-1539442254-1920479978 from pod my-cluster-47068edd-kafka-clients-98bfc788f-pwwpt
2022-04-05 18:39:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-47068edd-kafka-clients-98bfc788f-pwwpt -n namespace-26 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-47068edd-kafka-bootstrap.namespace-26.svc:9092 --max-messages 100 --topic my-topic-1539442254-1920479978
2022-04-05 18:39:28 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 18:39:28 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 18:39:28 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6a6793c7, messages=[], arguments=[--group-id, my-consumer-group-904505529, --bootstrap-server, my-cluster-47068edd-kafka-bootstrap.namespace-26.svc:9092, --group-instance-id, instance1524694138, --max-messages, 100, --topic, my-topic-1539442254-1920479978], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-47068edd-kafka-clients-98bfc788f-pwwpt', podNamespace='namespace-26', bootstrapServer='my-cluster-47068edd-kafka-bootstrap.namespace-26.svc:9092', topicName='my-topic-1539442254-1920479978', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-904505529', consumerInstanceId='instance1524694138', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1b025d1a}
2022-04-05 18:39:28 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-47068edd-kafka-bootstrap.namespace-26.svc:9092#my-topic-1539442254-1920479978 from pod my-cluster-47068edd-kafka-clients-98bfc788f-pwwpt
2022-04-05 18:39:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-47068edd-kafka-clients-98bfc788f-pwwpt -n namespace-26 -- /opt/kafka/consumer.sh --group-id my-consumer-group-904505529 --bootstrap-server my-cluster-47068edd-kafka-bootstrap.namespace-26.svc:9092 --group-instance-id instance1524694138 --max-messages 100 --topic my-topic-1539442254-1920479978
2022-04-05 18:39:34 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 18:39:34 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 18:39:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:39:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesPlainAnonymous
2022-04-05 18:39:34 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1539442254-1920479978 in namespace namespace-26
2022-04-05 18:39:34 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-47068edd in namespace namespace-26
2022-04-05 18:39:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-47068edd-kafka-clients in namespace namespace-26
2022-04-05 18:40:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:40:14 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-26 for test case:testSendMessagesPlainAnonymous
2022-04-05 18:40:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainAnonymous-FINISHED
2022-04-05 18:40:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:40:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:40:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainScramSha-STARTED
2022-04-05 18:40:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:40:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-27 for test case:testSendMessagesPlainScramSha
2022-04-05 18:40:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-27
2022-04-05 18:40:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-27
2022-04-05 18:40:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-27
2022-04-05 18:40:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f4fa889e in namespace namespace-27
2022-04-05 18:40:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-05 18:40:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f4fa889e will have desired state: Ready
2022-04-05 18:41:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f4fa889e is in desired state: Ready
2022-04-05 18:41:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-219354666-1446020945 in namespace namespace-27
2022-04-05 18:41:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-05 18:41:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-219354666-1446020945 will have desired state: Ready
2022-04-05 18:41:43 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-219354666-1446020945 is in desired state: Ready
2022-04-05 18:41:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1507817179-706635746 in namespace namespace-27
2022-04-05 18:41:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-05 18:41:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1507817179-706635746 will have desired state: Ready
2022-04-05 18:41:44 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1507817179-706635746 is in desired state: Ready
2022-04-05 18:41:44 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1507817179-706635746: 2022-04-05 18:41:44,231 INFO Processing override for entityPath: users/my-user-1507817179-706635746 with config: HashMap(SCRAM-SHA-512 -> [hidden]) (kafka.server.DynamicConfigManager) [/config/changes-event-process-thread]
2022-04-05 18:41:44 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1507817179-706635746: 2022-04-05 18:41:44,250 INFO Removing PRODUCE quota for user my-user-1507817179-706635746 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:44 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1507817179-706635746: 2022-04-05 18:41:44,274 INFO Removing FETCH quota for user my-user-1507817179-706635746 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:44 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1507817179-706635746: 2022-04-05 18:41:44,275 INFO Removing REQUEST quota for user my-user-1507817179-706635746 (kafka.server.ClientRequestQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:44 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1507817179-706635746: 2022-04-05 18:41:44,275 INFO Removing CONTROLLER_MUTATION quota for user my-user-1507817179-706635746 (kafka.server.ControllerMutationQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:44 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1507817179-706635746: 2022-04-05 18:41:44,530 INFO Processing override for entityPath: users/my-user-1507817179-706635746 with config: HashMap(SCRAM-SHA-512 -> [hidden]) (kafka.server.DynamicConfigManager) [/config/changes-event-process-thread]
2022-04-05 18:41:44 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1507817179-706635746: 2022-04-05 18:41:44,530 INFO Removing PRODUCE quota for user my-user-1507817179-706635746 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:44 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1507817179-706635746: 2022-04-05 18:41:44,531 INFO Removing FETCH quota for user my-user-1507817179-706635746 (kafka.server.ClientQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:44 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1507817179-706635746: 2022-04-05 18:41:44,531 INFO Removing REQUEST quota for user my-user-1507817179-706635746 (kafka.server.ClientRequestQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:44 [main] [32mINFO [m [ListenersST:273] Broker pod log line about user my-user-1507817179-706635746: 2022-04-05 18:41:44,531 INFO Removing CONTROLLER_MUTATION quota for user my-user-1507817179-706635746 (kafka.server.ControllerMutationQuotaManager) [/config/changes-event-process-thread]
2022-04-05 18:41:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f4fa889e-kafka-clients in namespace namespace-27
2022-04-05 18:41:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-27
2022-04-05 18:41:44 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f4fa889e-kafka-clients will be ready
2022-04-05 18:41:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f4fa889e-kafka-clients is ready
2022-04-05 18:41:46 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:41:46 [main] [32mINFO [m [ListenersST:296] Checking produced and consumed messages to pod:my-cluster-f4fa889e-kafka-clients-869d745f55-hc8vp
2022-04-05 18:41:46 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7c39dc8c, messages=[], arguments=[USER=my_user_1507817179_706635746, --bootstrap-server, my-cluster-f4fa889e-kafka-bootstrap.namespace-27.svc:9095, --max-messages, 100, --topic, my-topic-219354666-1446020945], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-f4fa889e-kafka-clients-869d745f55-hc8vp', podNamespace='namespace-27', bootstrapServer='my-cluster-f4fa889e-kafka-bootstrap.namespace-27.svc:9095', topicName='my-topic-219354666-1446020945', maxMessages=100, kafkaUsername='my-user-1507817179-706635746', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7f280f86}
2022-04-05 18:41:46 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-f4fa889e-kafka-bootstrap.namespace-27.svc:9095:my-topic-219354666-1446020945 from pod my-cluster-f4fa889e-kafka-clients-869d745f55-hc8vp
2022-04-05 18:41:46 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f4fa889e-kafka-clients-869d745f55-hc8vp -n namespace-27 -- /opt/kafka/producer.sh USER=my_user_1507817179_706635746 --bootstrap-server my-cluster-f4fa889e-kafka-bootstrap.namespace-27.svc:9095 --max-messages 100 --topic my-topic-219354666-1446020945
2022-04-05 18:41:49 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 18:41:49 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 18:41:49 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4c573be2, messages=[], arguments=[USER=my_user_1507817179_706635746, --group-id, my-consumer-group-1241553396, --bootstrap-server, my-cluster-f4fa889e-kafka-bootstrap.namespace-27.svc:9095, --group-instance-id, instance326829867, --max-messages, 100, --topic, my-topic-219354666-1446020945], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f4fa889e-kafka-clients-869d745f55-hc8vp', podNamespace='namespace-27', bootstrapServer='my-cluster-f4fa889e-kafka-bootstrap.namespace-27.svc:9095', topicName='my-topic-219354666-1446020945', maxMessages=100, kafkaUsername='my-user-1507817179-706635746', consumerGroupName='my-consumer-group-1241553396', consumerInstanceId='instance326829867', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@73bc5e2c}
2022-04-05 18:41:49 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-f4fa889e-kafka-bootstrap.namespace-27.svc:9095#my-topic-219354666-1446020945 from pod my-cluster-f4fa889e-kafka-clients-869d745f55-hc8vp
2022-04-05 18:41:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f4fa889e-kafka-clients-869d745f55-hc8vp -n namespace-27 -- /opt/kafka/consumer.sh USER=my_user_1507817179_706635746 --group-id my-consumer-group-1241553396 --bootstrap-server my-cluster-f4fa889e-kafka-bootstrap.namespace-27.svc:9095 --group-instance-id instance326829867 --max-messages 100 --topic my-topic-219354666-1446020945
2022-04-05 18:41:55 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 18:41:55 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 18:41:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:41:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesPlainScramSha
2022-04-05 18:41:55 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1507817179-706635746 in namespace namespace-27
2022-04-05 18:41:55 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f4fa889e-kafka-clients in namespace namespace-27
2022-04-05 18:41:55 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-219354666-1446020945 in namespace namespace-27
2022-04-05 18:41:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f4fa889e in namespace namespace-27
2022-04-05 18:42:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:42:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-27 for test case:testSendMessagesPlainScramSha
2022-04-05 18:43:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesPlainScramSha-FINISHED
2022-04-05 18:43:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:43:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:43:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-STARTED
2022-04-05 18:43:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:43:01 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-28 for test case:testSendMessagesTlsScramSha
2022-04-05 18:43:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-28
2022-04-05 18:43:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-28
2022-04-05 18:43:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-28
2022-04-05 18:43:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-97e7bd8a in namespace namespace-28
2022-04-05 18:43:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-05 18:43:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-97e7bd8a will have desired state: Ready
2022-04-05 18:44:13 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-97e7bd8a is in desired state: Ready
2022-04-05 18:44:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-240464061-82322853 in namespace namespace-28
2022-04-05 18:44:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-05 18:44:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-240464061-82322853 will have desired state: Ready
2022-04-05 18:44:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-240464061-82322853 is in desired state: Ready
2022-04-05 18:44:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1471107008-136143839 in namespace namespace-28
2022-04-05 18:44:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-05 18:44:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1471107008-136143839 will have desired state: Ready
2022-04-05 18:44:15 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1471107008-136143839 is in desired state: Ready
2022-04-05 18:44:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-97e7bd8a-kafka-clients in namespace namespace-28
2022-04-05 18:44:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-28
2022-04-05 18:44:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-97e7bd8a-kafka-clients will be ready
2022-04-05 18:44:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-97e7bd8a-kafka-clients is ready
2022-04-05 18:44:18 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:44:18 [main] [32mINFO [m [ListenersST:370] Checking produced and consumed messages to pod:my-cluster-97e7bd8a-kafka-clients-6f6cdc64dd-rn8h9
2022-04-05 18:44:18 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@75af3d03, messages=[], arguments=[USER=my_user_1471107008_136143839, --bootstrap-server, my-cluster-97e7bd8a-kafka-bootstrap.namespace-28.svc:9096, --max-messages, 100, --topic, my-topic-240464061-82322853], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-97e7bd8a-kafka-clients-6f6cdc64dd-rn8h9', podNamespace='namespace-28', bootstrapServer='my-cluster-97e7bd8a-kafka-bootstrap.namespace-28.svc:9096', topicName='my-topic-240464061-82322853', maxMessages=100, kafkaUsername='my-user-1471107008-136143839', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@21427849}
2022-04-05 18:44:18 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-97e7bd8a-kafka-bootstrap.namespace-28.svc:9096:my-topic-240464061-82322853 from pod my-cluster-97e7bd8a-kafka-clients-6f6cdc64dd-rn8h9
2022-04-05 18:44:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97e7bd8a-kafka-clients-6f6cdc64dd-rn8h9 -n namespace-28 -- /opt/kafka/producer.sh USER=my_user_1471107008_136143839 --bootstrap-server my-cluster-97e7bd8a-kafka-bootstrap.namespace-28.svc:9096 --max-messages 100 --topic my-topic-240464061-82322853
2022-04-05 18:44:21 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 18:44:21 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 18:44:21 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4fcc362a, messages=[], arguments=[USER=my_user_1471107008_136143839, --group-id, my-consumer-group-315705781, --bootstrap-server, my-cluster-97e7bd8a-kafka-bootstrap.namespace-28.svc:9096, --group-instance-id, instance1086976064, --max-messages, 100, --topic, my-topic-240464061-82322853], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-97e7bd8a-kafka-clients-6f6cdc64dd-rn8h9', podNamespace='namespace-28', bootstrapServer='my-cluster-97e7bd8a-kafka-bootstrap.namespace-28.svc:9096', topicName='my-topic-240464061-82322853', maxMessages=100, kafkaUsername='my-user-1471107008-136143839', consumerGroupName='my-consumer-group-315705781', consumerInstanceId='instance1086976064', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7dfe89ec}
2022-04-05 18:44:21 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-97e7bd8a-kafka-bootstrap.namespace-28.svc:9096:my-topic-240464061-82322853 from pod my-cluster-97e7bd8a-kafka-clients-6f6cdc64dd-rn8h9
2022-04-05 18:44:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-97e7bd8a-kafka-clients-6f6cdc64dd-rn8h9 -n namespace-28 -- /opt/kafka/consumer.sh USER=my_user_1471107008_136143839 --group-id my-consumer-group-315705781 --bootstrap-server my-cluster-97e7bd8a-kafka-bootstrap.namespace-28.svc:9096 --group-instance-id instance1086976064 --max-messages 100 --topic my-topic-240464061-82322853
2022-04-05 18:44:29 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 18:44:29 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 18:44:29 [main] [32mINFO [m [ListenersST:377] Checking if generated password has 25 characters
2022-04-05 18:44:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:44:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendMessagesTlsScramSha
2022-04-05 18:44:29 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1471107008-136143839 in namespace namespace-28
2022-04-05 18:44:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-97e7bd8a-kafka-clients in namespace namespace-28
2022-04-05 18:44:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-240464061-82322853 in namespace namespace-28
2022-04-05 18:44:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-97e7bd8a in namespace namespace-28
2022-04-05 18:45:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:45:19 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-28 for test case:testSendMessagesTlsScramSha
2022-04-05 18:45:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testSendMessagesTlsScramSha-FINISHED
2022-04-05 18:45:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:45:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:45:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testNonExistingCustomCertificate-STARTED
2022-04-05 18:45:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:45:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-29 for test case:testNonExistingCustomCertificate
2022-04-05 18:45:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-29
2022-04-05 18:45:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-29
2022-04-05 18:45:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-29
2022-04-05 18:45:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d2efbdec in namespace namespace-29
2022-04-05 18:45:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-29
2022-04-05 18:45:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:45:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNonExistingCustomCertificate
2022-04-05 18:45:55 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d2efbdec in namespace namespace-29
2022-04-05 18:45:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:45:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-29 for test case:testNonExistingCustomCertificate
2022-04-05 18:46:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testNonExistingCustomCertificate-FINISHED
2022-04-05 18:46:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:46:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:46:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testAdvertisedHostNamesAppearsInBrokerCerts-STARTED
2022-04-05 18:46:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:46:23 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-30 for test case:testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-05 18:46:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-30
2022-04-05 18:46:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-30
2022-04-05 18:46:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-30
2022-04-05 18:46:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-16a23d40 in namespace namespace-30
2022-04-05 18:46:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-30
2022-04-05 18:46:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-16a23d40 will have desired state: Ready
2022-04-05 18:47:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-16a23d40 is in desired state: Ready
2022-04-05 18:47:49 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-16a23d40-kafka-0.crt
2022-04-05 18:47:49 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-16a23d40-kafka-1.crt
2022-04-05 18:47:49 [main] [32mINFO [m [ListenersST:2338] Encoding my-cluster-16a23d40-kafka-2.crt
2022-04-05 18:47:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:47:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-05 18:47:49 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-16a23d40 in namespace namespace-30
2022-04-05 18:47:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:47:59 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-30 for test case:testAdvertisedHostNamesAppearsInBrokerCerts
2022-04-05 18:48:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testAdvertisedHostNamesAppearsInBrokerCerts-FINISHED
2022-04-05 18:48:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:48:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:48:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.ListenersST.testMessagesTlsScramShaWithPredefinedPassword-STARTED
2022-04-05 18:48:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:48:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-31 for test case:testMessagesTlsScramShaWithPredefinedPassword
2022-04-05 18:48:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-31
2022-04-05 18:48:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-31
2022-04-05 18:48:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-31
2022-04-05 18:48:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-404718b7 in namespace namespace-31
2022-04-05 18:48:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-05 18:48:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-931167574-794519777 in namespace namespace-31
2022-04-05 18:48:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-05 18:48:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1140979967-1381861618 in namespace namespace-31
2022-04-05 18:48:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-05 18:48:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-404718b7 will have desired state: Ready
2022-04-05 18:49:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-404718b7 is in desired state: Ready
2022-04-05 18:49:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-931167574-794519777 will have desired state: Ready
2022-04-05 18:49:45 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-931167574-794519777 is in desired state: Ready
2022-04-05 18:49:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1140979967-1381861618 will have desired state: Ready
2022-04-05 18:49:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1140979967-1381861618 is in desired state: Ready
2022-04-05 18:49:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-404718b7-kafka-clients in namespace namespace-31
2022-04-05 18:49:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-05 18:49:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-404718b7-kafka-clients will be ready
2022-04-05 18:49:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-404718b7-kafka-clients is ready
2022-04-05 18:49:47 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:49:47 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4f225e09, messages=[], arguments=[USER=my_user_931167574_794519777, --bootstrap-server, my-cluster-404718b7-kafka-bootstrap.namespace-31.svc:9096, --max-messages, 100, --topic, my-topic-1140979967-1381861618], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-404718b7-kafka-clients-767bdb797f-r8rzd', podNamespace='namespace-31', bootstrapServer='my-cluster-404718b7-kafka-bootstrap.namespace-31.svc:9096', topicName='my-topic-1140979967-1381861618', maxMessages=100, kafkaUsername='my-user-931167574-794519777', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@748f9029}
2022-04-05 18:49:47 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-404718b7-kafka-bootstrap.namespace-31.svc:9096:my-topic-1140979967-1381861618 from pod my-cluster-404718b7-kafka-clients-767bdb797f-r8rzd
2022-04-05 18:49:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-404718b7-kafka-clients-767bdb797f-r8rzd -n namespace-31 -- /opt/kafka/producer.sh USER=my_user_931167574_794519777 --bootstrap-server my-cluster-404718b7-kafka-bootstrap.namespace-31.svc:9096 --max-messages 100 --topic my-topic-1140979967-1381861618
2022-04-05 18:49:51 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 18:49:51 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 18:49:51 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3ac8569e, messages=[], arguments=[USER=my_user_931167574_794519777, --group-id, my-consumer-group-1001901184, --bootstrap-server, my-cluster-404718b7-kafka-bootstrap.namespace-31.svc:9096, --group-instance-id, instance1501673058, --max-messages, 100, --topic, my-topic-1140979967-1381861618], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-404718b7-kafka-clients-767bdb797f-r8rzd', podNamespace='namespace-31', bootstrapServer='my-cluster-404718b7-kafka-bootstrap.namespace-31.svc:9096', topicName='my-topic-1140979967-1381861618', maxMessages=100, kafkaUsername='my-user-931167574-794519777', consumerGroupName='my-consumer-group-1001901184', consumerInstanceId='instance1501673058', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@324e8626}
2022-04-05 18:49:51 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-404718b7-kafka-bootstrap.namespace-31.svc:9096:my-topic-1140979967-1381861618 from pod my-cluster-404718b7-kafka-clients-767bdb797f-r8rzd
2022-04-05 18:49:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-404718b7-kafka-clients-767bdb797f-r8rzd -n namespace-31 -- /opt/kafka/consumer.sh USER=my_user_931167574_794519777 --group-id my-consumer-group-1001901184 --bootstrap-server my-cluster-404718b7-kafka-bootstrap.namespace-31.svc:9096 --group-instance-id instance1501673058 --max-messages 100 --topic my-topic-1140979967-1381861618
2022-04-05 18:49:58 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 18:49:58 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 18:49:58 [main] [32mINFO [m [ListenersST:2213] Changing password in secret: my-cluster-404718b7-secret, we should be able to send/receive messages
2022-04-05 18:49:58 [main] [32mINFO [m [SecretUtils:171] Waiting for user password will be changed to Y29tcGxldGVseV9kaWZmZXJlbnRfc2VjcmV0X3Bhc3N3b3Jk in secret: my-user-931167574-794519777
2022-04-05 18:51:24 [main] [32mINFO [m [ListenersST:2222] We need to recreate Kafka Clients deployment, so the correct password from secret will be taken
2022-04-05 18:51:24 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-404718b7-kafka-clients in namespace namespace-31
2022-04-05 18:52:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-404718b7-kafka-clients in namespace namespace-31
2022-04-05 18:52:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-31
2022-04-05 18:52:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-404718b7-kafka-clients will be ready
2022-04-05 18:52:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-404718b7-kafka-clients is ready
2022-04-05 18:52:16 [main] [32mINFO [m [ListenersST:2226] Receiving messages with new password
2022-04-05 18:52:16 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1f0fb303, messages=[], arguments=[USER=my_user_931167574_794519777, --group-id, my-consumer-group-2068286808, --bootstrap-server, my-cluster-404718b7-kafka-bootstrap.namespace-31.svc:9096, --group-instance-id, instance412196765, --max-messages, 100, --topic, my-topic-1140979967-1381861618], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-404718b7-kafka-clients-55f45bd47f-k4v77', podNamespace='namespace-31', bootstrapServer='my-cluster-404718b7-kafka-bootstrap.namespace-31.svc:9096', topicName='my-topic-1140979967-1381861618', maxMessages=100, kafkaUsername='my-user-931167574-794519777', consumerGroupName='my-consumer-group-2068286808', consumerInstanceId='instance412196765', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@593671b5}
2022-04-05 18:52:16 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-404718b7-kafka-bootstrap.namespace-31.svc:9096:my-topic-1140979967-1381861618 from pod my-cluster-404718b7-kafka-clients-55f45bd47f-k4v77
2022-04-05 18:52:16 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-404718b7-kafka-clients-55f45bd47f-k4v77 -n namespace-31 -- /opt/kafka/consumer.sh USER=my_user_931167574_794519777 --group-id my-consumer-group-2068286808 --bootstrap-server my-cluster-404718b7-kafka-bootstrap.namespace-31.svc:9096 --group-instance-id instance412196765 --max-messages 100 --topic my-topic-1140979967-1381861618
2022-04-05 18:52:24 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 18:52:24 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 18:52:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:52:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMessagesTlsScramShaWithPredefinedPassword
2022-04-05 18:52:24 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1140979967-1381861618 in namespace namespace-31
2022-04-05 18:52:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-931167574-794519777 in namespace namespace-31
2022-04-05 18:52:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-404718b7-kafka-clients in namespace namespace-31
2022-04-05 18:52:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-404718b7 in namespace namespace-31
2022-04-05 18:52:34 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-404718b7-kafka-clients in namespace namespace-31
2022-04-05 18:53:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:53:14 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-31 for test case:testMessagesTlsScramShaWithPredefinedPassword
2022-04-05 18:53:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.ListenersST.testMessagesTlsScramShaWithPredefinedPassword-FINISHED
2022-04-05 18:53:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:53:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:53:19 [main] [32mINFO [m [ResourceManager:346] In context ListenersST is everything deleted.
2022-04-05 18:53:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,304.083 s - in io.strimzi.systemtest.kafka.listeners.ListenersST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.listeners.MultipleListenersST
2022-04-05 18:53:25 [main] [32mINFO [m [MultipleListenersST:294] Starting to generate test cases for multiple listeners
2022-04-05 18:53:25 [main] [32mINFO [m [MultipleListenersST:300] Generating INTERNAL listener
2022-04-05 18:53:25 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type INTERNAL -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@8daa1996, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@cf0205b2, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@1059f1ce]
2022-04-05 18:53:25 [main] [32mINFO [m [MultipleListenersST:300] Generating ROUTE listener
2022-04-05 18:53:25 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type ROUTE -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@a008f52e]
2022-04-05 18:53:25 [main] [32mINFO [m [MultipleListenersST:300] Generating LOADBALANCER listener
2022-04-05 18:53:25 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type LOADBALANCER -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@b073367c, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@f1cb2298]
2022-04-05 18:53:25 [main] [32mINFO [m [MultipleListenersST:300] Generating NODEPORT listener
2022-04-05 18:53:25 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type NODEPORT -> [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@329ddfe8, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@73f5cc04, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@a84d962e]
2022-04-05 18:53:25 [main] [32mINFO [m [MultipleListenersST:300] Generating INGRESS listener
2022-04-05 18:53:25 [main] [32mINFO [m [MultipleListenersST:363] Generating listeners with type INGRESS -> []
2022-04-05 18:53:25 [main] [32mINFO [m [MultipleListenersST:367] Finished with generation of test cases for multiple listeners
2022-04-05 18:53:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-listeners-st
2022-04-05 18:53:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-listeners-st
2022-04-05 18:53:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-listeners-st
2022-04-05 18:53:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:53:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.listeners.MultipleListenersST.testMultipleInternal-STARTED
2022-04-05 18:53:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:53:25 [main] [32mINFO [m [MultipleListenersST:163] This is listeners [io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@8daa1996, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@cf0205b2, io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener@1059f1ce], which will verified.
2022-04-05 18:53:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ed9330f3 in namespace multiple-listeners-st
2022-04-05 18:53:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ed9330f3 will have desired state: Ready
2022-04-05 18:54:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ed9330f3 is in desired state: Ready
2022-04-05 18:54:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1783444637-593508475 in namespace multiple-listeners-st
2022-04-05 18:54:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1783444637-593508475 will have desired state: Ready
2022-04-05 18:54:37 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1783444637-593508475 is in desired state: Ready
2022-04-05 18:54:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1521763301-1677229948 in namespace multiple-listeners-st
2022-04-05 18:54:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1521763301-1677229948 will have desired state: Ready
2022-04-05 18:54:38 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1521763301-1677229948 is in desired state: Ready
2022-04-05 18:54:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ed9330f3-kafka-clients-plain in namespace multiple-listeners-st
2022-04-05 18:54:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ed9330f3-kafka-clients-plain will be ready
2022-04-05 18:54:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ed9330f3-kafka-clients-plain is ready
2022-04-05 18:54:40 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:54:40 [main] [32mINFO [m [MultipleListenersST:274] Checking produced and consumed messages to pod:my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf
2022-04-05 18:54:40 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@31e1fcf2, messages=[], arguments=[--bootstrap-server, my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13900, --max-messages, 100, --topic, my-topic-1521763301-1677229948], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13900', topicName='my-topic-1521763301-1677229948', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@30abd880}
2022-04-05 18:54:40 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13900:my-topic-1521763301-1677229948 from pod my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf
2022-04-05 18:54:40 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf -n multiple-listeners-st -- /opt/kafka/producer.sh --bootstrap-server my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13900 --max-messages 100 --topic my-topic-1521763301-1677229948
2022-04-05 18:54:43 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 18:54:43 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 18:54:43 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@671370d4, messages=[], arguments=[--group-id, my-consumer-group-586175970, --bootstrap-server, my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13900, --group-instance-id, instance299834440, --max-messages, 100, --topic, my-topic-1521763301-1677229948], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13900', topicName='my-topic-1521763301-1677229948', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-586175970', consumerInstanceId='instance299834440', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@912c6ae}
2022-04-05 18:54:43 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13900#my-topic-1521763301-1677229948 from pod my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf
2022-04-05 18:54:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf -n multiple-listeners-st -- /opt/kafka/consumer.sh --group-id my-consumer-group-586175970 --bootstrap-server my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13900 --group-instance-id instance299834440 --max-messages 100 --topic my-topic-1521763301-1677229948
2022-04-05 18:54:49 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 18:54:49 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 18:54:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-97768251-1619064141 in namespace multiple-listeners-st
2022-04-05 18:54:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-97768251-1619064141 will have desired state: Ready
2022-04-05 18:54:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-97768251-1619064141 is in desired state: Ready
2022-04-05 18:54:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ed9330f3-kafka-clients-plain in namespace multiple-listeners-st
2022-04-05 18:54:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ed9330f3-kafka-clients-plain will be ready
2022-04-05 18:54:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ed9330f3-kafka-clients-plain is ready
2022-04-05 18:54:50 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:54:50 [main] [32mINFO [m [MultipleListenersST:274] Checking produced and consumed messages to pod:my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf
2022-04-05 18:54:50 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@62b7d772, messages=[], arguments=[--bootstrap-server, my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13901, --max-messages, 100, --topic, my-topic-97768251-1619064141], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13901', topicName='my-topic-97768251-1619064141', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@592b16a8}
2022-04-05 18:54:50 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13901:my-topic-97768251-1619064141 from pod my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf
2022-04-05 18:54:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf -n multiple-listeners-st -- /opt/kafka/producer.sh --bootstrap-server my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13901 --max-messages 100 --topic my-topic-97768251-1619064141
2022-04-05 18:54:52 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 18:54:52 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 18:54:52 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1661099, messages=[], arguments=[--group-id, my-consumer-group-324983639, --bootstrap-server, my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13901, --group-instance-id, instance966341964, --max-messages, 100, --topic, my-topic-97768251-1619064141], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13901', topicName='my-topic-97768251-1619064141', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-324983639', consumerInstanceId='instance966341964', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7d0f5a3c}
2022-04-05 18:54:52 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13901#my-topic-97768251-1619064141 from pod my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf
2022-04-05 18:54:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf -n multiple-listeners-st -- /opt/kafka/consumer.sh --group-id my-consumer-group-324983639 --bootstrap-server my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13901 --group-instance-id instance966341964 --max-messages 100 --topic my-topic-97768251-1619064141
2022-04-05 18:54:58 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 18:54:58 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 18:54:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-951375668-2077478474 in namespace multiple-listeners-st
2022-04-05 18:54:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-951375668-2077478474 will have desired state: Ready
2022-04-05 18:54:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-951375668-2077478474 is in desired state: Ready
2022-04-05 18:54:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ed9330f3-kafka-clients-plain in namespace multiple-listeners-st
2022-04-05 18:54:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ed9330f3-kafka-clients-plain will be ready
2022-04-05 18:54:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ed9330f3-kafka-clients-plain is ready
2022-04-05 18:54:59 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 18:54:59 [main] [32mINFO [m [MultipleListenersST:274] Checking produced and consumed messages to pod:my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf
2022-04-05 18:54:59 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5ca99361, messages=[], arguments=[--bootstrap-server, my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13902, --max-messages, 100, --topic, my-topic-951375668-2077478474], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13902', topicName='my-topic-951375668-2077478474', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@f9c84b}
2022-04-05 18:54:59 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13902:my-topic-951375668-2077478474 from pod my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf
2022-04-05 18:54:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf -n multiple-listeners-st -- /opt/kafka/producer.sh --bootstrap-server my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13902 --max-messages 100 --topic my-topic-951375668-2077478474
2022-04-05 18:55:02 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 18:55:02 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 18:55:02 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6a23cd5d, messages=[], arguments=[--group-id, my-consumer-group-33545942, --bootstrap-server, my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13902, --group-instance-id, instance294908051, --max-messages, 100, --topic, my-topic-951375668-2077478474], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf', podNamespace='multiple-listeners-st', bootstrapServer='my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13902', topicName='my-topic-951375668-2077478474', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-33545942', consumerInstanceId='instance294908051', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5b70ec72}
2022-04-05 18:55:02 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13902#my-topic-951375668-2077478474 from pod my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf
2022-04-05 18:55:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ed9330f3-kafka-clients-plain-5689d4d55f-c8glf -n multiple-listeners-st -- /opt/kafka/consumer.sh --group-id my-consumer-group-33545942 --bootstrap-server my-cluster-ed9330f3-kafka-bootstrap.multiple-listeners-st.svc:13902 --group-instance-id instance294908051 --max-messages 100 --topic my-topic-951375668-2077478474
2022-04-05 18:55:08 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 18:55:08 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 18:55:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:55:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultipleInternal
2022-04-05 18:55:08 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ed9330f3-kafka-clients-plain in namespace multiple-listeners-st
2022-04-05 18:55:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1521763301-1677229948 in namespace multiple-listeners-st
2022-04-05 18:55:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1783444637-593508475 in namespace multiple-listeners-st
2022-04-05 18:55:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ed9330f3 in namespace multiple-listeners-st
2022-04-05 18:55:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ed9330f3-kafka-clients-plain in namespace multiple-listeners-st
2022-04-05 18:55:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ed9330f3-kafka-clients-plain in namespace multiple-listeners-st
2022-04-05 18:55:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-97768251-1619064141 in namespace multiple-listeners-st
2022-04-05 18:55:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-951375668-2077478474 in namespace multiple-listeners-st
2022-04-05 18:55:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:55:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.listeners.MultipleListenersST.testMultipleInternal-FINISHED
2022-04-05 18:55:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:55:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:55:48 [main] [32mINFO [m [ResourceManager:346] In context MultipleListenersST is everything deleted.
2022-04-05 18:55:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 148.412 s - in io.strimzi.systemtest.kafka.listeners.MultipleListenersST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
2022-04-05 18:55:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: dynamic-conf-st
2022-04-05 18:55:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: dynamic-conf-st
2022-04-05 18:55:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: dynamic-conf-st
2022-04-05 18:55:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:55:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testSimpleDynamicConfiguration-STARTED
2022-04-05 18:55:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:55:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3cc31fc8 in namespace dynamic-conf-st
2022-04-05 18:55:53 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3cc31fc8 will have desired state: Ready
2022-04-05 18:57:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3cc31fc8 is in desired state: Ready
2022-04-05 18:57:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-3cc31fc8-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 18:57:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 18:57:11 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-05 18:57:11 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-3cc31fc8-kafka are stable
2022-04-05 18:57:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 18:57:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 18:57:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 18:57:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 18:57:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 18:57:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 18:57:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 18:57:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 18:57:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 18:57:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 18:57:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 18:57:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 18:57:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 18:57:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 18:57:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 18:57:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 18:57:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 18:57:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 18:57:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 18:57:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 18:57:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 18:57:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 18:57:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 18:57:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 18:57:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 18:57:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 18:57:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 18:57:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 18:57:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 18:57:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 18:57:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 18:57:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 18:57:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 18:57:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 18:57:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 18:57:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 18:57:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 18:57:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 18:57:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 18:57:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 18:57:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 18:57:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 18:57:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 18:57:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 18:57:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 18:57:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 18:57:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 18:57:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 18:57:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 18:57:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 18:57:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 18:57:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 18:57:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 18:57:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 18:57:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 18:57:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 18:57:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 18:57:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 18:57:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 18:57:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 18:57:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 18:57:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 18:57:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 18:57:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 18:57:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 18:57:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 18:57:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 18:57:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 18:57:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 18:57:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 18:57:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 18:57:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 18:57:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 18:57:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 18:57:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 18:57:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 18:57:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 18:57:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 18:57:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 18:57:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 18:57:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 18:57:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 18:57:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 18:57:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 18:57:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 18:57:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 18:57:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 18:57:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 18:57:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 18:57:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 18:57:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 18:57:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 18:57:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 18:57:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 18:57:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 18:57:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 18:57:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 18:57:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 18:57:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 18:57:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 18:57:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 18:57:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 18:57:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 18:57:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 18:57:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 18:57:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 18:57:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 18:57:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 18:57:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 18:57:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 18:57:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 18:57:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 18:57:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 18:57:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 18:57:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 18:57:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 18:57:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 18:57:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 18:57:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 18:57:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 18:57:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 18:57:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 18:57:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 18:57:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 18:57:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 18:57:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 18:57:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 18:57:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 18:57:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 18:57:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 18:57:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 18:57:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 18:57:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 18:57:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 18:57:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 18:57:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 18:57:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 18:57:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 18:57:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 18:57:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 18:57:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 18:57:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 18:57:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 18:57:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 18:57:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 18:57:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 18:57:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 18:58:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 18:58:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 18:58:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3cc31fc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 18:58:00 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-3cc31fc8-kafka-0 ,my-cluster-3cc31fc8-kafka-1 ,my-cluster-3cc31fc8-kafka-2
2022-04-05 18:58:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-3cc31fc8-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 18:58:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 18:58:03 [main] [32mINFO [m [DynamicConfST:102] Verify values after update
2022-04-05 18:58:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 18:58:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSimpleDynamicConfiguration
2022-04-05 18:58:03 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3cc31fc8 in namespace dynamic-conf-st
2022-04-05 18:58:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 18:58:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testSimpleDynamicConfiguration-FINISHED
2022-04-05 18:58:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 18:58:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 18:58:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testUpdateToExternalListenerCausesRollingRestart-STARTED
2022-04-05 18:58:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 18:58:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bf9f700c in namespace dynamic-conf-st
2022-04-05 18:58:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bf9f700c will have desired state: Ready
2022-04-05 18:59:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bf9f700c is in desired state: Ready
2022-04-05 18:59:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-bf9f700c-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 18:59:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 18:59:28 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-05 18:59:28 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-bf9f700c-kafka are stable
2022-04-05 18:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 18:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 18:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 18:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 18:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 18:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 18:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 18:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 18:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 18:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 18:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 18:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 18:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 18:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 18:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 18:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 18:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 18:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 18:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 18:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 18:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 18:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 18:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 18:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 18:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 18:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 18:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 18:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 18:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 18:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 18:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 18:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 18:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 18:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 18:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 18:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 18:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 18:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 18:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 18:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 18:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 18:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 18:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 18:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 18:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 18:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 18:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 18:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 18:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 18:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 18:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 18:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 18:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 18:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 18:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 18:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 18:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 18:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 18:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 18:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 18:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 18:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 18:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 18:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 18:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 18:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 18:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 18:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 18:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 18:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 18:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 18:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 18:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 18:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 18:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 18:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 18:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 18:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 18:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 18:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 18:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 18:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 18:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 18:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 18:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 18:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 18:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 18:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 18:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 18:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 18:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 18:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 18:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:00:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:00:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:00:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:00:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:00:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:00:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:00:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:00:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:00:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:00:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:00:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:00:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:00:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:00:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:00:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:00:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:00:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:00:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:00:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:00:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:00:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:00:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:00:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:00:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:00:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:00:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:00:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:00:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:00:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:00:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:00:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:00:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:00:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:00:18 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-bf9f700c-kafka-0 ,my-cluster-bf9f700c-kafka-1 ,my-cluster-bf9f700c-kafka-2
2022-04-05 19:00:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-bf9f700c-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:00:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:00:21 [main] [32mINFO [m [DynamicConfST:163] Updating listeners of Kafka cluster
2022-04-05 19:00:21 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-bf9f700c-kafka rolling update
2022-04-05 19:02:01 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-bf9f700c-kafka has been successfully rolled
2022-04-05 19:02:01 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-bf9f700c-kafka to be ready
2022-04-05 19:02:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bf9f700c will have desired state: Ready
2022-04-05 19:02:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bf9f700c is in desired state: Ready
2022-04-05 19:02:34 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-bf9f700c is ready
2022-04-05 19:02:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-bf9f700c-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:02:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:02:37 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-05 19:02:37 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-bf9f700c-kafka are stable
2022-04-05 19:02:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:02:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:02:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:02:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:02:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:02:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:02:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:02:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:02:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:02:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:02:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:02:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:02:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:02:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:02:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:02:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:02:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:02:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:02:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:02:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:02:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:02:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:02:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:02:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:02:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:02:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:02:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:02:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:02:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:02:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:02:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:02:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:02:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:02:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:02:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:02:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:02:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:02:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:02:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:02:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:02:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:02:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:02:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:02:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:02:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:02:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:02:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:02:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:02:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:02:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:02:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:02:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:02:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:02:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:02:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:02:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:02:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:02:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:02:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:02:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:02:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:02:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:02:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:02:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:02:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:02:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:02:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:02:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:02:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:03:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:03:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:03:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:03:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:03:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:03:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:03:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:03:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:03:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:03:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:03:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:03:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:03:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:03:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:03:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:03:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:03:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:03:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:03:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:03:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:03:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:03:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:03:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:03:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:03:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:03:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:03:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:03:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:03:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:03:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:03:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:03:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:03:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:03:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:03:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:03:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:03:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:03:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:03:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:03:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:03:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:03:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:03:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:03:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:03:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:03:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:03:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:03:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:03:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:03:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:03:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:03:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:03:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:03:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:03:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:03:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:03:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:03:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:03:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:03:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:03:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:03:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:03:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:03:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:03:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:03:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:03:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:03:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:03:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:03:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:03:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:03:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:03:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:03:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:03:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:03:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:03:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:03:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:03:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:03:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:03:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:03:27 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-bf9f700c-kafka-0 ,my-cluster-bf9f700c-kafka-1 ,my-cluster-bf9f700c-kafka-2
2022-04-05 19:03:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-bf9f700c-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:03:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:03:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-bf9f700c-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:03:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:03:32 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-05 19:03:33 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-bf9f700c-kafka are stable
2022-04-05 19:03:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:03:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:03:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:03:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:03:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:03:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:03:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:03:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:03:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:03:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:03:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:03:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:03:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:03:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:03:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:03:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:03:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:03:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:03:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:03:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:03:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:04:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:04:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:04:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:04:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:04:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:04:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:04:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:04:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:04:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:04:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:04:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:04:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:04:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:04:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:04:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:04:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:04:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:04:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:04:22 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-bf9f700c-kafka-0 ,my-cluster-bf9f700c-kafka-1 ,my-cluster-bf9f700c-kafka-2
2022-04-05 19:04:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-bf9f700c-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:04:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:04:25 [main] [32mINFO [m [DynamicConfST:214] Updating listeners of Kafka cluster
2022-04-05 19:04:25 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-bf9f700c-kafka rolling update
2022-04-05 19:05:40 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-bf9f700c-kafka has been successfully rolled
2022-04-05 19:05:40 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-bf9f700c-kafka to be ready
2022-04-05 19:06:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bf9f700c will have desired state: Ready
2022-04-05 19:06:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bf9f700c is in desired state: Ready
2022-04-05 19:06:07 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-bf9f700c is ready
2022-04-05 19:06:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-bf9f700c-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:06:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:06:10 [main] [32mINFO [m [DynamicConfST:380] Updating configuration of Kafka cluster
2022-04-05 19:06:10 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-bf9f700c-kafka are stable
2022-04-05 19:06:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:06:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:06:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 19:06:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:06:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:06:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 19:06:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:06:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:06:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 19:06:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:06:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:06:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 19:06:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:06:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:06:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 19:06:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:06:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:06:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 19:06:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:06:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:06:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 19:06:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:06:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:06:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 19:06:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:06:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:06:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 19:06:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:06:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:06:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 19:06:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:06:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:06:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 19:06:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:06:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:06:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 19:06:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:06:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:06:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 19:06:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:06:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:06:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 19:06:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:06:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:06:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 19:06:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:06:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:06:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 19:06:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:06:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:06:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 19:06:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:06:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:06:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 19:06:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:06:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:06:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 19:06:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:06:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:06:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 19:06:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:06:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:06:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 19:06:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:06:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:06:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 19:06:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:06:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:06:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 19:06:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:06:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:06:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 19:06:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:06:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:06:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 19:06:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:06:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:06:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 19:06:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:06:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:06:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 19:06:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:06:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:06:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 19:06:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:06:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:06:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 19:06:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:06:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:06:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 19:06:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:06:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:06:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 19:06:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:06:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:06:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 19:06:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:06:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:06:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 19:06:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:06:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:06:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 19:06:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:06:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:06:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 19:06:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:06:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:06:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 19:06:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:06:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:06:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 19:06:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:06:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:06:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 19:06:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:06:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:06:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 19:06:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:06:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:06:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 19:06:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:06:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:06:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 19:06:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:06:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:06:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 19:06:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:06:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:06:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 19:06:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:06:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:06:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 19:06:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:06:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:06:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 19:06:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:06:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:06:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 19:06:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:06:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:06:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 19:06:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:06:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:06:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 19:06:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:06:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:06:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 19:06:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:06:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:06:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-bf9f700c-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 19:06:59 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-bf9f700c-kafka-0 ,my-cluster-bf9f700c-kafka-1 ,my-cluster-bf9f700c-kafka-2
2022-04-05 19:07:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-st exec my-cluster-bf9f700c-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:07:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:07:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:07:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateToExternalListenerCausesRollingRestart
2022-04-05 19:07:02 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bf9f700c in namespace dynamic-conf-st
2022-04-05 19:07:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:07:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST.testUpdateToExternalListenerCausesRollingRestart-FINISHED
2022-04-05 19:07:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:07:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:07:12 [main] [32mINFO [m [ResourceManager:346] In context DynamicConfST is everything deleted.
2022-04-05 19:07:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 722.41 s - in io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
2022-04-05 19:07:56 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: dynamic-conf-shared-st
2022-04-05 19:07:56 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: dynamic-conf-shared-st
2022-04-05 19:07:56 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: dynamic-conf-shared-st
2022-04-05 19:07:56 [main] [32mINFO [m [DynamicConfSharedST:218] Deploying shared Kafka across all test cases!
2022-04-05 19:07:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-05 19:07:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: dynamic-configuration-shared-cluster-name will have desired state: Ready
2022-04-05 19:09:17 [main] [32mINFO [m [ResourceManager:444] Kafka: dynamic-configuration-shared-cluster-name is in desired state: Ready
2022-04-05 19:09:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:09:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-STARTED
2022-04-05 19:09:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:334] Kafka config {advertised.listeners=io.strimzi.kafka.config.model.ConfigModel@262b56ec, alter.config.policy.class.name=io.strimzi.kafka.config.model.ConfigModel@74be32c5, alter.log.dirs.replication.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@68946f95, alter.log.dirs.replication.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@738ca596, authorizer.class.name=io.strimzi.kafka.config.model.ConfigModel@f6c113d, auto.create.topics.enable=io.strimzi.kafka.config.model.ConfigModel@ac1320f, auto.leader.rebalance.enable=io.strimzi.kafka.config.model.ConfigModel@41621c05, background.threads=io.strimzi.kafka.config.model.ConfigModel@5754a1aa, broker.heartbeat.interval.ms=io.strimzi.kafka.config.model.ConfigModel@385ea784, broker.id=io.strimzi.kafka.config.model.ConfigModel@3b0cbbca, broker.id.generation.enable=io.strimzi.kafka.config.model.ConfigModel@6adf0a9a, broker.rack=io.strimzi.kafka.config.model.ConfigModel@18f4af9a, broker.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@555b4987, client.quota.callback.class=io.strimzi.kafka.config.model.ConfigModel@bd76a0d, compression.type=io.strimzi.kafka.config.model.ConfigModel@19ce2a37, connection.failed.authentication.delay.ms=io.strimzi.kafka.config.model.ConfigModel@24fbdeeb, connections.max.idle.ms=io.strimzi.kafka.config.model.ConfigModel@2be3ac82, connections.max.reauth.ms=io.strimzi.kafka.config.model.ConfigModel@1b543cf1, control.plane.listener.name=io.strimzi.kafka.config.model.ConfigModel@73a3223e, controlled.shutdown.enable=io.strimzi.kafka.config.model.ConfigModel@9d5b627, controlled.shutdown.max.retries=io.strimzi.kafka.config.model.ConfigModel@3fe49c23, controlled.shutdown.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@56d9c9a, controller.listener.names=io.strimzi.kafka.config.model.ConfigModel@6f35fcdb, controller.quorum.append.linger.ms=io.strimzi.kafka.config.model.ConfigModel@4b750b94, controller.quorum.election.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@506b935d, controller.quorum.election.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@398b4c86, controller.quorum.fetch.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@7918ac48, controller.quorum.request.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@1a523154, controller.quorum.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@162fa838, controller.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@75233907, controller.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@4965b107, controller.socket.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@42b6e1ee, create.topic.policy.class.name=io.strimzi.kafka.config.model.ConfigModel@29b3ffe8, default.replication.factor=io.strimzi.kafka.config.model.ConfigModel@45b400d8, delegation.token.expiry.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@21bd6ce0, delegation.token.expiry.time.ms=io.strimzi.kafka.config.model.ConfigModel@547150a8, delegation.token.master.key=io.strimzi.kafka.config.model.ConfigModel@620bb971, delegation.token.max.lifetime.ms=io.strimzi.kafka.config.model.ConfigModel@75cd728, delegation.token.secret.key=io.strimzi.kafka.config.model.ConfigModel@4dcc614f, delete.records.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@13668c4e, delete.topic.enable=io.strimzi.kafka.config.model.ConfigModel@2c197f62, fetch.max.bytes=io.strimzi.kafka.config.model.ConfigModel@4d1d185e, fetch.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@63f5ceab, group.initial.rebalance.delay.ms=io.strimzi.kafka.config.model.ConfigModel@44d63a67, group.max.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@2353bff0, group.max.size=io.strimzi.kafka.config.model.ConfigModel@6298c2c, group.min.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@4b648ad4, initial.broker.registration.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@3e9484dd, inter.broker.listener.name=io.strimzi.kafka.config.model.ConfigModel@8600c0, inter.broker.protocol.version=io.strimzi.kafka.config.model.ConfigModel@4a04a410, kafka.metrics.polling.interval.secs=io.strimzi.kafka.config.model.ConfigModel@2559a5ae, kafka.metrics.reporters=io.strimzi.kafka.config.model.ConfigModel@3ff16fb4, leader.imbalance.check.interval.seconds=io.strimzi.kafka.config.model.ConfigModel@f41f88a, leader.imbalance.per.broker.percentage=io.strimzi.kafka.config.model.ConfigModel@608ae956, listener.security.protocol.map=io.strimzi.kafka.config.model.ConfigModel@896443c, listeners=io.strimzi.kafka.config.model.ConfigModel@3c2e0655, log.cleaner.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@3c2b2cf2, log.cleaner.dedupe.buffer.size=io.strimzi.kafka.config.model.ConfigModel@bdca278, log.cleaner.delete.retention.ms=io.strimzi.kafka.config.model.ConfigModel@31d1a09b, log.cleaner.enable=io.strimzi.kafka.config.model.ConfigModel@7d81145a, log.cleaner.io.buffer.load.factor=io.strimzi.kafka.config.model.ConfigModel@1828eba4, log.cleaner.io.buffer.size=io.strimzi.kafka.config.model.ConfigModel@768955bb, log.cleaner.io.max.bytes.per.second=io.strimzi.kafka.config.model.ConfigModel@4ae0e689, log.cleaner.max.compaction.lag.ms=io.strimzi.kafka.config.model.ConfigModel@3fb6084b, log.cleaner.min.cleanable.ratio=io.strimzi.kafka.config.model.ConfigModel@601cb1d2, log.cleaner.min.compaction.lag.ms=io.strimzi.kafka.config.model.ConfigModel@5c8404e7, log.cleaner.threads=io.strimzi.kafka.config.model.ConfigModel@111d7550, log.cleanup.policy=io.strimzi.kafka.config.model.ConfigModel@1e66d368, log.dir=io.strimzi.kafka.config.model.ConfigModel@1bf17357, log.dirs=io.strimzi.kafka.config.model.ConfigModel@672efff2, log.flush.interval.messages=io.strimzi.kafka.config.model.ConfigModel@1d63a1b2, log.flush.interval.ms=io.strimzi.kafka.config.model.ConfigModel@3536cce5, log.flush.offset.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@254d7adf, log.flush.scheduler.interval.ms=io.strimzi.kafka.config.model.ConfigModel@350cd0eb, log.flush.start.offset.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@356289c9, log.index.interval.bytes=io.strimzi.kafka.config.model.ConfigModel@36303a64, log.index.size.max.bytes=io.strimzi.kafka.config.model.ConfigModel@786525ff, log.message.downconversion.enable=io.strimzi.kafka.config.model.ConfigModel@2bbd3990, log.message.format.version=io.strimzi.kafka.config.model.ConfigModel@ab0c1ef, log.message.timestamp.difference.max.ms=io.strimzi.kafka.config.model.ConfigModel@3de429c7, log.message.timestamp.type=io.strimzi.kafka.config.model.ConfigModel@6c7fb959, log.preallocate=io.strimzi.kafka.config.model.ConfigModel@2e4c6cff, log.retention.bytes=io.strimzi.kafka.config.model.ConfigModel@22ff7f60, log.retention.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@3e49d0e9, log.retention.hours=io.strimzi.kafka.config.model.ConfigModel@2fed0308, log.retention.minutes=io.strimzi.kafka.config.model.ConfigModel@620ba99e, log.retention.ms=io.strimzi.kafka.config.model.ConfigModel@3b56dec0, log.roll.hours=io.strimzi.kafka.config.model.ConfigModel@4b688fdb, log.roll.jitter.hours=io.strimzi.kafka.config.model.ConfigModel@c5a20fd, log.roll.jitter.ms=io.strimzi.kafka.config.model.ConfigModel@33223fb1, log.roll.ms=io.strimzi.kafka.config.model.ConfigModel@3e0f47cb, log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@31961186, log.segment.delete.delay.ms=io.strimzi.kafka.config.model.ConfigModel@6c168281, max.connection.creation.rate=io.strimzi.kafka.config.model.ConfigModel@4eebf705, max.connections=io.strimzi.kafka.config.model.ConfigModel@a1ec00c, max.connections.per.ip=io.strimzi.kafka.config.model.ConfigModel@b85fae8, max.connections.per.ip.overrides=io.strimzi.kafka.config.model.ConfigModel@53df6393, max.incremental.fetch.session.cache.slots=io.strimzi.kafka.config.model.ConfigModel@421df532, message.max.bytes=io.strimzi.kafka.config.model.ConfigModel@3eff43dd, metadata.log.dir=io.strimzi.kafka.config.model.ConfigModel@1a09bc50, metadata.log.max.record.bytes.between.snapshots=io.strimzi.kafka.config.model.ConfigModel@32e28779, metadata.log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@1ffb5072, metadata.log.segment.min.bytes=io.strimzi.kafka.config.model.ConfigModel@5b5e09fb, metadata.log.segment.ms=io.strimzi.kafka.config.model.ConfigModel@ce2c5fc, metadata.max.retention.bytes=io.strimzi.kafka.config.model.ConfigModel@2a1d4256, metadata.max.retention.ms=io.strimzi.kafka.config.model.ConfigModel@6f20efa7, metric.reporters=io.strimzi.kafka.config.model.ConfigModel@441a3269, metrics.num.samples=io.strimzi.kafka.config.model.ConfigModel@5e4dc233, metrics.recording.level=io.strimzi.kafka.config.model.ConfigModel@1e02345e, metrics.sample.window.ms=io.strimzi.kafka.config.model.ConfigModel@76b7bdee, min.insync.replicas=io.strimzi.kafka.config.model.ConfigModel@632b502b, node.id=io.strimzi.kafka.config.model.ConfigModel@53474a27, num.io.threads=io.strimzi.kafka.config.model.ConfigModel@5ce834d5, num.network.threads=io.strimzi.kafka.config.model.ConfigModel@17fbba6b, num.partitions=io.strimzi.kafka.config.model.ConfigModel@2ee80ab7, num.recovery.threads.per.data.dir=io.strimzi.kafka.config.model.ConfigModel@47176b3f, num.replica.alter.log.dirs.threads=io.strimzi.kafka.config.model.ConfigModel@5ac4a194, num.replica.fetchers=io.strimzi.kafka.config.model.ConfigModel@10a66045, offset.metadata.max.bytes=io.strimzi.kafka.config.model.ConfigModel@7e756d54, offsets.commit.required.acks=io.strimzi.kafka.config.model.ConfigModel@247bf36, offsets.commit.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@7df076eb, offsets.load.buffer.size=io.strimzi.kafka.config.model.ConfigModel@5e779558, offsets.retention.check.interval.ms=io.strimzi.kafka.config.model.ConfigModel@bbd4c0f, offsets.retention.minutes=io.strimzi.kafka.config.model.ConfigModel@343cec41, offsets.topic.compression.codec=io.strimzi.kafka.config.model.ConfigModel@4a859303, offsets.topic.num.partitions=io.strimzi.kafka.config.model.ConfigModel@28ba125e, offsets.topic.replication.factor=io.strimzi.kafka.config.model.ConfigModel@4906ee72, offsets.topic.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@1a0b4df7, password.encoder.cipher.algorithm=io.strimzi.kafka.config.model.ConfigModel@7c70c83e, password.encoder.iterations=io.strimzi.kafka.config.model.ConfigModel@4201d0c, password.encoder.key.length=io.strimzi.kafka.config.model.ConfigModel@7aab0684, password.encoder.keyfactory.algorithm=io.strimzi.kafka.config.model.ConfigModel@3a0f98d3, password.encoder.old.secret=io.strimzi.kafka.config.model.ConfigModel@40448694, password.encoder.secret=io.strimzi.kafka.config.model.ConfigModel@44082bed, principal.builder.class=io.strimzi.kafka.config.model.ConfigModel@66b59ace, process.roles=io.strimzi.kafka.config.model.ConfigModel@20ba5fcb, producer.purgatory.purge.interval.requests=io.strimzi.kafka.config.model.ConfigModel@442e1d6e, queued.max.request.bytes=io.strimzi.kafka.config.model.ConfigModel@417c0145, queued.max.requests=io.strimzi.kafka.config.model.ConfigModel@bd5804e, quota.window.num=io.strimzi.kafka.config.model.ConfigModel@79e3d2f8, quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@4d1265c7, remote.log.index.file.cache.total.size.bytes=io.strimzi.kafka.config.model.ConfigModel@6cc52309, remote.log.manager.task.interval.ms=io.strimzi.kafka.config.model.ConfigModel@4b35092f, remote.log.manager.task.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@2ca666a3, remote.log.manager.task.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@72c412ad, remote.log.manager.task.retry.jitter=io.strimzi.kafka.config.model.ConfigModel@375cba97, remote.log.manager.thread.pool.size=io.strimzi.kafka.config.model.ConfigModel@54c3a122, remote.log.metadata.manager.class.name=io.strimzi.kafka.config.model.ConfigModel@4bcf4667, remote.log.metadata.manager.class.path=io.strimzi.kafka.config.model.ConfigModel@194c74c9, remote.log.metadata.manager.impl.prefix=io.strimzi.kafka.config.model.ConfigModel@4b96fd75, remote.log.metadata.manager.listener.name=io.strimzi.kafka.config.model.ConfigModel@2158f94, remote.log.reader.max.pending.tasks=io.strimzi.kafka.config.model.ConfigModel@33580dcf, remote.log.reader.threads=io.strimzi.kafka.config.model.ConfigModel@49c8cd51, remote.log.storage.manager.class.name=io.strimzi.kafka.config.model.ConfigModel@3549fc48, remote.log.storage.manager.class.path=io.strimzi.kafka.config.model.ConfigModel@1b8ebc5a, remote.log.storage.manager.impl.prefix=io.strimzi.kafka.config.model.ConfigModel@68cbec91, remote.log.storage.system.enable=io.strimzi.kafka.config.model.ConfigModel@67e6169c, replica.fetch.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@1d370d94, replica.fetch.max.bytes=io.strimzi.kafka.config.model.ConfigModel@73b50e04, replica.fetch.min.bytes=io.strimzi.kafka.config.model.ConfigModel@44addb87, replica.fetch.response.max.bytes=io.strimzi.kafka.config.model.ConfigModel@13a87778, replica.fetch.wait.max.ms=io.strimzi.kafka.config.model.ConfigModel@36568334, replica.high.watermark.checkpoint.interval.ms=io.strimzi.kafka.config.model.ConfigModel@6dc87ed4, replica.lag.time.max.ms=io.strimzi.kafka.config.model.ConfigModel@4793f109, replica.selector.class=io.strimzi.kafka.config.model.ConfigModel@17d04d34, replica.socket.receive.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@159d33d9, replica.socket.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@3b0dc160, replication.quota.window.num=io.strimzi.kafka.config.model.ConfigModel@634e64b1, replication.quota.window.size.seconds=io.strimzi.kafka.config.model.ConfigModel@76e23c01, request.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@a9dcaff, reserved.broker.max.id=io.strimzi.kafka.config.model.ConfigModel@5fce0c0d, sasl.client.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@4fb580a9, sasl.enabled.mechanisms=io.strimzi.kafka.config.model.ConfigModel@28d0bf6a, sasl.jaas.config=io.strimzi.kafka.config.model.ConfigModel@4cfe42bd, sasl.kerberos.kinit.cmd=io.strimzi.kafka.config.model.ConfigModel@637f914b, sasl.kerberos.min.time.before.relogin=io.strimzi.kafka.config.model.ConfigModel@2cf545, sasl.kerberos.principal.to.local.rules=io.strimzi.kafka.config.model.ConfigModel@2daa31c5, sasl.kerberos.service.name=io.strimzi.kafka.config.model.ConfigModel@137f6567, sasl.kerberos.ticket.renew.jitter=io.strimzi.kafka.config.model.ConfigModel@c954b8a, sasl.kerberos.ticket.renew.window.factor=io.strimzi.kafka.config.model.ConfigModel@6b740180, sasl.login.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@17ac2132, sasl.login.class=io.strimzi.kafka.config.model.ConfigModel@7f902afd, sasl.login.connect.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@597ff79e, sasl.login.read.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@124c8530, sasl.login.refresh.buffer.seconds=io.strimzi.kafka.config.model.ConfigModel@649f93fa, sasl.login.refresh.min.period.seconds=io.strimzi.kafka.config.model.ConfigModel@1aa69a56, sasl.login.refresh.window.factor=io.strimzi.kafka.config.model.ConfigModel@3cc34d9b, sasl.login.refresh.window.jitter=io.strimzi.kafka.config.model.ConfigModel@4ad02a36, sasl.login.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@524860d5, sasl.login.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@7c9224e0, sasl.mechanism.controller.protocol=io.strimzi.kafka.config.model.ConfigModel@5a1b117c, sasl.mechanism.inter.broker.protocol=io.strimzi.kafka.config.model.ConfigModel@11510193, sasl.oauthbearer.clock.skew.seconds=io.strimzi.kafka.config.model.ConfigModel@8e95a4, sasl.oauthbearer.expected.audience=io.strimzi.kafka.config.model.ConfigModel@6dd60471, sasl.oauthbearer.expected.issuer=io.strimzi.kafka.config.model.ConfigModel@6fc47846, sasl.oauthbearer.jwks.endpoint.refresh.ms=io.strimzi.kafka.config.model.ConfigModel@7680b1b4, sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms=io.strimzi.kafka.config.model.ConfigModel@2d72975, sasl.oauthbearer.jwks.endpoint.retry.backoff.ms=io.strimzi.kafka.config.model.ConfigModel@5f7f50d2, sasl.oauthbearer.jwks.endpoint.url=io.strimzi.kafka.config.model.ConfigModel@13351533, sasl.oauthbearer.scope.claim.name=io.strimzi.kafka.config.model.ConfigModel@604b0bf0, sasl.oauthbearer.sub.claim.name=io.strimzi.kafka.config.model.ConfigModel@5b6c1a0d, sasl.oauthbearer.token.endpoint.url=io.strimzi.kafka.config.model.ConfigModel@7e303872, sasl.server.callback.handler.class=io.strimzi.kafka.config.model.ConfigModel@4517260a, security.inter.broker.protocol=io.strimzi.kafka.config.model.ConfigModel@7d3ba1d3, security.providers=io.strimzi.kafka.config.model.ConfigModel@463c700b, socket.connection.setup.timeout.max.ms=io.strimzi.kafka.config.model.ConfigModel@39302316, socket.connection.setup.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@456b654c, socket.receive.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@657e710b, socket.request.max.bytes=io.strimzi.kafka.config.model.ConfigModel@4067f987, socket.send.buffer.bytes=io.strimzi.kafka.config.model.ConfigModel@78774a0e, ssl.cipher.suites=io.strimzi.kafka.config.model.ConfigModel@66a80149, ssl.client.auth=io.strimzi.kafka.config.model.ConfigModel@7048c2be, ssl.enabled.protocols=io.strimzi.kafka.config.model.ConfigModel@f9cb6f1, ssl.endpoint.identification.algorithm=io.strimzi.kafka.config.model.ConfigModel@4d79ba36, ssl.engine.factory.class=io.strimzi.kafka.config.model.ConfigModel@6b7d5899, ssl.key.password=io.strimzi.kafka.config.model.ConfigModel@5d962a7a, ssl.keymanager.algorithm=io.strimzi.kafka.config.model.ConfigModel@37d73407, ssl.keystore.certificate.chain=io.strimzi.kafka.config.model.ConfigModel@37ff90c1, ssl.keystore.key=io.strimzi.kafka.config.model.ConfigModel@3647af37, ssl.keystore.location=io.strimzi.kafka.config.model.ConfigModel@5a6e867f, ssl.keystore.password=io.strimzi.kafka.config.model.ConfigModel@5497f639, ssl.keystore.type=io.strimzi.kafka.config.model.ConfigModel@1fa50df2, ssl.principal.mapping.rules=io.strimzi.kafka.config.model.ConfigModel@14103726, ssl.protocol=io.strimzi.kafka.config.model.ConfigModel@3a6316a5, ssl.provider=io.strimzi.kafka.config.model.ConfigModel@512e09ee, ssl.secure.random.implementation=io.strimzi.kafka.config.model.ConfigModel@665354a4, ssl.trustmanager.algorithm=io.strimzi.kafka.config.model.ConfigModel@736fe64f, ssl.truststore.certificates=io.strimzi.kafka.config.model.ConfigModel@519b00b9, ssl.truststore.location=io.strimzi.kafka.config.model.ConfigModel@70db121d, ssl.truststore.password=io.strimzi.kafka.config.model.ConfigModel@c519ed6, ssl.truststore.type=io.strimzi.kafka.config.model.ConfigModel@5c8d, transaction.abort.timed.out.transaction.cleanup.interval.ms=io.strimzi.kafka.config.model.ConfigModel@9170afc, transaction.max.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@21f4aa39, transaction.remove.expired.transaction.cleanup.interval.ms=io.strimzi.kafka.config.model.ConfigModel@21d327ff, transaction.state.log.load.buffer.size=io.strimzi.kafka.config.model.ConfigModel@2335e37c, transaction.state.log.min.isr=io.strimzi.kafka.config.model.ConfigModel@12445d0c, transaction.state.log.num.partitions=io.strimzi.kafka.config.model.ConfigModel@1665881f, transaction.state.log.replication.factor=io.strimzi.kafka.config.model.ConfigModel@2eb1b9f3, transaction.state.log.segment.bytes=io.strimzi.kafka.config.model.ConfigModel@2293915a, transactional.id.expiration.ms=io.strimzi.kafka.config.model.ConfigModel@128f0439, unclean.leader.election.enable=io.strimzi.kafka.config.model.ConfigModel@28904307, zookeeper.clientCnxnSocket=io.strimzi.kafka.config.model.ConfigModel@b4d09c7, zookeeper.connect=io.strimzi.kafka.config.model.ConfigModel@35ea50b5, zookeeper.connection.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@5fae24fd, zookeeper.max.in.flight.requests=io.strimzi.kafka.config.model.ConfigModel@750cdc74, zookeeper.session.timeout.ms=io.strimzi.kafka.config.model.ConfigModel@166ce023, zookeeper.set.acl=io.strimzi.kafka.config.model.ConfigModel@71e475a3, zookeeper.ssl.cipher.suites=io.strimzi.kafka.config.model.ConfigModel@5f432eae, zookeeper.ssl.client.enable=io.strimzi.kafka.config.model.ConfigModel@4cbfa64e, zookeeper.ssl.crl.enable=io.strimzi.kafka.config.model.ConfigModel@3da32a02, zookeeper.ssl.enabled.protocols=io.strimzi.kafka.config.model.ConfigModel@6f381978, zookeeper.ssl.endpoint.identification.algorithm=io.strimzi.kafka.config.model.ConfigModel@29c87c6f, zookeeper.ssl.keystore.location=io.strimzi.kafka.config.model.ConfigModel@187432ce, zookeeper.ssl.keystore.password=io.strimzi.kafka.config.model.ConfigModel@3c23e8f8, zookeeper.ssl.keystore.type=io.strimzi.kafka.config.model.ConfigModel@137fc5dd, zookeeper.ssl.ocsp.enable=io.strimzi.kafka.config.model.ConfigModel@79bef8d9, zookeeper.ssl.protocol=io.strimzi.kafka.config.model.ConfigModel@40655762, zookeeper.ssl.truststore.location=io.strimzi.kafka.config.model.ConfigModel@632213be, zookeeper.ssl.truststore.password=io.strimzi.kafka.config.model.ConfigModel@e1e632a, zookeeper.ssl.truststore.type=io.strimzi.kafka.config.model.ConfigModel@e82a00, zookeeper.sync.time.ms=io.strimzi.kafka.config.model.ConfigModel@6a5ca338}
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:336] Number of all kafka configs 261
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:356] Number of dynamic-configs 40
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:364] Number of forbidden-exception-configs 7
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:371] Size of dynamic-configs with forbidden-exception-configs 46
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] compression.type -> CLUSTER_WIDE:STRING
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.min.compaction.lag.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.retention.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] max.connections.per.ip.overrides -> CLUSTER_WIDE:STRING
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] metric.reporters -> CLUSTER_WIDE:LIST
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.flush.interval.messages -> CLUSTER_WIDE:LONG
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.message.timestamp.difference.max.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.flush.interval.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] principal.builder.class -> PER_BROKER:CLASS
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.delete.retention.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.buffer.size -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] min.insync.replicas -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] zookeeper.connection.timeout.ms -> READ_ONLY:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.threads -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.max.bytes.per.second -> CLUSTER_WIDE:DOUBLE
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.min.cleanable.ratio -> CLUSTER_WIDE:DOUBLE
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] num.recovery.threads.per.data.dir -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.retention.bytes -> CLUSTER_WIDE:LONG
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] num.network.threads -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.cleanup.policy -> CLUSTER_WIDE:LIST
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.message.timestamp.type -> CLUSTER_WIDE:STRING
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.preallocate -> CLUSTER_WIDE:BOOLEAN
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.roll.jitter.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] max.connections -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] max.connections.per.ip -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] background.threads -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.message.downconversion.enable -> CLUSTER_WIDE:BOOLEAN
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] message.max.bytes -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] ssl.protocol -> PER_BROKER:STRING
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] num.partitions -> READ_ONLY:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] num.io.threads -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] ssl.enabled.protocols -> PER_BROKER:LIST
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] max.connection.creation.rate -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.roll.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] ssl.cipher.suites -> PER_BROKER:LIST
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] unclean.leader.election.enable -> CLUSTER_WIDE:BOOLEAN
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.index.interval.bytes -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.backoff.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.segment.bytes -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.io.buffer.load.factor -> CLUSTER_WIDE:DOUBLE
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.index.size.max.bytes -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] zookeeper.connect -> READ_ONLY:STRING
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.segment.delete.delay.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.max.compaction.lag.ms -> CLUSTER_WIDE:LONG
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] num.replica.fetchers -> CLUSTER_WIDE:INT
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:373] log.cleaner.dedupe.buffer.size -> CLUSTER_WIDE:LONG
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, compression.type=lz4}'
2022-04-05 19:09:17 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-05 19:10:19 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-05 19:10:19 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is compression.type=lz4 and expected is compression.type=lz4
2022-04-05 19:10:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:10:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:10:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-1 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:10:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:10:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-2 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:10:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:10:28 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{compression.type=lz4, default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-05 19:10:28 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{compression.type=lz4, default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, log.preallocate=true}'
2022-04-05 19:10:28 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-05 19:11:30 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-05 19:11:30 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is log.preallocate=true and expected is log.preallocate=true
2022-04-05 19:11:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:11:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:11:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-1 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:11:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:11:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-2 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:11:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:11:39 [main] [32mINFO [m [KafkaUtils:234] Kafka config before updating '{compression.type=lz4, default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, log.preallocate=true, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3}'
2022-04-05 19:11:39 [main] [32mINFO [m [KafkaUtils:238] Kafka config after updating '{compression.type=lz4, default.replication.factor=3, inter.broker.protocol.version=3.1, log.message.format.version=3.1, log.preallocate=true, min.insync.replicas=2, offsets.topic.replication.factor=3, transaction.state.log.min.isr=2, transaction.state.log.replication.factor=3, log.message.downconversion.enable=false}'
2022-04-05 19:11:39 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-05 19:12:41 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-05 19:12:41 [main] [32mINFO [m [KafkaUtils:262] Dynamic Configuration in Kafka CR is log.message.downconversion.enable=false and expected is log.message.downconversion.enable=false
2022-04-05 19:12:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-0 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:12:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:12:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-1 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:12:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:12:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace dynamic-conf-shared-st exec dynamic-configuration-shared-cluster-name-kafka-2 -- /bin/bash -c bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe
2022-04-05 19:12:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:12:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:12:49 [main] [32mINFO [m [ResourceManager:346] In context testDynConfiguration is everything deleted.
2022-04-05 19:12:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:12:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST.testDynConfiguration-FINISHED
2022-04-05 19:12:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:12:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:12:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for DynamicConfSharedST
2022-04-05 19:12:49 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka dynamic-configuration-shared-cluster-name in namespace dynamic-conf-shared-st
2022-04-05 19:12:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 314.655 s - in io.strimzi.systemtest.kafka.dynamicconfiguration.DynamicConfSharedST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.KafkaST
2022-04-05 19:13:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: kafka-st
2022-04-05 19:13:10 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kafka-st
2022-04-05 19:13:10 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: kafka-st
2022-04-05 19:13:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:13:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaOffsetsReplicationFactorHigherThanReplicas-STARTED
2022-04-05 19:13:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:13:10 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-32 for test case:testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-05 19:13:10 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-32
2022-04-05 19:13:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-32
2022-04-05 19:13:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-32
2022-04-05 19:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-417c5963 in namespace namespace-32
2022-04-05 19:13:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-32
2022-04-05 19:13:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:13:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-05 19:13:13 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-417c5963 in namespace namespace-32
2022-04-05 19:13:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:13:13 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-32 for test case:testKafkaOffsetsReplicationFactorHigherThanReplicas
2022-04-05 19:13:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaOffsetsReplicationFactorHigherThanReplicas-FINISHED
2022-04-05 19:13:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:13:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:13:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserOperator-STARTED
2022-04-05 19:13:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:13:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-33 for test case:testEntityOperatorWithoutUserOperator
2022-04-05 19:13:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-33
2022-04-05 19:13:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-33
2022-04-05 19:13:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-33
2022-04-05 19:13:18 [main] [32mINFO [m [KafkaST:787] Deploying Kafka cluster without UO in EO
2022-04-05 19:13:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-38dd7efb in namespace namespace-33
2022-04-05 19:13:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-33
2022-04-05 19:13:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-38dd7efb will have desired state: Ready
2022-04-05 19:14:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-38dd7efb is in desired state: Ready
2022-04-05 19:14:35 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 76 seconds
2022-04-05 19:14:35 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-05 19:14:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:14:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutUserOperator
2022-04-05 19:14:35 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-38dd7efb in namespace namespace-33
2022-04-05 19:14:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:14:45 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-33 for test case:testEntityOperatorWithoutUserOperator
2022-04-05 19:15:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserOperator-FINISHED
2022-04-05 19:15:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:15:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:15:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutTopicOperator-STARTED
2022-04-05 19:15:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:15:28 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-34 for test case:testEntityOperatorWithoutTopicOperator
2022-04-05 19:15:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-34
2022-04-05 19:15:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-34
2022-04-05 19:15:28 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-34
2022-04-05 19:15:28 [main] [32mINFO [m [KafkaST:757] Deploying Kafka cluster without TO in EO
2022-04-05 19:15:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f822e4fd in namespace namespace-34
2022-04-05 19:15:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-34
2022-04-05 19:15:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f822e4fd will have desired state: Ready
2022-04-05 19:16:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f822e4fd is in desired state: Ready
2022-04-05 19:16:40 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 71 seconds
2022-04-05 19:16:40 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-05 19:16:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:16:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutTopicOperator
2022-04-05 19:16:40 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f822e4fd in namespace namespace-34
2022-04-05 19:16:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:16:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-34 for test case:testEntityOperatorWithoutTopicOperator
2022-04-05 19:17:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutTopicOperator-FINISHED
2022-04-05 19:17:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:17:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:17:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testTopicWithoutLabels-STARTED
2022-04-05 19:17:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:17:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-35 for test case:testTopicWithoutLabels
2022-04-05 19:17:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-35
2022-04-05 19:17:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-35
2022-04-05 19:17:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-35
2022-04-05 19:17:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-994ae841 in namespace namespace-35
2022-04-05 19:17:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-35
2022-04-05 19:17:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-994ae841 will have desired state: Ready
2022-04-05 19:18:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-994ae841 is in desired state: Ready
2022-04-05 19:18:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic topic-without-labels in namespace namespace-35
2022-04-05 19:18:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-35
2022-04-05 19:18:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-994ae841-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 19:18:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:18:45 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic topic-without-labels deletion
2022-04-05 19:18:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-35 exec my-cluster-994ae841-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 19:18:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:18:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:18:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicWithoutLabels
2022-04-05 19:18:48 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic topic-without-labels in namespace namespace-35
2022-04-05 19:18:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-994ae841 in namespace namespace-35
2022-04-05 19:18:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:18:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-35 for test case:testTopicWithoutLabels
2022-04-05 19:19:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testTopicWithoutLabels-FINISHED
2022-04-05 19:19:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:19:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:19:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveTopicOperatorFromEntityOperator-STARTED
2022-04-05 19:19:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:19:41 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-36 for test case:testRemoveTopicOperatorFromEntityOperator
2022-04-05 19:19:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-36
2022-04-05 19:19:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-36
2022-04-05 19:19:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-36
2022-04-05 19:19:41 [main] [32mINFO [m [KafkaST:623] Deploying Kafka cluster my-cluster-07a42414
2022-04-05 19:19:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-07a42414 in namespace namespace-36
2022-04-05 19:19:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-36
2022-04-05 19:19:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-07a42414 will have desired state: Ready
2022-04-05 19:20:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-07a42414 is in desired state: Ready
2022-04-05 19:20:57 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-07a42414-entity-operator-6878bcf84-dgvbk will be deleted
2022-04-05 19:21:07 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-07a42414-entity-operator-6878bcf84-dgvbk deleted
2022-04-05 19:21:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-07a42414-entity-operator will be ready
2022-04-05 19:21:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-07a42414-entity-operator is ready
2022-04-05 19:21:20 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-07a42414-entity-operator to be ready
2022-04-05 19:21:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-07a42414-entity-operator is ready
2022-04-05 19:21:30 [main] [32mINFO [m [PodUtils:201] Wait until Pod my-cluster-07a42414-entity-operator will have 1 containers
2022-04-05 19:21:30 [main] [32mINFO [m [PodUtils:205] Pod my-cluster-07a42414-entity-operator has 1 containers
2022-04-05 19:21:30 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-07a42414-entity-operator-fc64b69f7-8nlmt will be deleted
2022-04-05 19:21:40 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-07a42414-entity-operator-fc64b69f7-8nlmt deleted
2022-04-05 19:21:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-07a42414-entity-operator will be ready
2022-04-05 19:22:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-07a42414-entity-operator is ready
2022-04-05 19:22:01 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-07a42414-entity-operator to be ready
2022-04-05 19:22:11 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-07a42414-entity-operator is ready
2022-04-05 19:22:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:22:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveTopicOperatorFromEntityOperator
2022-04-05 19:22:11 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-07a42414 in namespace namespace-36
2022-04-05 19:22:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:22:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-36 for test case:testRemoveTopicOperatorFromEntityOperator
2022-04-05 19:23:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveTopicOperatorFromEntityOperator-FINISHED
2022-04-05 19:23:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:23:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:23:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserAndTopicOperators-STARTED
2022-04-05 19:23:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:23:04 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-37 for test case:testEntityOperatorWithoutUserAndTopicOperators
2022-04-05 19:23:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-37
2022-04-05 19:23:04 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-37
2022-04-05 19:23:04 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-37
2022-04-05 19:23:04 [main] [32mINFO [m [KafkaST:814] Deploying Kafka cluster without UO and TO in EO
2022-04-05 19:23:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9dca48c6 in namespace namespace-37
2022-04-05 19:23:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-37
2022-04-05 19:23:04 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9dca48c6 will have desired state: Ready
2022-04-05 19:23:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9dca48c6 is in desired state: Ready
2022-04-05 19:23:53 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 48 seconds
2022-04-05 19:23:53 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-05 19:23:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:23:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEntityOperatorWithoutUserAndTopicOperators
2022-04-05 19:23:53 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9dca48c6 in namespace namespace-37
2022-04-05 19:24:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:24:03 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-37 for test case:testEntityOperatorWithoutUserAndTopicOperators
2022-04-05 19:24:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEntityOperatorWithoutUserAndTopicOperators-FINISHED
2022-04-05 19:24:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:24:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:24:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserAndTopicOperatorsFromEntityOperator-STARTED
2022-04-05 19:24:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:24:30 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-38 for test case:testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-05 19:24:30 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-38
2022-04-05 19:24:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-38
2022-04-05 19:24:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-38
2022-04-05 19:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e93c5cd6 in namespace namespace-38
2022-04-05 19:24:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-38
2022-04-05 19:24:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e93c5cd6 will have desired state: Ready
2022-04-05 19:25:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e93c5cd6 is in desired state: Ready
2022-04-05 19:25:46 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-e93c5cd6-entity-operator will have stable 0 replicas
2022-04-05 19:25:46 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:25:47 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:25:48 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:25:49 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:25:50 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:25:51 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:25:52 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:25:53 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-05 19:25:54 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-05 19:25:55 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-05 19:25:56 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-05 19:25:57 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-05 19:25:58 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-05 19:25:59 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-05 19:26:00 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-05 19:26:01 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-05 19:26:02 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-05 19:26:03 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-05 19:26:04 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-05 19:26:05 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-05 19:26:06 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-05 19:26:07 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-05 19:26:08 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-05 19:26:09 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-05 19:26:10 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-05 19:26:11 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-05 19:26:12 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-05 19:26:13 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-05 19:26:13 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-e93c5cd6-entity-operator has 0 replicas
2022-04-05 19:26:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-e93c5cd6-entity-operator will be ready
2022-04-05 19:26:44 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-e93c5cd6-entity-operator is ready
2022-04-05 19:26:44 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 134 seconds
2022-04-05 19:26:45 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-05 19:26:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:26:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-05 19:26:45 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e93c5cd6 in namespace namespace-38
2022-04-05 19:26:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:26:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-38 for test case:testRemoveUserAndTopicOperatorsFromEntityOperator
2022-04-05 19:27:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserAndTopicOperatorsFromEntityOperator-FINISHED
2022-04-05 19:27:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:27:38 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:27:38 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testConsumerOffsetFiles-STARTED
2022-04-05 19:27:38 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:27:38 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-39 for test case:testConsumerOffsetFiles
2022-04-05 19:27:38 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-39
2022-04-05 19:27:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-39
2022-04-05 19:27:38 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-39
2022-04-05 19:27:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4f8987ea in namespace namespace-39
2022-04-05 19:27:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-05 19:27:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4f8987ea will have desired state: Ready
2022-04-05 19:28:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4f8987ea is in desired state: Ready
2022-04-05 19:28:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-485931110-1051111253 in namespace namespace-39
2022-04-05 19:28:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-05 19:28:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-485931110-1051111253 will have desired state: Ready
2022-04-05 19:28:58 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-485931110-1051111253 is in desired state: Ready
2022-04-05 19:28:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4f8987ea-kafka-clients in namespace namespace-39
2022-04-05 19:28:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-39
2022-04-05 19:28:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4f8987ea-kafka-clients will be ready
2022-04-05 19:29:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4f8987ea-kafka-clients is ready
2022-04-05 19:29:00 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 19:29:00 [main] [32mINFO [m [KafkaST:1415] Executing command cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V in my-cluster-4f8987ea-kafka-0
2022-04-05 19:29:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-39 exec my-cluster-4f8987ea-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V
2022-04-05 19:29:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:29:01 [main] [32mINFO [m [KafkaST:1422] Result: 
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99

2022-04-05 19:29:01 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@26583b1e, messages=[], arguments=[--bootstrap-server, my-cluster-4f8987ea-kafka-bootstrap.namespace-39.svc:9092, --max-messages, 100, --topic, my-topic-485931110-1051111253], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4f8987ea-kafka-clients-74c8b8dddb-5wd72', podNamespace='namespace-39', bootstrapServer='my-cluster-4f8987ea-kafka-bootstrap.namespace-39.svc:9092', topicName='my-topic-485931110-1051111253', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@a06fd0c}
2022-04-05 19:29:01 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-4f8987ea-kafka-bootstrap.namespace-39.svc:9092:my-topic-485931110-1051111253 from pod my-cluster-4f8987ea-kafka-clients-74c8b8dddb-5wd72
2022-04-05 19:29:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4f8987ea-kafka-clients-74c8b8dddb-5wd72 -n namespace-39 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-4f8987ea-kafka-bootstrap.namespace-39.svc:9092 --max-messages 100 --topic my-topic-485931110-1051111253
2022-04-05 19:29:03 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 19:29:03 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 19:29:03 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@b77190b, messages=[], arguments=[--group-id, my-consumer-group-547745782, --bootstrap-server, my-cluster-4f8987ea-kafka-bootstrap.namespace-39.svc:9092, --group-instance-id, instance868282215, --max-messages, 100, --topic, my-topic-485931110-1051111253], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4f8987ea-kafka-clients-74c8b8dddb-5wd72', podNamespace='namespace-39', bootstrapServer='my-cluster-4f8987ea-kafka-bootstrap.namespace-39.svc:9092', topicName='my-topic-485931110-1051111253', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-547745782', consumerInstanceId='instance868282215', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@56b5047b}
2022-04-05 19:29:03 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4f8987ea-kafka-bootstrap.namespace-39.svc:9092#my-topic-485931110-1051111253 from pod my-cluster-4f8987ea-kafka-clients-74c8b8dddb-5wd72
2022-04-05 19:29:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4f8987ea-kafka-clients-74c8b8dddb-5wd72 -n namespace-39 -- /opt/kafka/consumer.sh --group-id my-consumer-group-547745782 --bootstrap-server my-cluster-4f8987ea-kafka-bootstrap.namespace-39.svc:9092 --group-instance-id instance868282215 --max-messages 100 --topic my-topic-485931110-1051111253
2022-04-05 19:29:09 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 19:29:09 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 19:29:09 [main] [32mINFO [m [KafkaST:1429] Executing command cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V in my-cluster-4f8987ea-kafka-0
2022-04-05 19:29:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-39 exec my-cluster-4f8987ea-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/;ls -1 | sed -n "s#__consumer_offsets-\([0-9]*\)#\1#p" | sort -V
2022-04-05 19:29:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:29:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:29:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConsumerOffsetFiles
2022-04-05 19:29:09 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-485931110-1051111253 in namespace namespace-39
2022-04-05 19:29:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4f8987ea-kafka-clients in namespace namespace-39
2022-04-05 19:29:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4f8987ea in namespace namespace-39
2022-04-05 19:29:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:29:49 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-39 for test case:testConsumerOffsetFiles
2022-04-05 19:30:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testConsumerOffsetFiles-FINISHED
2022-04-05 19:30:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:30:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:30:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testAppDomainLabels-STARTED
2022-04-05 19:30:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:30:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-40 for test case:testAppDomainLabels
2022-04-05 19:30:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-40
2022-04-05 19:30:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-40
2022-04-05 19:30:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-40
2022-04-05 19:30:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ccde6ae0 in namespace namespace-40
2022-04-05 19:30:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-40
2022-04-05 19:30:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ccde6ae0 will have desired state: Ready
2022-04-05 19:31:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ccde6ae0 is in desired state: Ready
2022-04-05 19:31:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2004795925-1715948944 in namespace namespace-40
2022-04-05 19:31:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-40
2022-04-05 19:31:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2004795925-1715948944 will have desired state: Ready
2022-04-05 19:31:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2004795925-1715948944 is in desired state: Ready
2022-04-05 19:31:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ccde6ae0-kafka-clients in namespace namespace-40
2022-04-05 19:31:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-40
2022-04-05 19:31:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ccde6ae0-kafka-clients will be ready
2022-04-05 19:31:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ccde6ae0-kafka-clients is ready
2022-04-05 19:31:18 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1220] ---> PODS <---
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1232] ---> STATEFUL SETS <---
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1236] Getting labels from stateful set of kafka resource
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-ccde6ae0-kafka, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1241] Getting labels from stateful set of zookeeper resource
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-ccde6ae0-zookeeper, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1244] ---> SERVICES <---
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-ccde6ae0-kafka-bootstrap service
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/discovery=true, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-ccde6ae0-kafka, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-ccde6ae0-kafka-brokers service
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-ccde6ae0-kafka, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-ccde6ae0-zookeeper-client service
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-ccde6ae0-zookeeper-client, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1251] Getting labels from my-cluster-ccde6ae0-zookeeper-nodes service
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1765] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-ccde6ae0-zookeeper, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1255] ---> SECRETS <---
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-ccde6ae0-clients-ca secret
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-ccde6ae0-clients-ca-cert secret
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-ccde6ae0-cluster-ca secret
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-ccde6ae0-cluster-ca-cert secret
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-ccde6ae0-cluster-operator-certs secret
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-ccde6ae0-entity-topic-operator-certs secret
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-topic-operator, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-ccde6ae0-entity-user-operator-certs secret
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-user-operator, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-ccde6ae0-kafka-brokers secret
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1262] Getting labels from my-cluster-ccde6ae0-zookeeper-nodes secret
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1266] ---> CONFIG MAPS <---
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-ccde6ae0-entity-topic-operator-config config map
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-topic-operator, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-ccde6ae0-entity-user-operator-config config map
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=entity-user-operator, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-ccde6ae0-kafka-config config map
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-ccde6ae0-kafka, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1271] Getting labels from my-cluster-ccde6ae0-zookeeper-config config map
2022-04-05 19:31:18 [main] [32mINFO [m [KafkaST:1772] Verifying labels {app.kubernetes.io/instance=my-cluster-ccde6ae0, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-ccde6ae0, strimzi.io/cluster=my-cluster-ccde6ae0, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testAppDomainLabels}
2022-04-05 19:31:18 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@66484d54, messages=[], arguments=[--bootstrap-server, my-cluster-ccde6ae0-kafka-bootstrap.namespace-40.svc:9092, --max-messages, 100, --topic, my-topic-2004795925-1715948944], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-ccde6ae0-kafka-clients-5f9849cd56-prcsp', podNamespace='namespace-40', bootstrapServer='my-cluster-ccde6ae0-kafka-bootstrap.namespace-40.svc:9092', topicName='my-topic-2004795925-1715948944', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5f2d12b7}
2022-04-05 19:31:18 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-ccde6ae0-kafka-bootstrap.namespace-40.svc:9092:my-topic-2004795925-1715948944 from pod my-cluster-ccde6ae0-kafka-clients-5f9849cd56-prcsp
2022-04-05 19:31:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ccde6ae0-kafka-clients-5f9849cd56-prcsp -n namespace-40 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-ccde6ae0-kafka-bootstrap.namespace-40.svc:9092 --max-messages 100 --topic my-topic-2004795925-1715948944
2022-04-05 19:31:20 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 19:31:20 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 19:31:20 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4eeb0a35, messages=[], arguments=[--group-id, my-consumer-group-744017122, --bootstrap-server, my-cluster-ccde6ae0-kafka-bootstrap.namespace-40.svc:9092, --group-instance-id, instance879607376, --max-messages, 100, --topic, my-topic-2004795925-1715948944], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ccde6ae0-kafka-clients-5f9849cd56-prcsp', podNamespace='namespace-40', bootstrapServer='my-cluster-ccde6ae0-kafka-bootstrap.namespace-40.svc:9092', topicName='my-topic-2004795925-1715948944', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-744017122', consumerInstanceId='instance879607376', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@79e40714}
2022-04-05 19:31:20 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-ccde6ae0-kafka-bootstrap.namespace-40.svc:9092#my-topic-2004795925-1715948944 from pod my-cluster-ccde6ae0-kafka-clients-5f9849cd56-prcsp
2022-04-05 19:31:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ccde6ae0-kafka-clients-5f9849cd56-prcsp -n namespace-40 -- /opt/kafka/consumer.sh --group-id my-consumer-group-744017122 --bootstrap-server my-cluster-ccde6ae0-kafka-bootstrap.namespace-40.svc:9092 --group-instance-id instance879607376 --max-messages 100 --topic my-topic-2004795925-1715948944
2022-04-05 19:31:26 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 19:31:26 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 19:31:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:31:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAppDomainLabels
2022-04-05 19:31:26 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2004795925-1715948944 in namespace namespace-40
2022-04-05 19:31:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ccde6ae0-kafka-clients in namespace namespace-40
2022-04-05 19:31:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ccde6ae0 in namespace namespace-40
2022-04-05 19:32:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:32:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-40 for test case:testAppDomainLabels
2022-04-05 19:32:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testAppDomainLabels-FINISHED
2022-04-05 19:32:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:32:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:32:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserOperatorFromEntityOperator-STARTED
2022-04-05 19:32:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:32:12 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-41 for test case:testRemoveUserOperatorFromEntityOperator
2022-04-05 19:32:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-41
2022-04-05 19:32:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-41
2022-04-05 19:32:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-41
2022-04-05 19:32:12 [main] [32mINFO [m [KafkaST:669] Deploying Kafka cluster my-cluster-3d9b01ae
2022-04-05 19:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3d9b01ae in namespace namespace-41
2022-04-05 19:32:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-41
2022-04-05 19:32:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3d9b01ae will have desired state: Ready
2022-04-05 19:33:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3d9b01ae is in desired state: Ready
2022-04-05 19:33:26 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-3d9b01ae-entity-operator-99985b748-42l6x will be deleted
2022-04-05 19:33:36 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-3d9b01ae-entity-operator-99985b748-42l6x deleted
2022-04-05 19:33:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3d9b01ae-entity-operator will be ready
2022-04-05 19:34:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3d9b01ae-entity-operator is ready
2022-04-05 19:34:20 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-3d9b01ae-entity-operator to be ready
2022-04-05 19:34:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-3d9b01ae-entity-operator is ready
2022-04-05 19:34:30 [main] [32mINFO [m [PodUtils:201] Wait until Pod my-cluster-3d9b01ae-entity-operator will have 2 containers
2022-04-05 19:34:30 [main] [32mINFO [m [PodUtils:205] Pod my-cluster-3d9b01ae-entity-operator has 2 containers
2022-04-05 19:34:30 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-3d9b01ae-entity-operator-646645cc87-fgzgw will be deleted
2022-04-05 19:34:35 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-3d9b01ae-entity-operator-646645cc87-fgzgw deleted
2022-04-05 19:34:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3d9b01ae-entity-operator will be ready
2022-04-05 19:35:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3d9b01ae-entity-operator is ready
2022-04-05 19:35:23 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-3d9b01ae-entity-operator to be ready
2022-04-05 19:35:33 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-3d9b01ae-entity-operator is ready
2022-04-05 19:35:34 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 201 seconds
2022-04-05 19:35:34 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-05 19:35:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:35:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRemoveUserOperatorFromEntityOperator
2022-04-05 19:35:34 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3d9b01ae in namespace namespace-41
2022-04-05 19:35:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:35:44 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-41 for test case:testRemoveUserOperatorFromEntityOperator
2022-04-05 19:36:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testRemoveUserOperatorFromEntityOperator-FINISHED
2022-04-05 19:36:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:36:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:36:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testUOListeningOnlyUsersInSameCluster-STARTED
2022-04-05 19:36:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:36:27 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-42 for test case:testUOListeningOnlyUsersInSameCluster
2022-04-05 19:36:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-42
2022-04-05 19:36:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-42
2022-04-05 19:36:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-42
2022-04-05 19:36:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1 in namespace namespace-42
2022-04-05 19:36:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-42
2022-04-05 19:36:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1 will have desired state: Ready
2022-04-05 19:37:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1 is in desired state: Ready
2022-04-05 19:37:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2 in namespace namespace-42
2022-04-05 19:37:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-42
2022-04-05 19:37:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2 will have desired state: Ready
2022-04-05 19:38:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2 is in desired state: Ready
2022-04-05 19:38:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1059661081-2036240358 in namespace namespace-42
2022-04-05 19:38:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-42
2022-04-05 19:38:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1059661081-2036240358 will have desired state: Ready
2022-04-05 19:38:50 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1059661081-2036240358 is in desired state: Ready
2022-04-05 19:38:50 [main] [32mINFO [m [KafkaST:1292] Verifying that user my-user-1059661081-2036240358 in cluster my-cluster-1 is created
2022-04-05 19:38:50 [main] [32mINFO [m [KafkaST:1297] Verifying that user my-user-1059661081-2036240358 in cluster my-cluster-2 is not created
2022-04-05 19:38:50 [main] [32mINFO [m [KafkaST:1302] Verifying that user belongs to my-cluster-1 cluster
2022-04-05 19:38:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:38:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUOListeningOnlyUsersInSameCluster
2022-04-05 19:38:50 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2 in namespace namespace-42
2022-04-05 19:38:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1059661081-2036240358 in namespace namespace-42
2022-04-05 19:38:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1 in namespace namespace-42
2022-04-05 19:39:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:39:10 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-42 for test case:testUOListeningOnlyUsersInSameCluster
2022-04-05 19:39:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testUOListeningOnlyUsersInSameCluster-FINISHED
2022-04-05 19:39:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:39:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:39:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrueFalse-STARTED
2022-04-05 19:39:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:39:37 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-43 for test case:testKafkaJBODDeleteClaimsTrueFalse
2022-04-05 19:39:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-43
2022-04-05 19:39:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-43
2022-04-05 19:39:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-43
2022-04-05 19:39:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bf20ea8c in namespace namespace-43
2022-04-05 19:39:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-43
2022-04-05 19:39:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bf20ea8c will have desired state: Ready
2022-04-05 19:40:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bf20ea8c is in desired state: Ready
2022-04-05 19:40:53 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-bf20ea8c-kafka-0
2022-04-05 19:40:53 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-bf20ea8c-kafka-1
2022-04-05 19:40:53 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-bf20ea8c-kafka-0
2022-04-05 19:40:53 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-bf20ea8c-kafka-1
2022-04-05 19:40:53 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-05 19:40:53 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-05 19:40:53 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-05 19:40:53 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-05 19:40:53 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-05 19:40:53 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-05 19:40:53 [main] [32mINFO [m [KafkaST:882] Deleting cluster
2022-04-05 19:40:53 [main] [32mINFO [m [KafkaST:885] Waiting for PVC deletion
2022-04-05 19:41:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:41:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsTrueFalse
2022-04-05 19:41:28 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bf20ea8c in namespace namespace-43
2022-04-05 19:41:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:41:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-43 for test case:testKafkaJBODDeleteClaimsTrueFalse
2022-04-05 19:41:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrueFalse-FINISHED
2022-04-05 19:41:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:41:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:41:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testLabelsAndAnnotationForPVC-STARTED
2022-04-05 19:41:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:41:39 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-44 for test case:testLabelsAndAnnotationForPVC
2022-04-05 19:41:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-44
2022-04-05 19:41:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-44
2022-04-05 19:41:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-44
2022-04-05 19:41:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-dbb4d051 in namespace namespace-44
2022-04-05 19:41:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-44
2022-04-05 19:41:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-dbb4d051 will have desired state: Ready
2022-04-05 19:42:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-dbb4d051 is in desired state: Ready
2022-04-05 19:42:52 [main] [32mINFO [m [KafkaST:1510] Check if Kubernetes labels are applied
2022-04-05 19:42:52 [main] [32mINFO [m [KafkaST:1517] Kubernetes labels are correctly set and present
2022-04-05 19:42:52 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-dbb4d051-kafka-0 - testValue = testValue
2022-04-05 19:42:52 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-dbb4d051-kafka-1 - testValue = testValue
2022-04-05 19:42:52 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-0-my-cluster-dbb4d051-kafka-2 - testValue = testValue
2022-04-05 19:42:52 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-dbb4d051-kafka-0 - testValue = testValue
2022-04-05 19:42:52 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-dbb4d051-kafka-1 - testValue = testValue
2022-04-05 19:42:52 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-1-my-cluster-dbb4d051-kafka-2 - testValue = testValue
2022-04-05 19:42:52 [main] [32mINFO [m [KafkaST:1525] Verifying that PVC label data-my-cluster-dbb4d051-zookeeper-0 - testValue = testValue
2022-04-05 19:42:52 [main] [32mINFO [m [KafkaST:1535] Replacing kafka && zookeeper labels and annotations from testKey to editedTestValue
2022-04-05 19:42:52 [main] [32mINFO [m [PersistentVolumeClaimUtils:30] Wait until PVC labels will change {testKey=editedTestValue}
2022-04-05 19:42:55 [main] [32mINFO [m [PersistentVolumeClaimUtils:46] PVC labels has changed {testKey=editedTestValue}
2022-04-05 19:42:55 [main] [32mINFO [m [PersistentVolumeClaimUtils:50] Wait until PVC annotation will change {testKey=editedTestValue}
2022-04-05 19:42:55 [main] [32mINFO [m [PersistentVolumeClaimUtils:66] PVC annotation has changed {testKey=editedTestValue}
2022-04-05 19:42:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-dbb4d051 will have desired state: Ready
2022-04-05 19:42:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-dbb4d051 is in desired state: Ready
2022-04-05 19:42:55 [main] [32mINFO [m [KafkaST:1549] [PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:42:03Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-dbb4d051, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-dbb4d051, strimzi.io/cluster=my-cluster-dbb4d051, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dbb4d051-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-dbb4d051-kafka-0, namespace=namespace-44, ownerReferences=[], resourceVersion=728730, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-0-my-cluster-dbb4d051-kafka-0, uid=dc8a9309-8c1c-4305-acf3-ecb06de8192d, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-dc8a9309-8c1c-4305-acf3-ecb06de8192d, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:42:03Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-dbb4d051, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-dbb4d051, strimzi.io/cluster=my-cluster-dbb4d051, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dbb4d051-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-dbb4d051-kafka-1, namespace=namespace-44, ownerReferences=[], resourceVersion=728731, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-0-my-cluster-dbb4d051-kafka-1, uid=00b70f73-bbad-4eeb-914e-0a3cb2e36c4f, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-00b70f73-bbad-4eeb-914e-0a3cb2e36c4f, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:42:03Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-dbb4d051, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-dbb4d051, strimzi.io/cluster=my-cluster-dbb4d051, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dbb4d051-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-0-my-cluster-dbb4d051-kafka-2, namespace=namespace-44, ownerReferences=[], resourceVersion=728738, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-0-my-cluster-dbb4d051-kafka-2, uid=5a865b88-b1ee-4678-8c1a-44c254fce5fd, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=20Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-5a865b88-b1ee-4678-8c1a-44c254fce5fd, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=20Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:42:03Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-dbb4d051, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-dbb4d051, strimzi.io/cluster=my-cluster-dbb4d051, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dbb4d051-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-dbb4d051-kafka-0, namespace=namespace-44, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-dbb4d051, uid=71f0661f-a29c-43fe-b0e4-8bb40de6346f, additionalProperties={})], resourceVersion=728740, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-1-my-cluster-dbb4d051-kafka-0, uid=85dfc825-6a28-4bdb-a9f0-70634799797b, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-85dfc825-6a28-4bdb-a9f0-70634799797b, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:42:03Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-dbb4d051, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-dbb4d051, strimzi.io/cluster=my-cluster-dbb4d051, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dbb4d051-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-dbb4d051-kafka-1, namespace=namespace-44, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-dbb4d051, uid=71f0661f-a29c-43fe-b0e4-8bb40de6346f, additionalProperties={})], resourceVersion=728742, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-1-my-cluster-dbb4d051-kafka-1, uid=68c77b92-b58e-4d58-b035-629408dc0c98, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-68c77b92-b58e-4d58-b035-629408dc0c98, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=true, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:42:03Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-dbb4d051, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-dbb4d051, strimzi.io/cluster=my-cluster-dbb4d051, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dbb4d051-kafka, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-1-my-cluster-dbb4d051-kafka-2, namespace=namespace-44, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-dbb4d051, uid=71f0661f-a29c-43fe-b0e4-8bb40de6346f, additionalProperties={})], resourceVersion=728741, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-1-my-cluster-dbb4d051-kafka-2, uid=aca612e8-9577-4ba6-a130-d8e757f83967, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=10Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-aca612e8-9577-4ba6-a130-d8e757f83967, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=10Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={}), PersistentVolumeClaim(apiVersion=v1, kind=PersistentVolumeClaim, metadata=ObjectMeta(annotations={pv.kubernetes.io/bind-completed=yes, strimzi.io/delete-claim=false, testKey=editedTestValue}, clusterName=null, creationTimestamp=2022-04-05T19:41:41Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[kubernetes.io/pvc-protection], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-dbb4d051, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=zookeeper, app.kubernetes.io/part-of=strimzi-my-cluster-dbb4d051, strimzi.io/cluster=my-cluster-dbb4d051, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-dbb4d051-zookeeper, test.case=testLabelsAndAnnotationForPVC, testKey=editedTestValue}, managedFields=[], name=data-my-cluster-dbb4d051-zookeeper-0, namespace=namespace-44, ownerReferences=[], resourceVersion=728722, selfLink=/api/v1/namespaces/namespace-44/persistentvolumeclaims/data-my-cluster-dbb4d051-zookeeper-0, uid=ea617b9f-fcd1-4d62-80cf-5ace47b37a66, additionalProperties={}), spec=PersistentVolumeClaimSpec(accessModes=[ReadWriteOnce], dataSource=null, dataSourceRef=null, resources=ResourceRequirements(limits=null, requests={storage=3Gi}, additionalProperties={}), selector=null, storageClassName=standard, volumeMode=Filesystem, volumeName=pvc-ea617b9f-fcd1-4d62-80cf-5ace47b37a66, additionalProperties={}), status=PersistentVolumeClaimStatus(accessModes=[ReadWriteOnce], allocatedResources=null, capacity={storage=3Gi}, conditions=[], phase=Bound, resizeStatus=null, additionalProperties={}), additionalProperties={})]
2022-04-05 19:42:55 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-dbb4d051-kafka-0 - testValue = editedTestValue
2022-04-05 19:42:55 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-dbb4d051-kafka-1 - testValue = editedTestValue
2022-04-05 19:42:55 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-0-my-cluster-dbb4d051-kafka-2 - testValue = editedTestValue
2022-04-05 19:42:55 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-dbb4d051-kafka-0 - testValue = editedTestValue
2022-04-05 19:42:55 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-dbb4d051-kafka-1 - testValue = editedTestValue
2022-04-05 19:42:55 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-1-my-cluster-dbb4d051-kafka-2 - testValue = editedTestValue
2022-04-05 19:42:55 [main] [32mINFO [m [KafkaST:1554] Verifying replaced PVC label data-my-cluster-dbb4d051-zookeeper-0 - testValue = editedTestValue
2022-04-05 19:42:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:42:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLabelsAndAnnotationForPVC
2022-04-05 19:42:55 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-dbb4d051 in namespace namespace-44
2022-04-05 19:43:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:43:05 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-44 for test case:testLabelsAndAnnotationForPVC
2022-04-05 19:43:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testLabelsAndAnnotationForPVC-FINISHED
2022-04-05 19:43:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:43:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:43:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testMessagesAreStoredInDisk-STARTED
2022-04-05 19:43:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:43:49 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-45 for test case:testMessagesAreStoredInDisk
2022-04-05 19:43:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-45
2022-04-05 19:43:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-45
2022-04-05 19:43:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-45
2022-04-05 19:43:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3073a90e in namespace namespace-45
2022-04-05 19:43:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-05 19:43:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3073a90e will have desired state: Ready
2022-04-05 19:44:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3073a90e is in desired state: Ready
2022-04-05 19:44:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1438177229-1116720103 in namespace namespace-45
2022-04-05 19:44:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-05 19:44:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1438177229-1116720103 will have desired state: Ready
2022-04-05 19:44:56 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1438177229-1116720103 is in desired state: Ready
2022-04-05 19:44:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3073a90e-kafka-clients in namespace namespace-45
2022-04-05 19:44:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-45
2022-04-05 19:44:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3073a90e-kafka-clients will be ready
2022-04-05 19:44:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3073a90e-kafka-clients is ready
2022-04-05 19:44:58 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 19:44:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-3073a90e-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0; ls -1
2022-04-05 19:44:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:44:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-3073a90e-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0; ls -1 | sed -n '/my-topic-1438177229-1116720103/p'
2022-04-05 19:44:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:44:58 [main] [32mINFO [m [KafkaST:1344] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-1438177229-1116720103-0
/;cat 00000000000000000000.log in my-cluster-3073a90e-kafka-0
2022-04-05 19:44:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-3073a90e-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-1438177229-1116720103-0
/;cat 00000000000000000000.log
2022-04-05 19:44:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:44:59 [main] [32mINFO [m [KafkaST:1348] Topic my-topic-1438177229-1116720103 is present in kafka broker my-cluster-3073a90e-kafka-0 with no data
2022-04-05 19:44:59 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@12b3c7d6, messages=[], arguments=[--bootstrap-server, my-cluster-3073a90e-kafka-bootstrap.namespace-45.svc:9092, --max-messages, 100, --topic, my-topic-1438177229-1116720103], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-3073a90e-kafka-clients-5bbbb99785-mrj72', podNamespace='namespace-45', bootstrapServer='my-cluster-3073a90e-kafka-bootstrap.namespace-45.svc:9092', topicName='my-topic-1438177229-1116720103', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4b3e66ff}
2022-04-05 19:44:59 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-3073a90e-kafka-bootstrap.namespace-45.svc:9092:my-topic-1438177229-1116720103 from pod my-cluster-3073a90e-kafka-clients-5bbbb99785-mrj72
2022-04-05 19:44:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3073a90e-kafka-clients-5bbbb99785-mrj72 -n namespace-45 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-3073a90e-kafka-bootstrap.namespace-45.svc:9092 --max-messages 100 --topic my-topic-1438177229-1116720103
2022-04-05 19:45:01 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 19:45:01 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 19:45:01 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@18069a46, messages=[], arguments=[--group-id, my-consumer-group-1606858370, --bootstrap-server, my-cluster-3073a90e-kafka-bootstrap.namespace-45.svc:9092, --group-instance-id, instance792369955, --max-messages, 100, --topic, my-topic-1438177229-1116720103], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-3073a90e-kafka-clients-5bbbb99785-mrj72', podNamespace='namespace-45', bootstrapServer='my-cluster-3073a90e-kafka-bootstrap.namespace-45.svc:9092', topicName='my-topic-1438177229-1116720103', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1606858370', consumerInstanceId='instance792369955', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@49cbe1ea}
2022-04-05 19:45:01 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-3073a90e-kafka-bootstrap.namespace-45.svc:9092#my-topic-1438177229-1116720103 from pod my-cluster-3073a90e-kafka-clients-5bbbb99785-mrj72
2022-04-05 19:45:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-3073a90e-kafka-clients-5bbbb99785-mrj72 -n namespace-45 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1606858370 --bootstrap-server my-cluster-3073a90e-kafka-bootstrap.namespace-45.svc:9092 --group-instance-id instance792369955 --max-messages 100 --topic my-topic-1438177229-1116720103
2022-04-05 19:45:07 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 19:45:07 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 19:45:07 [main] [32mINFO [m [KafkaST:1355] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-1438177229-1116720103-0
/;cat 00000000000000000000.log in my-cluster-3073a90e-kafka-0
2022-04-05 19:45:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-3073a90e-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-1438177229-1116720103-0
/;cat 00000000000000000000.log
2022-04-05 19:45:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:45:07 [main] [32mINFO [m [KafkaST:1364] Deleting kafka pod my-cluster-3073a90e-kafka-0
2022-04-05 19:45:07 [main] [32mINFO [m [KafkaST:1364] Deleting kafka pod my-cluster-3073a90e-kafka-clients-5bbbb99785-mrj72
2022-04-05 19:45:07 [main] [32mINFO [m [KafkaST:1368] Wait for kafka to rolling restart ...
2022-04-05 19:45:07 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-3073a90e-kafka rolling update
2022-04-05 19:45:17 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-3073a90e-kafka has been successfully rolled
2022-04-05 19:45:17 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of my-cluster-3073a90e-kafka to be ready
2022-04-05 19:45:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3073a90e will have desired state: Ready
2022-04-05 19:45:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3073a90e is in desired state: Ready
2022-04-05 19:45:49 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-3073a90e is ready
2022-04-05 19:45:49 [main] [32mINFO [m [KafkaST:1371] Executing command cd /var/lib/kafka/data/kafka-log0/my-topic-1438177229-1116720103-0
/;cat 00000000000000000000.log in my-cluster-3073a90e-kafka-0
2022-04-05 19:45:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-45 exec my-cluster-3073a90e-kafka-0 -- /bin/bash -c cd /var/lib/kafka/data/kafka-log0/my-topic-1438177229-1116720103-0
/;cat 00000000000000000000.log
2022-04-05 19:45:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:45:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:45:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMessagesAreStoredInDisk
2022-04-05 19:45:50 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1438177229-1116720103 in namespace namespace-45
2022-04-05 19:45:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3073a90e-kafka-clients in namespace namespace-45
2022-04-05 19:45:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3073a90e in namespace namespace-45
2022-04-05 19:46:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:46:40 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-45 for test case:testMessagesAreStoredInDisk
2022-04-05 19:46:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testMessagesAreStoredInDisk-FINISHED
2022-04-05 19:46:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:46:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:46:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-STARTED
2022-04-05 19:46:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:46:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-46 for test case:testLabelModificationDoesNotBreakCluster
2022-04-05 19:46:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-46
2022-04-05 19:46:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-46
2022-04-05 19:46:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-46
2022-04-05 19:46:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cd47d888 in namespace namespace-46
2022-04-05 19:46:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-05 19:46:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cd47d888 will have desired state: Ready
2022-04-05 19:47:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cd47d888 is in desired state: Ready
2022-04-05 19:47:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1414717652-151771994 in namespace namespace-46
2022-04-05 19:47:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-05 19:47:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1414717652-151771994 will have desired state: Ready
2022-04-05 19:47:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1414717652-151771994 is in desired state: Ready
2022-04-05 19:47:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-cd47d888-kafka-clients in namespace namespace-46
2022-04-05 19:47:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-46
2022-04-05 19:47:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-cd47d888-kafka-clients will be ready
2022-04-05 19:47:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-cd47d888-kafka-clients is ready
2022-04-05 19:47:59 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 19:47:59 [main] [32mINFO [m [KafkaST:1078] Waiting for kafka stateful set labels changed {label-name-1=name-of-the-label-1, label-name-2=name-of-the-label-2}
2022-04-05 19:47:59 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> name-of-the-label-1
2022-04-05 19:47:59 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> name-of-the-label-2
2022-04-05 19:47:59 [main] [32mINFO [m [KafkaST:1081] Getting labels from stateful set resource
2022-04-05 19:47:59 [main] [32mINFO [m [KafkaST:1084] Verifying default labels in the Kafka CR
2022-04-05 19:47:59 [main] [32mINFO [m [KafkaST:1095] Setting new values of labels from name-of-the-label-1 to new-name-of-the-label-1 | from name-of-the-label-2 to new-name-of-the-label-2 and adding one label-name-3 with value name-of-the-label-3
2022-04-05 19:47:59 [main] [32mINFO [m [KafkaST:1098] Edit kafka labels in Kafka CR
2022-04-05 19:47:59 [main] [32mINFO [m [KafkaST:1109] Waiting for kafka service labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-05 19:47:59 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-1 -> new-name-of-the-label-1
2022-04-05 19:48:30 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-2 -> new-name-of-the-label-2
2022-04-05 19:48:30 [main] [32mINFO [m [ServiceUtils:33] Waiting for Service label change label-name-3 -> name-of-the-label-3
2022-04-05 19:48:30 [main] [32mINFO [m [KafkaST:1112] Verifying kafka labels via services
2022-04-05 19:48:30 [main] [32mINFO [m [KafkaST:1118] Waiting for Kafka ConfigMap my-cluster-cd47d888-kafka-config in namespace namespace-46 to have new labels: {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-05 19:48:30 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-cd47d888-kafka-config label change label-name-1 -> new-name-of-the-label-1
2022-04-05 19:48:31 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-cd47d888-kafka-config label change label-name-2 -> new-name-of-the-label-2
2022-04-05 19:48:31 [main] [32mINFO [m [ConfigMapUtils:42] Waiting for ConfigMap my-cluster-cd47d888-kafka-config label change label-name-3 -> name-of-the-label-3
2022-04-05 19:48:31 [main] [32mINFO [m [KafkaST:1121] Verifying Kafka labels on ConfigMap my-cluster-cd47d888-kafka-config in namespace namespace-46
2022-04-05 19:48:31 [main] [32mINFO [m [KafkaST:1127] Waiting for kafka stateful set labels changed {label-name-1=new-name-of-the-label-1, label-name-2=new-name-of-the-label-2, label-name-3=name-of-the-label-3}
2022-04-05 19:48:31 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-1 -> new-name-of-the-label-1
2022-04-05 19:48:31 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-2 -> new-name-of-the-label-2
2022-04-05 19:48:31 [main] [32mINFO [m [StatefulSetUtils:85] Waiting for Stateful set label change label-name-3 -> name-of-the-label-3
2022-04-05 19:48:31 [main] [32mINFO [m [KafkaST:1130] Verifying kafka labels via stateful set
2022-04-05 19:48:31 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-cd47d888-kafka rolling update
2022-04-05 19:49:51 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-cd47d888-kafka has been successfully rolled
2022-04-05 19:49:51 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-cd47d888-kafka to be ready
2022-04-05 19:50:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cd47d888 will have desired state: Ready
2022-04-05 19:50:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cd47d888 is in desired state: Ready
2022-04-05 19:50:16 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-cd47d888 is ready
2022-04-05 19:50:16 [main] [32mINFO [m [KafkaST:1136] Verifying via kafka pods
2022-04-05 19:50:16 [main] [32mINFO [m [KafkaST:1143] Removing labels: label-name-1 -> new-name-of-the-label-1, label-name-2 -> new-name-of-the-label-2, label-name-3 -> name-of-the-label-3
2022-04-05 19:50:16 [main] [32mINFO [m [KafkaST:1155] Waiting for kafka service labels deletion {app.kubernetes.io/instance=my-cluster-cd47d888, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-cd47d888, controller-revision-hash=my-cluster-cd47d888-kafka-86b46576bf, statefulset.kubernetes.io/pod-name=my-cluster-cd47d888-kafka-0, strimzi.io/cluster=my-cluster-cd47d888, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-cd47d888-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-05 19:50:16 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-1 change to null
2022-04-05 19:51:33 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-2 change to null
2022-04-05 19:51:33 [main] [32mINFO [m [ServiceUtils:44] Service label label-name-3 change to null
2022-04-05 19:51:33 [main] [32mINFO [m [KafkaST:1158] Verifying kafka labels via services
2022-04-05 19:51:34 [main] [32mINFO [m [KafkaST:1164] Waiting for Kafka ConfigMap my-cluster-cd47d888-kafka-config in namespace namespace-46 to have labels removed: [label-name-1, label-name-2, label-name-3]
2022-04-05 19:51:34 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-cd47d888-kafka-config label label-name-1 change to null
2022-04-05 19:51:34 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-cd47d888-kafka-config label label-name-1 change to null
2022-04-05 19:51:34 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-cd47d888-kafka-config label label-name-2 change to null
2022-04-05 19:51:34 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-cd47d888-kafka-config label label-name-2 change to null
2022-04-05 19:51:34 [main] [32mINFO [m [ConfigMapUtils:53] Waiting for ConfigMap my-cluster-cd47d888-kafka-config label label-name-3 change to null
2022-04-05 19:51:34 [main] [32mINFO [m [ConfigMapUtils:60] ConfigMap my-cluster-cd47d888-kafka-config label label-name-3 change to null
2022-04-05 19:51:34 [main] [32mINFO [m [KafkaST:1167] Verifying Kafka labels on ConfigMap my-cluster-cd47d888-kafka-config in namespace namespace-46
2022-04-05 19:51:34 [main] [32mINFO [m [KafkaST:1173] Waiting for kafka stateful set labels changed {app.kubernetes.io/instance=my-cluster-cd47d888, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-cd47d888, controller-revision-hash=my-cluster-cd47d888-kafka-86b46576bf, statefulset.kubernetes.io/pod-name=my-cluster-cd47d888-kafka-0, strimzi.io/cluster=my-cluster-cd47d888, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-cd47d888-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-05 19:51:34 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-1 change to null
2022-04-05 19:51:34 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-1 change to null
2022-04-05 19:51:34 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-2 change to null
2022-04-05 19:51:34 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-2 change to null
2022-04-05 19:51:34 [main] [32mINFO [m [StatefulSetUtils:96] Waiting for StatefulSet label label-name-3 change to null
2022-04-05 19:51:34 [main] [32mINFO [m [StatefulSetUtils:101] StatefulSet label label-name-3 change to null
2022-04-05 19:51:34 [main] [32mINFO [m [KafkaST:1176] Verifying kafka labels via stateful set
2022-04-05 19:51:34 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-cd47d888-kafka rolling update
2022-04-05 19:51:34 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-cd47d888-kafka has been successfully rolled
2022-04-05 19:51:34 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-cd47d888-kafka to be ready
2022-04-05 19:53:06 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cd47d888 will have desired state: Ready
2022-04-05 19:53:06 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cd47d888 is in desired state: Ready
2022-04-05 19:53:06 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-cd47d888 is ready
2022-04-05 19:53:06 [main] [32mINFO [m [KafkaST:1181] Waiting for kafka pod labels deletion {app.kubernetes.io/instance=my-cluster-cd47d888, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=kafka, app.kubernetes.io/part-of=strimzi-my-cluster-cd47d888, controller-revision-hash=my-cluster-cd47d888-kafka-86b46576bf, statefulset.kubernetes.io/pod-name=my-cluster-cd47d888-kafka-0, strimzi.io/cluster=my-cluster-cd47d888, strimzi.io/kind=Kafka, strimzi.io/name=my-cluster-cd47d888-kafka, test.case=testLabelModificationDoesNotBreakCluster}
2022-04-05 19:53:06 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-1 change to null
2022-04-05 19:53:06 [main] [32mINFO [m [PodUtils:267] Pod label label-name-1 changed to null
2022-04-05 19:53:06 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-2 change to null
2022-04-05 19:53:06 [main] [32mINFO [m [PodUtils:267] Pod label label-name-2 changed to null
2022-04-05 19:53:06 [main] [32mINFO [m [PodUtils:262] Waiting for Pod label label-name-3 change to null
2022-04-05 19:53:06 [main] [32mINFO [m [PodUtils:267] Pod label label-name-3 changed to null
2022-04-05 19:53:06 [main] [32mINFO [m [KafkaST:1186] Verifying via kafka pods
2022-04-05 19:53:06 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5afe7a8b, messages=[], arguments=[--bootstrap-server, my-cluster-cd47d888-kafka-bootstrap.namespace-46.svc:9092, --max-messages, 100, --topic, my-topic-1414717652-151771994], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-cd47d888-kafka-clients-7dd4cf7c97-rsnl4', podNamespace='namespace-46', bootstrapServer='my-cluster-cd47d888-kafka-bootstrap.namespace-46.svc:9092', topicName='my-topic-1414717652-151771994', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1794c87}
2022-04-05 19:53:06 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-cd47d888-kafka-bootstrap.namespace-46.svc:9092:my-topic-1414717652-151771994 from pod my-cluster-cd47d888-kafka-clients-7dd4cf7c97-rsnl4
2022-04-05 19:53:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-cd47d888-kafka-clients-7dd4cf7c97-rsnl4 -n namespace-46 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-cd47d888-kafka-bootstrap.namespace-46.svc:9092 --max-messages 100 --topic my-topic-1414717652-151771994
2022-04-05 19:53:10 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 19:53:10 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 19:53:10 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@35b18317, messages=[], arguments=[--group-id, my-consumer-group-1696505682, --bootstrap-server, my-cluster-cd47d888-kafka-bootstrap.namespace-46.svc:9092, --group-instance-id, instance1845491177, --max-messages, 100, --topic, my-topic-1414717652-151771994], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-cd47d888-kafka-clients-7dd4cf7c97-rsnl4', podNamespace='namespace-46', bootstrapServer='my-cluster-cd47d888-kafka-bootstrap.namespace-46.svc:9092', topicName='my-topic-1414717652-151771994', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1696505682', consumerInstanceId='instance1845491177', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7e67f528}
2022-04-05 19:53:10 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-cd47d888-kafka-bootstrap.namespace-46.svc:9092#my-topic-1414717652-151771994 from pod my-cluster-cd47d888-kafka-clients-7dd4cf7c97-rsnl4
2022-04-05 19:53:10 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-cd47d888-kafka-clients-7dd4cf7c97-rsnl4 -n namespace-46 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1696505682 --bootstrap-server my-cluster-cd47d888-kafka-bootstrap.namespace-46.svc:9092 --group-instance-id instance1845491177 --max-messages 100 --topic my-topic-1414717652-151771994
2022-04-05 19:53:18 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 19:53:18 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 19:53:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:53:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLabelModificationDoesNotBreakCluster
2022-04-05 19:53:18 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1414717652-151771994 in namespace namespace-46
2022-04-05 19:53:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-cd47d888-kafka-clients in namespace namespace-46
2022-04-05 19:53:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cd47d888 in namespace namespace-46
2022-04-05 19:54:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:54:08 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-46 for test case:testLabelModificationDoesNotBreakCluster
2022-04-05 19:54:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testLabelModificationDoesNotBreakCluster-FINISHED
2022-04-05 19:54:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:54:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:54:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testEODeletion-STARTED
2022-04-05 19:54:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:54:14 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-47 for test case:testEODeletion
2022-04-05 19:54:14 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-47
2022-04-05 19:54:14 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-47
2022-04-05 19:54:14 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-47
2022-04-05 19:54:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7f5d3be3 in namespace namespace-47
2022-04-05 19:54:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-47
2022-04-05 19:54:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7f5d3be3 will have desired state: Ready
2022-04-05 19:55:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7f5d3be3 is in desired state: Ready
2022-04-05 19:55:30 [main] [32mINFO [m [KafkaST:122] Setting entity operator to null
2022-04-05 19:55:30 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-7f5d3be3-entity-operator is not deleted yet! Triggering force delete by cmd client!
2022-04-05 19:55:35 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-7f5d3be3-entity-operator is not deleted yet! Triggering force delete by cmd client!
2022-04-05 19:55:40 [main] [32mINFO [m [PodUtils:154] Waiting when Pod my-cluster-7f5d3be3-entity-operator-6b5d96c868-vgnjl will be deleted
2022-04-05 19:55:40 [main] [32mINFO [m [PodUtils:171] Pod my-cluster-7f5d3be3-entity-operator-6b5d96c868-vgnjl deleted
2022-04-05 19:55:40 [main] [32mINFO [m [KafkaST:130] Entity operator was deleted
2022-04-05 19:55:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 19:55:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testEODeletion
2022-04-05 19:55:40 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7f5d3be3 in namespace namespace-47
2022-04-05 19:55:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 19:55:50 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-47 for test case:testEODeletion
2022-04-05 19:56:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testEODeletion-FINISHED
2022-04-05 19:56:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 19:56:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 19:56:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testJvmAndResources-STARTED
2022-04-05 19:56:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 19:56:33 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-48 for test case:testJvmAndResources
2022-04-05 19:56:33 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-48
2022-04-05 19:56:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-48
2022-04-05 19:56:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-48
2022-04-05 19:56:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-da518316 in namespace namespace-48
2022-04-05 19:56:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-48
2022-04-05 19:56:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-da518316 will have desired state: Ready
2022-04-05 19:57:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-da518316 is in desired state: Ready
2022-04-05 19:57:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-48 exec my-cluster-da518316-kafka-0 -c kafka -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-05 19:57:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:57:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-48 exec my-cluster-da518316-zookeeper-0 -c zookeeper -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-05 19:57:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:57:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-48 exec my-cluster-da518316-entity-operator-b8d647b47-kgrm9 -c topic-operator -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-05 19:57:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:57:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-48 exec my-cluster-da518316-entity-operator-b8d647b47-kgrm9 -c user-operator -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-05 19:57:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 19:57:56 [main] [32mINFO [m [KafkaST:533] Check if -D java options are present in topic-operator
2022-04-05 19:57:56 [main] [32mINFO [m [KafkaST:533] Check if -D java options are present in user-operator
2022-04-05 19:57:56 [main] [32mINFO [m [KafkaST:552] Checking no rolling update for Kafka cluster
2022-04-05 19:57:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 50
2022-04-05 19:57:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 49
2022-04-05 19:57:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 48
2022-04-05 19:57:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 47
2022-04-05 19:58:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 46
2022-04-05 19:58:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 45
2022-04-05 19:58:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 44
2022-04-05 19:58:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 43
2022-04-05 19:58:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 42
2022-04-05 19:58:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 41
2022-04-05 19:58:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 40
2022-04-05 19:58:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 39
2022-04-05 19:58:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 38
2022-04-05 19:58:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 37
2022-04-05 19:58:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 36
2022-04-05 19:58:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 35
2022-04-05 19:58:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 34
2022-04-05 19:58:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 33
2022-04-05 19:58:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 32
2022-04-05 19:58:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 31
2022-04-05 19:58:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 30
2022-04-05 19:58:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 29
2022-04-05 19:58:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 28
2022-04-05 19:58:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 27
2022-04-05 19:58:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 26
2022-04-05 19:58:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 25
2022-04-05 19:58:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 24
2022-04-05 19:58:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 23
2022-04-05 19:58:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 22
2022-04-05 19:58:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 21
2022-04-05 19:58:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 20
2022-04-05 19:58:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 19
2022-04-05 19:58:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 18
2022-04-05 19:58:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 17
2022-04-05 19:58:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 16
2022-04-05 19:58:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 15
2022-04-05 19:58:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 14
2022-04-05 19:58:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 13
2022-04-05 19:58:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 12
2022-04-05 19:58:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 11
2022-04-05 19:58:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 10
2022-04-05 19:58:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 9
2022-04-05 19:58:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 8
2022-04-05 19:58:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 7
2022-04-05 19:58:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 6
2022-04-05 19:58:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 5
2022-04-05 19:58:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 4
2022-04-05 19:58:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 3
2022-04-05 19:58:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 2
2022-04-05 19:58:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 1
2022-04-05 19:58:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-zookeeper-0=828e1186-cf42-450b-b765-50712fea29d5} pods didn't roll. Remaining seconds for stability: 0
2022-04-05 19:58:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 50
2022-04-05 19:58:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 49
2022-04-05 19:58:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 48
2022-04-05 19:58:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 47
2022-04-05 19:58:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 46
2022-04-05 19:58:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 45
2022-04-05 19:58:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 44
2022-04-05 19:58:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 43
2022-04-05 19:58:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 42
2022-04-05 19:58:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 41
2022-04-05 19:58:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 40
2022-04-05 19:58:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 39
2022-04-05 19:58:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 38
2022-04-05 19:58:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 37
2022-04-05 19:59:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 36
2022-04-05 19:59:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 35
2022-04-05 19:59:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 34
2022-04-05 19:59:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 33
2022-04-05 19:59:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 32
2022-04-05 19:59:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 31
2022-04-05 19:59:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 30
2022-04-05 19:59:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 29
2022-04-05 19:59:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 28
2022-04-05 19:59:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 27
2022-04-05 19:59:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 26
2022-04-05 19:59:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 25
2022-04-05 19:59:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 24
2022-04-05 19:59:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 23
2022-04-05 19:59:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 22
2022-04-05 19:59:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 21
2022-04-05 19:59:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 20
2022-04-05 19:59:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 19
2022-04-05 19:59:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 18
2022-04-05 19:59:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 17
2022-04-05 19:59:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 16
2022-04-05 19:59:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 15
2022-04-05 19:59:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 14
2022-04-05 19:59:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 13
2022-04-05 19:59:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 12
2022-04-05 19:59:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 11
2022-04-05 19:59:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 10
2022-04-05 19:59:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 9
2022-04-05 19:59:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 8
2022-04-05 19:59:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 7
2022-04-05 19:59:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 6
2022-04-05 19:59:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 5
2022-04-05 19:59:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 4
2022-04-05 19:59:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 3
2022-04-05 19:59:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 2
2022-04-05 19:59:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 1
2022-04-05 19:59:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-da518316-kafka-0=b0d8c6e9-351a-43b0-867c-c584a6e9738c} pods didn't roll. Remaining seconds for stability: 0
2022-04-05 19:59:36 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 50
2022-04-05 19:59:37 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 49
2022-04-05 19:59:38 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 48
2022-04-05 19:59:39 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 47
2022-04-05 19:59:40 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 46
2022-04-05 19:59:41 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 45
2022-04-05 19:59:42 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 44
2022-04-05 19:59:43 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 43
2022-04-05 19:59:44 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 42
2022-04-05 19:59:45 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 41
2022-04-05 19:59:46 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 40
2022-04-05 19:59:47 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 39
2022-04-05 19:59:48 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 38
2022-04-05 19:59:49 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 37
2022-04-05 19:59:50 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 36
2022-04-05 19:59:51 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 35
2022-04-05 19:59:52 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 34
2022-04-05 19:59:53 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 33
2022-04-05 19:59:54 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 32
2022-04-05 19:59:55 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 31
2022-04-05 19:59:56 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 30
2022-04-05 19:59:57 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 29
2022-04-05 19:59:58 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 28
2022-04-05 19:59:59 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 27
2022-04-05 20:00:00 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 26
2022-04-05 20:00:01 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 25
2022-04-05 20:00:03 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 24
2022-04-05 20:00:04 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 23
2022-04-05 20:00:05 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 22
2022-04-05 20:00:06 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 21
2022-04-05 20:00:07 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 20
2022-04-05 20:00:08 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 19
2022-04-05 20:00:09 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 18
2022-04-05 20:00:10 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 17
2022-04-05 20:00:11 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 16
2022-04-05 20:00:12 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 15
2022-04-05 20:00:13 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 14
2022-04-05 20:00:14 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 13
2022-04-05 20:00:15 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 12
2022-04-05 20:00:16 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 11
2022-04-05 20:00:17 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 10
2022-04-05 20:00:18 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 9
2022-04-05 20:00:19 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 8
2022-04-05 20:00:20 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 7
2022-04-05 20:00:21 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 6
2022-04-05 20:00:22 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 5
2022-04-05 20:00:23 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 4
2022-04-05 20:00:24 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 3
2022-04-05 20:00:25 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 2
2022-04-05 20:00:26 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 1
2022-04-05 20:00:27 [main] [32mINFO [m [DeploymentUtils:80] {my-cluster-da518316-entity-operator-b8d647b47-kgrm9=53d95176-d798-4084-9fa7-dccfa5d33595} pods not rolling waiting, remaining seconds for stability 0
2022-04-05 20:00:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:00:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJvmAndResources
2022-04-05 20:00:27 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-da518316 in namespace namespace-48
2022-04-05 20:00:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:00:37 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-48 for test case:testJvmAndResources
2022-04-05 20:00:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testJvmAndResources-FINISHED
2022-04-05 20:00:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:00:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:00:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testPersistentStorageSize-STARTED
2022-04-05 20:00:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:00:48 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-49 for test case:testPersistentStorageSize
2022-04-05 20:00:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-49
2022-04-05 20:00:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-49
2022-04-05 20:00:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-49
2022-04-05 20:00:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-384cc58f in namespace namespace-49
2022-04-05 20:00:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-05 20:00:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-384cc58f will have desired state: Ready
2022-04-05 20:02:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-384cc58f is in desired state: Ready
2022-04-05 20:02:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-794901754-839747438 in namespace namespace-49
2022-04-05 20:02:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-05 20:02:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-794901754-839747438 will have desired state: Ready
2022-04-05 20:02:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-794901754-839747438 is in desired state: Ready
2022-04-05 20:02:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-384cc58f-kafka-clients in namespace namespace-49
2022-04-05 20:02:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-49
2022-04-05 20:02:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-384cc58f-kafka-clients will be ready
2022-04-05 20:02:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-384cc58f-kafka-clients is ready
2022-04-05 20:02:03 [main] [32mINFO [m [KafkaST:1694] Checking volume data-0-my-cluster-384cc58f-kafka-0 and size of storage 70Gi
2022-04-05 20:02:03 [main] [32mINFO [m [KafkaST:1694] Checking volume data-0-my-cluster-384cc58f-kafka-1 and size of storage 70Gi
2022-04-05 20:02:03 [main] [32mINFO [m [KafkaST:1694] Checking volume data-1-my-cluster-384cc58f-kafka-0 and size of storage 20Gi
2022-04-05 20:02:03 [main] [32mINFO [m [KafkaST:1694] Checking volume data-1-my-cluster-384cc58f-kafka-1 and size of storage 20Gi
2022-04-05 20:02:03 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:02:03 [main] [32mINFO [m [KafkaST:983] Checking produced and consumed messages to pod:my-cluster-384cc58f-kafka-clients-7bbf7784fc-rplk4
2022-04-05 20:02:03 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@751d45af, messages=[], arguments=[--bootstrap-server, my-cluster-384cc58f-kafka-bootstrap.namespace-49.svc:9092, --max-messages, 100, --topic, my-topic-794901754-839747438], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-384cc58f-kafka-clients-7bbf7784fc-rplk4', podNamespace='namespace-49', bootstrapServer='my-cluster-384cc58f-kafka-bootstrap.namespace-49.svc:9092', topicName='my-topic-794901754-839747438', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@464c238}
2022-04-05 20:02:03 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-384cc58f-kafka-bootstrap.namespace-49.svc:9092:my-topic-794901754-839747438 from pod my-cluster-384cc58f-kafka-clients-7bbf7784fc-rplk4
2022-04-05 20:02:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-384cc58f-kafka-clients-7bbf7784fc-rplk4 -n namespace-49 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-384cc58f-kafka-bootstrap.namespace-49.svc:9092 --max-messages 100 --topic my-topic-794901754-839747438
2022-04-05 20:02:06 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 20:02:06 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 20:02:06 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@380f74a1, messages=[], arguments=[--group-id, my-consumer-group-1454662585, --bootstrap-server, my-cluster-384cc58f-kafka-bootstrap.namespace-49.svc:9092, --group-instance-id, instance268520764, --max-messages, 100, --topic, my-topic-794901754-839747438], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-384cc58f-kafka-clients-7bbf7784fc-rplk4', podNamespace='namespace-49', bootstrapServer='my-cluster-384cc58f-kafka-bootstrap.namespace-49.svc:9092', topicName='my-topic-794901754-839747438', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1454662585', consumerInstanceId='instance268520764', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1a5800d0}
2022-04-05 20:02:06 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-384cc58f-kafka-bootstrap.namespace-49.svc:9092#my-topic-794901754-839747438 from pod my-cluster-384cc58f-kafka-clients-7bbf7784fc-rplk4
2022-04-05 20:02:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-384cc58f-kafka-clients-7bbf7784fc-rplk4 -n namespace-49 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1454662585 --bootstrap-server my-cluster-384cc58f-kafka-bootstrap.namespace-49.svc:9092 --group-instance-id instance268520764 --max-messages 100 --topic my-topic-794901754-839747438
2022-04-05 20:02:11 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 20:02:11 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 20:02:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:02:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testPersistentStorageSize
2022-04-05 20:02:11 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-794901754-839747438 in namespace namespace-49
2022-04-05 20:02:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-384cc58f in namespace namespace-49
2022-04-05 20:02:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-384cc58f-kafka-clients in namespace namespace-49
2022-04-05 20:03:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:03:01 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-49 for test case:testPersistentStorageSize
2022-04-05 20:03:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testPersistentStorageSize-FINISHED
2022-04-05 20:03:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:03:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:03:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testForTopicOperator-STARTED
2022-04-05 20:03:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:03:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-50 for test case:testForTopicOperator
2022-04-05 20:03:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-50
2022-04-05 20:03:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-50
2022-04-05 20:03:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-50
2022-04-05 20:03:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d6ab59f4 in namespace namespace-50
2022-04-05 20:03:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-05 20:03:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d6ab59f4 will have desired state: Ready
2022-04-05 20:04:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d6ab59f4 is in desired state: Ready
2022-04-05 20:04:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-949609400-645424141 in namespace namespace-50
2022-04-05 20:04:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-50
2022-04-05 20:04:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-949609400-645424141 will have desired state: Ready
2022-04-05 20:04:27 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-949609400-645424141 is in desired state: Ready
2022-04-05 20:04:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-949609400-645424141 will have desired state: Ready
2022-04-05 20:04:27 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-949609400-645424141 is in desired state: Ready
2022-04-05 20:04:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-d6ab59f4-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 20:04:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:04:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-d6ab59f4-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --create  --topic topic-from-cli --replication-factor 1 --partitions 1
2022-04-05 20:04:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:04:33 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic topic-from-cli creation 
2022-04-05 20:04:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-d6ab59f4-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 20:04:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:04:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-d6ab59f4-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic-949609400-645424141 --partitions 2
2022-04-05 20:04:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:04:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d6ab59f4 will have desired state: Ready
2022-04-05 20:04:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d6ab59f4 is in desired state: Ready
2022-04-05 20:04:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-d6ab59f4-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-topic-949609400-645424141
2022-04-05 20:04:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:04:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d6ab59f4 will have desired state: Ready
2022-04-05 20:04:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d6ab59f4 is in desired state: Ready
2022-04-05 20:04:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-d6ab59f4-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic-from-cli
2022-04-05 20:04:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:04:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-d6ab59f4-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic my-topic-949609400-645424141
2022-04-05 20:04:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:04:48 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-949609400-645424141 deletion
2022-04-05 20:04:48 [main] [33mWARN [m [KafkaTopicUtils:110] KafkaTopic my-topic-949609400-645424141 is not deleted yet! Triggering force delete by cmd client!
2022-04-05 20:05:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-50 exec my-cluster-d6ab59f4-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-05 20:05:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:05:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:05:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testForTopicOperator
2022-04-05 20:05:02 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-949609400-645424141 in namespace namespace-50
2022-04-05 20:05:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d6ab59f4 in namespace namespace-50
2022-04-05 20:05:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:05:12 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-50 for test case:testForTopicOperator
2022-04-05 20:05:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testForTopicOperator-FINISHED
2022-04-05 20:05:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:05:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:05:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testReadOnlyRootFileSystem-STARTED
2022-04-05 20:05:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:05:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-51 for test case:testReadOnlyRootFileSystem
2022-04-05 20:05:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-51
2022-04-05 20:05:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-51
2022-04-05 20:05:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-51
2022-04-05 20:05:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7d93c40d in namespace namespace-51
2022-04-05 20:05:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-05 20:05:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7d93c40d will have desired state: Ready
2022-04-05 20:08:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7d93c40d is in desired state: Ready
2022-04-05 20:08:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7d93c40d will have desired state: Ready
2022-04-05 20:08:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7d93c40d is in desired state: Ready
2022-04-05 20:08:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1280887701-1050021220 in namespace namespace-51
2022-04-05 20:08:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-05 20:08:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1280887701-1050021220 will have desired state: Ready
2022-04-05 20:08:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1280887701-1050021220 is in desired state: Ready
2022-04-05 20:08:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7d93c40d-kafka-clients in namespace namespace-51
2022-04-05 20:08:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-51
2022-04-05 20:08:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7d93c40d-kafka-clients will be ready
2022-04-05 20:08:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7d93c40d-kafka-clients is ready
2022-04-05 20:08:11 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:08:11 [main] [32mINFO [m [KafkaST:1652] Checking produced and consumed messages to pod:my-cluster-7d93c40d-kafka-clients-764dbfb8f9-gj7xj
2022-04-05 20:08:11 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@66e67d0f, messages=[], arguments=[--bootstrap-server, my-cluster-7d93c40d-kafka-bootstrap.namespace-51.svc:9092, --max-messages, 100, --topic, my-topic-1280887701-1050021220], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7d93c40d-kafka-clients-764dbfb8f9-gj7xj', podNamespace='namespace-51', bootstrapServer='my-cluster-7d93c40d-kafka-bootstrap.namespace-51.svc:9092', topicName='my-topic-1280887701-1050021220', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6413ddc}
2022-04-05 20:08:11 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-7d93c40d-kafka-bootstrap.namespace-51.svc:9092:my-topic-1280887701-1050021220 from pod my-cluster-7d93c40d-kafka-clients-764dbfb8f9-gj7xj
2022-04-05 20:08:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7d93c40d-kafka-clients-764dbfb8f9-gj7xj -n namespace-51 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-7d93c40d-kafka-bootstrap.namespace-51.svc:9092 --max-messages 100 --topic my-topic-1280887701-1050021220
2022-04-05 20:08:14 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 20:08:14 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 20:08:14 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2fda8734, messages=[], arguments=[--group-id, my-consumer-group-843566074, --bootstrap-server, my-cluster-7d93c40d-kafka-bootstrap.namespace-51.svc:9092, --group-instance-id, instance146172368, --max-messages, 100, --topic, my-topic-1280887701-1050021220], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7d93c40d-kafka-clients-764dbfb8f9-gj7xj', podNamespace='namespace-51', bootstrapServer='my-cluster-7d93c40d-kafka-bootstrap.namespace-51.svc:9092', topicName='my-topic-1280887701-1050021220', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-843566074', consumerInstanceId='instance146172368', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@20fae12a}
2022-04-05 20:08:14 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-7d93c40d-kafka-bootstrap.namespace-51.svc:9092#my-topic-1280887701-1050021220 from pod my-cluster-7d93c40d-kafka-clients-764dbfb8f9-gj7xj
2022-04-05 20:08:14 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7d93c40d-kafka-clients-764dbfb8f9-gj7xj -n namespace-51 -- /opt/kafka/consumer.sh --group-id my-consumer-group-843566074 --bootstrap-server my-cluster-7d93c40d-kafka-bootstrap.namespace-51.svc:9092 --group-instance-id instance146172368 --max-messages 100 --topic my-topic-1280887701-1050021220
2022-04-05 20:08:20 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 20:08:20 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 20:08:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:08:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReadOnlyRootFileSystem
2022-04-05 20:08:20 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1280887701-1050021220 in namespace namespace-51
2022-04-05 20:08:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7d93c40d-kafka-clients in namespace namespace-51
2022-04-05 20:08:20 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7d93c40d in namespace namespace-51
2022-04-05 20:08:20 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-51, for cruise control Kafka cluster my-cluster-7d93c40d
2022-04-05 20:09:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:09:10 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-51 for test case:testReadOnlyRootFileSystem
2022-04-05 20:09:15 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testReadOnlyRootFileSystem-FINISHED
2022-04-05 20:09:15 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:09:15 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:09:15 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testCustomAndUpdatedValues-STARTED
2022-04-05 20:09:15 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:09:15 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-52 for test case:testCustomAndUpdatedValues
2022-04-05 20:09:15 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-52
2022-04-05 20:09:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-52
2022-04-05 20:09:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-52
2022-04-05 20:09:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-996b2725 in namespace namespace-52
2022-04-05 20:09:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-52
2022-04-05 20:09:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-996b2725 will have desired state: Ready
2022-04-05 20:11:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-996b2725 is in desired state: Ready
2022-04-05 20:11:18 [main] [32mINFO [m [KafkaST:290] Verify values before update
2022-04-05 20:11:18 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-996b2725-kafka in pod name
2022-04-05 20:11:18 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container kafka
2022-04-05 20:11:18 [main] [32mINFO [m [KafkaST:1661] Checking kafka configuration
2022-04-05 20:11:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-996b2725-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-05 20:11:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:11:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-996b2725-kafka-1 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-05 20:11:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:11:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-996b2725-kafka-2 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-05 20:11:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:11:18 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-996b2725-kafka
2022-04-05 20:11:18 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container kafka
2022-04-05 20:11:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-996b2725-kafka-0 -- cat /tmp/strimzi.properties
2022-04-05 20:11:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:11:19 [main] [32mINFO [m [KafkaST:308] Testing Zookeepers
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-996b2725-zookeeper in pod name
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container zookeeper
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-996b2725-zookeeper
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:194] Testing configuration for container zookeeper
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-996b2725-zookeeper
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container zookeeper
2022-04-05 20:11:19 [main] [32mINFO [m [KafkaST:315] Checking configuration of TO and UO
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-996b2725-entity-operator in pod name
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container topic-operator
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-996b2725-entity-operator
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container topic-operator
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-996b2725-entity-operator in pod name
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container user-operator
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-996b2725-entity-operator
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container user-operator
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-996b2725-entity-operator in pod name
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container tls-sidecar
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-996b2725-entity-operator
2022-04-05 20:11:19 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container tls-sidecar
2022-04-05 20:11:19 [main] [32mINFO [m [KafkaST:326] Updating configuration of Kafka cluster
2022-04-05 20:11:19 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-996b2725-zookeeper rolling update
2022-04-05 20:12:49 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-996b2725-zookeeper has been successfully rolled
2022-04-05 20:12:49 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-996b2725-zookeeper to be ready
2022-04-05 20:13:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-996b2725 will have desired state: Ready
2022-04-05 20:13:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-996b2725 is in desired state: Ready
2022-04-05 20:13:30 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-996b2725 is ready
2022-04-05 20:13:30 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-996b2725-kafka rolling update
2022-04-05 20:14:55 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-996b2725-kafka has been successfully rolled
2022-04-05 20:14:55 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-996b2725-kafka to be ready
2022-04-05 20:15:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-996b2725 will have desired state: Ready
2022-04-05 20:15:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-996b2725 is in desired state: Ready
2022-04-05 20:15:39 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-996b2725 is ready
2022-04-05 20:15:39 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-996b2725-entity-operator rolling update
2022-04-05 20:15:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-996b2725-entity-operator will be ready
2022-04-05 20:17:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-996b2725-entity-operator is ready
2022-04-05 20:17:32 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-996b2725-entity-operator rolling update finished
2022-04-05 20:17:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-996b2725 will have desired state: Ready
2022-04-05 20:17:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-996b2725 is in desired state: Ready
2022-04-05 20:17:32 [main] [32mINFO [m [KafkaST:386] Verify values after update
2022-04-05 20:17:32 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-996b2725-kafka in pod name
2022-04-05 20:17:32 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container kafka
2022-04-05 20:17:32 [main] [32mINFO [m [KafkaST:1661] Checking kafka configuration
2022-04-05 20:17:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-996b2725-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-05 20:17:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:17:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-996b2725-kafka-1 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-05 20:17:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:17:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-996b2725-kafka-2 -- /bin/bash -c cat /tmp/strimzi.properties
2022-04-05 20:17:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:17:32 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-996b2725-kafka
2022-04-05 20:17:32 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container kafka
2022-04-05 20:17:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-52 exec my-cluster-996b2725-kafka-0 -- cat /tmp/strimzi.properties
2022-04-05 20:17:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 20:17:33 [main] [32mINFO [m [KafkaST:404] Testing Zookeepers
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-996b2725-zookeeper in pod name
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container zookeeper
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-996b2725-zookeeper
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:194] Testing configuration for container zookeeper
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-996b2725-zookeeper
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container zookeeper
2022-04-05 20:17:33 [main] [32mINFO [m [KafkaST:410] Getting entity operator to check configuration of TO and UO
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-996b2725-entity-operator in pod name
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container topic-operator
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-996b2725-entity-operator
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container topic-operator
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-996b2725-entity-operator in pod name
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container user-operator
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-996b2725-entity-operator
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container user-operator
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-996b2725-entity-operator in pod name
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container tls-sidecar
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-996b2725-entity-operator
2022-04-05 20:17:33 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container tls-sidecar
2022-04-05 20:17:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:17:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-05 20:17:33 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-996b2725 in namespace namespace-52
2022-04-05 20:17:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:17:43 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-52 for test case:testCustomAndUpdatedValues
2022-04-05 20:18:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testCustomAndUpdatedValues-FINISHED
2022-04-05 20:18:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:18:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:18:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrue-STARTED
2022-04-05 20:18:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:18:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-53 for test case:testKafkaJBODDeleteClaimsTrue
2022-04-05 20:18:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-53
2022-04-05 20:18:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-53
2022-04-05 20:18:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-53
2022-04-05 20:18:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a1148d25 in namespace namespace-53
2022-04-05 20:18:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-53
2022-04-05 20:18:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a1148d25 will have desired state: Ready
2022-04-05 20:19:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a1148d25 is in desired state: Ready
2022-04-05 20:19:41 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-a1148d25-kafka-0
2022-04-05 20:19:41 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-a1148d25-kafka-1
2022-04-05 20:19:41 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-a1148d25-kafka-0
2022-04-05 20:19:41 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-a1148d25-kafka-1
2022-04-05 20:19:41 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-05 20:19:41 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-05 20:19:41 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-05 20:19:42 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-05 20:19:42 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-05 20:19:42 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-05 20:19:42 [main] [32mINFO [m [KafkaST:906] Deleting cluster
2022-04-05 20:19:42 [main] [32mINFO [m [KafkaST:909] Waiting for PVC deletion
2022-04-05 20:20:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:20:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsTrue
2022-04-05 20:20:02 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a1148d25 in namespace namespace-53
2022-04-05 20:20:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:20:02 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-53 for test case:testKafkaJBODDeleteClaimsTrue
2022-04-05 20:20:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsTrue-FINISHED
2022-04-05 20:20:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:20:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:20:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsFalse-STARTED
2022-04-05 20:20:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:20:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-54 for test case:testKafkaJBODDeleteClaimsFalse
2022-04-05 20:20:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-54
2022-04-05 20:20:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-54
2022-04-05 20:20:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-54
2022-04-05 20:20:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2c9f57f6 in namespace namespace-54
2022-04-05 20:20:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-54
2022-04-05 20:20:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2c9f57f6 will have desired state: Ready
2022-04-05 20:21:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2c9f57f6 is in desired state: Ready
2022-04-05 20:21:30 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-2c9f57f6-kafka-0
2022-04-05 20:21:30 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-0-my-cluster-2c9f57f6-kafka-1
2022-04-05 20:21:30 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-2c9f57f6-kafka-0
2022-04-05 20:21:30 [main] [32mINFO [m [KafkaST:1710] Checking labels for volume:data-1-my-cluster-2c9f57f6-kafka-1
2022-04-05 20:21:30 [main] [32mINFO [m [KafkaST:1717] Checking PVC names included in JBOD array
2022-04-05 20:21:30 [main] [32mINFO [m [KafkaST:1724] Checking PVC on Kafka pods
2022-04-05 20:21:30 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 0
2022-04-05 20:21:30 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 0
2022-04-05 20:21:30 [main] [32mINFO [m [KafkaST:1729] Getting list of mounted data sources and PVCs on Kafka pod 1
2022-04-05 20:21:30 [main] [32mINFO [m [KafkaST:1737] Verifying mounted data sources and PVCs on Kafka pod 1
2022-04-05 20:21:30 [main] [32mINFO [m [KafkaST:930] Deleting cluster
2022-04-05 20:21:30 [main] [32mINFO [m [KafkaST:933] Waiting for PVC deletion
2022-04-05 20:21:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:21:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaJBODDeleteClaimsFalse
2022-04-05 20:21:30 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2c9f57f6 in namespace namespace-54
2022-04-05 20:21:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:21:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-54 for test case:testKafkaJBODDeleteClaimsFalse
2022-04-05 20:22:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.KafkaST.testKafkaJBODDeleteClaimsFalse-FINISHED
2022-04-05 20:22:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:22:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:22:08 [main] [32mINFO [m [ResourceManager:346] In context KafkaST is everything deleted.
2022-04-05 20:22:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 23, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4,142.893 s - in io.strimzi.systemtest.kafka.KafkaST
[[1;34mINFO[m] Running io.strimzi.systemtest.kafka.ConfigProviderST
2022-04-05 20:22:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: config-provider-st
2022-04-05 20:22:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: config-provider-st
2022-04-05 20:22:13 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: config-provider-st
2022-04-05 20:22:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:22:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.kafka.ConfigProviderST.testConnectWithConnectorUsingConfigAndEnvProvider-STARTED
2022-04-05 20:22:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:22:13 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-55 for test case:testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-05 20:22:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-55
2022-04-05 20:22:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-55
2022-04-05 20:22:13 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-55
2022-04-05 20:22:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7dbb1a3f in namespace namespace-55
2022-04-05 20:22:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-05 20:22:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7dbb1a3f will have desired state: Ready
2022-04-05 20:23:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7dbb1a3f is in desired state: Ready
2022-04-05 20:23:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-7dbb1a3f in namespace namespace-55
2022-04-05 20:23:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-05 20:23:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-7dbb1a3f will have desired state: Ready
2022-04-05 20:24:36 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-7dbb1a3f is in desired state: Ready
2022-04-05 20:24:36 [main] [32mINFO [m [ConfigProviderST:100] Creating needed RoleBinding and Role for Kubernetes Config Provider
2022-04-05 20:24:36 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding connector-config-rb in namespace namespace-55
2022-04-05 20:24:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-05 20:24:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-7dbb1a3f in namespace namespace-55
2022-04-05 20:24:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-05 20:24:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-7dbb1a3f will have desired state: Ready
2022-04-05 20:24:37 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-7dbb1a3f is in desired state: Ready
2022-04-05 20:24:37 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 20:24:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-my-consumer-group-222986789 in namespace namespace-55
2022-04-05 20:24:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-55
2022-04-05 20:24:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-my-consumer-group-222986789 will be in active state
2022-04-05 20:24:38 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-7dbb1a3f-connect-58cb599d56-fd766
2022-04-05 20:24:44 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-7dbb1a3f-connect-58cb599d56-fd766
2022-04-05 20:24:44 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:24:44 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-05 20:24:44 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding connector-config-rb in namespace namespace-55
2022-04-05 20:24:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job producer-my-consumer-group-222986789 in namespace namespace-55
2022-04-05 20:24:44 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-7dbb1a3f in namespace namespace-55
2022-04-05 20:24:44 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7dbb1a3f in namespace namespace-55
2022-04-05 20:24:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-7dbb1a3f in namespace namespace-55
2022-04-05 20:24:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:24:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-55 for test case:testConnectWithConnectorUsingConfigAndEnvProvider
2022-04-05 20:25:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.kafka.ConfigProviderST.testConnectWithConnectorUsingConfigAndEnvProvider-FINISHED
2022-04-05 20:25:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:25:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:25:38 [main] [32mINFO [m [ResourceManager:346] In context ConfigProviderST is everything deleted.
2022-04-05 20:25:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 210.038 s - in io.strimzi.systemtest.kafka.ConfigProviderST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.custom.CustomAuthorizerST
2022-04-05 20:25:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: custom-authorizer-st
2022-04-05 20:25:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: custom-authorizer-st
2022-04-05 20:25:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: custom-authorizer-st
2022-04-05 20:25:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka custom-authorizer in namespace custom-authorizer-st
2022-04-05 20:25:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: custom-authorizer will have desired state: Ready
2022-04-05 20:27:00 [main] [32mINFO [m [ResourceManager:444] Kafka: custom-authorizer is in desired state: Ready
2022-04-05 20:27:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:27:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclWithSuperUser-STARTED
2022-04-05 20:27:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:27:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1921754918-884751161 in namespace custom-authorizer-st
2022-04-05 20:27:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1921754918-884751161 will have desired state: Ready
2022-04-05 20:27:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1921754918-884751161 is in desired state: Ready
2022-04-05 20:27:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sre-admin in namespace custom-authorizer-st
2022-04-05 20:27:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sre-admin will have desired state: Ready
2022-04-05 20:27:02 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sre-admin is in desired state: Ready
2022-04-05 20:27:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a1db355a-kafka-clients in namespace custom-authorizer-st
2022-04-05 20:27:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a1db355a-kafka-clients will be ready
2022-04-05 20:27:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a1db355a-kafka-clients is ready
2022-04-05 20:27:04 [main] [32mINFO [m [CustomAuthorizerST:173] Checking kafka super user:sre-admin that is able to send messages to topic:my-topic-1921754918-884751161
2022-04-05 20:27:04 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:27:04 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@20e32f5e, messages=[], arguments=[USER=sre_admin, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093, --max-messages, 100, --topic, my-topic-1921754918-884751161], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-a1db355a-kafka-clients-56c9974474-lqb5c', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1921754918-884751161', maxMessages=100, kafkaUsername='sre-admin', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@d4e3987}
2022-04-05 20:27:04 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1921754918-884751161 from pod my-cluster-a1db355a-kafka-clients-56c9974474-lqb5c
2022-04-05 20:27:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a1db355a-kafka-clients-56c9974474-lqb5c -n custom-authorizer-st -- /opt/kafka/producer.sh USER=sre_admin --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093 --max-messages 100 --topic my-topic-1921754918-884751161
2022-04-05 20:27:08 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 20:27:08 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 20:27:08 [main] [32mINFO [m [CustomAuthorizerST:187] Checking kafka super user:sre-admin that is able to read messages to topic:my-topic-609391865-1811347379 regardless that we configured Acls with only write operation
2022-04-05 20:27:08 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5821b88f, messages=[], arguments=[USER=sre_admin, --group-id, my-consumer-group-912422257, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093, --group-instance-id, instance1076278287, --max-messages, 100, --topic, my-topic-1921754918-884751161], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-a1db355a-kafka-clients-56c9974474-lqb5c', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1921754918-884751161', maxMessages=100, kafkaUsername='sre-admin', consumerGroupName='my-consumer-group-912422257', consumerInstanceId='instance1076278287', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@24df2f92}
2022-04-05 20:27:08 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1921754918-884751161 from pod my-cluster-a1db355a-kafka-clients-56c9974474-lqb5c
2022-04-05 20:27:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-a1db355a-kafka-clients-56c9974474-lqb5c -n custom-authorizer-st -- /opt/kafka/consumer.sh USER=sre_admin --group-id my-consumer-group-912422257 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093 --group-instance-id instance1076278287 --max-messages 100 --topic my-topic-1921754918-884751161
2022-04-05 20:27:15 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 20:27:15 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 20:27:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:27:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAclWithSuperUser
2022-04-05 20:27:15 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sre-admin in namespace custom-authorizer-st
2022-04-05 20:27:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1921754918-884751161 in namespace custom-authorizer-st
2022-04-05 20:27:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a1db355a-kafka-clients in namespace custom-authorizer-st
2022-04-05 20:27:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:27:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclWithSuperUser-FINISHED
2022-04-05 20:27:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:27:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:27:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclRuleReadAndWrite-STARTED
2022-04-05 20:27:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:27:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1355878018-1768268110 in namespace custom-authorizer-st
2022-04-05 20:27:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1355878018-1768268110 will have desired state: Ready
2022-04-05 20:27:56 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1355878018-1768268110 is in desired state: Ready
2022-04-05 20:27:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser kafka-user-write in namespace custom-authorizer-st
2022-04-05 20:27:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: kafka-user-write will have desired state: Ready
2022-04-05 20:27:57 [main] [32mINFO [m [ResourceManager:444] KafkaUser: kafka-user-write is in desired state: Ready
2022-04-05 20:27:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser kafka-user-read in namespace custom-authorizer-st
2022-04-05 20:27:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: kafka-user-read will have desired state: Ready
2022-04-05 20:27:58 [main] [32mINFO [m [ResourceManager:444] KafkaUser: kafka-user-read is in desired state: Ready
2022-04-05 20:27:58 [main] [32mINFO [m [CustomAuthorizerST:105] Checking KafkaUser kafka-user-write that is able to send messages to topic 'my-topic-1355878018-1768268110'
2022-04-05 20:27:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-27fa9460-kafka-clients in namespace custom-authorizer-st
2022-04-05 20:27:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-27fa9460-kafka-clients will be ready
2022-04-05 20:28:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-27fa9460-kafka-clients is ready
2022-04-05 20:28:00 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:28:00 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@60dd5479, messages=[], arguments=[USER=kafka_user_write, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093, --max-messages, 500, --topic, my-topic-1355878018-1768268110], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-27fa9460-kafka-clients-5b4d9fb6bd-tgb97', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1355878018-1768268110', maxMessages=500, kafkaUsername='kafka-user-write', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5e725c75}
2022-04-05 20:28:00 [main] [32mINFO [m [InternalKafkaClient:124] Producing 500 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1355878018-1768268110 from pod my-cluster-27fa9460-kafka-clients-5b4d9fb6bd-tgb97
2022-04-05 20:28:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-27fa9460-kafka-clients-5b4d9fb6bd-tgb97 -n custom-authorizer-st -- /opt/kafka/producer.sh USER=kafka_user_write --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093 --max-messages 500 --topic my-topic-1355878018-1768268110
2022-04-05 20:28:04 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 20:28:04 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 500 messages
2022-04-05 20:28:04 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@43e47b96, messages=[], arguments=[USER=kafka_user_write, --group-id, my-consumer-group-304485144, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093, --group-instance-id, instance762262555, --max-messages, 500, --topic, my-topic-1355878018-1768268110], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-27fa9460-kafka-clients-5b4d9fb6bd-tgb97', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1355878018-1768268110', maxMessages=500, kafkaUsername='kafka-user-write', consumerGroupName='my-consumer-group-304485144', consumerInstanceId='instance762262555', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@24ac57f0}
2022-04-05 20:28:04 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 500 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1355878018-1768268110 from pod my-cluster-27fa9460-kafka-clients-5b4d9fb6bd-tgb97
2022-04-05 20:28:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-27fa9460-kafka-clients-5b4d9fb6bd-tgb97 -n custom-authorizer-st -- /opt/kafka/consumer.sh USER=kafka_user_write --group-id my-consumer-group-304485144 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093 --group-instance-id instance762262555 --max-messages 500 --topic my-topic-1355878018-1768268110
2022-04-05 20:28:08 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 20:28:08 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 0 messages
2022-04-05 20:28:08 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@54de579, messages=[], arguments=[USER=kafka_user_read, --group-id, consumer-group-name-1, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093, --group-instance-id, instance317480496, --max-messages, 500, --topic, my-topic-1355878018-1768268110], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-27fa9460-kafka-clients-5b4d9fb6bd-tgb97', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1355878018-1768268110', maxMessages=500, kafkaUsername='kafka-user-read', consumerGroupName='consumer-group-name-1', consumerInstanceId='instance317480496', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@fb9166b}
2022-04-05 20:28:08 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 500 messages from custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1355878018-1768268110 from pod my-cluster-27fa9460-kafka-clients-5b4d9fb6bd-tgb97
2022-04-05 20:28:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-27fa9460-kafka-clients-5b4d9fb6bd-tgb97 -n custom-authorizer-st -- /opt/kafka/consumer.sh USER=kafka_user_read --group-id consumer-group-name-1 --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093 --group-instance-id instance317480496 --max-messages 500 --topic my-topic-1355878018-1768268110
2022-04-05 20:28:15 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 20:28:15 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 500 messages
2022-04-05 20:28:15 [main] [32mINFO [m [CustomAuthorizerST:137] Checking KafkaUser kafka-user-read that is not able to send messages to topic 'my-topic-1355878018-1768268110'
2022-04-05 20:28:15 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2340dac9, messages=[], arguments=[USER=kafka_user_read, --bootstrap-server, custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093, --max-messages, 500, --topic, my-topic-1355878018-1768268110], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-27fa9460-kafka-clients-5b4d9fb6bd-tgb97', podNamespace='custom-authorizer-st', bootstrapServer='custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093', topicName='my-topic-1355878018-1768268110', maxMessages=500, kafkaUsername='kafka-user-read', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@431821f7}
2022-04-05 20:28:15 [main] [32mINFO [m [InternalKafkaClient:124] Producing 500 messages to custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093:my-topic-1355878018-1768268110 from pod my-cluster-27fa9460-kafka-clients-5b4d9fb6bd-tgb97
2022-04-05 20:28:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-27fa9460-kafka-clients-5b4d9fb6bd-tgb97 -n custom-authorizer-st -- /opt/kafka/producer.sh USER=kafka_user_read --bootstrap-server custom-authorizer-kafka-bootstrap.custom-authorizer-st.svc:9093 --max-messages 500 --topic my-topic-1355878018-1768268110
2022-04-05 20:28:18 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 20:28:18 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced -1 messages
2022-04-05 20:28:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:28:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAclRuleReadAndWrite
2022-04-05 20:28:18 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser kafka-user-read in namespace custom-authorizer-st
2022-04-05 20:28:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-27fa9460-kafka-clients in namespace custom-authorizer-st
2022-04-05 20:28:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser kafka-user-write in namespace custom-authorizer-st
2022-04-05 20:28:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1355878018-1768268110 in namespace custom-authorizer-st
2022-04-05 20:28:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:28:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.custom.CustomAuthorizerST.testAclRuleReadAndWrite-FINISHED
2022-04-05 20:28:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:28:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:28:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for CustomAuthorizerST
2022-04-05 20:28:58 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka custom-authorizer in namespace custom-authorizer-st
2022-04-05 20:29:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 232.157 s - in io.strimzi.systemtest.security.custom.CustomAuthorizerST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.OpaIntegrationST
2022-04-05 20:29:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: opa-integration-st
2022-04-05 20:29:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: opa-integration-st
2022-04-05 20:29:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: opa-integration-st
2022-04-05 20:29:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka opa-cluster in namespace opa-integration-st
2022-04-05 20:29:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: opa-cluster will have desired state: Ready
2022-04-05 20:30:51 [main] [32mINFO [m [ResourceManager:444] Kafka: opa-cluster is in desired state: Ready
2022-04-05 20:30:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:30:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorizationSuperUser-STARTED
2022-04-05 20:30:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:30:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-579227017-1905037149 in namespace opa-integration-st
2022-04-05 20:30:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-579227017-1905037149 will have desired state: Ready
2022-04-05 20:30:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-579227017-1905037149 is in desired state: Ready
2022-04-05 20:30:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser arnost in namespace opa-integration-st
2022-04-05 20:30:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: arnost will have desired state: Ready
2022-04-05 20:30:53 [main] [32mINFO [m [ResourceManager:444] KafkaUser: arnost is in desired state: Ready
2022-04-05 20:30:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d852d092-kafka-clients in namespace opa-integration-st
2022-04-05 20:30:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d852d092-kafka-clients will be ready
2022-04-05 20:30:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d852d092-kafka-clients is ready
2022-04-05 20:30:55 [main] [32mINFO [m [OpaIntegrationST:120] Checking KafkaUser good-user that is able to send and receive messages to/from topic 'my-topic-579227017-1905037149'
2022-04-05 20:30:55 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@34375188, messages=[], arguments=[USER=arnost, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093, --max-messages, 100, --topic, my-topic-579227017-1905037149], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d852d092-kafka-clients-6d89f4dd58-p4lwl', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-579227017-1905037149', maxMessages=100, kafkaUsername='arnost', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@721f6fc6}
2022-04-05 20:30:55 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-579227017-1905037149 from pod my-cluster-d852d092-kafka-clients-6d89f4dd58-p4lwl
2022-04-05 20:30:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d852d092-kafka-clients-6d89f4dd58-p4lwl -n opa-integration-st -- /opt/kafka/producer.sh USER=arnost --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093 --max-messages 100 --topic my-topic-579227017-1905037149
2022-04-05 20:30:59 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 20:30:59 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 20:30:59 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@72965797, messages=[], arguments=[USER=arnost, --group-id, consumer-group-name-2, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093, --group-instance-id, instance2619121, --max-messages, 100, --topic, my-topic-579227017-1905037149], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d852d092-kafka-clients-6d89f4dd58-p4lwl', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-579227017-1905037149', maxMessages=100, kafkaUsername='arnost', consumerGroupName='consumer-group-name-2', consumerInstanceId='instance2619121', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7bfe6671}
2022-04-05 20:30:59 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-579227017-1905037149 from pod my-cluster-d852d092-kafka-clients-6d89f4dd58-p4lwl
2022-04-05 20:30:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d852d092-kafka-clients-6d89f4dd58-p4lwl -n opa-integration-st -- /opt/kafka/consumer.sh USER=arnost --group-id consumer-group-name-2 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093 --group-instance-id instance2619121 --max-messages 100 --topic my-topic-579227017-1905037149
2022-04-05 20:31:07 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 20:31:07 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 20:31:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:31:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOpaAuthorizationSuperUser
2022-04-05 20:31:07 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser arnost in namespace opa-integration-st
2022-04-05 20:31:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d852d092-kafka-clients in namespace opa-integration-st
2022-04-05 20:31:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-579227017-1905037149 in namespace opa-integration-st
2022-04-05 20:31:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:31:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorizationSuperUser-FINISHED
2022-04-05 20:31:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:31:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:31:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorization-STARTED
2022-04-05 20:31:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:31:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser good-user in namespace opa-integration-st
2022-04-05 20:31:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: good-user will have desired state: Ready
2022-04-05 20:31:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: good-user is in desired state: Ready
2022-04-05 20:31:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bad-user in namespace opa-integration-st
2022-04-05 20:31:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bad-user will have desired state: Ready
2022-04-05 20:31:49 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bad-user is in desired state: Ready
2022-04-05 20:31:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f5f1831f-kafka-clients in namespace opa-integration-st
2022-04-05 20:31:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f5f1831f-kafka-clients will be ready
2022-04-05 20:31:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f5f1831f-kafka-clients is ready
2022-04-05 20:31:51 [main] [32mINFO [m [OpaIntegrationST:72] Checking KafkaUser good-user that is able to send and receive messages to/from topic 'my-topic-2000367322-856102066'
2022-04-05 20:31:51 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1cfe3135, messages=[], arguments=[USER=good_user, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093, --max-messages, 100, --topic, my-topic-2000367322-856102066], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-f5f1831f-kafka-clients-666454d484-842mr', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-2000367322-856102066', maxMessages=100, kafkaUsername='good-user', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7f24949e}
2022-04-05 20:31:51 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-2000367322-856102066 from pod my-cluster-f5f1831f-kafka-clients-666454d484-842mr
2022-04-05 20:31:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f5f1831f-kafka-clients-666454d484-842mr -n opa-integration-st -- /opt/kafka/producer.sh USER=good_user --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093 --max-messages 100 --topic my-topic-2000367322-856102066
2022-04-05 20:31:56 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 20:31:56 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 20:31:56 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3d310791, messages=[], arguments=[USER=good_user, --group-id, my-consumer-group-341168635, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093, --group-instance-id, instance1237437353, --max-messages, 100, --topic, my-topic-2000367322-856102066], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f5f1831f-kafka-clients-666454d484-842mr', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-2000367322-856102066', maxMessages=100, kafkaUsername='good-user', consumerGroupName='my-consumer-group-341168635', consumerInstanceId='instance1237437353', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@70024930}
2022-04-05 20:31:56 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-2000367322-856102066 from pod my-cluster-f5f1831f-kafka-clients-666454d484-842mr
2022-04-05 20:31:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f5f1831f-kafka-clients-666454d484-842mr -n opa-integration-st -- /opt/kafka/consumer.sh USER=good_user --group-id my-consumer-group-341168635 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093 --group-instance-id instance1237437353 --max-messages 100 --topic my-topic-2000367322-856102066
2022-04-05 20:32:03 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 20:32:03 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 20:32:03 [main] [32mINFO [m [OpaIntegrationST:89] Checking KafkaUser bad-user that is not able to send or receive messages to/from topic 'my-topic-2000367322-856102066'
2022-04-05 20:32:03 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@b7006bc, messages=[], arguments=[USER=bad_user, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093, --max-messages, 100, --topic, my-topic-2000367322-856102066], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-f5f1831f-kafka-clients-666454d484-842mr', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-2000367322-856102066', maxMessages=100, kafkaUsername='bad-user', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@66eaf4cd}
2022-04-05 20:32:03 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-2000367322-856102066 from pod my-cluster-f5f1831f-kafka-clients-666454d484-842mr
2022-04-05 20:32:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f5f1831f-kafka-clients-666454d484-842mr -n opa-integration-st -- /opt/kafka/producer.sh USER=bad_user --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093 --max-messages 100 --topic my-topic-2000367322-856102066
2022-04-05 20:32:06 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 20:32:06 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced -1 messages
2022-04-05 20:32:06 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5c610a1e, messages=[], arguments=[USER=bad_user, --group-id, my-consumer-group-341168635, --bootstrap-server, opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093, --group-instance-id, instance873961039, --max-messages, 100, --topic, my-topic-2000367322-856102066], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f5f1831f-kafka-clients-666454d484-842mr', podNamespace='opa-integration-st', bootstrapServer='opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093', topicName='my-topic-2000367322-856102066', maxMessages=100, kafkaUsername='bad-user', consumerGroupName='my-consumer-group-341168635', consumerInstanceId='instance873961039', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6959852b}
2022-04-05 20:32:06 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093:my-topic-2000367322-856102066 from pod my-cluster-f5f1831f-kafka-clients-666454d484-842mr
2022-04-05 20:32:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f5f1831f-kafka-clients-666454d484-842mr -n opa-integration-st -- /opt/kafka/consumer.sh USER=bad_user --group-id my-consumer-group-341168635 --bootstrap-server opa-cluster-kafka-bootstrap.opa-integration-st.svc:9093 --group-instance-id instance873961039 --max-messages 100 --topic my-topic-2000367322-856102066
2022-04-05 20:32:33 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 20:32:33 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 0 messages
2022-04-05 20:32:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:32:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOpaAuthorization
2022-04-05 20:32:33 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bad-user in namespace opa-integration-st
2022-04-05 20:32:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser good-user in namespace opa-integration-st
2022-04-05 20:32:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f5f1831f-kafka-clients in namespace opa-integration-st
2022-04-05 20:33:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:33:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.OpaIntegrationST.testOpaAuthorization-FINISHED
2022-04-05 20:33:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:33:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:33:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OpaIntegrationST
2022-04-05 20:33:23 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka opa-cluster in namespace opa-integration-st
2022-04-05 20:33:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 264.56 s - in io.strimzi.systemtest.security.OpaIntegrationST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.SecurityST
2022-04-05 20:34:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: security-st
2022-04-05 20:34:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: security-st
2022-04-05 20:34:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: security-st
2022-04-05 20:34:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:34:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-STARTED
2022-04-05 20:34:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:34:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-56 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-05 20:34:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-56
2022-04-05 20:34:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-56
2022-04-05 20:34:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-56
2022-04-05 20:34:00 [main] [32mINFO [m [SecretUtils:70] Creating secret my-cluster-7f8f883b-cluster-ca-cert
2022-04-05 20:34:00 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 20:34:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7f8f883b in namespace namespace-56
2022-04-05 20:34:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-05 20:34:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7f8f883b will have desired state: Ready
2022-04-05 20:36:08 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7f8f883b is in desired state: Ready
2022-04-05 20:36:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-996943206-2068566808 in namespace namespace-56
2022-04-05 20:36:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-05 20:36:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-996943206-2068566808 will have desired state: Ready
2022-04-05 20:36:09 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-996943206-2068566808 is in desired state: Ready
2022-04-05 20:36:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-850760129-618147564 in namespace namespace-56
2022-04-05 20:36:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-05 20:36:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-850760129-618147564 will have desired state: Ready
2022-04-05 20:36:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-850760129-618147564 is in desired state: Ready
2022-04-05 20:36:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7f8f883b-kafka-clients in namespace namespace-56
2022-04-05 20:36:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-56
2022-04-05 20:36:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7f8f883b-kafka-clients will be ready
2022-04-05 20:36:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7f8f883b-kafka-clients is ready
2022-04-05 20:36:12 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:36:12 [main] [32mINFO [m [SecurityST:660] Checking produced and consumed messages to pod:my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h
2022-04-05 20:36:12 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@12f86052, messages=[], arguments=[--bootstrap-server, my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092, --max-messages, 100, --topic, my-topic-850760129-618147564], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h', podNamespace='namespace-56', bootstrapServer='my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-850760129-618147564', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@43143290}
2022-04-05 20:36:12 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092:my-topic-850760129-618147564 from pod my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h
2022-04-05 20:36:12 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h -n namespace-56 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092 --max-messages 100 --topic my-topic-850760129-618147564
2022-04-05 20:36:14 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 20:36:14 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 20:36:14 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@43f0c46, messages=[], arguments=[--group-id, my-consumer-group-1374883184, --bootstrap-server, my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092, --group-instance-id, instance1177804813, --max-messages, 100, --topic, my-topic-850760129-618147564], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h', podNamespace='namespace-56', bootstrapServer='my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-850760129-618147564', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1374883184', consumerInstanceId='instance1177804813', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@66dd22bf}
2022-04-05 20:36:14 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092#my-topic-850760129-618147564 from pod my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h
2022-04-05 20:36:14 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h -n namespace-56 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1374883184 --bootstrap-server my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092 --group-instance-id instance1177804813 --max-messages 100 --topic my-topic-850760129-618147564
2022-04-05 20:36:20 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 20:36:20 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 20:36:20 [main] [32mINFO [m [SecretUtils:131] Waiting for Secret my-cluster-7f8f883b-cluster-ca-cert certificate change
2022-04-05 20:36:20 [main] [32mINFO [m [SecretUtils:138] Certificate in Secret my-cluster-7f8f883b-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUJ6s8v1qZq6z40HLGzzpA20gdhsQwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDUyMDM0MDBaFw0yMzA0MDUyMDM0MDBaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQDQ9GdaJ5cxC1il40VUzcuIttklmpWn4ylllsxhFzSH
a3JfLXmMDpBuq88t0LLD1QOkhq50LV1e1O38gNbrajU1Wzr0NLfkU5rjjeIR6oYh
mYg7+85KVYpXmNgmGLmYevqjTG8gJ8RYery8zcCYfFrPzrtzjtxjQkj3Sr5ubjva
aaGKUDRShjQJKxX2yNFbEevVCPr8TzpolJrwCxnK6+2AyGGSyn/U5exxUT16Twem
tbslKiTp6d+VMUkEjXqsztVhEtm3HdzkVGP9xAzR4QVzF5MLmfPayh7EUywYn1jC
nzTOTBp+VpDQoYKfhrJUdwUul01vF2tqXFSiJGb8ASYE1HyzP9xt+vWzdgRAs5Nz
33uRa9NoMpzJdY9d799KrWai6T5zZ3LDZ4L1EJIFoZ7nWJmsbntBJILLrNyxfduk
ZoAn8Daj2s2zo3ZLSYyi6kSeEVxEeXsWNfo73bBhNSkmhQJEDYNQBRwpsTFBRwME
vYPCmtFKkSrMLkXeuB0FLSj4qaAtH8sTXbBmtTDhFCKUjirp4/fomVPK3S0gn98o
8mHx36gVpqDyUpkxy2g9My4yVvqA6TPrEze/VYnFtjS1xTFwMvgnjTT0UnXdsXsR
SGP/S2cl/OEwWjZDgTZYcwYhTYITNaVuGoLukEQELTDOlOiuREqSyCce6jI+k4U9
mwIDAQABo0UwQzAdBgNVHQ4EFgQUAi61xJ5VZsc9k4zf8XRzrQ5tAzgwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
AFHdnQklbI6xS7dQspJFZc866kJz9erbtElf+dZehI/CmALLB13vVVZN8PjuEmpS
j16H2DzNnH+aiAkcGtbMQQ6Z5Rn14EgnhU7z5r32UQ+TNFXwDW8Wi1Y3FH69foda
zZwLUuFWJdXkwTWDkC7fnKjr+Hww68/PRAsKDdy3M7+9Ef6gpBXwpfylwVApmlFs
q4WAiHUoUA42qm9ssA90dyJJULYho6iqXQhKzmdMHbgsFY7ZxrR6vrIKsWpjRVZU
ktlNAHHA9TqwNgm5kuYU9BNpGgI5f++pRiKmxwi+I4N/SNs+bDu7nv1En0HNwysq
Nwbs4ZWKcgdVXfu44TcTHk+gN4N3xfckM4NxRWYQA0gSNNNdD8H6ZmmE919WsVjA
9zl5u3k5AO+c35WsQjg2I8t46VcF9AG6vAh3wvFMpTBvMa6c+aLYZ9BV8GyudbjH
TuvlniPpUU2QzDgBKvBx+9OZrjVQV22mZaBWovtr0iqjPgLZvEr4FKei0neB/b/9
3E8UTGD9YVvj6yYDOF9Tgx0A/ataTjSPtVh7y+gHBRmKshZn1apW4WKOh2++i7k1
oloTmsliBNYqSLiDWtIs9OLprIJFboEJuVK9IQopbQU71HXrTQ4REyf4ygouCPWD
Lf1ZwmOBdemUsL0plMEuvWFzyKQxtvgjYkKQStpino2k
-----END CERTIFICATE-----

2022-04-05 20:36:20 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-05 20:37:22 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-05 20:37:22 [main] [32mINFO [m [SecurityST:672] Checking produced and consumed messages to pod:my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h
2022-04-05 20:37:22 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1fba6bbe, messages=[], arguments=[--bootstrap-server, my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092, --max-messages, 100, --topic, my-topic-850760129-618147564], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h', podNamespace='namespace-56', bootstrapServer='my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-850760129-618147564', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@107d6bd4}
2022-04-05 20:37:22 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092:my-topic-850760129-618147564 from pod my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h
2022-04-05 20:37:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h -n namespace-56 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092 --max-messages 100 --topic my-topic-850760129-618147564
2022-04-05 20:37:25 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 20:37:25 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 20:37:25 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6d91d6eb, messages=[], arguments=[--group-id, my-consumer-group-1374883184, --bootstrap-server, my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092, --group-instance-id, instance712185673, --max-messages, 100, --topic, my-topic-850760129-618147564], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h', podNamespace='namespace-56', bootstrapServer='my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092', topicName='my-topic-850760129-618147564', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1374883184', consumerInstanceId='instance712185673', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@16c92c2d}
2022-04-05 20:37:25 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092#my-topic-850760129-618147564 from pod my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h
2022-04-05 20:37:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7f8f883b-kafka-clients-76dcbc58b4-xqz4h -n namespace-56 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1374883184 --bootstrap-server my-cluster-7f8f883b-kafka-bootstrap.namespace-56.svc:9092 --group-instance-id instance712185673 --max-messages 100 --topic my-topic-850760129-618147564
2022-04-05 20:37:30 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 20:37:30 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 20:37:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:37:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-05 20:37:30 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-850760129-618147564 in namespace namespace-56
2022-04-05 20:37:30 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-996943206-2068566808 in namespace namespace-56
2022-04-05 20:37:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7f8f883b in namespace namespace-56
2022-04-05 20:37:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-56, for cruise control Kafka cluster my-cluster-7f8f883b
2022-04-05 20:37:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7f8f883b-kafka-clients in namespace namespace-56
2022-04-05 20:38:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:38:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-56 for test case:testAutoRenewCaCertsTriggerByExpiredCertificate
2022-04-05 20:38:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewCaCertsTriggerByExpiredCertificate-FINISHED
2022-04-05 20:38:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:38:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:38:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-STARTED
2022-04-05 20:38:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:38:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-57 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-05 20:38:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-57
2022-04-05 20:38:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-57
2022-04-05 20:38:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-57
2022-04-05 20:38:26 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 20:38:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-590f506c in namespace namespace-57
2022-04-05 20:38:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-05 20:38:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-590f506c will have desired state: Ready
2022-04-05 20:40:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-590f506c is in desired state: Ready
2022-04-05 20:40:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1397302586-1585492696 in namespace namespace-57
2022-04-05 20:40:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-05 20:40:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1397302586-1585492696 will have desired state: Ready
2022-04-05 20:40:51 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1397302586-1585492696 is in desired state: Ready
2022-04-05 20:40:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1585588842-1756709319 in namespace namespace-57
2022-04-05 20:40:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-05 20:40:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1585588842-1756709319 will have desired state: Ready
2022-04-05 20:40:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1585588842-1756709319 is in desired state: Ready
2022-04-05 20:40:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-590f506c-kafka-clients in namespace namespace-57
2022-04-05 20:40:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-05 20:40:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-590f506c-kafka-clients will be ready
2022-04-05 20:40:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-590f506c-kafka-clients is ready
2022-04-05 20:40:54 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:40:54 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-590f506c-kafka-clients-5cccbb6ff5-kr4j2
2022-04-05 20:40:54 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5762adba, messages=[], arguments=[--bootstrap-server, my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092, --max-messages, 100, --topic, my-topic-1585588842-1756709319], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-590f506c-kafka-clients-5cccbb6ff5-kr4j2', podNamespace='namespace-57', bootstrapServer='my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-1585588842-1756709319', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7b5ddca7}
2022-04-05 20:40:54 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092:my-topic-1585588842-1756709319 from pod my-cluster-590f506c-kafka-clients-5cccbb6ff5-kr4j2
2022-04-05 20:40:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-590f506c-kafka-clients-5cccbb6ff5-kr4j2 -n namespace-57 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092 --max-messages 100 --topic my-topic-1585588842-1756709319
2022-04-05 20:40:56 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 20:40:56 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 20:40:56 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1422a6ea, messages=[], arguments=[--group-id, my-consumer-group-2065550054, --bootstrap-server, my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092, --group-instance-id, instance1381324972, --max-messages, 100, --topic, my-topic-1585588842-1756709319], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-590f506c-kafka-clients-5cccbb6ff5-kr4j2', podNamespace='namespace-57', bootstrapServer='my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-1585588842-1756709319', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2065550054', consumerInstanceId='instance1381324972', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@10fea88}
2022-04-05 20:40:56 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092#my-topic-1585588842-1756709319 from pod my-cluster-590f506c-kafka-clients-5cccbb6ff5-kr4j2
2022-04-05 20:40:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-590f506c-kafka-clients-5cccbb6ff5-kr4j2 -n namespace-57 -- /opt/kafka/consumer.sh --group-id my-consumer-group-2065550054 --bootstrap-server my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092 --group-instance-id instance1381324972 --max-messages 100 --topic my-topic-1585588842-1756709319
2022-04-05 20:41:02 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 20:41:02 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 20:41:02 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-05 20:41:02 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-590f506c-clients-ca with strimzi.io/force-replace
2022-04-05 20:41:02 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-05 20:41:02 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-590f506c-kafka rolling update
2022-04-05 20:42:33 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-590f506c-kafka has been successfully rolled
2022-04-05 20:42:33 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-05 20:42:33 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-590f506c-kafka rolling update
2022-04-05 20:43:48 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-590f506c-kafka has been successfully rolled
2022-04-05 20:43:48 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-590f506c-kafka to be ready
2022-04-05 20:44:12 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-05 20:44:12 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-590f506c-kafka-clients-5cccbb6ff5-kr4j2
2022-04-05 20:44:12 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3724dfe1, messages=[], arguments=[--group-id, my-consumer-group-1390827259, --bootstrap-server, my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092, --group-instance-id, instance1355523973, --max-messages, 100, --topic, my-topic-1585588842-1756709319], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-590f506c-kafka-clients-5cccbb6ff5-kr4j2', podNamespace='namespace-57', bootstrapServer='my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-1585588842-1756709319', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1390827259', consumerInstanceId='instance1355523973', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@293c54c4}
2022-04-05 20:44:12 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092#my-topic-1585588842-1756709319 from pod my-cluster-590f506c-kafka-clients-5cccbb6ff5-kr4j2
2022-04-05 20:44:12 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-590f506c-kafka-clients-5cccbb6ff5-kr4j2 -n namespace-57 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1390827259 --bootstrap-server my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092 --group-instance-id instance1355523973 --max-messages 100 --topic my-topic-1585588842-1756709319
2022-04-05 20:44:18 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 20:44:18 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 20:44:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2146850997-158590339 in namespace namespace-57
2022-04-05 20:44:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-05 20:44:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2146850997-158590339 will have desired state: Ready
2022-04-05 20:44:19 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2146850997-158590339 is in desired state: Ready
2022-04-05 20:44:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-590f506c-kafka-clients-tls in namespace namespace-57
2022-04-05 20:44:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-57
2022-04-05 20:44:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-590f506c-kafka-clients-tls will be ready
2022-04-05 20:44:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-590f506c-kafka-clients-tls is ready
2022-04-05 20:44:21 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-590f506c-kafka-clients-tls-f9d56b44b-688wz
2022-04-05 20:44:21 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@29ab6f54, messages=[], arguments=[--group-id, my-consumer-group-133313325, --bootstrap-server, my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092, --group-instance-id, instance1680051314, --max-messages, 100, --topic, my-topic-1585588842-1756709319], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-590f506c-kafka-clients-tls-f9d56b44b-688wz', podNamespace='namespace-57', bootstrapServer='my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092', topicName='my-topic-1585588842-1756709319', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-133313325', consumerInstanceId='instance1680051314', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1c5095b3}
2022-04-05 20:44:21 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092#my-topic-1585588842-1756709319 from pod my-cluster-590f506c-kafka-clients-tls-f9d56b44b-688wz
2022-04-05 20:44:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-590f506c-kafka-clients-tls-f9d56b44b-688wz -n namespace-57 -- /opt/kafka/consumer.sh --group-id my-consumer-group-133313325 --bootstrap-server my-cluster-590f506c-kafka-bootstrap.namespace-57.svc:9092 --group-instance-id instance1680051314 --max-messages 100 --topic my-topic-1585588842-1756709319
2022-04-05 20:44:27 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 20:44:27 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 20:44:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:44:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-05 20:44:27 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-590f506c-kafka-clients in namespace namespace-57
2022-04-05 20:44:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1397302586-1585492696 in namespace namespace-57
2022-04-05 20:44:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-590f506c-kafka-clients-tls in namespace namespace-57
2022-04-05 20:44:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2146850997-158590339 in namespace namespace-57
2022-04-05 20:44:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1585588842-1756709319 in namespace namespace-57
2022-04-05 20:44:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-590f506c in namespace namespace-57
2022-04-05 20:44:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-57, for cruise control Kafka cluster my-cluster-590f506c
2022-04-05 20:45:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:45:07 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-57 for test case:testAutoReplaceClientsCaKeysTriggeredByAnno
2022-04-05 20:45:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClientsCaKeysTriggeredByAnno-FINISHED
2022-04-05 20:45:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:45:34 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:45:34 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-STARTED
2022-04-05 20:45:34 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:45:34 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-58 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-04-05 20:45:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-58
2022-04-05 20:45:34 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-58
2022-04-05 20:45:34 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-58
2022-04-05 20:45:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-75dd9732-source in namespace namespace-58
2022-04-05 20:45:34 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-05 20:45:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-75dd9732-source will have desired state: Ready
2022-04-05 20:46:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-75dd9732-source is in desired state: Ready
2022-04-05 20:46:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-75dd9732-target in namespace namespace-58
2022-04-05 20:46:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-05 20:46:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-75dd9732-target will have desired state: Ready
2022-04-05 20:47:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-75dd9732-target is in desired state: Ready
2022-04-05 20:47:59 [main] [32mINFO [m [SecurityST:888] Getting IP of the source bootstrap service for consumer
2022-04-05 20:47:59 [main] [32mINFO [m [SecurityST:891] Getting IP of the target bootstrap service for producer
2022-04-05 20:47:59 [main] [32mINFO [m [SecurityST:894] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to consumer with address 10.111.8.201:9093
2022-04-05 20:47:59 [main] [32mINFO [m [SecurityST:895] KafkaMirrorMaker without config ssl.endpoint.identification.algorithm will not connect to producer with address 10.102.14.86:9093
2022-04-05 20:47:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-75dd9732 in namespace namespace-58
2022-04-05 20:47:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-58
2022-04-05 20:47:59 [main] [32mINFO [m [PodUtils:245] Wait until Pod my-cluster-75dd9732-mirror-maker is present
2022-04-05 20:48:00 [main] [32mINFO [m [PodUtils:249] Pod my-cluster-75dd9732-mirror-maker is present
2022-04-05 20:48:00 [main] [32mINFO [m [PodUtils:236] Wait until Pod my-cluster-75dd9732-mirror-maker-5c54bc665b-f2wt6 is in CrashLoopBackOff state
2022-04-05 20:48:12 [main] [32mINFO [m [PodUtils:241] Pod my-cluster-75dd9732-mirror-maker-5c54bc665b-f2wt6 is in CrashLoopBackOff state
2022-04-05 20:48:12 [main] [32mINFO [m [SecurityST:930] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to consumer with address 10.111.8.201:9093
2022-04-05 20:48:12 [main] [32mINFO [m [SecurityST:931] KafkaMirrorMaker with config ssl.endpoint.identification.algorithm will connect to producer with address 10.102.14.86:9093
2022-04-05 20:48:12 [main] [32mINFO [m [SecurityST:933] Adding configuration ssl.endpoint.identification.algorithm to the mirror maker...
2022-04-05 20:48:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-75dd9732 will have desired state: Ready
2022-04-05 20:54:08 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-75dd9732 is in desired state: Ready
2022-04-05 20:54:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 20:54:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsHostnameVerificationWithMirrorMaker
2022-04-05 20:54:08 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-75dd9732-target in namespace namespace-58
2022-04-05 20:54:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-75dd9732 in namespace namespace-58
2022-04-05 20:54:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-75dd9732-source in namespace namespace-58
2022-04-05 20:54:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 20:54:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-58 for test case:testTlsHostnameVerificationWithMirrorMaker
2022-04-05 20:54:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithMirrorMaker-FINISHED
2022-04-05 20:54:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 20:54:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 20:54:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-STARTED
2022-04-05 20:54:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 20:54:39 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-59 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-05 20:54:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-59
2022-04-05 20:54:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-59
2022-04-05 20:54:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-59
2022-04-05 20:54:39 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 20:54:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6c7f1c60 in namespace namespace-59
2022-04-05 20:54:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-05 20:54:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6c7f1c60 will have desired state: Ready
2022-04-05 20:56:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6c7f1c60 is in desired state: Ready
2022-04-05 20:56:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-5730953-1997858025 in namespace namespace-59
2022-04-05 20:56:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-05 20:56:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-5730953-1997858025 will have desired state: Ready
2022-04-05 20:56:50 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-5730953-1997858025 is in desired state: Ready
2022-04-05 20:56:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1140969416-265154834 in namespace namespace-59
2022-04-05 20:56:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-05 20:56:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1140969416-265154834 will have desired state: Ready
2022-04-05 20:56:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1140969416-265154834 is in desired state: Ready
2022-04-05 20:56:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6c7f1c60-kafka-clients in namespace namespace-59
2022-04-05 20:56:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-05 20:56:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6c7f1c60-kafka-clients will be ready
2022-04-05 20:56:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6c7f1c60-kafka-clients is ready
2022-04-05 20:56:53 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 20:56:53 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-6c7f1c60-kafka-clients-5dc44d9c-ndk8q
2022-04-05 20:56:53 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@43512de7, messages=[], arguments=[--bootstrap-server, my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9092, --max-messages, 100, --topic, my-topic-1140969416-265154834], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-6c7f1c60-kafka-clients-5dc44d9c-ndk8q', podNamespace='namespace-59', bootstrapServer='my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-1140969416-265154834', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@51c0af7a}
2022-04-05 20:56:53 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9092:my-topic-1140969416-265154834 from pod my-cluster-6c7f1c60-kafka-clients-5dc44d9c-ndk8q
2022-04-05 20:56:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6c7f1c60-kafka-clients-5dc44d9c-ndk8q -n namespace-59 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9092 --max-messages 100 --topic my-topic-1140969416-265154834
2022-04-05 20:56:55 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 20:56:55 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 20:56:55 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@d92443a, messages=[], arguments=[--group-id, my-consumer-group-1856611658, --bootstrap-server, my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9092, --group-instance-id, instance440440669, --max-messages, 100, --topic, my-topic-1140969416-265154834], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-6c7f1c60-kafka-clients-5dc44d9c-ndk8q', podNamespace='namespace-59', bootstrapServer='my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-1140969416-265154834', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1856611658', consumerInstanceId='instance440440669', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@59fd8b00}
2022-04-05 20:56:55 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9092#my-topic-1140969416-265154834 from pod my-cluster-6c7f1c60-kafka-clients-5dc44d9c-ndk8q
2022-04-05 20:56:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6c7f1c60-kafka-clients-5dc44d9c-ndk8q -n namespace-59 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1856611658 --bootstrap-server my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9092 --group-instance-id instance440440669 --max-messages 100 --topic my-topic-1140969416-265154834
2022-04-05 20:57:01 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 20:57:01 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 20:57:01 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-05 20:57:01 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-6c7f1c60-cluster-ca-cert with strimzi.io/force-renew
2022-04-05 20:57:01 [main] [32mINFO [m [SecurityST:291] Wait for zk to rolling restart ...
2022-04-05 20:57:01 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-6c7f1c60-zookeeper rolling update
2022-04-05 20:58:41 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-6c7f1c60-zookeeper has been successfully rolled
2022-04-05 20:58:41 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-6c7f1c60-zookeeper to be ready
2022-04-05 20:59:10 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-05 20:59:10 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-6c7f1c60-kafka rolling update
2022-04-05 21:00:15 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-6c7f1c60-kafka has been successfully rolled
2022-04-05 21:00:15 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-6c7f1c60-kafka to be ready
2022-04-05 21:00:51 [main] [32mINFO [m [SecurityST:299] Wait for EO to rolling restart ...
2022-04-05 21:00:51 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-6c7f1c60-entity-operator rolling update
2022-04-05 21:00:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6c7f1c60-entity-operator will be ready
2022-04-05 21:01:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6c7f1c60-entity-operator is ready
2022-04-05 21:01:44 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-6c7f1c60-entity-operator rolling update finished
2022-04-05 21:01:44 [main] [32mINFO [m [SecurityST:303] Wait for CC and KE to rolling restart ...
2022-04-05 21:01:44 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-6c7f1c60-kafka-exporter rolling update
2022-04-05 21:02:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6c7f1c60-kafka-exporter will be ready
2022-04-05 21:02:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6c7f1c60-kafka-exporter is ready
2022-04-05 21:02:59 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-6c7f1c60-kafka-exporter rolling update finished
2022-04-05 21:02:59 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-6c7f1c60-cruise-control rolling update
2022-04-05 21:02:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6c7f1c60-cruise-control will be ready
2022-04-05 21:02:59 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6c7f1c60-cruise-control is ready
2022-04-05 21:03:09 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-6c7f1c60-cruise-control rolling update finished
2022-04-05 21:03:09 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-05 21:03:09 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-6c7f1c60-kafka-clients-5dc44d9c-ndk8q
2022-04-05 21:03:09 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@50947d05, messages=[], arguments=[--group-id, my-consumer-group-1276262337, --bootstrap-server, my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9092, --group-instance-id, instance1375042022, --max-messages, 100, --topic, my-topic-1140969416-265154834], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-6c7f1c60-kafka-clients-5dc44d9c-ndk8q', podNamespace='namespace-59', bootstrapServer='my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9092', topicName='my-topic-1140969416-265154834', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1276262337', consumerInstanceId='instance1375042022', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@35c3cb4e}
2022-04-05 21:03:09 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9092#my-topic-1140969416-265154834 from pod my-cluster-6c7f1c60-kafka-clients-5dc44d9c-ndk8q
2022-04-05 21:03:09 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6c7f1c60-kafka-clients-5dc44d9c-ndk8q -n namespace-59 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1276262337 --bootstrap-server my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9092 --group-instance-id instance1375042022 --max-messages 100 --topic my-topic-1140969416-265154834
2022-04-05 21:03:15 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 21:03:15 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 21:03:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-6c7f1c60 in namespace namespace-59
2022-04-05 21:03:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-05 21:03:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-6c7f1c60 will have desired state: Ready
2022-04-05 21:03:16 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-6c7f1c60 is in desired state: Ready
2022-04-05 21:03:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6c7f1c60-kafka-clients-tls in namespace namespace-59
2022-04-05 21:03:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-59
2022-04-05 21:03:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6c7f1c60-kafka-clients-tls will be ready
2022-04-05 21:03:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6c7f1c60-kafka-clients-tls is ready
2022-04-05 21:03:18 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-6c7f1c60-kafka-clients-tls-685bb4b848-fmw7r
2022-04-05 21:03:18 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5ab4ada3, messages=[], arguments=[USER=bob_my_cluster_6c7f1c60, --group-id, my-consumer-group-1325670677, --bootstrap-server, my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9093, --group-instance-id, instance668068, --max-messages, 100, --topic, my-topic-1140969416-265154834], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-6c7f1c60-kafka-clients-tls-685bb4b848-fmw7r', podNamespace='namespace-59', bootstrapServer='my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9093', topicName='my-topic-1140969416-265154834', maxMessages=100, kafkaUsername='bob-my-cluster-6c7f1c60', consumerGroupName='my-consumer-group-1325670677', consumerInstanceId='instance668068', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@71868166}
2022-04-05 21:03:18 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9093#my-topic-1140969416-265154834 from pod my-cluster-6c7f1c60-kafka-clients-tls-685bb4b848-fmw7r
2022-04-05 21:03:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-6c7f1c60-kafka-clients-tls-685bb4b848-fmw7r -n namespace-59 -- /opt/kafka/consumer.sh USER=bob_my_cluster_6c7f1c60 --group-id my-consumer-group-1325670677 --bootstrap-server my-cluster-6c7f1c60-kafka-bootstrap.namespace-59.svc:9093 --group-instance-id instance668068 --max-messages 100 --topic my-topic-1140969416-265154834
2022-04-05 21:03:25 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 21:03:25 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 21:03:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 21:03:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-05 21:03:25 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6c7f1c60-kafka-clients in namespace namespace-59
2022-04-05 21:03:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-5730953-1997858025 in namespace namespace-59
2022-04-05 21:03:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6c7f1c60-kafka-clients-tls in namespace namespace-59
2022-04-05 21:03:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6c7f1c60 in namespace namespace-59
2022-04-05 21:03:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-59, for cruise control Kafka cluster my-cluster-6c7f1c60
2022-04-05 21:03:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1140969416-265154834 in namespace namespace-59
2022-04-05 21:03:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-6c7f1c60 in namespace namespace-59
2022-04-05 21:04:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 21:04:25 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-59 for test case:testAutoRenewClusterCaCertsTriggeredByAnno
2022-04-05 21:04:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClusterCaCertsTriggeredByAnno-FINISHED
2022-04-05 21:04:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 21:04:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 21:04:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-STARTED
2022-04-05 21:04:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 21:04:32 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-60 for test case:testCaRenewalBreakInMiddle
2022-04-05 21:04:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-60
2022-04-05 21:04:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-60
2022-04-05 21:04:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-60
2022-04-05 21:04:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b3e3261f in namespace namespace-60
2022-04-05 21:04:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-05 21:04:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b3e3261f will have desired state: Ready
2022-04-05 21:05:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b3e3261f is in desired state: Ready
2022-04-05 21:05:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1911957996-1603951348 in namespace namespace-60
2022-04-05 21:05:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-05 21:05:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1911957996-1603951348 will have desired state: Ready
2022-04-05 21:05:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1911957996-1603951348 is in desired state: Ready
2022-04-05 21:05:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-712879578-529818178 in namespace namespace-60
2022-04-05 21:05:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-05 21:05:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-712879578-529818178 will have desired state: Ready
2022-04-05 21:05:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-712879578-529818178 is in desired state: Ready
2022-04-05 21:05:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b3e3261f-kafka-clients in namespace namespace-60
2022-04-05 21:05:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-05 21:05:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b3e3261f-kafka-clients will be ready
2022-04-05 21:05:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b3e3261f-kafka-clients is ready
2022-04-05 21:05:50 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 21:05:50 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7063a78f, messages=[], arguments=[USER=my_user_1911957996_1603951348, --bootstrap-server, my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093, --max-messages, 100, --topic, my-topic-712879578-529818178], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk', podNamespace='namespace-60', bootstrapServer='my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-712879578-529818178', maxMessages=100, kafkaUsername='my-user-1911957996-1603951348', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2eff4482}
2022-04-05 21:05:50 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093:my-topic-712879578-529818178 from pod my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk
2022-04-05 21:05:50 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk -n namespace-60 -- /opt/kafka/producer.sh USER=my_user_1911957996_1603951348 --bootstrap-server my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093 --max-messages 100 --topic my-topic-712879578-529818178
2022-04-05 21:05:54 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 21:05:54 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 21:05:54 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@45732bf2, messages=[], arguments=[USER=my_user_1911957996_1603951348, --group-id, my-consumer-group-1826040922, --bootstrap-server, my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093, --group-instance-id, instance929221656, --max-messages, 100, --topic, my-topic-712879578-529818178], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk', podNamespace='namespace-60', bootstrapServer='my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-712879578-529818178', maxMessages=100, kafkaUsername='my-user-1911957996-1603951348', consumerGroupName='my-consumer-group-1826040922', consumerInstanceId='instance929221656', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@11fca61b}
2022-04-05 21:05:54 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093:my-topic-712879578-529818178 from pod my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk
2022-04-05 21:05:54 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk -n namespace-60 -- /opt/kafka/consumer.sh USER=my_user_1911957996_1603951348 --group-id my-consumer-group-1826040922 --bootstrap-server my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093 --group-instance-id instance929221656 --max-messages 100 --topic my-topic-712879578-529818178
2022-04-05 21:06:01 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 21:06:01 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 21:06:01 [main] [32mINFO [m [SecretUtils:70] Creating secret my-cluster-b3e3261f-cluster-ca-cert
2022-04-05 21:06:01 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b3e3261f-zookeeper are in desired state
2022-04-05 21:06:02 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b3e3261f-zookeeper are in desired state
2022-04-05 21:06:03 [main] [32mINFO [m [SecurityST:1218] No pods of my-cluster-b3e3261f-zookeeper are in desired state
2022-04-05 21:06:04 [main] [32mINFO [m [SecurityST:1221] Pod in 'Pending' state: my-cluster-b3e3261f-zookeeper-1
2022-04-05 21:06:04 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@721d0e26, messages=[], arguments=[USER=my_user_1911957996_1603951348, --group-id, my-consumer-group-1970198733, --bootstrap-server, my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093, --group-instance-id, instance781188535, --max-messages, 100, --topic, my-topic-712879578-529818178], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk', podNamespace='namespace-60', bootstrapServer='my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-712879578-529818178', maxMessages=100, kafkaUsername='my-user-1911957996-1603951348', consumerGroupName='my-consumer-group-1970198733', consumerInstanceId='instance781188535', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@16d09366}
2022-04-05 21:06:04 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093:my-topic-712879578-529818178 from pod my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk
2022-04-05 21:06:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk -n namespace-60 -- /opt/kafka/consumer.sh USER=my_user_1911957996_1603951348 --group-id my-consumer-group-1970198733 --bootstrap-server my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093 --group-instance-id instance781188535 --max-messages 100 --topic my-topic-712879578-529818178
2022-04-05 21:06:11 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 21:06:11 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 21:06:11 [main] [32mINFO [m [SecretUtils:131] Waiting for Secret my-cluster-b3e3261f-cluster-ca-cert certificate change
2022-04-05 21:06:11 [main] [32mINFO [m [SecretUtils:138] Certificate in Secret my-cluster-b3e3261f-cluster-ca-cert has changed, was -----BEGIN CERTIFICATE-----
MIIDKjCCAhKgAwIBAgIJAJBt0u1FFTG+MA0GCSqGSIb3DQEBCwUAMCoxEzARBgNV
BAoMCnN0cmltemkuaW8xEzARBgNVBAMMCmNsdXN0ZXItY2EwHhcNMTgxMDIzMTAw
MTExWhcNMTgxMDI0MTAwMTExWjAqMRMwEQYDVQQKDApzdHJpbXppLmlvMRMwEQYD
VQQDDApjbHVzdGVyLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA
xpuYrNXYHqw3ajwd12aAeuTlAX4rVwVdPuIex6A4NL8J3d2DV+ngXgNTH//RhiF5
If5KRWSsLei5BUIrwuQutOUNCQwyACmri9+yrx6+tevligiokAUwhHxcDHZpwC3T
+2dzk/BkI++vbSuvjFmBKGQi9gfyoTnStTEQ85KVJUS170hzwDjzaEiJsKpOPx/G
+KTdkAopLucoxr4sxhYeO4mQ2PkT0QL+R8Ohs6LD6v/bqalFP+rS8vibolfxjMNm
lXQCOd8UfXy8OEOaNoNCvhnn/cT/hbEG/ARbV3hHmUh9COV+TSV5dhsbmS5h4MKw
LzP449nGQBmLSkZMu984DQIDAQABo1MwUTAdBgNVHQ4EFgQUOXubcHBZJ7vSzjpi
pfXdFSP3dsEwHwYDVR0jBBgwFoAUOXubcHBZJ7vSzjpipfXdFSP3dsEwDwYDVR0T
AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFFPGykbzUREDMzh+33i3a8TF
UTQnPMN/SuVbpLfQdpkpLO+aVWjVvJP6qMrI7jRO5zhj4MecAf7YKpe+dyRTTz9B
Dy9BZcujHYjCKdcKBnBFQ7B1xQm9tL1bw+a3ABzSTlhLiBcCxhJEawlWy1Gh18ab
3x/Kqnz0mk/jt5+n9HwlKHuBQVIxRCsfHWwq+WvIfoxM+N//akV8/29hLUf5TlYH
F5CX4G2pA5sSdaDHQ4ekQWuqM6tfvsGLl2KOmEFEgVR4GfaWI4BsUCzlpBNcCGWv
V7klZvBxQPG7MVy0cB8yzTDtUpR0jUFUkZOSp5Pr3yWcwPWEgWkaXYfO+FWETA==
-----END CERTIFICATE-----
, is now -----BEGIN CERTIFICATE-----
MIIFLDCCAxSgAwIBAgITbP2PQqwThIPrtI0xGSyEdXE6nTANBgkqhkiG9w0BAQ0F
ADAtMRMwEQYDVQQKDAppby5zdHJpbXppMRYwFAYDVQQDDA1jbHVzdGVyLWNhIHYw
MB4XDTIyMDQwNTIxMDYwMVoXDTIyMDQxMjIxMDYwMVowLTETMBEGA1UECgwKaW8u
c3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2MDCCAiIwDQYJKoZIhvcNAQEB
BQADggIPADCCAgoCggIBAO733JQFXHbe5SMHr0jor7n4SJYIYN5+3nJI8qiBajxN
9LUXOfVQgKwiqE+j60CQrCYOlyRpejrtwsaYxjnq8vJMRQhQ36Ul/2NOpAUMHL8Q
2yALZ+W82O+HQY6icS20Jh58a27BnW06htODZGtQIDFqtVW6HHWflUceYvNO/qcZ
BDqiEFs6YxvmvnvU/xMNqLiy57DQ4Arvbf/jZWkIqbrRxYXGR60Z9JgcPWkhZZqf
xDgrRkpjjOzkYt0umU13gi7qr7Q7InJhFJComBONEEh7TgFofPTZrDXAq2O1pdpl
LWk33+oUTxlf2zBZg9GWZCu4so7lyzKXnre4MMnTk7n5ogYI/piTFivboB2IswTr
zk9/11Ox7/z6AfkyOG9qwjcO6obhs45wTuunZl9yG95kAsu6riNwK3VpptVdxC1U
5mYUq5EluXR7OUljHGaiJLsY9ozC+drSIhUZx7wzBrOTIJnSSm3JJTgLfFjbr5ri
3SGyZGfuxeVHgIri7/FmXuBfGoiC5OGzI2mPrEsWw9FbHbuiBI90JoIXj7SCxvay
dV/zNUdji4EV1VOrgaktxzf8hRY3YjPyEy65dwz+b39GdJUhjc5XE6rbkdwKexOj
gprEGVtqzIgJ8Dzu2fCcFVOjz2k3IWGpdKu3y6Bh5M6ip3EOx5/BDSRFuCecCJwn
AgMBAAGjRTBDMB0GA1UdDgQWBBQsWHjjruufH9+nLwbb+vLPGZmJQTASBgNVHRMB
Af8ECDAGAQH/AgEAMA4GA1UdDwEB/wQEAwIBBjANBgkqhkiG9w0BAQ0FAAOCAgEA
jDCqzqeu/7TkqWbPQ9iPg74Y5JoUjD/5dkXvh0l1ThOWgVyRI2lnk2mxW5tfHxrJ
+k5U4blNZkxm1eDcGbavy6eNeQxlpw9kaDKfbfB+7PkiVFsVgaiDn1KMdOfxvB9J
+ukq2a38TYpZHEtndeo9kzmuNIa6poHZDr0iKO47tSTbE0BIl2Dy8pLL8e6nggvb
D739J7I5OzeLkrDAHEqfi1exeAXVliw06Sk3uJHELuCsIWgAvHUi39uz6SGGEXes
kGwed++Mkkx0wKLKeL6jNhUZmQnx8yu7BvxJ4ejUh53kaVsHhz9pg2dzeUqr2Fqs
qI/eiqhIAAdIThyLL5kHuJmCJx4W1pp2fhzpPH6f4aF2BfXJv+1NDGdpMH1tZ3K/
hfiYRp2v6iTA/QASi9kRDkdrqTr8aL9HGeSM/uPevRiqFT9QRulSBBEiniMjkIRx
EnJHenfs/b0D+mHOPfJQbE76bb5uyj2Zuo9JzcMwYJmXARomqjTylCvHseTF5Kpc
GPGfKngwHWlU8klJ1FoxU4eNtpCPBIGMJkV8NHTcQ6FxVnePLln83fvDdVUm6RLZ
J6PF/yGcXsWZDF7QKLf6IcA0DcLN1irfvCBj9R1qLFL8wThtIo914K/tEQjlsuWC
/BIs0mTN7dpwhah8nDROxWNeZrWzM1IDs296709AD7I=
-----END CERTIFICATE-----

2022-04-05 21:06:11 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-b3e3261f-zookeeper rolling update
2022-04-05 21:11:57 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-b3e3261f-zookeeper has been successfully rolled
2022-04-05 21:11:57 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-b3e3261f-zookeeper to be ready
2022-04-05 21:12:28 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-b3e3261f-kafka rolling update
2022-04-05 21:13:28 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-b3e3261f-kafka has been successfully rolled
2022-04-05 21:13:28 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-b3e3261f-kafka to be ready
2022-04-05 21:13:56 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-b3e3261f-entity-operator rolling update
2022-04-05 21:13:56 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b3e3261f-entity-operator will be ready
2022-04-05 21:19:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b3e3261f-entity-operator is ready
2022-04-05 21:19:36 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-b3e3261f-entity-operator rolling update finished
2022-04-05 21:19:36 [main] [32mINFO [m [SecurityST:1252] Checking produced and consumed messages to pod:my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk
2022-04-05 21:19:36 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2b5ec345, messages=[], arguments=[USER=my_user_1911957996_1603951348, --group-id, my-consumer-group-316397069, --bootstrap-server, my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093, --group-instance-id, instance716443720, --max-messages, 100, --topic, my-topic-712879578-529818178], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk', podNamespace='namespace-60', bootstrapServer='my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-712879578-529818178', maxMessages=100, kafkaUsername='my-user-1911957996-1603951348', consumerGroupName='my-consumer-group-316397069', consumerInstanceId='instance716443720', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6409c316}
2022-04-05 21:19:36 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093:my-topic-712879578-529818178 from pod my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk
2022-04-05 21:19:36 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk -n namespace-60 -- /opt/kafka/consumer.sh USER=my_user_1911957996_1603951348 --group-id my-consumer-group-316397069 --bootstrap-server my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093 --group-instance-id instance716443720 --max-messages 100 --topic my-topic-712879578-529818178
2022-04-05 21:19:43 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 21:19:43 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 21:19:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1748716671-1423614568 in namespace namespace-60
2022-04-05 21:19:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-60
2022-04-05 21:19:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1748716671-1423614568 will have desired state: Ready
2022-04-05 21:19:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1748716671-1423614568 is in desired state: Ready
2022-04-05 21:19:44 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3dddf624, messages=[], arguments=[USER=my_user_1911957996_1603951348, --bootstrap-server, my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093, --max-messages, 100, --topic, my-topic-1748716671-1423614568], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk', podNamespace='namespace-60', bootstrapServer='my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-1748716671-1423614568', maxMessages=100, kafkaUsername='my-user-1911957996-1603951348', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@17e686bd}
2022-04-05 21:19:44 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093:my-topic-1748716671-1423614568 from pod my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk
2022-04-05 21:19:44 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk -n namespace-60 -- /opt/kafka/producer.sh USER=my_user_1911957996_1603951348 --bootstrap-server my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093 --max-messages 100 --topic my-topic-1748716671-1423614568
2022-04-05 21:19:48 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 21:19:48 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 21:19:48 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5281d36, messages=[], arguments=[USER=my_user_1911957996_1603951348, --group-id, my-consumer-group-1334002718, --bootstrap-server, my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093, --group-instance-id, instance667190047, --max-messages, 100, --topic, my-topic-1748716671-1423614568], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk', podNamespace='namespace-60', bootstrapServer='my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093', topicName='my-topic-1748716671-1423614568', maxMessages=100, kafkaUsername='my-user-1911957996-1603951348', consumerGroupName='my-consumer-group-1334002718', consumerInstanceId='instance667190047', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@60c44e31}
2022-04-05 21:19:48 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093:my-topic-1748716671-1423614568 from pod my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk
2022-04-05 21:19:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b3e3261f-kafka-clients-5d6f998987-v5kvk -n namespace-60 -- /opt/kafka/consumer.sh USER=my_user_1911957996_1603951348 --group-id my-consumer-group-1334002718 --bootstrap-server my-cluster-b3e3261f-kafka-bootstrap.namespace-60.svc:9093 --group-instance-id instance667190047 --max-messages 100 --topic my-topic-1748716671-1423614568
2022-04-05 21:19:55 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 21:19:55 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 21:19:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 21:19:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCaRenewalBreakInMiddle
2022-04-05 21:19:55 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-712879578-529818178 in namespace namespace-60
2022-04-05 21:19:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1911957996-1603951348 in namespace namespace-60
2022-04-05 21:19:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1748716671-1423614568 in namespace namespace-60
2022-04-05 21:19:55 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b3e3261f in namespace namespace-60
2022-04-05 21:20:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b3e3261f-kafka-clients in namespace namespace-60
2022-04-05 21:20:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 21:20:45 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-60 for test case:testCaRenewalBreakInMiddle
2022-04-05 21:20:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCaRenewalBreakInMiddle-FINISHED
2022-04-05 21:20:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 21:20:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 21:20:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-STARTED
2022-04-05 21:20:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 21:20:52 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-61 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-04-05 21:20:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-61
2022-04-05 21:20:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-61
2022-04-05 21:20:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-61
2022-04-05 21:20:52 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 21:20:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4c1e4cdd in namespace namespace-61
2022-04-05 21:20:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-05 21:20:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4c1e4cdd will have desired state: Ready
2022-04-05 21:23:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4c1e4cdd is in desired state: Ready
2022-04-05 21:23:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-40394807-474061149 in namespace namespace-61
2022-04-05 21:23:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-05 21:23:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-40394807-474061149 will have desired state: Ready
2022-04-05 21:23:16 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-40394807-474061149 is in desired state: Ready
2022-04-05 21:23:16 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-755492593-152319597 in namespace namespace-61
2022-04-05 21:23:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-05 21:23:16 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-755492593-152319597 will have desired state: Ready
2022-04-05 21:23:17 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-755492593-152319597 is in desired state: Ready
2022-04-05 21:23:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4c1e4cdd-kafka-clients in namespace namespace-61
2022-04-05 21:23:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-05 21:23:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4c1e4cdd-kafka-clients will be ready
2022-04-05 21:23:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4c1e4cdd-kafka-clients is ready
2022-04-05 21:23:19 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 21:23:19 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-4c1e4cdd-kafka-clients-7bdb6cbb4b-m4n4n
2022-04-05 21:23:19 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@36116302, messages=[], arguments=[--bootstrap-server, my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9092, --max-messages, 100, --topic, my-topic-755492593-152319597], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4c1e4cdd-kafka-clients-7bdb6cbb4b-m4n4n', podNamespace='namespace-61', bootstrapServer='my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-755492593-152319597', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@74660e79}
2022-04-05 21:23:19 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9092:my-topic-755492593-152319597 from pod my-cluster-4c1e4cdd-kafka-clients-7bdb6cbb4b-m4n4n
2022-04-05 21:23:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4c1e4cdd-kafka-clients-7bdb6cbb4b-m4n4n -n namespace-61 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9092 --max-messages 100 --topic my-topic-755492593-152319597
2022-04-05 21:23:21 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 21:23:21 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 21:23:21 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@547d2c63, messages=[], arguments=[--group-id, my-consumer-group-1331457182, --bootstrap-server, my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9092, --group-instance-id, instance1437539376, --max-messages, 100, --topic, my-topic-755492593-152319597], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4c1e4cdd-kafka-clients-7bdb6cbb4b-m4n4n', podNamespace='namespace-61', bootstrapServer='my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-755492593-152319597', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1331457182', consumerInstanceId='instance1437539376', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@10acfdc9}
2022-04-05 21:23:21 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9092#my-topic-755492593-152319597 from pod my-cluster-4c1e4cdd-kafka-clients-7bdb6cbb4b-m4n4n
2022-04-05 21:23:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4c1e4cdd-kafka-clients-7bdb6cbb4b-m4n4n -n namespace-61 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1331457182 --bootstrap-server my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9092 --group-instance-id instance1437539376 --max-messages 100 --topic my-topic-755492593-152319597
2022-04-05 21:23:27 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 21:23:27 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 21:23:27 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-05 21:23:27 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-4c1e4cdd-cluster-ca-cert with strimzi.io/force-renew
2022-04-05 21:23:27 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-4c1e4cdd-clients-ca-cert with strimzi.io/force-renew
2022-04-05 21:23:27 [main] [32mINFO [m [SecurityST:291] Wait for zk to rolling restart ...
2022-04-05 21:23:27 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4c1e4cdd-zookeeper rolling update
2022-04-05 21:24:37 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4c1e4cdd-zookeeper has been successfully rolled
2022-04-05 21:24:37 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-4c1e4cdd-zookeeper to be ready
2022-04-05 21:25:12 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-05 21:25:12 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4c1e4cdd-kafka rolling update
2022-04-05 21:26:17 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4c1e4cdd-kafka has been successfully rolled
2022-04-05 21:26:17 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-4c1e4cdd-kafka to be ready
2022-04-05 21:26:45 [main] [32mINFO [m [SecurityST:299] Wait for EO to rolling restart ...
2022-04-05 21:26:45 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-4c1e4cdd-entity-operator rolling update
2022-04-05 21:26:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4c1e4cdd-entity-operator will be ready
2022-04-05 21:30:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4c1e4cdd-entity-operator is ready
2022-04-05 21:30:21 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-4c1e4cdd-entity-operator rolling update finished
2022-04-05 21:30:21 [main] [32mINFO [m [SecurityST:303] Wait for CC and KE to rolling restart ...
2022-04-05 21:30:21 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-4c1e4cdd-kafka-exporter rolling update
2022-04-05 21:31:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4c1e4cdd-kafka-exporter will be ready
2022-04-05 21:31:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4c1e4cdd-kafka-exporter is ready
2022-04-05 21:31:37 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-4c1e4cdd-kafka-exporter rolling update finished
2022-04-05 21:31:37 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-4c1e4cdd-cruise-control rolling update
2022-04-05 21:31:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4c1e4cdd-cruise-control will be ready
2022-04-05 21:31:37 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4c1e4cdd-cruise-control is ready
2022-04-05 21:31:47 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-4c1e4cdd-cruise-control rolling update finished
2022-04-05 21:31:47 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-05 21:31:47 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-4c1e4cdd-kafka-clients-7bdb6cbb4b-m4n4n
2022-04-05 21:31:47 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@60233512, messages=[], arguments=[--group-id, my-consumer-group-2009230159, --bootstrap-server, my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9092, --group-instance-id, instance2105721248, --max-messages, 100, --topic, my-topic-755492593-152319597], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4c1e4cdd-kafka-clients-7bdb6cbb4b-m4n4n', podNamespace='namespace-61', bootstrapServer='my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9092', topicName='my-topic-755492593-152319597', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2009230159', consumerInstanceId='instance2105721248', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@73a9b395}
2022-04-05 21:31:47 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9092#my-topic-755492593-152319597 from pod my-cluster-4c1e4cdd-kafka-clients-7bdb6cbb4b-m4n4n
2022-04-05 21:31:47 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4c1e4cdd-kafka-clients-7bdb6cbb4b-m4n4n -n namespace-61 -- /opt/kafka/consumer.sh --group-id my-consumer-group-2009230159 --bootstrap-server my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9092 --group-instance-id instance2105721248 --max-messages 100 --topic my-topic-755492593-152319597
2022-04-05 21:31:53 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 21:31:53 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 21:31:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-4c1e4cdd in namespace namespace-61
2022-04-05 21:31:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-05 21:31:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-4c1e4cdd will have desired state: Ready
2022-04-05 21:31:54 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-4c1e4cdd is in desired state: Ready
2022-04-05 21:31:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4c1e4cdd-kafka-clients-tls in namespace namespace-61
2022-04-05 21:31:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-61
2022-04-05 21:31:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4c1e4cdd-kafka-clients-tls will be ready
2022-04-05 21:31:56 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4c1e4cdd-kafka-clients-tls is ready
2022-04-05 21:31:56 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-4c1e4cdd-kafka-clients-tls-c967d8977-2fm2j
2022-04-05 21:31:56 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6539b524, messages=[], arguments=[USER=bob_my_cluster_4c1e4cdd, --group-id, my-consumer-group-1742426324, --bootstrap-server, my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9093, --group-instance-id, instance1942628380, --max-messages, 100, --topic, my-topic-755492593-152319597], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4c1e4cdd-kafka-clients-tls-c967d8977-2fm2j', podNamespace='namespace-61', bootstrapServer='my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9093', topicName='my-topic-755492593-152319597', maxMessages=100, kafkaUsername='bob-my-cluster-4c1e4cdd', consumerGroupName='my-consumer-group-1742426324', consumerInstanceId='instance1942628380', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5bb280dc}
2022-04-05 21:31:56 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9093#my-topic-755492593-152319597 from pod my-cluster-4c1e4cdd-kafka-clients-tls-c967d8977-2fm2j
2022-04-05 21:31:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4c1e4cdd-kafka-clients-tls-c967d8977-2fm2j -n namespace-61 -- /opt/kafka/consumer.sh USER=bob_my_cluster_4c1e4cdd --group-id my-consumer-group-1742426324 --bootstrap-server my-cluster-4c1e4cdd-kafka-bootstrap.namespace-61.svc:9093 --group-instance-id instance1942628380 --max-messages 100 --topic my-topic-755492593-152319597
2022-04-05 21:32:03 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 21:32:03 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 21:32:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 21:32:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewAllCaCertsTriggeredByAnno
2022-04-05 21:32:03 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4c1e4cdd-kafka-clients in namespace namespace-61
2022-04-05 21:32:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4c1e4cdd-kafka-clients-tls in namespace namespace-61
2022-04-05 21:32:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-40394807-474061149 in namespace namespace-61
2022-04-05 21:32:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-4c1e4cdd in namespace namespace-61
2022-04-05 21:32:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4c1e4cdd in namespace namespace-61
2022-04-05 21:32:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-61, for cruise control Kafka cluster my-cluster-4c1e4cdd
2022-04-05 21:32:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-755492593-152319597 in namespace namespace-61
2022-04-05 21:32:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 21:32:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-61 for test case:testAutoRenewAllCaCertsTriggeredByAnno
2022-04-05 21:33:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewAllCaCertsTriggeredByAnno-FINISHED
2022-04-05 21:33:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 21:33:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 21:33:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-STARTED
2022-04-05 21:33:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 21:33:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-62 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-04-05 21:33:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-62
2022-04-05 21:33:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-62
2022-04-05 21:33:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-62
2022-04-05 21:33:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-49d648a1 in namespace namespace-62
2022-04-05 21:33:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-05 21:33:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-49d648a1 will have desired state: Ready
2022-04-05 21:34:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-49d648a1 is in desired state: Ready
2022-04-05 21:34:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-820511063-771661353 in namespace namespace-62
2022-04-05 21:34:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-05 21:34:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-820511063-771661353 will have desired state: Ready
2022-04-05 21:34:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-820511063-771661353 is in desired state: Ready
2022-04-05 21:34:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-400072683-1213166638 in namespace namespace-62
2022-04-05 21:34:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-05 21:34:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-400072683-1213166638 will have desired state: Ready
2022-04-05 21:34:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-400072683-1213166638 is in desired state: Ready
2022-04-05 21:34:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-49d648a1-kafka-clients in namespace namespace-62
2022-04-05 21:34:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-62
2022-04-05 21:34:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-49d648a1-kafka-clients will be ready
2022-04-05 21:34:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-49d648a1-kafka-clients is ready
2022-04-05 21:34:16 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 21:34:16 [main] [32mINFO [m [SecurityST:797] Verifying that secret Secret(apiVersion=v1, data={ca.crt=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, ca.p12=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, ca.password=YXB5aHlEcEhhdHJ0}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-04-05T21:33:01Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-49d648a1, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-49d648a1, strimzi.io/cluster=my-cluster-49d648a1, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[], name=my-cluster-49d648a1-clients-ca-cert, namespace=namespace-62, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-49d648a1, uid=f7d370e1-7d25-4314-ae43-b3bd95fd7874, additionalProperties={})], resourceVersion=746274, selfLink=/api/v1/namespaces/namespace-62/secrets/my-cluster-49d648a1-clients-ca-cert, uid=910243f5-6544-4420-af45-47f0818e5b28, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-49d648a1-clients-ca-cert is present
2022-04-05 21:34:16 [main] [32mINFO [m [SecurityST:797] Verifying that secret Secret(apiVersion=v1, data={ca.crt=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, ca.p12=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, ca.password=Z0FnUDUzY0NEWXN6}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations={strimzi.io/ca-cert-generation=0}, clusterName=null, creationTimestamp=2022-04-05T21:33:01Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-cluster-49d648a1, app.kubernetes.io/managed-by=strimzi-cluster-operator, app.kubernetes.io/name=strimzi, app.kubernetes.io/part-of=strimzi-my-cluster-49d648a1, strimzi.io/cluster=my-cluster-49d648a1, strimzi.io/kind=Kafka, strimzi.io/name=strimzi, test.case=testCertRegeneratedAfterInternalCAisDeleted}, managedFields=[], name=my-cluster-49d648a1-cluster-ca-cert, namespace=namespace-62, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=Kafka, name=my-cluster-49d648a1, uid=f7d370e1-7d25-4314-ae43-b3bd95fd7874, additionalProperties={})], resourceVersion=746273, selfLink=/api/v1/namespaces/namespace-62/secrets/my-cluster-49d648a1-cluster-ca-cert, uid=1e2fccb0-aa78-46c7-9ec4-ab45b4ed9dba, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) with name my-cluster-49d648a1-cluster-ca-cert is present
2022-04-05 21:34:16 [main] [32mINFO [m [SecurityST:802] Deleting secret my-cluster-49d648a1-clients-ca-cert
2022-04-05 21:34:16 [main] [32mINFO [m [SecurityST:802] Deleting secret my-cluster-49d648a1-cluster-ca-cert
2022-04-05 21:34:16 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-49d648a1-kafka are stable
2022-04-05 21:34:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:34:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:34:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:34:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:34:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:34:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:34:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:34:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:34:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:34:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:34:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:34:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:34:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:34:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:34:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:34:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:34:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:34:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:34:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:34:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:34:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:34:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:34:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:34:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:34:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:34:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:34:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:34:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:34:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:34:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:34:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:34:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:34:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:34:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:34:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:34:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:34:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:34:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:34:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:34:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:34:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:34:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:34:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:34:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:34:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:34:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:34:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:34:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:34:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:34:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:34:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:34:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:34:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:34:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:34:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:34:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:34:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:34:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:34:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:34:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:34:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:34:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:34:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:34:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:34:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:34:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:34:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:34:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:34:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:34:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:34:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:34:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:34:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:34:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:34:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:34:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:34:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:34:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:34:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:34:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:34:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:34:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:34:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:34:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:34:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:34:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:34:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:34:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:34:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:34:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:34:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:34:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:34:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:34:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:34:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:34:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:34:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:34:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:34:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:34:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:34:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:34:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:34:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:34:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:34:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:34:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:34:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:34:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:34:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:34:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:34:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:34:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:34:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:34:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:34:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:34:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:34:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:34:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:34:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:34:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:34:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 21:34:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 21:34:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 21:34:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 21:34:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 21:34:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 21:34:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 21:34:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 21:34:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 21:34:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 21:34:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 21:34:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 21:34:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 21:34:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 21:34:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 21:34:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 21:34:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 21:34:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 21:34:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 21:34:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 21:34:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 21:34:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 21:34:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 21:34:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 21:34:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 21:34:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 21:34:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 21:34:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 21:34:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 21:34:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 21:34:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 21:34:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 21:34:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 21:34:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 21:34:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 21:34:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 21:34:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 21:34:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 21:34:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 21:34:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 21:34:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 21:34:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 21:34:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 21:34:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 21:34:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 21:34:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 21:34:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 21:34:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 21:34:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 21:34:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 21:34:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 21:34:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 21:35:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 21:35:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 21:35:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 21:35:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 21:35:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 21:35:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 21:35:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 21:35:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 21:35:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 21:35:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 21:35:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 21:35:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 21:35:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 21:35:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 21:35:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 21:35:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 21:35:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 21:35:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 21:35:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 21:35:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 21:35:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 21:35:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 21:35:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 21:35:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 21:35:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 21:35:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 21:35:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 21:35:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 21:35:06 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-49d648a1-kafka-0 ,my-cluster-49d648a1-kafka-1 ,my-cluster-49d648a1-kafka-2 ,my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn
2022-04-05 21:35:06 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-49d648a1-kafka rolling update
2022-04-05 21:36:06 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-49d648a1-kafka has been successfully rolled
2022-04-05 21:36:06 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-49d648a1-kafka to be ready
2022-04-05 21:36:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-49d648a1 will have desired state: Ready
2022-04-05 21:36:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-49d648a1 is in desired state: Ready
2022-04-05 21:36:39 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-49d648a1 is ready
2022-04-05 21:36:39 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-49d648a1-clients-ca-cert
2022-04-05 21:36:39 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-49d648a1-clients-ca-cert created
2022-04-05 21:36:39 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-cluster-49d648a1-cluster-ca-cert
2022-04-05 21:36:39 [main] [32mINFO [m [SecretUtils:50] Secret my-cluster-49d648a1-cluster-ca-cert created
2022-04-05 21:36:39 [main] [32mINFO [m [SecurityST:821] Checking consumed messages to pod:my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn
2022-04-05 21:36:39 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4199f299, messages=[], arguments=[USER=my_user_820511063_771661353, --bootstrap-server, my-cluster-49d648a1-kafka-bootstrap.namespace-62.svc:9093, --max-messages, 100, --topic, my-topic-400072683-1213166638], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn', podNamespace='namespace-62', bootstrapServer='my-cluster-49d648a1-kafka-bootstrap.namespace-62.svc:9093', topicName='my-topic-400072683-1213166638', maxMessages=100, kafkaUsername='my-user-820511063-771661353', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@d0a55f5}
2022-04-05 21:36:39 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-49d648a1-kafka-bootstrap.namespace-62.svc:9093:my-topic-400072683-1213166638 from pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn
2022-04-05 21:36:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn -n namespace-62 -- /opt/kafka/producer.sh USER=my_user_820511063_771661353 --bootstrap-server my-cluster-49d648a1-kafka-bootstrap.namespace-62.svc:9093 --max-messages 100 --topic my-topic-400072683-1213166638
2022-04-05 21:36:42 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 21:36:42 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 21:36:42 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@61ed3a96, messages=[], arguments=[USER=my_user_820511063_771661353, --group-id, my-consumer-group-157580487, --bootstrap-server, my-cluster-49d648a1-kafka-bootstrap.namespace-62.svc:9093, --group-instance-id, instance580592964, --max-messages, 100, --topic, my-topic-400072683-1213166638], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn', podNamespace='namespace-62', bootstrapServer='my-cluster-49d648a1-kafka-bootstrap.namespace-62.svc:9093', topicName='my-topic-400072683-1213166638', maxMessages=100, kafkaUsername='my-user-820511063-771661353', consumerGroupName='my-consumer-group-157580487', consumerInstanceId='instance580592964', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3e17755c}
2022-04-05 21:36:42 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-49d648a1-kafka-bootstrap.namespace-62.svc:9093:my-topic-400072683-1213166638 from pod my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn
2022-04-05 21:36:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-49d648a1-kafka-clients-6bf9b98c5c-lwzbn -n namespace-62 -- /opt/kafka/consumer.sh USER=my_user_820511063_771661353 --group-id my-consumer-group-157580487 --bootstrap-server my-cluster-49d648a1-kafka-bootstrap.namespace-62.svc:9093 --group-instance-id instance580592964 --max-messages 100 --topic my-topic-400072683-1213166638
2022-04-05 21:36:50 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 21:36:50 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 21:36:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 21:36:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertRegeneratedAfterInternalCAisDeleted
2022-04-05 21:36:50 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-400072683-1213166638 in namespace namespace-62
2022-04-05 21:36:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-820511063-771661353 in namespace namespace-62
2022-04-05 21:36:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-49d648a1-kafka-clients in namespace namespace-62
2022-04-05 21:36:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-49d648a1 in namespace namespace-62
2022-04-05 21:37:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 21:37:40 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-62 for test case:testCertRegeneratedAfterInternalCAisDeleted
2022-04-05 21:37:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRegeneratedAfterInternalCAisDeleted-FINISHED
2022-04-05 21:37:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 21:37:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 21:37:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-STARTED
2022-04-05 21:37:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 21:37:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-63 for test case:testKafkaAndKafkaConnectCipherSuites
2022-04-05 21:37:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-63
2022-04-05 21:37:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-63
2022-04-05 21:37:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-63
2022-04-05 21:37:45 [main] [32mINFO [m [SecurityST:1362] Deploying Kafka cluster with the support TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 cipher algorithms
2022-04-05 21:37:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2c4f9cf8 in namespace namespace-63
2022-04-05 21:37:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-05 21:37:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2c4f9cf8 will have desired state: Ready
2022-04-05 21:39:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2c4f9cf8 is in desired state: Ready
2022-04-05 21:39:04 [main] [32mINFO [m [SecurityST:1374] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-04-05 21:39:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2c4f9cf8-kafka-clients in namespace namespace-63
2022-04-05 21:39:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-05 21:39:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2c4f9cf8-kafka-clients will be ready
2022-04-05 21:39:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2c4f9cf8-kafka-clients is ready
2022-04-05 21:39:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2c4f9cf8-scraper in namespace namespace-63
2022-04-05 21:39:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-05 21:39:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2c4f9cf8-scraper will be ready
2022-04-05 21:39:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2c4f9cf8-scraper is ready
2022-04-05 21:39:08 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-2c4f9cf8-scraper to be ready
2022-04-05 21:39:18 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-2c4f9cf8-scraper is ready
2022-04-05 21:39:18 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-2c4f9cf8-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 21:39:18 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-2c4f9cf8-allow in namespace namespace-63
2022-04-05 21:39:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-05 21:39:18 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 21:39:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-2c4f9cf8 in namespace namespace-63
2022-04-05 21:39:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-63
2022-04-05 21:39:18 [main] [32mINFO [m [SecurityST:1391] Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm
2022-04-05 21:39:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-2c4f9cf8 will have desired state: NotReady
2022-04-05 21:44:19 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-2c4f9cf8 is in desired state: NotReady
2022-04-05 21:44:19 [main] [32mINFO [m [SecurityST:1395] Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.
2022-04-05 21:44:19 [main] [32mINFO [m [SecurityST:1399] Verifying that Kafka Connect has the accepted configuration:
 ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
2022-04-05 21:44:19 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-04-05 21:44:19 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.cipher.suites -> TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 change
2022-04-05 21:44:19 [main] [32mINFO [m [SecurityST:1404] Verifying that Kafka Connect is stable
2022-04-05 21:44:19 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-2c4f9cf8-connect are stable
2022-04-05 21:44:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 21:44:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 21:44:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 21:44:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 21:44:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 21:44:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 21:44:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 21:44:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 21:44:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 21:44:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 21:44:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 21:44:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 21:44:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 21:44:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 21:44:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 21:44:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 21:44:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 21:44:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 21:44:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 21:44:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 21:44:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 21:44:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 21:44:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 21:44:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 21:44:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 21:44:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 21:44:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 21:44:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 21:44:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 21:44:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 21:44:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 21:44:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 21:44:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 21:44:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 21:44:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 21:44:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 21:44:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 21:44:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 21:44:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 21:44:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 21:44:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 21:45:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 21:45:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 21:45:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 21:45:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 21:45:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 21:45:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 21:45:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 21:45:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 21:45:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 21:45:08 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-2c4f9cf8-connect-69687bb85d-8bq7p
2022-04-05 21:45:08 [main] [32mINFO [m [SecurityST:1408] Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm
2022-04-05 21:45:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-2c4f9cf8 will have desired state: Ready
2022-04-05 21:50:39 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-2c4f9cf8 is in desired state: Ready
2022-04-05 21:50:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 21:50:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndKafkaConnectCipherSuites
2022-04-05 21:50:39 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2c4f9cf8-scraper in namespace namespace-63
2022-04-05 21:50:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-2c4f9cf8 in namespace namespace-63
2022-04-05 21:50:39 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2c4f9cf8-kafka-clients in namespace namespace-63
2022-04-05 21:50:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2c4f9cf8 in namespace namespace-63
2022-04-05 21:50:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-2c4f9cf8-allow in namespace namespace-63
2022-04-05 21:51:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 21:51:29 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-63 for test case:testKafkaAndKafkaConnectCipherSuites
2022-04-05 21:51:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectCipherSuites-FINISHED
2022-04-05 21:51:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 21:51:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 21:51:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-STARTED
2022-04-05 21:51:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 21:51:35 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-64 for test case:testCertRenewalInMaintenanceWindow
2022-04-05 21:51:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-64
2022-04-05 21:51:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-64
2022-04-05 21:51:35 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-64
2022-04-05 21:51:35 [main] [32mINFO [m [SecurityST:698] Maintenance window is: * 56-10 * * * ? *
2022-04-05 21:51:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d964d91d in namespace namespace-64
2022-04-05 21:51:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-05 21:51:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d964d91d will have desired state: Ready
2022-04-05 21:52:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d964d91d is in desired state: Ready
2022-04-05 21:52:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1093777628-1276683248 in namespace namespace-64
2022-04-05 21:52:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-05 21:52:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1093777628-1276683248 will have desired state: Ready
2022-04-05 21:52:46 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1093777628-1276683248 is in desired state: Ready
2022-04-05 21:52:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-724741149-1981541637 in namespace namespace-64
2022-04-05 21:52:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-05 21:52:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-724741149-1981541637 will have desired state: Ready
2022-04-05 21:52:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-724741149-1981541637 is in desired state: Ready
2022-04-05 21:52:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-724741149-1981541637 in namespace namespace-64
2022-04-05 21:52:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-05 21:52:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-724741149-1981541637 will have desired state: Ready
2022-04-05 21:52:47 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-724741149-1981541637 is in desired state: Ready
2022-04-05 21:52:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d964d91d-kafka-clients in namespace namespace-64
2022-04-05 21:52:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-64
2022-04-05 21:52:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d964d91d-kafka-clients will be ready
2022-04-05 21:52:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d964d91d-kafka-clients is ready
2022-04-05 21:52:49 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 21:52:49 [main] [32mINFO [m [SecurityST:728] Annotate secret my-cluster-d964d91d-cluster-ca-cert with secret force-renew annotation
2022-04-05 21:52:49 [main] [32mINFO [m [SecurityST:735] Wait until maintenance windows starts
2022-04-05 21:56:00 [main] [32mINFO [m [SecurityST:741] Maintenance window starts
2022-04-05 21:56:00 [main] [32mINFO [m [SecurityST:745] Wait until rolling update is triggered during maintenance window
2022-04-05 21:56:00 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d964d91d-kafka rolling update
2022-04-05 21:58:10 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d964d91d-kafka has been successfully rolled
2022-04-05 21:58:10 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d964d91d-kafka to be ready
2022-04-05 21:58:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d964d91d will have desired state: Ready
2022-04-05 21:58:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d964d91d is in desired state: Ready
2022-04-05 21:58:34 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d964d91d is ready
2022-04-05 21:58:34 [main] [32mINFO [m [SecurityST:750] Checking consumed messages to pod:my-cluster-d964d91d-kafka-clients-5849f67499-86gvd
2022-04-05 21:58:34 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3ea017cf, messages=[], arguments=[USER=my_user_1093777628_1276683248, --bootstrap-server, my-cluster-d964d91d-kafka-bootstrap.namespace-64.svc:9093, --max-messages, 100, --topic, my-topic-724741149-1981541637], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d964d91d-kafka-clients-5849f67499-86gvd', podNamespace='namespace-64', bootstrapServer='my-cluster-d964d91d-kafka-bootstrap.namespace-64.svc:9093', topicName='my-topic-724741149-1981541637', maxMessages=100, kafkaUsername='my-user-1093777628-1276683248', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6adcbd37}
2022-04-05 21:58:34 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-d964d91d-kafka-bootstrap.namespace-64.svc:9093:my-topic-724741149-1981541637 from pod my-cluster-d964d91d-kafka-clients-5849f67499-86gvd
2022-04-05 21:58:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d964d91d-kafka-clients-5849f67499-86gvd -n namespace-64 -- /opt/kafka/producer.sh USER=my_user_1093777628_1276683248 --bootstrap-server my-cluster-d964d91d-kafka-bootstrap.namespace-64.svc:9093 --max-messages 100 --topic my-topic-724741149-1981541637
2022-04-05 21:58:38 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 21:58:38 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 21:58:38 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@26f52d8, messages=[], arguments=[USER=my_user_1093777628_1276683248, --group-id, my-consumer-group-208380525, --bootstrap-server, my-cluster-d964d91d-kafka-bootstrap.namespace-64.svc:9093, --group-instance-id, instance750004200, --max-messages, 100, --topic, my-topic-724741149-1981541637], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d964d91d-kafka-clients-5849f67499-86gvd', podNamespace='namespace-64', bootstrapServer='my-cluster-d964d91d-kafka-bootstrap.namespace-64.svc:9093', topicName='my-topic-724741149-1981541637', maxMessages=100, kafkaUsername='my-user-1093777628-1276683248', consumerGroupName='my-consumer-group-208380525', consumerInstanceId='instance750004200', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@d556340}
2022-04-05 21:58:38 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-d964d91d-kafka-bootstrap.namespace-64.svc:9093:my-topic-724741149-1981541637 from pod my-cluster-d964d91d-kafka-clients-5849f67499-86gvd
2022-04-05 21:58:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d964d91d-kafka-clients-5849f67499-86gvd -n namespace-64 -- /opt/kafka/consumer.sh USER=my_user_1093777628_1276683248 --group-id my-consumer-group-208380525 --bootstrap-server my-cluster-d964d91d-kafka-bootstrap.namespace-64.svc:9093 --group-instance-id instance750004200 --max-messages 100 --topic my-topic-724741149-1981541637
2022-04-05 21:58:45 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 21:58:45 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 21:58:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 21:58:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertRenewalInMaintenanceWindow
2022-04-05 21:58:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-724741149-1981541637 in namespace namespace-64
2022-04-05 21:58:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1093777628-1276683248 in namespace namespace-64
2022-04-05 21:58:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d964d91d-kafka-clients in namespace namespace-64
2022-04-05 21:58:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d964d91d in namespace namespace-64
2022-04-05 21:58:55 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-724741149-1981541637 in namespace namespace-64
2022-04-05 21:59:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 21:59:45 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-64 for test case:testCertRenewalInMaintenanceWindow
2022-04-05 21:59:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertRenewalInMaintenanceWindow-FINISHED
2022-04-05 21:59:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 21:59:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 21:59:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-STARTED
2022-04-05 21:59:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 21:59:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-65 for test case:testOwnerReferenceOfCASecrets
2022-04-05 21:59:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-65
2022-04-05 21:59:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-65
2022-04-05 21:59:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-65
2022-04-05 21:59:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-99c2155b in namespace namespace-65
2022-04-05 21:59:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-65
2022-04-05 21:59:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-99c2155b will have desired state: Ready
2022-04-05 22:01:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-99c2155b is in desired state: Ready
2022-04-05 22:01:11 [main] [32mINFO [m [SecurityST:1432] Listing all cluster CAs for my-cluster-99c2155b
2022-04-05 22:01:11 [main] [32mINFO [m [SecurityST:1436] Deleting Kafka:my-cluster-99c2155b
2022-04-05 22:01:11 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-cluster-99c2155b
2022-04-05 22:01:13 [main] [32mINFO [m [SecurityST:1440] Checking actual secrets after Kafka deletion
2022-04-05 22:01:13 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-99c2155b-clients-ca secret is still present
2022-04-05 22:01:13 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-99c2155b-clients-ca
2022-04-05 22:01:13 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-99c2155b-clients-ca-cert secret is still present
2022-04-05 22:01:13 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-99c2155b-clients-ca-cert
2022-04-05 22:01:13 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-99c2155b-cluster-ca secret is still present
2022-04-05 22:01:13 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-99c2155b-cluster-ca
2022-04-05 22:01:13 [main] [32mINFO [m [SecurityST:1443] Checking that my-cluster-99c2155b-cluster-ca-cert secret is still present
2022-04-05 22:01:13 [main] [32mINFO [m [SecurityST:1446] Deleting secret: my-cluster-99c2155b-cluster-ca-cert
2022-04-05 22:01:13 [main] [32mINFO [m [SecurityST:1450] Deploying Kafka with generateSecretOwnerReference set to true
2022-04-05 22:01:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-second-cluster-my-cluster-99c2155b in namespace namespace-65
2022-04-05 22:01:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-65
2022-04-05 22:01:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-second-cluster-my-cluster-99c2155b will have desired state: Ready
2022-04-05 22:03:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-second-cluster-my-cluster-99c2155b is in desired state: Ready
2022-04-05 22:03:31 [main] [32mINFO [m [SecurityST:1465] Deleting Kafka:my-second-cluster-my-cluster-99c2155b
2022-04-05 22:03:31 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-second-cluster-my-cluster-99c2155b
2022-04-05 22:03:34 [main] [32mINFO [m [SecurityST:1469] Checking actual secrets after Kafka deletion
2022-04-05 22:03:34 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-99c2155b-clients-ca secret is deleted
2022-04-05 22:03:35 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-99c2155b-clients-ca-cert secret is deleted
2022-04-05 22:03:35 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-99c2155b-cluster-ca secret is deleted
2022-04-05 22:03:35 [main] [32mINFO [m [SecurityST:1472] Checking that my-second-cluster-my-cluster-99c2155b-cluster-ca-cert secret is deleted
2022-04-05 22:03:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 22:03:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testOwnerReferenceOfCASecrets
2022-04-05 22:03:35 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-second-cluster-my-cluster-99c2155b in namespace namespace-65
2022-04-05 22:03:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-99c2155b in namespace namespace-65
2022-04-05 22:03:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 22:03:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-65 for test case:testOwnerReferenceOfCASecrets
2022-04-05 22:04:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testOwnerReferenceOfCASecrets-FINISHED
2022-04-05 22:04:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 22:04:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 22:04:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-STARTED
2022-04-05 22:04:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 22:04:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-66 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-05 22:04:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-66
2022-04-05 22:04:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-66
2022-04-05 22:04:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-66
2022-04-05 22:04:18 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 22:04:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ed694c3c in namespace namespace-66
2022-04-05 22:04:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-05 22:04:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ed694c3c will have desired state: Ready
2022-04-05 22:06:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ed694c3c is in desired state: Ready
2022-04-05 22:06:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1074072147-1919078973 in namespace namespace-66
2022-04-05 22:06:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-05 22:06:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1074072147-1919078973 will have desired state: Ready
2022-04-05 22:06:22 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1074072147-1919078973 is in desired state: Ready
2022-04-05 22:06:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2107607411-790163545 in namespace namespace-66
2022-04-05 22:06:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-05 22:06:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2107607411-790163545 will have desired state: Ready
2022-04-05 22:06:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2107607411-790163545 is in desired state: Ready
2022-04-05 22:06:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ed694c3c-kafka-clients in namespace namespace-66
2022-04-05 22:06:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-05 22:06:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ed694c3c-kafka-clients will be ready
2022-04-05 22:06:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ed694c3c-kafka-clients is ready
2022-04-05 22:06:26 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 22:06:26 [main] [32mINFO [m [SecurityST:260] Checking produced and consumed messages to pod:my-cluster-ed694c3c-kafka-clients-659f99445c-97wb8
2022-04-05 22:06:26 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@59579633, messages=[], arguments=[--bootstrap-server, my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9092, --max-messages, 100, --topic, my-topic-2107607411-790163545], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-ed694c3c-kafka-clients-659f99445c-97wb8', podNamespace='namespace-66', bootstrapServer='my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-2107607411-790163545', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2a6c9ae9}
2022-04-05 22:06:26 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9092:my-topic-2107607411-790163545 from pod my-cluster-ed694c3c-kafka-clients-659f99445c-97wb8
2022-04-05 22:06:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ed694c3c-kafka-clients-659f99445c-97wb8 -n namespace-66 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9092 --max-messages 100 --topic my-topic-2107607411-790163545
2022-04-05 22:06:28 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 22:06:28 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 22:06:28 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4aa80209, messages=[], arguments=[--group-id, my-consumer-group-420621361, --bootstrap-server, my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9092, --group-instance-id, instance857863035, --max-messages, 100, --topic, my-topic-2107607411-790163545], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ed694c3c-kafka-clients-659f99445c-97wb8', podNamespace='namespace-66', bootstrapServer='my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-2107607411-790163545', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-420621361', consumerInstanceId='instance857863035', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@45d7bb9}
2022-04-05 22:06:28 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9092#my-topic-2107607411-790163545 from pod my-cluster-ed694c3c-kafka-clients-659f99445c-97wb8
2022-04-05 22:06:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ed694c3c-kafka-clients-659f99445c-97wb8 -n namespace-66 -- /opt/kafka/consumer.sh --group-id my-consumer-group-420621361 --bootstrap-server my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9092 --group-instance-id instance857863035 --max-messages 100 --topic my-topic-2107607411-790163545
2022-04-05 22:06:34 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:06:34 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:06:34 [main] [32mINFO [m [SecurityST:274] Triggering CA cert renewal by adding the annotation
2022-04-05 22:06:34 [main] [32mINFO [m [SecurityST:286] Patching secret my-cluster-ed694c3c-clients-ca-cert with strimzi.io/force-renew
2022-04-05 22:06:34 [main] [32mINFO [m [SecurityST:295] Wait for kafka to rolling restart ...
2022-04-05 22:06:34 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-ed694c3c-kafka rolling update
2022-04-05 22:08:04 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-ed694c3c-kafka has been successfully rolled
2022-04-05 22:08:04 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-ed694c3c-kafka to be ready
2022-04-05 22:08:33 [main] [32mINFO [m [SecurityST:308] Checking the certificates have been replaced
2022-04-05 22:08:33 [main] [32mINFO [m [SecurityST:322] Checking consumed messages to pod:my-cluster-ed694c3c-kafka-clients-659f99445c-97wb8
2022-04-05 22:08:33 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@fc106ee, messages=[], arguments=[--group-id, my-consumer-group-1460278725, --bootstrap-server, my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9092, --group-instance-id, instance670663509, --max-messages, 100, --topic, my-topic-2107607411-790163545], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ed694c3c-kafka-clients-659f99445c-97wb8', podNamespace='namespace-66', bootstrapServer='my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9092', topicName='my-topic-2107607411-790163545', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1460278725', consumerInstanceId='instance670663509', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2930af7b}
2022-04-05 22:08:33 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9092#my-topic-2107607411-790163545 from pod my-cluster-ed694c3c-kafka-clients-659f99445c-97wb8
2022-04-05 22:08:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ed694c3c-kafka-clients-659f99445c-97wb8 -n namespace-66 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1460278725 --bootstrap-server my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9092 --group-instance-id instance670663509 --max-messages 100 --topic my-topic-2107607411-790163545
2022-04-05 22:08:39 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:08:39 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:08:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser bob-my-cluster-ed694c3c in namespace namespace-66
2022-04-05 22:08:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-05 22:08:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: bob-my-cluster-ed694c3c will have desired state: Ready
2022-04-05 22:08:40 [main] [32mINFO [m [ResourceManager:444] KafkaUser: bob-my-cluster-ed694c3c is in desired state: Ready
2022-04-05 22:08:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-ed694c3c-kafka-clients-tls in namespace namespace-66
2022-04-05 22:08:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-66
2022-04-05 22:08:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ed694c3c-kafka-clients-tls will be ready
2022-04-05 22:08:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ed694c3c-kafka-clients-tls is ready
2022-04-05 22:08:42 [main] [32mINFO [m [SecurityST:346] Checking consumed messages to pod:my-cluster-ed694c3c-kafka-clients-tls-ccf7c46c4-sgpl7
2022-04-05 22:08:42 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@64467e5e, messages=[], arguments=[USER=bob_my_cluster_ed694c3c, --group-id, my-consumer-group-210918598, --bootstrap-server, my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9093, --group-instance-id, instance1094937889, --max-messages, 100, --topic, my-topic-2107607411-790163545], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-ed694c3c-kafka-clients-tls-ccf7c46c4-sgpl7', podNamespace='namespace-66', bootstrapServer='my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9093', topicName='my-topic-2107607411-790163545', maxMessages=100, kafkaUsername='bob-my-cluster-ed694c3c', consumerGroupName='my-consumer-group-210918598', consumerInstanceId='instance1094937889', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@48a15b46}
2022-04-05 22:08:42 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9093#my-topic-2107607411-790163545 from pod my-cluster-ed694c3c-kafka-clients-tls-ccf7c46c4-sgpl7
2022-04-05 22:08:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-ed694c3c-kafka-clients-tls-ccf7c46c4-sgpl7 -n namespace-66 -- /opt/kafka/consumer.sh USER=bob_my_cluster_ed694c3c --group-id my-consumer-group-210918598 --bootstrap-server my-cluster-ed694c3c-kafka-bootstrap.namespace-66.svc:9093 --group-instance-id instance1094937889 --max-messages 100 --topic my-topic-2107607411-790163545
2022-04-05 22:08:49 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:08:49 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:08:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 22:08:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-05 22:08:49 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ed694c3c-kafka-clients in namespace namespace-66
2022-04-05 22:08:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1074072147-1919078973 in namespace namespace-66
2022-04-05 22:08:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-ed694c3c-kafka-clients-tls in namespace namespace-66
2022-04-05 22:08:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ed694c3c in namespace namespace-66
2022-04-05 22:08:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-66, for cruise control Kafka cluster my-cluster-ed694c3c
2022-04-05 22:09:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2107607411-790163545 in namespace namespace-66
2022-04-05 22:09:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser bob-my-cluster-ed694c3c in namespace namespace-66
2022-04-05 22:09:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 22:09:40 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-66 for test case:testAutoRenewClientsCaCertsTriggeredByAnno
2022-04-05 22:09:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoRenewClientsCaCertsTriggeredByAnno-FINISHED
2022-04-05 22:09:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 22:09:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 22:09:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-STARTED
2022-04-05 22:09:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 22:09:45 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-67 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-05 22:09:45 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-67
2022-04-05 22:09:45 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-67
2022-04-05 22:09:45 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-67
2022-04-05 22:09:45 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 22:09:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d9a0d86b in namespace namespace-67
2022-04-05 22:09:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-05 22:09:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d9a0d86b will have desired state: Ready
2022-04-05 22:11:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d9a0d86b is in desired state: Ready
2022-04-05 22:11:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1032938552-1467818222 in namespace namespace-67
2022-04-05 22:11:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-05 22:11:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1032938552-1467818222 will have desired state: Ready
2022-04-05 22:11:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1032938552-1467818222 is in desired state: Ready
2022-04-05 22:11:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1596209619-506472983 in namespace namespace-67
2022-04-05 22:11:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-05 22:11:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1596209619-506472983 will have desired state: Ready
2022-04-05 22:11:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1596209619-506472983 is in desired state: Ready
2022-04-05 22:11:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d9a0d86b-kafka-clients in namespace namespace-67
2022-04-05 22:11:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-05 22:11:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d9a0d86b-kafka-clients will be ready
2022-04-05 22:11:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d9a0d86b-kafka-clients is ready
2022-04-05 22:11:51 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 22:11:51 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-d9a0d86b-kafka-clients-649966dd49-jljm4
2022-04-05 22:11:51 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@f03b9e2, messages=[], arguments=[--bootstrap-server, my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092, --max-messages, 100, --topic, my-topic-1596209619-506472983], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d9a0d86b-kafka-clients-649966dd49-jljm4', podNamespace='namespace-67', bootstrapServer='my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1596209619-506472983', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@594e5f0f}
2022-04-05 22:11:51 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092:my-topic-1596209619-506472983 from pod my-cluster-d9a0d86b-kafka-clients-649966dd49-jljm4
2022-04-05 22:11:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d9a0d86b-kafka-clients-649966dd49-jljm4 -n namespace-67 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092 --max-messages 100 --topic my-topic-1596209619-506472983
2022-04-05 22:11:53 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 22:11:53 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 22:11:53 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@fd66a1, messages=[], arguments=[--group-id, my-consumer-group-700145578, --bootstrap-server, my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092, --group-instance-id, instance1580513293, --max-messages, 100, --topic, my-topic-1596209619-506472983], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d9a0d86b-kafka-clients-649966dd49-jljm4', podNamespace='namespace-67', bootstrapServer='my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1596209619-506472983', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-700145578', consumerInstanceId='instance1580513293', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2be0f2f5}
2022-04-05 22:11:53 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092#my-topic-1596209619-506472983 from pod my-cluster-d9a0d86b-kafka-clients-649966dd49-jljm4
2022-04-05 22:11:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d9a0d86b-kafka-clients-649966dd49-jljm4 -n namespace-67 -- /opt/kafka/consumer.sh --group-id my-consumer-group-700145578 --bootstrap-server my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092 --group-instance-id instance1580513293 --max-messages 100 --topic my-topic-1596209619-506472983
2022-04-05 22:11:59 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:11:59 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:11:59 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-05 22:11:59 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-d9a0d86b-cluster-ca with strimzi.io/force-replace
2022-04-05 22:11:59 [main] [32mINFO [m [SecurityST:484] Wait for zk to rolling restart (1)...
2022-04-05 22:11:59 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d9a0d86b-zookeeper rolling update
2022-04-05 22:13:39 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d9a0d86b-zookeeper has been successfully rolled
2022-04-05 22:13:39 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-05 22:13:39 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d9a0d86b-kafka rolling update
2022-04-05 22:15:29 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d9a0d86b-kafka has been successfully rolled
2022-04-05 22:15:29 [main] [32mINFO [m [SecurityST:494] Wait for EO to rolling restart (1)...
2022-04-05 22:15:29 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-d9a0d86b-entity-operator rolling update
2022-04-05 22:15:59 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d9a0d86b-entity-operator will be ready
2022-04-05 22:17:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d9a0d86b-entity-operator is ready
2022-04-05 22:17:40 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-d9a0d86b-entity-operator rolling update finished
2022-04-05 22:17:40 [main] [32mINFO [m [SecurityST:499] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-04-05 22:17:40 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-d9a0d86b-kafka-exporter rolling update
2022-04-05 22:17:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d9a0d86b-kafka-exporter will be ready
2022-04-05 22:17:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d9a0d86b-kafka-exporter is ready
2022-04-05 22:18:05 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-d9a0d86b-kafka-exporter rolling update finished
2022-04-05 22:18:05 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-d9a0d86b-cruise-control rolling update
2022-04-05 22:18:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d9a0d86b-cruise-control will be ready
2022-04-05 22:18:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d9a0d86b-cruise-control is ready
2022-04-05 22:18:24 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-d9a0d86b-cruise-control rolling update finished
2022-04-05 22:18:24 [main] [32mINFO [m [SecurityST:505] Wait for zk to rolling restart (2)...
2022-04-05 22:18:24 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d9a0d86b-zookeeper rolling update
2022-04-05 22:19:19 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d9a0d86b-zookeeper has been successfully rolled
2022-04-05 22:19:19 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-d9a0d86b-zookeeper to be ready
2022-04-05 22:19:48 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-05 22:19:48 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d9a0d86b-kafka rolling update
2022-04-05 22:20:38 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d9a0d86b-kafka has been successfully rolled
2022-04-05 22:20:38 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-d9a0d86b-kafka to be ready
2022-04-05 22:21:08 [main] [32mINFO [m [SecurityST:515] Wait for EO to rolling restart (2)...
2022-04-05 22:21:08 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-d9a0d86b-entity-operator rolling update
2022-04-05 22:21:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d9a0d86b-entity-operator will be ready
2022-04-05 22:23:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d9a0d86b-entity-operator is ready
2022-04-05 22:23:40 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-d9a0d86b-entity-operator rolling update finished
2022-04-05 22:23:40 [main] [32mINFO [m [SecurityST:520] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-04-05 22:23:40 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-d9a0d86b-kafka-exporter rolling update
2022-04-05 22:24:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d9a0d86b-kafka-exporter will be ready
2022-04-05 22:24:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d9a0d86b-kafka-exporter is ready
2022-04-05 22:24:50 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-d9a0d86b-kafka-exporter rolling update finished
2022-04-05 22:24:50 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-d9a0d86b-cruise-control rolling update
2022-04-05 22:24:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d9a0d86b-cruise-control will be ready
2022-04-05 22:24:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d9a0d86b-cruise-control is ready
2022-04-05 22:25:00 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-d9a0d86b-cruise-control rolling update finished
2022-04-05 22:25:00 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-05 22:25:00 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-d9a0d86b-kafka-clients-649966dd49-jljm4
2022-04-05 22:25:00 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@cceddca, messages=[], arguments=[--group-id, my-consumer-group-608810820, --bootstrap-server, my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092, --group-instance-id, instance2070925502, --max-messages, 100, --topic, my-topic-1596209619-506472983], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d9a0d86b-kafka-clients-649966dd49-jljm4', podNamespace='namespace-67', bootstrapServer='my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1596209619-506472983', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-608810820', consumerInstanceId='instance2070925502', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2f5cbcf9}
2022-04-05 22:25:00 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092#my-topic-1596209619-506472983 from pod my-cluster-d9a0d86b-kafka-clients-649966dd49-jljm4
2022-04-05 22:25:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d9a0d86b-kafka-clients-649966dd49-jljm4 -n namespace-67 -- /opt/kafka/consumer.sh --group-id my-consumer-group-608810820 --bootstrap-server my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092 --group-instance-id instance2070925502 --max-messages 100 --topic my-topic-1596209619-506472983
2022-04-05 22:25:06 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:25:06 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:25:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1545316864-1196013432 in namespace namespace-67
2022-04-05 22:25:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-05 22:25:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1545316864-1196013432 will have desired state: Ready
2022-04-05 22:25:07 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1545316864-1196013432 is in desired state: Ready
2022-04-05 22:25:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d9a0d86b-kafka-clients-tls in namespace namespace-67
2022-04-05 22:25:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-67
2022-04-05 22:25:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d9a0d86b-kafka-clients-tls will be ready
2022-04-05 22:25:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d9a0d86b-kafka-clients-tls is ready
2022-04-05 22:25:09 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-d9a0d86b-kafka-clients-tls-c48fdb695-mrcq5
2022-04-05 22:25:09 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2936652e, messages=[], arguments=[--group-id, my-consumer-group-847416915, --bootstrap-server, my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092, --group-instance-id, instance1349728002, --max-messages, 100, --topic, my-topic-1596209619-506472983], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-d9a0d86b-kafka-clients-tls-c48fdb695-mrcq5', podNamespace='namespace-67', bootstrapServer='my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092', topicName='my-topic-1596209619-506472983', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-847416915', consumerInstanceId='instance1349728002', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@63c7b6db}
2022-04-05 22:25:09 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092#my-topic-1596209619-506472983 from pod my-cluster-d9a0d86b-kafka-clients-tls-c48fdb695-mrcq5
2022-04-05 22:25:09 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d9a0d86b-kafka-clients-tls-c48fdb695-mrcq5 -n namespace-67 -- /opt/kafka/consumer.sh --group-id my-consumer-group-847416915 --bootstrap-server my-cluster-d9a0d86b-kafka-bootstrap.namespace-67.svc:9092 --group-instance-id instance1349728002 --max-messages 100 --topic my-topic-1596209619-506472983
2022-04-05 22:25:15 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:25:15 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:25:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 22:25:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-05 22:25:15 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d9a0d86b-kafka-clients in namespace namespace-67
2022-04-05 22:25:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1032938552-1467818222 in namespace namespace-67
2022-04-05 22:25:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d9a0d86b-kafka-clients-tls in namespace namespace-67
2022-04-05 22:25:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d9a0d86b in namespace namespace-67
2022-04-05 22:25:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-67, for cruise control Kafka cluster my-cluster-d9a0d86b
2022-04-05 22:25:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1596209619-506472983 in namespace namespace-67
2022-04-05 22:25:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1545316864-1196013432 in namespace namespace-67
2022-04-05 22:26:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 22:26:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-67 for test case:testAutoReplaceClusterCaKeysTriggeredByAnno
2022-04-05 22:26:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceClusterCaKeysTriggeredByAnno-FINISHED
2022-04-05 22:26:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 22:26:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 22:26:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-STARTED
2022-04-05 22:26:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 22:26:12 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-68 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-05 22:26:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-68
2022-04-05 22:26:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-68
2022-04-05 22:26:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-68
2022-04-05 22:26:12 [main] [32mINFO [m [SecurityST:587] Creating a cluster
2022-04-05 22:26:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4ea01bdc in namespace namespace-68
2022-04-05 22:26:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-05 22:26:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4ea01bdc will have desired state: Ready
2022-04-05 22:28:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4ea01bdc is in desired state: Ready
2022-04-05 22:28:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-333004147-218685194 in namespace namespace-68
2022-04-05 22:28:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-05 22:28:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-333004147-218685194 will have desired state: Ready
2022-04-05 22:28:19 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-333004147-218685194 is in desired state: Ready
2022-04-05 22:28:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1455166852-294208379 in namespace namespace-68
2022-04-05 22:28:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-05 22:28:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1455166852-294208379 will have desired state: Ready
2022-04-05 22:28:20 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1455166852-294208379 is in desired state: Ready
2022-04-05 22:28:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4ea01bdc-kafka-clients in namespace namespace-68
2022-04-05 22:28:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-05 22:28:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4ea01bdc-kafka-clients will be ready
2022-04-05 22:28:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4ea01bdc-kafka-clients is ready
2022-04-05 22:28:22 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 22:28:22 [main] [32mINFO [m [SecurityST:453] Checking produced and consumed messages to pod:my-cluster-4ea01bdc-kafka-clients-6bb96fd5b-8plqs
2022-04-05 22:28:22 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@580683d6, messages=[], arguments=[--bootstrap-server, my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092, --max-messages, 100, --topic, my-topic-1455166852-294208379], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4ea01bdc-kafka-clients-6bb96fd5b-8plqs', podNamespace='namespace-68', bootstrapServer='my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1455166852-294208379', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1adf0e40}
2022-04-05 22:28:22 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092:my-topic-1455166852-294208379 from pod my-cluster-4ea01bdc-kafka-clients-6bb96fd5b-8plqs
2022-04-05 22:28:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4ea01bdc-kafka-clients-6bb96fd5b-8plqs -n namespace-68 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092 --max-messages 100 --topic my-topic-1455166852-294208379
2022-04-05 22:28:24 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-05 22:28:24 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-05 22:28:24 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4300b126, messages=[], arguments=[--group-id, my-consumer-group-590925897, --bootstrap-server, my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092, --group-instance-id, instance1095037203, --max-messages, 100, --topic, my-topic-1455166852-294208379], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4ea01bdc-kafka-clients-6bb96fd5b-8plqs', podNamespace='namespace-68', bootstrapServer='my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1455166852-294208379', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-590925897', consumerInstanceId='instance1095037203', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@214f0641}
2022-04-05 22:28:24 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092#my-topic-1455166852-294208379 from pod my-cluster-4ea01bdc-kafka-clients-6bb96fd5b-8plqs
2022-04-05 22:28:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4ea01bdc-kafka-clients-6bb96fd5b-8plqs -n namespace-68 -- /opt/kafka/consumer.sh --group-id my-consumer-group-590925897 --bootstrap-server my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092 --group-instance-id instance1095037203 --max-messages 100 --topic my-topic-1455166852-294208379
2022-04-05 22:28:30 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:28:30 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:28:30 [main] [32mINFO [m [SecurityST:467] Triggering CA cert renewal by adding the annotation
2022-04-05 22:28:30 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-4ea01bdc-cluster-ca with strimzi.io/force-replace
2022-04-05 22:28:30 [main] [32mINFO [m [SecurityST:479] Patching secret my-cluster-4ea01bdc-clients-ca with strimzi.io/force-replace
2022-04-05 22:28:30 [main] [32mINFO [m [SecurityST:484] Wait for zk to rolling restart (1)...
2022-04-05 22:28:30 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4ea01bdc-zookeeper rolling update
2022-04-05 22:29:50 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4ea01bdc-zookeeper has been successfully rolled
2022-04-05 22:29:50 [main] [32mINFO [m [SecurityST:489] Wait for kafka to rolling restart (1)...
2022-04-05 22:29:50 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4ea01bdc-kafka rolling update
2022-04-05 22:31:20 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4ea01bdc-kafka has been successfully rolled
2022-04-05 22:31:20 [main] [32mINFO [m [SecurityST:494] Wait for EO to rolling restart (1)...
2022-04-05 22:31:20 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-4ea01bdc-entity-operator rolling update
2022-04-05 22:31:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4ea01bdc-entity-operator will be ready
2022-04-05 22:32:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4ea01bdc-entity-operator is ready
2022-04-05 22:32:35 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-4ea01bdc-entity-operator rolling update finished
2022-04-05 22:32:35 [main] [32mINFO [m [SecurityST:499] Wait for KafkaExporter and CruiseControl to rolling restart (1)...
2022-04-05 22:32:35 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-4ea01bdc-kafka-exporter rolling update
2022-04-05 22:32:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4ea01bdc-kafka-exporter will be ready
2022-04-05 22:32:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4ea01bdc-kafka-exporter is ready
2022-04-05 22:32:55 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-4ea01bdc-kafka-exporter rolling update finished
2022-04-05 22:32:55 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-4ea01bdc-cruise-control rolling update
2022-04-05 22:32:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4ea01bdc-cruise-control will be ready
2022-04-05 22:33:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4ea01bdc-cruise-control is ready
2022-04-05 22:33:19 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-4ea01bdc-cruise-control rolling update finished
2022-04-05 22:33:19 [main] [32mINFO [m [SecurityST:505] Wait for zk to rolling restart (2)...
2022-04-05 22:33:19 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4ea01bdc-zookeeper rolling update
2022-04-05 22:34:19 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4ea01bdc-zookeeper has been successfully rolled
2022-04-05 22:34:19 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-4ea01bdc-zookeeper to be ready
2022-04-05 22:34:46 [main] [32mINFO [m [SecurityST:510] Wait for kafka to rolling restart (2)...
2022-04-05 22:34:46 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4ea01bdc-kafka rolling update
2022-04-05 22:35:41 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4ea01bdc-kafka has been successfully rolled
2022-04-05 22:35:41 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-4ea01bdc-kafka to be ready
2022-04-05 22:36:12 [main] [32mINFO [m [SecurityST:515] Wait for EO to rolling restart (2)...
2022-04-05 22:36:12 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-4ea01bdc-entity-operator rolling update
2022-04-05 22:36:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4ea01bdc-entity-operator will be ready
2022-04-05 22:41:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4ea01bdc-entity-operator is ready
2022-04-05 22:41:52 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-4ea01bdc-entity-operator rolling update finished
2022-04-05 22:41:52 [main] [32mINFO [m [SecurityST:520] Wait for KafkaExporter and CruiseControl to rolling restart (2)...
2022-04-05 22:41:52 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-4ea01bdc-kafka-exporter rolling update
2022-04-05 22:42:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4ea01bdc-kafka-exporter will be ready
2022-04-05 22:42:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4ea01bdc-kafka-exporter is ready
2022-04-05 22:43:07 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-4ea01bdc-kafka-exporter rolling update finished
2022-04-05 22:43:07 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-4ea01bdc-cruise-control rolling update
2022-04-05 22:43:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4ea01bdc-cruise-control will be ready
2022-04-05 22:43:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4ea01bdc-cruise-control is ready
2022-04-05 22:43:17 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-4ea01bdc-cruise-control rolling update finished
2022-04-05 22:43:17 [main] [32mINFO [m [SecurityST:525] Checking the certificates have been replaced
2022-04-05 22:43:17 [main] [32mINFO [m [SecurityST:536] Checking consumed messages to pod:my-cluster-4ea01bdc-kafka-clients-6bb96fd5b-8plqs
2022-04-05 22:43:17 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@46dea026, messages=[], arguments=[--group-id, my-consumer-group-1687889949, --bootstrap-server, my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092, --group-instance-id, instance226998987, --max-messages, 100, --topic, my-topic-1455166852-294208379], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4ea01bdc-kafka-clients-6bb96fd5b-8plqs', podNamespace='namespace-68', bootstrapServer='my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1455166852-294208379', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-1687889949', consumerInstanceId='instance226998987', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1a4ce8b8}
2022-04-05 22:43:17 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092#my-topic-1455166852-294208379 from pod my-cluster-4ea01bdc-kafka-clients-6bb96fd5b-8plqs
2022-04-05 22:43:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4ea01bdc-kafka-clients-6bb96fd5b-8plqs -n namespace-68 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1687889949 --bootstrap-server my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092 --group-instance-id instance226998987 --max-messages 100 --topic my-topic-1455166852-294208379
2022-04-05 22:43:23 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:43:23 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:43:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1517597085-51804316 in namespace namespace-68
2022-04-05 22:43:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-05 22:43:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1517597085-51804316 will have desired state: Ready
2022-04-05 22:43:24 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1517597085-51804316 is in desired state: Ready
2022-04-05 22:43:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4ea01bdc-kafka-clients-tls in namespace namespace-68
2022-04-05 22:43:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-68
2022-04-05 22:43:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-4ea01bdc-kafka-clients-tls will be ready
2022-04-05 22:43:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-4ea01bdc-kafka-clients-tls is ready
2022-04-05 22:43:26 [main] [32mINFO [m [SecurityST:561] Checking consumed messages to pod:my-cluster-4ea01bdc-kafka-clients-tls-8fb54b477-8v677
2022-04-05 22:43:26 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@627acb51, messages=[], arguments=[--group-id, my-consumer-group-976712931, --bootstrap-server, my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092, --group-instance-id, instance947150221, --max-messages, 100, --topic, my-topic-1455166852-294208379], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4ea01bdc-kafka-clients-tls-8fb54b477-8v677', podNamespace='namespace-68', bootstrapServer='my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092', topicName='my-topic-1455166852-294208379', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-976712931', consumerInstanceId='instance947150221', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1f8ef930}
2022-04-05 22:43:26 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092#my-topic-1455166852-294208379 from pod my-cluster-4ea01bdc-kafka-clients-tls-8fb54b477-8v677
2022-04-05 22:43:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4ea01bdc-kafka-clients-tls-8fb54b477-8v677 -n namespace-68 -- /opt/kafka/consumer.sh --group-id my-consumer-group-976712931 --bootstrap-server my-cluster-4ea01bdc-kafka-bootstrap.namespace-68.svc:9092 --group-instance-id instance947150221 --max-messages 100 --topic my-topic-1455166852-294208379
2022-04-05 22:43:32 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-05 22:43:32 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-05 22:43:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 22:43:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-05 22:43:32 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4ea01bdc-kafka-clients in namespace namespace-68
2022-04-05 22:43:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-333004147-218685194 in namespace namespace-68
2022-04-05 22:43:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4ea01bdc in namespace namespace-68
2022-04-05 22:43:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace namespace-68, for cruise control Kafka cluster my-cluster-4ea01bdc
2022-04-05 22:43:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1455166852-294208379 in namespace namespace-68
2022-04-05 22:43:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4ea01bdc-kafka-clients-tls in namespace namespace-68
2022-04-05 22:43:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1517597085-51804316 in namespace namespace-68
2022-04-05 22:44:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 22:44:32 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-68 for test case:testAutoReplaceAllCaKeysTriggeredByAnno
2022-04-05 22:44:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testAutoReplaceAllCaKeysTriggeredByAnno-FINISHED
2022-04-05 22:44:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 22:44:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 22:44:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-STARTED
2022-04-05 22:44:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 22:44:39 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-69 for test case:testClusterCACertRenew
2022-04-05 22:44:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-69
2022-04-05 22:44:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-69
2022-04-05 22:44:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-69
2022-04-05 22:44:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-79c4f5e7 in namespace namespace-69
2022-04-05 22:44:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-69
2022-04-05 22:44:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-79c4f5e7 will have desired state: Ready
2022-04-05 22:45:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-79c4f5e7 is in desired state: Ready
2022-04-05 22:45:50 [main] [32mINFO [m [SecurityST:1512] Change of kafka validity and renewal days - reconciliation should start.
2022-04-05 22:45:50 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-79c4f5e7-zookeeper rolling update
2022-04-05 22:46:50 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-79c4f5e7-zookeeper has been successfully rolled
2022-04-05 22:46:50 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-79c4f5e7-zookeeper to be ready
2022-04-05 22:47:20 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-79c4f5e7-kafka rolling update
2022-04-05 22:48:41 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-79c4f5e7-kafka has been successfully rolled
2022-04-05 22:48:41 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-79c4f5e7-kafka to be ready
2022-04-05 22:49:11 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-79c4f5e7-entity-operator rolling update
2022-04-05 22:49:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-79c4f5e7-entity-operator will be ready
2022-04-05 22:52:03 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-79c4f5e7-entity-operator is ready
2022-04-05 22:52:13 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-79c4f5e7-entity-operator rolling update finished
2022-04-05 22:52:13 [main] [32mINFO [m [SecurityST:1545] Initial ClusterCA cert dates: Tue Apr 05 22:44:39 UTC 2022 --> Mon Apr 25 22:44:39 UTC 2022
2022-04-05 22:52:13 [main] [32mINFO [m [SecurityST:1546] Changed ClusterCA cert dates: Tue Apr 05 22:45:51 UTC 2022 --> Sat Oct 22 22:45:51 UTC 2022
2022-04-05 22:52:13 [main] [32mINFO [m [SecurityST:1547] KafkaBroker cert creation dates: Tue Apr 05 22:45:05 UTC 2022 --> Mon Apr 25 22:45:05 UTC 2022
2022-04-05 22:52:13 [main] [32mINFO [m [SecurityST:1548] KafkaBroker cert changed dates:  Tue Apr 05 22:47:12 UTC 2022 --> Sat Oct 22 22:47:12 UTC 2022
2022-04-05 22:52:13 [main] [32mINFO [m [SecurityST:1549] Zookeeper cert creation dates: Tue Apr 05 22:44:43 UTC 2022 --> Mon Apr 25 22:44:43 UTC 2022
2022-04-05 22:52:13 [main] [32mINFO [m [SecurityST:1550] Zookeeper cert changed dates:  Tue Apr 05 22:45:52 UTC 2022 --> Sat Oct 22 22:45:52 UTC 2022
2022-04-05 22:52:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 22:52:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClusterCACertRenew
2022-04-05 22:52:13 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-79c4f5e7 in namespace namespace-69
2022-04-05 22:52:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 22:52:23 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-69 for test case:testClusterCACertRenew
2022-04-05 22:52:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClusterCACertRenew-FINISHED
2022-04-05 22:52:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 22:52:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 22:52:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-STARTED
2022-04-05 22:52:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 22:52:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-70 for test case:testKafkaAndKafkaConnectTlsVersion
2022-04-05 22:52:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-70
2022-04-05 22:52:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-70
2022-04-05 22:52:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-70
2022-04-05 22:52:51 [main] [32mINFO [m [SecurityST:1287] Deploying Kafka cluster with the support TLSv1.2 TLS
2022-04-05 22:52:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3ddea02d in namespace namespace-70
2022-04-05 22:52:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-05 22:52:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3ddea02d will have desired state: Ready
2022-04-05 22:54:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3ddea02d is in desired state: Ready
2022-04-05 22:54:17 [main] [32mINFO [m [SecurityST:1299] Verifying that Kafka cluster has the accepted configuration:
ssl.enabled.protocols -> TLSv1.2
ssl.protocol -> TLSv1.3
2022-04-05 22:54:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3ddea02d-kafka-clients in namespace namespace-70
2022-04-05 22:54:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-05 22:54:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3ddea02d-kafka-clients will be ready
2022-04-05 22:54:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3ddea02d-kafka-clients is ready
2022-04-05 22:54:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3ddea02d-scraper in namespace namespace-70
2022-04-05 22:54:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-05 22:54:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3ddea02d-scraper will be ready
2022-04-05 22:54:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3ddea02d-scraper is ready
2022-04-05 22:54:19 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-3ddea02d-scraper to be ready
2022-04-05 22:54:29 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-3ddea02d-scraper is ready
2022-04-05 22:54:29 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-3ddea02d-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 22:54:29 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-3ddea02d-allow in namespace namespace-70
2022-04-05 22:54:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-05 22:54:29 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 22:54:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-3ddea02d in namespace namespace-70
2022-04-05 22:54:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-70
2022-04-05 22:54:29 [main] [32mINFO [m [SecurityST:1322] Verifying that Kafka Connect status is NotReady because of different TLS version
2022-04-05 22:54:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-3ddea02d will have desired state: NotReady
2022-04-05 22:59:30 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-3ddea02d is in desired state: NotReady
2022-04-05 22:59:30 [main] [32mINFO [m [SecurityST:1326] Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.
2022-04-05 22:59:30 [main] [32mINFO [m [SecurityST:1330] Verifying that Kafka Connect has the accepted configuration:
 ssl.enabled.protocols -> TLSv1.2
 ssl.protocol -> TLSv1.3
2022-04-05 22:59:30 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-04-05 22:59:30 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.enabled.protocols -> TLSv1.2 change
2022-04-05 22:59:30 [main] [32mINFO [m [KafkaConnectUtils:101] Waiting for Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-04-05 22:59:30 [main] [32mINFO [m [KafkaConnectUtils:109] Kafka Connect property ssl.protocol -> TLSv1.3 change
2022-04-05 22:59:30 [main] [32mINFO [m [SecurityST:1339] Verifying that Kafka Connect is stable
2022-04-05 22:59:30 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-3ddea02d-connect are stable
2022-04-05 22:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 22:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 22:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 22:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 22:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 22:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 22:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 22:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 22:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 22:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 22:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 22:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 22:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 22:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 22:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 22:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 22:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 22:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 22:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 22:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 22:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 22:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 22:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 22:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 22:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 22:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 22:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 22:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 22:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 22:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 23:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 23:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 23:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 23:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 23:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 23:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 23:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 23:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 23:00:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 23:00:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 23:00:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 23:00:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 23:00:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 23:00:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 23:00:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 23:00:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 23:00:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 23:00:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 23:00:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 23:00:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-3ddea02d-connect-58494ccd86-pxsp4 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 23:00:19 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-3ddea02d-connect-58494ccd86-pxsp4
2022-04-05 23:00:19 [main] [32mINFO [m [SecurityST:1343] Verifying that Kafka Connect status is Ready because of same TLS version
2022-04-05 23:00:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-3ddea02d will have desired state: Ready
2022-04-05 23:05:32 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-3ddea02d is in desired state: Ready
2022-04-05 23:05:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:05:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndKafkaConnectTlsVersion
2022-04-05 23:05:32 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3ddea02d-scraper in namespace namespace-70
2022-04-05 23:05:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3ddea02d-kafka-clients in namespace namespace-70
2022-04-05 23:05:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3ddea02d in namespace namespace-70
2022-04-05 23:05:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-3ddea02d in namespace namespace-70
2022-04-05 23:05:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-3ddea02d-allow in namespace namespace-70
2022-04-05 23:06:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:06:12 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-70 for test case:testKafkaAndKafkaConnectTlsVersion
2022-04-05 23:06:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testKafkaAndKafkaConnectTlsVersion-FINISHED
2022-04-05 23:06:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:06:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:06:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-STARTED
2022-04-05 23:06:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:06:18 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-71 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-04-05 23:06:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-71
2022-04-05 23:06:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-71
2022-04-05 23:06:18 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-71
2022-04-05 23:06:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-6718371a in namespace namespace-71
2022-04-05 23:06:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-05 23:06:18 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-6718371a will have desired state: Ready
2022-04-05 23:07:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-6718371a is in desired state: Ready
2022-04-05 23:07:29 [main] [32mINFO [m [SecurityST:838] Getting IP of the bootstrap service
2022-04-05 23:07:29 [main] [32mINFO [m [SecurityST:842] KafkaConnect without config ssl.endpoint.identification.algorithm will not connect to 10.97.32.107:9093
2022-04-05 23:07:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6718371a-kafka-clients in namespace namespace-71
2022-04-05 23:07:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-05 23:07:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6718371a-kafka-clients will be ready
2022-04-05 23:07:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6718371a-kafka-clients is ready
2022-04-05 23:07:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6718371a-scraper in namespace namespace-71
2022-04-05 23:07:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-05 23:07:31 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6718371a-scraper will be ready
2022-04-05 23:07:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6718371a-scraper is ready
2022-04-05 23:07:33 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-6718371a-scraper to be ready
2022-04-05 23:07:43 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-6718371a-scraper is ready
2022-04-05 23:07:43 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-6718371a-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-05 23:07:43 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-6718371a-allow in namespace namespace-71
2022-04-05 23:07:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-05 23:07:43 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-05 23:07:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-6718371a in namespace namespace-71
2022-04-05 23:07:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-71
2022-04-05 23:07:43 [main] [32mINFO [m [PodUtils:245] Wait until Pod my-cluster-6718371a-connect is present
2022-04-05 23:07:44 [main] [32mINFO [m [PodUtils:249] Pod my-cluster-6718371a-connect is present
2022-04-05 23:07:44 [main] [32mINFO [m [PodUtils:236] Wait until Pod my-cluster-6718371a-connect-5f4f7b8bc4-frcbw is in CrashLoopBackOff state
2022-04-05 23:08:06 [main] [32mINFO [m [PodUtils:241] Pod my-cluster-6718371a-connect-5f4f7b8bc4-frcbw is in CrashLoopBackOff state
2022-04-05 23:08:06 [main] [32mINFO [m [SecurityST:872] KafkaConnect with config ssl.endpoint.identification.algorithm will connect to 10.97.32.107:9093
2022-04-05 23:08:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-6718371a will have desired state: Ready
2022-04-05 23:13:53 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-6718371a is in desired state: Ready
2022-04-05 23:13:53 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:13:53 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTlsHostnameVerificationWithKafkaConnect
2022-04-05 23:13:53 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6718371a-scraper in namespace namespace-71
2022-04-05 23:13:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6718371a-kafka-clients in namespace namespace-71
2022-04-05 23:13:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-6718371a in namespace namespace-71
2022-04-05 23:13:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-6718371a-allow in namespace namespace-71
2022-04-05 23:13:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-6718371a in namespace namespace-71
2022-04-05 23:14:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:14:44 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-71 for test case:testTlsHostnameVerificationWithKafkaConnect
2022-04-05 23:14:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testTlsHostnameVerificationWithKafkaConnect-FINISHED
2022-04-05 23:14:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:14:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:14:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-STARTED
2022-04-05 23:14:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:14:49 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-72 for test case:testClientsCACertRenew
2022-04-05 23:14:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-72
2022-04-05 23:14:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-72
2022-04-05 23:14:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-72
2022-04-05 23:14:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3ea1ea43 in namespace namespace-72
2022-04-05 23:14:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-72
2022-04-05 23:14:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3ea1ea43 will have desired state: Ready
2022-04-05 23:16:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3ea1ea43 is in desired state: Ready
2022-04-05 23:16:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser strimzi-tls-user-2122922460 in namespace namespace-72
2022-04-05 23:16:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-72
2022-04-05 23:16:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: strimzi-tls-user-2122922460 will have desired state: Ready
2022-04-05 23:16:04 [main] [32mINFO [m [ResourceManager:444] KafkaUser: strimzi-tls-user-2122922460 is in desired state: Ready
2022-04-05 23:16:04 [main] [32mINFO [m [SecurityST:1596] Change of kafka validity and renewal days - reconciliation should start.
2022-04-05 23:16:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 50
2022-04-05 23:16:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 49
2022-04-05 23:16:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 48
2022-04-05 23:16:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 47
2022-04-05 23:16:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 46
2022-04-05 23:16:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 45
2022-04-05 23:16:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 44
2022-04-05 23:16:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 43
2022-04-05 23:16:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 42
2022-04-05 23:16:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 41
2022-04-05 23:16:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 40
2022-04-05 23:16:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 39
2022-04-05 23:16:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 38
2022-04-05 23:16:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 37
2022-04-05 23:16:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 36
2022-04-05 23:16:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 35
2022-04-05 23:16:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 34
2022-04-05 23:16:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 33
2022-04-05 23:16:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 32
2022-04-05 23:16:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 31
2022-04-05 23:16:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 30
2022-04-05 23:16:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 29
2022-04-05 23:16:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 28
2022-04-05 23:16:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 27
2022-04-05 23:16:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 26
2022-04-05 23:16:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 25
2022-04-05 23:16:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 24
2022-04-05 23:16:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 23
2022-04-05 23:16:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 22
2022-04-05 23:16:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 21
2022-04-05 23:16:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 20
2022-04-05 23:16:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 19
2022-04-05 23:16:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 18
2022-04-05 23:16:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 17
2022-04-05 23:16:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 16
2022-04-05 23:16:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 15
2022-04-05 23:16:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 14
2022-04-05 23:16:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 13
2022-04-05 23:16:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 12
2022-04-05 23:16:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 11
2022-04-05 23:16:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 10
2022-04-05 23:16:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 9
2022-04-05 23:16:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 8
2022-04-05 23:16:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 7
2022-04-05 23:16:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 6
2022-04-05 23:16:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 5
2022-04-05 23:16:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 4
2022-04-05 23:16:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 3
2022-04-05 23:16:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 2
2022-04-05 23:16:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 1
2022-04-05 23:16:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ea1ea43-zookeeper-0=f276ce64-4517-4a21-ae3f-af43601b8376, my-cluster-3ea1ea43-zookeeper-2=0176dc7e-a46a-4627-98fd-335590b526b5, my-cluster-3ea1ea43-zookeeper-1=e6c99035-0100-4032-b111-cf6dcf76dcae} pods didn't roll. Remaining seconds for stability: 0
2022-04-05 23:16:54 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-3ea1ea43-kafka rolling update
2022-04-05 23:17:19 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-3ea1ea43-kafka has been successfully rolled
2022-04-05 23:17:19 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-3ea1ea43-kafka to be ready
2022-04-05 23:17:45 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-3ea1ea43-entity-operator rolling update
2022-04-05 23:17:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3ea1ea43-entity-operator will be ready
2022-04-05 23:18:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3ea1ea43-entity-operator is ready
2022-04-05 23:18:33 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-3ea1ea43-entity-operator rolling update finished
2022-04-05 23:18:33 [main] [32mINFO [m [SecurityST:1624] Initial ClientsCA cert dates: Tue Apr 05 23:14:50 UTC 2022 --> Mon Apr 25 23:14:50 UTC 2022
2022-04-05 23:18:33 [main] [32mINFO [m [SecurityST:1625] Changed ClientsCA cert dates: Tue Apr 05 23:16:04 UTC 2022 --> Sat Oct 22 23:16:04 UTC 2022
2022-04-05 23:18:33 [main] [32mINFO [m [SecurityST:1626] Initial userCert dates: Tue Apr 05 23:16:03 UTC 2022 --> Mon Apr 25 23:16:03 UTC 2022
2022-04-05 23:18:33 [main] [32mINFO [m [SecurityST:1627] Changed userCert dates: Tue Apr 05 23:17:52 UTC 2022 --> Sat Oct 22 23:17:52 UTC 2022
2022-04-05 23:18:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:18:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientsCACertRenew
2022-04-05 23:18:33 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser strimzi-tls-user-2122922460 in namespace namespace-72
2022-04-05 23:18:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3ea1ea43 in namespace namespace-72
2022-04-05 23:18:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:18:43 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-72 for test case:testClientsCACertRenew
2022-04-05 23:19:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testClientsCACertRenew-FINISHED
2022-04-05 23:19:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:19:27 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:19:27 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.SecurityST.testCertificates-STARTED
2022-04-05 23:19:27 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:19:27 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-73 for test case:testCertificates
2022-04-05 23:19:27 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-73
2022-04-05 23:19:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-73
2022-04-05 23:19:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-73
2022-04-05 23:19:27 [main] [32mINFO [m [SecurityST:118] Running testCertificates my-cluster-4989bea9
2022-04-05 23:19:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4989bea9 in namespace namespace-73
2022-04-05 23:19:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-73
2022-04-05 23:19:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4989bea9 will have desired state: Ready
2022-04-05 23:20:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4989bea9 is in desired state: Ready
2022-04-05 23:20:48 [main] [32mINFO [m [SecurityST:122] Check Kafka bootstrap certificate
2022-04-05 23:20:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-kafka-bootstrap:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-kafka-bootstrap
2022-04-05 23:20:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:48 [main] [32mINFO [m [SecurityST:125] OPENSSL OUTPUT: 

CONNECTED(00000003)
---
Certificate chain
 0 s:O = io.strimzi, CN = my-cluster-4989bea9-kafka
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----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-----END CERTIFICATE-----
 1 s:O = io.strimzi, CN = cluster-ca v0
   i:O = io.strimzi, CN = cluster-ca v0
-----BEGIN CERTIFICATE-----
MIIFLTCCAxWgAwIBAgIUT1JfQpT0/khl9pImkXJnC7tSSxcwDQYJKoZIhvcNAQEN
BQAwLTETMBEGA1UECgwKaW8uc3RyaW16aTEWMBQGA1UEAwwNY2x1c3Rlci1jYSB2
MDAeFw0yMjA0MDUyMzE5MjdaFw0yMzA0MDUyMzE5MjdaMC0xEzARBgNVBAoMCmlv
LnN0cmltemkxFjAUBgNVBAMMDWNsdXN0ZXItY2EgdjAwggIiMA0GCSqGSIb3DQEB
AQUAA4ICDwAwggIKAoICAQDLgZZTndsf+wKypCPG/x8P+SxoiT3NsYHwQnUuP1vD
n5F2j5dohlQMkZhsZNcl64xoxOiuZYI9fQpdS6WXz1g+9CPxkVw0rlnsyPv8m05L
2Y80MYMLpsl1caHNqi7Teroo1vR+J5wlSyWBO+Mi4auxUhuzRkjtwtj3qnQ+MyzO
1fJ0fR2g212+BkhUoor3RRjGDk2KbHnBu6mKTN8E5L0zHu8b8+W6yem9vEkctzDT
1wEYoTgVYKLre0ahY2yswT6U+feXwKKtviRo0trV6PWcR2iGXlYahEsaRMIndvjY
zzos4INVfFDc87EgMM8kA/c7HwQwZRJp8r8P/yaPINphNNi/2wSnkgKfw4F63N9M
9OgyzbU5mVGi29EinbziItBMkZyjKW2e01XvM9fMYSEgOJjpbsUTUyeCAluRPyk6
1pXf7pOpQ0/DqnlqCgBZmHqP/YdbvmBHly0Q3uydwuGRw926qBCvrfw0XJ4GCQzH
+vBWVuhFZPU91+WP4M68Xmx5kGo9aaQNlAcmDQD0JBbtdlHR6e0RMgWm+JcGzZOb
6+pAts8zGpehLLZYNZICmrzDawF60019i23ulWVbhGBRS/gl9xbo4UyyMZLvYNaG
RUjc94zVAZMdOTE6mnWGBOxf07kQvuGgwjKNhWGyzuPmooYOkQdV07UXbmF2LV8N
jQIDAQABo0UwQzAdBgNVHQ4EFgQUHAJYLxKoR6TIIhVtCU9Uh/2f0/EwEgYDVR0T
AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAQYwDQYJKoZIhvcNAQENBQADggIB
ABAuOQWNNsE9rSqHIbZeuPLW9RD7lnTsZCugub3eFqbOlYt5z4cuEh7opz18Jk6F
PPefjtYIbt5ISw0qizsZkuJGUiiUjFmStIRypF45mMrdto0pp6VnW6LPH6z4HFV5
Zn/t0AcdUUB7Xb7EMIbYQid1T7Vn9QjeXzsBUvQmpLbmTiKb5YNf1xZugtBQyJTr
tSGdGA/BfpKXBPxWxStcD1bNTggm2Frt5z/lCwqNFcxT9yD6W6SFhoLgManvoMzp
/XfdglC1R6KlgLAdCqVpWCNU8gipjlMAN55lR2WUNXKi7rbDbaXjvIzD0wsunzAW
1c3Hig0B3zUo6wzuuKdaYdkq0OZxAFocdMxhCZa18cYaefaZ7JZM26RKwxX5gzg/
iD59arBzbyYiK8fyGC24QYsduOyF2nMWIt2dDVcCi7cBULuE5Povr7P7VPPncKxi
rvGD0O++DH2QZVwMhPGqHHquRWbyMb6ZoTc3HvfI4Vt3x8U2EsCYaHfMAhPJ+Wq4
ZQyi5wRE4hvgE1t4HV/uS4mk2KMVzIqXG75azevuouYvkSmCVJOeFrocCKIh35Jd
x9wVqGW3VGaKhZdaonWobZUoMTYLsYoGYQe4cmvSHJmTm6yju/9fjryDvZODvcYL
X34h1hQFwWEGnKr0pH2Tu4iBkPGiVnzyUjlgt9e88NrK
-----END CERTIFICATE-----
---
Server certificate
subject=O = io.strimzi, CN = my-cluster-4989bea9-kafka

issuer=O = io.strimzi, CN = cluster-ca v0

---
No client certificate CA names sent
Peer signing digest: SHA256
Peer signature type: RSA-PSS
Server Temp Key: X25519, 253 bits
---
SSL handshake has read 3489 bytes and written 369 bytes
Verification: OK
Verified peername: my-cluster-4989bea9-kafka-bootstrap
---
New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384
Server public key is 2048 bit
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
Early data was not sent
Verify return code: 0 (ok)
---



2022-04-05 23:20:48 [main] [32mINFO [m [SecurityST:128] Check zookeeper client certificate
2022-04-05 23:20:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-zookeeper-client:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-zookeeper-client -cert /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-0.key
2022-04-05 23:20:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:49 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 0
2022-04-05 23:20:49 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-05 23:20:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-kafka-0.my-cluster-4989bea9-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-kafka-0.my-cluster-4989bea9-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-0.key
2022-04-05 23:20:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:49 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-05 23:20:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-kafka-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-kafka-0.my-cluster-4989bea9-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-kafka-0.my-cluster-4989bea9-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-0.crt -key /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-0.key
2022-04-05 23:20:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:49 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-05 23:20:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-zookeeper-0.my-cluster-4989bea9-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-zookeeper-0.my-cluster-4989bea9-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-4989bea9-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-4989bea9-zookeeper-0.key
2022-04-05 23:20:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:50 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-05 23:20:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-zookeeper-0 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-zookeeper-0.my-cluster-4989bea9-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-zookeeper-0.my-cluster-4989bea9-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-4989bea9-zookeeper-0.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-4989bea9-zookeeper-0.key
2022-04-05 23:20:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:50 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 1
2022-04-05 23:20:50 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-05 23:20:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-kafka-1.my-cluster-4989bea9-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-kafka-1.my-cluster-4989bea9-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-1.key
2022-04-05 23:20:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:50 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-05 23:20:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-kafka-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-kafka-1.my-cluster-4989bea9-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-kafka-1.my-cluster-4989bea9-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-1.crt -key /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-1.key
2022-04-05 23:20:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:50 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-05 23:20:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-zookeeper-1.my-cluster-4989bea9-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-zookeeper-1.my-cluster-4989bea9-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-4989bea9-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-4989bea9-zookeeper-1.key
2022-04-05 23:20:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:51 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-05 23:20:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-zookeeper-1 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-zookeeper-1.my-cluster-4989bea9-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-zookeeper-1.my-cluster-4989bea9-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-4989bea9-zookeeper-1.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-4989bea9-zookeeper-1.key
2022-04-05 23:20:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:51 [main] [32mINFO [m [SecurityST:139] Checking certificates for podId 2
2022-04-05 23:20:51 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9091
2022-04-05 23:20:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-kafka-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-kafka-2.my-cluster-4989bea9-kafka-brokers:9091 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-kafka-2.my-cluster-4989bea9-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-2.crt -key /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-2.key
2022-04-05 23:20:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:51 [main] [32mINFO [m [SecurityST:141] Check kafka certificate for port 9093
2022-04-05 23:20:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-kafka-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-kafka-2.my-cluster-4989bea9-kafka-brokers:9093 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-kafka-2.my-cluster-4989bea9-kafka-brokers.namespace-73.svc.cluster.local -cert /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-2.crt -key /opt/kafka/broker-certs/my-cluster-4989bea9-kafka-2.key
2022-04-05 23:20:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:51 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 2181
2022-04-05 23:20:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-zookeeper-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-zookeeper-2.my-cluster-4989bea9-zookeeper-nodes:2181 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-zookeeper-2.my-cluster-4989bea9-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-4989bea9-zookeeper-2.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-4989bea9-zookeeper-2.key
2022-04-05 23:20:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:51 [main] [32mINFO [m [SecurityST:148] Check zookeeper certificate for port 3888
2022-04-05 23:20:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-73 exec my-cluster-4989bea9-zookeeper-2 -- /bin/bash -c echo -n | openssl s_client -connect my-cluster-4989bea9-zookeeper-2.my-cluster-4989bea9-zookeeper-nodes:3888 -showcerts -CAfile /opt/kafka/cluster-ca-certs/ca.crt -verify_hostname my-cluster-4989bea9-zookeeper-2.my-cluster-4989bea9-zookeeper-nodes.namespace-73.svc.cluster.local -cert /opt/kafka/zookeeper-node-certs/my-cluster-4989bea9-zookeeper-2.crt -key /opt/kafka/zookeeper-node-certs/my-cluster-4989bea9-zookeeper-2.key
2022-04-05 23:20:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-05 23:20:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:20:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCertificates
2022-04-05 23:20:52 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4989bea9 in namespace namespace-73
2022-04-05 23:21:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:21:02 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-73 for test case:testCertificates
2022-04-05 23:21:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.SecurityST.testCertificates-FINISHED
2022-04-05 23:21:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:21:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:21:45 [main] [32mINFO [m [ResourceManager:346] In context SecurityST is everything deleted.
2022-04-05 23:21:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10,070.288 s - in io.strimzi.systemtest.security.SecurityST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
2022-04-05 23:21:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: alternative-reconcile-triggers-st
2022-04-05 23:21:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: alternative-reconcile-triggers-st
2022-04-05 23:21:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: alternative-reconcile-triggers-st
2022-04-05 23:21:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:21:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualRollingUpdateForSinglePod-STARTED
2022-04-05 23:21:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:21:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-74 for test case:testManualRollingUpdateForSinglePod
2022-04-05 23:21:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-74
2022-04-05 23:21:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-74
2022-04-05 23:21:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-74
2022-04-05 23:21:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-668c44d0 in namespace namespace-74
2022-04-05 23:21:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-74
2022-04-05 23:21:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-668c44d0 will have desired state: Ready
2022-04-05 23:23:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-668c44d0 is in desired state: Ready
2022-04-05 23:23:09 [main] [32mINFO [m [AlternativeReconcileTriggersST:290] Trying to roll just single Kafka and single ZK pod
2022-04-05 23:23:09 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-668c44d0-kafka rolling update
2022-04-05 23:23:19 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-668c44d0-kafka has been successfully rolled
2022-04-05 23:23:19 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-668c44d0-kafka to be ready
2022-04-05 23:23:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-668c44d0 will have desired state: Ready
2022-04-05 23:23:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-668c44d0 is in desired state: Ready
2022-04-05 23:23:42 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-668c44d0 is ready
2022-04-05 23:23:42 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-668c44d0-zookeeper rolling update
2022-04-05 23:24:02 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-668c44d0-zookeeper has been successfully rolled
2022-04-05 23:24:02 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-668c44d0-zookeeper to be ready
2022-04-05 23:24:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-668c44d0 will have desired state: Ready
2022-04-05 23:24:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-668c44d0 is in desired state: Ready
2022-04-05 23:24:33 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-668c44d0 is ready
2022-04-05 23:24:33 [main] [32mINFO [m [AlternativeReconcileTriggersST:311] Adding anno to all ZK and Kafka pods
2022-04-05 23:24:33 [main] [32mINFO [m [AlternativeReconcileTriggersST:320] Checking if the rolling update will be successful for Kafka
2022-04-05 23:24:33 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-668c44d0-kafka rolling update
2022-04-05 23:26:09 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-668c44d0-kafka has been successfully rolled
2022-04-05 23:26:09 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-668c44d0-kafka to be ready
2022-04-05 23:26:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-668c44d0 will have desired state: Ready
2022-04-05 23:26:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-668c44d0 is in desired state: Ready
2022-04-05 23:26:31 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-668c44d0 is ready
2022-04-05 23:26:31 [main] [32mINFO [m [AlternativeReconcileTriggersST:331] Checking if the rolling update will be successful for ZK
2022-04-05 23:26:31 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-668c44d0-zookeeper rolling update
2022-04-05 23:28:01 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-668c44d0-zookeeper has been successfully rolled
2022-04-05 23:28:01 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-668c44d0-zookeeper to be ready
2022-04-05 23:28:29 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-668c44d0 will have desired state: Ready
2022-04-05 23:28:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-668c44d0 is in desired state: Ready
2022-04-05 23:28:29 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-668c44d0 is ready
2022-04-05 23:28:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:28:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualRollingUpdateForSinglePod
2022-04-05 23:28:29 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-668c44d0 in namespace namespace-74
2022-04-05 23:28:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:28:39 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-74 for test case:testManualRollingUpdateForSinglePod
2022-04-05 23:29:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualRollingUpdateForSinglePod-FINISHED
2022-04-05 23:29:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:29:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:29:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualTriggeringRollingUpdate-STARTED
2022-04-05 23:29:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:29:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-75 for test case:testManualTriggeringRollingUpdate
2022-04-05 23:29:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-75
2022-04-05 23:29:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-75
2022-04-05 23:29:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-75
2022-04-05 23:29:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-30ff252e in namespace namespace-75
2022-04-05 23:29:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:29:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-30ff252e will have desired state: Ready
2022-04-05 23:30:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-30ff252e is in desired state: Ready
2022-04-05 23:30:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-272747812-977360427 in namespace namespace-75
2022-04-05 23:30:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:30:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-272747812-977360427 will have desired state: Ready
2022-04-05 23:30:44 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-272747812-977360427 is in desired state: Ready
2022-04-05 23:30:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic continuous-topic in namespace namespace-75
2022-04-05 23:30:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:30:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: continuous-topic will have desired state: Ready
2022-04-05 23:30:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: continuous-topic is in desired state: Ready
2022-04-05 23:30:45 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 23:30:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace namespace-75
2022-04-05 23:30:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:30:45 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-05 23:30:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace namespace-75
2022-04-05 23:30:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:30:46 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-05 23:30:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2129836981-1945389035 in namespace namespace-75
2022-04-05 23:30:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:30:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2129836981-1945389035 will have desired state: Ready
2022-04-05 23:30:47 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2129836981-1945389035 is in desired state: Ready
2022-04-05 23:30:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-30ff252e-kafka-clients in namespace namespace-75
2022-04-05 23:30:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:30:57 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 23:30:57 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@86dc55a, messages=[], arguments=[USER=my_user_2129836981_1945389035, --bootstrap-server, my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093, --max-messages, 100, --topic, my-topic-272747812-977360427], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf', podNamespace='namespace-75', bootstrapServer='my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-272747812-977360427', maxMessages=100, kafkaUsername='my-user-2129836981-1945389035', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@9251ac}
2022-04-05 23:30:57 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093:my-topic-272747812-977360427 from pod my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf
2022-04-05 23:30:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf -n namespace-75 -- /opt/kafka/producer.sh USER=my_user_2129836981_1945389035 --bootstrap-server my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093 --max-messages 100 --topic my-topic-272747812-977360427
2022-04-05 23:31:01 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 23:31:01 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 23:31:01 [main] [32mINFO [m [AlternativeReconcileTriggersST:145] Annotate Kafka StatefulSet my-cluster-30ff252e-kafka with manual rolling update annotation
2022-04-05 23:31:01 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-30ff252e-kafka rolling update
2022-04-05 23:32:46 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-30ff252e-kafka has been successfully rolled
2022-04-05 23:32:46 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-30ff252e-kafka to be ready
2022-04-05 23:33:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-30ff252e will have desired state: Ready
2022-04-05 23:33:15 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-30ff252e is in desired state: Ready
2022-04-05 23:33:15 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-30ff252e is ready
2022-04-05 23:33:15 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@77e46988, messages=[], arguments=[USER=my_user_2129836981_1945389035, --group-id, my-consumer-group-2045958487, --bootstrap-server, my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093, --group-instance-id, instance2977245, --max-messages, 100, --topic, my-topic-272747812-977360427], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf', podNamespace='namespace-75', bootstrapServer='my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-272747812-977360427', maxMessages=100, kafkaUsername='my-user-2129836981-1945389035', consumerGroupName='my-consumer-group-2045958487', consumerInstanceId='instance2977245', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7cb26ec8}
2022-04-05 23:33:15 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093:my-topic-272747812-977360427 from pod my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf
2022-04-05 23:33:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf -n namespace-75 -- /opt/kafka/consumer.sh USER=my_user_2129836981_1945389035 --group-id my-consumer-group-2045958487 --bootstrap-server my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093 --group-instance-id instance2977245 --max-messages 100 --topic my-topic-272747812-977360427
2022-04-05 23:33:22 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 23:33:22 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 23:33:22 [main] [32mINFO [m [AlternativeReconcileTriggersST:166] Annotate Zookeeper StatefulSet my-cluster-30ff252e-zookeeper with manual rolling update annotation
2022-04-05 23:33:22 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-30ff252e-zookeeper rolling update
2022-04-05 23:34:37 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-30ff252e-zookeeper has been successfully rolled
2022-04-05 23:34:37 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-30ff252e-zookeeper to be ready
2022-04-05 23:35:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-30ff252e will have desired state: Ready
2022-04-05 23:35:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-30ff252e is in desired state: Ready
2022-04-05 23:35:12 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-30ff252e is ready
2022-04-05 23:35:12 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3cb4a8af, messages=[], arguments=[USER=my_user_2129836981_1945389035, --group-id, my-consumer-group-505300525, --bootstrap-server, my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093, --group-instance-id, instance1474596076, --max-messages, 100, --topic, my-topic-272747812-977360427], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf', podNamespace='namespace-75', bootstrapServer='my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-272747812-977360427', maxMessages=100, kafkaUsername='my-user-2129836981-1945389035', consumerGroupName='my-consumer-group-505300525', consumerInstanceId='instance1474596076', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@375c0b0}
2022-04-05 23:35:12 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093:my-topic-272747812-977360427 from pod my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf
2022-04-05 23:35:12 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf -n namespace-75 -- /opt/kafka/consumer.sh USER=my_user_2129836981_1945389035 --group-id my-consumer-group-505300525 --bootstrap-server my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093 --group-instance-id instance1474596076 --max-messages 100 --topic my-topic-272747812-977360427
2022-04-05 23:35:19 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 23:35:19 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 23:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1353814606-1230073429 in namespace namespace-75
2022-04-05 23:35:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-75
2022-04-05 23:35:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1353814606-1230073429 will have desired state: Ready
2022-04-05 23:35:20 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1353814606-1230073429 is in desired state: Ready
2022-04-05 23:35:20 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7227d058, messages=[], arguments=[USER=my_user_2129836981_1945389035, --bootstrap-server, my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093, --max-messages, 100, --topic, my-topic-1353814606-1230073429], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf', podNamespace='namespace-75', bootstrapServer='my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-1353814606-1230073429', maxMessages=100, kafkaUsername='my-user-2129836981-1945389035', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5f7aeb47}
2022-04-05 23:35:20 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093:my-topic-1353814606-1230073429 from pod my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf
2022-04-05 23:35:20 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf -n namespace-75 -- /opt/kafka/producer.sh USER=my_user_2129836981_1945389035 --bootstrap-server my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093 --max-messages 100 --topic my-topic-1353814606-1230073429
2022-04-05 23:35:24 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 23:35:24 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 23:35:24 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@118e1b5b, messages=[], arguments=[USER=my_user_2129836981_1945389035, --group-id, my-consumer-group-1113606429, --bootstrap-server, my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093, --group-instance-id, instance1847510415, --max-messages, 100, --topic, my-topic-1353814606-1230073429], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf', podNamespace='namespace-75', bootstrapServer='my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093', topicName='my-topic-1353814606-1230073429', maxMessages=100, kafkaUsername='my-user-2129836981-1945389035', consumerGroupName='my-consumer-group-1113606429', consumerInstanceId='instance1847510415', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6b4fff63}
2022-04-05 23:35:24 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093:my-topic-1353814606-1230073429 from pod my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf
2022-04-05 23:35:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-30ff252e-kafka-clients-7cd45474cb-ngrlf -n namespace-75 -- /opt/kafka/consumer.sh USER=my_user_2129836981_1945389035 --group-id my-consumer-group-1113606429 --bootstrap-server my-cluster-30ff252e-kafka-bootstrap.namespace-75.svc:9093 --group-instance-id instance1847510415 --max-messages 100 --topic my-topic-1353814606-1230073429
2022-04-05 23:35:31 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-05 23:35:31 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-05 23:35:31 [main] [32mINFO [m [ClientUtils:61] Waiting till producer hello-world-producer and consumer hello-world-consumer finish
2022-04-05 23:39:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:39:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualTriggeringRollingUpdate
2022-04-05 23:39:33 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2129836981-1945389035 in namespace namespace-75
2022-04-05 23:39:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic continuous-topic in namespace namespace-75
2022-04-05 23:39:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1353814606-1230073429 in namespace namespace-75
2022-04-05 23:39:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace namespace-75
2022-04-05 23:39:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-272747812-977360427 in namespace namespace-75
2022-04-05 23:39:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace namespace-75
2022-04-05 23:39:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-30ff252e-kafka-clients in namespace namespace-75
2022-04-05 23:39:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-30ff252e in namespace namespace-75
2022-04-05 23:40:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:40:33 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-75 for test case:testManualTriggeringRollingUpdate
2022-04-05 23:40:39 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testManualTriggeringRollingUpdate-FINISHED
2022-04-05 23:40:39 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:40:39 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:40:39 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testAddingAndRemovingJbodVolumes-STARTED
2022-04-05 23:40:39 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:40:39 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-76 for test case:testAddingAndRemovingJbodVolumes
2022-04-05 23:40:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-76
2022-04-05 23:40:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-76
2022-04-05 23:40:39 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-76
2022-04-05 23:40:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-89be7739 in namespace namespace-76
2022-04-05 23:40:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:40:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-89be7739 will have desired state: Ready
2022-04-05 23:41:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-89be7739 is in desired state: Ready
2022-04-05 23:41:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1454314506-403307155 in namespace namespace-76
2022-04-05 23:41:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:41:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1454314506-403307155 will have desired state: Ready
2022-04-05 23:41:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1454314506-403307155 is in desired state: Ready
2022-04-05 23:41:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic continuous-topic in namespace namespace-76
2022-04-05 23:41:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:41:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: continuous-topic will have desired state: Ready
2022-04-05 23:42:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: continuous-topic is in desired state: Ready
2022-04-05 23:42:00 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-05 23:42:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace namespace-76
2022-04-05 23:42:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:42:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-05 23:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace namespace-76
2022-04-05 23:42:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:42:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-05 23:42:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-2125665822-111159654 in namespace namespace-76
2022-04-05 23:42:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:42:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-2125665822-111159654 will have desired state: Ready
2022-04-05 23:42:03 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-2125665822-111159654 is in desired state: Ready
2022-04-05 23:42:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-89be7739-kafka-clients in namespace namespace-76
2022-04-05 23:42:03 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-76
2022-04-05 23:42:13 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-05 23:42:13 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3ad17187, messages=[], arguments=[USER=my_user_2125665822_111159654, --bootstrap-server, my-cluster-89be7739-kafka-bootstrap.namespace-76.svc:9093, --max-messages, 100, --topic, my-topic-1454314506-403307155], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-89be7739-kafka-clients-5b7985d5d6-4q8lv', podNamespace='namespace-76', bootstrapServer='my-cluster-89be7739-kafka-bootstrap.namespace-76.svc:9093', topicName='my-topic-1454314506-403307155', maxMessages=100, kafkaUsername='my-user-2125665822-111159654', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1ab904bc}
2022-04-05 23:42:13 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-89be7739-kafka-bootstrap.namespace-76.svc:9093:my-topic-1454314506-403307155 from pod my-cluster-89be7739-kafka-clients-5b7985d5d6-4q8lv
2022-04-05 23:42:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-89be7739-kafka-clients-5b7985d5d6-4q8lv -n namespace-76 -- /opt/kafka/producer.sh USER=my_user_2125665822_111159654 --bootstrap-server my-cluster-89be7739-kafka-bootstrap.namespace-76.svc:9093 --max-messages 100 --topic my-topic-1454314506-403307155
2022-04-05 23:42:17 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-05 23:42:17 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-05 23:42:17 [main] [32mINFO [m [AlternativeReconcileTriggersST:408] Add JBOD volume to the Kafka cluster my-cluster-89be7739-kafka
2022-04-05 23:42:17 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-89be7739-kafka rolling update
2022-04-05 23:43:22 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-89be7739-kafka has been successfully rolled
2022-04-05 23:43:22 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-89be7739-kafka to be ready
2022-04-05 23:43:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-89be7739 will have desired state: Ready
2022-04-05 23:43:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-89be7739 is in desired state: Ready
2022-04-05 23:43:52 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-89be7739 is ready
2022-04-05 23:43:52 [main] [32mINFO [m [AlternativeReconcileTriggersST:419] Remove JBOD volume to the Kafka cluster my-cluster-89be7739-kafka
2022-04-05 23:43:52 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-89be7739-kafka rolling update
2022-04-05 23:44:57 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-89be7739-kafka has been successfully rolled
2022-04-05 23:44:57 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-89be7739-kafka to be ready
2022-04-05 23:45:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-89be7739 will have desired state: Ready
2022-04-05 23:45:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-89be7739 is in desired state: Ready
2022-04-05 23:45:22 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-89be7739 is ready
2022-04-05 23:45:22 [main] [32mINFO [m [ClientUtils:61] Waiting till producer hello-world-producer and consumer hello-world-consumer finish
2022-04-05 23:51:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:51:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAddingAndRemovingJbodVolumes
2022-04-05 23:51:26 [main] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace namespace-76
2022-04-05 23:51:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1454314506-403307155 in namespace namespace-76
2022-04-05 23:51:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-89be7739 in namespace namespace-76
2022-04-05 23:51:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic continuous-topic in namespace namespace-76
2022-04-05 23:51:26 [main] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace namespace-76
2022-04-05 23:51:26 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-89be7739-kafka-clients in namespace namespace-76
2022-04-05 23:51:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-2125665822-111159654 in namespace namespace-76
2022-04-05 23:52:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:52:26 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-76 for test case:testAddingAndRemovingJbodVolumes
2022-04-05 23:52:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testAddingAndRemovingJbodVolumes-FINISHED
2022-04-05 23:52:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:52:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:52:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testTriggerRollingUpdateAfterOverrideBootstrap-STARTED
2022-04-05 23:52:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:52:37 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-77 for test case:testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-05 23:52:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-77
2022-04-05 23:52:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-77
2022-04-05 23:52:38 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-77
2022-04-05 23:52:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8a487e6b in namespace namespace-77
2022-04-05 23:52:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-77
2022-04-05 23:52:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8a487e6b will have desired state: Ready
2022-04-05 23:53:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8a487e6b is in desired state: Ready
2022-04-05 23:53:51 [main] [32mINFO [m [AlternativeReconcileTriggersST:228] Adding new bootstrap dns: kafka-test.XXXX.azure.XXXX.net to external listeners
2022-04-05 23:53:51 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-8a487e6b-kafka rolling update
2022-04-05 23:55:06 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-8a487e6b-kafka has been successfully rolled
2022-04-05 23:55:06 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-8a487e6b-kafka to be ready
2022-04-05 23:55:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8a487e6b will have desired state: Ready
2022-04-05 23:55:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8a487e6b is in desired state: Ready
2022-04-05 23:55:33 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-8a487e6b is ready
2022-04-05 23:55:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8a487e6b will have desired state: Ready
2022-04-05 23:55:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8a487e6b is in desired state: Ready
2022-04-05 23:55:33 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-8a487e6b-kafka-0.crt cert
2022-04-05 23:55:33 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-05 23:55:33 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-8a487e6b-kafka-1.crt cert
2022-04-05 23:55:33 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-05 23:55:33 [main] [32mINFO [m [AlternativeReconcileTriggersST:258] Encoding my-cluster-8a487e6b-kafka-2.crt cert
2022-04-05 23:55:33 [main] [32mINFO [m [AlternativeReconcileTriggersST:263] Verifying that new DNS is in certificate subject alternative names
2022-04-05 23:55:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:55:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-05 23:55:33 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8a487e6b in namespace namespace-77
2022-04-05 23:55:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-05 23:55:43 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-77 for test case:testTriggerRollingUpdateAfterOverrideBootstrap
2022-04-05 23:56:27 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST.testTriggerRollingUpdateAfterOverrideBootstrap-FINISHED
2022-04-05 23:56:27 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-05 23:56:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-05 23:56:27 [main] [32mINFO [m [ResourceManager:346] In context AlternativeReconcileTriggersST is everything deleted.
2022-04-05 23:56:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,081.629 s - in io.strimzi.systemtest.rollingupdate.AlternativeReconcileTriggersST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.RollingUpdateST
2022-04-05 23:56:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: rolling-update-st
2022-04-05 23:56:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: rolling-update-st
2022-04-05 23:56:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: rolling-update-st
2022-04-05 23:56:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-05 23:56:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testMetricsChange-STARTED
2022-04-05 23:56:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-05 23:56:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9d26bf59 in namespace rolling-update-st
2022-04-05 23:56:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9d26bf59 will have desired state: Ready
2022-04-05 23:58:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9d26bf59 is in desired state: Ready
2022-04-05 23:58:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-9d26bf59-kafka-clients in namespace rolling-update-st
2022-04-05 23:58:37 [main] [32mINFO [m [RollingUpdateST:755] Check if metrics are present in pod of Kafka and Zookeeper
2022-04-05 23:58:37 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 0
2022-04-05 23:58:38 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 0
2022-04-05 23:58:39 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 0
2022-04-05 23:58:39 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 0
2022-04-05 23:58:40 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 0
2022-04-05 23:58:40 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 0
2022-04-05 23:58:40 [main] [32mINFO [m [RollingUpdateST:765] Changing metrics to something else
2022-04-05 23:58:40 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-9d26bf59-zookeeper are stable
2022-04-05 23:58:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 23:58:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 23:58:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 23:58:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 23:58:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 23:58:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 23:58:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 23:58:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 23:58:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 23:58:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 23:58:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 23:58:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 23:58:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 23:58:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 23:58:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 23:58:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 23:58:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 23:58:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 23:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 23:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 23:58:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 23:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 23:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 23:58:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 23:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 23:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 23:58:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 23:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 23:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 23:58:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 23:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 23:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 23:58:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 23:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 23:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 23:58:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 23:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 23:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 23:58:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 23:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 23:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 23:58:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 23:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 23:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 23:58:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 23:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 23:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 23:58:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 23:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 23:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 23:58:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 23:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 23:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 23:58:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 23:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 23:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 23:58:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 23:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 23:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 23:59:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 23:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 23:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 23:59:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 23:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 23:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 23:59:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 23:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 23:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 23:59:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 23:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 23:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 23:59:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 23:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 23:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 23:59:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 23:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 23:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 23:59:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 23:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 23:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 23:59:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 23:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 23:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 23:59:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 23:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 23:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 23:59:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 23:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 23:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 23:59:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 23:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 23:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 23:59:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-05 23:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 23:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 23:59:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-05 23:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 23:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 23:59:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-05 23:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 23:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 23:59:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-05 23:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 23:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 23:59:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-05 23:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 23:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 23:59:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-05 23:59:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 23:59:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 23:59:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-05 23:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 23:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 23:59:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-05 23:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 23:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 23:59:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-05 23:59:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 23:59:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 23:59:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-05 23:59:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 23:59:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 23:59:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-05 23:59:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 23:59:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 23:59:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-05 23:59:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 23:59:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 23:59:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-05 23:59:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 23:59:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 23:59:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-05 23:59:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 23:59:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 23:59:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-05 23:59:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 23:59:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 23:59:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-05 23:59:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 23:59:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 23:59:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-05 23:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 23:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 23:59:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-05 23:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 23:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 23:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-05 23:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 23:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 23:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-05 23:59:30 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-9d26bf59-zookeeper-0 ,my-cluster-9d26bf59-zookeeper-1 ,my-cluster-9d26bf59-zookeeper-2
2022-04-05 23:59:30 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-9d26bf59-kafka are stable
2022-04-05 23:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 23:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 23:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 23:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 23:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 50
2022-04-05 23:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 23:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 23:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 23:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 23:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 49
2022-04-05 23:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 23:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 23:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 23:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 23:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 48
2022-04-05 23:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 23:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 23:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 23:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 23:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 47
2022-04-05 23:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 23:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 23:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 23:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 23:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 46
2022-04-05 23:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 23:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 23:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 23:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 23:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 45
2022-04-05 23:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 23:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 23:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 23:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 23:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 44
2022-04-05 23:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 23:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 23:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 23:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 23:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 43
2022-04-05 23:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 23:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 23:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 23:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 23:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 42
2022-04-05 23:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 23:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 23:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 23:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 23:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 41
2022-04-05 23:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 23:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 23:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 23:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 23:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 40
2022-04-05 23:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 23:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 23:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 23:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 23:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 39
2022-04-05 23:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 23:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 23:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 23:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 23:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 38
2022-04-05 23:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 23:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 23:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 23:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 23:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 37
2022-04-05 23:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 23:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 23:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 23:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 23:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 36
2022-04-05 23:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 23:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 23:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 23:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 23:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 35
2022-04-05 23:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 23:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 23:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 23:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 23:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 34
2022-04-05 23:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 23:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 23:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 23:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 23:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 33
2022-04-05 23:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 23:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 23:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 23:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 23:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 32
2022-04-05 23:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 23:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 23:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 23:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 23:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 31
2022-04-05 23:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 23:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 23:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 23:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 23:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 30
2022-04-05 23:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 23:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 23:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 23:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 23:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 29
2022-04-05 23:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 23:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 23:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 23:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 23:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 28
2022-04-05 23:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 23:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 23:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 23:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 23:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 27
2022-04-05 23:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 23:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 23:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 23:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 23:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 26
2022-04-05 23:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 23:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 23:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 23:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 23:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 25
2022-04-05 23:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 23:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 23:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 23:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 23:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 24
2022-04-05 23:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 23:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 23:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 23:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 23:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 23
2022-04-05 23:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 23:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 23:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 23:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 23:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 22
2022-04-05 23:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 23:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 23:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 23:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 21
2022-04-05 23:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:00:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:00:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:00:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:00:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:00:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:00:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:00:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:00:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:00:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:00:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:00:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:00:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:00:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:00:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:00:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:00:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:00:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:00:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:00:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:00:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:00:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:00:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:00:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:00:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:00:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:00:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:00:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:00:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:00:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:00:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:00:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:00:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:00:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:00:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:00:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:00:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:00:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:00:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:00:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:00:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:00:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:00:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:00:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:00:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:00:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:00:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:00:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:00:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:00:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:00:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:00:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:00:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:00:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:00:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:00:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:00:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:00:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:00:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:00:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:00:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:00:20 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-9d26bf59-kafka-0 ,my-cluster-9d26bf59-kafka-1 ,my-cluster-9d26bf59-kafka-2 ,my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl ,my-cluster-9d26bf59-kafka-exporter-7f55786cdd-vsslq
2022-04-06 00:00:20 [main] [32mINFO [m [RollingUpdateST:800] Check if Kafka and Zookeeper pods didn't roll
2022-04-06 00:00:20 [main] [32mINFO [m [RollingUpdateST:804] Check if Kafka and Zookeeper metrics are changed
2022-04-06 00:00:20 [main] [32mINFO [m [RollingUpdateST:818] Check if metrics are present in pod of Kafka and Zookeeper
2022-04-06 00:00:20 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 0
2022-04-06 00:00:21 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 0
2022-04-06 00:00:21 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 0
2022-04-06 00:00:21 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 0
2022-04-06 00:00:21 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 0
2022-04-06 00:00:22 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 0
2022-04-06 00:00:22 [main] [32mINFO [m [RollingUpdateST:829] Removing metrics from Kafka and Zookeeper and setting them to null
2022-04-06 00:00:22 [main] [32mINFO [m [RollingUpdateST:836] Wait if Kafka and Zookeeper pods will roll
2022-04-06 00:00:22 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-9d26bf59-zookeeper rolling update
2022-04-06 00:01:17 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-9d26bf59-zookeeper has been successfully rolled
2022-04-06 00:01:17 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-9d26bf59-zookeeper to be ready
2022-04-06 00:01:42 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-9d26bf59-kafka rolling update
2022-04-06 00:02:47 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-9d26bf59-kafka has been successfully rolled
2022-04-06 00:02:47 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-9d26bf59-kafka to be ready
2022-04-06 00:03:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9d26bf59 will have desired state: Ready
2022-04-06 00:03:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9d26bf59 is in desired state: Ready
2022-04-06 00:03:16 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-9d26bf59 is ready
2022-04-06 00:03:16 [main] [32mINFO [m [RollingUpdateST:840] Check if metrics are not existing in pods
2022-04-06 00:03:16 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 7
2022-04-06 00:03:17 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.12 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 7
2022-04-06 00:03:17 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 7
2022-04-06 00:03:17 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.7 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 7
2022-04-06 00:03:17 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.8 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 7
2022-04-06 00:03:17 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod my-cluster-9d26bf59-kafka-clients-867464479f-bbxdl finished with return code: 7
2022-04-06 00:03:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:03:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMetricsChange
2022-04-06 00:03:17 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-9d26bf59-kafka-clients in namespace rolling-update-st
2022-04-06 00:03:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9d26bf59 in namespace rolling-update-st
2022-04-06 00:04:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:04:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testMetricsChange-FINISHED
2022-04-06 00:04:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:04:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:04:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testExternalLoggingChangeTriggerRollingUpdate-STARTED
2022-04-06 00:04:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:04:08 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-78 for test case:testExternalLoggingChangeTriggerRollingUpdate
2022-04-06 00:04:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-78
2022-04-06 00:04:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-78
2022-04-06 00:04:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-78
2022-04-06 00:04:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-d157ef52 in namespace namespace-78
2022-04-06 00:04:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-78
2022-04-06 00:04:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d157ef52 will have desired state: Ready
2022-04-06 00:05:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d157ef52 is in desired state: Ready
2022-04-06 00:05:23 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d157ef52-zookeeper rolling update
2022-04-06 00:06:23 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d157ef52-zookeeper has been successfully rolled
2022-04-06 00:06:23 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-d157ef52-zookeeper to be ready
2022-04-06 00:06:56 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d157ef52-kafka rolling update
2022-04-06 00:07:51 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d157ef52-kafka has been successfully rolled
2022-04-06 00:07:51 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d157ef52-kafka to be ready
2022-04-06 00:08:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d157ef52 will have desired state: Ready
2022-04-06 00:08:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d157ef52 is in desired state: Ready
2022-04-06 00:08:22 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d157ef52 is ready
2022-04-06 00:08:23 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d157ef52-zookeeper rolling update
2022-04-06 00:09:38 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d157ef52-zookeeper has been successfully rolled
2022-04-06 00:09:38 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-d157ef52-zookeeper to be ready
2022-04-06 00:10:07 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-d157ef52-kafka rolling update
2022-04-06 00:11:07 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-d157ef52-kafka has been successfully rolled
2022-04-06 00:11:07 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-d157ef52-kafka to be ready
2022-04-06 00:11:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-d157ef52 will have desired state: Ready
2022-04-06 00:11:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-d157ef52 is in desired state: Ready
2022-04-06 00:11:37 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-d157ef52 is ready
2022-04-06 00:11:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:11:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testExternalLoggingChangeTriggerRollingUpdate
2022-04-06 00:11:37 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-d157ef52 in namespace namespace-78
2022-04-06 00:11:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:11:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-78 for test case:testExternalLoggingChangeTriggerRollingUpdate
2022-04-06 00:12:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testExternalLoggingChangeTriggerRollingUpdate-FINISHED
2022-04-06 00:12:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:12:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:12:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testBrokerConfigurationChangeTriggerRollingUpdate-STARTED
2022-04-06 00:12:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:12:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-79 for test case:testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-06 00:12:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-79
2022-04-06 00:12:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-79
2022-04-06 00:12:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-79
2022-04-06 00:12:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a40a1919 in namespace namespace-79
2022-04-06 00:12:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-79
2022-04-06 00:12:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a40a1919 will have desired state: Ready
2022-04-06 00:13:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a40a1919 is in desired state: Ready
2022-04-06 00:13:38 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-a40a1919-kafka rolling update
2022-04-06 00:14:58 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-a40a1919-kafka has been successfully rolled
2022-04-06 00:14:58 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-a40a1919-kafka to be ready
2022-04-06 00:15:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a40a1919 will have desired state: Ready
2022-04-06 00:15:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a40a1919 is in desired state: Ready
2022-04-06 00:15:23 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-a40a1919 is ready
2022-04-06 00:15:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:15:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-06 00:15:23 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a40a1919 in namespace namespace-79
2022-04-06 00:15:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:15:33 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-79 for test case:testBrokerConfigurationChangeTriggerRollingUpdate
2022-04-06 00:16:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testBrokerConfigurationChangeTriggerRollingUpdate-FINISHED
2022-04-06 00:16:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:16:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:16:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testManualKafkaConfigMapChangeDontTriggerRollingUpdate-STARTED
2022-04-06 00:16:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:16:17 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-80 for test case:testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-06 00:16:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-80
2022-04-06 00:16:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-80
2022-04-06 00:16:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-80
2022-04-06 00:16:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8e11eaa8 in namespace namespace-80
2022-04-06 00:16:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-80
2022-04-06 00:16:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8e11eaa8 will have desired state: Ready
2022-04-06 00:17:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8e11eaa8 is in desired state: Ready
2022-04-06 00:17:34 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-8e11eaa8 are stable
2022-04-06 00:17:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:17:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:17:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:17:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:17:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:17:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:17:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:17:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:17:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:17:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:17:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:17:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:17:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:17:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:17:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:17:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:17:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:17:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:17:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:17:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:17:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:17:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:17:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:17:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:17:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:17:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:17:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:17:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:17:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:17:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:17:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:17:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:17:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:17:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:17:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:17:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:17:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:17:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:17:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:17:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:17:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:17:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:17:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:17:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:17:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:17:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:17:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:17:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:17:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:17:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:17:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:17:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:17:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:17:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:17:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:17:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:17:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:17:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:17:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:17:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:17:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:17:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:17:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:17:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:17:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:17:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:17:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:17:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:17:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:17:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:17:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:17:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:17:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:17:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:17:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:17:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:17:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:17:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:17:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:17:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:17:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:17:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:17:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:17:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:17:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:17:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:17:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:17:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:17:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:17:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:17:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:17:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:17:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:17:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:17:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:17:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:17:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:17:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:17:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:17:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:17:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:17:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:17:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:17:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:17:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:17:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:17:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:17:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:17:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:17:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:17:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:17:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:17:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:17:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:17:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:17:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:17:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:17:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:17:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:17:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:17:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:17:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:17:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:17:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:17:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:17:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:17:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:17:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:17:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:17:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:17:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:17:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:17:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:17:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:17:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:17:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:17:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:17:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:17:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:17:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:17:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:17:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:17:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:17:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:17:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:17:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:17:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:17:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:17:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:17:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:17:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:17:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:17:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:17:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:17:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:17:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:17:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:17:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:17:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:17:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:17:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:17:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:17:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:17:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:17:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:17:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:17:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:17:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:17:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:17:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:17:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:17:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:17:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:17:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:17:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:18:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:18:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:18:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:18:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:18:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:18:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:18:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:18:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:18:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:18:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:18:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:18:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:18:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:18:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:18:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:18:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:18:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:18:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:18:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:18:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:18:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:18:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:18:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:18:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:18:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:18:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:18:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:18:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:18:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:18:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:18:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:18:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:18:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:18:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:18:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:18:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:18:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:18:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:18:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:18:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:18:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:18:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:18:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:18:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:18:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:18:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:18:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:18:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:18:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:18:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:18:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:18:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:18:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:18:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:18:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:18:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:18:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:18:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:18:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:18:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:18:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:18:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:18:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:18:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:18:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:18:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:18:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:18:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:18:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:18:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:18:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:18:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:18:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:18:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:18:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:18:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:18:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:18:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:18:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:18:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:18:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:18:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:18:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:18:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:18:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:18:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:18:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:18:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:18:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:18:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:18:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:18:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:18:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:18:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:18:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:18:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:18:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:18:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:18:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:18:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:18:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:18:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:18:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:18:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:18:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:18:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:18:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:18:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:18:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:18:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:18:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:18:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:18:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:18:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:18:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:18:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:18:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:18:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:18:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:18:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:18:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:18:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:18:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:18:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:18:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:18:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:18:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:18:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:18:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:18:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:18:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:18:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:18:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:18:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:18:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:18:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:18:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:18:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:18:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:18:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:18:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:18:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:18:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:18:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:18:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:18:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:18:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:18:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:18:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:18:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:18:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:18:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:18:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:18:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:18:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:18:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:18:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:18:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:18:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:18:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:18:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:18:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:18:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:18:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:18:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:18:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:18:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:18:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:18:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:18:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:18:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:18:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:18:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:18:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:18:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-8e11eaa8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:18:25 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-8e11eaa8-entity-operator-59dfb47b44-czp98 ,my-cluster-8e11eaa8-kafka-0 ,my-cluster-8e11eaa8-kafka-1 ,my-cluster-8e11eaa8-kafka-2 ,my-cluster-8e11eaa8-zookeeper-0 ,my-cluster-8e11eaa8-zookeeper-1 ,my-cluster-8e11eaa8-zookeeper-2
2022-04-06 00:18:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:18:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-06 00:18:25 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8e11eaa8 in namespace namespace-80
2022-04-06 00:18:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:18:35 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-80 for test case:testManualKafkaConfigMapChangeDontTriggerRollingUpdate
2022-04-06 00:19:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testManualKafkaConfigMapChangeDontTriggerRollingUpdate-FINISHED
2022-04-06 00:19:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:19:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:19:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testZookeeperScaleUpScaleDown-STARTED
2022-04-06 00:19:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:19:02 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-81 for test case:testZookeeperScaleUpScaleDown
2022-04-06 00:19:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-81
2022-04-06 00:19:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-81
2022-04-06 00:19:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-81
2022-04-06 00:19:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-aba0a93f in namespace namespace-81
2022-04-06 00:19:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-06 00:19:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-aba0a93f will have desired state: Ready
2022-04-06 00:20:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-aba0a93f is in desired state: Ready
2022-04-06 00:20:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-974117274-1364457540 in namespace namespace-81
2022-04-06 00:20:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-06 00:20:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-974117274-1364457540 will have desired state: Ready
2022-04-06 00:20:56 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-974117274-1364457540 is in desired state: Ready
2022-04-06 00:20:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-27918972-74582413 in namespace namespace-81
2022-04-06 00:20:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-06 00:20:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-27918972-74582413 will have desired state: Ready
2022-04-06 00:20:57 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-27918972-74582413 is in desired state: Ready
2022-04-06 00:20:57 [main] [32mINFO [m [RollingUpdateST:398] Running zookeeperScaleUpScaleDown with cluster my-cluster-aba0a93f
2022-04-06 00:20:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-aba0a93f-kafka-clients in namespace namespace-81
2022-04-06 00:20:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-06 00:21:07 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 00:21:07 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3ed88e14, messages=[], arguments=[USER=my_user_27918972_74582413, --bootstrap-server, my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093, --max-messages, 100, --topic, my-topic-974117274-1364457540], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr', podNamespace='namespace-81', bootstrapServer='my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-974117274-1364457540', maxMessages=100, kafkaUsername='my-user-27918972-74582413', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@32b72434}
2022-04-06 00:21:07 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093:my-topic-974117274-1364457540 from pod my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr
2022-04-06 00:21:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr -n namespace-81 -- /opt/kafka/producer.sh USER=my_user_27918972_74582413 --bootstrap-server my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093 --max-messages 100 --topic my-topic-974117274-1364457540
2022-04-06 00:21:11 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:21:11 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:21:11 [main] [32mINFO [m [RollingUpdateST:426] Scale up Zookeeper to 7
2022-04-06 00:21:11 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1d125614, messages=[], arguments=[USER=my_user_27918972_74582413, --group-id, my-consumer-group-1960636730, --bootstrap-server, my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093, --group-instance-id, instance1116454389, --max-messages, 100, --topic, my-topic-974117274-1364457540], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr', podNamespace='namespace-81', bootstrapServer='my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-974117274-1364457540', maxMessages=100, kafkaUsername='my-user-27918972-74582413', consumerGroupName='my-consumer-group-1960636730', consumerInstanceId='instance1116454389', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6fef20f}
2022-04-06 00:21:11 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093:my-topic-974117274-1364457540 from pod my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr
2022-04-06 00:21:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr -n namespace-81 -- /opt/kafka/consumer.sh USER=my_user_27918972_74582413 --group-id my-consumer-group-1960636730 --bootstrap-server my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093 --group-instance-id instance1116454389 --max-messages 100 --topic my-topic-974117274-1364457540
2022-04-06 00:21:19 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:21:19 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:21:19 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 7 Pod(s) of my-cluster-aba0a93f-zookeeper to be ready
2022-04-06 00:24:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-aba0a93f will have desired state: Ready
2022-04-06 00:24:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-aba0a93f is in desired state: Ready
2022-04-06 00:24:14 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-aba0a93f is ready
2022-04-06 00:24:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-aba0a93f-zookeeper-0 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:24:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:24:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-aba0a93f-zookeeper-1 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:24:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:24:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-aba0a93f-zookeeper-2 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:24:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:24:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-aba0a93f-zookeeper-3 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:24:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:24:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-aba0a93f-zookeeper-4 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:24:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:24:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-aba0a93f-zookeeper-5 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:24:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:24:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-aba0a93f-zookeeper-6 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:24:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:24:15 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@13d3534c, messages=[], arguments=[USER=my_user_27918972_74582413, --group-id, my-consumer-group-1780606982, --bootstrap-server, my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093, --group-instance-id, instance652313088, --max-messages, 100, --topic, my-topic-974117274-1364457540], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr', podNamespace='namespace-81', bootstrapServer='my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-974117274-1364457540', maxMessages=100, kafkaUsername='my-user-27918972-74582413', consumerGroupName='my-consumer-group-1780606982', consumerInstanceId='instance652313088', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@64a1b885}
2022-04-06 00:24:15 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093:my-topic-974117274-1364457540 from pod my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr
2022-04-06 00:24:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr -n namespace-81 -- /opt/kafka/consumer.sh USER=my_user_27918972_74582413 --group-id my-consumer-group-1780606982 --bootstrap-server my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093 --group-instance-id instance652313088 --max-messages 100 --topic my-topic-974117274-1364457540
2022-04-06 00:24:22 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:24:22 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:24:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-60364483-230988139 in namespace namespace-81
2022-04-06 00:24:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-06 00:24:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-60364483-230988139 will have desired state: Ready
2022-04-06 00:24:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-60364483-230988139 is in desired state: Ready
2022-04-06 00:24:23 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@76be585d, messages=[], arguments=[USER=my_user_27918972_74582413, --bootstrap-server, my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093, --max-messages, 100, --topic, my-topic-60364483-230988139], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr', podNamespace='namespace-81', bootstrapServer='my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-60364483-230988139', maxMessages=100, kafkaUsername='my-user-27918972-74582413', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6ae77c06}
2022-04-06 00:24:23 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093:my-topic-60364483-230988139 from pod my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr
2022-04-06 00:24:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr -n namespace-81 -- /opt/kafka/producer.sh USER=my_user_27918972_74582413 --bootstrap-server my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093 --max-messages 100 --topic my-topic-60364483-230988139
2022-04-06 00:24:27 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:24:27 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:24:27 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1672ca06, messages=[], arguments=[USER=my_user_27918972_74582413, --group-id, my-consumer-group-360398745, --bootstrap-server, my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093, --group-instance-id, instance1602436800, --max-messages, 100, --topic, my-topic-60364483-230988139], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr', podNamespace='namespace-81', bootstrapServer='my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-60364483-230988139', maxMessages=100, kafkaUsername='my-user-27918972-74582413', consumerGroupName='my-consumer-group-360398745', consumerInstanceId='instance1602436800', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1f32a39f}
2022-04-06 00:24:27 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093:my-topic-60364483-230988139 from pod my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr
2022-04-06 00:24:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr -n namespace-81 -- /opt/kafka/consumer.sh USER=my_user_27918972_74582413 --group-id my-consumer-group-360398745 --bootstrap-server my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093 --group-instance-id instance1602436800 --max-messages 100 --topic my-topic-60364483-230988139
2022-04-06 00:24:34 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:24:34 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:24:34 [main] [32mINFO [m [RollingUpdateST:453] Scale down Zookeeper to 3
2022-04-06 00:24:34 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-aba0a93f-zookeeper to be ready
2022-04-06 00:25:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-aba0a93f will have desired state: Ready
2022-04-06 00:25:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-aba0a93f is in desired state: Ready
2022-04-06 00:25:17 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-aba0a93f is ready
2022-04-06 00:25:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-aba0a93f-zookeeper-0 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:25:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:25:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-aba0a93f-zookeeper-1 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:25:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:25:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-81 exec my-cluster-aba0a93f-zookeeper-2 -- /bin/bash -c echo mntr | nc localhost 12181
2022-04-06 00:25:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 00:25:18 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@49783a34, messages=[], arguments=[USER=my_user_27918972_74582413, --group-id, my-consumer-group-1682451527, --bootstrap-server, my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093, --group-instance-id, instance92246797, --max-messages, 100, --topic, my-topic-60364483-230988139], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr', podNamespace='namespace-81', bootstrapServer='my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-60364483-230988139', maxMessages=100, kafkaUsername='my-user-27918972-74582413', consumerGroupName='my-consumer-group-1682451527', consumerInstanceId='instance92246797', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@435c579b}
2022-04-06 00:25:18 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093:my-topic-60364483-230988139 from pod my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr
2022-04-06 00:25:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr -n namespace-81 -- /opt/kafka/consumer.sh USER=my_user_27918972_74582413 --group-id my-consumer-group-1682451527 --bootstrap-server my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093 --group-instance-id instance92246797 --max-messages 100 --topic my-topic-60364483-230988139
2022-04-06 00:25:25 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:25:25 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:25:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1336383987-154218821 in namespace namespace-81
2022-04-06 00:25:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-81
2022-04-06 00:25:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1336383987-154218821 will have desired state: Ready
2022-04-06 00:25:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1336383987-154218821 is in desired state: Ready
2022-04-06 00:25:26 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2a0159cd, messages=[], arguments=[USER=my_user_27918972_74582413, --bootstrap-server, my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093, --max-messages, 100, --topic, my-topic-1336383987-154218821], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr', podNamespace='namespace-81', bootstrapServer='my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1336383987-154218821', maxMessages=100, kafkaUsername='my-user-27918972-74582413', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@495afbe7}
2022-04-06 00:25:26 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093:my-topic-1336383987-154218821 from pod my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr
2022-04-06 00:25:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr -n namespace-81 -- /opt/kafka/producer.sh USER=my_user_27918972_74582413 --bootstrap-server my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093 --max-messages 100 --topic my-topic-1336383987-154218821
2022-04-06 00:25:30 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:25:30 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:25:30 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@361014f, messages=[], arguments=[USER=my_user_27918972_74582413, --group-id, my-consumer-group-1952644653, --bootstrap-server, my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093, --group-instance-id, instance212773057, --max-messages, 100, --topic, my-topic-1336383987-154218821], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr', podNamespace='namespace-81', bootstrapServer='my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093', topicName='my-topic-1336383987-154218821', maxMessages=100, kafkaUsername='my-user-27918972-74582413', consumerGroupName='my-consumer-group-1952644653', consumerInstanceId='instance212773057', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@bc02399}
2022-04-06 00:25:30 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093:my-topic-1336383987-154218821 from pod my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr
2022-04-06 00:25:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-aba0a93f-kafka-clients-5d749b8d4b-559qr -n namespace-81 -- /opt/kafka/consumer.sh USER=my_user_27918972_74582413 --group-id my-consumer-group-1952644653 --bootstrap-server my-cluster-aba0a93f-kafka-bootstrap.namespace-81.svc:9093 --group-instance-id instance212773057 --max-messages 100 --topic my-topic-1336383987-154218821
2022-04-06 00:25:37 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:25:37 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:25:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:25:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testZookeeperScaleUpScaleDown
2022-04-06 00:25:37 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-aba0a93f-kafka-clients in namespace namespace-81
2022-04-06 00:25:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-974117274-1364457540 in namespace namespace-81
2022-04-06 00:25:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1336383987-154218821 in namespace namespace-81
2022-04-06 00:25:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-60364483-230988139 in namespace namespace-81
2022-04-06 00:25:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-27918972-74582413 in namespace namespace-81
2022-04-06 00:25:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-aba0a93f in namespace namespace-81
2022-04-06 00:26:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:26:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-81 for test case:testZookeeperScaleUpScaleDown
2022-04-06 00:26:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testZookeeperScaleUpScaleDown-FINISHED
2022-04-06 00:26:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:26:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:26:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringZookeeperRollingUpdate-STARTED
2022-04-06 00:26:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:26:23 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-82 for test case:testRecoveryDuringZookeeperRollingUpdate
2022-04-06 00:26:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-82
2022-04-06 00:26:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-82
2022-04-06 00:26:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-82
2022-04-06 00:26:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-15ef899e in namespace namespace-82
2022-04-06 00:26:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-06 00:26:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1553234608-1281807597 in namespace namespace-82
2022-04-06 00:26:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-06 00:26:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-15ef899e will have desired state: Ready
2022-04-06 00:27:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-15ef899e is in desired state: Ready
2022-04-06 00:27:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1553234608-1281807597 will have desired state: Ready
2022-04-06 00:27:45 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1553234608-1281807597 is in desired state: Ready
2022-04-06 00:27:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1523463559-871309581 in namespace namespace-82
2022-04-06 00:27:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-06 00:27:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1523463559-871309581 will have desired state: Ready
2022-04-06 00:27:46 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1523463559-871309581 is in desired state: Ready
2022-04-06 00:27:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-15ef899e-kafka-clients in namespace namespace-82
2022-04-06 00:27:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-06 00:27:56 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 00:27:56 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@157db7fa, messages=[], arguments=[USER=my_user_1523463559_871309581, --bootstrap-server, my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093, --max-messages, 100, --topic, my-topic-1553234608-1281807597], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh', podNamespace='namespace-82', bootstrapServer='my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-1553234608-1281807597', maxMessages=100, kafkaUsername='my-user-1523463559-871309581', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@72317b1a}
2022-04-06 00:27:56 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093:my-topic-1553234608-1281807597 from pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh
2022-04-06 00:27:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh -n namespace-82 -- /opt/kafka/producer.sh USER=my_user_1523463559_871309581 --bootstrap-server my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093 --max-messages 100 --topic my-topic-1553234608-1281807597
2022-04-06 00:28:00 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:28:00 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:28:00 [main] [32mINFO [m [RollingUpdateST:117] Update resources for pods
2022-04-06 00:28:00 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@13314c45, messages=[], arguments=[USER=my_user_1523463559_871309581, --group-id, my-consumer-group-277324892, --bootstrap-server, my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093, --group-instance-id, instance135053239, --max-messages, 100, --topic, my-topic-1553234608-1281807597], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh', podNamespace='namespace-82', bootstrapServer='my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-1553234608-1281807597', maxMessages=100, kafkaUsername='my-user-1523463559-871309581', consumerGroupName='my-consumer-group-277324892', consumerInstanceId='instance135053239', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6b8be4a9}
2022-04-06 00:28:00 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093:my-topic-1553234608-1281807597 from pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh
2022-04-06 00:28:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh -n namespace-82 -- /opt/kafka/consumer.sh USER=my_user_1523463559_871309581 --group-id my-consumer-group-277324892 --bootstrap-server my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093 --group-instance-id instance135053239 --max-messages 100 --topic my-topic-1553234608-1281807597
2022-04-06 00:28:08 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:28:08 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:28:08 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-06 00:28:08 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-15ef899e-zookeeper will be in pending phase
2022-04-06 00:28:08 [main] [32mINFO [m [RollingUpdateST:130] Verifying stability of zookeeper pods except the one, which is in pending phase
2022-04-06 00:28:08 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-15ef899e-zookeeper are stable
2022-04-06 00:28:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:28:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:28:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:28:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:28:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:28:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:28:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:28:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:28:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:28:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:28:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:28:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:28:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:28:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:28:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:28:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:28:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:28:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:28:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:28:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:28:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:28:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:28:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:28:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:28:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:28:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:28:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:28:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:28:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:28:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:28:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:28:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:28:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:28:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:28:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:28:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:28:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:28:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:28:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:28:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:28:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:28:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:28:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:28:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:28:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:28:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:28:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:28:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:28:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:28:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:28:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:28:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:28:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:28:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:28:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:28:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:28:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:28:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:28:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:28:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:28:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:28:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:28:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:28:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:28:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:28:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:28:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:28:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:28:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:28:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:28:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:28:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:28:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:28:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:28:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:28:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:28:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:28:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:28:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:28:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:28:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:28:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:28:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:28:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:28:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:28:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:28:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:28:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:28:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:28:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:28:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:28:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:28:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:28:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:28:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:28:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:28:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:28:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:28:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:28:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:28:57 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-15ef899e-zookeeper-1 ,my-cluster-15ef899e-zookeeper-2
2022-04-06 00:28:57 [main] [32mINFO [m [RollingUpdateST:133] Verifying stability of kafka pods
2022-04-06 00:28:57 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-15ef899e-kafka are stable
2022-04-06 00:28:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:28:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:28:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:28:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:28:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:28:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:28:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:28:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:28:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:28:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:28:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:28:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:29:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:29:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:29:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:29:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:29:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:29:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:29:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:29:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:29:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:29:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:29:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:29:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:29:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:29:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:29:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:29:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:29:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:29:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:29:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:29:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:29:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:29:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:29:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:29:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:29:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:29:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:29:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:29:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:29:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:29:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:29:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:29:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:29:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:29:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:29:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:29:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:29:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:29:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:29:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:29:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:29:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:29:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:29:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:29:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:29:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:29:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:29:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:29:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:29:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:29:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:29:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:29:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:29:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:29:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:29:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:29:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:29:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:29:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:29:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:29:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:29:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:29:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:29:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:29:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:29:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:29:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:29:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:29:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:29:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:29:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:29:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:29:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:29:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:29:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:29:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:29:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:29:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:29:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:29:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:29:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:29:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:29:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:29:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:29:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:29:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:29:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:29:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:29:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:29:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:29:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:29:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:29:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:29:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:29:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:29:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:29:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:29:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:29:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:29:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:29:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:29:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:29:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:29:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:29:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:29:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:29:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:29:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:29:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:29:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:29:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:29:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:29:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:29:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:29:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:29:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:29:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:29:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:29:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:29:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:29:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:29:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:29:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:29:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:29:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:29:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:29:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:29:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:29:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:29:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:29:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:29:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:29:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:29:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:29:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:29:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:29:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:29:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:29:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:29:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:29:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:29:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:29:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:29:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:29:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:29:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:29:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:29:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:29:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:29:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:29:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:29:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:29:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:29:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:29:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:29:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:29:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:29:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:29:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:29:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:29:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:29:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:29:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:29:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:29:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:29:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:29:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:29:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:29:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:29:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:29:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:29:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:29:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:29:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:29:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:29:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:29:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:29:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:29:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:29:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:29:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:29:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:29:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:29:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:29:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:29:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:29:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:29:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:29:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:29:47 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-15ef899e-kafka-0 ,my-cluster-15ef899e-kafka-1 ,my-cluster-15ef899e-kafka-2 ,my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh
2022-04-06 00:29:47 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-15ef899e-zookeeper to be ready
2022-04-06 00:35:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-15ef899e will have desired state: Ready
2022-04-06 00:35:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-15ef899e is in desired state: Ready
2022-04-06 00:35:01 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-15ef899e is ready
2022-04-06 00:35:01 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3b207f56, messages=[], arguments=[USER=my_user_1523463559_871309581, --group-id, my-consumer-group-641211401, --bootstrap-server, my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093, --group-instance-id, instance1737606733, --max-messages, 100, --topic, my-topic-1553234608-1281807597], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh', podNamespace='namespace-82', bootstrapServer='my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-1553234608-1281807597', maxMessages=100, kafkaUsername='my-user-1523463559-871309581', consumerGroupName='my-consumer-group-641211401', consumerInstanceId='instance1737606733', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6b4dcdfa}
2022-04-06 00:35:01 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093:my-topic-1553234608-1281807597 from pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh
2022-04-06 00:35:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh -n namespace-82 -- /opt/kafka/consumer.sh USER=my_user_1523463559_871309581 --group-id my-consumer-group-641211401 --bootstrap-server my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093 --group-instance-id instance1737606733 --max-messages 100 --topic my-topic-1553234608-1281807597
2022-04-06 00:35:08 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:35:08 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:35:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1959099593-75837126 in namespace namespace-82
2022-04-06 00:35:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-82
2022-04-06 00:35:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1959099593-75837126 will have desired state: Ready
2022-04-06 00:35:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1959099593-75837126 is in desired state: Ready
2022-04-06 00:35:09 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5aaf2894, messages=[], arguments=[USER=my_user_1523463559_871309581, --bootstrap-server, my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093, --max-messages, 100, --topic, my-topic-1959099593-75837126], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh', podNamespace='namespace-82', bootstrapServer='my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-1959099593-75837126', maxMessages=100, kafkaUsername='my-user-1523463559-871309581', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5f881c82}
2022-04-06 00:35:09 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093:my-topic-1959099593-75837126 from pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh
2022-04-06 00:35:09 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh -n namespace-82 -- /opt/kafka/producer.sh USER=my_user_1523463559_871309581 --bootstrap-server my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093 --max-messages 100 --topic my-topic-1959099593-75837126
2022-04-06 00:35:13 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:35:13 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:35:13 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@40061ab1, messages=[], arguments=[USER=my_user_1523463559_871309581, --group-id, my-consumer-group-1574074981, --bootstrap-server, my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093, --group-instance-id, instance955260765, --max-messages, 100, --topic, my-topic-1959099593-75837126], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh', podNamespace='namespace-82', bootstrapServer='my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093', topicName='my-topic-1959099593-75837126', maxMessages=100, kafkaUsername='my-user-1523463559-871309581', consumerGroupName='my-consumer-group-1574074981', consumerInstanceId='instance955260765', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@62cd3658}
2022-04-06 00:35:13 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093:my-topic-1959099593-75837126 from pod my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh
2022-04-06 00:35:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-15ef899e-kafka-clients-7fd44979d4-tlnjh -n namespace-82 -- /opt/kafka/consumer.sh USER=my_user_1523463559_871309581 --group-id my-consumer-group-1574074981 --bootstrap-server my-cluster-15ef899e-kafka-bootstrap.namespace-82.svc:9093 --group-instance-id instance955260765 --max-messages 100 --topic my-topic-1959099593-75837126
2022-04-06 00:35:20 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:35:20 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:35:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:35:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryDuringZookeeperRollingUpdate
2022-04-06 00:35:20 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1523463559-871309581 in namespace namespace-82
2022-04-06 00:35:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1959099593-75837126 in namespace namespace-82
2022-04-06 00:35:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1553234608-1281807597 in namespace namespace-82
2022-04-06 00:35:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-15ef899e in namespace namespace-82
2022-04-06 00:35:30 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-15ef899e-kafka-clients in namespace namespace-82
2022-04-06 00:36:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:36:10 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-82 for test case:testRecoveryDuringZookeeperRollingUpdate
2022-04-06 00:36:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringZookeeperRollingUpdate-FINISHED
2022-04-06 00:36:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:36:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:36:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringKafkaRollingUpdate-STARTED
2022-04-06 00:36:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:36:16 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-83 for test case:testRecoveryDuringKafkaRollingUpdate
2022-04-06 00:36:16 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-83
2022-04-06 00:36:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-83
2022-04-06 00:36:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-83
2022-04-06 00:36:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-cca15dc8 in namespace namespace-83
2022-04-06 00:36:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-06 00:36:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cca15dc8 will have desired state: Ready
2022-04-06 00:37:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cca15dc8 is in desired state: Ready
2022-04-06 00:37:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1919788828-388280294 in namespace namespace-83
2022-04-06 00:37:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-06 00:37:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1919788828-388280294 will have desired state: Ready
2022-04-06 00:37:41 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1919788828-388280294 is in desired state: Ready
2022-04-06 00:37:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1947141744-876858073 in namespace namespace-83
2022-04-06 00:37:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-06 00:37:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1947141744-876858073 will have desired state: Ready
2022-04-06 00:37:42 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1947141744-876858073 is in desired state: Ready
2022-04-06 00:37:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-cca15dc8-kafka-clients in namespace namespace-83
2022-04-06 00:37:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-06 00:37:43 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 00:37:43 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@22316e0b, messages=[], arguments=[USER=my_user_1947141744_876858073, --bootstrap-server, my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093, --max-messages, 100, --topic, my-topic-1919788828-388280294], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj', podNamespace='namespace-83', bootstrapServer='my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1919788828-388280294', maxMessages=100, kafkaUsername='my-user-1947141744-876858073', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@26a67b91}
2022-04-06 00:37:43 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093:my-topic-1919788828-388280294 from pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj
2022-04-06 00:37:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj -n namespace-83 -- /opt/kafka/producer.sh USER=my_user_1947141744_876858073 --bootstrap-server my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093 --max-messages 100 --topic my-topic-1919788828-388280294
2022-04-06 00:37:43 [main] [32mINFO [m [VerifiableClient:199] CLI_KAFKA_VERIFIABLE_PRODUCER RETURN code: 1
2022-04-06 00:37:43 [main] [32mINFO [m [VerifiableClient:206] ======STDERR START=======
2022-04-06 00:37:43 [main] [32mINFO [m [VerifiableClient:207] error: unable to upgrade connection: container not found ("my-cluster-cca15dc8-kafka-clients")

2022-04-06 00:37:43 [main] [32mINFO [m [VerifiableClient:208] ======STDERR END======
2022-04-06 00:37:43 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: false
2022-04-06 00:37:43 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced -1 messages
2022-04-06 00:37:58 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@25c64c2c, messages=[], arguments=[USER=my_user_1947141744_876858073, --bootstrap-server, my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093, --max-messages, 100, --topic, my-topic-1919788828-388280294], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj', podNamespace='namespace-83', bootstrapServer='my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1919788828-388280294', maxMessages=100, kafkaUsername='my-user-1947141744-876858073', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@30a9d35b}
2022-04-06 00:37:58 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093:my-topic-1919788828-388280294 from pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj
2022-04-06 00:37:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj -n namespace-83 -- /opt/kafka/producer.sh USER=my_user_1947141744_876858073 --bootstrap-server my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093 --max-messages 100 --topic my-topic-1919788828-388280294
2022-04-06 00:38:02 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:38:02 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:38:02 [main] [32mINFO [m [RollingUpdateST:203] Update resources for pods
2022-04-06 00:38:02 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1dd563df, messages=[], arguments=[USER=my_user_1947141744_876858073, --group-id, my-consumer-group-1049962398, --bootstrap-server, my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093, --group-instance-id, instance56159741, --max-messages, 100, --topic, my-topic-1919788828-388280294], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj', podNamespace='namespace-83', bootstrapServer='my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1919788828-388280294', maxMessages=100, kafkaUsername='my-user-1947141744-876858073', consumerGroupName='my-consumer-group-1049962398', consumerInstanceId='instance56159741', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@631847ec}
2022-04-06 00:38:02 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093:my-topic-1919788828-388280294 from pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj
2022-04-06 00:38:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj -n namespace-83 -- /opt/kafka/consumer.sh USER=my_user_1947141744_876858073 --group-id my-consumer-group-1049962398 --bootstrap-server my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093 --group-instance-id instance56159741 --max-messages 100 --topic my-topic-1919788828-388280294
2022-04-06 00:38:09 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:38:09 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:38:09 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-06 00:38:09 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-cca15dc8-kafka will be in pending phase
2022-04-06 00:38:17 [main] [32mINFO [m [RollingUpdateST:220] Verifying stability of kafka pods except the one, which is in pending phase
2022-04-06 00:38:17 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-cca15dc8-kafka are stable
2022-04-06 00:38:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:38:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:38:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:38:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:38:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:38:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:38:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:38:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:38:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:38:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:38:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:38:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:38:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:38:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:38:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:38:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:38:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:38:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:38:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:38:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:38:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:38:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:38:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:38:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:38:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:38:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:38:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:38:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:38:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:38:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:38:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:38:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:38:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:38:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:38:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:38:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:38:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:38:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:38:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:38:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:38:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:38:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:38:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:38:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:38:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:38:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:38:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:38:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:38:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:38:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:38:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:38:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:38:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:38:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:38:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:38:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:38:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:38:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:38:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:38:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:38:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:38:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:38:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:38:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:38:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:38:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:38:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:38:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:38:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:38:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:38:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:38:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:38:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:38:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:38:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:38:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:38:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:38:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:38:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:38:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:38:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:38:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:38:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:38:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:38:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:38:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:38:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:38:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:38:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:38:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:38:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:38:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:38:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:38:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:38:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:38:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:38:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:38:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:38:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:38:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:38:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:38:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:38:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:38:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:38:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:38:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:38:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:38:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:38:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:38:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:38:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:38:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:38:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:38:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:38:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:38:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:38:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:38:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:38:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:38:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:38:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:38:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:38:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:38:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:38:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:38:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:39:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:39:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:39:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:39:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:39:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:39:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:39:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:39:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:39:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:39:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:39:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:39:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:39:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:39:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:39:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:39:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:39:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:39:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:39:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:39:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:39:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:39:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:39:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:39:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:39:07 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-cca15dc8-kafka-1 ,my-cluster-cca15dc8-kafka-2 ,my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj
2022-04-06 00:39:07 [main] [32mINFO [m [RollingUpdateST:223] Verifying stability of zookeeper pods
2022-04-06 00:39:07 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-cca15dc8-zookeeper are stable
2022-04-06 00:39:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:39:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:39:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 00:39:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:39:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:39:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 00:39:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:39:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:39:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 00:39:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:39:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:39:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 00:39:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:39:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:39:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 00:39:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:39:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:39:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 00:39:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:39:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:39:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 00:39:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:39:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:39:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 00:39:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:39:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:39:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 00:39:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:39:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:39:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 00:39:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:39:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:39:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 00:39:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:39:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:39:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 00:39:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:39:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:39:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 00:39:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:39:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:39:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 00:39:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:39:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:39:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 00:39:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:39:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:39:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 00:39:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:39:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:39:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 00:39:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:39:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:39:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 00:39:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:39:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:39:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 00:39:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:39:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:39:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 00:39:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:39:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:39:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 00:39:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:39:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:39:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 00:39:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:39:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:39:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 00:39:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:39:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:39:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 00:39:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:39:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:39:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 00:39:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:39:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:39:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 00:39:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:39:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:39:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 00:39:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:39:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:39:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 00:39:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:39:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:39:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 00:39:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:39:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:39:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 00:39:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:39:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:39:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 00:39:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:39:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:39:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 00:39:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:39:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:39:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 00:39:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:39:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:39:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 00:39:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:39:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:39:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 00:39:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:39:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:39:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 00:39:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:39:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:39:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 00:39:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:39:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:39:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 00:39:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:39:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:39:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 00:39:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:39:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:39:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 00:39:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:39:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:39:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 00:39:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:39:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:39:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 00:39:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:39:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:39:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 00:39:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:39:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:39:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 00:39:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:39:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:39:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 00:39:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:39:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:39:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 00:39:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:39:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:39:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 00:39:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:39:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:39:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 00:39:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:39:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:39:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 00:39:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:39:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:39:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-cca15dc8-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 00:39:57 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-cca15dc8-zookeeper-0 ,my-cluster-cca15dc8-zookeeper-1 ,my-cluster-cca15dc8-zookeeper-2
2022-04-06 00:39:57 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@77cbcef7, messages=[], arguments=[USER=my_user_1947141744_876858073, --group-id, my-consumer-group-1150947522, --bootstrap-server, my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093, --group-instance-id, instance73483120, --max-messages, 100, --topic, my-topic-1919788828-388280294], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj', podNamespace='namespace-83', bootstrapServer='my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1919788828-388280294', maxMessages=100, kafkaUsername='my-user-1947141744-876858073', consumerGroupName='my-consumer-group-1150947522', consumerInstanceId='instance73483120', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@ae5eb65}
2022-04-06 00:39:57 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093:my-topic-1919788828-388280294 from pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj
2022-04-06 00:39:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj -n namespace-83 -- /opt/kafka/consumer.sh USER=my_user_1947141744_876858073 --group-id my-consumer-group-1150947522 --bootstrap-server my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093 --group-instance-id instance73483120 --max-messages 100 --topic my-topic-1919788828-388280294
2022-04-06 00:40:03 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:40:03 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:40:03 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-06 00:40:03 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-cca15dc8-kafka to be ready
2022-04-06 00:45:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-cca15dc8 will have desired state: Ready
2022-04-06 00:45:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-cca15dc8 is in desired state: Ready
2022-04-06 00:45:21 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-cca15dc8 is ready
2022-04-06 00:45:21 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6cbe39dc, messages=[], arguments=[USER=my_user_1947141744_876858073, --group-id, my-consumer-group-1167124527, --bootstrap-server, my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093, --group-instance-id, instance1478398212, --max-messages, 100, --topic, my-topic-1919788828-388280294], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj', podNamespace='namespace-83', bootstrapServer='my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-1919788828-388280294', maxMessages=100, kafkaUsername='my-user-1947141744-876858073', consumerGroupName='my-consumer-group-1167124527', consumerInstanceId='instance1478398212', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@45abebe8}
2022-04-06 00:45:21 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093:my-topic-1919788828-388280294 from pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj
2022-04-06 00:45:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj -n namespace-83 -- /opt/kafka/consumer.sh USER=my_user_1947141744_876858073 --group-id my-consumer-group-1167124527 --bootstrap-server my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093 --group-instance-id instance1478398212 --max-messages 100 --topic my-topic-1919788828-388280294
2022-04-06 00:45:28 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:45:28 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:45:28 [main] [32mINFO [m [ClientUtils:45] Consumer successfully consumed 100 messages for the 1 time
2022-04-06 00:45:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2144647216-593305670 in namespace namespace-83
2022-04-06 00:45:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-83
2022-04-06 00:45:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2144647216-593305670 will have desired state: Ready
2022-04-06 00:45:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2144647216-593305670 is in desired state: Ready
2022-04-06 00:45:29 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2aa5fca7, messages=[], arguments=[USER=my_user_1947141744_876858073, --bootstrap-server, my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093, --max-messages, 100, --topic, my-topic-2144647216-593305670], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj', podNamespace='namespace-83', bootstrapServer='my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-2144647216-593305670', maxMessages=100, kafkaUsername='my-user-1947141744-876858073', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@30cba5fd}
2022-04-06 00:45:29 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093:my-topic-2144647216-593305670 from pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj
2022-04-06 00:45:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj -n namespace-83 -- /opt/kafka/producer.sh USER=my_user_1947141744_876858073 --bootstrap-server my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093 --max-messages 100 --topic my-topic-2144647216-593305670
2022-04-06 00:45:33 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:45:33 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:45:33 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@f86075e, messages=[], arguments=[USER=my_user_1947141744_876858073, --group-id, my-consumer-group-113857849, --bootstrap-server, my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093, --group-instance-id, instance942482497, --max-messages, 100, --topic, my-topic-2144647216-593305670], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj', podNamespace='namespace-83', bootstrapServer='my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093', topicName='my-topic-2144647216-593305670', maxMessages=100, kafkaUsername='my-user-1947141744-876858073', consumerGroupName='my-consumer-group-113857849', consumerInstanceId='instance942482497', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@374840f6}
2022-04-06 00:45:33 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093:my-topic-2144647216-593305670 from pod my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj
2022-04-06 00:45:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-cca15dc8-kafka-clients-85bbdfc865-tfrlj -n namespace-83 -- /opt/kafka/consumer.sh USER=my_user_1947141744_876858073 --group-id my-consumer-group-113857849 --bootstrap-server my-cluster-cca15dc8-kafka-bootstrap.namespace-83.svc:9093 --group-instance-id instance942482497 --max-messages 100 --topic my-topic-2144647216-593305670
2022-04-06 00:45:40 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:45:40 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:45:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:45:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryDuringKafkaRollingUpdate
2022-04-06 00:45:40 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1947141744-876858073 in namespace namespace-83
2022-04-06 00:45:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1919788828-388280294 in namespace namespace-83
2022-04-06 00:45:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-cca15dc8 in namespace namespace-83
2022-04-06 00:45:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2144647216-593305670 in namespace namespace-83
2022-04-06 00:45:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-cca15dc8-kafka-clients in namespace namespace-83
2022-04-06 00:46:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:46:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-83 for test case:testRecoveryDuringKafkaRollingUpdate
2022-04-06 00:46:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testRecoveryDuringKafkaRollingUpdate-FINISHED
2022-04-06 00:46:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:46:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:46:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-STARTED
2022-04-06 00:46:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:46:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8ad8c7eb in namespace rolling-update-st
2022-04-06 00:46:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8ad8c7eb will have desired state: Ready
2022-04-06 00:47:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8ad8c7eb is in desired state: Ready
2022-04-06 00:47:57 [main] [32mINFO [m [RollingUpdateST:630] Deleting Cluster Operator pod with labels LabelSelector(matchExpressions=[], matchLabels={name=strimzi-cluster-operator}, additionalProperties={})
2022-04-06 00:47:57 [main] [32mINFO [m [RollingUpdateST:632] Cluster Operator pod deleted
2022-04-06 00:47:57 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-8ad8c7eb-zookeeper rolling update
2022-04-06 00:48:42 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-8ad8c7eb-zookeeper has been successfully rolled
2022-04-06 00:48:42 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-8ad8c7eb-zookeeper to be ready
2022-04-06 00:49:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8ad8c7eb will have desired state: Ready
2022-04-06 00:49:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8ad8c7eb is in desired state: Ready
2022-04-06 00:49:12 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-8ad8c7eb is ready
2022-04-06 00:49:17 [main] [32mINFO [m [RollingUpdateST:639] Deleting Cluster Operator pod with labels LabelSelector(matchExpressions=[], matchLabels={name=strimzi-cluster-operator}, additionalProperties={})
2022-04-06 00:49:17 [main] [32mINFO [m [RollingUpdateST:641] Cluster Operator pod deleted
2022-04-06 00:49:17 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-8ad8c7eb-kafka rolling update
2022-04-06 00:51:12 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-8ad8c7eb-kafka has been successfully rolled
2022-04-06 00:51:12 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-8ad8c7eb-kafka to be ready
2022-04-06 00:51:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8ad8c7eb will have desired state: Ready
2022-04-06 00:51:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8ad8c7eb is in desired state: Ready
2022-04-06 00:51:42 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-8ad8c7eb is ready
2022-04-06 00:51:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 00:51:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClusterOperatorFinishAllRollingUpdates
2022-04-06 00:51:42 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8ad8c7eb in namespace rolling-update-st
2022-04-06 00:51:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 00:51:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testClusterOperatorFinishAllRollingUpdates-FINISHED
2022-04-06 00:51:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 00:51:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 00:51:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testKafkaAndZookeeperScaleUpScaleDown-STARTED
2022-04-06 00:51:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 00:51:52 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-84 for test case:testKafkaAndZookeeperScaleUpScaleDown
2022-04-06 00:51:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-84
2022-04-06 00:51:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-84
2022-04-06 00:51:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-84
2022-04-06 00:51:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-4c76c4d4 in namespace namespace-84
2022-04-06 00:51:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-06 00:51:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4c76c4d4 will have desired state: Ready
2022-04-06 00:54:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4c76c4d4 is in desired state: Ready
2022-04-06 00:54:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-96522343-1735823911 in namespace namespace-84
2022-04-06 00:54:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-06 00:54:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-96522343-1735823911 will have desired state: Ready
2022-04-06 00:54:19 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-96522343-1735823911 is in desired state: Ready
2022-04-06 00:54:19 [main] [32mINFO [m [AbstractST:489] Verifying docker image names
2022-04-06 00:54:19 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-06 00:54:19 [main] [32mINFO [m [AbstractST:525] Docker images verified
2022-04-06 00:54:19 [main] [32mINFO [m [RollingUpdateST:292] Running kafkaScaleUpScaleDown my-cluster-4c76c4d4
2022-04-06 00:54:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-379670473-453874151 in namespace namespace-84
2022-04-06 00:54:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-06 00:54:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-379670473-453874151 will have desired state: Ready
2022-04-06 00:54:20 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-379670473-453874151 is in desired state: Ready
2022-04-06 00:54:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-4c76c4d4-kafka-clients in namespace namespace-84
2022-04-06 00:54:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-06 00:54:30 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 00:54:30 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@62026328, messages=[], arguments=[USER=my_user_96522343_1735823911, --bootstrap-server, my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093, --max-messages, 100, --topic, my-topic-379670473-453874151], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69', podNamespace='namespace-84', bootstrapServer='my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-379670473-453874151', maxMessages=100, kafkaUsername='my-user-96522343-1735823911', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@78d1c284}
2022-04-06 00:54:30 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093:my-topic-379670473-453874151 from pod my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69
2022-04-06 00:54:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69 -n namespace-84 -- /opt/kafka/producer.sh USER=my_user_96522343_1735823911 --bootstrap-server my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093 --max-messages 100 --topic my-topic-379670473-453874151
2022-04-06 00:54:34 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 00:54:34 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 00:54:34 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@c0651d2, messages=[], arguments=[USER=my_user_96522343_1735823911, --group-id, my-consumer-group-1395073573, --bootstrap-server, my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093, --group-instance-id, instance951560965, --max-messages, 100, --topic, my-topic-379670473-453874151], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69', podNamespace='namespace-84', bootstrapServer='my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-379670473-453874151', maxMessages=100, kafkaUsername='my-user-96522343-1735823911', consumerGroupName='my-consumer-group-1395073573', consumerInstanceId='instance951560965', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@13b1b5e8}
2022-04-06 00:54:34 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093:my-topic-379670473-453874151 from pod my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69
2022-04-06 00:54:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69 -n namespace-84 -- /opt/kafka/consumer.sh USER=my_user_96522343_1735823911 --group-id my-consumer-group-1395073573 --bootstrap-server my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093 --group-instance-id instance951560965 --max-messages 100 --topic my-topic-379670473-453874151
2022-04-06 00:54:41 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:54:41 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:54:41 [main] [32mINFO [m [RollingUpdateST:317] Scale up Kafka to 7
2022-04-06 00:54:41 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4c76c4d4-kafka rolling update
2022-04-06 00:56:11 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4c76c4d4-kafka has been successfully rolled
2022-04-06 00:56:11 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 7 Pod(s) of my-cluster-4c76c4d4-kafka to be ready
2022-04-06 00:57:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4c76c4d4 will have desired state: Ready
2022-04-06 00:57:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4c76c4d4 is in desired state: Ready
2022-04-06 00:57:00 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-4c76c4d4 is ready
2022-04-06 00:57:00 [main] [32mINFO [m [RollingUpdateST:327] Kafka scale up to 7 finished
2022-04-06 00:57:00 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4f45f55b, messages=[], arguments=[USER=my_user_96522343_1735823911, --group-id, my-consumer-group-719135588, --bootstrap-server, my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093, --group-instance-id, instance3769551, --max-messages, 100, --topic, my-topic-379670473-453874151], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69', podNamespace='namespace-84', bootstrapServer='my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-379670473-453874151', maxMessages=100, kafkaUsername='my-user-96522343-1735823911', consumerGroupName='my-consumer-group-719135588', consumerInstanceId='instance3769551', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@18f43834}
2022-04-06 00:57:00 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093:my-topic-379670473-453874151 from pod my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69
2022-04-06 00:57:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69 -n namespace-84 -- /opt/kafka/consumer.sh USER=my_user_96522343_1735823911 --group-id my-consumer-group-719135588 --bootstrap-server my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093 --group-instance-id instance3769551 --max-messages 100 --topic my-topic-379670473-453874151
2022-04-06 00:57:08 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:57:08 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:57:08 [main] [32mINFO [m [RollingUpdateST:339] Scale up Zookeeper to 5
2022-04-06 00:57:08 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 5 Pod(s) of my-cluster-4c76c4d4-zookeeper to be ready
2022-04-06 00:58:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4c76c4d4 will have desired state: Ready
2022-04-06 00:58:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4c76c4d4 is in desired state: Ready
2022-04-06 00:58:24 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-4c76c4d4 is ready
2022-04-06 00:58:24 [main] [32mINFO [m [RollingUpdateST:342] Kafka scale up to 5 finished
2022-04-06 00:58:24 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@310cfc38, messages=[], arguments=[USER=my_user_96522343_1735823911, --group-id, my-consumer-group-1164031467, --bootstrap-server, my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093, --group-instance-id, instance814881976, --max-messages, 100, --topic, my-topic-379670473-453874151], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69', podNamespace='namespace-84', bootstrapServer='my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-379670473-453874151', maxMessages=100, kafkaUsername='my-user-96522343-1735823911', consumerGroupName='my-consumer-group-1164031467', consumerInstanceId='instance814881976', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@391fefb6}
2022-04-06 00:58:24 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093:my-topic-379670473-453874151 from pod my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69
2022-04-06 00:58:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69 -n namespace-84 -- /opt/kafka/consumer.sh USER=my_user_96522343_1735823911 --group-id my-consumer-group-1164031467 --bootstrap-server my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093 --group-instance-id instance814881976 --max-messages 100 --topic my-topic-379670473-453874151
2022-04-06 00:58:32 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 00:58:32 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 00:58:32 [main] [32mINFO [m [RollingUpdateST:351] Scale down Kafka to 3
2022-04-06 00:58:32 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-4c76c4d4-kafka rolling update
2022-04-06 01:00:22 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-4c76c4d4-kafka has been successfully rolled
2022-04-06 01:00:22 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-4c76c4d4-kafka to be ready
2022-04-06 01:00:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-4c76c4d4 will have desired state: Ready
2022-04-06 01:00:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-4c76c4d4 is in desired state: Ready
2022-04-06 01:00:51 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-4c76c4d4 is ready
2022-04-06 01:00:51 [main] [32mINFO [m [RollingUpdateST:356] Kafka scale down to 3 finished
2022-04-06 01:00:51 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4a405cb2, messages=[], arguments=[USER=my_user_96522343_1735823911, --group-id, my-consumer-group-1635460028, --bootstrap-server, my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093, --group-instance-id, instance1425856386, --max-messages, 100, --topic, my-topic-379670473-453874151], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69', podNamespace='namespace-84', bootstrapServer='my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-379670473-453874151', maxMessages=100, kafkaUsername='my-user-96522343-1735823911', consumerGroupName='my-consumer-group-1635460028', consumerInstanceId='instance1425856386', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5d9ce1d7}
2022-04-06 01:00:51 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093:my-topic-379670473-453874151 from pod my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69
2022-04-06 01:00:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69 -n namespace-84 -- /opt/kafka/consumer.sh USER=my_user_96522343_1735823911 --group-id my-consumer-group-1635460028 --bootstrap-server my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093 --group-instance-id instance1425856386 --max-messages 100 --topic my-topic-379670473-453874151
2022-04-06 01:00:59 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 01:00:59 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 01:00:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1615324875-742618801 in namespace namespace-84
2022-04-06 01:00:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-84
2022-04-06 01:00:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1615324875-742618801 will have desired state: Ready
2022-04-06 01:02:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1615324875-742618801 is in desired state: Ready
2022-04-06 01:02:13 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@16459bd2, messages=[], arguments=[USER=my_user_96522343_1735823911, --bootstrap-server, my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093, --max-messages, 100, --topic, my-topic-1615324875-742618801], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69', podNamespace='namespace-84', bootstrapServer='my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1615324875-742618801', maxMessages=100, kafkaUsername='my-user-96522343-1735823911', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5e28f969}
2022-04-06 01:02:13 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093:my-topic-1615324875-742618801 from pod my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69
2022-04-06 01:02:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69 -n namespace-84 -- /opt/kafka/producer.sh USER=my_user_96522343_1735823911 --bootstrap-server my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093 --max-messages 100 --topic my-topic-1615324875-742618801
2022-04-06 01:02:17 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 01:02:17 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 01:02:17 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7eecd9f4, messages=[], arguments=[USER=my_user_96522343_1735823911, --group-id, my-consumer-group-686308032, --bootstrap-server, my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093, --group-instance-id, instance59270728, --max-messages, 100, --topic, my-topic-1615324875-742618801], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69', podNamespace='namespace-84', bootstrapServer='my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093', topicName='my-topic-1615324875-742618801', maxMessages=100, kafkaUsername='my-user-96522343-1735823911', consumerGroupName='my-consumer-group-686308032', consumerInstanceId='instance59270728', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@671687ce}
2022-04-06 01:02:17 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093:my-topic-1615324875-742618801 from pod my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69
2022-04-06 01:02:17 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-4c76c4d4-kafka-clients-66988c97f8-rkk69 -n namespace-84 -- /opt/kafka/consumer.sh USER=my_user_96522343_1735823911 --group-id my-consumer-group-686308032 --bootstrap-server my-cluster-4c76c4d4-kafka-bootstrap.namespace-84.svc:9093 --group-instance-id instance59270728 --max-messages 100 --topic my-topic-1615324875-742618801
2022-04-06 01:02:25 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 01:02:25 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 01:02:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:02:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaAndZookeeperScaleUpScaleDown
2022-04-06 01:02:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-379670473-453874151 in namespace namespace-84
2022-04-06 01:02:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1615324875-742618801 in namespace namespace-84
2022-04-06 01:02:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-96522343-1735823911 in namespace namespace-84
2022-04-06 01:02:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-4c76c4d4 in namespace namespace-84
2022-04-06 01:02:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-4c76c4d4-kafka-clients in namespace namespace-84
2022-04-06 01:03:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:03:25 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-84 for test case:testKafkaAndZookeeperScaleUpScaleDown
2022-04-06 01:03:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.RollingUpdateST.testKafkaAndZookeeperScaleUpScaleDown-FINISHED
2022-04-06 01:03:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:03:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:03:31 [main] [32mINFO [m [ResourceManager:346] In context RollingUpdateST is everything deleted.
2022-04-06 01:03:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4,024.688 s - in io.strimzi.systemtest.rollingupdate.RollingUpdateST
[[1;34mINFO[m] Running io.strimzi.systemtest.log.LoggingChangeST
2022-04-06 01:03:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: logging-change-st
2022-04-06 01:03:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: logging-change-st
2022-04-06 01:03:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: logging-change-st
2022-04-06 01:03:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:03:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetClusterOperatorLoggingLevels-STARTED
2022-04-06 01:03:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:03:37 [main] [32mINFO [m [LoggingChangeST:618] Checking that original logging config is different from the new one
2022-04-06 01:03:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:03:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:03:37 [main] [32mINFO [m [LoggingChangeST:621] Changing logging for cluster-operator
2022-04-06 01:03:37 [main] [32mINFO [m [LoggingChangeST:624] Waiting for log4j2.properties will contain desired settings
2022-04-06 01:03:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:03:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:03:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:03:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:03:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:03:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:03:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:03:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:03:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:03:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:03:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:03:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:03:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:03:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:03:44 [main] [32mINFO [m [LoggingChangeST:629] Checking log4j2.properties in CO pod
2022-04-06 01:03:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:03:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:03:44 [main] [32mINFO [m [LoggingChangeST:633] Checking if CO rolled its pod
2022-04-06 01:03:45 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:45 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:45 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:45 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:46 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:46 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:46 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:46 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:47 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:47 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:47 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:47 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:48 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:48 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:48 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:48 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:49 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:49 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:49 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:49 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:50 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:50 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:50 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:50 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:51 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:51 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:51 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:51 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:52 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:52 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:52 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:52 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:53 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:53 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:23 INFO  ClusterOperator:128 - Triggering periodic reconciliation for namespace *
2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:53 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:54 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:54 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:54 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:54 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:55 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:55 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:55 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:55 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:56 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:56 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:56 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:56 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:57 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:57 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:57 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:57 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:58 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:58 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:58 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:58 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:59 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:59 [main] [33mWARN [m [LoggingChangeST:639] 2022-04-06 01:03:29 INFO  AbstractOperator:373 - Reconciliation #42(watch) Kafka(namespace-84/my-cluster-4c76c4d4): Reconciliation is in progress

2022-04-06 01:03:59 [main] [33mWARN [m [LoggingChangeST:639] 
2022-04-06 01:03:59 [main] [32mINFO [m [LoggingChangeST:643] Changing all levels from OFF to INFO/WARN
2022-04-06 01:03:59 [main] [32mINFO [m [LoggingChangeST:647] Changing logging for cluster-operator
2022-04-06 01:03:59 [main] [32mINFO [m [LoggingChangeST:650] Waiting for log4j2.properties will contain desired settings
2022-04-06 01:03:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:03:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:06 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:06 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:36 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:36 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:42 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:42 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:54 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:54 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:04:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:04:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:05:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:05:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:05:01 [main] [32mINFO [m [LoggingChangeST:655] Checking log4j2.properties in CO pod
2022-04-06 01:05:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-t475h -- /bin/bash -c cat /opt/strimzi/custom-config/log4j2.properties
2022-04-06 01:05:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:05:01 [main] [32mINFO [m [LoggingChangeST:659] Checking if CO rolled its pod
2022-04-06 01:05:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:05:23 [main] [32mINFO [m [ResourceManager:346] In context testDynamicallySetClusterOperatorLoggingLevels is everything deleted.
2022-04-06 01:05:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:05:23 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetClusterOperatorLoggingLevels-FINISHED
2022-04-06 01:05:23 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:05:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:05:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLogger-STARTED
2022-04-06 01:05:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:05:23 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-85 for test case:testDynamicallySetUnknownKafkaLogger
2022-04-06 01:05:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-85
2022-04-06 01:05:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-85
2022-04-06 01:05:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-85
2022-04-06 01:05:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-facc3720 in namespace namespace-85
2022-04-06 01:05:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-85
2022-04-06 01:05:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-facc3720 will have desired state: Ready
2022-04-06 01:06:38 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-facc3720 is in desired state: Ready
2022-04-06 01:06:38 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-facc3720-kafka rolling update
2022-04-06 01:07:53 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-facc3720-kafka has been successfully rolled
2022-04-06 01:07:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:07:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetUnknownKafkaLogger
2022-04-06 01:07:56 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-facc3720 in namespace namespace-85
2022-04-06 01:08:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:08:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-85 for test case:testDynamicallySetUnknownKafkaLogger
2022-04-06 01:08:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLogger-FINISHED
2022-04-06 01:08:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:08:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:08:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaExternalLogging-STARTED
2022-04-06 01:08:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:08:50 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-86 for test case:testDynamicallySetKafkaExternalLogging
2022-04-06 01:08:50 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-86
2022-04-06 01:08:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-86
2022-04-06 01:08:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-86
2022-04-06 01:08:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-839c30ae in namespace namespace-86
2022-04-06 01:08:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-86
2022-04-06 01:08:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-839c30ae will have desired state: Ready
2022-04-06 01:09:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-839c30ae is in desired state: Ready
2022-04-06 01:09:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 50
2022-04-06 01:10:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 49
2022-04-06 01:10:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 48
2022-04-06 01:10:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 47
2022-04-06 01:10:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 46
2022-04-06 01:10:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 45
2022-04-06 01:10:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 44
2022-04-06 01:10:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 43
2022-04-06 01:10:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 42
2022-04-06 01:10:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 41
2022-04-06 01:10:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 40
2022-04-06 01:10:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 39
2022-04-06 01:10:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 38
2022-04-06 01:10:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 37
2022-04-06 01:10:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 36
2022-04-06 01:10:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 35
2022-04-06 01:10:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 34
2022-04-06 01:10:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 33
2022-04-06 01:10:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 32
2022-04-06 01:10:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 31
2022-04-06 01:10:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 30
2022-04-06 01:10:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 29
2022-04-06 01:10:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 28
2022-04-06 01:10:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 27
2022-04-06 01:10:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 26
2022-04-06 01:10:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 25
2022-04-06 01:10:25 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 24
2022-04-06 01:10:26 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 23
2022-04-06 01:10:27 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 22
2022-04-06 01:10:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 21
2022-04-06 01:10:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 20
2022-04-06 01:10:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 19
2022-04-06 01:10:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 18
2022-04-06 01:10:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 17
2022-04-06 01:10:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 16
2022-04-06 01:10:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 15
2022-04-06 01:10:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 14
2022-04-06 01:10:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 13
2022-04-06 01:10:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 12
2022-04-06 01:10:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 11
2022-04-06 01:10:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 10
2022-04-06 01:10:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 9
2022-04-06 01:10:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 8
2022-04-06 01:10:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 7
2022-04-06 01:10:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 6
2022-04-06 01:10:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 5
2022-04-06 01:10:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 4
2022-04-06 01:10:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 3
2022-04-06 01:10:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 2
2022-04-06 01:10:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 1
2022-04-06 01:10:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-839c30ae-kafka-0=0e31e792-5bcc-450e-9851-8ae48a9762f6, my-cluster-839c30ae-kafka-1=cd40e717-2bc8-40c4-9c08-9687d6471727, my-cluster-839c30ae-kafka-2=c239e46f-a1db-4f49-affa-44f376fcf21c} pods didn't roll. Remaining seconds for stability: 0
2022-04-06 01:10:52 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-839c30ae-kafka rolling update
2022-04-06 01:12:17 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-839c30ae-kafka has been successfully rolled
2022-04-06 01:12:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:12:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetKafkaExternalLogging
2022-04-06 01:12:21 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-839c30ae in namespace namespace-86
2022-04-06 01:12:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:12:31 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-86 for test case:testDynamicallySetKafkaExternalLogging
2022-04-06 01:13:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaExternalLogging-FINISHED
2022-04-06 01:13:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:13:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:13:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testNotExistingCMSetsDefaultLogging-STARTED
2022-04-06 01:13:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:13:14 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-87 for test case:testNotExistingCMSetsDefaultLogging
2022-04-06 01:13:14 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-87
2022-04-06 01:13:15 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-87
2022-04-06 01:13:15 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-87
2022-04-06 01:13:15 [main] [32mINFO [m [TestUtils:197] /home/ec2-user/strimzi-kafka-operator/systemtest/../cluster-operator/src/main/resources/kafkaDefaultLoggingProperties
2022-04-06 01:13:15 [main] [32mINFO [m [LoggingChangeST:1320] Deploying Kafka with custom logging
2022-04-06 01:13:15 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-af801b5f in namespace namespace-87
2022-04-06 01:13:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-87
2022-04-06 01:13:15 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-af801b5f will have desired state: Ready
2022-04-06 01:14:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-af801b5f is in desired state: Ready
2022-04-06 01:14:28 [main] [32mINFO [m [LoggingChangeST:1344] Changing external logging's CM to not existing one
2022-04-06 01:14:28 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 50
2022-04-06 01:14:29 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 49
2022-04-06 01:14:30 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 48
2022-04-06 01:14:31 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 47
2022-04-06 01:14:32 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 46
2022-04-06 01:14:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 45
2022-04-06 01:14:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 44
2022-04-06 01:14:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 43
2022-04-06 01:14:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 42
2022-04-06 01:14:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 41
2022-04-06 01:14:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 40
2022-04-06 01:14:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 39
2022-04-06 01:14:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 38
2022-04-06 01:14:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 37
2022-04-06 01:14:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 36
2022-04-06 01:14:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 35
2022-04-06 01:14:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 34
2022-04-06 01:14:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 33
2022-04-06 01:14:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 32
2022-04-06 01:14:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 31
2022-04-06 01:14:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 30
2022-04-06 01:14:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 29
2022-04-06 01:14:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 28
2022-04-06 01:14:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 27
2022-04-06 01:14:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 26
2022-04-06 01:14:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 25
2022-04-06 01:14:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 24
2022-04-06 01:14:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 23
2022-04-06 01:14:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 22
2022-04-06 01:14:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 21
2022-04-06 01:14:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 20
2022-04-06 01:14:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 19
2022-04-06 01:15:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 18
2022-04-06 01:15:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 17
2022-04-06 01:15:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 16
2022-04-06 01:15:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 15
2022-04-06 01:15:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 14
2022-04-06 01:15:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 13
2022-04-06 01:15:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 12
2022-04-06 01:15:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 11
2022-04-06 01:15:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 10
2022-04-06 01:15:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 9
2022-04-06 01:15:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 8
2022-04-06 01:15:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 7
2022-04-06 01:15:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 6
2022-04-06 01:15:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 5
2022-04-06 01:15:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 4
2022-04-06 01:15:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 3
2022-04-06 01:15:16 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 2
2022-04-06 01:15:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 1
2022-04-06 01:15:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-af801b5f-kafka-2=abd552a4-8d13-4bb7-bd69-9a46fed9a2e7, my-cluster-af801b5f-kafka-1=09180a4e-bcc3-4c9d-acb9-a4baa8c9aee3, my-cluster-af801b5f-kafka-0=87ee2515-6727-4adc-aae5-4fb3f89b3e4c} pods didn't roll. Remaining seconds for stability: 0
2022-04-06 01:15:18 [main] [32mINFO [m [LoggingChangeST:1358] Checking that log4j.properties in custom-config isn't empty and configuration is default
2022-04-06 01:15:18 [main] [32mINFO [m [LoggingChangeST:1366] Checking if Kafka:my-cluster-af801b5f contains error about non-existing CM
2022-04-06 01:15:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:15:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNotExistingCMSetsDefaultLogging
2022-04-06 01:15:18 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-af801b5f in namespace namespace-87
2022-04-06 01:15:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:15:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-87 for test case:testNotExistingCMSetsDefaultLogging
2022-04-06 01:16:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testNotExistingCMSetsDefaultLogging-FINISHED
2022-04-06 01:16:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:16:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:16:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetConnectLoggingLevels-STARTED
2022-04-06 01:16:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:16:12 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-88 for test case:testDynamicallySetConnectLoggingLevels
2022-04-06 01:16:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-88
2022-04-06 01:16:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-88
2022-04-06 01:16:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-88
2022-04-06 01:16:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5a990001 in namespace namespace-88
2022-04-06 01:16:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-06 01:16:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5a990001 will have desired state: Ready
2022-04-06 01:17:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5a990001 is in desired state: Ready
2022-04-06 01:17:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5a990001-scraper in namespace namespace-88
2022-04-06 01:17:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-06 01:17:28 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5a990001-scraper will be ready
2022-04-06 01:17:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5a990001-scraper is ready
2022-04-06 01:17:30 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-5a990001-scraper to be ready
2022-04-06 01:17:40 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-5a990001-scraper is ready
2022-04-06 01:17:40 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-5a990001-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 01:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-5a990001-allow in namespace namespace-88
2022-04-06 01:17:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-06 01:17:40 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 01:17:40 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-5a990001 in namespace namespace-88
2022-04-06 01:17:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-88
2022-04-06 01:17:40 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-5a990001 will have desired state: Ready
2022-04-06 01:18:46 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-5a990001 is in desired state: Ready
2022-04-06 01:18:46 [main] [32mINFO [m [LoggingChangeST:703] Asserting if log is without records
2022-04-06 01:18:46 [main] [32mINFO [m [LoggingChangeST:706] Changing rootLogger level to DEBUG with inline logging
2022-04-06 01:18:46 [main] [32mINFO [m [LoggingChangeST:715] Waiting for log4j.properties will contain desired settings
2022-04-06 01:18:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-88 exec my-cluster-5a990001-scraper-558b6cd868-r6wtq -- curl http://my-cluster-5a990001-connect-api:8083/admin/loggers/root
2022-04-06 01:18:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:46 [main] [32mINFO [m [LoggingChangeST:760] Setting log level of Connect to OFF
2022-04-06 01:18:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-88 exec my-cluster-5a990001-scraper-558b6cd868-r6wtq -- curl http://my-cluster-5a990001-connect-api:8083/admin/loggers/root
2022-04-06 01:18:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:18:48 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-88 exec my-cluster-5a990001-scraper-558b6cd868-r6wtq -- curl http://my-cluster-5a990001-connect-api:8083/admin/loggers/root
2022-04-06 01:18:48 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:19:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:19:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetConnectLoggingLevels
2022-04-06 01:19:17 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-5a990001-allow in namespace namespace-88
2022-04-06 01:19:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5a990001-scraper in namespace namespace-88
2022-04-06 01:19:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-5a990001 in namespace namespace-88
2022-04-06 01:19:17 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5a990001 in namespace namespace-88
2022-04-06 01:20:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:20:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-88 for test case:testDynamicallySetConnectLoggingLevels
2022-04-06 01:20:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetConnectLoggingLevels-FINISHED
2022-04-06 01:20:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:20:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:20:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testMM2LoggingLevelsHierarchy-STARTED
2022-04-06 01:20:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:20:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-89 for test case:testMM2LoggingLevelsHierarchy
2022-04-06 01:20:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-89
2022-04-06 01:20:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-89
2022-04-06 01:20:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-89
2022-04-06 01:20:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7cc90998-source in namespace namespace-89
2022-04-06 01:20:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-06 01:20:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7cc90998-source will have desired state: Ready
2022-04-06 01:21:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7cc90998-source is in desired state: Ready
2022-04-06 01:21:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7cc90998-target in namespace namespace-89
2022-04-06 01:21:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-06 01:21:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7cc90998-target will have desired state: Ready
2022-04-06 01:23:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7cc90998-target is in desired state: Ready
2022-04-06 01:23:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7cc90998-kafka-clients in namespace namespace-89
2022-04-06 01:23:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-06 01:23:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-7cc90998 in namespace namespace-89
2022-04-06 01:23:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-89
2022-04-06 01:23:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-7cc90998 will have desired state: Ready
2022-04-06 01:24:14 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-7cc90998 is in desired state: Ready
2022-04-06 01:24:14 [main] [32mINFO [m [LoggingChangeST:1253] Waiting for log4j.properties will contain desired settings
2022-04-06 01:24:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-7cc90998-mirrormaker2-5b48b97bc6-gjxds -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:24:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:24:15 [main] [32mINFO [m [LoggingChangeST:1258] Changing log levels
2022-04-06 01:24:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-7cc90998-mirrormaker2-5b48b97bc6-gjxds -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:24:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:24:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-7cc90998-mirrormaker2-5b48b97bc6-gjxds -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:24:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:24:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-7cc90998-mirrormaker2-5b48b97bc6-gjxds -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:24:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:24:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-7cc90998-mirrormaker2-5b48b97bc6-gjxds -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:24:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:24:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-7cc90998-mirrormaker2-5b48b97bc6-gjxds -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:24:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:24:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-7cc90998-mirrormaker2-5b48b97bc6-gjxds -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:24:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:24:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-7cc90998-mirrormaker2-5b48b97bc6-gjxds -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:24:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:24:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-7cc90998-mirrormaker2-5b48b97bc6-gjxds -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:24:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:24:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-7cc90998-mirrormaker2-5b48b97bc6-gjxds -- curl http://localhost:8083/admin/loggers/org.eclipse.jetty.util.thread.strategy.EatWhatYouKill
2022-04-06 01:24:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:24:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-89 exec my-cluster-7cc90998-mirrormaker2-5b48b97bc6-gjxds -- curl http://localhost:8083/admin/loggers/org.apache.kafka.connect.runtime.WorkerTask
2022-04-06 01:24:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:24:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:24:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMM2LoggingLevelsHierarchy
2022-04-06 01:24:24 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7cc90998-kafka-clients in namespace namespace-89
2022-04-06 01:24:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-7cc90998 in namespace namespace-89
2022-04-06 01:24:24 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7cc90998-target in namespace namespace-89
2022-04-06 01:24:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7cc90998-source in namespace namespace-89
2022-04-06 01:25:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:25:24 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-89 for test case:testMM2LoggingLevelsHierarchy
2022-04-06 01:25:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testMM2LoggingLevelsHierarchy-FINISHED
2022-04-06 01:25:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:25:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:25:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testLoggingHierarchy-STARTED
2022-04-06 01:25:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:25:31 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-90 for test case:testLoggingHierarchy
2022-04-06 01:25:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-90
2022-04-06 01:25:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-90
2022-04-06 01:25:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-90
2022-04-06 01:25:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-de4a6aab in namespace namespace-90
2022-04-06 01:25:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-06 01:25:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-de4a6aab will have desired state: Ready
2022-04-06 01:26:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-de4a6aab is in desired state: Ready
2022-04-06 01:26:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-de4a6aab-scraper in namespace namespace-90
2022-04-06 01:26:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-06 01:26:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-de4a6aab-scraper will be ready
2022-04-06 01:26:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-de4a6aab-scraper is ready
2022-04-06 01:26:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-de4a6aab-scraper to be ready
2022-04-06 01:26:58 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-de4a6aab-scraper is ready
2022-04-06 01:26:58 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-de4a6aab-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 01:26:58 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-de4a6aab-allow in namespace namespace-90
2022-04-06 01:26:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-06 01:26:58 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 01:26:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-de4a6aab in namespace namespace-90
2022-04-06 01:26:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-06 01:26:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-de4a6aab in namespace namespace-90
2022-04-06 01:26:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-90
2022-04-06 01:26:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-de4a6aab will have desired state: Ready
2022-04-06 01:28:06 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-de4a6aab is in desired state: Ready
2022-04-06 01:28:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-de4a6aab will have desired state: Ready
2022-04-06 01:28:06 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-de4a6aab is in desired state: Ready
2022-04-06 01:28:06 [main] [32mINFO [m [LoggingChangeST:1398] Changing rootLogger level in KafkaConnector to ERROR with inline logging
2022-04-06 01:28:06 [main] [32mINFO [m [LoggingChangeST:1404] Waiting for Connect API loggers will contain desired settings
2022-04-06 01:28:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:08 [main] [32mINFO [m [LoggingChangeST:1410] Restarting Kafka connector my-cluster-de4a6aab with class name org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl -X POST http://my-cluster-de4a6aab-connect-api:8083/connectors/my-cluster-de4a6aab/restart
2022-04-06 01:28:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:08 [main] [32mINFO [m [KafkaConnectorUtils:168] Wait until KafkaConnector my-cluster-de4a6aab's worker will be in RUNNING state
2022-04-06 01:28:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl GET http://my-cluster-de4a6aab-connect-api:8083/connectors/my-cluster-de4a6aab/status
2022-04-06 01:28:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:09 [main] [32mINFO [m [LoggingChangeST:1417] Checking that logger is same for connector with class name org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:09 [main] [32mINFO [m [LoggingChangeST:1423] Changing KafkaConnect's root logger to WARN, KafkaConnector: my-cluster-de4a6aab shouldn't inherit it
2022-04-06 01:28:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/root
2022-04-06 01:28:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:09 [main] [32mINFO [m [LoggingChangeST:1437] Checking if KafkaConnector org.apache.kafka.connect.file.FileStreamSourceConnector doesn't inherit logger from KafkaConnect
2022-04-06 01:28:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:09 [main] [33mWARN [m [KafkaConnectorUtils:191] Logger level has changed: {"level":"WARN"}
. Reseting counter from 0 to 0
2022-04-06 01:28:10 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:10 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:10 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 49
2022-04-06 01:28:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:12 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 48
2022-04-06 01:28:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:13 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 47
2022-04-06 01:28:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:14 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 46
2022-04-06 01:28:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:15 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 45
2022-04-06 01:28:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:16 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 44
2022-04-06 01:28:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:17 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 43
2022-04-06 01:28:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:19 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 42
2022-04-06 01:28:20 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:20 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:20 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 41
2022-04-06 01:28:21 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:21 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:21 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 40
2022-04-06 01:28:22 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:22 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:22 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 39
2022-04-06 01:28:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:23 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 38
2022-04-06 01:28:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:25 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 37
2022-04-06 01:28:26 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:26 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:26 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 36
2022-04-06 01:28:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:27 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 35
2022-04-06 01:28:28 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:28 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:28 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 34
2022-04-06 01:28:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:29 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 33
2022-04-06 01:28:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:31 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 32
2022-04-06 01:28:32 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:32 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:32 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 31
2022-04-06 01:28:33 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:33 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 30
2022-04-06 01:28:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:34 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 29
2022-04-06 01:28:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:35 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 28
2022-04-06 01:28:37 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:37 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:37 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 27
2022-04-06 01:28:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:38 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 26
2022-04-06 01:28:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:39 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 25
2022-04-06 01:28:40 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:40 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:40 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 24
2022-04-06 01:28:41 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:41 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 23
2022-04-06 01:28:43 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:43 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:43 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 22
2022-04-06 01:28:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:44 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 21
2022-04-06 01:28:45 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:45 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:45 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 20
2022-04-06 01:28:46 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:46 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 19
2022-04-06 01:28:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:47 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 18
2022-04-06 01:28:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:49 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 17
2022-04-06 01:28:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:50 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 16
2022-04-06 01:28:51 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:51 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 15
2022-04-06 01:28:52 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:52 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:52 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 14
2022-04-06 01:28:53 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:53 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:53 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 13
2022-04-06 01:28:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:55 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 12
2022-04-06 01:28:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:56 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 11
2022-04-06 01:28:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:57 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 10
2022-04-06 01:28:58 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:58 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 9
2022-04-06 01:28:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:28:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:28:59 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 8
2022-04-06 01:29:01 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:29:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:29:01 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 7
2022-04-06 01:29:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:29:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:29:02 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 6
2022-04-06 01:29:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:29:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:29:03 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 5
2022-04-06 01:29:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:29:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:29:04 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 4
2022-04-06 01:29:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:29:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:29:05 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 3
2022-04-06 01:29:07 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:29:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:29:07 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 2
2022-04-06 01:29:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:29:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:29:08 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 1
2022-04-06 01:29:09 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-90 exec my-cluster-de4a6aab-scraper-68778cddf-dfwsb -- curl http://my-cluster-de4a6aab-connect-api:8083/admin/loggers/org.apache.kafka.connect.file.FileStreamSourceConnector
2022-04-06 01:29:09 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:29:09 [main] [32mINFO [m [KafkaConnectorUtils:189] Logger level is ERROR. Remaining seconds for logger to be stable: 0
2022-04-06 01:29:09 [main] [32mINFO [m [KafkaConnectorUtils:196] Logger for connector org.apache.kafka.connect.file.FileStreamSourceConnector is stable
2022-04-06 01:29:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:29:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testLoggingHierarchy
2022-04-06 01:29:09 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-de4a6aab-allow in namespace namespace-90
2022-04-06 01:29:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-de4a6aab-scraper in namespace namespace-90
2022-04-06 01:29:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-de4a6aab in namespace namespace-90
2022-04-06 01:29:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-de4a6aab in namespace namespace-90
2022-04-06 01:29:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-de4a6aab in namespace namespace-90
2022-04-06 01:29:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:29:59 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-90 for test case:testLoggingHierarchy
2022-04-06 01:30:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testLoggingHierarchy-FINISHED
2022-04-06 01:30:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:30:04 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:30:04 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testJSONFormatLogging-STARTED
2022-04-06 01:30:04 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:30:04 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-91 for test case:testJSONFormatLogging
2022-04-06 01:30:04 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-91
2022-04-06 01:30:05 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-91
2022-04-06 01:30:05 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-91
2022-04-06 01:30:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2eedb237 in namespace namespace-91
2022-04-06 01:30:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-91
2022-04-06 01:30:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2eedb237 will have desired state: Ready
2022-04-06 01:31:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2eedb237 is in desired state: Ready
2022-04-06 01:31:28 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: strimzi-cluster-operator-78689684d4-t475h
2022-04-06 01:31:28 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2eedb237-kafka-2
2022-04-06 01:31:28 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2eedb237-kafka-1
2022-04-06 01:31:28 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2eedb237-kafka-0
2022-04-06 01:31:28 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2eedb237-zookeeper-1
2022-04-06 01:31:29 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2eedb237-zookeeper-0
2022-04-06 01:31:29 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2eedb237-zookeeper-2
2022-04-06 01:31:29 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2eedb237-entity-operator-6c458885c7-xq8pp
2022-04-06 01:31:29 [main] [32mINFO [m [StUtils:278] JSON format logging successfully set for pod: my-cluster-2eedb237-entity-operator-6c458885c7-xq8pp
2022-04-06 01:31:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:31:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJSONFormatLogging
2022-04-06 01:31:29 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2eedb237 in namespace namespace-91
2022-04-06 01:31:39 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:31:39 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-91 for test case:testJSONFormatLogging
2022-04-06 01:32:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testJSONFormatLogging-FINISHED
2022-04-06 01:32:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:32:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:32:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaLoggingLevels-STARTED
2022-04-06 01:32:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:32:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-92 for test case:testDynamicallySetKafkaLoggingLevels
2022-04-06 01:32:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-92
2022-04-06 01:32:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-92
2022-04-06 01:32:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-92
2022-04-06 01:32:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a9b8e37f in namespace namespace-92
2022-04-06 01:32:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-92
2022-04-06 01:32:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a9b8e37f will have desired state: Ready
2022-04-06 01:33:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a9b8e37f is in desired state: Ready
2022-04-06 01:33:39 [main] [32mINFO [m [LoggingChangeST:828] Changing rootLogger level to DEBUG with inline logging
2022-04-06 01:33:39 [main] [32mINFO [m [LoggingChangeST:835] Waiting for dynamic change in the kafka pod
2022-04-06 01:33:46 [main] [32mINFO [m [LoggingChangeST:853] Setting external logging INFO
2022-04-06 01:33:46 [main] [32mINFO [m [LoggingChangeST:889] Setting log level of kafka INFO
2022-04-06 01:33:46 [main] [32mINFO [m [LoggingChangeST:895] Waiting for dynamic change in the kafka pod
2022-04-06 01:33:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:33:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetKafkaLoggingLevels
2022-04-06 01:33:50 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a9b8e37f in namespace namespace-92
2022-04-06 01:34:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:34:00 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-92 for test case:testDynamicallySetKafkaLoggingLevels
2022-04-06 01:34:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetKafkaLoggingLevels-FINISHED
2022-04-06 01:34:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:34:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:34:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetEOloggingLevels-STARTED
2022-04-06 01:34:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:34:44 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-93 for test case:testDynamicallySetEOloggingLevels
2022-04-06 01:34:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-93
2022-04-06 01:34:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-93
2022-04-06 01:34:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-93
2022-04-06 01:34:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c9fe2216 in namespace namespace-93
2022-04-06 01:34:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-93
2022-04-06 01:34:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c9fe2216 will have desired state: Ready
2022-04-06 01:35:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c9fe2216 is in desired state: Ready
2022-04-06 01:35:56 [main] [32mINFO [m [LoggingChangeST:285] Checking if EO pod contains any log (except configuration)
2022-04-06 01:35:56 [main] [32mINFO [m [LoggingChangeST:288] Changing rootLogger level to DEBUG with inline logging
2022-04-06 01:35:56 [main] [32mINFO [m [LoggingChangeST:296] Waiting for log4j2.properties will contain desired settings
2022-04-06 01:37:13 [main] [32mINFO [m [LoggingChangeST:313] Setting external logging OFF
2022-04-06 01:37:13 [main] [32mINFO [m [LoggingChangeST:371] Setting log level of TO and UO to OFF - records should not appear in log
2022-04-06 01:37:13 [main] [32mINFO [m [LoggingChangeST:378] Waiting for log4j2.properties will contain desired settings
2022-04-06 01:38:37 [main] [32mINFO [m [LoggingChangeST:396] Setting external logging OFF
2022-04-06 01:38:37 [main] [32mINFO [m [LoggingChangeST:432] Waiting for log4j2.properties will contain desired settings
2022-04-06 01:39:43 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:39:43 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetEOloggingLevels
2022-04-06 01:39:43 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c9fe2216 in namespace namespace-93
2022-04-06 01:39:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:39:53 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-93 for test case:testDynamicallySetEOloggingLevels
2022-04-06 01:40:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetEOloggingLevels-FINISHED
2022-04-06 01:40:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:40:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:40:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLoggerValue-STARTED
2022-04-06 01:40:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:40:20 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-94 for test case:testDynamicallySetUnknownKafkaLoggerValue
2022-04-06 01:40:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-94
2022-04-06 01:40:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-94
2022-04-06 01:40:20 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-94
2022-04-06 01:40:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3ab51f4a in namespace namespace-94
2022-04-06 01:40:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-94
2022-04-06 01:40:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3ab51f4a will have desired state: Ready
2022-04-06 01:41:33 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3ab51f4a is in desired state: Ready
2022-04-06 01:41:33 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 50
2022-04-06 01:41:34 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 49
2022-04-06 01:41:35 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 48
2022-04-06 01:41:36 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 47
2022-04-06 01:41:37 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 46
2022-04-06 01:41:38 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 45
2022-04-06 01:41:39 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 44
2022-04-06 01:41:40 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 43
2022-04-06 01:41:41 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 42
2022-04-06 01:41:42 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 41
2022-04-06 01:41:43 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 40
2022-04-06 01:41:44 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 39
2022-04-06 01:41:45 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 38
2022-04-06 01:41:46 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 37
2022-04-06 01:41:47 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 36
2022-04-06 01:41:48 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 35
2022-04-06 01:41:49 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 34
2022-04-06 01:41:50 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 33
2022-04-06 01:41:51 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 32
2022-04-06 01:41:52 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 31
2022-04-06 01:41:53 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 30
2022-04-06 01:41:54 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 29
2022-04-06 01:41:55 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 28
2022-04-06 01:41:56 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 27
2022-04-06 01:41:57 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 26
2022-04-06 01:41:58 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 25
2022-04-06 01:41:59 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 24
2022-04-06 01:42:00 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 23
2022-04-06 01:42:01 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 22
2022-04-06 01:42:02 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 21
2022-04-06 01:42:03 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 20
2022-04-06 01:42:04 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 19
2022-04-06 01:42:05 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 18
2022-04-06 01:42:06 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 17
2022-04-06 01:42:07 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 16
2022-04-06 01:42:08 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 15
2022-04-06 01:42:09 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 14
2022-04-06 01:42:10 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 13
2022-04-06 01:42:11 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 12
2022-04-06 01:42:12 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 11
2022-04-06 01:42:13 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 10
2022-04-06 01:42:14 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 9
2022-04-06 01:42:15 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 8
2022-04-06 01:42:17 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 7
2022-04-06 01:42:18 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 6
2022-04-06 01:42:19 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 5
2022-04-06 01:42:20 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 4
2022-04-06 01:42:21 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 3
2022-04-06 01:42:22 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 2
2022-04-06 01:42:23 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 1
2022-04-06 01:42:24 [main] [32mINFO [m [RollingUpdateUtils:143] {my-cluster-3ab51f4a-kafka-2=6207c335-2b95-4db0-be6f-013fd6208a79, my-cluster-3ab51f4a-kafka-1=9e89b159-fe55-4227-b3e3-78d5d9a3d557, my-cluster-3ab51f4a-kafka-0=cffe94de-ec50-4d67-97ea-83494c5cb880} pods didn't roll. Remaining seconds for stability: 0
2022-04-06 01:42:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:42:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetUnknownKafkaLoggerValue
2022-04-06 01:42:24 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3ab51f4a in namespace namespace-94
2022-04-06 01:42:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:42:34 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-94 for test case:testDynamicallySetUnknownKafkaLoggerValue
2022-04-06 01:43:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetUnknownKafkaLoggerValue-FINISHED
2022-04-06 01:43:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:43:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:43:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetBridgeLoggingLevels-STARTED
2022-04-06 01:43:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:43:17 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-95 for test case:testDynamicallySetBridgeLoggingLevels
2022-04-06 01:43:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-95
2022-04-06 01:43:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-95
2022-04-06 01:43:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-95
2022-04-06 01:43:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-61d014c8 in namespace namespace-95
2022-04-06 01:43:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-06 01:43:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-61d014c8-kafka-clients in namespace namespace-95
2022-04-06 01:43:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-06 01:43:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-61d014c8 in namespace namespace-95
2022-04-06 01:43:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-95
2022-04-06 01:43:17 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-61d014c8 will have desired state: Ready
2022-04-06 01:44:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-61d014c8 is in desired state: Ready
2022-04-06 01:44:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-61d014c8-kafka-clients will be ready
2022-04-06 01:44:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-61d014c8-kafka-clients is ready
2022-04-06 01:44:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-61d014c8 will have desired state: Ready
2022-04-06 01:44:27 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-61d014c8 is in desired state: Ready
2022-04-06 01:44:27 [main] [32mINFO [m [LoggingChangeST:485] Asserting if log is without records
2022-04-06 01:44:28 [main] [32mINFO [m [LoggingChangeST:488] Changing rootLogger level to DEBUG with inline logging
2022-04-06 01:44:28 [main] [32mINFO [m [LoggingChangeST:500] Waiting for log4j2.properties will contain desired settings
2022-04-06 01:45:25 [main] [32mINFO [m [LoggingChangeST:557] Setting log level of Bridge to OFF - records should not appear in the log
2022-04-06 01:45:25 [main] [32mINFO [m [LoggingChangeST:563] Waiting for log4j2.properties will contain desired settings
2022-04-06 01:47:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:47:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetBridgeLoggingLevels
2022-04-06 01:47:25 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-61d014c8-kafka-clients in namespace namespace-95
2022-04-06 01:47:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-61d014c8 in namespace namespace-95
2022-04-06 01:47:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-61d014c8 in namespace namespace-95
2022-04-06 01:48:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:48:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-95 for test case:testDynamicallySetBridgeLoggingLevels
2022-04-06 01:48:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetBridgeLoggingLevels-FINISHED
2022-04-06 01:48:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:48:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:48:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetMM2LoggingLevels-STARTED
2022-04-06 01:48:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:48:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-96 for test case:testDynamicallySetMM2LoggingLevels
2022-04-06 01:48:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-96
2022-04-06 01:48:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-96
2022-04-06 01:48:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-96
2022-04-06 01:48:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a3d9bb6c-source in namespace namespace-96
2022-04-06 01:48:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-06 01:48:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a3d9bb6c-source will have desired state: Ready
2022-04-06 01:49:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a3d9bb6c-source is in desired state: Ready
2022-04-06 01:49:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a3d9bb6c-target in namespace namespace-96
2022-04-06 01:49:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-06 01:49:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a3d9bb6c-target will have desired state: Ready
2022-04-06 01:50:59 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a3d9bb6c-target is in desired state: Ready
2022-04-06 01:50:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-a3d9bb6c-kafka-clients in namespace namespace-96
2022-04-06 01:50:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-06 01:50:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-a3d9bb6c in namespace namespace-96
2022-04-06 01:50:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-96
2022-04-06 01:50:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-a3d9bb6c will have desired state: Ready
2022-04-06 01:52:11 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-a3d9bb6c is in desired state: Ready
2022-04-06 01:52:11 [main] [32mINFO [m [LoggingChangeST:1123] Changing rootLogger level to DEBUG with inline logging
2022-04-06 01:52:11 [main] [32mINFO [m [LoggingChangeST:1132] Waiting for log4j.properties will contain desired settings
2022-04-06 01:52:11 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-a3d9bb6c-mirrormaker2-7494d5bcc8-2sqsr -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:52:11 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:52:11 [main] [32mINFO [m [LoggingChangeST:1176] Setting log level of MM2 to OFF
2022-04-06 01:52:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-a3d9bb6c-mirrormaker2-7494d5bcc8-2sqsr -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:52:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:52:14 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-96 exec my-cluster-a3d9bb6c-mirrormaker2-7494d5bcc8-2sqsr -- curl http://localhost:8083/admin/loggers/root
2022-04-06 01:52:14 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:52:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:52:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDynamicallySetMM2LoggingLevels
2022-04-06 01:52:14 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-a3d9bb6c-kafka-clients in namespace namespace-96
2022-04-06 01:52:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-a3d9bb6c in namespace namespace-96
2022-04-06 01:52:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a3d9bb6c-target in namespace namespace-96
2022-04-06 01:52:14 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a3d9bb6c-source in namespace namespace-96
2022-04-06 01:53:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:53:14 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-96 for test case:testDynamicallySetMM2LoggingLevels
2022-04-06 01:53:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LoggingChangeST.testDynamicallySetMM2LoggingLevels-FINISHED
2022-04-06 01:53:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:53:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:53:21 [main] [32mINFO [m [ResourceManager:346] In context LoggingChangeST is everything deleted.
2022-04-06 01:53:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,989.41 s - in io.strimzi.systemtest.log.LoggingChangeST
[[1;34mINFO[m] Running io.strimzi.systemtest.log.LogSettingST
2022-04-06 01:53:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: log-setting-st
2022-04-06 01:53:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: log-setting-st
2022-04-06 01:53:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: log-setting-st
2022-04-06 01:53:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka log-setting-cluster-name in namespace log-setting-st
2022-04-06 01:53:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka gc-set-logging in namespace log-setting-st
2022-04-06 01:53:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment shared-kafka-clients in namespace log-setting-st
2022-04-06 01:53:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: log-setting-cluster-name will have desired state: Ready
2022-04-06 01:55:30 [main] [32mINFO [m [ResourceManager:444] Kafka: log-setting-cluster-name is in desired state: Ready
2022-04-06 01:55:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: gc-set-logging will have desired state: Ready
2022-04-06 01:55:30 [main] [32mINFO [m [ResourceManager:444] Kafka: gc-set-logging is in desired state: Ready
2022-04-06 01:55:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: shared-kafka-clients will be ready
2022-04-06 01:55:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: shared-kafka-clients is ready
2022-04-06 01:55:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:55:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testMirrorMaker2LogSetting-STARTED
2022-04-06 01:55:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:55:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-2b30257b-mirror-maker-2 in namespace log-setting-st
2022-04-06 01:55:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-2b30257b-mirror-maker-2 will have desired state: Ready
2022-04-06 01:56:37 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-2b30257b-mirror-maker-2 is in desired state: Ready
2022-04-06 01:56:37 [main] [32mINFO [m [LogSettingST:357] Checking if MirrorMaker2 has log level set properly
2022-04-06 01:56:37 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: mirrormaker.root.logger Expected: TRACE
2022-04-06 01:56:37 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.mirrormaker.logger.level Expected: TRACE
2022-04-06 01:56:37 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-2b30257b-mirror-maker-2-mirrormaker2
2022-04-06 01:56:37 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-2b30257b-mirror-maker-2-mirrormaker2
2022-04-06 01:56:37 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 01:56:37 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-2b30257b-mirror-maker-2-mirrormaker2 rolling update
2022-04-06 01:57:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2b30257b-mirror-maker-2-mirrormaker2 will be ready
2022-04-06 01:57:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2b30257b-mirror-maker-2-mirrormaker2 is ready
2022-04-06 01:58:07 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-2b30257b-mirror-maker-2-mirrormaker2 rolling update finished
2022-04-06 01:58:07 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-2b30257b-mirror-maker-2-mirrormaker2
2022-04-06 01:58:07 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-2b30257b-mirror-maker-2-mirrormaker2
2022-04-06 01:58:07 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 01:58:08 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-2b30257b-mirror-maker-2-mirrormaker2-597b7788ffhml8m container my-cluster-2b30257b-mirror-maker-2-mirrormaker2 will be ready
2022-04-06 01:58:08 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-2b30257b-mirror-maker-2-mirrormaker2-597b7788ffhml8m container my-cluster-2b30257b-mirror-maker-2-mirrormaker2 is ready
2022-04-06 01:58:08 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-2b30257b-mirror-maker-2-mirrormaker2-597b7788ffhml8m with container my-cluster-2b30257b-mirror-maker-2-mirrormaker2
2022-04-06 01:58:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:58:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2LogSetting
2022-04-06 01:58:08 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-2b30257b-mirror-maker-2 in namespace log-setting-st
2022-04-06 01:58:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:58:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testMirrorMaker2LogSetting-FINISHED
2022-04-06 01:58:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:58:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:58:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testCruiseControlLogChange-STARTED
2022-04-06 01:58:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:58:18 [main] [32mINFO [m [LogSettingST:409] Check that default/actual root logging level is info
2022-04-06 01:58:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-749bc67d6d-mj29d -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 01:58:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:58:18 [main] [32mINFO [m [LogSettingST:414] Check logs in CruiseControl - make sure no DEBUG is found there.
2022-04-06 01:58:18 [main] [32mINFO [m [LogSettingST:422] Wait for change of root logger in log-setting-cluster-name-cruise-control-749bc67d6d-mj29d.
2022-04-06 01:58:19 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-749bc67d6d-mj29d -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 01:58:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:58:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-749bc67d6d-mj29d -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 01:58:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:58:29 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-749bc67d6d-mj29d -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 01:58:29 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:58:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-749bc67d6d-mj29d -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 01:58:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:58:39 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-749bc67d6d-mj29d -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 01:58:39 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:58:44 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-749bc67d6d-mj29d -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 01:58:44 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:58:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-749bc67d6d-mj29d -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 01:58:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:58:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-749bc67d6d-mj29d -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 01:58:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:59:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace log-setting-st exec log-setting-cluster-name-cruise-control-749bc67d6d-mj29d -- grep -i rootlogger.level /opt/cruise-control/custom-config/log4j2.properties
2022-04-06 01:59:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 01:59:00 [main] [32mINFO [m [LogSettingST:428] Check cruise control logs in pod log-setting-cluster-name-cruise-control-749bc67d6d-mj29d and it's container cruise-control .
2022-04-06 01:59:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 01:59:21 [main] [32mINFO [m [ResourceManager:346] In context testCruiseControlLogChange is everything deleted.
2022-04-06 01:59:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 01:59:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testCruiseControlLogChange-FINISHED
2022-04-06 01:59:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 01:59:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 01:59:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testMirrorMakerLogSetting-STARTED
2022-04-06 01:59:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 01:59:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-3b1bb420-mirror-maker in namespace log-setting-st
2022-04-06 01:59:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-3b1bb420-mirror-maker will have desired state: Ready
2022-04-06 02:00:30 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-3b1bb420-mirror-maker is in desired state: Ready
2022-04-06 02:00:30 [main] [32mINFO [m [LogSettingST:322] Checking if MirrorMaker has log level set properly
2022-04-06 02:00:30 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: mirrormaker.root.logger Expected: TRACE
2022-04-06 02:00:30 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.mirrormaker.logger.level Expected: TRACE
2022-04-06 02:00:30 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-3b1bb420-mirror-maker-mirror-maker
2022-04-06 02:00:30 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-3b1bb420-mirror-maker-mirror-maker
2022-04-06 02:00:30 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 02:00:30 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-3b1bb420-mirror-maker-mirror-maker rolling update
2022-04-06 02:01:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3b1bb420-mirror-maker-mirror-maker will be ready
2022-04-06 02:01:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3b1bb420-mirror-maker-mirror-maker is ready
2022-04-06 02:01:55 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-3b1bb420-mirror-maker-mirror-maker rolling update finished
2022-04-06 02:01:55 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-3b1bb420-mirror-maker-mirror-maker
2022-04-06 02:01:55 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-3b1bb420-mirror-maker-mirror-maker
2022-04-06 02:01:55 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:01:56 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-3b1bb420-mirror-maker-mirror-maker-7545f59fc-hvp4h container my-cluster-3b1bb420-mirror-maker-mirror-maker will be ready
2022-04-06 02:01:56 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-3b1bb420-mirror-maker-mirror-maker-7545f59fc-hvp4h container my-cluster-3b1bb420-mirror-maker-mirror-maker is ready
2022-04-06 02:01:56 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-3b1bb420-mirror-maker-mirror-maker-7545f59fc-hvp4h with container my-cluster-3b1bb420-mirror-maker-mirror-maker
2022-04-06 02:01:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:01:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerLogSetting
2022-04-06 02:01:56 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-3b1bb420-mirror-maker in namespace log-setting-st
2022-04-06 02:02:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:02:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testMirrorMakerLogSetting-FINISHED
2022-04-06 02:02:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:02:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:02:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testConnectLogSetting-STARTED
2022-04-06 02:02:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:02:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6a46ffdb-connect-scraper in namespace log-setting-st
2022-04-06 02:02:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6a46ffdb-connect-scraper will be ready
2022-04-06 02:02:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6a46ffdb-connect-scraper is ready
2022-04-06 02:02:08 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-6a46ffdb-connect-scraper to be ready
2022-04-06 02:02:18 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-6a46ffdb-connect-scraper is ready
2022-04-06 02:02:18 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-6a46ffdb-connect-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 02:02:18 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-6a46ffdb-connect-allow in namespace log-setting-st
2022-04-06 02:02:18 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 02:02:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-6a46ffdb-connect in namespace log-setting-st
2022-04-06 02:02:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-6a46ffdb-connect will have desired state: Ready
2022-04-06 02:03:25 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-6a46ffdb-connect is in desired state: Ready
2022-04-06 02:03:25 [main] [32mINFO [m [LogSettingST:287] Checking if Connect has log level set properly
2022-04-06 02:03:25 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.I0Itec.zkclient Expected: ERROR
2022-04-06 02:03:25 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: connect.root.logger.level Expected: INFO
2022-04-06 02:03:25 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.connect.logger.level Expected: DEBUG
2022-04-06 02:03:25 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.reflections Expected: WARN
2022-04-06 02:03:25 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-6a46ffdb-connect-connect
2022-04-06 02:03:25 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-6a46ffdb-connect-connect
2022-04-06 02:03:25 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 02:03:25 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-6a46ffdb-connect-connect rolling update
2022-04-06 02:04:35 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6a46ffdb-connect-connect will be ready
2022-04-06 02:04:35 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6a46ffdb-connect-connect is ready
2022-04-06 02:04:45 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-6a46ffdb-connect-connect rolling update finished
2022-04-06 02:04:45 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-6a46ffdb-connect-connect
2022-04-06 02:04:45 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-6a46ffdb-connect-connect
2022-04-06 02:04:45 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:04:46 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-6a46ffdb-connect-connect-76976cfdcb-8cjwf container my-cluster-6a46ffdb-connect-connect will be ready
2022-04-06 02:04:46 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-6a46ffdb-connect-connect-76976cfdcb-8cjwf container my-cluster-6a46ffdb-connect-connect is ready
2022-04-06 02:04:46 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-6a46ffdb-connect-connect-76976cfdcb-8cjwf with container my-cluster-6a46ffdb-connect-connect
2022-04-06 02:04:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:04:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConnectLogSetting
2022-04-06 02:04:46 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-6a46ffdb-connect-allow in namespace log-setting-st
2022-04-06 02:04:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6a46ffdb-connect-scraper in namespace log-setting-st
2022-04-06 02:04:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-6a46ffdb-connect in namespace log-setting-st
2022-04-06 02:05:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:05:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testConnectLogSetting-FINISHED
2022-04-06 02:05:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:05:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:05:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testKafkaLogSetting-STARTED
2022-04-06 02:05:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:05:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-953144602-307635766 in namespace log-setting-st
2022-04-06 02:05:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-953144602-307635766 will have desired state: Ready
2022-04-06 02:05:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-953144602-307635766 is in desired state: Ready
2022-04-06 02:05:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1288556036-1115785912 in namespace log-setting-st
2022-04-06 02:05:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1288556036-1115785912 will have desired state: Ready
2022-04-06 02:05:38 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1288556036-1115785912 is in desired state: Ready
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:217] Checking if Kafka, Zookeeper, TO and UO of cluster:log-setting-cluster-name has log level set properly
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.apache.zookeeper Expected: WARN
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.network.Processor Expected: OFF
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.request.logger Expected: FATAL
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.controller Expected: WARN
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: kafka.root.logger.level Expected: INFO
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.state.change.logger Expected: DEBUG
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.network.RequestChannel$ Expected: ERROR
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.server.KafkaApis Expected: INFO
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka Expected: TRACE
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.apache.kafka Expected: DEBUG
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.authorizer.logger Expected: FATAL
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.kafka.log.LogCleaner Expected: TRACE
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: log4j.logger.org.I0Itec.zkclient.ZkClient Expected: ERROR
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.kafka.logger.level Expected: INFO
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: zookeeper.root.logger Expected: OFF
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.zookeeper.logger.level Expected: DEBUG
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: rootLogger.level Expected: DEBUG
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.operator.logger.level Expected: DEBUG
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: rootLogger.level Expected: DEBUG
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.operator.logger.level Expected: DEBUG
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:226] Checking if Kafka, Zookeeper, TO and UO of cluster:log-setting-cluster-name has GC logging enabled in stateful sets/deployments
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=true
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-06 02:05:38 [main] [32mINFO [m [LogSettingST:232] Changing JVM options - setting GC logging to false
2022-04-06 02:05:38 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: log-setting-cluster-name-zookeeper rolling update
2022-04-06 02:05:48 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: log-setting-cluster-name-zookeeper has been successfully rolled
2022-04-06 02:05:48 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 1 Pod(s) of log-setting-cluster-name-zookeeper to be ready
2022-04-06 02:06:18 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: log-setting-cluster-name-kafka rolling update
2022-04-06 02:07:18 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: log-setting-cluster-name-kafka has been successfully rolled
2022-04-06 02:07:18 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of log-setting-cluster-name-kafka to be ready
2022-04-06 02:07:43 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment log-setting-cluster-name-entity-operator rolling update
2022-04-06 02:07:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: log-setting-cluster-name-entity-operator will be ready
2022-04-06 02:08:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: log-setting-cluster-name-entity-operator is ready
2022-04-06 02:08:32 [main] [32mINFO [m [DeploymentUtils:141] Deployment log-setting-cluster-name-entity-operator rolling update finished
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:244] Checking if Kafka, Zookeeper, TO and UO of cluster: log-setting-cluster-name has GC logging disabled in stateful sets/deployments
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:250] Checking if Kafka, Zookeeper, TO and UO of cluster: gc-set-logging has GC logging disabled in stateful sets/deployments
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-kafka, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-0, container: kafka
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-1, container: kafka
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-kafka-2, container: kafka
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:512] Checking pods with selector: LabelSelector(matchExpressions=[], matchLabels={strimzi.io/name=log-setting-cluster-name-zookeeper, strimzi.io/cluster=log-setting-cluster-name, strimzi.io/kind=Kafka}, additionalProperties={})
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:516] Checking pod log-setting-cluster-name-zookeeper-0, container: zookeeper
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:529] STRIMZI_KAFKA_GC_LOG_ENABLED=false
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:493] Checking container with name: topic-operator
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:490] Checking deployment: log-setting-cluster-name-entity-operator
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:493] Checking container with name: user-operator
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-06 02:08:32 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-cruise-control-749bc67d6d-mj29d container cruise-control will be ready
2022-04-06 02:08:32 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-cruise-control-749bc67d6d-mj29d container cruise-control is ready
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-cruise-control-749bc67d6d-mj29d with container cruise-control
2022-04-06 02:08:32 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-cruise-control-749bc67d6d-mj29d container tls-sidecar will be ready
2022-04-06 02:08:32 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-cruise-control-749bc67d6d-mj29d container tls-sidecar is ready
2022-04-06 02:08:32 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-cruise-control-749bc67d6d-mj29d with container tls-sidecar
2022-04-06 02:08:33 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-chbln container topic-operator will be ready
2022-04-06 02:08:33 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-chbln container topic-operator is ready
2022-04-06 02:08:33 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-chbln with container topic-operator
2022-04-06 02:08:33 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-chbln container user-operator will be ready
2022-04-06 02:08:33 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-chbln container user-operator is ready
2022-04-06 02:08:33 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-chbln with container user-operator
2022-04-06 02:08:33 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-entity-operator-d78c874cf-chbln container tls-sidecar will be ready
2022-04-06 02:08:33 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-entity-operator-d78c874cf-chbln container tls-sidecar is ready
2022-04-06 02:08:33 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-entity-operator-d78c874cf-chbln with container tls-sidecar
2022-04-06 02:08:33 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-0 container kafka will be ready
2022-04-06 02:08:33 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-0 container kafka is ready
2022-04-06 02:08:33 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-0 with container kafka
2022-04-06 02:08:33 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-1 container kafka will be ready
2022-04-06 02:08:33 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-1 container kafka is ready
2022-04-06 02:08:33 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-1 with container kafka
2022-04-06 02:08:34 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-2 container kafka will be ready
2022-04-06 02:08:34 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-2 container kafka is ready
2022-04-06 02:08:34 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-2 with container kafka
2022-04-06 02:08:34 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-h7lmb container log-setting-cluster-name-kafka-exporter will be ready
2022-04-06 02:08:34 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-h7lmb container log-setting-cluster-name-kafka-exporter is ready
2022-04-06 02:08:34 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-kafka-exporter-7b59f7cd48-h7lmb with container log-setting-cluster-name-kafka-exporter
2022-04-06 02:08:34 [main] [32mINFO [m [PodUtils:343] Waiting for Pod log-setting-cluster-name-zookeeper-0 container zookeeper will be ready
2022-04-06 02:08:34 [main] [32mINFO [m [PodUtils:347] Pod log-setting-cluster-name-zookeeper-0 container zookeeper is ready
2022-04-06 02:08:34 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod log-setting-cluster-name-zookeeper-0 with container zookeeper
2022-04-06 02:08:34 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-65ckq container topic-operator will be ready
2022-04-06 02:08:34 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-65ckq container topic-operator is ready
2022-04-06 02:08:34 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-65ckq with container topic-operator
2022-04-06 02:08:34 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-65ckq container user-operator will be ready
2022-04-06 02:08:34 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-65ckq container user-operator is ready
2022-04-06 02:08:34 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-65ckq with container user-operator
2022-04-06 02:08:35 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-entity-operator-6dccd5cb65-65ckq container tls-sidecar will be ready
2022-04-06 02:08:35 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-entity-operator-6dccd5cb65-65ckq container tls-sidecar is ready
2022-04-06 02:08:35 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-entity-operator-6dccd5cb65-65ckq with container tls-sidecar
2022-04-06 02:08:35 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-kafka-0 container kafka will be ready
2022-04-06 02:08:35 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-kafka-0 container kafka is ready
2022-04-06 02:08:35 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-kafka-0 with container kafka
2022-04-06 02:08:35 [main] [32mINFO [m [PodUtils:343] Waiting for Pod gc-set-logging-zookeeper-0 container zookeeper will be ready
2022-04-06 02:08:35 [main] [32mINFO [m [PodUtils:347] Pod gc-set-logging-zookeeper-0 container zookeeper is ready
2022-04-06 02:08:35 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod gc-set-logging-zookeeper-0 with container zookeeper
2022-04-06 02:08:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:08:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaLogSetting
2022-04-06 02:08:35 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1288556036-1115785912 in namespace log-setting-st
2022-04-06 02:08:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-953144602-307635766 in namespace log-setting-st
2022-04-06 02:08:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:08:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testKafkaLogSetting-FINISHED
2022-04-06 02:08:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:08:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:08:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.log.LogSettingST.testBridgeLogSetting-STARTED
2022-04-06 02:08:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:08:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-a80671a5-bridge in namespace log-setting-st
2022-04-06 02:08:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-a80671a5-bridge will have desired state: Ready
2022-04-06 02:09:10 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-a80671a5-bridge is in desired state: Ready
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:392] Checking if Bridge has log level set properly
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.subscribe.name Expected: http.openapi.operation.subscribe
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.createConsumer.name Expected: http.openapi.operation.createConsumer
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.createConsumer.level Expected: INFO
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.deleteConsumer.name Expected: http.openapi.operation.deleteConsumer
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.poll.name Expected: http.openapi.operation.poll
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.sendToPartition.level Expected: TRACE
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.unsubscribe.name Expected: http.openapi.operation.unsubscribe
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.unsubscribe.level Expected: DEBUG
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.ready.level Expected: WARN
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.assign.name Expected: http.openapi.operation.assign
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToEnd.name Expected: http.openapi.operation.seekToEnd
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.poll.level Expected: INFO
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.deleteConsumer.level Expected: DEBUG
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.subscribe.level Expected: TRACE
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.openapi.level Expected: TRACE
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.commit.name Expected: http.openapi.operation.commit
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.send.level Expected: ERROR
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seek.name Expected: http.openapi.operation.seek
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.healthy.level Expected: ERROR
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.ready.name Expected: http.openapi.operation.ready
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: test.logger.bridge.level Expected: ERROR
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seek.level Expected: INFO
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.assign.level Expected: TRACE
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.sendToPartition.name Expected: http.openapi.operation.sendToPartition
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.send.name Expected: http.openapi.operation.send
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.openapi.name Expected: http.openapi.operation.openapi
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.healthy.name Expected: http.openapi.operation.healthy
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.commit.level Expected: DEBUG
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToEnd.level Expected: WARN
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToBeginning.name Expected: http.openapi.operation.seekToBeginning
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:476] Check log level setting for logger: logger.seekToBeginning.level Expected: DEBUG
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-a80671a5-bridge-bridge
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-a80671a5-bridge-bridge
2022-04-06 02:09:10 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=true
2022-04-06 02:09:10 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-a80671a5-bridge-bridge rolling update
2022-04-06 02:09:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-a80671a5-bridge-bridge will be ready
2022-04-06 02:09:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-a80671a5-bridge-bridge is ready
2022-04-06 02:09:50 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-a80671a5-bridge-bridge rolling update finished
2022-04-06 02:09:50 [main] [32mINFO [m [LogSettingST:498] Checking deployment: my-cluster-a80671a5-bridge-bridge
2022-04-06 02:09:50 [main] [32mINFO [m [LogSettingST:500] Checking container with name: my-cluster-a80671a5-bridge-bridge
2022-04-06 02:09:50 [main] [32mINFO [m [LogSettingST:529] STRIMZI_GC_LOG_ENABLED=false
2022-04-06 02:09:51 [main] [32mINFO [m [PodUtils:343] Waiting for Pod my-cluster-a80671a5-bridge-bridge-85f5c55cdb-zd2tv container my-cluster-a80671a5-bridge-bridge will be ready
2022-04-06 02:09:51 [main] [32mINFO [m [PodUtils:347] Pod my-cluster-a80671a5-bridge-bridge-85f5c55cdb-zd2tv container my-cluster-a80671a5-bridge-bridge is ready
2022-04-06 02:09:51 [main] [32mINFO [m [LogSettingST:453] Checking tini process for pod my-cluster-a80671a5-bridge-bridge-85f5c55cdb-zd2tv with container my-cluster-a80671a5-bridge-bridge
2022-04-06 02:09:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:09:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBridgeLogSetting
2022-04-06 02:09:51 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-a80671a5-bridge in namespace log-setting-st
2022-04-06 02:10:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:10:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.log.LogSettingST.testBridgeLogSetting-FINISHED
2022-04-06 02:10:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:10:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:10:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for LogSettingST
2022-04-06 02:10:01 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka gc-set-logging in namespace log-setting-st
2022-04-06 02:10:01 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka log-setting-cluster-name in namespace log-setting-st
2022-04-06 02:10:01 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace log-setting-st, for cruise control Kafka cluster log-setting-cluster-name
2022-04-06 02:10:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment shared-kafka-clients in namespace log-setting-st
2022-04-06 02:10:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,051.609 s - in io.strimzi.systemtest.log.LogSettingST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.FeatureGatesIsolatedST
2022-04-06 02:10:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:11:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:11:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testSwitchingStrimziPodSetFeatureGateOnAndOff-STARTED
2022-04-06 02:11:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:11:23 [main] [32mINFO [m [FeatureGatesIsolatedST:270] Deploying CO with STS - SPS is disabled
2022-04-06 02:11:23 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:11:23 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:11:23 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:11:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:11:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:11:23 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:11:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:11:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:11:59 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=-UseStrimziPodSets, valueFrom=null, additionalProperties={})]
2022-04-06 02:11:59 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:11:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:11:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:11:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:12:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:12:00 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:12:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:12:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:12:00 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:12:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:12:00 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:12:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:12:00 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:12:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:12:00 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:12:00 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:12:00 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 02:12:00 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:12:00 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 02:12:00 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 02:12:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:12:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:12:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:12:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:12:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:12:41 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:12:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:12:51 [main] [32mINFO [m [FeatureGatesIsolatedST:281] Deploying Kafka
2022-04-06 02:12:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b3b9f7b6 in namespace infra-namespace
2022-04-06 02:12:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b3b9f7b6 will have desired state: Ready
2022-04-06 02:14:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b3b9f7b6 is in desired state: Ready
2022-04-06 02:14:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-34796136-1291701218 in namespace infra-namespace
2022-04-06 02:14:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-34796136-1291701218 will have desired state: Ready
2022-04-06 02:14:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-34796136-1291701218 is in desired state: Ready
2022-04-06 02:14:11 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 02:14:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-664620021 in namespace infra-namespace
2022-04-06 02:14:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-1404198903 in namespace infra-namespace
2022-04-06 02:14:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-664620021 will be in active state
2022-04-06 02:14:12 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1404198903 will be in active state
2022-04-06 02:14:12 [main] [32mINFO [m [FeatureGatesIsolatedST:304] Changing FG env variable to enable SPS
2022-04-06 02:14:12 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-06 02:14:17 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:14:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:14:49 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-06 02:14:49 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-b3b9f7b6-zookeeper rolling update
2022-04-06 02:15:19 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-b3b9f7b6-zookeeper has been successfully rolled
2022-04-06 02:15:19 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-b3b9f7b6-zookeeper to be ready
2022-04-06 02:15:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b3b9f7b6 will have desired state: Ready
2022-04-06 02:15:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b3b9f7b6 is in desired state: Ready
2022-04-06 02:15:48 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-b3b9f7b6 is ready
2022-04-06 02:15:48 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-b3b9f7b6-kafka rolling update
2022-04-06 02:16:48 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-b3b9f7b6-kafka has been successfully rolled
2022-04-06 02:16:48 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-b3b9f7b6-kafka to be ready
2022-04-06 02:17:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b3b9f7b6 will have desired state: Ready
2022-04-06 02:17:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b3b9f7b6 is in desired state: Ready
2022-04-06 02:17:14 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-b3b9f7b6 is ready
2022-04-06 02:17:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b3b9f7b6 will have desired state: Ready
2022-04-06 02:17:14 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b3b9f7b6 is in desired state: Ready
2022-04-06 02:17:14 [main] [32mINFO [m [FeatureGatesIsolatedST:319] Changing FG env variable to disable again SPS
2022-04-06 02:17:14 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-06 02:17:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:17:46 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:17:56 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-06 02:17:56 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-b3b9f7b6-zookeeper rolling update
2022-04-06 02:18:41 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-b3b9f7b6-zookeeper has been successfully rolled
2022-04-06 02:18:41 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-b3b9f7b6-zookeeper to be ready
2022-04-06 02:19:09 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b3b9f7b6 will have desired state: Ready
2022-04-06 02:19:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b3b9f7b6 is in desired state: Ready
2022-04-06 02:19:09 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-b3b9f7b6 is ready
2022-04-06 02:19:09 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-b3b9f7b6-kafka rolling update
2022-04-06 02:20:15 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-b3b9f7b6-kafka has been successfully rolled
2022-04-06 02:20:15 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-b3b9f7b6-kafka to be ready
2022-04-06 02:20:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b3b9f7b6 will have desired state: Ready
2022-04-06 02:20:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b3b9f7b6 is in desired state: Ready
2022-04-06 02:20:40 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-b3b9f7b6 is ready
2022-04-06 02:20:40 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-test-664620021 and consumer consumer-test-1404198903 finish
2022-04-06 02:23:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:23:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSwitchingStrimziPodSetFeatureGateOnAndOff
2022-04-06 02:23:16 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-664620021 in namespace infra-namespace
2022-04-06 02:23:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-34796136-1291701218 in namespace infra-namespace
2022-04-06 02:23:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-1404198903 in namespace infra-namespace
2022-04-06 02:23:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b3b9f7b6 in namespace infra-namespace
2022-04-06 02:23:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:23:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testSwitchingStrimziPodSetFeatureGateOnAndOff-FINISHED
2022-04-06 02:23:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:23:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:23:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testControlPlaneListenerFeatureGate-STARTED
2022-04-06 02:23:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:23:26 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:23:26 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:23:26 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:23:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:23:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:23:26 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:23:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:23:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:23:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:23:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:23:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:23:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:23:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:23:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:23:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:23:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:23:36 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:23:36 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:23:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:23:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:23:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:23:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:23:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:23:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:23:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:23:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:23:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:23:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:23:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:23:47 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:23:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:24:02 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=-ControlPlaneListener, valueFrom=null, additionalProperties={})]
2022-04-06 02:24:02 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:24:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:24:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:24:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:24:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:24:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:24:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:24:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:24:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:24:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:24:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:24:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:24:03 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 02:24:03 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:24:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:24:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:24:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:24:19 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:24:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:24:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f31195f9 in namespace infra-namespace
2022-04-06 02:24:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f31195f9 will have desired state: Ready
2022-04-06 02:25:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f31195f9 is in desired state: Ready
2022-04-06 02:25:49 [main] [32mINFO [m [FeatureGatesIsolatedST:96] Check for presence of ContainerPort 9090/tcp (tcp-ctrlplane) in first Kafka pod.
2022-04-06 02:25:49 [main] [32mINFO [m [FeatureGatesIsolatedST:104] Try to send some messages to Kafka over next few minutes.
2022-04-06 02:25:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1219092948-1287280620 in namespace infra-namespace
2022-04-06 02:25:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1219092948-1287280620 will have desired state: Ready
2022-04-06 02:25:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1219092948-1287280620 is in desired state: Ready
2022-04-06 02:25:50 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 02:25:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-447194548 in namespace infra-namespace
2022-04-06 02:25:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-447194548 will be in active state
2022-04-06 02:25:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-1335968017 in namespace infra-namespace
2022-04-06 02:25:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1335968017 will be in active state
2022-04-06 02:25:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-1335968017 will be in active state
2022-04-06 02:25:52 [main] [32mINFO [m [FeatureGatesIsolatedST:127] Delete first found Kafka broker pod.
2022-04-06 02:25:52 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-f31195f9-zookeeper to be ready
2022-04-06 02:26:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f31195f9 will have desired state: Ready
2022-04-06 02:26:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f31195f9 is in desired state: Ready
2022-04-06 02:26:02 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-f31195f9 is ready
2022-04-06 02:26:02 [main] [32mINFO [m [FeatureGatesIsolatedST:131] Force Rolling Update of Kafka via annotation.
2022-04-06 02:26:02 [main] [32mINFO [m [FeatureGatesIsolatedST:139] Wait for next reconciliation to happen.
2022-04-06 02:26:02 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-f31195f9-zookeeper rolling update
2022-04-06 02:27:07 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-f31195f9-zookeeper has been successfully rolled
2022-04-06 02:27:07 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-f31195f9-zookeeper to be ready
2022-04-06 02:27:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f31195f9 will have desired state: Ready
2022-04-06 02:27:34 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f31195f9 is in desired state: Ready
2022-04-06 02:27:34 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-f31195f9 is ready
2022-04-06 02:27:34 [main] [32mINFO [m [FeatureGatesIsolatedST:142] Waiting for clients to finish sending/receiving messages.
2022-04-06 02:27:34 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-test-447194548 to finished
2022-04-06 02:28:34 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-test-1335968017 to finished
2022-04-06 02:28:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:28:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testControlPlaneListenerFeatureGate
2022-04-06 02:28:39 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-447194548 in namespace infra-namespace
2022-04-06 02:28:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1219092948-1287280620 in namespace infra-namespace
2022-04-06 02:28:39 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f31195f9 in namespace infra-namespace
2022-04-06 02:28:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-1335968017 in namespace infra-namespace
2022-04-06 02:28:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:28:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testControlPlaneListenerFeatureGate-FINISHED
2022-04-06 02:28:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:28:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:28:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testStrimziPodSetsFeatureGate-STARTED
2022-04-06 02:28:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:28:49 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:28:49 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:28:49 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:28:49 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:28:49 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:28:49 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:28:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:28:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:28:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:28:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:28:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:28:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:28:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:28:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:28:49 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:28:59 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:28:59 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:28:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:28:59 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:28:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:28:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:29:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:29:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:29:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:29:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:29:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:29:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:29:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:29:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:29:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:29:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:29:25 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_FEATURE_GATES, value=+UseStrimziPodSets, valueFrom=null, additionalProperties={})]
2022-04-06 02:29:25 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:29:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:29:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:29:25 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:29:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:29:26 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:29:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:29:26 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:29:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:29:26 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:29:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:29:26 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:29:26 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:29:26 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 02:29:26 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:29:26 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 02:29:26 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 02:29:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:29:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:29:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:29:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:29:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:29:58 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:30:08 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:30:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-925303e7 in namespace infra-namespace
2022-04-06 02:30:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-925303e7 will have desired state: Ready
2022-04-06 02:32:10 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-925303e7 is in desired state: Ready
2022-04-06 02:32:10 [main] [32mINFO [m [FeatureGatesIsolatedST:182] Try to send some messages to Kafka over next few minutes.
2022-04-06 02:32:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1960364885-2010726388 in namespace infra-namespace
2022-04-06 02:32:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1960364885-2010726388 will have desired state: Ready
2022-04-06 02:32:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1960364885-2010726388 is in desired state: Ready
2022-04-06 02:32:11 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 02:32:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-test-1053753917 in namespace infra-namespace
2022-04-06 02:32:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-test-1053753917 will be in active state
2022-04-06 02:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-test-699649717 in namespace infra-namespace
2022-04-06 02:32:12 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-699649717 will be in active state
2022-04-06 02:32:13 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-test-699649717 will be in active state
2022-04-06 02:32:13 [main] [32mINFO [m [FeatureGatesIsolatedST:207] Delete first found ZooKeeper pod my-cluster-925303e7-zookeeper-0
2022-04-06 02:32:13 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-925303e7-zookeeper to be ready
2022-04-06 02:32:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-925303e7 will have desired state: Ready
2022-04-06 02:32:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-925303e7 is in desired state: Ready
2022-04-06 02:32:55 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-925303e7 is ready
2022-04-06 02:32:55 [main] [32mINFO [m [FeatureGatesIsolatedST:213] Delete first found Kafka broker pod my-cluster-925303e7-kafka-0
2022-04-06 02:32:55 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-925303e7-kafka to be ready
2022-04-06 02:33:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-925303e7 will have desired state: Ready
2022-04-06 02:33:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-925303e7 is in desired state: Ready
2022-04-06 02:33:36 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-925303e7 is ready
2022-04-06 02:33:36 [main] [32mINFO [m [FeatureGatesIsolatedST:218] Force Rolling Update of ZooKeeper via annotation.
2022-04-06 02:33:36 [main] [32mINFO [m [FeatureGatesIsolatedST:228] Wait for next reconciliation to happen.
2022-04-06 02:33:36 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-925303e7-zookeeper rolling update
2022-04-06 02:35:21 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-925303e7-zookeeper has been successfully rolled
2022-04-06 02:35:21 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-925303e7-zookeeper to be ready
2022-04-06 02:35:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-925303e7 will have desired state: Ready
2022-04-06 02:35:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-925303e7 is in desired state: Ready
2022-04-06 02:35:48 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-925303e7 is ready
2022-04-06 02:35:48 [main] [32mINFO [m [FeatureGatesIsolatedST:232] Force Rolling Update of Kafka via annotation.
2022-04-06 02:35:48 [main] [32mINFO [m [FeatureGatesIsolatedST:242] Wait for next reconciliation to happen.
2022-04-06 02:35:48 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-925303e7-kafka rolling update
2022-04-06 02:37:23 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-925303e7-kafka has been successfully rolled
2022-04-06 02:37:23 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-925303e7-kafka to be ready
2022-04-06 02:37:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-925303e7 will have desired state: Ready
2022-04-06 02:37:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-925303e7 is in desired state: Ready
2022-04-06 02:37:51 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-925303e7 is ready
2022-04-06 02:37:51 [main] [32mINFO [m [FeatureGatesIsolatedST:245] Waiting for clients to finish sending/receiving messages.
2022-04-06 02:37:51 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-test-1053753917 to finished
2022-04-06 02:37:57 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-test-699649717 to finished
2022-04-06 02:38:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:38:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziPodSetsFeatureGate
2022-04-06 02:38:02 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-test-1053753917 in namespace infra-namespace
2022-04-06 02:38:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1960364885-2010726388 in namespace infra-namespace
2022-04-06 02:38:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-925303e7 in namespace infra-namespace
2022-04-06 02:38:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job consumer-test-699649717 in namespace infra-namespace
2022-04-06 02:38:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:38:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.FeatureGatesIsolatedST.testStrimziPodSetsFeatureGate-FINISHED
2022-04-06 02:38:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:38:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:38:12 [main] [32mINFO [m [ResourceManager:346] In context FeatureGatesIsolatedST is everything deleted.
2022-04-06 02:38:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,633.864 s - in io.strimzi.systemtest.operators.FeatureGatesIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
2022-04-06 02:38:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:38:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:38:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST.testNamespacedRbacScopeDeploysRoles-STARTED
2022-04-06 02:38:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:38:37 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:38:37 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:38:37 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:38:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:38:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:38:37 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:38:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:38:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:38:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:38:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:38:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:38:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 02:38:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:38:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:38:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:38:47 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:38:47 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:38:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:38:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:38:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:38:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:38:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:38:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:38:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:38:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:38:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:38:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:38:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:38:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:38:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:39:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:39:13 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_RBAC_SCOPE, value=NAMESPACE, valueFrom=null, additionalProperties={})]
2022-04-06 02:39:13 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:39:13 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:39:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:39:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 02:39:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 02:39:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 02:39:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 02:39:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:39:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:39:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:39:14 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:39:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:39:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:39:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:39:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:39:14 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:39:14 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:39:14 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-06 02:39:14 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator14190634517627966264.yaml in namespace infra-namespace
2022-04-06 02:39:14 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:39:14 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-06 02:39:14 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation635744428414263818.yaml in namespace infra-namespace
2022-04-06 02:39:14 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:39:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:39:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:39:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:39:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:39:58 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:39:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e91ab34c in namespace infra-namespace
2022-04-06 02:39:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e91ab34c will have desired state: Ready
2022-04-06 02:41:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e91ab34c is in desired state: Ready
2022-04-06 02:41:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e91ab34c will have desired state: Ready
2022-04-06 02:41:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e91ab34c is in desired state: Ready
2022-04-06 02:41:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:41:22 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testNamespacedRbacScopeDeploysRoles
2022-04-06 02:41:22 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e91ab34c in namespace infra-namespace
2022-04-06 02:41:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:41:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST.testNamespacedRbacScopeDeploysRoles-FINISHED
2022-04-06 02:41:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:41:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:41:32 [main] [32mINFO [m [ResourceManager:346] In context NamespaceRbacScopeOperatorIsolatedST is everything deleted.
2022-04-06 02:41:32 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 200.63 s - in io.strimzi.systemtest.operators.NamespaceRbacScopeOperatorIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.RecoveryIsolatedST
2022-04-06 02:41:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:41:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:41:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperMetricsConfigDeletion-STARTED
2022-04-06 02:41:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:41:57 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:41:57 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:41:57 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:41:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:41:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:41:57 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:41:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:41:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:41:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 02:41:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 02:41:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:41:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 02:41:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 02:41:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:41:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:42:07 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:42:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:42:07 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:42:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:42:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:42:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 02:42:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:42:23 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 02:42:23 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:42:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:42:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:42:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:42:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:42:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:42:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:42:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:42:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:42:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:42:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:42:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:42:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:42:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:42:24 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:42:24 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:42:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:42:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:43:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:43:01 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:43:11 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:43:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1332226672 in namespace infra-namespace
2022-04-06 02:43:12 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1332226672 will have desired state: Ready
2022-04-06 02:44:39 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1332226672 is in desired state: Ready
2022-04-06 02:44:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1332226672 in namespace infra-namespace
2022-04-06 02:44:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1332226672 will be ready
2022-04-06 02:44:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1332226672 is ready
2022-04-06 02:44:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1332226672 in namespace infra-namespace
2022-04-06 02:44:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1332226672 will have desired state: Ready
2022-04-06 02:45:00 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1332226672 is in desired state: Ready
2022-04-06 02:45:00 [main] [32mINFO [m [RecoveryIsolatedST:191] Running deleteZookeeperMetricsConfig with cluster recovery-cluster-1332226672
2022-04-06 02:45:00 [main] [32mINFO [m [RecoveryIsolatedST:199] Waiting for creation recovery-cluster-1332226672-zookeeper-config
2022-04-06 02:45:00 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-1332226672-zookeeper-config-7657b1ca-d306-4a40-a4d8-f22356ef566e recovery in namespace infra-namespace
2022-04-06 02:45:02 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-1332226672-zookeeper-config was recovered
2022-04-06 02:45:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:45:02 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperMetricsConfigDeletion
2022-04-06 02:45:02 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1332226672 in namespace infra-namespace
2022-04-06 02:45:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1332226672 in namespace infra-namespace
2022-04-06 02:45:02 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1332226672 in namespace infra-namespace
2022-04-06 02:45:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:45:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperMetricsConfigDeletion-FINISHED
2022-04-06 02:45:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:45:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:45:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeServiceDeletion-STARTED
2022-04-06 02:45:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:45:52 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:45:52 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:45:52 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:45:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:45:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:45:52 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:45:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:45:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:45:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:45:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:45:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:45:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:45:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:45:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:46:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:46:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:46:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:46:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:46:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:46:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:46:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:46:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:46:23 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 02:46:23 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:46:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:46:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:46:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:46:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:46:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:46:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:46:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:46:23 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:46:23 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:46:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:46:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:46:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:46:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:46:24 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:46:24 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:46:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:46:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:46:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:46:57 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:47:07 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:47:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-574423731 in namespace infra-namespace
2022-04-06 02:47:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-574423731 will have desired state: Ready
2022-04-06 02:48:34 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-574423731 is in desired state: Ready
2022-04-06 02:48:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-574423731 in namespace infra-namespace
2022-04-06 02:48:34 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-574423731 will be ready
2022-04-06 02:48:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-574423731 is ready
2022-04-06 02:48:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-574423731 in namespace infra-namespace
2022-04-06 02:48:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-574423731 will have desired state: Ready
2022-04-06 02:48:58 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-574423731 is in desired state: Ready
2022-04-06 02:48:58 [main] [32mINFO [m [RecoveryIsolatedST:222] Running deleteKafkaBridgeService with cluster recovery-cluster-574423731
2022-04-06 02:48:58 [main] [32mINFO [m [RecoveryIsolatedST:227] Waiting for service recovery-cluster-574423731-bridge-service recovery
2022-04-06 02:48:58 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-574423731-bridge-service-363a5139-9b9e-4fb8-a2db-b441f7e5b5ab in namespace infra-namespace will be recovered
2022-04-06 02:49:01 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-574423731-bridge-service in namespace infra-namespace is recovered
2022-04-06 02:49:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:49:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeServiceDeletion
2022-04-06 02:49:01 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-574423731 in namespace infra-namespace
2022-04-06 02:49:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-574423731 in namespace infra-namespace
2022-04-06 02:49:01 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-574423731 in namespace infra-namespace
2022-04-06 02:49:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:49:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeServiceDeletion-FINISHED
2022-04-06 02:49:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:49:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:49:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaHeadlessServiceDeletion-STARTED
2022-04-06 02:49:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:49:41 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:49:41 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:49:41 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:49:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:49:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:49:41 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:49:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:49:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:49:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:49:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:49:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:49:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:49:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:49:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:49:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:49:51 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:49:51 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:49:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:49:51 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:49:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:49:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:49:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:49:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:49:51 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:49:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:49:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:50:01 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:50:01 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:50:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:50:17 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 02:50:17 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:50:17 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:50:17 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:50:17 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:50:17 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:50:17 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:50:17 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:50:18 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:50:18 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:50:18 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 02:50:18 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:50:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:50:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:50:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:50:41 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:50:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:50:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1601283844 in namespace infra-namespace
2022-04-06 02:50:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1601283844 will have desired state: Ready
2022-04-06 02:52:11 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1601283844 is in desired state: Ready
2022-04-06 02:52:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1601283844 in namespace infra-namespace
2022-04-06 02:52:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1601283844 will be ready
2022-04-06 02:52:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1601283844 is ready
2022-04-06 02:52:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1601283844 in namespace infra-namespace
2022-04-06 02:52:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1601283844 will have desired state: Ready
2022-04-06 02:52:36 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1601283844 is in desired state: Ready
2022-04-06 02:52:36 [main] [32mINFO [m [RecoveryIsolatedST:143] Running deleteKafkaHeadlessService with cluster recovery-cluster-1601283844
2022-04-06 02:52:36 [main] [32mINFO [m [RecoveryIsolatedST:150] Waiting for creation recovery-cluster-1601283844-kafka-brokers
2022-04-06 02:52:36 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-1601283844-kafka-brokers-9127a724-9e9b-4707-b56c-426b130e16c8 in namespace infra-namespace will be recovered
2022-04-06 02:52:56 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-1601283844-kafka-brokers in namespace infra-namespace is recovered
2022-04-06 02:52:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:52:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaHeadlessServiceDeletion
2022-04-06 02:52:56 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1601283844 in namespace infra-namespace
2022-04-06 02:52:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1601283844 in namespace infra-namespace
2022-04-06 02:52:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1601283844 in namespace infra-namespace
2022-04-06 02:53:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:53:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaHeadlessServiceDeletion-FINISHED
2022-04-06 02:53:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:53:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:53:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaStatefulSetDeletion-STARTED
2022-04-06 02:53:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:53:36 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:53:36 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:53:36 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:53:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:53:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:53:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:53:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:53:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:53:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:53:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:53:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:53:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:46 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:53:46 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:53:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:53:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:53:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:53:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:53:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:53:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:53:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:53:57 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:54:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:54:12 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 02:54:12 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:54:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:54:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:54:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:54:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:54:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:54:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:54:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:54:13 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:54:13 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:54:13 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:54:13 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:54:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:54:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:54:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:54:24 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:54:34 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:54:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1221433845 in namespace infra-namespace
2022-04-06 02:54:34 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1221433845 will have desired state: Ready
2022-04-06 02:55:49 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1221433845 is in desired state: Ready
2022-04-06 02:55:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1221433845 in namespace infra-namespace
2022-04-06 02:55:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1221433845 will be ready
2022-04-06 02:55:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1221433845 is ready
2022-04-06 02:55:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1221433845 in namespace infra-namespace
2022-04-06 02:55:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1221433845 will have desired state: Ready
2022-04-06 02:56:13 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1221433845 is in desired state: Ready
2022-04-06 02:56:13 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-1221433845-kafka will be deleted
2022-04-06 02:56:13 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1221433845-kafka-0 will be deleted
2022-04-06 02:56:28 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1221433845-kafka-0 deleted
2022-04-06 02:56:28 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1221433845-kafka-1 will be deleted
2022-04-06 02:56:33 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1221433845-kafka-1 deleted
2022-04-06 02:56:33 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1221433845-kafka-2 will be deleted
2022-04-06 02:56:33 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1221433845-kafka-2 deleted
2022-04-06 02:56:33 [main] [32mINFO [m [RecoveryIsolatedST:90] Waiting for recovery recovery-cluster-1221433845-kafka
2022-04-06 02:56:33 [main] [32mINFO [m [StatefulSetUtils:73] Waiting for StatefulSet recovery-cluster-1221433845-kafka-5eeb64c5-8550-47f5-9550-42f163c9e19b recovery in namespace infra-namespace
2022-04-06 02:56:44 [main] [32mINFO [m [StatefulSetUtils:76] StatefulSet recovery-cluster-1221433845-kafka was recovered
2022-04-06 02:56:44 [main] [32mINFO [m [StatefulSetUtils:39] Waiting for StatefulSet recovery-cluster-1221433845-kafka to be ready
2022-04-06 02:57:06 [main] [32mINFO [m [StatefulSetUtils:44] Waiting for 3 Pod(s) of StatefulSet recovery-cluster-1221433845-kafka to be ready
2022-04-06 02:57:16 [main] [32mINFO [m [StatefulSetUtils:47] StatefulSet recovery-cluster-1221433845-kafka is ready
2022-04-06 02:57:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:57:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaStatefulSetDeletion
2022-04-06 02:57:16 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1221433845 in namespace infra-namespace
2022-04-06 02:57:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1221433845 in namespace infra-namespace
2022-04-06 02:57:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1221433845 in namespace infra-namespace
2022-04-06 02:58:16 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:58:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaStatefulSetDeletion-FINISHED
2022-04-06 02:58:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 02:58:16 [main] [32mINFO [m [StrimziPodSetTestCondition:23] According to STRIMZI_FEATURE_GATES env variable with value: , the StatefulSets are used, skipping this StrimziPodSet related test
2022-04-06 02:58:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 02:58:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromEntityOperatorDeletion-STARTED
2022-04-06 02:58:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 02:58:16 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 02:58:16 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 02:58:16 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 02:58:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 02:58:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 02:58:16 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:58:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:58:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:58:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:58:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:58:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:58:17 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:58:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:58:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:58:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:58:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:58:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:58:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:58:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:58:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 02:58:52 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 02:58:52 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 02:58:53 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 02:58:53 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:58:53 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 02:58:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 02:58:53 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:58:53 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 02:58:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 02:58:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 02:59:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 02:59:29 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 02:59:39 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 02:59:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1870359684 in namespace infra-namespace
2022-04-06 02:59:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1870359684 will have desired state: Ready
2022-04-06 03:01:06 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1870359684 is in desired state: Ready
2022-04-06 03:01:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1870359684 in namespace infra-namespace
2022-04-06 03:01:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1870359684 will be ready
2022-04-06 03:01:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1870359684 is ready
2022-04-06 03:01:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1870359684 in namespace infra-namespace
2022-04-06 03:01:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1870359684 will have desired state: Ready
2022-04-06 03:01:33 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1870359684 is in desired state: Ready
2022-04-06 03:01:33 [main] [32mINFO [m [RecoveryIsolatedST:64] Running testRecoveryFromEntityOperatorDeletion with cluster recovery-cluster-1870359684
2022-04-06 03:01:33 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-1870359684-entity-operator will be deleted
2022-04-06 03:01:33 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1870359684-entity-operator-5b4cb484b5-dc69h will be deleted
2022-04-06 03:01:48 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1870359684-entity-operator-5b4cb484b5-dc69h deleted
2022-04-06 03:01:48 [main] [32mINFO [m [RecoveryIsolatedST:72] Waiting for recovery recovery-cluster-1870359684-entity-operator
2022-04-06 03:01:48 [main] [32mINFO [m [DeploymentUtils:154] Waiting for Deployment recovery-cluster-1870359684-entity-operator-54616ecf-bc45-47f3-86e9-526be0712357 recovery in namespace infra-namespace
2022-04-06 03:02:02 [main] [32mINFO [m [DeploymentUtils:157] Deployment recovery-cluster-1870359684-entity-operator was recovered
2022-04-06 03:02:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: recovery-cluster-1870359684-entity-operator will be ready
2022-04-06 03:02:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: recovery-cluster-1870359684-entity-operator is ready
2022-04-06 03:02:25 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment recovery-cluster-1870359684-entity-operator to be ready
2022-04-06 03:02:35 [main] [32mINFO [m [DeploymentUtils:197] Deployment recovery-cluster-1870359684-entity-operator is ready
2022-04-06 03:02:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:02:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromEntityOperatorDeletion
2022-04-06 03:02:35 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1870359684 in namespace infra-namespace
2022-04-06 03:02:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1870359684 in namespace infra-namespace
2022-04-06 03:02:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1870359684 in namespace infra-namespace
2022-04-06 03:03:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:03:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromEntityOperatorDeletion-FINISHED
2022-04-06 03:03:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:03:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:03:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeDeploymentDeletion-STARTED
2022-04-06 03:03:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:03:25 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:03:25 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:03:25 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:03:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:03:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:03:25 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:03:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:03:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:03:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:03:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:03:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:03:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:03:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:03:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:03:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:03:36 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:03:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:03:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:03:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:03:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:03:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:03:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:03:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:03:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:03:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:03:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:03:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:03:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:03:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:04:01 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:04:01 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:04:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:04:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:04:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:04:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:04:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:04:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:04:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:04:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:04:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:04:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:04:31 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:04:41 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:04:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1897630129 in namespace infra-namespace
2022-04-06 03:04:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1897630129 will have desired state: Ready
2022-04-06 03:06:43 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1897630129 is in desired state: Ready
2022-04-06 03:06:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1897630129 in namespace infra-namespace
2022-04-06 03:06:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1897630129 will be ready
2022-04-06 03:06:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1897630129 is ready
2022-04-06 03:06:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1897630129 in namespace infra-namespace
2022-04-06 03:06:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1897630129 will have desired state: Ready
2022-04-06 03:07:10 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1897630129 is in desired state: Ready
2022-04-06 03:07:10 [main] [32mINFO [m [RecoveryIsolatedST:206] Running deleteKafkaBridgeDeployment with cluster recovery-cluster-1897630129
2022-04-06 03:07:10 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-1897630129-bridge will be deleted
2022-04-06 03:07:10 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-1897630129-bridge-69674d9665-6xwpp will be deleted
2022-04-06 03:07:20 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-1897630129-bridge-69674d9665-6xwpp deleted
2022-04-06 03:07:20 [main] [32mINFO [m [RecoveryIsolatedST:215] Waiting for deployment recovery-cluster-1897630129-bridge recovery
2022-04-06 03:07:20 [main] [32mINFO [m [DeploymentUtils:154] Waiting for Deployment recovery-cluster-1897630129-bridge-483f0510-55ff-420c-b418-963befe820a1 recovery in namespace infra-namespace
2022-04-06 03:07:39 [main] [32mINFO [m [DeploymentUtils:157] Deployment recovery-cluster-1897630129-bridge was recovered
2022-04-06 03:07:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:07:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeDeploymentDeletion
2022-04-06 03:07:39 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1897630129 in namespace infra-namespace
2022-04-06 03:07:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1897630129 in namespace infra-namespace
2022-04-06 03:07:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1897630129 in namespace infra-namespace
2022-04-06 03:08:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:08:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeDeploymentDeletion-FINISHED
2022-04-06 03:08:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:08:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:08:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaServiceDeletion-STARTED
2022-04-06 03:08:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:08:29 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:08:29 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:08:29 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:08:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:08:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:08:29 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:08:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:08:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:08:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:08:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:08:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:08:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:08:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:08:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:08:40 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:08:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:08:40 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:08:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:08:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:08:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:08:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:08:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:08:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:08:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:08:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:08:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:08:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:08:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:09:06 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:09:06 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:09:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:09:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:09:06 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:09:06 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:09:06 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:09:06 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:09:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:09:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:09:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:09:24 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:09:35 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:09:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-447851354 in namespace infra-namespace
2022-04-06 03:09:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-447851354 will have desired state: Ready
2022-04-06 03:11:03 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-447851354 is in desired state: Ready
2022-04-06 03:11:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-447851354 in namespace infra-namespace
2022-04-06 03:11:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-447851354 will be ready
2022-04-06 03:11:05 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-447851354 is ready
2022-04-06 03:11:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-447851354 in namespace infra-namespace
2022-04-06 03:11:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-447851354 will have desired state: Ready
2022-04-06 03:11:31 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-447851354 is in desired state: Ready
2022-04-06 03:11:31 [main] [32mINFO [m [RecoveryIsolatedST:115] Running deleteKafkaService with cluster recovery-cluster-447851354
2022-04-06 03:11:31 [main] [32mINFO [m [RecoveryIsolatedST:122] Waiting for creation recovery-cluster-447851354-kafka-bootstrap
2022-04-06 03:11:31 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-447851354-kafka-bootstrap-3d2ae90d-cb56-4817-a339-0af83419318d in namespace infra-namespace will be recovered
2022-04-06 03:11:45 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-447851354-kafka-bootstrap in namespace infra-namespace is recovered
2022-04-06 03:11:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:11:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaServiceDeletion
2022-04-06 03:11:45 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-447851354 in namespace infra-namespace
2022-04-06 03:11:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-447851354 in namespace infra-namespace
2022-04-06 03:11:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-447851354 in namespace infra-namespace
2022-04-06 03:12:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:12:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaServiceDeletion-FINISHED
2022-04-06 03:12:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:12:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:12:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperStatefulSetDeletion-STARTED
2022-04-06 03:12:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:12:35 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:12:35 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:12:35 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:12:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:12:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:12:35 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:12:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:12:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:12:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:12:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:12:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:12:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:12:45 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:12:45 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:12:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:12:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:12:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:12:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:12:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:12:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:12:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:12:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:12:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:12:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:12:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:12:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:12:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:12:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:13:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:13:11 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:13:11 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:13:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:13:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:13:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:13:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:13:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:13:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:13:12 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:13:12 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:13:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:13:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:13:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:13:50 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:14:00 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:14:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-610769017 in namespace infra-namespace
2022-04-06 03:14:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-610769017 will have desired state: Ready
2022-04-06 03:15:20 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-610769017 is in desired state: Ready
2022-04-06 03:15:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-610769017 in namespace infra-namespace
2022-04-06 03:15:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-610769017 will be ready
2022-04-06 03:15:22 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-610769017 is ready
2022-04-06 03:15:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-610769017 in namespace infra-namespace
2022-04-06 03:15:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-610769017 will have desired state: Ready
2022-04-06 03:15:48 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-610769017 is in desired state: Ready
2022-04-06 03:15:48 [main] [32mINFO [m [PodUtils:121] Waiting when all Pods with prefix recovery-cluster-610769017-zookeeper will be deleted
2022-04-06 03:15:48 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-610769017-zookeeper-0 will be deleted
2022-04-06 03:15:53 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-610769017-zookeeper-0 deleted
2022-04-06 03:15:53 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-610769017-zookeeper-1 will be deleted
2022-04-06 03:15:58 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-610769017-zookeeper-1 deleted
2022-04-06 03:15:58 [main] [32mINFO [m [PodUtils:154] Waiting when Pod recovery-cluster-610769017-zookeeper-2 will be deleted
2022-04-06 03:15:58 [main] [32mINFO [m [PodUtils:171] Pod recovery-cluster-610769017-zookeeper-2 deleted
2022-04-06 03:15:58 [main] [32mINFO [m [RecoveryIsolatedST:107] Waiting for recovery recovery-cluster-610769017-zookeeper
2022-04-06 03:15:58 [main] [32mINFO [m [StatefulSetUtils:73] Waiting for StatefulSet recovery-cluster-610769017-zookeeper-2a71a613-a479-435e-8b62-a8eb3fe7a4ad recovery in namespace infra-namespace
2022-04-06 03:16:07 [main] [32mINFO [m [StatefulSetUtils:76] StatefulSet recovery-cluster-610769017-zookeeper was recovered
2022-04-06 03:16:07 [main] [32mINFO [m [StatefulSetUtils:39] Waiting for StatefulSet recovery-cluster-610769017-zookeeper to be ready
2022-04-06 03:16:31 [main] [32mINFO [m [StatefulSetUtils:44] Waiting for 3 Pod(s) of StatefulSet recovery-cluster-610769017-zookeeper to be ready
2022-04-06 03:16:41 [main] [32mINFO [m [StatefulSetUtils:47] StatefulSet recovery-cluster-610769017-zookeeper is ready
2022-04-06 03:16:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:16:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperStatefulSetDeletion
2022-04-06 03:16:41 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-610769017 in namespace infra-namespace
2022-04-06 03:16:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-610769017 in namespace infra-namespace
2022-04-06 03:16:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-610769017 in namespace infra-namespace
2022-04-06 03:17:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:17:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperStatefulSetDeletion-FINISHED
2022-04-06 03:17:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:17:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:17:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeMetricsConfigDeletion-STARTED
2022-04-06 03:17:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:17:31 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:17:31 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:17:31 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:17:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:17:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:17:31 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:17:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:17:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:17:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:17:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:17:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:17:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:17:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:17:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:17:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:17:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:17:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:17:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:17:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:17:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:17:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:17:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:17:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:17:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:17:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:17:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:17:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:17:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:18:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:18:08 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:18:08 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:18:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:18:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:18:08 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:18:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:18:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:18:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:18:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:18:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:18:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:18:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:18:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:18:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:18:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:18:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:18:09 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:18:09 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:18:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:18:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:18:31 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:18:31 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:18:41 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:18:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1261027281 in namespace infra-namespace
2022-04-06 03:18:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1261027281 will have desired state: Ready
2022-04-06 03:20:06 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1261027281 is in desired state: Ready
2022-04-06 03:20:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1261027281 in namespace infra-namespace
2022-04-06 03:20:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1261027281 will be ready
2022-04-06 03:20:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1261027281 is ready
2022-04-06 03:20:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1261027281 in namespace infra-namespace
2022-04-06 03:20:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1261027281 will have desired state: Ready
2022-04-06 03:20:33 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1261027281 is in desired state: Ready
2022-04-06 03:20:33 [main] [32mINFO [m [RecoveryIsolatedST:234] Running deleteKafkaBridgeMetricsConfig with cluster recovery-cluster-1261027281
2022-04-06 03:20:33 [main] [32mINFO [m [RecoveryIsolatedST:239] Waiting for metric config recovery-cluster-1261027281-bridge-config re-creation
2022-04-06 03:20:33 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-1261027281-bridge-config-b898daf4-43f2-4af7-8946-35c32539fc73 recovery in namespace infra-namespace
2022-04-06 03:20:45 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-1261027281-bridge-config was recovered
2022-04-06 03:20:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:20:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaBridgeMetricsConfigDeletion
2022-04-06 03:20:45 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1261027281 in namespace infra-namespace
2022-04-06 03:20:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1261027281 in namespace infra-namespace
2022-04-06 03:20:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1261027281 in namespace infra-namespace
2022-04-06 03:21:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:21:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaBridgeMetricsConfigDeletion-FINISHED
2022-04-06 03:21:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:21:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:21:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperHeadlessServiceDeletion-STARTED
2022-04-06 03:21:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:21:35 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:21:35 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:21:35 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:21:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:21:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:21:35 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:21:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:21:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:21:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:21:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:21:46 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:21:46 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:21:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:21:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:21:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:21:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:22:01 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:22:01 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:22:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:22:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:22:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:22:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:22:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:22:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:22:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:22:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:22:30 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:22:30 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:22:40 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:22:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-561472157 in namespace infra-namespace
2022-04-06 03:22:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-561472157 will have desired state: Ready
2022-04-06 03:23:53 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-561472157 is in desired state: Ready
2022-04-06 03:23:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-561472157 in namespace infra-namespace
2022-04-06 03:23:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-561472157 will be ready
2022-04-06 03:23:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-561472157 is ready
2022-04-06 03:23:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-561472157 in namespace infra-namespace
2022-04-06 03:23:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-561472157 will have desired state: Ready
2022-04-06 03:24:17 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-561472157 is in desired state: Ready
2022-04-06 03:24:17 [main] [32mINFO [m [RecoveryIsolatedST:157] Running deleteKafkaHeadlessService with cluster recovery-cluster-561472157
2022-04-06 03:24:17 [main] [32mINFO [m [RecoveryIsolatedST:164] Waiting for creation recovery-cluster-561472157-zookeeper-nodes
2022-04-06 03:24:17 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-561472157-zookeeper-nodes-178e9a6c-24af-4e68-ad53-f2988a927b00 in namespace infra-namespace will be recovered
2022-04-06 03:24:40 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-561472157-zookeeper-nodes in namespace infra-namespace is recovered
2022-04-06 03:24:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:24:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperHeadlessServiceDeletion
2022-04-06 03:24:40 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-561472157 in namespace infra-namespace
2022-04-06 03:24:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-561472157 in namespace infra-namespace
2022-04-06 03:24:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-561472157 in namespace infra-namespace
2022-04-06 03:25:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:25:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperHeadlessServiceDeletion-FINISHED
2022-04-06 03:25:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:25:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:25:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaMetricsConfigDeletion-STARTED
2022-04-06 03:25:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:25:20 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:25:20 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:25:20 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:25:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:25:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:25:20 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:25:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:25:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:25:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:25:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:25:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:25:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:25:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:25:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:25:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:25:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:25:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:31 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:25:31 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:25:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:25:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:25:56 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:25:56 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:25:56 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:25:56 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:25:56 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:25:56 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:25:56 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:25:56 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:25:57 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:25:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:25:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:25:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:25:57 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:25:57 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:25:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:25:57 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:26:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:26:16 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:26:26 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:26:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-281966042 in namespace infra-namespace
2022-04-06 03:26:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-281966042 will have desired state: Ready
2022-04-06 03:27:49 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-281966042 is in desired state: Ready
2022-04-06 03:27:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-281966042 in namespace infra-namespace
2022-04-06 03:27:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-281966042 will be ready
2022-04-06 03:27:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-281966042 is ready
2022-04-06 03:27:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-281966042 in namespace infra-namespace
2022-04-06 03:27:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-281966042 will have desired state: Ready
2022-04-06 03:28:17 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-281966042 is in desired state: Ready
2022-04-06 03:28:17 [main] [32mINFO [m [RecoveryIsolatedST:171] Running deleteKafkaMetricsConfig with cluster recovery-cluster-281966042
2022-04-06 03:28:17 [main] [32mINFO [m [RecoveryIsolatedST:185] Waiting for creation recovery-cluster-281966042-kafka-config
2022-04-06 03:28:17 [main] [32mINFO [m [ConfigMapUtils:30] Waiting for config map recovery-cluster-281966042-kafka-config-4ae6f7b4-b98d-422e-8458-0c16cd6f72c6 recovery in namespace infra-namespace
2022-04-06 03:28:35 [main] [32mINFO [m [ConfigMapUtils:33] Config map recovery-cluster-281966042-kafka-config was recovered
2022-04-06 03:28:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:28:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromKafkaMetricsConfigDeletion
2022-04-06 03:28:35 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-281966042 in namespace infra-namespace
2022-04-06 03:28:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-281966042 in namespace infra-namespace
2022-04-06 03:28:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-281966042 in namespace infra-namespace
2022-04-06 03:29:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:29:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromKafkaMetricsConfigDeletion-FINISHED
2022-04-06 03:29:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:29:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:29:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperServiceDeletion-STARTED
2022-04-06 03:29:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:29:36 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:29:36 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:29:36 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:29:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:29:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:29:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:29:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:29:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:29:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:29:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:29:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:29:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:29:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:29:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:29:46 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:29:46 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:29:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:29:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:29:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:29:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:29:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:29:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:29:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:29:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:29:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:29:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:29:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:29:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:30:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:30:11 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:30:11 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:30:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:30:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:30:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:30:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:30:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:30:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:30:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:30:11 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:30:11 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:30:12 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:30:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:30:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:30:12 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:30:12 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:30:12 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:30:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:30:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:30:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:30:53 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:31:03 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:31:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1779846762 in namespace infra-namespace
2022-04-06 03:31:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1779846762 will have desired state: Ready
2022-04-06 03:32:32 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1779846762 is in desired state: Ready
2022-04-06 03:32:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1779846762 in namespace infra-namespace
2022-04-06 03:32:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1779846762 will be ready
2022-04-06 03:32:34 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1779846762 is ready
2022-04-06 03:32:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1779846762 in namespace infra-namespace
2022-04-06 03:32:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1779846762 will have desired state: Ready
2022-04-06 03:32:58 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1779846762 is in desired state: Ready
2022-04-06 03:32:58 [main] [32mINFO [m [RecoveryIsolatedST:129] Running deleteKafkaService with cluster recovery-cluster-1779846762
2022-04-06 03:32:58 [main] [32mINFO [m [RecoveryIsolatedST:136] Waiting for creation recovery-cluster-1779846762-zookeeper-client
2022-04-06 03:32:58 [main] [32mINFO [m [ServiceUtils:58] Waiting when Service recovery-cluster-1779846762-zookeeper-client-c3a0d60f-1983-4b17-a537-1c59c672e5e0 in namespace infra-namespace will be recovered
2022-04-06 03:33:20 [main] [32mINFO [m [ServiceUtils:62] recovery-cluster-1779846762-zookeeper-client in namespace infra-namespace is recovered
2022-04-06 03:33:20 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:33:20 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromZookeeperServiceDeletion
2022-04-06 03:33:20 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1779846762 in namespace infra-namespace
2022-04-06 03:33:20 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1779846762 in namespace infra-namespace
2022-04-06 03:33:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1779846762 in namespace infra-namespace
2022-04-06 03:34:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:34:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromZookeeperServiceDeletion-FINISHED
2022-04-06 03:34:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:34:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:34:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromImpossibleMemoryRequest-STARTED
2022-04-06 03:34:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:34:10 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:34:10 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:34:10 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:34:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:34:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:34:10 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:34:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:34:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:34:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:34:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:34:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:34:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:34:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:21 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:34:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:34:21 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:34:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:34:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:34:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:34:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:34:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:34:46 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:34:46 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:34:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:34:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:34:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:34:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:34:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:34:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:34:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:34:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:34:46 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:46 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:34:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:34:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:34:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:34:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:34:47 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:34:47 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:34:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:35:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:35:16 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:35:26 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:35:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka recovery-cluster-1790169192 in namespace infra-namespace
2022-04-06 03:35:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1790169192 will have desired state: Ready
2022-04-06 03:36:45 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1790169192 is in desired state: Ready
2022-04-06 03:36:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment kafka-clients-recovery-cluster-1790169192 in namespace infra-namespace
2022-04-06 03:36:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: kafka-clients-recovery-cluster-1790169192 will be ready
2022-04-06 03:36:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: kafka-clients-recovery-cluster-1790169192 is ready
2022-04-06 03:36:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge recovery-cluster-1790169192 in namespace infra-namespace
2022-04-06 03:36:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: recovery-cluster-1790169192 will have desired state: Ready
2022-04-06 03:37:05 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: recovery-cluster-1790169192 is in desired state: Ready
2022-04-06 03:37:05 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: recovery-cluster-1790169192-kafka will be in pending phase
2022-04-06 03:37:17 [main] [32mINFO [m [PodUtils:306] Verify that all pods with prefix: recovery-cluster-1790169192-kafka are stable in pending phase
2022-04-06 03:37:17 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 50
2022-04-06 03:37:18 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 49
2022-04-06 03:37:19 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 48
2022-04-06 03:37:20 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 47
2022-04-06 03:37:21 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 46
2022-04-06 03:37:22 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 45
2022-04-06 03:37:23 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 44
2022-04-06 03:37:24 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 43
2022-04-06 03:37:25 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 42
2022-04-06 03:37:26 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 41
2022-04-06 03:37:27 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 40
2022-04-06 03:37:28 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 39
2022-04-06 03:37:29 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 38
2022-04-06 03:37:30 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 37
2022-04-06 03:37:31 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 36
2022-04-06 03:37:32 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 35
2022-04-06 03:37:33 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 34
2022-04-06 03:37:34 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 33
2022-04-06 03:37:35 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 32
2022-04-06 03:37:36 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 31
2022-04-06 03:37:37 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 30
2022-04-06 03:37:38 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 29
2022-04-06 03:37:39 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 28
2022-04-06 03:37:40 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 27
2022-04-06 03:37:41 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 26
2022-04-06 03:37:42 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 25
2022-04-06 03:37:43 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 24
2022-04-06 03:37:44 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 23
2022-04-06 03:37:45 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 22
2022-04-06 03:37:46 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 21
2022-04-06 03:37:47 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 20
2022-04-06 03:37:48 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 19
2022-04-06 03:37:49 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 18
2022-04-06 03:37:50 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 17
2022-04-06 03:37:51 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 16
2022-04-06 03:37:52 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 15
2022-04-06 03:37:53 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 14
2022-04-06 03:37:54 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 13
2022-04-06 03:37:55 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 12
2022-04-06 03:37:56 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 11
2022-04-06 03:37:57 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 10
2022-04-06 03:37:58 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 9
2022-04-06 03:37:59 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 8
2022-04-06 03:38:00 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 7
2022-04-06 03:38:01 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 6
2022-04-06 03:38:02 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 5
2022-04-06 03:38:03 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 4
2022-04-06 03:38:04 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 3
2022-04-06 03:38:05 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 2
2022-04-06 03:38:06 [main] [32mINFO [m [PodUtils:322] Pod recovery-cluster-1790169192-kafka-1 is in the Pending state. Remaining seconds pod to be stable 1
2022-04-06 03:38:06 [main] [32mINFO [m [PodUtils:335] All pods are stable recovery-cluster-1790169192-kafka-1
2022-04-06 03:38:06 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of recovery-cluster-1790169192-kafka to be ready
2022-04-06 03:44:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1790169192 will have desired state: Ready
2022-04-06 03:44:10 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1790169192 is in desired state: Ready
2022-04-06 03:44:10 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: recovery-cluster-1790169192 is ready
2022-04-06 03:44:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: recovery-cluster-1790169192 will have desired state: Ready
2022-04-06 03:44:10 [main] [32mINFO [m [ResourceManager:444] Kafka: recovery-cluster-1790169192 is in desired state: Ready
2022-04-06 03:44:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:44:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRecoveryFromImpossibleMemoryRequest
2022-04-06 03:44:10 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment kafka-clients-recovery-cluster-1790169192 in namespace infra-namespace
2022-04-06 03:44:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka recovery-cluster-1790169192 in namespace infra-namespace
2022-04-06 03:44:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge recovery-cluster-1790169192 in namespace infra-namespace
2022-04-06 03:44:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:44:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.RecoveryIsolatedST.testRecoveryFromImpossibleMemoryRequest-FINISHED
2022-04-06 03:44:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:44:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:44:50 [main] [32mINFO [m [ResourceManager:346] In context RecoveryIsolatedST is everything deleted.
2022-04-06 03:44:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 14, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 3,797.585 s - in io.strimzi.systemtest.operators.RecoveryIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
2022-04-06 03:44:50 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:45:15 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 03:45:15 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 03:45:15 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 03:45:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:45:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 03:45:15 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:45:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:45:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:45:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:45:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:45:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:45:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:45:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:25 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:45:25 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:45:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:45:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:45:35 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:45:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:45:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:45:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:45:51 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 03:45:51 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 03:45:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 03:45:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:45:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 03:45:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 03:45:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:45:51 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 03:45:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 03:45:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 03:46:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 03:46:04 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 03:46:14 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 03:46:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 03:46:14 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 03:47:45 [main] [32mINFO [m [ResourceManager:444] Kafka: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 03:47:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-609391865-1811347379 in namespace infra-namespace
2022-04-06 03:47:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-609391865-1811347379 will have desired state: Ready
2022-04-06 03:47:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-609391865-1811347379 is in desired state: Ready
2022-04-06 03:47:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-06 03:47:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-shared-kafka-clients will be ready
2022-04-06 03:47:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-shared-kafka-clients is ready
2022-04-06 03:47:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:47:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicChangingInSyncReplicasStatus-STARTED
2022-04-06 03:47:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:47:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-25224152-2079631447 in namespace infra-namespace
2022-04-06 03:47:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-25224152-2079631447 will have desired state: Ready
2022-04-06 03:47:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-25224152-2079631447 is in desired state: Ready
2022-04-06 03:47:49 [main] [32mINFO [m [CustomResourceStatusIsolatedST:481] Changing min.insync.replicas to random char
2022-04-06 03:47:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-25224152-2079631447 will have desired state: NotReady
2022-04-06 03:47:50 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-25224152-2079631447 is in desired state: NotReady
2022-04-06 03:47:50 [main] [32mINFO [m [CustomResourceStatusIsolatedST:488] Wait 245000 ms for next reconciliation
2022-04-06 03:51:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:51:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicChangingInSyncReplicasStatus
2022-04-06 03:51:55 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-25224152-2079631447 in namespace infra-namespace
2022-04-06 03:52:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:52:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicChangingInSyncReplicasStatus-FINISHED
2022-04-06 03:52:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:52:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:52:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatusNotReady-STARTED
2022-04-06 03:52:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:52:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace infra-namespace
2022-04-06 03:52:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef will have desired state: NotReady
2022-04-06 03:52:06 [main] [32mINFO [m [ResourceManager:444] KafkaUser: sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: NotReady
2022-04-06 03:52:06 [main] [32mINFO [m [CustomResourceStatusIsolatedST:179] Checking status of deployed KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef
2022-04-06 03:52:06 [main] [32mINFO [m [CustomResourceStatusIsolatedST:181] KafkaUser Status: True
2022-04-06 03:52:06 [main] [32mINFO [m [CustomResourceStatusIsolatedST:182] KafkaUser Type: NotReady
2022-04-06 03:52:06 [main] [32mINFO [m [CustomResourceStatusIsolatedST:183] KafkaUser Message: Spec cannot be null
2022-04-06 03:52:06 [main] [32mINFO [m [CustomResourceStatusIsolatedST:184] KafkaUser Reason: InvalidResourceException
2022-04-06 03:52:06 [main] [32mINFO [m [CustomResourceStatusIsolatedST:186] KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef is in desired state: NotReady
2022-04-06 03:52:06 [main] [32mINFO [m [KafkaUserUtils:62] Waiting for KafkaUser deletion sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef
2022-04-06 03:52:06 [main] [32mINFO [m [KafkaUserUtils:75] KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef deleted
2022-04-06 03:52:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:52:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaUserStatusNotReady
2022-04-06 03:52:06 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef in namespace infra-namespace
2022-04-06 03:52:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:52:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatusNotReady-FINISHED
2022-04-06 03:52:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:52:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:52:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatus-STARTED
2022-04-06 03:52:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:52:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-962009103-1756828438 in namespace infra-namespace
2022-04-06 03:52:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-962009103-1756828438 will have desired state: Ready
2022-04-06 03:52:07 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-962009103-1756828438 is in desired state: Ready
2022-04-06 03:52:07 [main] [32mINFO [m [CustomResourceStatusIsolatedST:162] Checking status of deployed KafkaUser
2022-04-06 03:52:07 [main] [32mINFO [m [CustomResourceStatusIsolatedST:164] KafkaUser Status: True
2022-04-06 03:52:07 [main] [32mINFO [m [CustomResourceStatusIsolatedST:165] KafkaUser Type: Ready
2022-04-06 03:52:07 [main] [32mINFO [m [CustomResourceStatusIsolatedST:167] KafkaUser is in desired state: Ready
2022-04-06 03:52:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:52:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaUserStatus
2022-04-06 03:52:07 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-962009103-1756828438 in namespace infra-namespace
2022-04-06 03:52:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:52:17 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaUserStatus-FINISHED
2022-04-06 03:52:17 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:52:17 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:52:17 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatusNotReady-STARTED
2022-04-06 03:52:17 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:52:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-252854575-424489687 in namespace infra-namespace
2022-04-06 03:52:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-252854575-424489687 will have desired state: NotReady
2022-04-06 03:52:18 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-252854575-424489687 is in desired state: NotReady
2022-04-06 03:52:19 [main] [32mINFO [m [KafkaTopicUtils:104] Waiting for KafkaTopic my-topic-252854575-424489687 deletion
2022-04-06 03:52:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:52:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicStatusNotReady
2022-04-06 03:52:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-252854575-424489687 in namespace infra-namespace
2022-04-06 03:52:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:52:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatusNotReady-FINISHED
2022-04-06 03:52:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:52:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:52:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaStatusCertificate-STARTED
2022-04-06 03:52:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:52:19 [main] [32mINFO [m [CustomResourceStatusIsolatedST:381] Check if KafkaStatus certificates are the same as secret certificates
2022-04-06 03:52:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:52:19 [main] [32mINFO [m [ResourceManager:346] In context testKafkaStatusCertificate is everything deleted.
2022-04-06 03:52:19 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:52:19 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaStatusCertificate-FINISHED
2022-04-06 03:52:19 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:52:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:52:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaBridgeStatus-STARTED
2022-04-06 03:52:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:52:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 03:52:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 03:52:45 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 03:52:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 03:52:45 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 03:52:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-06 03:53:17 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-06 03:53:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 03:54:19 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 03:54:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:54:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeStatus
2022-04-06 03:54:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 03:54:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:54:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaBridgeStatus-FINISHED
2022-04-06 03:54:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:54:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:54:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatus-STARTED
2022-04-06 03:54:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:54:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1576266148-1534050060 in namespace infra-namespace
2022-04-06 03:54:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1576266148-1534050060 will have desired state: Ready
2022-04-06 03:54:30 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1576266148-1534050060 is in desired state: Ready
2022-04-06 03:54:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1576266148-1534050060 will have desired state: Ready
2022-04-06 03:54:30 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1576266148-1534050060 is in desired state: Ready
2022-04-06 03:54:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 03:54:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicStatus
2022-04-06 03:54:30 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1576266148-1534050060 in namespace infra-namespace
2022-04-06 03:54:40 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 03:54:40 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicStatus-FINISHED
2022-04-06 03:54:40 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 03:54:40 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 03:54:40 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2Status-STARTED
2022-04-06 03:54:40 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 03:54:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-0ae88b29 in namespace infra-namespace
2022-04-06 03:54:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-0ae88b29 will have desired state: Ready
2022-04-06 03:55:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-0ae88b29 is in desired state: Ready
2022-04-06 03:55:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-0ae88b29-mirror-maker-2 in namespace infra-namespace
2022-04-06 03:55:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-0ae88b29-mirror-maker-2 will have desired state: Ready
2022-04-06 03:57:01 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-0ae88b29-mirror-maker-2 is in desired state: Ready
2022-04-06 03:57:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-0ae88b29-mirror-maker-2 will have desired state: Ready
2022-04-06 03:57:01 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-0ae88b29-mirror-maker-2 is in desired state: Ready
2022-04-06 03:57:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-0ae88b29-mirror-maker-2 will have desired state: NotReady
2022-04-06 03:57:32 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-0ae88b29-mirror-maker-2 is in desired state: NotReady
2022-04-06 03:57:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-0ae88b29-mirror-maker-2 will have desired state: Ready
2022-04-06 03:59:05 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-0ae88b29-mirror-maker-2 is in desired state: Ready
2022-04-06 03:59:29 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-0ae88b29-mirror-maker-2-mirrormaker2 are stable
2022-04-06 03:59:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 03:59:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 03:59:31 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 03:59:32 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 03:59:33 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 03:59:34 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 03:59:35 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 03:59:36 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 03:59:37 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 03:59:38 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 03:59:39 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 03:59:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 03:59:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 03:59:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 03:59:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 03:59:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 03:59:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 03:59:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 03:59:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 03:59:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 03:59:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 03:59:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 03:59:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 03:59:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 03:59:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 03:59:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 03:59:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 03:59:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 03:59:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 03:59:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 03:59:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 04:00:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 04:00:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 04:00:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 04:00:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 04:00:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 04:00:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 04:00:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 04:00:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 04:00:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 04:00:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 04:00:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 04:00:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 04:00:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 04:00:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 04:00:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 04:00:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 04:00:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 04:00:17 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 04:00:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 04:00:18 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-0ae88b29-mirror-maker-2-mirrormaker2-64547c5556mtqb5
2022-04-06 04:00:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:00:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2Status
2022-04-06 04:00:18 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-0ae88b29-mirror-maker-2 in namespace infra-namespace
2022-04-06 04:00:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-0ae88b29 in namespace infra-namespace
2022-04-06 04:00:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:00:28 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2Status-FINISHED
2022-04-06 04:00:28 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:00:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:00:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectorWithoutClusterConfig-STARTED
2022-04-06 04:00:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:00:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-4c141ac4 in namespace infra-namespace
2022-04-06 04:00:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-4c141ac4 will have desired state: NotReady
2022-04-06 04:00:29 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-4c141ac4 is in desired state: NotReady
2022-04-06 04:00:29 [main] [32mINFO [m [KafkaConnectorUtils:98] KafkaConnector: my-cluster-4c141ac4 is not deleted yet, triggering force delete
2022-04-06 04:00:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:00:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectorWithoutClusterConfig
2022-04-06 04:00:31 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-4c141ac4 in namespace infra-namespace
2022-04-06 04:00:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:00:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectorWithoutClusterConfig-FINISHED
2022-04-06 04:00:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:00:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:00:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatusWrongBootstrap-STARTED
2022-04-06 04:00:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:00:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-564a13e4 in namespace infra-namespace
2022-04-06 04:00:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-564a13e4 will have desired state: Ready
2022-04-06 04:01:32 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-564a13e4 is in desired state: Ready
2022-04-06 04:01:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-564a13e4 will have desired state: Ready
2022-04-06 04:01:32 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-564a13e4 is in desired state: Ready
2022-04-06 04:01:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-564a13e4 will have desired state: NotReady
2022-04-06 04:02:03 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-564a13e4 is in desired state: NotReady
2022-04-06 04:02:03 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-564a13e4 will have desired state: Ready
2022-04-06 04:02:35 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-564a13e4 is in desired state: Ready
2022-04-06 04:02:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:02:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMakerStatusWrongBootstrap
2022-04-06 04:02:35 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-564a13e4 in namespace infra-namespace
2022-04-06 04:02:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:02:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatusWrongBootstrap-FINISHED
2022-04-06 04:02:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:02:45 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:02:45 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectAndConnectorStatus-STARTED
2022-04-06 04:02:45 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:02:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment custom-resource-status-cluster-name-scraper in namespace infra-namespace
2022-04-06 04:02:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: custom-resource-status-cluster-name-scraper will be ready
2022-04-06 04:02:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: custom-resource-status-cluster-name-scraper is ready
2022-04-06 04:02:47 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment custom-resource-status-cluster-name-scraper to be ready
2022-04-06 04:02:57 [main] [32mINFO [m [DeploymentUtils:197] Deployment custom-resource-status-cluster-name-scraper is ready
2022-04-06 04:02:57 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to custom-resource-status-cluster-name-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 04:02:57 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy custom-resource-status-cluster-name-allow in namespace infra-namespace
2022-04-06 04:02:57 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 04:02:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 04:02:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:04:07 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:04:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 04:04:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:04:08 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:04:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-06 04:04:39 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-06 04:04:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:06:29 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:06:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-06 04:06:30 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-06 04:06:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:06:31 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:06:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: NotReady
2022-04-06 04:06:32 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: NotReady
2022-04-06 04:06:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: custom-resource-status-cluster-name will have desired state: Ready
2022-04-06 04:06:33 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: custom-resource-status-cluster-name is in desired state: Ready
2022-04-06 04:06:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:06:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndConnectorStatus
2022-04-06 04:06:33 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 04:06:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy custom-resource-status-cluster-name-allow in namespace infra-namespace
2022-04-06 04:06:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 04:06:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment custom-resource-status-cluster-name-scraper in namespace infra-namespace
2022-04-06 04:07:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:07:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaConnectAndConnectorStatus-FINISHED
2022-04-06 04:07:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:07:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:07:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2WrongBootstrap-STARTED
2022-04-06 04:07:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:07:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-2a4cd0f5-mirror-maker-2 in namespace infra-namespace
2022-04-06 04:07:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-2a4cd0f5-mirror-maker-2 will have desired state: NotReady
2022-04-06 04:07:44 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-2a4cd0f5-mirror-maker-2 is in desired state: NotReady
2022-04-06 04:07:44 [main] [33mWARN [m [DeploymentUtils:213] Deployment my-cluster-2a4cd0f5-mirror-maker-2-mirrormaker2 is not deleted yet! Triggering force delete by cmd client!
2022-04-06 04:07:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:07:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2WrongBootstrap
2022-04-06 04:07:50 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-2a4cd0f5-mirror-maker-2 in namespace infra-namespace
2022-04-06 04:07:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:07:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMaker2WrongBootstrap-FINISHED
2022-04-06 04:07:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:07:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:07:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicDecreaseStatus-STARTED
2022-04-06 04:07:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:07:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-884050094-2088016852 in namespace infra-namespace
2022-04-06 04:07:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-884050094-2088016852 will have desired state: Ready
2022-04-06 04:07:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-884050094-2088016852 is in desired state: Ready
2022-04-06 04:07:51 [main] [32mINFO [m [CustomResourceStatusIsolatedST:457] Decreasing number of partitions to 1
2022-04-06 04:07:51 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-topic-884050094-2088016852
2022-04-06 04:07:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-884050094-2088016852 will have desired state: NotReady
2022-04-06 04:07:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-884050094-2088016852 is in desired state: NotReady
2022-04-06 04:07:52 [main] [32mINFO [m [CustomResourceStatusIsolatedST:465] Wait 245000 ms for next reconciliation
2022-04-06 04:11:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:11:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicDecreaseStatus
2022-04-06 04:11:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-884050094-2088016852 in namespace infra-namespace
2022-04-06 04:12:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:12:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaTopicDecreaseStatus-FINISHED
2022-04-06 04:12:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:12:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:12:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus-STARTED
2022-04-06 04:12:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:12:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-88b123df-mirror-maker in namespace infra-namespace
2022-04-06 04:12:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-88b123df-mirror-maker will have desired state: Ready
2022-04-06 04:13:28 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-88b123df-mirror-maker is in desired state: Ready
2022-04-06 04:13:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-88b123df-mirror-maker will have desired state: Ready
2022-04-06 04:13:28 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-88b123df-mirror-maker is in desired state: Ready
2022-04-06 04:13:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-88b123df-mirror-maker will have desired state: NotReady
2022-04-06 04:13:59 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-88b123df-mirror-maker is in desired state: NotReady
2022-04-06 04:13:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-88b123df-mirror-maker will have desired state: Ready
2022-04-06 04:15:35 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-88b123df-mirror-maker is in desired state: Ready
2022-04-06 04:15:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:15:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMakerStatus
2022-04-06 04:15:35 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-88b123df-mirror-maker in namespace infra-namespace
2022-04-06 04:15:45 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:15:45 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST.testKafkaMirrorMakerStatus-FINISHED
2022-04-06 04:15:45 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:15:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:15:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for CustomResourceStatusIsolatedST
2022-04-06 04:15:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-609391865-1811347379 in namespace infra-namespace
2022-04-06 04:15:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka custom-resource-status-cluster-name in namespace infra-namespace
2022-04-06 04:15:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-06 04:16:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1,895.272 s - in io.strimzi.systemtest.operators.CustomResourceStatusIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
2022-04-06 04:16:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:16:50 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 04:16:50 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 04:16:50 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 04:16:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:16:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 04:16:50 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:16:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:16:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:16:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:16:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:16:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:16:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:16:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:16:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:16:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:16:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:16:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:16:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:16:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:00 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:17:00 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:17:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:17:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:17:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:17:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-STARTED
2022-04-06 04:17:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:17:26 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating first-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-06 04:17:26 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@1422440a, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@1a33205e, clusterOperatorName='first-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=first-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=first-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 04:17:26 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:17:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-co-cluster-test
2022-04-06 04:17:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-06 04:17:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:17:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:17:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:17:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:17:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:17:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:17:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-06 04:17:27 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:17:27 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:17:27 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-06 04:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:17:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: first-strimzi-cluster-operator will be ready
2022-04-06 04:17:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: first-strimzi-cluster-operator is ready
2022-04-06 04:17:51 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment first-strimzi-cluster-operator to be ready
2022-04-06 04:18:01 [main] [32mINFO [m [DeploymentUtils:197] Deployment first-strimzi-cluster-operator is ready
2022-04-06 04:18:01 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating second-strimzi-cluster-operator in multiple-co-cluster-test namespace
2022-04-06 04:18:01 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@1422440a, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@1a33205e, clusterOperatorName='second-strimzi-cluster-operator', namespaceInstallTo='multiple-co-cluster-test', namespaceToWatch='multiple-co-cluster-test', bindingsNamespaces=[multiple-co-cluster-test], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=second-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=second-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 04:18:01 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:18:01 [main] [32mINFO [m [SetupClusterOperator:254] Environment for ClusterOperator was already prepared! Going to install it now.
2022-04-06 04:18:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:18:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: multiple-co-cluster-test
2022-04-06 04:18:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:18:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace multiple-co-cluster-test
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:18:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testKafkaCCAndRebalanceWithMultipleCOs from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace multiple-co-cluster-test
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-06 04:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:18:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-strimzi-cluster-operator will be ready
2022-04-06 04:18:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-strimzi-cluster-operator is ready
2022-04-06 04:18:28 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment second-strimzi-cluster-operator to be ready
2022-04-06 04:18:38 [main] [32mINFO [m [DeploymentUtils:197] Deployment second-strimzi-cluster-operator is ready
2022-04-06 04:18:38 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:171] Deploying Kafka with {app.kubernetes.io/operator=first-strimzi-cluster-operator} selector of first-strimzi-cluster-operator
2022-04-06 04:18:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5678cce7 in namespace multiple-co-cluster-test
2022-04-06 04:18:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5678cce7 will have desired state: Ready
2022-04-06 04:20:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5678cce7 is in desired state: Ready
2022-04-06 04:20:22 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:180] Removing CR selector from Kafka and increasing number of replicas to 4, new pod should not appear
2022-04-06 04:20:22 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:188] Creating KafkaRebalance when CC doesn't have label for CO, the KR should be ignored
2022-04-06 04:20:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaRebalance my-cluster-5678cce7 in namespace multiple-co-cluster-test
2022-04-06 04:20:22 [main] [32mINFO [m [KafkaUtils:180] Waiting for cluster stability
2022-04-06 04:21:24 [main] [32mINFO [m [KafkaUtils:208] Kafka cluster is stable after 61 polls.
2022-04-06 04:21:24 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:204] Checking if KafkaRebalance is still ignored, after the cluster stability wait
2022-04-06 04:21:24 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:209] Adding {app.kubernetes.io/operator=second-strimzi-cluster-operator} selector of second-strimzi-cluster-operator to Kafka
2022-04-06 04:21:24 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:212] Waiting for Kafka to scales pods to 4
2022-04-06 04:21:24 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-5678cce7-kafka to be ready
2022-04-06 04:24:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5678cce7 will have desired state: Ready
2022-04-06 04:24:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5678cce7 is in desired state: Ready
2022-04-06 04:24:47 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-5678cce7 is ready
2022-04-06 04:24:47 [main] [32mINFO [m [KafkaRebalanceUtils:75] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-5678cce7): ============================================================================
2022-04-06 04:24:47 [main] [32mINFO [m [KafkaRebalanceUtils:76] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-5678cce7): PendingProposal
2022-04-06 04:24:47 [main] [32mINFO [m [KafkaRebalanceUtils:77] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-5678cce7): ============================================================================
2022-04-06 04:24:47 [main] [32mINFO [m [KafkaRebalanceUtils:81] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-5678cce7): Verifying that KafkaRebalance resource is in PendingProposal state
2022-04-06 04:24:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-5678cce7 will have desired state: PendingProposal
2022-04-06 04:24:47 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-5678cce7 is in desired state: PendingProposal
2022-04-06 04:24:47 [main] [32mINFO [m [KafkaRebalanceUtils:85] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-5678cce7): Verifying that KafkaRebalance resource is in ProposalReady state
2022-04-06 04:24:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-5678cce7 will have desired state: ProposalReady
2022-04-06 04:25:20 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-5678cce7 is in desired state: ProposalReady
2022-04-06 04:25:20 [main] [32mINFO [m [KafkaRebalanceUtils:90] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-5678cce7): ============================================================================
2022-04-06 04:25:20 [main] [32mINFO [m [KafkaRebalanceUtils:91] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-5678cce7): ProposalReady
2022-04-06 04:25:20 [main] [32mINFO [m [KafkaRebalanceUtils:92] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-5678cce7): ============================================================================
2022-04-06 04:25:20 [main] [32mINFO [m [KafkaRebalanceUtils:94] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-5678cce7): Triggering the rebalance with annotation strimzi.io/rebalance=approve of KafkaRebalance resource
2022-04-06 04:25:20 [main] [32mINFO [m [KafkaRebalanceUtils:63] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-5678cce7): Annotating KafkaRebalance:my-cluster-5678cce7 with annotation approve
2022-04-06 04:25:20 [main] [32mINFO [m [KafkaRebalanceUtils:98] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-5678cce7): Response from the annotation process kafkarebalance.kafka.strimzi.io/my-cluster-5678cce7 annotated
2022-04-06 04:25:20 [main] [32mINFO [m [KafkaRebalanceUtils:100] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-5678cce7): Verifying that annotation triggers the Rebalancing state
2022-04-06 04:25:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-5678cce7 will have desired state: Rebalancing
2022-04-06 04:25:21 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-5678cce7 is in desired state: Rebalancing
2022-04-06 04:25:21 [main] [32mINFO [m [KafkaRebalanceUtils:104] Reconciliation #8(test) KafkaRebalance(second-co-namespace/my-cluster-5678cce7): Verifying that KafkaRebalance is in the Ready state
2022-04-06 04:25:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaRebalance: my-cluster-5678cce7 will have desired state: Ready
2022-04-06 04:25:26 [main] [32mINFO [m [ResourceManager:444] KafkaRebalance: my-cluster-5678cce7 is in desired state: Ready
2022-04-06 04:25:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:25:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaCCAndRebalanceWithMultipleCOs
2022-04-06 04:25:26 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:25:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:25:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:25:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:25:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-06 04:25:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment second-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:25:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:25:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:25:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:25:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5678cce7 in namespace multiple-co-cluster-test
2022-04-06 04:25:36 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace multiple-co-cluster-test, for cruise control Kafka cluster my-cluster-5678cce7
2022-04-06 04:25:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaRebalance my-cluster-5678cce7 in namespace multiple-co-cluster-test
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:25:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:46 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace multiple-co-cluster-test
2022-04-06 04:25:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment first-strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:25:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:25:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:25:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:25:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:25:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:25:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:25:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:25:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:25:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:25:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:25:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:06 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace multiple-co-cluster-test
2022-04-06 04:26:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:26:06 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testKafkaCCAndRebalanceWithMultipleCOs-FINISHED
2022-04-06 04:26:06 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:26:06 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:26:06 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testMultipleCOsInDifferentNamespaces-STARTED
2022-04-06 04:26:06 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:26:06 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:26:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding first-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:26:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding first-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:26:06 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating first-strimzi-cluster-operator in first-co-namespace namespace
2022-04-06 04:26:06 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@1422440a, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@2370506a, clusterOperatorName='first-strimzi-cluster-operator', namespaceInstallTo='first-co-namespace', namespaceToWatch='*', bindingsNamespaces=[first-co-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=first-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=first-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 04:26:06 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:26:06 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: first-co-namespace
2022-04-06 04:26:06 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: first-co-namespace
2022-04-06 04:26:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:26:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:26:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:26:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:26:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:26:06 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:26:06 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:26:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: first-co-namespace
2022-04-06 04:26:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace first-co-namespace
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:26:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace first-co-namespace
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:26:07 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace first-co-namespace
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:26:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace first-co-namespace
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:26:07 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace first-co-namespace
2022-04-06 04:26:07 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace first-co-namespace
2022-04-06 04:26:08 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:26:08 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:26:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:26:08 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:26:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment first-strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:26:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: first-strimzi-cluster-operator will be ready
2022-04-06 04:26:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: first-strimzi-cluster-operator is ready
2022-04-06 04:26:41 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment first-strimzi-cluster-operator to be ready
2022-04-06 04:26:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment first-strimzi-cluster-operator is ready
2022-04-06 04:26:51 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding second-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding second-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:26:51 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:230] Creating second-strimzi-cluster-operator in second-co-namespace namespace
2022-04-06 04:26:51 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@1422440a, extensionContext=org.junit.jupiter.engine.descriptor.MethodExtensionContext@2370506a, clusterOperatorName='second-strimzi-cluster-operator', namespaceInstallTo='second-co-namespace', namespaceToWatch='*', bindingsNamespaces=[second-co-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_RESOURCE_SELECTOR, value=app.kubernetes.io/operator=second-strimzi-cluster-operator, valueFrom=null, additionalProperties={})], extraLabels={app.kubernetes.io/operator=second-strimzi-cluster-operator}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 04:26:51 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:26:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-co-namespace
2022-04-06 04:26:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-co-namespace
2022-04-06 04:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:51 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:26:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-co-namespace
2022-04-06 04:26:52 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace second-co-namespace
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:26:52 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace second-co-namespace
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:26:52 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace second-co-namespace
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:26:52 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace second-co-namespace
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:26:52 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case testMultipleCOsInDifferentNamespaces from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace second-co-namespace
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-co-namespace
2022-04-06 04:26:52 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:26:52 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:26:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:26:52 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-strimzi-cluster-operator will be ready
2022-04-06 04:27:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-strimzi-cluster-operator is ready
2022-04-06 04:27:26 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment second-strimzi-cluster-operator to be ready
2022-04-06 04:27:36 [main] [32mINFO [m [DeploymentUtils:197] Deployment second-strimzi-cluster-operator is ready
2022-04-06 04:27:36 [main] [33mWARN [m [KubeClusterResource:151] Namespace multiple-co-cluster-test is already created, going to delete it
2022-04-06 04:27:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: multiple-co-cluster-test
2022-04-06 04:27:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-06 04:27:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: multiple-co-cluster-test
2022-04-06 04:27:43 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:100] Deploying Kafka without CR selector
2022-04-06 04:27:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-258026a3 in namespace multiple-co-cluster-test
2022-04-06 04:27:43 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-258026a3 will have stable 0 replicas
2022-04-06 04:27:43 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-06 04:27:44 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-06 04:27:45 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-06 04:27:46 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-06 04:27:47 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-06 04:27:48 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-06 04:27:49 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-06 04:27:50 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-06 04:27:51 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-06 04:27:52 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-06 04:27:53 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-06 04:27:54 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-06 04:27:55 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-06 04:27:56 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-06 04:27:57 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-06 04:27:58 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-06 04:27:59 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-06 04:28:00 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-06 04:28:01 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-06 04:28:02 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-06 04:28:02 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-258026a3 has 0 replicas
2022-04-06 04:28:02 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:110] Adding {app.kubernetes.io/operator=first-strimzi-cluster-operator} selector of first-strimzi-cluster-operator into Kafka CR
2022-04-06 04:28:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-258026a3 will have desired state: Ready
2022-04-06 04:29:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-258026a3 is in desired state: Ready
2022-04-06 04:29:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-751690157-491989472 in namespace multiple-co-cluster-test
2022-04-06 04:29:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-258026a3 in namespace multiple-co-cluster-test
2022-04-06 04:29:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-751690157-491989472 will have desired state: Ready
2022-04-06 04:29:30 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-751690157-491989472 is in desired state: Ready
2022-04-06 04:29:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-258026a3 will have desired state: Ready
2022-04-06 04:30:39 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-258026a3 is in desired state: Ready
2022-04-06 04:30:39 [main] [32mINFO [m [MultipleClusterOperatorsIsolatedST:130] Deploying KafkaConnector with file sink and CR selector - {app.kubernetes.io/operator=second-strimzi-cluster-operator} - different than selector in Kafka
2022-04-06 04:30:39 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-258026a3 in namespace multiple-co-cluster-test
2022-04-06 04:30:39 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-258026a3 will have desired state: Ready
2022-04-06 04:30:40 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-258026a3 is in desired state: Ready
2022-04-06 04:30:40 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 04:30:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace multiple-co-cluster-test
2022-04-06 04:30:40 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-06 04:30:41 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:hello-world-producer to finished
2022-04-06 04:30:50 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-258026a3-connect-69b8f8c7b9-fkwpq
2022-04-06 04:30:51 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-258026a3-connect-69b8f8c7b9-fkwpq
2022-04-06 04:30:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:30:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultipleCOsInDifferentNamespaces
2022-04-06 04:30:51 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:30:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:30:51 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:30:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:30:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:30:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:30:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment second-strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:30:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-258026a3 in namespace multiple-co-cluster-test
2022-04-06 04:31:01 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:31:01 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:31:01 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:31:01 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:01 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:01 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:31:01 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-751690157-491989472 in namespace multiple-co-cluster-test
2022-04-06 04:31:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:31:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-258026a3 in namespace multiple-co-cluster-test
2022-04-06 04:31:11 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-258026a3 in namespace multiple-co-cluster-test
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace multiple-co-cluster-test
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-co-namespace
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace second-co-namespace
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment first-strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding second-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding second-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace first-co-namespace
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding first-strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding first-strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:31:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace first-co-namespace
2022-04-06 04:31:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:31:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST.testMultipleCOsInDifferentNamespaces-FINISHED
2022-04-06 04:31:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:31:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:31:21 [main] [32mINFO [m [ResourceManager:346] In context MultipleClusterOperatorsIsolatedST is everything deleted.
2022-04-06 04:31:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 895.891 s - in io.strimzi.systemtest.operators.MultipleClusterOperatorsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
2022-04-06 04:31:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:31:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:31:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorsWhenRackAwarenessIsEnabled-STARTED
2022-04-06 04:31:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:31:46 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 04:31:46 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 04:31:46 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 04:31:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:31:46 [main] [32mINFO [m [ResourceManager:346] In context JUnit Jupiter is everything deleted.
2022-04-06 04:31:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:32:12 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@1422440a, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=NAMESPACE, testClassName='null', testMethodName='null'}
2022-04-06 04:32:12 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:32:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 04:32:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:32:12 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:32:12 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:32:12 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:32:12 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:32:12 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:32:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:32:13 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/020-Role-strimzi-cluster-operator-role7934384266175879239.yaml in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:32:13 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/021-Role-strimzi-cluster-operator-role8815100646525568329.yaml in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-06 04:32:13 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/030-Role-strimzi-kafka-broker10607999239379411266.yaml in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-06 04:32:13 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/031-Role-strimzi-entity-operator767140149265728109.yaml in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-06 04:32:13 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/033-Role-strimzi-kafka-client1321976903105605593.yaml in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-06 04:32:13 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator8160679197314573578.yaml in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-06 04:32:13 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation7230807186531900885.yaml in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-06 04:32:13 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator11673065751434309411.yaml in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-06 04:32:13 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation2406563660974136242.yaml in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:32:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 04:32:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 04:32:54 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 04:33:04 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 04:33:04 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:99] Deploying Kafka: my-cluster-fff3f164, which should not be deployed and error should be present in CR status message
2022-04-06 04:33:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fff3f164 in namespace infra-namespace
2022-04-06 04:33:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fff3f164-kafka-clients in namespace infra-namespace
2022-04-06 04:33:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fff3f164-kafka-clients will be ready
2022-04-06 04:33:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fff3f164-kafka-clients is ready
2022-04-06 04:33:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fff3f164-scraper in namespace infra-namespace
2022-04-06 04:33:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fff3f164-scraper will be ready
2022-04-06 04:33:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fff3f164-scraper is ready
2022-04-06 04:33:41 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-fff3f164-scraper to be ready
2022-04-06 04:33:51 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-fff3f164-scraper is ready
2022-04-06 04:33:51 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-fff3f164-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 04:33:51 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-fff3f164-allow in namespace infra-namespace
2022-04-06 04:33:51 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 04:33:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-fff3f164 in namespace infra-namespace
2022-04-06 04:33:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:33:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCRBDeletionErrorsWhenRackAwarenessIsEnabled
2022-04-06 04:33:52 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fff3f164-scraper in namespace infra-namespace
2022-04-06 04:33:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fff3f164-kafka-clients in namespace infra-namespace
2022-04-06 04:33:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-fff3f164 in namespace infra-namespace
2022-04-06 04:33:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fff3f164 in namespace infra-namespace
2022-04-06 04:34:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-fff3f164-allow in namespace infra-namespace
2022-04-06 04:34:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:34:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorsWhenRackAwarenessIsEnabled-FINISHED
2022-04-06 04:34:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:34:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:34:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled-STARTED
2022-04-06 04:34:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:34:42 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 04:34:42 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 04:34:42 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 04:34:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:34:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 04:34:42 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:34:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:34:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:34:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:34:42 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:34:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:34:42 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:34:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:34:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:34:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:34:43 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:34:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:34:43 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:34:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:34:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:34:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:34:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:34:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:34:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:53 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:34:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:03 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:03 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:35:18 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@1422440a, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=NAMESPACE, testClassName='null', testMethodName='null'}
2022-04-06 04:35:18 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:35:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 04:35:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:35:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:35:18 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:35:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:35:18 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:35:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:35:18 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-06 04:35:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:35:18 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-06 04:35:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:35:18 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-06 04:35:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:35:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:35:19 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/020-Role-strimzi-cluster-operator-role3406063582550452197.yaml in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRole-strimzi-cluster-operator-role.yaml
2022-04-06 04:35:19 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/021-Role-strimzi-cluster-operator-role14979034171334422059.yaml in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRole-strimzi-kafka-broker.yaml
2022-04-06 04:35:19 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/030-Role-strimzi-kafka-broker17051749007973374437.yaml in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-ClusterRole-strimzi-entity-operator.yaml
2022-04-06 04:35:19 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/031-Role-strimzi-entity-operator11036253359231547843.yaml in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRole-strimzi-kafka-client.yaml
2022-04-06 04:35:19 [main] [32mINFO [m [RoleResource:43] Creating Role from /tmp/033-Role-strimzi-kafka-client8068424392795582351.yaml in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-06 04:35:19 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator10689947270922032451.yaml in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-06 04:35:19 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation5565511783702714151.yaml in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml
2022-04-06 04:35:19 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/020-Role-strimzi-cluster-operator10238807866481121835.yaml in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [SetupClusterOperator:535] Replaced ClusterRole for Role in /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
2022-04-06 04:35:19 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /tmp/031-Role-strimzi-cluster-operator-entity-operator-delegation15195876323485833465.yaml in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:35:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 04:35:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 04:35:51 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 04:36:01 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 04:36:01 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:63] Deploying Kafka: my-cluster-a1f170c3, which should be deployed even the CRBs are not present
2022-04-06 04:36:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-a1f170c3 in namespace infra-namespace
2022-04-06 04:36:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-a1f170c3 will have desired state: Ready
2022-04-06 04:37:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-a1f170c3 is in desired state: Ready
2022-04-06 04:37:23 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:67] CO log should contain some information about ignoring forbidden access to CRB for Kafka
2022-04-06 04:37:23 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:71] Deploying KafkaConnect: my-cluster-a1f170c3 without rack awareness, the CR should be deployed without error
2022-04-06 04:37:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-a1f170c3 in namespace infra-namespace
2022-04-06 04:37:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-a1f170c3 will have desired state: Ready
2022-04-06 04:38:28 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-a1f170c3 is in desired state: Ready
2022-04-06 04:38:28 [main] [32mINFO [m [ClusterOperatorRbacIsolatedST:74] CO log should contain some information about ignoring forbidden access to CRB for KafkaConnect
2022-04-06 04:38:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:38:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled
2022-04-06 04:38:28 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-a1f170c3 in namespace infra-namespace
2022-04-06 04:38:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-a1f170c3 in namespace infra-namespace
2022-04-06 04:38:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:38:38 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST.testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled-FINISHED
2022-04-06 04:38:38 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:38:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:38:38 [main] [32mINFO [m [ResourceManager:346] In context ClusterOperatorRbacIsolatedST is everything deleted.
2022-04-06 04:38:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 437.519 s - in io.strimzi.systemtest.operators.ClusterOperatorRbacIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
2022-04-06 04:38:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:39:03 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 04:39:03 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 04:39:03 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 04:39:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:39:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 04:39:03 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:39:03 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:03 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:39:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:39:04 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:39:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:39:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:39:04 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:39:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:39:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:39:04 [main] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:39:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:39:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-broker in namespace infra-namespace
2022-04-06 04:39:04 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-entity-operator in namespace infra-namespace
2022-04-06 04:39:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-kafka-client in namespace infra-namespace
2022-04-06 04:39:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-namespaced in namespace infra-namespace
2022-04-06 04:39:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Role strimzi-cluster-operator-global in namespace infra-namespace
2022-04-06 04:39:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:39:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:39:14 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:24 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:34 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:39:39 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
, extraEnvVars=[EnvVar(name=STRIMZI_CUSTOM_KAFKA_BRIDGE_SERVICE_LABELS, value=app=bar, valueFrom=null, additionalProperties={}), EnvVar(name=STRIMZI_CUSTOM_KAFKA_BRIDGE_SERVICE_ANNOTATIONS, value=bar=app, valueFrom=null, additionalProperties={})]
2022-04-06 04:39:39 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:39:39 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 04:39:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:39:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 04:39:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:39:40 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:39:40 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:39:40 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:39:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:39:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 04:40:20 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 04:40:20 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 04:40:30 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 04:40:30 [main] [32mINFO [m [HttpBridgeIsolatedST:434] Deploy Kafka and KafkaBridge before tests
2022-04-06 04:40:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka http-bridge-cluster-name in namespace infra-namespace
2022-04-06 04:40:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: http-bridge-cluster-name will have desired state: Ready
2022-04-06 04:41:41 [main] [32mINFO [m [ResourceManager:444] Kafka: http-bridge-cluster-name is in desired state: Ready
2022-04-06 04:41:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-06 04:41:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-shared-kafka-clients will be ready
2022-04-06 04:41:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-shared-kafka-clients is ready
2022-04-06 04:41:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge http-bridge-cluster-name in namespace infra-namespace
2022-04-06 04:41:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-cluster-name will have desired state: Ready
2022-04-06 04:42:00 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-cluster-name is in desired state: Ready
2022-04-06 04:42:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:42:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testReceiveSimpleMessage-STARTED
2022-04-06 04:42:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:42:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-947211470-946703523 in namespace infra-namespace
2022-04-06 04:42:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-947211470-946703523 will have desired state: Ready
2022-04-06 04:42:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-947211470-946703523 is in desired state: Ready
2022-04-06 04:42:01 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 04:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-923805115 in namespace infra-namespace
2022-04-06 04:42:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-923805115 will be in active state
2022-04-06 04:42:02 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 04:42:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-1117992562 in namespace infra-namespace
2022-04-06 04:42:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-1117992562 will be in active state
2022-04-06 04:42:03 [main] [32mINFO [m [ClientUtils:61] Waiting till producer producer-1117992562 and consumer consumer-923805115 finish
2022-04-06 04:42:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:42:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReceiveSimpleMessage
2022-04-06 04:42:19 [main] [32mINFO [m [ResourceManager:241] Delete of Job consumer-923805115 in namespace infra-namespace
2022-04-06 04:42:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job producer-1117992562 in namespace infra-namespace
2022-04-06 04:42:19 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-947211470-946703523 in namespace infra-namespace
2022-04-06 04:42:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:42:29 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testReceiveSimpleMessage-FINISHED
2022-04-06 04:42:29 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:42:29 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:42:29 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-06 04:42:29 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:42:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge example-bridge in namespace infra-namespace
2022-04-06 04:42:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: example-bridge will have desired state: Ready
2022-04-06 04:42:53 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: example-bridge is in desired state: Ready
2022-04-06 04:42:53 [main] [32mINFO [m [HttpBridgeIsolatedST:351] Adding label to KafkaBridge resource, the CR should be recreated
2022-04-06 04:42:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: example-bridge-bridge will be ready
2022-04-06 04:42:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: example-bridge-bridge is ready
2022-04-06 04:42:53 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment example-bridge-bridge to be ready
2022-04-06 04:43:41 [main] [32mINFO [m [DeploymentUtils:197] Deployment example-bridge-bridge is ready
2022-04-06 04:43:41 [main] [32mINFO [m [HttpBridgeIsolatedST:358] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-06 04:43:41 [main] [32mINFO [m [HttpBridgeIsolatedST:363] Changing deployment strategy to ROLLING_UPDATE
2022-04-06 04:43:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: example-bridge will have desired state: Ready
2022-04-06 04:43:41 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: example-bridge is in desired state: Ready
2022-04-06 04:43:41 [main] [32mINFO [m [HttpBridgeIsolatedST:368] Adding another label to KafkaBridge resource, pods should be rolled
2022-04-06 04:43:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: example-bridge-bridge will be ready
2022-04-06 04:43:41 [main] [32mINFO [m [DeploymentUtils:168] Deployment: example-bridge-bridge is ready
2022-04-06 04:43:41 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment example-bridge-bridge to be ready
2022-04-06 04:44:16 [main] [32mINFO [m [DeploymentUtils:197] Deployment example-bridge-bridge is ready
2022-04-06 04:44:16 [main] [32mINFO [m [HttpBridgeIsolatedST:372] Checking that observed gen. higher (rolling update) and label is changed
2022-04-06 04:44:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:44:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-06 04:44:16 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge example-bridge in namespace infra-namespace
2022-04-06 04:44:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:44:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-06 04:44:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:44:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:44:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeToZero-STARTED
2022-04-06 04:44:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:44:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge scaling-bridge-down in namespace infra-namespace
2022-04-06 04:44:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: scaling-bridge-down will have desired state: Ready
2022-04-06 04:44:44 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: scaling-bridge-down is in desired state: Ready
2022-04-06 04:44:44 [main] [32mINFO [m [HttpBridgeIsolatedST:285] Scaling KafkaBridge to zero replicas
2022-04-06 04:44:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: http-bridge-cluster-name will have desired state: Ready
2022-04-06 04:44:44 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: http-bridge-cluster-name is in desired state: Ready
2022-04-06 04:44:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:44:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleBridgeToZero
2022-04-06 04:44:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge scaling-bridge-down in namespace infra-namespace
2022-04-06 04:45:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:45:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeToZero-FINISHED
2022-04-06 04:45:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:45:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:45:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testDiscoveryAnnotation-STARTED
2022-04-06 04:45:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:45:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:45:07 [main] [32mINFO [m [ResourceManager:346] In context testDiscoveryAnnotation is everything deleted.
2022-04-06 04:45:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:45:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testDiscoveryAnnotation-FINISHED
2022-04-06 04:45:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:45:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:45:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomBridgeLabelsAreProperlySet-STARTED
2022-04-06 04:45:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:45:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge bridge-my-cluster-0196a062 in namespace infra-namespace
2022-04-06 04:45:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: bridge-my-cluster-0196a062 will have desired state: Ready
2022-04-06 04:45:31 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: bridge-my-cluster-0196a062 is in desired state: Ready
2022-04-06 04:45:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:45:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomBridgeLabelsAreProperlySet
2022-04-06 04:45:31 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge bridge-my-cluster-0196a062 in namespace infra-namespace
2022-04-06 04:45:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:45:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomBridgeLabelsAreProperlySet-FINISHED
2022-04-06 04:45:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:45:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:45:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeSubresource-STARTED
2022-04-06 04:45:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:45:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge scaling-bridge-up in namespace infra-namespace
2022-04-06 04:45:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: scaling-bridge-up will have desired state: Ready
2022-04-06 04:45:58 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: scaling-bridge-up is in desired state: Ready
2022-04-06 04:45:58 [main] [32mINFO [m [HttpBridgeIsolatedST:312] -------> Scaling KafkaBridge subresource <-------
2022-04-06 04:45:58 [main] [32mINFO [m [HttpBridgeIsolatedST:313] Scaling subresource replicas to 4
2022-04-06 04:45:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: scaling-bridge-up-bridge will be ready
2022-04-06 04:45:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: scaling-bridge-up-bridge is ready
2022-04-06 04:45:58 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment scaling-bridge-up-bridge to be ready
2022-04-06 04:46:34 [main] [32mINFO [m [DeploymentUtils:197] Deployment scaling-bridge-up-bridge is ready
2022-04-06 04:46:34 [main] [32mINFO [m [HttpBridgeIsolatedST:317] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-06 04:46:34 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:46:34 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleBridgeSubresource
2022-04-06 04:46:34 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge scaling-bridge-up in namespace infra-namespace
2022-04-06 04:46:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:46:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testScaleBridgeSubresource-FINISHED
2022-04-06 04:46:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:46:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:46:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-06 04:46:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:46:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge custom-bridge in namespace infra-namespace
2022-04-06 04:46:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: custom-bridge will have desired state: Ready
2022-04-06 04:47:20 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: custom-bridge is in desired state: Ready
2022-04-06 04:47:20 [main] [32mINFO [m [HttpBridgeIsolatedST:225] Verify values before update
2022-04-06 04:47:20 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix custom-bridge-bridge in pod name
2022-04-06 04:47:21 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container custom-bridge-bridge
2022-04-06 04:47:21 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name custom-bridge-bridge
2022-04-06 04:47:21 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container custom-bridge-bridge
2022-04-06 04:47:21 [main] [32mINFO [m [HttpBridgeIsolatedST:230] Check if actual env variable KAFKA_BRIDGE_PRODUCER_CONFIG has different value than test.value
2022-04-06 04:47:21 [main] [32mINFO [m [HttpBridgeIsolatedST:236] Updating values in Bridge container
2022-04-06 04:47:21 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment custom-bridge-bridge rolling update
2022-04-06 04:48:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: custom-bridge-bridge will be ready
2022-04-06 04:48:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: custom-bridge-bridge is ready
2022-04-06 04:48:11 [main] [32mINFO [m [DeploymentUtils:141] Deployment custom-bridge-bridge rolling update finished
2022-04-06 04:48:11 [main] [32mINFO [m [HttpBridgeIsolatedST:253] Verify values after update
2022-04-06 04:48:11 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix custom-bridge-bridge in pod name
2022-04-06 04:48:11 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container custom-bridge-bridge
2022-04-06 04:48:11 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name custom-bridge-bridge
2022-04-06 04:48:11 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container custom-bridge-bridge
2022-04-06 04:48:11 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name custom-bridge-bridge
2022-04-06 04:48:11 [main] [32mINFO [m [AbstractST:194] Testing configuration for container custom-bridge-bridge
2022-04-06 04:48:11 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name custom-bridge-bridge
2022-04-06 04:48:11 [main] [32mINFO [m [AbstractST:194] Testing configuration for container custom-bridge-bridge
2022-04-06 04:48:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:48:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-06 04:48:11 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge custom-bridge in namespace infra-namespace
2022-04-06 04:48:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:48:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-06 04:48:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:48:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:48:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testSendSimpleMessage-STARTED
2022-04-06 04:48:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:48:21 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 04:48:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-767507235-1187622124 in namespace infra-namespace
2022-04-06 04:48:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-767507235-1187622124 will have desired state: Ready
2022-04-06 04:48:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-767507235-1187622124 is in desired state: Ready
2022-04-06 04:48:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Job producer-193925976 in namespace infra-namespace
2022-04-06 04:48:22 [main] [32mINFO [m [JobUtils:81] Waiting for job: producer-193925976 will be in active state
2022-04-06 04:48:23 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:producer-193925976 to finished
2022-04-06 04:50:11 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 04:50:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job consumer-1228010955 in namespace infra-namespace
2022-04-06 04:50:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: consumer-1228010955 will be in active state
2022-04-06 04:50:12 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:consumer-1228010955 to finished
2022-04-06 04:50:23 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type my-bridge
2022-04-06 04:50:23 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-06 04:50:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:50:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSendSimpleMessage
2022-04-06 04:50:23 [main] [32mINFO [m [ResourceManager:241] Delete of Job producer-193925976 in namespace infra-namespace
2022-04-06 04:50:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-767507235-1187622124 in namespace infra-namespace
2022-04-06 04:50:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job consumer-1228010955 in namespace infra-namespace
2022-04-06 04:50:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:50:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.bridge.HttpBridgeIsolatedST.testSendSimpleMessage-FINISHED
2022-04-06 04:50:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:50:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:50:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HttpBridgeIsolatedST
2022-04-06 04:50:33 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-shared-kafka-clients in namespace infra-namespace
2022-04-06 04:50:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge http-bridge-cluster-name in namespace infra-namespace
2022-04-06 04:50:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka http-bridge-cluster-name in namespace infra-namespace
2022-04-06 04:51:23 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 764.917 s - in io.strimzi.systemtest.bridge.HttpBridgeIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.HelmChartIsolatedST
2022-04-06 04:51:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:51:48 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 04:51:48 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 04:51:48 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 04:51:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:51:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 04:51:48 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:51:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:51:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:51:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:51:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:51:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:51:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:51:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:51:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:51:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:51:58 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:51:58 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:51:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:51:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:51:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:51:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:52:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:52:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:52:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:52:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:52:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:52:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:52:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:52:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:52:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:52:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:52:34 [main] [32mINFO [m [HelmChartIsolatedST:67] Creating resources before the test class
2022-04-06 04:52:34 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 04:52:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:52:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: kube-system
2022-04-06 04:52:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace kube-system apply -f -
2022-04-06 04:52:35 [main] [32mINFO [m [Exec:417] Input: apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
2022-04-06 04:52:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 04:52:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:52:35 [main] [32mINFO [m [HelmClient:44] Installing helm-chart strimzi-systemtests
2022-04-06 04:53:19 [main] [32mINFO [m [Exec:417] Command: helm install strimzi-systemtests --set defaultImageRegistry=quay.io,defaultImageRepository=strimzi,fullReconciliationIntervalMs=30000,kafkaBridge.image.tag=latest,resources.limits.memory=512Mi,kafkaBridge.image.repository=strimzi,featureGates=,image.imagePullPolicy=Always,watchAnyNamespace=false,resources.requests.memory=512Mi,operationTimeoutMs=300000,resources.limits.cpu=1000m,logLevelOverride=DEBUG,defaultImageTag=latest,resources.requests.cpu=200m,kafkaBridge.image.registry=quay.io --timeout 120s --debug /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/helm-charts/helm3/strimzi-kafka-operator --namespace infra-namespace --wait
2022-04-06 04:53:19 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 04:53:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 04:53:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 04:53:19 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:53:19 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.HelmChartIsolatedST.testStrimziComponentsViaHelmChart-STARTED
2022-04-06 04:53:19 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:53:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-660c3897-kafka-clients in namespace infra-namespace
2022-04-06 04:53:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-660c3897-kafka-clients will be ready
2022-04-06 04:53:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-660c3897-kafka-clients is ready
2022-04-06 04:53:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-660c3897 in namespace infra-namespace
2022-04-06 04:53:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-660c3897 will have desired state: Ready
2022-04-06 04:54:53 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-660c3897 is in desired state: Ready
2022-04-06 04:54:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-660c3897-scraper in namespace infra-namespace
2022-04-06 04:54:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-660c3897-scraper will be ready
2022-04-06 04:54:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-660c3897-scraper is ready
2022-04-06 04:54:55 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-660c3897-scraper to be ready
2022-04-06 04:55:05 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-660c3897-scraper is ready
2022-04-06 04:55:05 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-660c3897-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 04:55:05 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-660c3897-allow in namespace infra-namespace
2022-04-06 04:55:05 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 04:55:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1194927588-895849555 in namespace infra-namespace
2022-04-06 04:55:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-660c3897 in namespace infra-namespace
2022-04-06 04:55:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-cluster-660c3897 in namespace infra-namespace
2022-04-06 04:55:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1194927588-895849555 will have desired state: Ready
2022-04-06 04:55:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1194927588-895849555 is in desired state: Ready
2022-04-06 04:55:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-660c3897 will have desired state: Ready
2022-04-06 04:56:17 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-660c3897 is in desired state: Ready
2022-04-06 04:56:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-cluster-660c3897 will have desired state: Ready
2022-04-06 04:56:17 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-cluster-660c3897 is in desired state: Ready
2022-04-06 04:56:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-660c3897 in namespace infra-namespace
2022-04-06 04:56:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-660c3897 will have desired state: Ready
2022-04-06 04:56:18 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-660c3897 is in desired state: Ready
2022-04-06 04:56:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:56:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziComponentsViaHelmChart
2022-04-06 04:56:18 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-660c3897 in namespace infra-namespace
2022-04-06 04:56:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-660c3897 in namespace infra-namespace
2022-04-06 04:56:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-660c3897-scraper in namespace infra-namespace
2022-04-06 04:56:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1194927588-895849555 in namespace infra-namespace
2022-04-06 04:56:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-cluster-660c3897 in namespace infra-namespace
2022-04-06 04:56:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-660c3897 in namespace infra-namespace
2022-04-06 04:56:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-660c3897-allow in namespace infra-namespace
2022-04-06 04:56:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-660c3897-kafka-clients in namespace infra-namespace
2022-04-06 04:57:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:57:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.HelmChartIsolatedST.testStrimziComponentsViaHelmChart-FINISHED
2022-04-06 04:57:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 04:57:18 [main] [32mINFO [m [HelmClient:71] Deleting helm-chart:strimzi-systemtests in namespace:infra-namespace
2022-04-06 04:57:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:57:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for HelmChartIsolatedST
2022-04-06 04:57:18 [main] [32mINFO [m [HelmClient:71] Deleting helm-chart:strimzi-systemtests in namespace:infra-namespace
2022-04-06 04:57:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:57:18 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 04:57:18 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:57:18 [main] [33mWARN [m [KubeClusterResource:151] Namespace infra-namespace is already created, going to delete it
2022-04-06 04:57:29 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 04:57:29 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:57:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:57:30 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 04:57:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:57:30 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:57:30 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:57:30 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:57:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:57:30 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 04:57:51 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 04:57:51 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 04:58:01 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 397.807 s - in io.strimzi.systemtest.specific.HelmChartIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.SpecificIsolatedST
2022-04-06 04:58:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:58:26 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 04:58:26 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 04:58:26 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 04:58:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 04:58:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 04:58:26 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:58:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:58:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:58:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:58:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:58:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:58:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:58:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:58:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:58:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:58:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:58:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:58:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:58:36 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:58:36 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:58:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:58:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:58:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:58:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:58:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:58:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:58:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:58:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:58:46 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:58:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:58:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 04:59:02 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 04:59:02 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 04:59:02 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 04:59:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 04:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 04:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 04:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 04:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 04:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 04:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 04:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 04:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 04:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:59:02 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 04:59:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 04:59:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 04:59:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 04:59:03 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 04:59:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:59:03 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 04:59:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 04:59:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 04:59:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 04:59:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 04:59:03 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 04:59:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 04:59:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 04:59:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:59:03 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 04:59:03 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 04:59:03 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:59:03 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 04:59:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 04:59:03 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 04:59:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 04:59:03 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 04:59:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 04:59:25 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 04:59:35 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 04:59:35 [main] [32mINFO [m [SpecificIsolatedST:508] 0.21.4
2022-04-06 04:59:35 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 04:59:35 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAware-STARTED
2022-04-06 04:59:35 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 04:59:35 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-26c2021b in namespace infra-namespace
2022-04-06 04:59:35 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-26c2021b will have desired state: Ready
2022-04-06 05:00:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-26c2021b is in desired state: Ready
2022-04-06 05:00:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-26c2021b-kafka-0 -- /bin/bash -c cat /opt/kafka/init/rack.id
2022-04-06 05:00:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:00:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-26c2021b-kafka-0 -- /bin/bash -c cat /tmp/strimzi.properties | grep broker.rack
2022-04-06 05:00:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:00:49 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:00:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-producer in namespace infra-namespace
2022-04-06 05:00:49 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-producer will be in active state
2022-04-06 05:00:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Job hello-world-consumer in namespace infra-namespace
2022-04-06 05:00:50 [main] [32mINFO [m [JobUtils:81] Waiting for job: hello-world-consumer will be in active state
2022-04-06 05:00:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:00:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRackAware
2022-04-06 05:00:50 [main] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-producer in namespace infra-namespace
2022-04-06 05:00:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job hello-world-consumer in namespace infra-namespace
2022-04-06 05:00:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-26c2021b in namespace infra-namespace
2022-04-06 05:01:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:01:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAware-FINISHED
2022-04-06 05:01:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:01:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:01:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAwareConnectWrongDeployment-STARTED
2022-04-06 05:01:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:01:00 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:01:00 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:01:00 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:01:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:01:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:01:00 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:01:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:01:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:01:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:01:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 05:01:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:01:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:01:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:10 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:01:10 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:01:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:01:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:01:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:01:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:01:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:01:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:01:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:01:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:20 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:01:36 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@1422440a, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=30000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 05:01:36 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:01:36 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:01:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:01:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:01:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 05:01:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:01:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:01:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:01:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:01:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:01:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:01:37 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:01:37 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:01:37 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:01:37 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:01:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:01:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:02:01 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:02:01 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:02:11 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:02:11 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-06 05:02:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:02:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:02:21 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-06 05:02:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f90c1fa8 in namespace infra-namespace
2022-04-06 05:02:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f90c1fa8 will have desired state: Ready
2022-04-06 05:03:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f90c1fa8 is in desired state: Ready
2022-04-06 05:03:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f90c1fa8-kafka-clients in namespace infra-namespace
2022-04-06 05:03:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f90c1fa8-kafka-clients will be ready
2022-04-06 05:03:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f90c1fa8-kafka-clients is ready
2022-04-06 05:03:45 [main] [32mINFO [m [SpecificIsolatedST:196] Deploy KafkaConnect with wrong rack-aware topology key: wrong-key
2022-04-06 05:03:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f90c1fa8-scraper in namespace infra-namespace
2022-04-06 05:03:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f90c1fa8-scraper will be ready
2022-04-06 05:03:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f90c1fa8-scraper is ready
2022-04-06 05:03:47 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-f90c1fa8-scraper to be ready
2022-04-06 05:03:57 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-f90c1fa8-scraper is ready
2022-04-06 05:03:57 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-f90c1fa8-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 05:03:57 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-f90c1fa8-allow in namespace infra-namespace
2022-04-06 05:03:57 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 05:03:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-f90c1fa8 in namespace infra-namespace
2022-04-06 05:03:58 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-f90c1fa8-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 05:03:58 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-f90c1fa8-allow in namespace infra-namespace
2022-04-06 05:03:58 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 05:03:58 [main] [32mINFO [m [PodUtils:277] Wait for at least one pod with prefix: my-cluster-f90c1fa8-connect will be in pending phase
2022-04-06 05:03:59 [main] [32mINFO [m [SpecificIsolatedST:227] Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect
2022-04-06 05:04:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-f90c1fa8 will have desired state: Ready
2022-04-06 05:06:23 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-f90c1fa8 is in desired state: Ready
2022-04-06 05:06:23 [main] [32mINFO [m [SpecificIsolatedST:238] KafkaConnect is ready with changed rack key: 'rack-key'.
2022-04-06 05:06:23 [main] [32mINFO [m [SpecificIsolatedST:239] Verify KafkaConnect rack key update
2022-04-06 05:06:23 [main] [32mINFO [m [KafkaConnectUtils:156] Send and receive messages through KafkaConnect
2022-04-06 05:06:23 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 05:06:23 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-f90c1fa8-connect-8579747ddd-zf4t9 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 05:06:23 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:06:23 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 05:06:24 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-f90c1fa8-scraper-798d884f44-9qt6g -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-609391865-1811347379", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-f90c1fa8-connect-api.infra-namespace.svc:8083/connectors
2022-04-06 05:06:24 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:06:24 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 05:06:24 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@4d49b766, messages=[], arguments=[--bootstrap-server, my-cluster-f90c1fa8-kafka-bootstrap.infra-namespace.svc:9092, --max-messages, 100, --topic, my-topic-609391865-1811347379], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-f90c1fa8-kafka-clients-687b4c9f57-5qhds', podNamespace='infra-namespace', bootstrapServer='my-cluster-f90c1fa8-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-609391865-1811347379', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6de610b8}
2022-04-06 05:06:24 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-f90c1fa8-kafka-bootstrap.infra-namespace.svc:9092:my-topic-609391865-1811347379 from pod my-cluster-f90c1fa8-kafka-clients-687b4c9f57-5qhds
2022-04-06 05:06:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f90c1fa8-kafka-clients-687b4c9f57-5qhds -n infra-namespace -- /opt/kafka/producer.sh --bootstrap-server my-cluster-f90c1fa8-kafka-bootstrap.infra-namespace.svc:9092 --max-messages 100 --topic my-topic-609391865-1811347379
2022-04-06 05:06:27 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 05:06:27 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 05:06:27 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3a2aef79, messages=[], arguments=[--group-id, my-consumer-group-441548846, --bootstrap-server, my-cluster-f90c1fa8-kafka-bootstrap.infra-namespace.svc:9092, --group-instance-id, instance1459110110, --max-messages, 100, --topic, my-topic-609391865-1811347379], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f90c1fa8-kafka-clients-687b4c9f57-5qhds', podNamespace='infra-namespace', bootstrapServer='my-cluster-f90c1fa8-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-609391865-1811347379', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-441548846', consumerInstanceId='instance1459110110', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6b6db851}
2022-04-06 05:06:27 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-f90c1fa8-kafka-bootstrap.infra-namespace.svc:9092#my-topic-609391865-1811347379 from pod my-cluster-f90c1fa8-kafka-clients-687b4c9f57-5qhds
2022-04-06 05:06:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f90c1fa8-kafka-clients-687b4c9f57-5qhds -n infra-namespace -- /opt/kafka/consumer.sh --group-id my-consumer-group-441548846 --bootstrap-server my-cluster-f90c1fa8-kafka-bootstrap.infra-namespace.svc:9092 --group-instance-id instance1459110110 --max-messages 100 --topic my-topic-609391865-1811347379
2022-04-06 05:06:33 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 05:06:33 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 05:06:33 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-f90c1fa8-connect-8579747ddd-zf4t9
2022-04-06 05:06:33 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-f90c1fa8-connect-8579747ddd-zf4t9
2022-04-06 05:06:33 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:06:33 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:06:33 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:06:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:06:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:06:33 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:06:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:06:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:06:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:06:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:06:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:06:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:06:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:06:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:06:34 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:06:44 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:06:44 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:06:44 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:06:44 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:06:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:06:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:06:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:06:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:06:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:06:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:06:54 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:06:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:06:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:07:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:07:47 [main] [32mINFO [m [SetupClusterOperator:223] Cluster operator installation configuration:
SetupClusterOperator{cluster=io.strimzi.test.k8s.KubeClusterResource@1422440a, extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566, clusterOperatorName='strimzi-cluster-operator', namespaceInstallTo='infra-namespace', namespaceToWatch='infra-namespace', bindingsNamespaces=[infra-namespace], operationTimeout=300000, reconciliationInterval=30000, extraEnvVars=[], extraLabels={}, clusterOperatorRBACType=CLUSTER, testClassName='null', testMethodName='null'}
2022-04-06 05:07:47 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:07:47 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:07:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:07:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:07:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:07:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:07:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:07:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:07:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:07:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:07:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:07:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:07:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:07:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:07:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:07:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:07:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:07:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:07:48 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:07:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:07:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 05:07:48 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:07:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:07:48 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:07:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:07:48 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:07:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:07:48 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:07:48 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:07:48 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:07:48 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:07:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:07:48 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:08:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:08:11 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:08:21 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:08:21 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment strimzi-cluster-operator rolling update
2022-04-06 05:08:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:08:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:08:31 [main] [32mINFO [m [DeploymentUtils:141] Deployment strimzi-cluster-operator rolling update finished
2022-04-06 05:08:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:08:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRackAwareConnectWrongDeployment
2022-04-06 05:08:31 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-f90c1fa8-allow in namespace infra-namespace
2022-04-06 05:08:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-f90c1fa8-allow in namespace infra-namespace
2022-04-06 05:08:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f90c1fa8-kafka-clients in namespace infra-namespace
2022-04-06 05:08:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f90c1fa8 in namespace infra-namespace
2022-04-06 05:08:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f90c1fa8-scraper in namespace infra-namespace
2022-04-06 05:08:31 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-f90c1fa8 in namespace infra-namespace
2022-04-06 05:08:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:08:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testRackAwareConnectWrongDeployment-FINISHED
2022-04-06 05:08:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:08:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:08:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.specific.SpecificIsolatedST.testDeployUnsupportedKafka-STARTED
2022-04-06 05:08:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:08:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-13d70a5d in namespace infra-namespace
2022-04-06 05:08:31 [main] [32mINFO [m [SpecificIsolatedST:414] Kafka with version 6.6.6 deployed.
2022-04-06 05:08:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-13d70a5d will have desired state: NotReady
2022-04-06 05:08:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-13d70a5d is in desired state: NotReady
2022-04-06 05:08:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:08:35 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployUnsupportedKafka
2022-04-06 05:08:35 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-13d70a5d in namespace infra-namespace
2022-04-06 05:08:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:08:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.specific.SpecificIsolatedST.testDeployUnsupportedKafka-FINISHED
2022-04-06 05:08:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:08:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:08:35 [main] [32mINFO [m [ResourceManager:346] In context SpecificIsolatedST is everything deleted.
2022-04-06 05:08:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 633.983 s - in io.strimzi.systemtest.specific.SpecificIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.specific.DrainCleanerIsolatedST
2022-04-06 05:08:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:09:00 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:09:00 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:09:00 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:09:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:09:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:09:00 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:09:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:09:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:09:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:09:11 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:09:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:09:11 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:09:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:09:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:09:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:09:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:09:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:09:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:09:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:09:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:09:26 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=strimzi-drain-cleaner
namespaceToWatch=strimzi-drain-cleaner
bindingsNamespaces=[strimzi-drain-cleaner]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 05:09:26 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:09:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: strimzi-drain-cleaner
2022-04-06 05:09:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: strimzi-drain-cleaner
2022-04-06 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:26 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:27 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:09:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:09:27 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: strimzi-drain-cleaner
2022-04-06 05:09:27 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace strimzi-drain-cleaner
2022-04-06 05:09:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:09:27 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-06 05:09:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:09:27 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-06 05:09:27 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:09:27 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace strimzi-drain-cleaner
2022-04-06 05:09:27 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:09:27 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace strimzi-drain-cleaner
2022-04-06 05:09:27 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace strimzi-drain-cleaner
2022-04-06 05:09:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:09:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:09:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:09:52 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:10:02 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:10:02 [main] [32mINFO [m [RequiredMinKubeApiVersionCondition:30] testDrainCleanerWithComponents is @RequiredMinKubeApiVersion with version 1.17, but the running on cluster with 1.16: Ignoring testDrainCleanerWithComponents
2022-04-06 05:10:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:10:02 [main] [32mINFO [m [ResourceManager:346] In context DrainCleanerIsolatedST is everything deleted.
2022-04-06 05:10:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 2, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 87.201 s - in io.strimzi.systemtest.specific.DrainCleanerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
2022-04-06 05:10:02 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:10:27 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:10:27 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:10:27 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:10:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:10:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:10:27 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:10:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:10:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:10:27 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:10:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:10:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace strimzi-drain-cleaner
2022-04-06 05:10:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:10:28 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:10:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:10:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:10:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:10:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace strimzi-drain-cleaner
2022-04-06 05:10:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:10:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:10:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:10:58 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace,second-namespace-test
bindingsNamespaces=[infra-namespace, second-namespace-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 05:10:58 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:10:58 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-namespace-test
2022-04-06 05:10:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-namespace-test
2022-04-06 05:10:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:10:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-06 05:10:59 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-06 05:10:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:11:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:11:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:11:26 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:11:36 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:11:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:11:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster in namespace second-namespace-test
2022-04-06 05:11:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster will have desired state: Ready
2022-04-06 05:12:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster is in desired state: Ready
2022-04-06 05:12:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:12:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:12:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-STARTED
2022-04-06 05:12:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:12:57 [main] [32mINFO [m [MultipleNamespaceIsolatedST:59] Deploying Kafka in different namespace than CO when CO watches multiple namespaces
2022-04-06 05:12:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:12:57 [main] [32mINFO [m [AbstractNamespaceST:46] Check if Kafka Cluster my-cluster in namespace second-namespace-test
2022-04-06 05:12:57 [main] [32mINFO [m [AbstractNamespaceST:51] Kafka condition status: True
2022-04-06 05:12:57 [main] [32mINFO [m [AbstractNamespaceST:52] Kafka condition type: Ready
2022-04-06 05:12:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:12:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:12:57 [main] [32mINFO [m [ResourceManager:346] In context testKafkaInDifferentNsThanClusterOperator is everything deleted.
2022-04-06 05:12:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:12:57 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-FINISHED
2022-04-06 05:12:57 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:12:57 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:12:57 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-STARTED
2022-04-06 05:12:57 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:12:57 [main] [32mINFO [m [MultipleNamespaceIsolatedST:45] Deploying TO to watch a different namespace that it is deployed in
2022-04-06 05:12:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:13:00 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace second-namespace-test exec my-cluster-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-06 05:13:00 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:13:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1013205271-825274543 in namespace infra-namespace
2022-04-06 05:13:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1013205271-825274543 will have desired state: Ready
2022-04-06 05:13:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1013205271-825274543 is in desired state: Ready
2022-04-06 05:13:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:13:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicOperatorWatchingOtherNamespace
2022-04-06 05:13:01 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1013205271-825274543 in namespace infra-namespace
2022-04-06 05:13:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:13:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-FINISHED
2022-04-06 05:13:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:13:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:13:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-STARTED
2022-04-06 05:13:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:13:11 [main] [32mINFO [m [MultipleNamespaceIsolatedST:69] Deploying KafkaMirrorMaker in different namespace than CO when CO watches multiple namespaces
2022-04-06 05:13:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:13:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-target in namespace second-namespace-test
2022-04-06 05:13:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-target will have desired state: Ready
2022-04-06 05:14:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-target is in desired state: Ready
2022-04-06 05:14:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-06 05:14:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-06 05:15:27 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-06 05:15:27 [main] [32mINFO [m [AbstractNamespaceST:71] Waiting for creation my-cluster-mirror-maker in namespace second-namespace-test
2022-04-06 05:15:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-06 05:15:27 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-06 05:15:27 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:15:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:15:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployMirrorMakerAcrossMultipleNamespace
2022-04-06 05:15:27 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-06 05:15:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-target in namespace second-namespace-test
2022-04-06 05:15:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:15:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-FINISHED
2022-04-06 05:15:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:15:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:15:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for MultipleNamespaceIsolatedST
2022-04-06 05:15:37 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster in namespace second-namespace-test
2022-04-06 05:15:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 344.445 s - in io.strimzi.systemtest.watcher.MultipleNamespaceIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
2022-04-06 05:15:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:16:12 [main] [32mINFO [m [AllNamespaceIsolatedST:190] Creating resources before the test class
2022-04-06 05:16:12 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:16:12 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:16:12 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:16:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:16:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:16:12 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:16:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:16:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:16:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-06 05:16:12 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:16:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-06 05:16:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:16:12 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:16:12 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:16:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:16:22 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:22 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:16:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:16:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:16:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:16:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:16:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:16:22 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:16:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:16:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:16:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:43 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:16:48 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace, second-namespace-test, third-namespace-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 05:16:48 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:16:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:16:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-namespace-test
2022-04-06 05:16:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: third-namespace-test
2022-04-06 05:16:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:16:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:16:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:16:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:16:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:16:48 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-namespace-test
2022-04-06 05:16:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: third-namespace-test
2022-04-06 05:16:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-06 05:16:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-06 05:16:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace third-namespace-test
2022-04-06 05:16:49 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace third-namespace-test
2022-04-06 05:16:49 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:16:49 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 05:16:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:16:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:17:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:17:28 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:17:38 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:17:38 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-06 05:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster in namespace third-namespace-test
2022-04-06 05:17:38 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster will have desired state: Ready
2022-04-06 05:18:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster is in desired state: Ready
2022-04-06 05:18:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:18:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-second in namespace second-namespace-test
2022-04-06 05:18:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-second will have desired state: Ready
2022-04-06 05:19:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-second is in desired state: Ready
2022-04-06 05:19:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:19:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:19:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-STARTED
2022-04-06 05:19:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:19:58 [main] [32mINFO [m [AllNamespaceIsolatedST:82] Deploying Kafka cluster in different namespace than CO when CO watches all namespaces
2022-04-06 05:19:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:19:58 [main] [32mINFO [m [AbstractNamespaceST:46] Check if Kafka Cluster my-cluster-second in namespace second-namespace-test
2022-04-06 05:19:58 [main] [32mINFO [m [AbstractNamespaceST:51] Kafka condition status: True
2022-04-06 05:19:58 [main] [32mINFO [m [AbstractNamespaceST:52] Kafka condition type: Ready
2022-04-06 05:19:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:19:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:19:58 [main] [32mINFO [m [ResourceManager:346] In context testKafkaInDifferentNsThanClusterOperator is everything deleted.
2022-04-06 05:19:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:19:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testKafkaInDifferentNsThanClusterOperator-FINISHED
2022-04-06 05:19:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:19:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:19:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-STARTED
2022-04-06 05:19:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:19:58 [main] [32mINFO [m [AllNamespaceIsolatedST:66] Deploying TO to watch a different namespace that it is deployed in
2022-04-06 05:19:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-06 05:20:02 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace third-namespace-test exec my-cluster-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-06 05:20:02 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:20:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-842719026-226462934 in namespace second-namespace-test
2022-04-06 05:20:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-842719026-226462934 will have desired state: Ready
2022-04-06 05:20:03 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-842719026-226462934 is in desired state: Ready
2022-04-06 05:20:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:20:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:20:03 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTopicOperatorWatchingOtherNamespace
2022-04-06 05:20:03 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-842719026-226462934 in namespace second-namespace-test
2022-04-06 05:20:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:20:13 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testTopicOperatorWatchingOtherNamespace-FINISHED
2022-04-06 05:20:13 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:20:13 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:20:13 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUOWatchingOtherNamespace-STARTED
2022-04-06 05:20:13 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:20:13 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:20:13 [main] [32mINFO [m [AllNamespaceIsolatedST:121] Creating user in other namespace than CO and Kafka cluster with UO
2022-04-06 05:20:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-885117958-1248349747 in namespace second-namespace-test
2022-04-06 05:20:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-885117958-1248349747 will have desired state: Ready
2022-04-06 05:20:14 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-885117958-1248349747 is in desired state: Ready
2022-04-06 05:20:14 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:20:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:20:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUOWatchingOtherNamespace
2022-04-06 05:20:14 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-885117958-1248349747 in namespace second-namespace-test
2022-04-06 05:20:24 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:20:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUOWatchingOtherNamespace-FINISHED
2022-04-06 05:20:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:20:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:20:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUserInDifferentNamespace-STARTED
2022-04-06 05:20:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:20:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:20:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-885117958-1248349747 in namespace second-namespace-test
2022-04-06 05:20:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-885117958-1248349747 will have desired state: Ready
2022-04-06 05:20:25 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-885117958-1248349747 is in desired state: Ready
2022-04-06 05:20:25 [main] [32mINFO [m [AllNamespaceIsolatedST:137] KafkaUser condition status: True
2022-04-06 05:20:25 [main] [32mINFO [m [AllNamespaceIsolatedST:138] KafkaUser condition type: Ready
2022-04-06 05:20:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: third-namespace-test
2022-04-06 05:20:25 [main] [32mINFO [m [AllNamespaceIsolatedST:148] Copying secret Secret(apiVersion=v1, data={ca.crt=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, user.crt=LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVJVENDQWdtZ0F3SUJBZ0lVWmwxZnZobll4amF0TjNGLzVCUExxTk5QVnk4d0RRWUpLb1pJaHZjTkFRRU4KQlFBd0xURVRNQkVHQTFVRUNnd0thVzh1YzNSeWFXMTZhVEVXTUJRR0ExVUVBd3dOWTJ4cFpXNTBjeTFqWVNCMgpNREFlRncweU1qQTBNRFl3TlRJd01qUmFGdzB5TXpBME1EWXdOVEl3TWpSYU1DY3hKVEFqQmdOVkJBTU1IRzE1CkxYVnpaWEl0T0RnMU1URTNPVFU0TFRFeU5EZ3pORGszTkRjd2dnRWlNQTBHQ1NxR1NJYjNEUUVCQVFVQUE0SUIKRHdBd2dnRUtBb0lCQVFDZ2FOU3BHQ0xhWVA3dnJYdmYwS3BxYUxhN2xvOW9JUUlIbHI4bGdpNHl3WFFzc0FMbApYTDQ5RDgybGMxZ1d0RWI2V3FEdk1KQTJJWTdwR1RIYmorblgveUtINGpHVm03U25wOWN4UzFhUVVSNVZxeG5vCllmaWRTMU5jcStjWGtuWFduSnVBRmUyamg2RTBqMW04UUZLc1V6aUxDMXlLaTRyUHY4MWRpZ1BVbE1KSFlGY0EKYlJRdGVIOEpCMUVGUWRxN3pIY1Fwc25Ib0V3SDc5UStHank3K1JoZEhRdU8wVTFPa3dJbWN2Z0hkMS9DY1h0NAp5NjNKd29sdERTQ0l6dk16ZFArV2w5cndVek1ieU1DQmRwQ2Vib3JiN1dBMXg1Sm1nZDFVUmE2RTBkNEdwOGRJCm5BVjREd0VjK2pKTG1QR0RVNTBWak9JazhTNGtFSFNyWmRSTkFnTUJBQUdqUHpBOU1CMEdBMVVkRGdRV0JCUWIKOEdYTXNFaThONGJJY3F5cjdhazA1RmxuN1RBTUJnTlZIUk1CQWY4RUFqQUFNQTRHQTFVZER3RUIvd1FFQXdJRgpvREFOQmdrcWhraUc5dzBCQVEwRkFBT0NBZ0VBUmJkZ2JJK2kySnF2bzFhVFhUeXZJZTlMWXZhNWFDRUN2cGVmCmZETjZXVkVYbThGaDFMMTFPUjFzVllLck4wdnBGdkJwZCt2Q3ZrVUJRaUhlZ2ZDNnFUOFVHODVxOGdWWHp2bnEKUndyblpXSGwrM3hIV3hQTStsM1Z6T2FHcXRzVm9OVmFKclo5TC90KzNIOEI0WDA5QXRtSytHbFcwY1FhdE1BZQpDUWNKUEZyWkIrZDZCTVJGT0dGSWRhSDlaMnBNdW5CcnBTNDRtWjVCMEVjVnR4V0MrK0NEaTRFa1E5MlZrNEhhCm5NTGxXVUhxWlFsT1lUT2VoL3dLajhGNVkyT0lLNWRXN0x5YjZ5Q3l2eTFtUTRXQk5jMDQ2MU9qQW9la0ZlU3QKcmFGUzZZVEkvSzZBSExjZkZxS2VmSTJyOGI3ZVYrbFlpU0RvbXArK0pQVVFNK1VoWklLVUo5R0JMSUJlVmV0agpybDBRQzRJaVRWaURIWUNNOUVEcXBqbUlzeGcySENTWitoVFhvUzRYUVVoNlJhd2FPbmhDMWNOclIxZzFHc3plCmE3b25oTjM0eHZ3aDROSDVtMGJYRXNzdGFKTlZXV1VaTCtCczl5YWxTMXpRU3V3RWdUUTVjNVZRUERqUXp2cTUKTnd3bGViTmtBdUlaeTBLUlJ2b1Bhb1NMUnE0NnNpV2VtdmtiQjFRbE50N0JVQ1Y2MVlWNG1tTU0xTkJkdmFhSAp6aU1CaWFRR1ZtVkZsV3Btd2wwV3lDbGJEdjM2cFpPbSsxSmcrWCtmY0dEdGJ4dm9UendUVWg0ZVhMQlB6MDRoCms4NGhRMGNVa0hRL0lHaXJHcEJONVI4aGgxQWRLOTh2Y1NTZFg3MVlEWVZtdkVZRzEwRC9YTDZYQ3hOL3dDMHAKaTRHSFNJbz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=, user.key=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, user.p12=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, user.password=a0ZHMGlQS0dRdEVP}, immutable=null, kind=Secret, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2022-04-06T05:20:24Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={app.kubernetes.io/instance=my-user-885117958-1248349747, app.kubernetes.io/managed-by=strimzi-user-operator, app.kubernetes.io/name=strimzi-user-operator, app.kubernetes.io/part-of=strimzi-my-user-885117958-1248349747, strimzi.io/cluster=my-cluster, strimzi.io/kind=KafkaUser, test.case=testUserInDifferentNamespace}, managedFields=[], name=my-user-885117958-1248349747, namespace=second-namespace-test, ownerReferences=[OwnerReference(apiVersion=kafka.strimzi.io/v1beta2, blockOwnerDeletion=false, controller=false, kind=KafkaUser, name=my-user-885117958-1248349747, uid=582a9ad9-f214-499a-9af7-0169b8e0a43a, additionalProperties={})], resourceVersion=819510, selfLink=/api/v1/namespaces/second-namespace-test/secrets/my-user-885117958-1248349747, uid=ed644d99-adc2-478c-8c01-8e48ae2e473b, additionalProperties={}), stringData=null, type=Opaque, additionalProperties={}) from namespace second-namespace-test to namespace third-namespace-test
2022-04-06 05:20:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-kafka-clients in namespace third-namespace-test
2022-04-06 05:20:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-kafka-clients will be ready
2022-04-06 05:20:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-kafka-clients is ready
2022-04-06 05:20:27 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 05:20:27 [main] [32mINFO [m [AllNamespaceIsolatedST:168] Checking produced and consumed messages to pod:my-cluster-kafka-clients-5b79cdb665-wwbzr
2022-04-06 05:20:27 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6b5fa553, messages=[], arguments=[USER=my_user_885117958_1248349747, --bootstrap-server, my-cluster-kafka-bootstrap.third-namespace-test.svc:9093, --max-messages, 100, --topic, my-topic-609391865-1811347379], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-kafka-clients-5b79cdb665-wwbzr', podNamespace='third-namespace-test', bootstrapServer='my-cluster-kafka-bootstrap.third-namespace-test.svc:9093', topicName='my-topic-609391865-1811347379', maxMessages=100, kafkaUsername='my-user-885117958-1248349747', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@35618671}
2022-04-06 05:20:27 [main] [32mINFO [m [InternalKafkaClient:124] Producing 100 messages to my-cluster-kafka-bootstrap.third-namespace-test.svc:9093:my-topic-609391865-1811347379 from pod my-cluster-kafka-clients-5b79cdb665-wwbzr
2022-04-06 05:20:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-kafka-clients-5b79cdb665-wwbzr -n third-namespace-test -- /opt/kafka/producer.sh USER=my_user_885117958_1248349747 --bootstrap-server my-cluster-kafka-bootstrap.third-namespace-test.svc:9093 --max-messages 100 --topic my-topic-609391865-1811347379
2022-04-06 05:20:32 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 05:20:32 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 100 messages
2022-04-06 05:20:32 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1baf64b4, messages=[], arguments=[USER=my_user_885117958_1248349747, --group-id, my-consumer-group-360792386, --bootstrap-server, my-cluster-kafka-bootstrap.third-namespace-test.svc:9093, --group-instance-id, instance369531618, --max-messages, 100, --topic, my-topic-609391865-1811347379], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-kafka-clients-5b79cdb665-wwbzr', podNamespace='third-namespace-test', bootstrapServer='my-cluster-kafka-bootstrap.third-namespace-test.svc:9093', topicName='my-topic-609391865-1811347379', maxMessages=100, kafkaUsername='my-user-885117958-1248349747', consumerGroupName='my-consumer-group-360792386', consumerInstanceId='instance369531618', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@228db7de}
2022-04-06 05:20:32 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 100 messages from my-cluster-kafka-bootstrap.third-namespace-test.svc:9093:my-topic-609391865-1811347379 from pod my-cluster-kafka-clients-5b79cdb665-wwbzr
2022-04-06 05:20:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-kafka-clients-5b79cdb665-wwbzr -n third-namespace-test -- /opt/kafka/consumer.sh USER=my_user_885117958_1248349747 --group-id my-consumer-group-360792386 --bootstrap-server my-cluster-kafka-bootstrap.third-namespace-test.svc:9093 --group-instance-id instance369531618 --max-messages 100 --topic my-topic-609391865-1811347379
2022-04-06 05:20:39 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 05:20:39 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 100 messages
2022-04-06 05:20:39 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:20:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:20:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUserInDifferentNamespace
2022-04-06 05:20:39 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-kafka-clients in namespace third-namespace-test
2022-04-06 05:20:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-885117958-1248349747 in namespace second-namespace-test
2022-04-06 05:21:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:21:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testUserInDifferentNamespace-FINISHED
2022-04-06 05:21:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:21:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:21:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-STARTED
2022-04-06 05:21:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:21:20 [main] [32mINFO [m [AllNamespaceIsolatedST:92] Deploying KafkaMirrorMaker in different namespace than CO when CO watches all namespaces
2022-04-06 05:21:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:21:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-target in namespace second-namespace-test
2022-04-06 05:21:20 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-target will have desired state: Ready
2022-04-06 05:22:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-target is in desired state: Ready
2022-04-06 05:22:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-06 05:22:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-06 05:23:37 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-06 05:23:37 [main] [32mINFO [m [AbstractNamespaceST:71] Waiting for creation my-cluster-mirror-maker in namespace second-namespace-test
2022-04-06 05:23:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster will have desired state: Ready
2022-04-06 05:23:37 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster is in desired state: Ready
2022-04-06 05:23:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:23:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:23:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployMirrorMakerAcrossMultipleNamespace
2022-04-06 05:23:37 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster in namespace second-namespace-test
2022-04-06 05:23:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-target in namespace second-namespace-test
2022-04-06 05:23:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:23:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployMirrorMakerAcrossMultipleNamespace-FINISHED
2022-04-06 05:23:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:23:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:23:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO-STARTED
2022-04-06 05:23:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:23:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-namespace-test
2022-04-06 05:23:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d2450e8e-kafka-clients in namespace second-namespace-test
2022-04-06 05:23:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d2450e8e-kafka-clients will be ready
2022-04-06 05:23:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d2450e8e-kafka-clients is ready
2022-04-06 05:23:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d2450e8ekafka-connect-scraper in namespace second-namespace-test
2022-04-06 05:23:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d2450e8ekafka-connect-scraper will be ready
2022-04-06 05:23:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d2450e8ekafka-connect-scraper is ready
2022-04-06 05:23:50 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-d2450e8ekafka-connect-scraper to be ready
2022-04-06 05:24:00 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-d2450e8ekafka-connect-scraper is ready
2022-04-06 05:24:00 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-d2450e8ekafka-connect-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 05:24:00 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-d2450e8ekafka-connect-allow in namespace second-namespace-test
2022-04-06 05:24:00 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 05:24:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-d2450e8ekafka-connect in namespace second-namespace-test
2022-04-06 05:24:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-d2450e8ekafka-connect will have desired state: Ready
2022-04-06 05:25:06 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-d2450e8ekafka-connect is in desired state: Ready
2022-04-06 05:25:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-d2450e8ekafka-connect in namespace second-namespace-test
2022-04-06 05:25:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-d2450e8ekafka-connect will have desired state: Ready
2022-04-06 05:25:07 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-d2450e8ekafka-connect is in desired state: Ready
2022-04-06 05:25:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-d2450e8ekafka-connect will have desired state: Ready
2022-04-06 05:25:07 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-d2450e8ekafka-connect is in desired state: Ready
2022-04-06 05:25:07 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 05:25:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace second-namespace-test exec my-cluster-d2450e8ekafka-connect-connect-8666f54b7f-wsf22 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 05:25:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:25:08 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 05:25:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-d2450e8ekafka-connect-kafka-clients in namespace second-namespace-test
2022-04-06 05:25:08 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-d2450e8ekafka-connect-kafka-clients will be ready
2022-04-06 05:25:10 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-d2450e8ekafka-connect-kafka-clients is ready
2022-04-06 05:25:10 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 05:25:10 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1ff52c85, messages=[], arguments=[--bootstrap-server, my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092, --max-messages, 100, --topic, my-topic-609391865-1811347379], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-d2450e8e-kafka-clients-7bd8f94b6-2nsnw', podNamespace='second-namespace-test', bootstrapServer='my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092', topicName='my-topic-609391865-1811347379', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3fa1e448}
2022-04-06 05:25:10 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092:my-topic-609391865-1811347379 from pod my-cluster-d2450e8e-kafka-clients-7bd8f94b6-2nsnw
2022-04-06 05:25:10 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-d2450e8e-kafka-clients-7bd8f94b6-2nsnw -n second-namespace-test -- /opt/kafka/producer.sh --bootstrap-server my-cluster-second-kafka-bootstrap.second-namespace-test.svc:9092 --max-messages 100 --topic my-topic-609391865-1811347379
2022-04-06 05:25:12 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 05:25:12 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 05:25:12 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-d2450e8ekafka-connect-connect-8666f54b7f-wsf22
2022-04-06 05:25:14 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-d2450e8ekafka-connect-connect-8666f54b7f-wsf22
2022-04-06 05:25:14 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:25:14 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:25:14 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO
2022-04-06 05:25:14 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-d2450e8ekafka-connect in namespace second-namespace-test
2022-04-06 05:25:14 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d2450e8ekafka-connect-kafka-clients in namespace second-namespace-test
2022-04-06 05:25:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d2450e8ekafka-connect-scraper in namespace second-namespace-test
2022-04-06 05:25:14 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-d2450e8e-kafka-clients in namespace second-namespace-test
2022-04-06 05:25:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-d2450e8ekafka-connect-allow in namespace second-namespace-test
2022-04-06 05:25:54 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-d2450e8ekafka-connect in namespace second-namespace-test
2022-04-06 05:26:04 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:26:04 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.watcher.AllNamespaceIsolatedST.testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO-FINISHED
2022-04-06 05:26:04 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:26:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:26:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for AllNamespaceIsolatedST
2022-04-06 05:26:04 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-second in namespace second-namespace-test
2022-04-06 05:26:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster in namespace third-namespace-test
2022-04-06 05:26:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 626.851 s - in io.strimzi.systemtest.watcher.AllNamespaceIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-06 05:26:14 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:26:39 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 05:26:39 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 05:26:39 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 05:26:39 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:26:39 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 05:26:39 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace third-namespace-test
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace third-namespace-test
2022-04-06 05:26:39 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 05:26:39 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:26:39 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-namespace-test
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:26:39 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-namespace-test
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:26:39 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:49 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:26:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:27:09 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:27:20 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 05:27:20 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 05:27:20 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 05:27:20 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:20 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 05:27:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:27:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 05:27:21 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:27:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 05:27:21 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 05:27:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 05:27:21 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 05:27:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 05:27:21 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 05:27:21 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:27:21 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 05:27:21 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 05:27:21 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:27:21 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 05:27:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 05:27:21 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 05:27:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 05:27:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 05:27:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 05:27:48 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 05:27:58 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 05:27:58 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 05:27:58 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-06 05:27:58 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 05:29:33 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 05:29:33 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 05:29:33 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-06 05:29:33 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-06 05:29:33 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-06 05:29:33 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-06 05:29:33 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-06 05:29:33 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-06 05:29:33 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-06 05:29:33 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-06 05:29:33 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-06 05:29:33 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-06 05:29:33 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-06 05:29:33 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-06 05:29:33 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-06 05:29:33 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-06 05:29:33 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-06 05:29:33 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-06 05:29:33 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-06 05:29:33 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-06 05:29:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 05:29:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-plain-name will have desired state: Ready
2022-04-06 05:30:51 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-plain-name is in desired state: Ready
2022-04-06 05:30:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:30:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainProducerConsumer-STARTED
2022-04-06 05:30:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:30:51 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:30:51 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:30:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-662d8455 in namespace infra-namespace
2022-04-06 05:30:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-662d8455 will be in active state
2022-04-06 05:30:52 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-producer-my-cluster-662d8455 to finished
2022-04-06 05:31:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-662d8455 in namespace infra-namespace
2022-04-06 05:31:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-662d8455 will be in active state
2022-04-06 05:31:01 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-662d8455 to finished
2022-04-06 05:31:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:31:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSaslPlainProducerConsumer
2022-04-06 05:31:12 [main] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-662d8455 in namespace infra-namespace
2022-04-06 05:31:12 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-662d8455 in namespace infra-namespace
2022-04-06 05:31:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:31:12 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainProducerConsumer-FINISHED
2022-04-06 05:31:12 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:31:12 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:31:12 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth-STARTED
2022-04-06 05:31:12 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:31:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-bc465816-kafka-clients in namespace infra-namespace
2022-04-06 05:31:12 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bc465816-kafka-clients will be ready
2022-04-06 05:31:14 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bc465816-kafka-clients is ready
2022-04-06 05:31:14 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-bc465816-scraper in namespace infra-namespace
2022-04-06 05:31:14 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-bc465816-scraper will be ready
2022-04-06 05:31:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-bc465816-scraper is ready
2022-04-06 05:31:16 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-bc465816-scraper to be ready
2022-04-06 05:31:26 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-bc465816-scraper is ready
2022-04-06 05:31:26 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-bc465816-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 05:31:26 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-bc465816-allow in namespace infra-namespace
2022-04-06 05:31:26 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 05:31:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-bc465816 in namespace infra-namespace
2022-04-06 05:31:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-bc465816 will have desired state: Ready
2022-04-06 05:32:30 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-bc465816 is in desired state: Ready
2022-04-06 05:32:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:32:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth
2022-04-06 05:32:30 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-bc465816-allow in namespace infra-namespace
2022-04-06 05:32:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-bc465816 in namespace infra-namespace
2022-04-06 05:32:30 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-bc465816-scraper in namespace infra-namespace
2022-04-06 05:32:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-bc465816-kafka-clients in namespace infra-namespace
2022-04-06 05:33:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:33:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth-FINISHED
2022-04-06 05:33:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:33:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:33:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker-STARTED
2022-04-06 05:33:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:33:10 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:33:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1925136013-1095029598 in namespace infra-namespace
2022-04-06 05:33:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1925136013-1095029598 will have desired state: Ready
2022-04-06 05:33:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1925136013-1095029598 is in desired state: Ready
2022-04-06 05:33:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-7bf605cd in namespace infra-namespace
2022-04-06 05:33:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-7bf605cd will be in active state
2022-04-06 05:33:12 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-7bf605cd to finished
2022-04-06 05:33:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-7bf605cd in namespace infra-namespace
2022-04-06 05:33:20 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-7bf605cd will be in active state
2022-04-06 05:33:21 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-7bf605cd to finished
2022-04-06 05:33:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7bf605cd-target in namespace infra-namespace
2022-04-06 05:33:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7bf605cd-target will have desired state: Ready
2022-04-06 05:34:32 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7bf605cd-target is in desired state: Ready
2022-04-06 05:34:32 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 05:34:32 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: oauth-cluster-plain-name will have desired state: Ready
2022-04-06 05:35:36 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: oauth-cluster-plain-name is in desired state: Ready
2022-04-06 05:35:36 [main] [32mINFO [m [OauthPlainIsolatedST:440] Deleting the Job
2022-04-06 05:35:36 [main] [32mINFO [m [OauthPlainIsolatedST:443] Creating new client with new consumer-group and also to point on my-cluster-7bf605cd-target cluster
2022-04-06 05:35:36 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:35:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer in namespace infra-namespace
2022-04-06 05:35:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer will be in active state
2022-04-06 05:35:37 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer to finished
2022-04-06 05:35:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:35:48 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker
2022-04-06 05:35:48 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7bf605cd-target in namespace infra-namespace
2022-04-06 05:35:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-7bf605cd in namespace infra-namespace
2022-04-06 05:35:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer in namespace infra-namespace
2022-04-06 05:35:48 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 05:35:48 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-7bf605cd in namespace infra-namespace
2022-04-06 05:35:48 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1925136013-1095029598 in namespace infra-namespace
2022-04-06 05:35:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:35:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker-FINISHED
2022-04-06 05:35:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:35:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:35:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerBridge-STARTED
2022-04-06 05:35:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:35:58 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:35:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1162441482-1766443943 in namespace infra-namespace
2022-04-06 05:35:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1162441482-1766443943 will have desired state: Ready
2022-04-06 05:35:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1162441482-1766443943 is in desired state: Ready
2022-04-06 05:35:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-0fe0222d in namespace infra-namespace
2022-04-06 05:35:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-0fe0222d will be in active state
2022-04-06 05:36:00 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-0fe0222d to finished
2022-04-06 05:36:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-0fe0222d in namespace infra-namespace
2022-04-06 05:36:08 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-0fe0222d will be in active state
2022-04-06 05:36:09 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-0fe0222d to finished
2022-04-06 05:36:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-0fe0222d-kafka-clients in namespace infra-namespace
2022-04-06 05:36:20 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-0fe0222d-kafka-clients will be ready
2022-04-06 05:36:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-0fe0222d-kafka-clients is ready
2022-04-06 05:36:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 05:36:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: oauth-cluster-plain-name will have desired state: Ready
2022-04-06 05:36:48 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: oauth-cluster-plain-name is in desired state: Ready
2022-04-06 05:36:48 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:36:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer-my-cluster-0fe0222d in namespace infra-namespace
2022-04-06 05:36:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer-my-cluster-0fe0222d will be in active state
2022-04-06 05:36:49 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer-my-cluster-0fe0222d to finished
2022-04-06 05:38:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:38:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerBridge
2022-04-06 05:38:38 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-0fe0222d-kafka-clients in namespace infra-namespace
2022-04-06 05:38:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-0fe0222d in namespace infra-namespace
2022-04-06 05:38:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1162441482-1766443943 in namespace infra-namespace
2022-04-06 05:38:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer-my-cluster-0fe0222d in namespace infra-namespace
2022-04-06 05:38:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 05:38:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-0fe0222d in namespace infra-namespace
2022-04-06 05:39:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:39:18 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerBridge-FINISHED
2022-04-06 05:39:18 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:39:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:39:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumer-STARTED
2022-04-06 05:39:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:39:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-956079194-889609790 in namespace infra-namespace
2022-04-06 05:39:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-956079194-889609790 will have desired state: Ready
2022-04-06 05:39:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-956079194-889609790 is in desired state: Ready
2022-04-06 05:39:19 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:39:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-7029d2b6 in namespace infra-namespace
2022-04-06 05:39:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-7029d2b6 will be in active state
2022-04-06 05:39:20 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-7029d2b6 to finished
2022-04-06 05:39:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-7029d2b6 in namespace infra-namespace
2022-04-06 05:39:28 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-7029d2b6 will be in active state
2022-04-06 05:39:29 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-7029d2b6 to finished
2022-04-06 05:39:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:39:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumer
2022-04-06 05:39:40 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-7029d2b6 in namespace infra-namespace
2022-04-06 05:39:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-956079194-889609790 in namespace infra-namespace
2022-04-06 05:39:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-7029d2b6 in namespace infra-namespace
2022-04-06 05:39:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:39:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumer-FINISHED
2022-04-06 05:39:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:39:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:39:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker2-STARTED
2022-04-06 05:39:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:39:50 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:39:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1542978887-631944839 in namespace infra-namespace
2022-04-06 05:39:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1542978887-631944839 will have desired state: Ready
2022-04-06 05:39:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1542978887-631944839 is in desired state: Ready
2022-04-06 05:39:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-c3ab3f94 in namespace infra-namespace
2022-04-06 05:39:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-c3ab3f94 will be in active state
2022-04-06 05:39:52 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-c3ab3f94 to finished
2022-04-06 05:40:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-c3ab3f94 in namespace infra-namespace
2022-04-06 05:40:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-c3ab3f94 will be in active state
2022-04-06 05:40:02 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-c3ab3f94 to finished
2022-04-06 05:40:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c3ab3f94-target in namespace infra-namespace
2022-04-06 05:40:13 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c3ab3f94-target will have desired state: Ready
2022-04-06 05:41:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c3ab3f94-target is in desired state: Ready
2022-04-06 05:41:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 05:41:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: oauth-cluster-plain-name will have desired state: Ready
2022-04-06 05:42:32 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: oauth-cluster-plain-name is in desired state: Ready
2022-04-06 05:42:33 [main] [32mINFO [m [OauthPlainIsolatedST:590] Deleting the Job oauth-consumer-my-cluster-c3ab3f94
2022-04-06 05:42:33 [main] [32mINFO [m [OauthPlainIsolatedST:593] Creating new client with new consumer-group and also to point on my-cluster-c3ab3f94-target cluster
2022-04-06 05:42:33 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:42:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-c3ab3f94 in namespace infra-namespace
2022-04-06 05:42:33 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-c3ab3f94 will be in active state
2022-04-06 05:42:34 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-c3ab3f94 to finished
2022-04-06 05:42:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:42:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerMirrorMaker2
2022-04-06 05:42:45 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c3ab3f94-target in namespace infra-namespace
2022-04-06 05:42:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-c3ab3f94 in namespace infra-namespace
2022-04-06 05:42:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-c3ab3f94 in namespace infra-namespace
2022-04-06 05:42:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 05:42:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-c3ab3f94 in namespace infra-namespace
2022-04-06 05:42:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1542978887-631944839 in namespace infra-namespace
2022-04-06 05:42:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:42:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerMirrorMaker2-FINISHED
2022-04-06 05:42:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:42:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:42:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks-STARTED
2022-04-06 05:42:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:42:55 [main] [32mINFO [m [OauthPlainIsolatedST:161] Setting producer and consumer properties
2022-04-06 05:42:55 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:42:55 [main] [32mINFO [m [OauthPlainIsolatedST:174] Use clients without access token containing audience token
2022-04-06 05:42:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-c54d6758 in namespace infra-namespace
2022-04-06 05:42:55 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-c54d6758 will be in active state
2022-04-06 05:42:56 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-producer-my-cluster-c54d6758 to finish with failure.
2022-04-06 05:46:36 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testProducerConsumerAudienceTokenChecks$0(OauthPlainIsolatedST.java:176)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks(OauthPlainIsolatedST.java:176)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 05:46:36 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-producer-my-cluster-c54d6758' finished with expected timeout.
2022-04-06 05:46:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-c54d6758 in namespace infra-namespace
2022-04-06 05:46:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-c54d6758 will be in active state
2022-04-06 05:46:36 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-consumer-my-cluster-c54d6758 to finish with failure.
2022-04-06 05:50:16 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testProducerConsumerAudienceTokenChecks$1(OauthPlainIsolatedST.java:178)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks(OauthPlainIsolatedST.java:178)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 05:50:16 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-consumer-my-cluster-c54d6758' finished with expected timeout.
2022-04-06 05:50:21 [main] [32mINFO [m [OauthPlainIsolatedST:183] Use clients with Access token containing audience token
2022-04-06 05:50:21 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:50:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-c54d6758 in namespace infra-namespace
2022-04-06 05:50:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-c54d6758 will be in active state
2022-04-06 05:50:22 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-producer-my-cluster-c54d6758 to finished
2022-04-06 05:50:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-c54d6758 in namespace infra-namespace
2022-04-06 05:50:30 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-c54d6758 will be in active state
2022-04-06 05:50:31 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-c54d6758 to finished
2022-04-06 05:50:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 05:50:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerAudienceTokenChecks
2022-04-06 05:50:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-c54d6758 in namespace infra-namespace
2022-04-06 05:50:42 [main] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-c54d6758 in namespace infra-namespace
2022-04-06 05:50:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-c54d6758 in namespace infra-namespace
2022-04-06 05:50:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-c54d6758 in namespace infra-namespace
2022-04-06 05:50:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 05:50:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerAudienceTokenChecks-FINISHED
2022-04-06 05:50:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 05:50:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 05:50:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-STARTED
2022-04-06 05:50:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 05:50:42 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 05:50:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1328384084-172227615 in namespace infra-namespace
2022-04-06 05:50:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1328384084-172227615 will have desired state: Ready
2022-04-06 05:50:43 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1328384084-172227615 is in desired state: Ready
2022-04-06 05:50:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-6361fa11 in namespace infra-namespace
2022-04-06 05:50:43 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-6361fa11 will be in active state
2022-04-06 05:50:44 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-6361fa11 to finished
2022-04-06 05:50:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-6361fa11 in namespace infra-namespace
2022-04-06 05:50:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-6361fa11 will be in active state
2022-04-06 05:50:53 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-6361fa11 to finished
2022-04-06 05:51:04 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6361fa11-kafka-clients in namespace infra-namespace
2022-04-06 05:51:04 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6361fa11-kafka-clients will be ready
2022-04-06 05:51:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6361fa11-kafka-clients is ready
2022-04-06 05:51:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-6361fa11-scraper in namespace infra-namespace
2022-04-06 05:51:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-6361fa11-scraper will be ready
2022-04-06 05:51:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-6361fa11-scraper is ready
2022-04-06 05:51:08 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-6361fa11-scraper to be ready
2022-04-06 05:51:18 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-6361fa11-scraper is ready
2022-04-06 05:51:18 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-6361fa11-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 05:51:18 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-6361fa11-allow in namespace infra-namespace
2022-04-06 05:51:18 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 05:51:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-6361fa11 in namespace infra-namespace
2022-04-06 05:51:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-6361fa11 will have desired state: Ready
2022-04-06 06:01:18 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for KafkaConnect: my-cluster-6361fa11 will have desired state: Ready, null
2022-04-06 06:01:18 [main] [32mINFO [m [ResourceManager:414] KafkaConnect status:

Conditions:
	Type: NotReady
	Message: Exceeded timeout of 300000ms while waiting for Deployment resource my-cluster-6361fa11-connect in namespace infra-namespace to be ready

Pods with conditions and messages:

my-cluster-6361fa11-connect-7c9dc5cc5b-r8ss9:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: Ready
	Message: containers with unready status: [my-cluster-6361fa11-connect]

	Type: ContainersReady
	Message: containers with unready status: [my-cluster-6361fa11-connect]

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-6361fa11-kafka-clients-cf5c48588-bfnq8:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>


my-cluster-6361fa11-scraper-695586dbf7-s5cdk:
	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>

	Type: <EMPTY>
	Message: <EMPTY>
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for KafkaConnect: my-cluster-6361fa11 will have desired state: Ready
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.systemtest.resources.ResourceManager.waitForResourceStatus(ResourceManager.java:435)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForConnectStatus(KafkaConnectUtils.java:42)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForConnectReady(KafkaConnectUtils.java:47)
	at io.strimzi.systemtest.resources.crd.KafkaConnectResource.waitForReadiness(KafkaConnectResource.java:42)
	at io.strimzi.systemtest.resources.crd.KafkaConnectResource.waitForReadiness(KafkaConnectResource.java:19)
	at io.strimzi.systemtest.resources.ResourceManager.lambda$waitResourceCondition$2(ResourceManager.java:268)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:142)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(OauthPlainIsolatedST.java:287)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-6361fa11
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(OauthPlainIsolatedST.java:287)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 06:01:18 [main] [1;31mERROR[m [TestExecutionWatcher:28] OauthPlainIsolatedST - Exception Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-6361fa11 has been thrown in @Test. Going to collect logs from components.
2022-04-06 06:01:18 [main] [32mINFO [m [LogCollector:252] Collecting events in Namespace infra-namespace
2022-04-06 06:01:18 [main] [32mINFO [m [LogCollector:259] Collecting ConfigMaps in Namespace infra-namespace
2022-04-06 06:01:18 [main] [32mINFO [m [LogCollector:217] Collecting logs for Pod(s) in Namespace infra-namespace
2022-04-06 06:01:18 [main] [33mWARN [m [LogCollector:247] Searching for logs in all pods failed! Some of the logs will not be stored. Exception messagenull
2022-04-06 06:01:18 [main] [32mINFO [m [LogCollector:266] Collecting Deployments in Namespace infra-namespace
2022-04-06 06:01:18 [main] [32mINFO [m [LogCollector:271] Collecting StatefulSets in Namespace infra-namespace
2022-04-06 06:01:18 [main] [32mINFO [m [LogCollector:276] Collecting ReplicaSets in Namespace infra-namespace
2022-04-06 06:01:18 [main] [32mINFO [m [LogCollector:281] Collecting Strimzi in Namespace infra-namespace
2022-04-06 06:01:19 [main] [32mINFO [m [LogCollector:287] Collecting cluster status
2022-04-06 06:01:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:01:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-06 06:01:19 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6361fa11-scraper in namespace infra-namespace
2022-04-06 06:01:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-6361fa11 in namespace infra-namespace
2022-04-06 06:01:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1328384084-172227615 in namespace infra-namespace
2022-04-06 06:01:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-6361fa11 in namespace infra-namespace
2022-04-06 06:01:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-6361fa11 in namespace infra-namespace
2022-04-06 06:01:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-6361fa11-allow in namespace infra-namespace
2022-04-06 06:01:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-6361fa11-kafka-clients in namespace infra-namespace
2022-04-06 06:01:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:01:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-06 06:01:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:01:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:01:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck-STARTED
2022-04-06 06:01:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:01:59 [main] [32mINFO [m [OauthPlainIsolatedST:213] Use clients with clientId not containing 'hello-world' in access token.
2022-04-06 06:01:59 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:01:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-producer-my-cluster-bc323867 in namespace infra-namespace
2022-04-06 06:01:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-producer-my-cluster-bc323867 will be in active state
2022-04-06 06:02:00 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:kafka-audience-producer-my-cluster-bc323867 to finish with failure.
2022-04-06 06:05:40 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testAccessTokenClaimCheck$2(OauthPlainIsolatedST.java:229)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck(OauthPlainIsolatedST.java:229)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 06:05:40 [main] [32mINFO [m [ClientUtils:100] Client job 'kafka-audience-producer-my-cluster-bc323867' finished with expected timeout.
2022-04-06 06:05:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Job kafka-audience-consumer-my-cluster-bc323867 in namespace infra-namespace
2022-04-06 06:05:40 [main] [32mINFO [m [JobUtils:81] Waiting for job: kafka-audience-consumer-my-cluster-bc323867 will be in active state
2022-04-06 06:05:41 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:kafka-audience-consumer-my-cluster-bc323867 to finish with failure.
2022-04-06 06:09:21 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.lambda$testAccessTokenClaimCheck$3(OauthPlainIsolatedST.java:231)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck(OauthPlainIsolatedST.java:231)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 06:09:21 [main] [32mINFO [m [ClientUtils:100] Client job 'kafka-audience-consumer-my-cluster-bc323867' finished with expected timeout.
2022-04-06 06:09:31 [main] [32mINFO [m [OauthPlainIsolatedST:236] Use clients with clientId containing 'hello-world' in access token.
2022-04-06 06:09:31 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:09:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-bc323867 in namespace infra-namespace
2022-04-06 06:09:31 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-bc323867 will be in active state
2022-04-06 06:09:32 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-bc323867 to finished
2022-04-06 06:09:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-bc323867 in namespace infra-namespace
2022-04-06 06:09:40 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-bc323867 will be in active state
2022-04-06 06:09:41 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-bc323867 to finished
2022-04-06 06:09:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:09:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testAccessTokenClaimCheck
2022-04-06 06:09:52 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-bc323867 in namespace infra-namespace
2022-04-06 06:09:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-consumer-my-cluster-bc323867 in namespace infra-namespace
2022-04-06 06:09:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-bc323867 in namespace infra-namespace
2022-04-06 06:09:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job kafka-audience-producer-my-cluster-bc323867 in namespace infra-namespace
2022-04-06 06:09:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:09:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testAccessTokenClaimCheck-FINISHED
2022-04-06 06:09:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:09:52 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 06:09:57 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 06:09:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:09:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:09:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthPlainIsolatedST
2022-04-06 06:09:57 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 06:09:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 06:10:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:10:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:10:07 [main] [32mINFO [m [ResourceManager:346] In context OauthPlainIsolatedST is everything deleted.
2022-04-06 06:10:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;31mERROR[m] Tests run: 9, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 2,632.913 s <<< FAILURE! - in io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
[[1;31mERROR[m] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(ExtensionContext)  Time elapsed: 677.354 s  <<< ERROR!
io.strimzi.test.WaitException: Timeout after 600000 ms waiting for Resource condition: readiness is fulfilled for resource KafkaConnect:my-cluster-6361fa11
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.resources.ResourceManager.waitResourceCondition(ResourceManager.java:264)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:226)
	at io.strimzi.systemtest.resources.ResourceManager.createResource(ResourceManager.java:148)
	at io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(OauthPlainIsolatedST.java:287)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)

[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
2022-04-06 06:10:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 06:10:32 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 06:10:32 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 06:10:32 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 06:10:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:10:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 06:10:32 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 06:10:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 06:10:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 06:10:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 06:10:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:10:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 06:10:32 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:10:42 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:10:42 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 06:10:42 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 06:10:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 06:10:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 06:10:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:10:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 06:10:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 06:10:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 06:10:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 06:10:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 06:10:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:10:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 06:10:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 06:10:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:10:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:10:52 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 06:11:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:11:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:11:18 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 06:11:18 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 06:11:18 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 06:11:18 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 06:11:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:11:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:11:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 06:11:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 06:11:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 06:11:18 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 06:11:18 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:11:19 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 06:11:19 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:11:19 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 06:11:19 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 06:11:19 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 06:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:11:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 06:11:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 06:11:36 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 06:11:46 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 06:11:46 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 06:11:46 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-06 06:11:46 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 06:13:27 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 06:13:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:13:27 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-06 06:13:27 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-06 06:13:27 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-06 06:13:27 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-06 06:13:27 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-06 06:13:27 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-06 06:13:27 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-06 06:13:27 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-06 06:13:27 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-06 06:13:27 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-06 06:13:27 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-06 06:13:27 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-06 06:13:27 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-06 06:13:27 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-06 06:13:27 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to kafka-authz realm
2022-04-06 06:13:27 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to kafka-authz realm
2022-04-06 06:13:27 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to kafka-authz realm
2022-04-06 06:13:27 [main] [32mINFO [m [KeycloakInstance:55] Using HTTPS endpoints
2022-04-06 06:13:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-authz-name in namespace infra-namespace
2022-04-06 06:13:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-06 06:14:34 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-06 06:14:34 [main] [32mINFO [m [OauthAuthorizationIsolatedST:680] Setting producer and consumer properties
2022-04-06 06:14:34 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-a-client in namespace infra-namespace
2022-04-06 06:14:34 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-a-client will have desired state: Ready
2022-04-06 06:14:35 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-a-client is in desired state: Ready
2022-04-06 06:14:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-b-client in namespace infra-namespace
2022-04-06 06:14:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-b-client will have desired state: Ready
2022-04-06 06:14:36 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-b-client is in desired state: Ready
2022-04-06 06:14:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:14:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.smokeTestForClients-STARTED
2022-04-06 06:14:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:14:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-1054078460-1412222483 in namespace infra-namespace
2022-04-06 06:14:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-1054078460-1412222483 will have desired state: Ready
2022-04-06 06:14:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-1054078460-1412222483 is in desired state: Ready
2022-04-06 06:14:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-4476deb6 in namespace infra-namespace
2022-04-06 06:14:37 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-4476deb6 will be in active state
2022-04-06 06:14:38 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-4476deb6 to finished
2022-04-06 06:14:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-4476deb6 in namespace infra-namespace
2022-04-06 06:14:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-4476deb6 will be in active state
2022-04-06 06:14:49 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-4476deb6 to finished
2022-04-06 06:15:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:15:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for smokeTestForClients
2022-04-06 06:15:00 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-4476deb6 in namespace infra-namespace
2022-04-06 06:15:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-1054078460-1412222483 in namespace infra-namespace
2022-04-06 06:15:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-4476deb6 in namespace infra-namespace
2022-04-06 06:15:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:15:10 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.smokeTestForClients-FINISHED
2022-04-06 06:15:10 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:15:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:15:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopic-STARTED
2022-04-06 06:15:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:15:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1448819715-1927348771 in namespace infra-namespace
2022-04-06 06:15:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1448819715-1927348771 will have desired state: Ready
2022-04-06 06:15:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1448819715-1927348771 is in desired state: Ready
2022-04-06 06:15:11 [main] [32mINFO [m [OauthAuthorizationIsolatedST:146] Sending 100 messages to broker with topic name my-topic-1448819715-1927348771
2022-04-06 06:15:11 [main] [32mINFO [m [OauthAuthorizationIsolatedST:147] Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'
2022-04-06 06:15:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-8972c7a5 in namespace infra-namespace
2022-04-06 06:15:11 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-8972c7a5 will be in active state
2022-04-06 06:15:12 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-producer-my-cluster-8972c7a5 will be in error state
2022-04-06 06:15:31 [main] [32mINFO [m [OauthAuthorizationIsolatedST:154] Sending 100 messages to broker with topic name x-topic-my-cluster-8972c7a5
2022-04-06 06:15:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-8972c7a5 in namespace infra-namespace
2022-04-06 06:15:31 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-8972c7a5 will be in active state
2022-04-06 06:15:32 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-producer-my-cluster-8972c7a5 will be in error state
2022-04-06 06:15:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topic-my-cluster-8972c7a5 in namespace infra-namespace
2022-04-06 06:15:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topic-my-cluster-8972c7a5 will have desired state: Ready
2022-04-06 06:15:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topic-my-cluster-8972c7a5 is in desired state: Ready
2022-04-06 06:15:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-8972c7a5 in namespace infra-namespace
2022-04-06 06:15:52 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-8972c7a5 will be in active state
2022-04-06 06:15:53 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-8972c7a5 to finished
2022-04-06 06:16:01 [main] [32mINFO [m [OauthAuthorizationIsolatedST:172] Sending 100 messages to broker with topic name a-topic-my-cluster-8972c7a5
2022-04-06 06:16:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-8972c7a5 in namespace infra-namespace
2022-04-06 06:16:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-8972c7a5 will be in active state
2022-04-06 06:16:02 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-8972c7a5 to finished
2022-04-06 06:16:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:16:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAWriteToTopic
2022-04-06 06:16:11 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topic-my-cluster-8972c7a5 in namespace infra-namespace
2022-04-06 06:16:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-8972c7a5 in namespace infra-namespace
2022-04-06 06:16:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-8972c7a5 in namespace infra-namespace
2022-04-06 06:16:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1448819715-1927348771 in namespace infra-namespace
2022-04-06 06:16:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-8972c7a5 in namespace infra-namespace
2022-04-06 06:16:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-8972c7a5 in namespace infra-namespace
2022-04-06 06:16:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:16:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopic-FINISHED
2022-04-06 06:16:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:16:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:16:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAReadFromTopic-STARTED
2022-04-06 06:16:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:16:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-421635908-859557712 in namespace infra-namespace
2022-04-06 06:16:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-421635908-859557712 will have desired state: Ready
2022-04-06 06:16:22 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-421635908-859557712 is in desired state: Ready
2022-04-06 06:16:22 [main] [32mINFO [m [OauthAuthorizationIsolatedST:208] Sending 100 messages to broker with topic name a-topic-my-topic-421635908-859557712
2022-04-06 06:16:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-bd65916d in namespace infra-namespace
2022-04-06 06:16:22 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-bd65916d will be in active state
2022-04-06 06:16:23 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-bd65916d to finished
2022-04-06 06:16:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-bd65916d in namespace infra-namespace
2022-04-06 06:16:32 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-bd65916d will be in active state
2022-04-06 06:16:33 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-consumer-my-cluster-bd65916d will be in error state
2022-04-06 06:16:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-bd65916d in namespace infra-namespace
2022-04-06 06:16:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-bd65916d will be in active state
2022-04-06 06:16:37 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-bd65916d to finished
2022-04-06 06:16:46 [main] [32mINFO [m [OauthAbstractST:153] Deleting team-a-client-consumer-my-cluster-bd65916d job
2022-04-06 06:16:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:16:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAReadFromTopic
2022-04-06 06:16:51 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-bd65916d in namespace infra-namespace
2022-04-06 06:16:51 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-bd65916d in namespace infra-namespace
2022-04-06 06:16:51 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-bd65916d in namespace infra-namespace
2022-04-06 06:16:51 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-421635908-859557712 in namespace infra-namespace
2022-04-06 06:17:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:17:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAReadFromTopic-FINISHED
2022-04-06 06:17:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:17:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:17:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamBWriteToTopic-STARTED
2022-04-06 06:17:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:17:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-375704311-1773046905 in namespace infra-namespace
2022-04-06 06:17:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-375704311-1773046905 will have desired state: Ready
2022-04-06 06:17:02 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-375704311-1773046905 is in desired state: Ready
2022-04-06 06:17:02 [main] [32mINFO [m [OauthAuthorizationIsolatedST:259] Sending 100 messages to broker with topic name my-topic-609391865-1811347379
2022-04-06 06:17:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-330398ff in namespace infra-namespace
2022-04-06 06:17:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-330398ff will be in active state
2022-04-06 06:17:03 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-b-client-producer-my-cluster-330398ff will be in error state
2022-04-06 06:17:21 [main] [32mINFO [m [OauthAuthorizationIsolatedST:265] Sending 100 messages to broker with topic name b-topic
2022-04-06 06:17:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-330398ff in namespace infra-namespace
2022-04-06 06:17:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-330398ff will be in active state
2022-04-06 06:17:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-consumer-my-cluster-330398ff in namespace infra-namespace
2022-04-06 06:17:22 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-consumer-my-cluster-330398ff will be in active state
2022-04-06 06:17:23 [main] [32mINFO [m [ClientUtils:61] Waiting till producer team-b-client-producer-my-cluster-330398ff and consumer team-b-client-consumer-my-cluster-330398ff finish
2022-04-06 06:17:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:17:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamBWriteToTopic
2022-04-06 06:17:40 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-330398ff in namespace infra-namespace
2022-04-06 06:17:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-330398ff in namespace infra-namespace
2022-04-06 06:17:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-375704311-1773046905 in namespace infra-namespace
2022-04-06 06:17:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-consumer-my-cluster-330398ff in namespace infra-namespace
2022-04-06 06:17:50 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:17:50 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamBWriteToTopic-FINISHED
2022-04-06 06:17:50 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:17:50 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:17:50 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX-STARTED
2022-04-06 06:17:50 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:17:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topicmy-topic-1776243300-1467599742 in namespace infra-namespace
2022-04-06 06:17:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topicmy-topic-1776243300-1467599742 will have desired state: Ready
2022-04-06 06:17:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topicmy-topic-1776243300-1467599742 is in desired state: Ready
2022-04-06 06:17:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-206d274e in namespace infra-namespace
2022-04-06 06:17:51 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-206d274e will be in active state
2022-04-06 06:17:52 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-206d274e to finished
2022-04-06 06:18:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-consumer-my-cluster-206d274e in namespace infra-namespace
2022-04-06 06:18:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-consumer-my-cluster-206d274e will be in active state
2022-04-06 06:18:03 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-b-client-consumer-my-cluster-206d274e to finished
2022-04-06 06:18:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:18:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX
2022-04-06 06:18:15 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-206d274e in namespace infra-namespace
2022-04-06 06:18:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topicmy-topic-1776243300-1467599742 in namespace infra-namespace
2022-04-06 06:18:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-consumer-my-cluster-206d274e in namespace infra-namespace
2022-04-06 06:18:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:18:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX-FINISHED
2022-04-06 06:18:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:18:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:18:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSuperUserWithOauthAuthorization-STARTED
2022-04-06 06:18:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:18:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topicmy-topic-1873617725-1040848686 in namespace infra-namespace
2022-04-06 06:18:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topicmy-topic-1873617725-1040848686 will have desired state: Ready
2022-04-06 06:18:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topicmy-topic-1873617725-1040848686 is in desired state: Ready
2022-04-06 06:18:26 [main] [32mINFO [m [OauthAuthorizationIsolatedST:347] Verifying that team B is not able write to topic starting with 'x-' because in kafka clusterdoes not have super-users to break authorization rules
2022-04-06 06:18:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1136027325-1280535341 in namespace infra-namespace
2022-04-06 06:18:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1136027325-1280535341 will have desired state: Ready
2022-04-06 06:18:27 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1136027325-1280535341 is in desired state: Ready
2022-04-06 06:18:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-3971fe78 in namespace infra-namespace
2022-04-06 06:18:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-3971fe78 will be in active state
2022-04-06 06:18:28 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-b-client-producer-my-cluster-3971fe78 will be in error state
2022-04-06 06:18:36 [main] [32mINFO [m [OauthAuthorizationIsolatedST:370] Verifying that team A is not able read to topic starting with 'x-' because in kafka clusterdoes not have super-users to break authorization rules
2022-04-06 06:18:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-3971fe78 in namespace infra-namespace
2022-04-06 06:18:36 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-3971fe78 will be in active state
2022-04-06 06:18:37 [main] [32mINFO [m [JobUtils:70] Waiting for job: team-a-client-consumer-my-cluster-3971fe78 will be in error state
2022-04-06 06:18:45 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: oauth-cluster-authz-name-kafka rolling update
2022-04-06 06:18:55 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: oauth-cluster-authz-name-kafka has been successfully rolled
2022-04-06 06:18:55 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-authz-name-kafka to be ready
2022-04-06 06:19:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-06 06:19:24 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-06 06:19:24 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-authz-name is ready
2022-04-06 06:19:24 [main] [32mINFO [m [OauthAuthorizationIsolatedST:404] Verifying that team B is able to write to topic starting with 'x-' and break authorization rule
2022-04-06 06:19:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-b-client-producer-my-cluster-3971fe78 in namespace infra-namespace
2022-04-06 06:19:24 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-b-client-producer-my-cluster-3971fe78 will be in active state
2022-04-06 06:19:25 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-b-client-producer-my-cluster-3971fe78 to finished
2022-04-06 06:19:34 [main] [32mINFO [m [OauthAuthorizationIsolatedST:409] Verifying that team A is able to write to topic starting with 'x-' and break authorization rule
2022-04-06 06:19:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-3971fe78 in namespace infra-namespace
2022-04-06 06:19:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-3971fe78 will be in active state
2022-04-06 06:19:35 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-3971fe78 to finished
2022-04-06 06:19:41 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:19:41 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSuperUserWithOauthAuthorization
2022-04-06 06:19:41 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-3971fe78 in namespace infra-namespace
2022-04-06 06:19:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-3971fe78 in namespace infra-namespace
2022-04-06 06:19:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1136027325-1280535341 in namespace infra-namespace
2022-04-06 06:19:41 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topicmy-topic-1873617725-1040848686 in namespace infra-namespace
2022-04-06 06:19:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-3971fe78 in namespace infra-namespace
2022-04-06 06:19:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job team-b-client-producer-my-cluster-3971fe78 in namespace infra-namespace
2022-04-06 06:19:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:19:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSuperUserWithOauthAuthorization-FINISHED
2022-04-06 06:19:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:19:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:19:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication-STARTED
2022-04-06 06:19:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:19:51 [main] [32mINFO [m [OauthAuthorizationIsolatedST:443] Verifying that team A producer is able to send messages to the x-topic-example-topic topic -> the topic starting with 'x'
2022-04-06 06:19:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic x-topic-example-topic in namespace infra-namespace
2022-04-06 06:19:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: x-topic-example-topic will have desired state: Ready
2022-04-06 06:19:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: x-topic-example-topic is in desired state: Ready
2022-04-06 06:19:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-example-topic in namespace infra-namespace
2022-04-06 06:19:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-example-topic will have desired state: Ready
2022-04-06 06:19:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-example-topic is in desired state: Ready
2022-04-06 06:19:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-ce33bb9a in namespace infra-namespace
2022-04-06 06:19:53 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-ce33bb9a will be in active state
2022-04-06 06:19:54 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-ce33bb9a to finished
2022-04-06 06:20:02 [main] [32mINFO [m [OauthAuthorizationIsolatedST:465] Adding the maxSecondsWithoutReauthentication to Kafka listener with OAuth authentication
2022-04-06 06:20:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-06 06:20:02 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-06 06:20:02 [main] [32mINFO [m [OauthAuthorizationIsolatedST:493] Setting the master realm token's lifespan to 3600s
2022-04-06 06:20:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-7rshj -- curl -v --insecure -X POST -d client_id=admin-cli&client_secret=aGVsbG8td29ybGQtcHJvZHVjZXItc2VjcmV0&grant_type=password&username=admin&password=Fgn6d8Re7r4nkw== https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/master/protocol/openid-connect/token
2022-04-06 06:20:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:20:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-7rshj -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/master -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI2QnBBeVM0UmIxQUtoUndRZDVrLUYxbmZiUlBkMXNwSEQzZEhpTU1tNG40In0.eyJleHAiOjE2NDkyMjYwNjMsImlhdCI6MTY0OTIyNjAwMywianRpIjoiOWE4ZTM1OGItOTIzMS00YzYxLThkZTMtZDA1YjhkMjIxM2Y4IiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiJlNzgzZjI2MC0xMjZjLTQ0OWUtYTlkMi03NDliOGQ2MDFkOGMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiODU1MmM5NjAtMmRmNy00NmFjLTgxOTAtMGVmOGViY2FhODVjIiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.kBc9Q_90GfM1O9dPuhxSujriR973vxhnNba1MIha1k_WNMvycCHOpE5Kf_oYuqN3z1Wz2bFQE-MBaUGtFuWjoHLQeoqqwcDWc8HG7PSB-hoB0vgdWrKv2lnpFet9WYT2C8wuVJuBv2pZho9sCZdhSAu4Gpen3FCKZly8koCNq6qctrU6YbpvCb2HkHRAJeZGKalrWnEeiSrIqNr-kUEzPbN0mimSM7807CuAbbKuHbuZTeEzk9ZkC1XyBU8AdyqXUh9CR04QvpVoXtfoX2HyoulyAFY8j6to3VYNkHaszpf3dSzvaBX38z8Rsft41yaw_5PZQGi9OlI5k-Slsid-qQ
2022-04-06 06:20:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:20:03 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-7rshj -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/master -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI2QnBBeVM0UmIxQUtoUndRZDVrLUYxbmZiUlBkMXNwSEQzZEhpTU1tNG40In0.eyJleHAiOjE2NDkyMjYwNjMsImlhdCI6MTY0OTIyNjAwMywianRpIjoiOWE4ZTM1OGItOTIzMS00YzYxLThkZTMtZDA1YjhkMjIxM2Y4IiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiJlNzgzZjI2MC0xMjZjLTQ0OWUtYTlkMi03NDliOGQ2MDFkOGMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiODU1MmM5NjAtMmRmNy00NmFjLTgxOTAtMGVmOGViY2FhODVjIiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.kBc9Q_90GfM1O9dPuhxSujriR973vxhnNba1MIha1k_WNMvycCHOpE5Kf_oYuqN3z1Wz2bFQE-MBaUGtFuWjoHLQeoqqwcDWc8HG7PSB-hoB0vgdWrKv2lnpFet9WYT2C8wuVJuBv2pZho9sCZdhSAu4Gpen3FCKZly8koCNq6qctrU6YbpvCb2HkHRAJeZGKalrWnEeiSrIqNr-kUEzPbN0mimSM7807CuAbbKuHbuZTeEzk9ZkC1XyBU8AdyqXUh9CR04QvpVoXtfoX2HyoulyAFY8j6to3VYNkHaszpf3dSzvaBX38z8Rsft41yaw_5PZQGi9OlI5k-Slsid-qQ -d {"id":"master","realm":"master","displayName":"Keycloak","displayNameHtml":"<div class=\"kc-logo-text\"><span>Keycloak</span></div>","notBefore":0,"revokeRefreshToken":false,"refreshTokenMaxReuse":0,"accessTokenLifespan":"3600","accessTokenLifespanForImplicitFlow":900,"ssoSessionIdleTimeout":1800,"ssoSessionMaxLifespan":36000,"ssoSessionIdleTimeoutRememberMe":0,"ssoSessionMaxLifespanRememberMe":0,"offlineSessionIdleTimeout":2592000,"offlineSessionMaxLifespanEnabled":false,"offlineSessionMaxLifespan":5184000,"clientSessionIdleTimeout":0,"clientSessionMaxLifespan":0,"clientOfflineSessionIdleTimeout":0,"clientOfflineSessionMaxLifespan":0,"accessCodeLifespan":60,"accessCodeLifespanUserAction":300,"accessCodeLifespanLogin":1800,"actionTokenGeneratedByAdminLifespan":43200,"actionTokenGeneratedByUserLifespan":300,"enabled":true,"sslRequired":"external","registrationAllowed":false,"registrationEmailAsUsername":false,"rememberMe":false,"verifyEmail":false,"loginWithEmailAllowed":true,"duplicateEmailsAllowed":false,"resetPasswordAllowed":false,"editUsernameAllowed":false,"bruteForceProtected":false,"permanentLockout":false,"maxFailureWaitSeconds":900,"minimumQuickLoginWaitSeconds":60,"waitIncrementSeconds":60,"quickLoginCheckMilliSeconds":1000,"maxDeltaTimeSeconds":43200,"failureFactor":30,"defaultRoles":["offline_access","uma_authorization"],"requiredCredentials":["password"],"otpPolicyType":"totp","otpPolicyAlgorithm":"HmacSHA1","otpPolicyInitialCounter":0,"otpPolicyDigits":6,"otpPolicyLookAheadWindow":1,"otpPolicyPeriod":30,"otpSupportedApplications":["FreeOTP","Google Authenticator"],"webAuthnPolicyRpEntityName":"keycloak","webAuthnPolicySignatureAlgorithms":["ES256"],"webAuthnPolicyRpId":"","webAuthnPolicyAttestationConveyancePreference":"not specified","webAuthnPolicyAuthenticatorAttachment":"not specified","webAuthnPolicyRequireResidentKey":"not specified","webAuthnPolicyUserVerificationRequirement":"not specified","webAuthnPolicyCreateTimeout":0,"webAuthnPolicyAvoidSameAuthenticatorRegister":false,"webAuthnPolicyAcceptableAaguids":[],"webAuthnPolicyPasswordlessRpEntityName":"keycloak","webAuthnPolicyPasswordlessSignatureAlgorithms":["ES256"],"webAuthnPolicyPasswordlessRpId":"","webAuthnPolicyPasswordlessAttestationConveyancePreference":"not specified","webAuthnPolicyPasswordlessAuthenticatorAttachment":"not specified","webAuthnPolicyPasswordlessRequireResidentKey":"not specified","webAuthnPolicyPasswordlessUserVerificationRequirement":"not specified","webAuthnPolicyPasswordlessCreateTimeout":0,"webAuthnPolicyPasswordlessAvoidSameAuthenticatorRegister":false,"webAuthnPolicyPasswordlessAcceptableAaguids":[],"browserSecurityHeaders":{"contentSecurityPolicyReportOnly":"","xContentTypeOptions":"nosniff","xRobotsTag":"none","xFrameOptions":"SAMEORIGIN","xXSSProtection":"1; mode=block","contentSecurityPolicy":"frame-src 'self'; frame-ancestors 'self'; object-src 'none';","strictTransportSecurity":"max-age=31536000; includeSubDomains"},"smtpServer":{},"eventsEnabled":false,"eventsListeners":["jboss-logging"],"enabledEventTypes":[],"adminEventsEnabled":false,"adminEventsDetailsEnabled":false,"internationalizationEnabled":false,"supportedLocales":[],"browserFlow":"browser","registrationFlow":"registration","directGrantFlow":"direct grant","resetCredentialsFlow":"reset credentials","clientAuthenticationFlow":"clients","dockerAuthenticationFlow":"docker auth","attributes":{},"userManagedAccessAllowed":false} -H Content-Type: application/json
2022-04-06 06:20:03 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:20:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-7rshj -- curl -v --insecure -X POST -d client_id=admin-cli&client_secret=aGVsbG8td29ybGQtcHJvZHVjZXItc2VjcmV0&grant_type=password&username=admin&password=Fgn6d8Re7r4nkw== https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/master/protocol/openid-connect/token
2022-04-06 06:20:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:20:04 [main] [32mINFO [m [OauthAuthorizationIsolatedST:508] Getting the kafka-authz kafka client for obtaining the Dev A Team policy for the x topics
2022-04-06 06:20:04 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-7rshj -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI2QnBBeVM0UmIxQUtoUndRZDVrLUYxbmZiUlBkMXNwSEQzZEhpTU1tNG40In0.eyJleHAiOjE2NDkyMjk2MDQsImlhdCI6MTY0OTIyNjAwNCwianRpIjoiZTY1Y2Q5MGMtMTRhYy00M2Q1LTk0YmItYjY3YzJhNDNiNzJlIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiJlNzgzZjI2MC0xMjZjLTQ0OWUtYTlkMi03NDliOGQ2MDFkOGMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiYmJjYjllOTUtNjA5MC00ZDgyLWI0OWItYjM1ZjQ1ZjFjZDEyIiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.WiXSE5JIo7xTGiVlr-9tFkz5H2-t2I-Pur9bvhTSO4VGQQVwCS7FOciqvcNATn8VAj_O-FnmYsDM7TaltzhztMNlgsUWXi5HVvxCpJIN36WIjVsXc1o8FXzJ7IFhqfeX4xJGUG8HcWmzE3qtWrkI7CBLJfcQzviWIWyGuyyJF1pKxPwoZ0VGlWCS3Bs6P5K8m9CLqzqSt4woH1OTfyVz4ZO9YCiN_8mEkB6YrhZCegJQIY0PZW6zqyq-5JOm1glAflyUYyGoev7VXzbDcL7Jw9qWwSgIIOInHqGLbiw0P0HwIL7p7oYAW0ULdy6UDa-LrNE_VvX52e2lYMgCpRzwwQ
2022-04-06 06:20:04 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:20:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-7rshj -- curl -v --insecure -X GET https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/c33b9821-c8de-47fd-a5f4-2bf6e32399e8/authz/resource-server/policy -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI2QnBBeVM0UmIxQUtoUndRZDVrLUYxbmZiUlBkMXNwSEQzZEhpTU1tNG40In0.eyJleHAiOjE2NDkyMjk2MDQsImlhdCI6MTY0OTIyNjAwNCwianRpIjoiZTY1Y2Q5MGMtMTRhYy00M2Q1LTk0YmItYjY3YzJhNDNiNzJlIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiJlNzgzZjI2MC0xMjZjLTQ0OWUtYTlkMi03NDliOGQ2MDFkOGMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiYmJjYjllOTUtNjA5MC00ZDgyLWI0OWItYjM1ZjQ1ZjFjZDEyIiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.WiXSE5JIo7xTGiVlr-9tFkz5H2-t2I-Pur9bvhTSO4VGQQVwCS7FOciqvcNATn8VAj_O-FnmYsDM7TaltzhztMNlgsUWXi5HVvxCpJIN36WIjVsXc1o8FXzJ7IFhqfeX4xJGUG8HcWmzE3qtWrkI7CBLJfcQzviWIWyGuyyJF1pKxPwoZ0VGlWCS3Bs6P5K8m9CLqzqSt4woH1OTfyVz4ZO9YCiN_8mEkB6YrhZCegJQIY0PZW6zqyq-5JOm1glAflyUYyGoev7VXzbDcL7Jw9qWwSgIIOInHqGLbiw0P0HwIL7p7oYAW0ULdy6UDa-LrNE_VvX52e2lYMgCpRzwwQ
2022-04-06 06:20:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:20:05 [main] [32mINFO [m [OauthAuthorizationIsolatedST:539] Changing the Dev Team A policy for topics starting with x- and checking that job will not be successful
2022-04-06 06:20:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-7rshj -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/c33b9821-c8de-47fd-a5f4-2bf6e32399e8/authz/resource-server/policy/f162312a-4482-4781-b245-ead5f36345be -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI2QnBBeVM0UmIxQUtoUndRZDVrLUYxbmZiUlBkMXNwSEQzZEhpTU1tNG40In0.eyJleHAiOjE2NDkyMjk2MDQsImlhdCI6MTY0OTIyNjAwNCwianRpIjoiZTY1Y2Q5MGMtMTRhYy00M2Q1LTk0YmItYjY3YzJhNDNiNzJlIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiJlNzgzZjI2MC0xMjZjLTQ0OWUtYTlkMi03NDliOGQ2MDFkOGMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiYmJjYjllOTUtNjA5MC00ZDgyLWI0OWItYjM1ZjQ1ZjFjZDEyIiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.WiXSE5JIo7xTGiVlr-9tFkz5H2-t2I-Pur9bvhTSO4VGQQVwCS7FOciqvcNATn8VAj_O-FnmYsDM7TaltzhztMNlgsUWXi5HVvxCpJIN36WIjVsXc1o8FXzJ7IFhqfeX4xJGUG8HcWmzE3qtWrkI7CBLJfcQzviWIWyGuyyJF1pKxPwoZ0VGlWCS3Bs6P5K8m9CLqzqSt4woH1OTfyVz4ZO9YCiN_8mEkB6YrhZCegJQIY0PZW6zqyq-5JOm1glAflyUYyGoev7VXzbDcL7Jw9qWwSgIIOInHqGLbiw0P0HwIL7p7oYAW0ULdy6UDa-LrNE_VvX52e2lYMgCpRzwwQ -d {"id":"f162312a-4482-4781-b245-ead5f36345be","name":"Dev Team A can write to topics that start with x- on any cluster","type":"scope","logic":"POSITIVE","decisionStrategy":"UNANIMOUS","config":{"resources":"[\"Topic:x-*\"]","scopes":"[\"Describe\"]","applyPolicies":"[\"Dev Team A\"]"}} -H Content-Type: application/json
2022-04-06 06:20:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:20:05 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-ce33bb9a to finished
2022-04-06 06:23:45 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for job finished, null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for job finished
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientSuccess(ClientUtils.java:77)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientSuccess(ClientUtils.java:72)
	at io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.lambda$testSessionReAuthentication$2(OauthAuthorizationIsolatedST.java:541)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:55)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:37)
	at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3082)
	at io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication(OauthAuthorizationIsolatedST.java:541)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 06:23:45 [main] [32mINFO [m [OauthAuthorizationIsolatedST:545] Sending messages to topic starting with a- -> the messages should be successfully sent
2022-04-06 06:23:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-ce33bb9a in namespace infra-namespace
2022-04-06 06:23:45 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-ce33bb9a will be in active state
2022-04-06 06:23:46 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-ce33bb9a to finished
2022-04-06 06:23:55 [main] [32mINFO [m [OauthAuthorizationIsolatedST:554] Changing back to the original settings and checking, if the producer will be successful
2022-04-06 06:23:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec strimzi-cluster-operator-78689684d4-7rshj -- curl -v --insecure -X PUT https://keycloak.infra-namespace.svc.cluster.local:8443/auth/admin/realms/kafka-authz/clients/c33b9821-c8de-47fd-a5f4-2bf6e32399e8/authz/resource-server/policy/f162312a-4482-4781-b245-ead5f36345be -H Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI2QnBBeVM0UmIxQUtoUndRZDVrLUYxbmZiUlBkMXNwSEQzZEhpTU1tNG40In0.eyJleHAiOjE2NDkyMjk2MDQsImlhdCI6MTY0OTIyNjAwNCwianRpIjoiZTY1Y2Q5MGMtMTRhYy00M2Q1LTk0YmItYjY3YzJhNDNiNzJlIiwiaXNzIjoiaHR0cHM6Ly9rZXljbG9hay5pbmZyYS1uYW1lc3BhY2Uuc3ZjLmNsdXN0ZXIubG9jYWw6ODQ0My9hdXRoL3JlYWxtcy9tYXN0ZXIiLCJzdWIiOiJlNzgzZjI2MC0xMjZjLTQ0OWUtYTlkMi03NDliOGQ2MDFkOGMiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhZG1pbi1jbGkiLCJzZXNzaW9uX3N0YXRlIjoiYmJjYjllOTUtNjA5MC00ZDgyLWI0OWItYjM1ZjQ1ZjFjZDEyIiwiYWNyIjoiMSIsInNjb3BlIjoicHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4ifQ.WiXSE5JIo7xTGiVlr-9tFkz5H2-t2I-Pur9bvhTSO4VGQQVwCS7FOciqvcNATn8VAj_O-FnmYsDM7TaltzhztMNlgsUWXi5HVvxCpJIN36WIjVsXc1o8FXzJ7IFhqfeX4xJGUG8HcWmzE3qtWrkI7CBLJfcQzviWIWyGuyyJF1pKxPwoZ0VGlWCS3Bs6P5K8m9CLqzqSt4woH1OTfyVz4ZO9YCiN_8mEkB6YrhZCegJQIY0PZW6zqyq-5JOm1glAflyUYyGoev7VXzbDcL7Jw9qWwSgIIOInHqGLbiw0P0HwIL7p7oYAW0ULdy6UDa-LrNE_VvX52e2lYMgCpRzwwQ -d {"id":"f162312a-4482-4781-b245-ead5f36345be","name":"Dev Team A can write to topics that start with x- on any cluster","type":"scope","logic":"POSITIVE","decisionStrategy":"UNANIMOUS","config":{"resources":"[\"Topic:x-*\"]","scopes":"[\"Describe\",\"Write\"]","applyPolicies":"[\"Dev Team A\"]"}} -H Content-Type: application/json
2022-04-06 06:23:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:23:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-ce33bb9a in namespace infra-namespace
2022-04-06 06:23:55 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-ce33bb9a will be in active state
2022-04-06 06:23:56 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-ce33bb9a to finished
2022-04-06 06:25:45 [main] [32mINFO [m [OauthAuthorizationIsolatedST:568] Changing configuration of Kafka back to it's original form
2022-04-06 06:25:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-authz-name will have desired state: Ready
2022-04-06 06:25:45 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-authz-name is in desired state: Ready
2022-04-06 06:25:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:25:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSessionReAuthentication
2022-04-06 06:25:45 [main] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-ce33bb9a in namespace infra-namespace
2022-04-06 06:25:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-ce33bb9a in namespace infra-namespace
2022-04-06 06:25:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-example-topic in namespace infra-namespace
2022-04-06 06:25:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic x-topic-example-topic in namespace infra-namespace
2022-04-06 06:25:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-ce33bb9a in namespace infra-namespace
2022-04-06 06:25:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:25:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testSessionReAuthentication-FINISHED
2022-04-06 06:25:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:25:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:25:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testKeycloakAuthorizerToDelegateToSimpleAuthorizer-STARTED
2022-04-06 06:25:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:25:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-97 for test case:testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-06 06:25:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-97
2022-04-06 06:25:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-97
2022-04-06 06:25:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-97
2022-04-06 06:25:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret sso-x509-https-secret in namespace infra-namespace
2022-04-06 06:25:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:25:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret team-a-client-secret in namespace infra-namespace
2022-04-06 06:25:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:25:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Secret team-b-client-secret in namespace infra-namespace
2022-04-06 06:25:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:25:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-33dee6d9 in namespace namespace-97
2022-04-06 06:25:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:25:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-33dee6d9 will have desired state: Ready
2022-04-06 06:27:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-33dee6d9 is in desired state: Ready
2022-04-06 06:27:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-a-client in namespace namespace-97
2022-04-06 06:27:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:27:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-a-client will have desired state: Ready
2022-04-06 06:27:06 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-a-client is in desired state: Ready
2022-04-06 06:27:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser team-b-client in namespace namespace-97
2022-04-06 06:27:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:27:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: team-b-client will have desired state: Ready
2022-04-06 06:27:07 [main] [32mINFO [m [ResourceManager:444] KafkaUser: team-b-client is in desired state: Ready
2022-04-06 06:27:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic a-topic-my-topic-1405148749-1799590271 in namespace namespace-97
2022-04-06 06:27:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:27:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: a-topic-my-topic-1405148749-1799590271 will have desired state: Ready
2022-04-06 06:27:08 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: a-topic-my-topic-1405148749-1799590271 is in desired state: Ready
2022-04-06 06:27:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-producer-my-cluster-33dee6d9 in namespace namespace-97
2022-04-06 06:27:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:27:08 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-producer-my-cluster-33dee6d9 will be in active state
2022-04-06 06:27:09 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-producer-my-cluster-33dee6d9 to finished
2022-04-06 06:27:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Job team-a-client-consumer-my-cluster-33dee6d9 in namespace namespace-97
2022-04-06 06:27:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-97
2022-04-06 06:27:18 [main] [32mINFO [m [JobUtils:81] Waiting for job: team-a-client-consumer-my-cluster-33dee6d9 will be in active state
2022-04-06 06:27:19 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:team-a-client-consumer-my-cluster-33dee6d9 to finished
2022-04-06 06:27:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:27:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-06 06:27:31 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-b-client in namespace namespace-97
2022-04-06 06:27:31 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Secret team-b-client-secret in namespace namespace-97
2022-04-06 06:27:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Secret team-a-client-secret in namespace namespace-97
2022-04-06 06:27:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-33dee6d9 in namespace namespace-97
2022-04-06 06:27:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-producer-my-cluster-33dee6d9 in namespace namespace-97
2022-04-06 06:27:41 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-a-client in namespace namespace-97
2022-04-06 06:27:41 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Secret sso-x509-https-secret in namespace namespace-97
2022-04-06 06:27:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job team-a-client-consumer-my-cluster-33dee6d9 in namespace namespace-97
2022-04-06 06:27:41 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic a-topic-my-topic-1405148749-1799590271 in namespace namespace-97
2022-04-06 06:27:51 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:27:51 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-97 for test case:testKeycloakAuthorizerToDelegateToSimpleAuthorizer
2022-04-06 06:27:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST.testKeycloakAuthorizerToDelegateToSimpleAuthorizer-FINISHED
2022-04-06 06:27:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:27:56 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 06:28:01 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 06:28:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:28:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:28:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthAuthorizationIsolatedST
2022-04-06 06:28:01 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-a-client in namespace infra-namespace
2022-04-06 06:28:01 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser team-b-client in namespace infra-namespace
2022-04-06 06:28:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-authz-name in namespace infra-namespace
2022-04-06 06:28:01 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 06:28:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:28:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:28:11 [main] [32mINFO [m [ResourceManager:346] In context OauthAuthorizationIsolatedST is everything deleted.
2022-04-06 06:28:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 10, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 1,084.091 s - in io.strimzi.systemtest.security.oauth.OauthAuthorizationIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
2022-04-06 06:28:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 06:28:36 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 06:28:36 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 06:28:36 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 06:28:36 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:28:36 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 06:28:36 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 06:28:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 06:28:36 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 06:28:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 06:28:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:28:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 06:28:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 06:28:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 06:28:36 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:28:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:28:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 06:28:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:28:36 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:28:46 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:28:46 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 06:28:46 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 06:28:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 06:28:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 06:28:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:28:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 06:28:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:28:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 06:28:56 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 06:28:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 06:28:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 06:29:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:29:12 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 06:29:12 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 06:29:12 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 06:29:12 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 06:29:12 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 06:29:13 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 06:29:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:29:13 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 06:29:13 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 06:29:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 06:29:13 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 06:29:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 06:29:13 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 06:29:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 06:29:13 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 06:29:13 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:29:13 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 06:29:13 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 06:29:13 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 06:29:13 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 06:29:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:29:13 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 06:29:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:29:13 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 06:29:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 06:29:28 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 06:29:38 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 06:29:38 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 06:29:38 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-06 06:29:38 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 06:31:07 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 06:31:07 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:31:07 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-06 06:31:07 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-06 06:31:07 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-06 06:31:07 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-06 06:31:07 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-06 06:31:07 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-06 06:31:07 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-06 06:31:07 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-06 06:31:07 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-06 06:31:07 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-06 06:31:07 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-06 06:31:07 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-06 06:31:07 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-06 06:31:07 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-06 06:31:07 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to scope-test realm
2022-04-06 06:31:07 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to scope-test realm
2022-04-06 06:31:07 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to scope-test realm
2022-04-06 06:31:07 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-06 06:31:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-scope-name in namespace infra-namespace
2022-04-06 06:31:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-06 06:32:23 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-06 06:32:23 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:32:23 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetCorrectly-STARTED
2022-04-06 06:32:23 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:32:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-03a33ff9-kafka-clients in namespace infra-namespace
2022-04-06 06:32:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-03a33ff9-kafka-clients will be ready
2022-04-06 06:32:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-03a33ff9-kafka-clients is ready
2022-04-06 06:32:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-03a33ff9-scraper in namespace infra-namespace
2022-04-06 06:32:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-03a33ff9-scraper will be ready
2022-04-06 06:32:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-03a33ff9-scraper is ready
2022-04-06 06:32:25 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-03a33ff9-scraper to be ready
2022-04-06 06:32:35 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-03a33ff9-scraper is ready
2022-04-06 06:32:35 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-03a33ff9-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 06:32:35 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-03a33ff9-allow in namespace infra-namespace
2022-04-06 06:32:35 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 06:32:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-03a33ff9 in namespace infra-namespace
2022-04-06 06:32:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-03a33ff9 will have desired state: Ready
2022-04-06 06:33:46 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-03a33ff9 is in desired state: Ready
2022-04-06 06:33:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:33:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScopeKafkaConnectSetCorrectly
2022-04-06 06:33:46 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-03a33ff9-allow in namespace infra-namespace
2022-04-06 06:33:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-03a33ff9-scraper in namespace infra-namespace
2022-04-06 06:33:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-03a33ff9 in namespace infra-namespace
2022-04-06 06:33:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-03a33ff9-kafka-clients in namespace infra-namespace
2022-04-06 06:34:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:34:36 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetCorrectly-FINISHED
2022-04-06 06:34:36 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:34:36 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:34:36 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetIncorrectly-STARTED
2022-04-06 06:34:36 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:34:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-31bb0f30-kafka-clients in namespace infra-namespace
2022-04-06 06:34:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-31bb0f30-kafka-clients will be ready
2022-04-06 06:34:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-31bb0f30-kafka-clients is ready
2022-04-06 06:34:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-31bb0f30-scraper in namespace infra-namespace
2022-04-06 06:34:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-31bb0f30-scraper will be ready
2022-04-06 06:34:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-31bb0f30-scraper is ready
2022-04-06 06:34:40 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-31bb0f30-scraper to be ready
2022-04-06 06:34:50 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-31bb0f30-scraper is ready
2022-04-06 06:34:50 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-31bb0f30-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 06:34:50 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-31bb0f30-allow in namespace infra-namespace
2022-04-06 06:34:50 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 06:34:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-31bb0f30 in namespace infra-namespace
2022-04-06 06:35:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:35:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScopeKafkaConnectSetIncorrectly
2022-04-06 06:35:04 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-31bb0f30-allow in namespace infra-namespace
2022-04-06 06:35:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-31bb0f30-scraper in namespace infra-namespace
2022-04-06 06:35:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-31bb0f30-kafka-clients in namespace infra-namespace
2022-04-06 06:35:04 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-31bb0f30 in namespace infra-namespace
2022-04-06 06:35:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:35:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testScopeKafkaConnectSetIncorrectly-FINISHED
2022-04-06 06:35:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:35:54 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:35:54 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetCorrectly-STARTED
2022-04-06 06:35:54 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:35:54 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:35:54 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2031063809-1406335937 in namespace infra-namespace
2022-04-06 06:35:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2031063809-1406335937 will have desired state: Ready
2022-04-06 06:35:55 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2031063809-1406335937 is in desired state: Ready
2022-04-06 06:35:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-b03f6324 in namespace infra-namespace
2022-04-06 06:35:55 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-b03f6324 will be in active state
2022-04-06 06:35:56 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-b03f6324 to finished
2022-04-06 06:36:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:36:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientScopeKafkaSetCorrectly
2022-04-06 06:36:04 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-b03f6324 in namespace infra-namespace
2022-04-06 06:36:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2031063809-1406335937 in namespace infra-namespace
2022-04-06 06:36:14 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:36:14 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetCorrectly-FINISHED
2022-04-06 06:36:14 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:36:14 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:36:14 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly-STARTED
2022-04-06 06:36:14 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:36:14 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:36:14 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-scope-name-kafka to be ready
2022-04-06 06:36:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-06 06:36:56 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-06 06:36:56 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-scope-name is ready
2022-04-06 06:36:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1477505961-1105625453 in namespace infra-namespace
2022-04-06 06:36:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1477505961-1105625453 will have desired state: Ready
2022-04-06 06:36:57 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1477505961-1105625453 is in desired state: Ready
2022-04-06 06:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-adefebd0 in namespace infra-namespace
2022-04-06 06:36:57 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-adefebd0 will be in active state
2022-04-06 06:36:58 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:oauth-producer-my-cluster-adefebd0 to finish with failure.
2022-04-06 06:40:38 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 220000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly(OauthScopeIsolatedST.java:224)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 06:40:38 [main] [32mINFO [m [ClientUtils:100] Client job 'oauth-producer-my-cluster-adefebd0' finished with expected timeout.
2022-04-06 06:40:43 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 1 Pod(s) of oauth-cluster-scope-name-kafka to be ready
2022-04-06 06:41:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-scope-name will have desired state: Ready
2022-04-06 06:41:24 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-scope-name is in desired state: Ready
2022-04-06 06:41:24 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: oauth-cluster-scope-name is ready
2022-04-06 06:41:24 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:41:24 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testClientScopeKafkaSetIncorrectly
2022-04-06 06:41:24 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-adefebd0 in namespace infra-namespace
2022-04-06 06:41:24 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1477505961-1105625453 in namespace infra-namespace
2022-04-06 06:41:34 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:41:34 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST.testClientScopeKafkaSetIncorrectly-FINISHED
2022-04-06 06:41:34 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:41:34 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 06:41:38 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 06:41:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:41:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:41:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthScopeIsolatedST
2022-04-06 06:41:38 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-scope-name in namespace infra-namespace
2022-04-06 06:41:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 06:41:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:41:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:41:48 [main] [32mINFO [m [ResourceManager:346] In context OauthScopeIsolatedST is everything deleted.
2022-04-06 06:41:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 817.214 s - in io.strimzi.systemtest.security.oauth.OauthScopeIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
2022-04-06 06:41:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 06:42:13 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 06:42:13 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 06:42:13 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 06:42:13 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:42:13 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 06:42:13 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:13 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 06:42:13 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 06:42:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 06:42:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:42:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 06:42:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:42:13 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:23 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:42:23 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 06:42:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:23 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 06:42:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 06:42:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:42:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 06:42:24 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:42:33 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 06:42:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:42:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 06:42:44 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:42:49 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 06:42:49 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 06:42:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 06:42:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 06:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 06:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 06:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 06:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 06:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:49 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:42:50 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 06:42:50 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:42:50 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 06:42:50 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 06:42:50 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 06:42:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:42:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 06:43:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 06:43:12 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 06:43:22 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 06:43:22 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 06:43:22 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-06 06:43:22 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 06:45:01 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 06:45:01 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:45:01 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-06 06:45:01 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-06 06:45:01 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-06 06:45:01 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-06 06:45:01 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-06 06:45:01 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-06 06:45:01 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-06 06:45:01 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-06 06:45:01 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-06 06:45:01 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-06 06:45:01 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-06 06:45:01 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-06 06:45:01 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-06 06:45:01 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-06 06:45:01 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-06 06:45:01 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-06 06:45:01 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-06 06:45:01 [main] [32mINFO [m [KeycloakInstance:55] Using HTTPS endpoints
2022-04-06 06:45:01 [main] [32mINFO [m [OauthTlsIsolatedST:480] Keycloak settings KeycloakInstance{jwksExpireSeconds=500, jwksRefreshSeconds=400, username='admin', password='VeTAevioeqxiMw==', httpsUri='keycloak.infra-namespace.svc.cluster.local:8443', httpUri='keycloak-discovery.infra-namespace.svc.cluster.local:8080', validIssuerUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal', jwksEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs', oauthTokenEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token', introspectionEndpointUri='https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token/introspect', userNameClaim='preferred_username', keystorePattern=<tls>\s*<key-stores>\s*<key-store name="kcKeyStore">\s*<credential-reference clear-text=".*"\/>, keystorePasswordPattern=\".*\"}
2022-04-06 06:45:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name in namespace infra-namespace
2022-04-06 06:45:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name will have desired state: Ready
2022-04-06 06:46:27 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name is in desired state: Ready
2022-04-06 06:46:27 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser hello-world-producer in namespace infra-namespace
2022-04-06 06:46:27 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: hello-world-producer will have desired state: Ready
2022-04-06 06:46:28 [main] [32mINFO [m [ResourceManager:444] KafkaUser: hello-world-producer is in desired state: Ready
2022-04-06 06:46:28 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:46:28 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerBridge-STARTED
2022-04-06 06:46:28 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:46:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1731461589-965047803 in namespace infra-namespace
2022-04-06 06:46:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1731461589-965047803 will have desired state: Ready
2022-04-06 06:46:29 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1731461589-965047803 is in desired state: Ready
2022-04-06 06:46:29 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:46:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-373b22af in namespace infra-namespace
2022-04-06 06:46:29 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-373b22af will be in active state
2022-04-06 06:46:30 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-373b22af to finished
2022-04-06 06:46:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-373b22af in namespace infra-namespace
2022-04-06 06:46:40 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-373b22af will be in active state
2022-04-06 06:46:41 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-373b22af to finished
2022-04-06 06:46:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-373b22af-kafka-clients in namespace infra-namespace
2022-04-06 06:46:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-373b22af-kafka-clients will be ready
2022-04-06 06:46:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-373b22af-kafka-clients is ready
2022-04-06 06:46:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge oauth-cluster-tls-name in namespace infra-namespace
2022-04-06 06:46:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: oauth-cluster-tls-name will have desired state: Ready
2022-04-06 06:47:21 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: oauth-cluster-tls-name is in desired state: Ready
2022-04-06 06:47:21 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:47:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer-my-cluster-373b22af in namespace infra-namespace
2022-04-06 06:47:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer-my-cluster-373b22af will be in active state
2022-04-06 06:47:22 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:bridge-producer-my-cluster-373b22af to finished
2022-04-06 06:47:40 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:47:40 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerBridge
2022-04-06 06:47:40 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-373b22af-kafka-clients in namespace infra-namespace
2022-04-06 06:47:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-373b22af in namespace infra-namespace
2022-04-06 06:47:40 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1731461589-965047803 in namespace infra-namespace
2022-04-06 06:47:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-373b22af in namespace infra-namespace
2022-04-06 06:47:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer-my-cluster-373b22af in namespace infra-namespace
2022-04-06 06:47:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge oauth-cluster-tls-name in namespace infra-namespace
2022-04-06 06:48:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:48:20 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerBridge-FINISHED
2022-04-06 06:48:20 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:48:20 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:48:20 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumer-STARTED
2022-04-06 06:48:20 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:48:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2045321937-107861725 in namespace infra-namespace
2022-04-06 06:48:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2045321937-107861725 will have desired state: Ready
2022-04-06 06:48:21 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2045321937-107861725 is in desired state: Ready
2022-04-06 06:48:21 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:48:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-3badcbb5 in namespace infra-namespace
2022-04-06 06:48:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-3badcbb5 will be in active state
2022-04-06 06:48:22 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-3badcbb5 to finished
2022-04-06 06:48:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-3badcbb5 in namespace infra-namespace
2022-04-06 06:48:30 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-3badcbb5 will be in active state
2022-04-06 06:48:31 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-3badcbb5 to finished
2022-04-06 06:48:42 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:48:42 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumer
2022-04-06 06:48:42 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-3badcbb5 in namespace infra-namespace
2022-04-06 06:48:42 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-3badcbb5 in namespace infra-namespace
2022-04-06 06:48:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2045321937-107861725 in namespace infra-namespace
2022-04-06 06:48:52 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:48:53 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumer-FINISHED
2022-04-06 06:48:53 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:48:53 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:48:53 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testIntrospectionEndpoint-STARTED
2022-04-06 06:48:53 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:48:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-523832448-2122271519 in namespace infra-namespace
2022-04-06 06:48:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-523832448-2122271519 will have desired state: Ready
2022-04-06 06:48:54 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-523832448-2122271519 is in desired state: Ready
2022-04-06 06:48:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name-intro in namespace infra-namespace
2022-04-06 06:48:54 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name-intro will have desired state: Ready
2022-04-06 06:50:02 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name-intro is in desired state: Ready
2022-04-06 06:50:02 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:50:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-e53d9348 in namespace infra-namespace
2022-04-06 06:50:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-e53d9348 will be in active state
2022-04-06 06:50:03 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-e53d9348 to finished
2022-04-06 06:50:13 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-e53d9348 in namespace infra-namespace
2022-04-06 06:50:13 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-e53d9348 will be in active state
2022-04-06 06:50:14 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-e53d9348 to finished
2022-04-06 06:50:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:50:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIntrospectionEndpoint
2022-04-06 06:50:21 [main] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-e53d9348 in namespace infra-namespace
2022-04-06 06:50:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-e53d9348 in namespace infra-namespace
2022-04-06 06:50:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name-intro in namespace infra-namespace
2022-04-06 06:50:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-523832448-2122271519 in namespace infra-namespace
2022-04-06 06:50:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:50:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testIntrospectionEndpoint-FINISHED
2022-04-06 06:50:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:50:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:50:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerConnect-STARTED
2022-04-06 06:50:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:50:31 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1565852344-388941540 in namespace infra-namespace
2022-04-06 06:50:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1565852344-388941540 will have desired state: Ready
2022-04-06 06:50:32 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1565852344-388941540 is in desired state: Ready
2022-04-06 06:50:32 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:50:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-87abde10 in namespace infra-namespace
2022-04-06 06:50:32 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-87abde10 will be in active state
2022-04-06 06:50:33 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-87abde10 to finished
2022-04-06 06:50:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-87abde10 in namespace infra-namespace
2022-04-06 06:50:41 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-87abde10 will be in active state
2022-04-06 06:50:42 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-87abde10 to finished
2022-04-06 06:50:53 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment oauth-cluster-tls-name-kafka-clients in namespace infra-namespace
2022-04-06 06:50:53 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: oauth-cluster-tls-name-kafka-clients will be ready
2022-04-06 06:50:55 [main] [32mINFO [m [DeploymentUtils:168] Deployment: oauth-cluster-tls-name-kafka-clients is ready
2022-04-06 06:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-87abde10-scraper in namespace infra-namespace
2022-04-06 06:50:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-87abde10-scraper will be ready
2022-04-06 06:50:57 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-87abde10-scraper is ready
2022-04-06 06:50:57 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-87abde10-scraper to be ready
2022-04-06 06:51:07 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-87abde10-scraper is ready
2022-04-06 06:51:07 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-87abde10-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 06:51:07 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-87abde10-allow in namespace infra-namespace
2022-04-06 06:51:07 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 06:51:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-87abde10 in namespace infra-namespace
2022-04-06 06:51:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-87abde10 will have desired state: Ready
2022-04-06 06:52:17 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-87abde10 is in desired state: Ready
2022-04-06 06:52:17 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 06:52:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-87abde10-connect-7db7547c8f-bbk47 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 06:52:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:52:17 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 06:52:17 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec oauth-cluster-tls-name-kafka-clients-8cb45f87d-mrrc5 -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-1565852344-388941540", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-87abde10-connect-api.infra-namespace.svc:8083/connectors
2022-04-06 06:52:17 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:52:17 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-87abde10-connect-7db7547c8f-bbk47
2022-04-06 06:52:21 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-87abde10-connect-7db7547c8f-bbk47
2022-04-06 06:52:21 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:52:21 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-06 06:52:21 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-87abde10-scraper in namespace infra-namespace
2022-04-06 06:52:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-87abde10 in namespace infra-namespace
2022-04-06 06:52:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-87abde10 in namespace infra-namespace
2022-04-06 06:52:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-87abde10-allow in namespace infra-namespace
2022-04-06 06:52:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-87abde10 in namespace infra-namespace
2022-04-06 06:52:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment oauth-cluster-tls-name-kafka-clients in namespace infra-namespace
2022-04-06 06:52:21 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1565852344-388941540 in namespace infra-namespace
2022-04-06 06:53:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:53:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-06 06:53:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:53:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:53:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testMirrorMaker-STARTED
2022-04-06 06:53:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:53:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-731629949-563445483 in namespace infra-namespace
2022-04-06 06:53:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-731629949-563445483 will have desired state: Ready
2022-04-06 06:53:02 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-731629949-563445483 is in desired state: Ready
2022-04-06 06:53:02 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:53:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-740a16aa in namespace infra-namespace
2022-04-06 06:53:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-740a16aa will be in active state
2022-04-06 06:53:03 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-740a16aa to finished
2022-04-06 06:53:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-740a16aa in namespace infra-namespace
2022-04-06 06:53:12 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-740a16aa will be in active state
2022-04-06 06:53:13 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-740a16aa to finished
2022-04-06 06:53:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-tls-name-target in namespace infra-namespace
2022-04-06 06:53:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-tls-name-target will have desired state: Ready
2022-04-06 06:54:41 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-tls-name-target is in desired state: Ready
2022-04-06 06:54:41 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker oauth-cluster-tls-name in namespace infra-namespace
2022-04-06 06:54:41 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: oauth-cluster-tls-name will have desired state: Ready
2022-04-06 06:55:44 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: oauth-cluster-tls-name is in desired state: Ready
2022-04-06 06:55:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-885117958-1248349747 in namespace infra-namespace
2022-04-06 06:55:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-885117958-1248349747 will have desired state: Ready
2022-04-06 06:55:45 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-885117958-1248349747 is in desired state: Ready
2022-04-06 06:55:45 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret my-user-885117958-1248349747
2022-04-06 06:55:45 [main] [32mINFO [m [SecretUtils:50] Secret my-user-885117958-1248349747 created
2022-04-06 06:55:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-885117958-1248349747 will have desired state: Ready
2022-04-06 06:55:45 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-885117958-1248349747 is in desired state: Ready
2022-04-06 06:55:45 [main] [32mINFO [m [OauthTlsIsolatedST:390] Creating new client with new consumer-group and also to point on oauth-cluster-tls-name-target cluster
2022-04-06 06:55:45 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 06:55:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-740a16aa in namespace infra-namespace
2022-04-06 06:55:45 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-740a16aa will be in active state
2022-04-06 06:55:46 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-740a16aa to finished
2022-04-06 06:55:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:55:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker
2022-04-06 06:55:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker oauth-cluster-tls-name in namespace infra-namespace
2022-04-06 06:55:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-740a16aa in namespace infra-namespace
2022-04-06 06:55:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-731629949-563445483 in namespace infra-namespace
2022-04-06 06:55:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-740a16aa in namespace infra-namespace
2022-04-06 06:55:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-740a16aa in namespace infra-namespace
2022-04-06 06:55:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-885117958-1248349747 in namespace infra-namespace
2022-04-06 06:55:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name-target in namespace infra-namespace
2022-04-06 06:56:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:56:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST.testMirrorMaker-FINISHED
2022-04-06 06:56:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 06:56:07 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 06:56:12 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 06:56:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 06:56:12 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:56:12 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthTlsIsolatedST
2022-04-06 06:56:12 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-tls-name in namespace infra-namespace
2022-04-06 06:56:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 06:56:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser hello-world-producer in namespace infra-namespace
2022-04-06 06:56:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:56:22 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:56:22 [main] [32mINFO [m [ResourceManager:346] In context OauthTlsIsolatedST is everything deleted.
2022-04-06 06:56:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 873.989 s - in io.strimzi.systemtest.security.oauth.OauthTlsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
2022-04-06 06:56:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 06:56:47 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 06:56:47 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 06:56:47 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 06:56:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 06:56:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 06:56:47 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 06:56:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 06:56:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 06:56:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 06:56:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 06:56:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:56:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 06:56:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 06:56:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:56:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:56:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 06:56:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:56:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:56:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:56:57 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:56:57 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 06:56:57 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 06:56:57 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 06:56:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 06:56:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:56:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 06:56:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 06:56:57 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 06:57:07 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 06:57:07 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 06:57:18 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 06:57:23 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=120000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 06:57:23 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 06:57:23 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 06:57:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:57:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 06:57:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:57:24 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 06:57:24 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 06:57:24 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 06:57:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 06:57:24 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 06:57:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 06:57:50 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 06:58:00 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 06:58:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 06:58:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaRollsWhenTopicIsUnderReplicated-STARTED
2022-04-06 06:58:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 06:58:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-98 for test case:testKafkaRollsWhenTopicIsUnderReplicated
2022-04-06 06:58:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-98
2022-04-06 06:58:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-98
2022-04-06 06:58:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-98
2022-04-06 06:58:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-83ad132b in namespace namespace-98
2022-04-06 06:58:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-98
2022-04-06 06:58:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-83ad132b will have desired state: Ready
2022-04-06 06:59:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-83ad132b is in desired state: Ready
2022-04-06 06:59:20 [main] [32mINFO [m [KafkaRollerIsolatedST:105] Running kafkaScaleUpScaleDown my-cluster-83ad132b
2022-04-06 06:59:20 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-83ad132b-kafka rolling update
2022-04-06 07:00:40 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-83ad132b-kafka has been successfully rolled
2022-04-06 07:00:40 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 4 Pod(s) of my-cluster-83ad132b-kafka to be ready
2022-04-06 07:01:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-83ad132b will have desired state: Ready
2022-04-06 07:01:25 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-83ad132b is in desired state: Ready
2022-04-06 07:01:25 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-83ad132b is ready
2022-04-06 07:01:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-226315740-1787036818 in namespace namespace-98
2022-04-06 07:01:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-98
2022-04-06 07:01:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-226315740-1787036818 will have desired state: Ready
2022-04-06 07:01:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-226315740-1787036818 is in desired state: Ready
2022-04-06 07:01:26 [main] [32mINFO [m [KafkaRollerIsolatedST:124] Scaling down to 3
2022-04-06 07:01:26 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-83ad132b-kafka rolling update
2022-04-06 07:03:11 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-83ad132b-kafka has been successfully rolled
2022-04-06 07:03:11 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-83ad132b-kafka to be ready
2022-04-06 07:03:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-83ad132b will have desired state: Ready
2022-04-06 07:03:40 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-83ad132b is in desired state: Ready
2022-04-06 07:03:40 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-83ad132b is ready
2022-04-06 07:03:40 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: my-cluster-83ad132b are stable
2022-04-06 07:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:03:40 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 07:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:03:41 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 07:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:03:42 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 07:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:03:43 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 07:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:03:44 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 07:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:03:45 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 07:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:03:46 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 07:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:03:47 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 07:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:03:48 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 07:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:03:49 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 07:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:03:50 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 07:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:03:51 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 07:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:03:52 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 07:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:03:53 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 07:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:03:54 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 07:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:03:55 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 07:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:03:56 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 07:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:03:57 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 07:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:03:58 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 07:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:03:59 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 07:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:04:00 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 07:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:04:01 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 07:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:04:02 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 07:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:04:03 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 07:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:04:04 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 07:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:04:05 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 07:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:04:06 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 07:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:04:07 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 07:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:04:08 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 07:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:04:09 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 07:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:04:10 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 07:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:04:11 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 07:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:04:12 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 07:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:04:13 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 07:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:04:14 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 07:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:04:15 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 07:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:04:16 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 07:04:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:04:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:04:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:04:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:04:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:04:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:04:18 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 07:04:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:04:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:04:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:04:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:04:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:04:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:04:19 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 07:04:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:04:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:04:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:04:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:04:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:04:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:04:20 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 07:04:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:04:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:04:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:04:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:04:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:04:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:04:21 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 07:04:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:04:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:04:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:04:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:04:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:04:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:04:22 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 07:04:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:04:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:04:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:04:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:04:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:04:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:04:23 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 07:04:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:04:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:04:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:04:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:04:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:04:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:04:24 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 07:04:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:04:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:04:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:04:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:04:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:04:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:04:25 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 07:04:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:04:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:04:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:04:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:04:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:04:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:04:26 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 07:04:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:04:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:04:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:04:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:04:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:04:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:04:27 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 07:04:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:04:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:04:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:04:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:04:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:04:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:04:28 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 07:04:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:04:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:04:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:04:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:04:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:04:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:04:29 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 07:04:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:04:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:04:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:04:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-kafka-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:04:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:04:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-1 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:04:30 [main] [32mINFO [m [PodUtils:322] Pod my-cluster-83ad132b-zookeeper-2 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 07:04:30 [main] [32mINFO [m [PodUtils:335] All pods are stable my-cluster-83ad132b-entity-operator-54b65c5756-w8v65 ,my-cluster-83ad132b-kafka-0 ,my-cluster-83ad132b-kafka-1 ,my-cluster-83ad132b-kafka-2 ,my-cluster-83ad132b-zookeeper-0 ,my-cluster-83ad132b-zookeeper-1 ,my-cluster-83ad132b-zookeeper-2
2022-04-06 07:04:30 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-83ad132b-kafka rolling update
2022-04-06 07:05:40 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-83ad132b-kafka has been successfully rolled
2022-04-06 07:05:40 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-83ad132b-kafka to be ready
2022-04-06 07:06:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-83ad132b will have desired state: Ready
2022-04-06 07:06:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-83ad132b is in desired state: Ready
2022-04-06 07:06:05 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-83ad132b is ready
2022-04-06 07:06:05 [main] [32mINFO [m [AbstractST:478] Search in strimzi-cluster-operator log for errors in last 484 seconds
2022-04-06 07:06:05 [main] [32mINFO [m [BaseCmdKubeClient:481] Exception not found
2022-04-06 07:06:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:06:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaRollsWhenTopicIsUnderReplicated
2022-04-06 07:06:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-226315740-1787036818 in namespace namespace-98
2022-04-06 07:06:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-83ad132b in namespace namespace-98
2022-04-06 07:06:15 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:06:15 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-98 for test case:testKafkaRollsWhenTopicIsUnderReplicated
2022-04-06 07:06:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaRollsWhenTopicIsUnderReplicated-FINISHED
2022-04-06 07:06:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:06:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:06:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPendingDueToRack-STARTED
2022-04-06 07:06:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:06:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-99 for test case:testKafkaPodPendingDueToRack
2022-04-06 07:06:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-99
2022-04-06 07:06:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-99
2022-04-06 07:06:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-99
2022-04-06 07:06:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-491cabc5 in namespace namespace-99
2022-04-06 07:06:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-99
2022-04-06 07:06:59 [main] [32mINFO [m [PodUtils:209] Wait until Pod my-cluster-491cabc5-kafka will have stable 3 replicas
2022-04-06 07:06:59 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:00 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:01 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:02 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:03 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:04 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:05 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:06 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:07 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:08 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:09 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:10 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:11 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:12 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:13 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:14 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:15 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:16 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:17 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:18 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:19 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:20 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:21 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:22 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:23 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:24 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:25 [main] [32mINFO [m [PodUtils:221] Pod replicas are not stable. Going to set the counter to zero.
2022-04-06 07:07:26 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 19 polls
2022-04-06 07:07:27 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 18 polls
2022-04-06 07:07:28 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 17 polls
2022-04-06 07:07:29 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 16 polls
2022-04-06 07:07:30 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 15 polls
2022-04-06 07:07:31 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 14 polls
2022-04-06 07:07:32 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 13 polls
2022-04-06 07:07:33 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 12 polls
2022-04-06 07:07:34 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 11 polls
2022-04-06 07:07:35 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 10 polls
2022-04-06 07:07:36 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 9 polls
2022-04-06 07:07:37 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 8 polls
2022-04-06 07:07:38 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 7 polls
2022-04-06 07:07:39 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 6 polls
2022-04-06 07:07:40 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 5 polls
2022-04-06 07:07:41 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 4 polls
2022-04-06 07:07:42 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 3 polls
2022-04-06 07:07:43 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 2 polls
2022-04-06 07:07:44 [main] [32mINFO [m [PodUtils:225] Pod replicas gonna be stable in 1 polls
2022-04-06 07:07:45 [main] [32mINFO [m [PodUtils:217] Pod replicas are stable for 20 polls intervals
2022-04-06 07:07:45 [main] [32mINFO [m [PodUtils:228] Pod my-cluster-491cabc5-kafka has 3 replicas
2022-04-06 07:07:45 [main] [32mINFO [m [KafkaRollerIsolatedST:309] Removing requirement for the affinity
2022-04-06 07:07:45 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-491cabc5 will have desired state: Ready
2022-04-06 07:11:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-491cabc5 is in desired state: Ready
2022-04-06 07:11:29 [main] [32mINFO [m [KafkaUtils:399] Waiting for deletion of Kafka:my-cluster-491cabc5
2022-04-06 07:11:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:11:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodPendingDueToRack
2022-04-06 07:11:30 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-491cabc5 in namespace namespace-99
2022-04-06 07:11:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:11:30 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-99 for test case:testKafkaPodPendingDueToRack
2022-04-06 07:12:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPendingDueToRack-FINISHED
2022-04-06 07:12:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:12:08 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:12:08 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodImagePullBackOff-STARTED
2022-04-06 07:12:08 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:12:08 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-100 for test case:testKafkaPodImagePullBackOff
2022-04-06 07:12:08 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-100
2022-04-06 07:12:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-100
2022-04-06 07:12:08 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-100
2022-04-06 07:12:08 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-8f236ec1 in namespace namespace-100
2022-04-06 07:12:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-100
2022-04-06 07:12:08 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8f236ec1 will have desired state: Ready
2022-04-06 07:13:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8f236ec1 is in desired state: Ready
2022-04-06 07:13:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8f236ec1 will have desired state: NotReady
2022-04-06 07:15:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8f236ec1 is in desired state: NotReady
2022-04-06 07:15:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-8f236ec1 will have desired state: Ready
2022-04-06 07:20:28 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-8f236ec1 is in desired state: Ready
2022-04-06 07:20:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:20:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodImagePullBackOff
2022-04-06 07:20:28 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-8f236ec1 in namespace namespace-100
2022-04-06 07:20:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:20:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-100 for test case:testKafkaPodImagePullBackOff
2022-04-06 07:21:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodImagePullBackOff-FINISHED
2022-04-06 07:21:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:21:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:21:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPending-STARTED
2022-04-06 07:21:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:21:21 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-101 for test case:testKafkaPodPending
2022-04-06 07:21:21 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-101
2022-04-06 07:21:21 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-101
2022-04-06 07:21:21 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-101
2022-04-06 07:21:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5c0e0112 in namespace namespace-101
2022-04-06 07:21:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-101
2022-04-06 07:21:21 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5c0e0112 will have desired state: Ready
2022-04-06 07:22:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5c0e0112 is in desired state: Ready
2022-04-06 07:22:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5c0e0112 will have desired state: NotReady
2022-04-06 07:24:55 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5c0e0112 is in desired state: NotReady
2022-04-06 07:24:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5c0e0112 will have desired state: Ready
2022-04-06 07:26:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5c0e0112 is in desired state: Ready
2022-04-06 07:26:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:26:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodPending
2022-04-06 07:26:57 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5c0e0112 in namespace namespace-101
2022-04-06 07:27:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:27:07 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-101 for test case:testKafkaPodPending
2022-04-06 07:27:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodPending-FINISHED
2022-04-06 07:27:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:27:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:27:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaTopicRFLowerThanMinInSyncReplicas-STARTED
2022-04-06 07:27:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:27:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-102 for test case:testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-06 07:27:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-102
2022-04-06 07:27:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-102
2022-04-06 07:27:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-102
2022-04-06 07:27:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fcb613bb in namespace namespace-102
2022-04-06 07:27:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-102
2022-04-06 07:27:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fcb613bb will have desired state: Ready
2022-04-06 07:29:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fcb613bb is in desired state: Ready
2022-04-06 07:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1173328176-1690426064 in namespace namespace-102
2022-04-06 07:29:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-102
2022-04-06 07:29:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1173328176-1690426064 will have desired state: Ready
2022-04-06 07:29:08 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1173328176-1690426064 is in desired state: Ready
2022-04-06 07:29:08 [main] [32mINFO [m [KafkaRollerIsolatedST:155] Setting KafkaTopic's min.insync.replicas to be higher than replication factor
2022-04-06 07:29:08 [main] [32mINFO [m [KafkaRollerIsolatedST:159] Annotate Kafka StatefulSet my-cluster-fcb613bb-kafka with manual rolling update annotation
2022-04-06 07:29:08 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-fcb613bb-kafka rolling update
2022-04-06 07:30:18 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-fcb613bb-kafka has been successfully rolled
2022-04-06 07:30:18 [main] [32mINFO [m [RollingUpdateUtils:127] Waiting for 3 Pod(s) of my-cluster-fcb613bb-kafka to be ready
2022-04-06 07:30:47 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fcb613bb will have desired state: Ready
2022-04-06 07:30:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fcb613bb is in desired state: Ready
2022-04-06 07:30:47 [main] [32mINFO [m [RollingUpdateUtils:132] Kafka: my-cluster-fcb613bb is ready
2022-04-06 07:30:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:30:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-06 07:30:47 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1173328176-1690426064 in namespace namespace-102
2022-04-06 07:30:47 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fcb613bb in namespace namespace-102
2022-04-06 07:30:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:30:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-102 for test case:testKafkaTopicRFLowerThanMinInSyncReplicas
2022-04-06 07:31:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaTopicRFLowerThanMinInSyncReplicas-FINISHED
2022-04-06 07:31:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:31:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:31:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodCrashLooping-STARTED
2022-04-06 07:31:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:31:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-103 for test case:testKafkaPodCrashLooping
2022-04-06 07:31:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-103
2022-04-06 07:31:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-103
2022-04-06 07:31:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-103
2022-04-06 07:31:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-14e7c5e9 in namespace namespace-103
2022-04-06 07:31:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-103
2022-04-06 07:31:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-14e7c5e9 will have desired state: Ready
2022-04-06 07:32:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-14e7c5e9 is in desired state: Ready
2022-04-06 07:32:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-14e7c5e9 will have desired state: NotReady
2022-04-06 07:34:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-14e7c5e9 is in desired state: NotReady
2022-04-06 07:34:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-14e7c5e9 will have desired state: Ready
2022-04-06 07:40:07 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-14e7c5e9 is in desired state: Ready
2022-04-06 07:40:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:40:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaPodCrashLooping
2022-04-06 07:40:07 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-14e7c5e9 in namespace namespace-103
2022-04-06 07:40:17 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:40:17 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-103 for test case:testKafkaPodCrashLooping
2022-04-06 07:41:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST.testKafkaPodCrashLooping-FINISHED
2022-04-06 07:41:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:41:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:41:00 [main] [32mINFO [m [ResourceManager:346] In context KafkaRollerIsolatedST is everything deleted.
2022-04-06 07:41:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,677.965 s - in io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.connect.ConnectIsolatedST
2022-04-06 07:41:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 07:41:25 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 07:41:25 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 07:41:25 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 07:41:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:41:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 07:41:25 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 07:41:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 07:41:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 07:41:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 07:41:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 07:41:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 07:41:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 07:41:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 07:41:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:41:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 07:41:35 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:41:35 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 07:41:35 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 07:41:35 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 07:41:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 07:41:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 07:41:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 07:41:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 07:41:35 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:41:45 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 07:41:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 07:41:45 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 07:41:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 07:41:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:41:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 07:41:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:42:01 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 07:42:01 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 07:42:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 07:42:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 07:42:01 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:42:02 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 07:42:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 07:42:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 07:42:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 07:42:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 07:42:02 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 07:42:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 07:42:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 07:42:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:42:02 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 07:42:02 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 07:42:02 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 07:42:02 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 07:42:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 07:42:02 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 07:42:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 07:42:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 07:42:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 07:42:33 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 07:42:43 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 07:42:43 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:42:43 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testMultiNodeKafkaConnectWithConnectorCreation-STARTED
2022-04-06 07:42:43 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:42:43 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-104 for test case:testMultiNodeKafkaConnectWithConnectorCreation
2022-04-06 07:42:43 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-104
2022-04-06 07:42:43 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-104
2022-04-06 07:42:43 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-104
2022-04-06 07:42:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b0368d78 in namespace namespace-104
2022-04-06 07:42:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 07:42:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b0368d78 will have desired state: Ready
2022-04-06 07:44:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b0368d78 is in desired state: Ready
2022-04-06 07:44:09 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b0368d78-scraper in namespace namespace-104
2022-04-06 07:44:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 07:44:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b0368d78-scraper will be ready
2022-04-06 07:44:12 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b0368d78-scraper is ready
2022-04-06 07:44:12 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-b0368d78-scraper to be ready
2022-04-06 07:44:22 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-b0368d78-scraper is ready
2022-04-06 07:44:22 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-b0368d78-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 07:44:22 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-b0368d78-allow in namespace namespace-104
2022-04-06 07:44:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 07:44:22 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 07:44:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-b0368d78 in namespace namespace-104
2022-04-06 07:44:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 07:44:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-b0368d78 will have desired state: Ready
2022-04-06 07:45:26 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-b0368d78 is in desired state: Ready
2022-04-06 07:45:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-b0368d78 in namespace namespace-104
2022-04-06 07:45:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 07:45:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-b0368d78 will have desired state: Ready
2022-04-06 07:45:27 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-b0368d78 is in desired state: Ready
2022-04-06 07:45:27 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 07:45:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-104 exec my-cluster-b0368d78-connect-6f5979b4d4-5rccc -- curl -X GET http://localhost:8083/connectors/my-cluster-b0368d78/status
2022-04-06 07:45:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 07:45:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-b0368d78-hello-world-producer in namespace namespace-104
2022-04-06 07:45:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 07:45:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-b0368d78-hello-world-consumer in namespace namespace-104
2022-04-06 07:45:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-104
2022-04-06 07:45:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-b0368d78-hello-world-producer will be in active state
2022-04-06 07:45:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-b0368d78-hello-world-consumer will be in active state
2022-04-06 07:45:28 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-b0368d78-hello-world-producer and consumer my-cluster-b0368d78-hello-world-consumer finish
2022-04-06 07:45:46 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-b0368d78-connect-6f5979b4d4-5rccc
2022-04-06 07:45:46 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-b0368d78-connect-6f5979b4d4-5rccc
2022-04-06 07:45:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:45:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMultiNodeKafkaConnectWithConnectorCreation
2022-04-06 07:45:46 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-b0368d78 in namespace namespace-104
2022-04-06 07:45:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-b0368d78-hello-world-consumer in namespace namespace-104
2022-04-06 07:45:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b0368d78-scraper in namespace namespace-104
2022-04-06 07:45:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-b0368d78 in namespace namespace-104
2022-04-06 07:45:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-b0368d78-hello-world-producer in namespace namespace-104
2022-04-06 07:45:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b0368d78 in namespace namespace-104
2022-04-06 07:45:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-b0368d78-allow in namespace namespace-104
2022-04-06 07:46:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:46:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-104 for test case:testMultiNodeKafkaConnectWithConnectorCreation
2022-04-06 07:46:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testMultiNodeKafkaConnectWithConnectorCreation-FINISHED
2022-04-06 07:46:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:46:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:46:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectScaleUpScaleDown-STARTED
2022-04-06 07:46:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:46:41 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-105 for test case:testKafkaConnectScaleUpScaleDown
2022-04-06 07:46:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-105
2022-04-06 07:46:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-105
2022-04-06 07:46:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-105
2022-04-06 07:46:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-44791db5 in namespace namespace-105
2022-04-06 07:46:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-105
2022-04-06 07:46:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-44791db5 will have desired state: Ready
2022-04-06 07:47:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-44791db5 is in desired state: Ready
2022-04-06 07:47:56 [main] [32mINFO [m [ConnectIsolatedST:395] Running kafkaConnectScaleUP namespace-105 in namespace
2022-04-06 07:47:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-44791db5 in namespace namespace-105
2022-04-06 07:47:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-105
2022-04-06 07:47:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-44791db5 will have desired state: Ready
2022-04-06 07:49:06 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-44791db5 is in desired state: Ready
2022-04-06 07:49:06 [main] [32mINFO [m [ConnectIsolatedST:407] Scaling up to 4
2022-04-06 07:49:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-44791db5-connect will be ready
2022-04-06 07:49:06 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-44791db5-connect is ready
2022-04-06 07:49:06 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-44791db5-connect to be ready
2022-04-06 07:50:25 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-44791db5-connect is ready
2022-04-06 07:50:25 [main] [32mINFO [m [ConnectIsolatedST:414] Scaling down to 1
2022-04-06 07:50:25 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-44791db5-connect will be ready
2022-04-06 07:50:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-44791db5-connect is ready
2022-04-06 07:50:25 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-44791db5-connect to be ready
2022-04-06 07:50:47 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-44791db5-connect is ready
2022-04-06 07:50:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:50:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectScaleUpScaleDown
2022-04-06 07:50:47 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-44791db5 in namespace namespace-105
2022-04-06 07:50:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-44791db5 in namespace namespace-105
2022-04-06 07:50:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:50:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-105 for test case:testKafkaConnectScaleUpScaleDown
2022-04-06 07:51:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectScaleUpScaleDown-FINISHED
2022-04-06 07:51:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:51:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:51:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectAndConnectorSubresource-STARTED
2022-04-06 07:51:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:51:41 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-106 for test case:testScaleConnectAndConnectorSubresource
2022-04-06 07:51:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-106
2022-04-06 07:51:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-106
2022-04-06 07:51:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-106
2022-04-06 07:51:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-918268de in namespace namespace-106
2022-04-06 07:51:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-06 07:51:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-918268de will have desired state: Ready
2022-04-06 07:52:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-918268de is in desired state: Ready
2022-04-06 07:52:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-918268de in namespace namespace-106
2022-04-06 07:52:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-06 07:52:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-918268de will have desired state: Ready
2022-04-06 07:54:08 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-918268de is in desired state: Ready
2022-04-06 07:54:08 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-918268de in namespace namespace-106
2022-04-06 07:54:08 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-106
2022-04-06 07:54:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-918268de will have desired state: Ready
2022-04-06 07:54:09 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-918268de is in desired state: Ready
2022-04-06 07:54:09 [main] [32mINFO [m [ConnectIsolatedST:979] -------> Scaling KafkaConnect subresource <-------
2022-04-06 07:54:09 [main] [32mINFO [m [ConnectIsolatedST:980] Scaling subresource replicas to 4
2022-04-06 07:54:09 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-918268de-connect will be ready
2022-04-06 07:54:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-918268de-connect is ready
2022-04-06 07:54:09 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-918268de-connect to be ready
2022-04-06 07:55:29 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-918268de-connect is ready
2022-04-06 07:55:29 [main] [32mINFO [m [ConnectIsolatedST:984] Check if replicas is set to 4, observed generation is higher - for spec and status - naming prefix should be same
2022-04-06 07:55:29 [main] [32mINFO [m [ConnectIsolatedST:998] -------> Scaling KafkaConnector subresource <-------
2022-04-06 07:55:29 [main] [32mINFO [m [ConnectIsolatedST:999] Scaling subresource task max to 4
2022-04-06 07:55:30 [main] [32mINFO [m [ConnectIsolatedST:1003] Check if taskMax is set to 4
2022-04-06 07:55:30 [main] [32mINFO [m [ConnectIsolatedST:1007] Check taskMax on Connect pods API
2022-04-06 07:55:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-918268de-connect-5cc9bd7658-b8j4g -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-918268de
2022-04-06 07:55:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 07:55:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-918268de-connect-5cc9bd7658-bnhcb -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-918268de
2022-04-06 07:55:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 07:55:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-918268de-connect-5cc9bd7658-bthnh -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-918268de
2022-04-06 07:55:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 07:55:31 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-106 exec my-cluster-918268de-connect-5cc9bd7658-frqd8 -- /bin/bash -c curl http://localhost:8083/connectors/my-cluster-918268de
2022-04-06 07:55:31 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 07:55:31 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 07:55:31 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectAndConnectorSubresource
2022-04-06 07:55:31 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-918268de in namespace namespace-106
2022-04-06 07:55:31 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-918268de in namespace namespace-106
2022-04-06 07:55:31 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-918268de in namespace namespace-106
2022-04-06 07:55:41 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 07:55:41 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-106 for test case:testScaleConnectAndConnectorSubresource
2022-04-06 07:56:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectAndConnectorSubresource-FINISHED
2022-04-06 07:56:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 07:56:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 07:56:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin-STARTED
2022-04-06 07:56:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 07:56:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-107 for test case:testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-06 07:56:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-107
2022-04-06 07:56:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-107
2022-04-06 07:56:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-107
2022-04-06 07:56:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-eaf0d24a in namespace namespace-107
2022-04-06 07:56:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 07:56:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-eaf0d24a will have desired state: Ready
2022-04-06 07:57:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-eaf0d24a is in desired state: Ready
2022-04-06 07:57:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1171554158-1594950986 in namespace namespace-107
2022-04-06 07:57:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 07:57:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1171554158-1594950986 will have desired state: Ready
2022-04-06 07:57:43 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1171554158-1594950986 is in desired state: Ready
2022-04-06 07:57:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-eaf0d24a-scraper in namespace namespace-107
2022-04-06 07:57:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 07:57:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-eaf0d24a-scraper will be ready
2022-04-06 07:57:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-eaf0d24a-scraper is ready
2022-04-06 07:57:45 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-eaf0d24a-scraper to be ready
2022-04-06 07:57:55 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-eaf0d24a-scraper is ready
2022-04-06 07:57:55 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-eaf0d24a-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 07:57:55 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-eaf0d24a-allow in namespace namespace-107
2022-04-06 07:57:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 07:57:55 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 07:57:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-eaf0d24a in namespace namespace-107
2022-04-06 07:57:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 07:57:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-eaf0d24a will have desired state: Ready
2022-04-06 07:59:04 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-eaf0d24a is in desired state: Ready
2022-04-06 07:59:04 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 07:59:05 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-107 exec my-cluster-eaf0d24a-connect-64fbfcc44-9l29j -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 07:59:05 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 07:59:05 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 07:59:05 [main] [32mINFO [m [ConnectIsolatedST:181] Creating KafkaConnector with 'pause: true'
2022-04-06 07:59:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-eaf0d24a in namespace namespace-107
2022-04-06 07:59:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 07:59:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-eaf0d24a will have desired state: Ready
2022-04-06 07:59:06 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-eaf0d24a is in desired state: Ready
2022-04-06 07:59:06 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 07:59:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-eaf0d24a-hello-world-producer in namespace namespace-107
2022-04-06 07:59:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 07:59:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-eaf0d24a-hello-world-consumer in namespace namespace-107
2022-04-06 07:59:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 07:59:06 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-eaf0d24a-hello-world-producer will be in active state
2022-04-06 07:59:07 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-eaf0d24a-hello-world-consumer will be in active state
2022-04-06 07:59:07 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-eaf0d24a-hello-world-producer and consumer my-cluster-eaf0d24a-hello-world-consumer finish
2022-04-06 07:59:18 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-eaf0d24a-connect-64fbfcc44-9l29j
2022-04-06 07:59:18 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-eaf0d24a-connect-64fbfcc44-9l29j
2022-04-06 07:59:18 [main] [32mINFO [m [ConnectIsolatedST:207] Pausing KafkaConnector: my-cluster-eaf0d24a
2022-04-06 07:59:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-eaf0d24a will have desired state: Ready
2022-04-06 07:59:18 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-eaf0d24a is in desired state: Ready
2022-04-06 07:59:18 [main] [32mINFO [m [ConnectIsolatedST:213] Clearing FileSink file to check if KafkaConnector will be really paused
2022-04-06 07:59:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-107 exec my-cluster-eaf0d24a-connect-64fbfcc44-9l29j -- /bin/bash -c truncate -s 0 /tmp/test-file-sink.txt
2022-04-06 07:59:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 07:59:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-eaf0d24a-hello-world-producer in namespace namespace-107
2022-04-06 07:59:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 07:59:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-eaf0d24a-hello-world-consumer in namespace namespace-107
2022-04-06 07:59:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-107
2022-04-06 07:59:18 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-eaf0d24a-hello-world-producer will be in active state
2022-04-06 07:59:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-eaf0d24a-hello-world-consumer will be in active state
2022-04-06 07:59:19 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-eaf0d24a-hello-world-producer and consumer my-cluster-eaf0d24a-hello-world-consumer finish
2022-04-06 08:00:09 [main] [32mINFO [m [ConnectIsolatedST:219] Because KafkaConnector is paused, no messages should appear to FileSink file
2022-04-06 08:00:09 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-eaf0d24a-connect-64fbfcc44-9l29j
io.strimzi.test.WaitException: Timeout after 60000 ms waiting for messages in file sink
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(KafkaConnectUtils.java:75)
	at io.strimzi.systemtest.connect.ConnectIsolatedST.lambda$testKafkaConnectAndPausedConnectorWithFileSinkPlugin$1(ConnectIsolatedST.java:220)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:55)
	at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:37)
	at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3082)
	at io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin(ConnectIsolatedST.java:220)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 08:01:09 [main] [32mINFO [m [ConnectIsolatedST:222] Unpausing KafkaConnector, messages should again appear to FileSink file
2022-04-06 08:01:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-eaf0d24a will have desired state: Ready
2022-04-06 08:01:09 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-eaf0d24a is in desired state: Ready
2022-04-06 08:01:09 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-eaf0d24a-connect-64fbfcc44-9l29j
2022-04-06 08:01:09 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-eaf0d24a-connect-64fbfcc44-9l29j
2022-04-06 08:01:09 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:01:09 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-06 08:01:09 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-eaf0d24a-hello-world-producer in namespace namespace-107
2022-04-06 08:01:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-eaf0d24a-hello-world-producer in namespace namespace-107
2022-04-06 08:01:09 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-eaf0d24a-scraper in namespace namespace-107
2022-04-06 08:01:09 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1171554158-1594950986 in namespace namespace-107
2022-04-06 08:01:09 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-eaf0d24a in namespace namespace-107
2022-04-06 08:01:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-eaf0d24a-hello-world-consumer in namespace namespace-107
2022-04-06 08:01:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-eaf0d24a-hello-world-consumer in namespace namespace-107
2022-04-06 08:01:09 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-eaf0d24a in namespace namespace-107
2022-04-06 08:01:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-eaf0d24a in namespace namespace-107
2022-04-06 08:01:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-eaf0d24a-allow in namespace namespace-107
2022-04-06 08:01:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:01:59 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-107 for test case:testKafkaConnectAndPausedConnectorWithFileSinkPlugin
2022-04-06 08:02:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndPausedConnectorWithFileSinkPlugin-FINISHED
2022-04-06 08:02:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:02:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:02:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged-STARTED
2022-04-06 08:02:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:02:05 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-108 for test case:testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-06 08:02:05 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-108
2022-04-06 08:02:05 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-108
2022-04-06 08:02:05 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-108
2022-04-06 08:02:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-41e905f9 in namespace namespace-108
2022-04-06 08:02:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-06 08:02:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-41e905f9 will have desired state: Ready
2022-04-06 08:03:12 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-41e905f9 is in desired state: Ready
2022-04-06 08:03:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1592695843-1095535264 in namespace namespace-108
2022-04-06 08:03:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-06 08:03:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1592695843-1095535264 will have desired state: Ready
2022-04-06 08:03:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1592695843-1095535264 is in desired state: Ready
2022-04-06 08:03:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1592695843-1095535264 in namespace namespace-108
2022-04-06 08:03:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-06 08:03:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1592695843-1095535264 will have desired state: Ready
2022-04-06 08:03:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1592695843-1095535264 is in desired state: Ready
2022-04-06 08:03:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-869964902-544974452 in namespace namespace-108
2022-04-06 08:03:13 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-06 08:03:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-869964902-544974452 will have desired state: Ready
2022-04-06 08:03:14 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-869964902-544974452 is in desired state: Ready
2022-04-06 08:03:14 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-41e905f9 in namespace namespace-108
2022-04-06 08:03:14 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-06 08:03:14 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-41e905f9 will have desired state: Ready
2022-04-06 08:04:17 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-41e905f9 is in desired state: Ready
2022-04-06 08:04:17 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 08:04:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-108 exec my-cluster-41e905f9-connect-5f7dbffc56-lcpzs -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 08:04:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:04:18 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 08:04:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1592695843-1095535264 in namespace namespace-108
2022-04-06 08:04:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-108
2022-04-06 08:04:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1592695843-1095535264 will have desired state: Ready
2022-04-06 08:04:18 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1592695843-1095535264 is in desired state: Ready
2022-04-06 08:04:18 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-41e905f9-connect rolling update
2022-04-06 08:05:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-41e905f9-connect will be ready
2022-04-06 08:05:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-41e905f9-connect is ready
2022-04-06 08:06:08 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-41e905f9-connect rolling update finished
2022-04-06 08:06:08 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 08:06:08 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-108 exec my-cluster-41e905f9-connect-57ffdcc9c7-29h99 -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 08:06:08 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:06:08 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 08:06:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:06:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-06 08:06:08 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-869964902-544974452 in namespace namespace-108
2022-04-06 08:06:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1592695843-1095535264 in namespace namespace-108
2022-04-06 08:06:08 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1592695843-1095535264 in namespace namespace-108
2022-04-06 08:06:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-41e905f9 in namespace namespace-108
2022-04-06 08:06:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1592695843-1095535264 in namespace namespace-108
2022-04-06 08:06:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-41e905f9 in namespace namespace-108
2022-04-06 08:06:28 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:06:28 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-108 for test case:testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged
2022-04-06 08:07:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithScramShaAuthenticationRolledAfterPasswordChanged-FINISHED
2022-04-06 08:07:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:07:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:07:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication-STARTED
2022-04-06 08:07:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:07:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-109 for test case:testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-06 08:07:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-109
2022-04-06 08:07:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-109
2022-04-06 08:07:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-109
2022-04-06 08:07:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2e3f564e in namespace namespace-109
2022-04-06 08:07:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:07:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2e3f564e will have desired state: Ready
2022-04-06 08:08:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2e3f564e is in desired state: Ready
2022-04-06 08:08:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-2e3f564e-user in namespace namespace-109
2022-04-06 08:08:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:08:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-2e3f564e-user will have desired state: Ready
2022-04-06 08:08:25 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-2e3f564e-user is in desired state: Ready
2022-04-06 08:08:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1090386333-924887019 in namespace namespace-109
2022-04-06 08:08:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:08:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1090386333-924887019 will have desired state: Ready
2022-04-06 08:08:26 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1090386333-924887019 is in desired state: Ready
2022-04-06 08:08:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-2e3f564e-scraper in namespace namespace-109
2022-04-06 08:08:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:08:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-2e3f564e-scraper will be ready
2022-04-06 08:08:28 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-2e3f564e-scraper is ready
2022-04-06 08:08:28 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-2e3f564e-scraper to be ready
2022-04-06 08:08:38 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-2e3f564e-scraper is ready
2022-04-06 08:08:38 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-2e3f564e-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:08:38 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-2e3f564e-allow in namespace namespace-109
2022-04-06 08:08:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:08:38 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:08:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-2e3f564e in namespace namespace-109
2022-04-06 08:08:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:08:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-2e3f564e will have desired state: Ready
2022-04-06 08:09:46 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-2e3f564e is in desired state: Ready
2022-04-06 08:09:46 [main] [32mINFO [m [ConnectIsolatedST:547] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-06 08:09:46 [main] [32mINFO [m [ConnectIsolatedST:550] Creating FileStreamSink connector via pod my-cluster-2e3f564e-scraper-65b94684-bhwkp with topic my-topic-1090386333-924887019
2022-04-06 08:09:47 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-109 exec my-cluster-2e3f564e-scraper-65b94684-bhwkp -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-1090386333-924887019", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-2e3f564e-connect-api.namespace-109.svc:8083/connectors
2022-04-06 08:09:47 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:09:47 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 08:09:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-2e3f564e-hello-world-producer in namespace namespace-109
2022-04-06 08:09:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:09:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-2e3f564e-hello-world-consumer in namespace namespace-109
2022-04-06 08:09:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-109
2022-04-06 08:09:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-2e3f564e-hello-world-producer will be in active state
2022-04-06 08:09:48 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-2e3f564e-hello-world-consumer will be in active state
2022-04-06 08:09:48 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-2e3f564e-hello-world-producer and consumer my-cluster-2e3f564e-hello-world-consumer finish
2022-04-06 08:10:05 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-2e3f564e-connect-5c47b8d67b-mbhb9
2022-04-06 08:10:05 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-2e3f564e-connect-5c47b8d67b-mbhb9
2022-04-06 08:10:05 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:10:05 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-06 08:10:05 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-2e3f564e in namespace namespace-109
2022-04-06 08:10:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-2e3f564e-hello-world-consumer in namespace namespace-109
2022-04-06 08:10:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1090386333-924887019 in namespace namespace-109
2022-04-06 08:10:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-2e3f564e-user in namespace namespace-109
2022-04-06 08:10:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-2e3f564e-hello-world-producer in namespace namespace-109
2022-04-06 08:10:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-2e3f564e-allow in namespace namespace-109
2022-04-06 08:10:05 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2e3f564e in namespace namespace-109
2022-04-06 08:10:15 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-2e3f564e-scraper in namespace namespace-109
2022-04-06 08:10:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:10:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-109 for test case:testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication
2022-04-06 08:11:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication-FINISHED
2022-04-06 08:11:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:11:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:11:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-06 08:11:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:11:01 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-110 for test case:testConfigureDeploymentStrategy
2022-04-06 08:11:01 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-110
2022-04-06 08:11:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-110
2022-04-06 08:11:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-110
2022-04-06 08:11:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7852056e in namespace namespace-110
2022-04-06 08:11:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-110
2022-04-06 08:11:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7852056e will have desired state: Ready
2022-04-06 08:12:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7852056e is in desired state: Ready
2022-04-06 08:12:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-7852056e in namespace namespace-110
2022-04-06 08:12:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-110
2022-04-06 08:12:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-7852056e will have desired state: Ready
2022-04-06 08:13:27 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-7852056e is in desired state: Ready
2022-04-06 08:13:27 [main] [32mINFO [m [ConnectIsolatedST:1191] Adding label to Connect resource, the CR should be recreated
2022-04-06 08:13:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7852056e-connect will be ready
2022-04-06 08:13:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7852056e-connect is ready
2022-04-06 08:13:27 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-7852056e-connect to be ready
2022-04-06 08:14:54 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-7852056e-connect is ready
2022-04-06 08:14:54 [main] [32mINFO [m [ConnectIsolatedST:1198] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-06 08:14:54 [main] [32mINFO [m [ConnectIsolatedST:1203] Changing deployment strategy to ROLLING_UPDATE
2022-04-06 08:14:54 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-7852056e will have desired state: Ready
2022-04-06 08:14:54 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-7852056e is in desired state: Ready
2022-04-06 08:14:54 [main] [32mINFO [m [ConnectIsolatedST:1208] Adding another label to Connect resource, pods should be rolled
2022-04-06 08:14:54 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7852056e-connect will be ready
2022-04-06 08:14:54 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7852056e-connect is ready
2022-04-06 08:14:54 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-7852056e-connect to be ready
2022-04-06 08:16:16 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-7852056e-connect is ready
2022-04-06 08:16:16 [main] [32mINFO [m [ConnectIsolatedST:1212] Checking that observed gen. higher (rolling update) and label is changed
2022-04-06 08:16:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:16:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-06 08:16:16 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-7852056e in namespace namespace-110
2022-04-06 08:16:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7852056e in namespace namespace-110
2022-04-06 08:16:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:16:26 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-110 for test case:testConfigureDeploymentStrategy
2022-04-06 08:17:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-06 08:17:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:17:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:17:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndConnectorFileSinkPlugin-STARTED
2022-04-06 08:17:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:17:07 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-111 for test case:testKafkaConnectAndConnectorFileSinkPlugin
2022-04-06 08:17:07 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-111
2022-04-06 08:17:07 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-111
2022-04-06 08:17:07 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-111
2022-04-06 08:17:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-fa18e1f8 in namespace namespace-111
2022-04-06 08:17:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-06 08:17:07 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-fa18e1f8 will have desired state: Ready
2022-04-06 08:18:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-fa18e1f8 is in desired state: Ready
2022-04-06 08:18:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-fa18e1f8-scraper in namespace namespace-111
2022-04-06 08:18:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-06 08:18:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-fa18e1f8-scraper will be ready
2022-04-06 08:18:25 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-fa18e1f8-scraper is ready
2022-04-06 08:18:25 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-fa18e1f8-scraper to be ready
2022-04-06 08:18:35 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-fa18e1f8-scraper is ready
2022-04-06 08:18:35 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-fa18e1f8-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:18:35 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-fa18e1f8-allow in namespace namespace-111
2022-04-06 08:18:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-06 08:18:35 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:18:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-fa18e1f8 in namespace namespace-111
2022-04-06 08:18:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-06 08:18:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-fa18e1f8 will have desired state: Ready
2022-04-06 08:19:46 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-fa18e1f8 is in desired state: Ready
2022-04-06 08:19:46 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector license-source in namespace namespace-111
2022-04-06 08:19:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-06 08:19:46 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: license-source will have desired state: Ready
2022-04-06 08:19:47 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: license-source is in desired state: Ready
2022-04-06 08:19:47 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 08:19:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-fa18e1f8-hello-world-consumer in namespace namespace-111
2022-04-06 08:19:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-111
2022-04-06 08:19:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-fa18e1f8-hello-world-consumer will be in active state
2022-04-06 08:19:48 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-fa18e1f8-hello-world-consumer to finished
2022-04-06 08:19:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-111 exec my-cluster-fa18e1f8-scraper-775c579459-qwcg9 -- /bin/bash -c curl http://my-cluster-fa18e1f8-connect-api.namespace-111.svc:8083/connectors/license-source
2022-04-06 08:19:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:19:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:19:59 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectAndConnectorFileSinkPlugin
2022-04-06 08:19:59 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-fa18e1f8 in namespace namespace-111
2022-04-06 08:19:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-fa18e1f8-hello-world-consumer in namespace namespace-111
2022-04-06 08:19:59 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-fa18e1f8-scraper in namespace namespace-111
2022-04-06 08:19:59 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector license-source in namespace namespace-111
2022-04-06 08:19:59 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-fa18e1f8 in namespace namespace-111
2022-04-06 08:20:09 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-fa18e1f8-allow in namespace namespace-111
2022-04-06 08:20:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:20:49 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-111 for test case:testKafkaConnectAndConnectorFileSinkPlugin
2022-04-06 08:20:55 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectAndConnectorFileSinkPlugin-FINISHED
2022-04-06 08:20:55 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:20:55 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:20:55 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testDeployUndeploy-STARTED
2022-04-06 08:20:55 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:20:55 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-112 for test case:testDeployUndeploy
2022-04-06 08:20:55 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-112
2022-04-06 08:20:55 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-112
2022-04-06 08:20:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-112
2022-04-06 08:20:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c08a72b6 in namespace namespace-112
2022-04-06 08:20:55 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-06 08:20:55 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c08a72b6 will have desired state: Ready
2022-04-06 08:22:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c08a72b6 is in desired state: Ready
2022-04-06 08:22:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c08a72b6-scraper in namespace namespace-112
2022-04-06 08:22:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-06 08:22:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c08a72b6-scraper will be ready
2022-04-06 08:22:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c08a72b6-scraper is ready
2022-04-06 08:22:18 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-c08a72b6-scraper to be ready
2022-04-06 08:22:28 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-c08a72b6-scraper is ready
2022-04-06 08:22:28 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-c08a72b6-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:22:28 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-c08a72b6-allow in namespace namespace-112
2022-04-06 08:22:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-06 08:22:28 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:22:28 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-c08a72b6 in namespace namespace-112
2022-04-06 08:22:28 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-112
2022-04-06 08:22:28 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-c08a72b6 will have desired state: Ready
2022-04-06 08:23:30 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-c08a72b6 is in desired state: Ready
2022-04-06 08:23:30 [main] [32mINFO [m [ConnectIsolatedST:123] Looks like the connect cluster my-cluster deployed OK
2022-04-06 08:23:30 [main] [32mINFO [m [ConnectIsolatedST:140] Verifying docker image names
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-06 08:23:30 [main] [32mINFO [m [ConnectIsolatedST:152] Docker images verified
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type connect
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-c08a72b6-connect-59d8dfb4d-pftms
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:362] Verifying labels for service my-cluster-c08a72b6-connect-api
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-c08a72b6-connect-config
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-c08a72b6-entity-topic-operator-config
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:407] CM my-cluster-c08a72b6-entity-topic-operator-config is not related to current test
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-c08a72b6-entity-user-operator-config
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:407] CM my-cluster-c08a72b6-entity-user-operator-config is not related to current test
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-c08a72b6-kafka-config
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-c08a72b6-zookeeper-config
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:407] CM my-cluster-c08a72b6-zookeeper-config is not related to current test
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-c08a72b6-connect
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-c08a72b6-entity-operator
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-c08a72b6-kafka
2022-04-06 08:23:30 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-c08a72b6-zookeeper
2022-04-06 08:23:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:23:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testDeployUndeploy
2022-04-06 08:23:30 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-c08a72b6-allow in namespace namespace-112
2022-04-06 08:23:30 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-c08a72b6 in namespace namespace-112
2022-04-06 08:23:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c08a72b6-scraper in namespace namespace-112
2022-04-06 08:23:30 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c08a72b6 in namespace namespace-112
2022-04-06 08:24:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:24:21 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-112 for test case:testDeployUndeploy
2022-04-06 08:24:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testDeployUndeploy-FINISHED
2022-04-06 08:24:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:24:26 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:24:26 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testMountingSecretAndConfigMapAsVolumesAndEnvVars-STARTED
2022-04-06 08:24:26 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:24:26 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-113 for test case:testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-06 08:24:26 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-113
2022-04-06 08:24:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-113
2022-04-06 08:24:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-113
2022-04-06 08:24:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7afb2436 in namespace namespace-113
2022-04-06 08:24:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-113
2022-04-06 08:24:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7afb2436 will have desired state: Ready
2022-04-06 08:25:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7afb2436 is in desired state: Ready
2022-04-06 08:25:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-7afb2436 in namespace namespace-113
2022-04-06 08:25:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-113
2022-04-06 08:25:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-7afb2436 will have desired state: Ready
2022-04-06 08:26:56 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-7afb2436 is in desired state: Ready
2022-04-06 08:26:56 [main] [32mINFO [m [ConnectIsolatedST:1148] Check if the ENVs contains desired values
2022-04-06 08:26:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-7afb2436-connect-cdbfdddbd-mtkrz -- /bin/bash -c printenv MY_CONNECT_SECRET
2022-04-06 08:26:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:26:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-7afb2436-connect-cdbfdddbd-mtkrz -- /bin/bash -c printenv MY_CONNECT_CONFIG_MAP
2022-04-06 08:26:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:26:56 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-7afb2436-connect-cdbfdddbd-mtkrz -- /bin/bash -c printenv MY_DOTED_CONNECT_SECRET
2022-04-06 08:26:56 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:26:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-7afb2436-connect-cdbfdddbd-mtkrz -- /bin/bash -c printenv MY_DOTED_CONNECT_CONFIG_MAP
2022-04-06 08:26:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:26:57 [main] [32mINFO [m [ConnectIsolatedST:1154] Check if volumes contains desired values
2022-04-06 08:26:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-7afb2436-connect-cdbfdddbd-mtkrz -- /bin/bash -c cat external-configuration/connect-config-map/my-key
2022-04-06 08:26:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:26:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-7afb2436-connect-cdbfdddbd-mtkrz -- /bin/bash -c cat external-configuration/connect-secret/my-secret-key
2022-04-06 08:26:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:26:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-7afb2436-connect-cdbfdddbd-mtkrz -- /bin/bash -c cat external-configuration/connect.config.map/my-key
2022-04-06 08:26:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:26:57 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-113 exec my-cluster-7afb2436-connect-cdbfdddbd-mtkrz -- /bin/bash -c cat external-configuration/connect.secret/my-secret-key
2022-04-06 08:26:57 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:26:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:26:57 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-06 08:26:57 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-7afb2436 in namespace namespace-113
2022-04-06 08:26:57 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7afb2436 in namespace namespace-113
2022-04-06 08:27:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:27:07 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-113 for test case:testMountingSecretAndConfigMapAsVolumesAndEnvVars
2022-04-06 08:27:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testMountingSecretAndConfigMapAsVolumesAndEnvVars-FINISHED
2022-04-06 08:27:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:27:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:27:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testJvmAndResources-STARTED
2022-04-06 08:27:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:27:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-114 for test case:testJvmAndResources
2022-04-06 08:27:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-114
2022-04-06 08:27:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-114
2022-04-06 08:27:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-114
2022-04-06 08:27:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-1a4eafd0 in namespace namespace-114
2022-04-06 08:27:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-06 08:27:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-1a4eafd0 will have desired state: Ready
2022-04-06 08:29:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-1a4eafd0 is in desired state: Ready
2022-04-06 08:29:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1a4eafd0-kafka-clients in namespace namespace-114
2022-04-06 08:29:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-06 08:29:05 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1a4eafd0-kafka-clients will be ready
2022-04-06 08:29:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1a4eafd0-kafka-clients is ready
2022-04-06 08:29:07 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-1a4eafd0-scraper in namespace namespace-114
2022-04-06 08:29:07 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-06 08:29:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-1a4eafd0-scraper will be ready
2022-04-06 08:29:09 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-1a4eafd0-scraper is ready
2022-04-06 08:29:09 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-1a4eafd0-scraper to be ready
2022-04-06 08:29:19 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-1a4eafd0-scraper is ready
2022-04-06 08:29:19 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-1a4eafd0-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:29:19 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-1a4eafd0-allow in namespace namespace-114
2022-04-06 08:29:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-06 08:29:19 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:29:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-1a4eafd0 in namespace namespace-114
2022-04-06 08:29:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-114
2022-04-06 08:29:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-1a4eafd0 will have desired state: Ready
2022-04-06 08:30:29 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-1a4eafd0 is in desired state: Ready
2022-04-06 08:30:30 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-114 exec my-cluster-1a4eafd0-connect-6fd55db8c7-lz7w7 -c my-cluster-1a4eafd0-connect -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-06 08:30:30 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:30:30 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:30:30 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testJvmAndResources
2022-04-06 08:30:30 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1a4eafd0-scraper in namespace namespace-114
2022-04-06 08:30:30 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-1a4eafd0 in namespace namespace-114
2022-04-06 08:30:30 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-1a4eafd0-kafka-clients in namespace namespace-114
2022-04-06 08:30:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-1a4eafd0 in namespace namespace-114
2022-04-06 08:30:40 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-1a4eafd0-allow in namespace namespace-114
2022-04-06 08:31:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:31:20 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-114 for test case:testJvmAndResources
2022-04-06 08:31:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testJvmAndResources-FINISHED
2022-04-06 08:31:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:31:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:31:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication-STARTED
2022-04-06 08:31:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:31:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-115 for test case:testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-06 08:31:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-115
2022-04-06 08:31:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-115
2022-04-06 08:31:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-115
2022-04-06 08:31:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-58d5bcc6 in namespace namespace-115
2022-04-06 08:31:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:31:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-58d5bcc6 will have desired state: Ready
2022-04-06 08:32:47 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-58d5bcc6 is in desired state: Ready
2022-04-06 08:32:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-58d5bcc6-user in namespace namespace-115
2022-04-06 08:32:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:32:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-58d5bcc6-user will have desired state: Ready
2022-04-06 08:32:48 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-58d5bcc6-user is in desired state: Ready
2022-04-06 08:32:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2095242365-2012140611 in namespace namespace-115
2022-04-06 08:32:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:32:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2095242365-2012140611 will have desired state: Ready
2022-04-06 08:32:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2095242365-2012140611 is in desired state: Ready
2022-04-06 08:32:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-58d5bcc6-scraper in namespace namespace-115
2022-04-06 08:32:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:32:49 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-58d5bcc6-scraper will be ready
2022-04-06 08:32:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-58d5bcc6-scraper is ready
2022-04-06 08:32:50 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-58d5bcc6-scraper to be ready
2022-04-06 08:33:00 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-58d5bcc6-scraper is ready
2022-04-06 08:33:00 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-58d5bcc6-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:33:00 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-58d5bcc6-allow in namespace namespace-115
2022-04-06 08:33:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:33:00 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:33:00 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-58d5bcc6 in namespace namespace-115
2022-04-06 08:33:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:33:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-58d5bcc6 will have desired state: Ready
2022-04-06 08:34:11 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-58d5bcc6 is in desired state: Ready
2022-04-06 08:34:11 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 08:34:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-115 exec my-cluster-58d5bcc6-connect-7d6c7774c7-zscdk -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 08:34:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:34:12 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 08:34:12 [main] [32mINFO [m [ConnectIsolatedST:474] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-06 08:34:12 [main] [32mINFO [m [ConnectIsolatedST:477] Creating FileStreamSink connector via pod my-cluster-58d5bcc6-scraper-657b867bb-pj5x7 with topic my-topic-2095242365-2012140611
2022-04-06 08:34:12 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-115 exec my-cluster-58d5bcc6-scraper-657b867bb-pj5x7 -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-2095242365-2012140611", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-58d5bcc6-connect-api.namespace-115.svc:8083/connectors
2022-04-06 08:34:12 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:34:12 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 08:34:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-58d5bcc6-hello-world-producer in namespace namespace-115
2022-04-06 08:34:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:34:12 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-58d5bcc6-hello-world-consumer in namespace namespace-115
2022-04-06 08:34:12 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-115
2022-04-06 08:34:12 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-58d5bcc6-hello-world-producer will be in active state
2022-04-06 08:34:12 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-58d5bcc6-hello-world-consumer will be in active state
2022-04-06 08:34:12 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-58d5bcc6-hello-world-producer and consumer my-cluster-58d5bcc6-hello-world-consumer finish
2022-04-06 08:34:29 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-58d5bcc6-connect-7d6c7774c7-zscdk
2022-04-06 08:34:29 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-58d5bcc6-connect-7d6c7774c7-zscdk
2022-04-06 08:34:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:34:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-06 08:34:29 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-58d5bcc6 in namespace namespace-115
2022-04-06 08:34:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2095242365-2012140611 in namespace namespace-115
2022-04-06 08:34:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-58d5bcc6-hello-world-consumer in namespace namespace-115
2022-04-06 08:34:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-58d5bcc6-hello-world-producer in namespace namespace-115
2022-04-06 08:34:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-58d5bcc6-user in namespace namespace-115
2022-04-06 08:34:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-58d5bcc6-allow in namespace namespace-115
2022-04-06 08:34:30 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-58d5bcc6-scraper in namespace namespace-115
2022-04-06 08:34:40 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-58d5bcc6 in namespace namespace-115
2022-04-06 08:35:10 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:35:10 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-115 for test case:testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication
2022-04-06 08:35:37 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication-FINISHED
2022-04-06 08:35:37 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:35:37 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:35:37 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithoutConnectorToZero-STARTED
2022-04-06 08:35:37 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:35:37 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-116 for test case:testScaleConnectWithoutConnectorToZero
2022-04-06 08:35:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-116
2022-04-06 08:35:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-116
2022-04-06 08:35:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-116
2022-04-06 08:35:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bc0a9148 in namespace namespace-116
2022-04-06 08:35:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-116
2022-04-06 08:35:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bc0a9148 will have desired state: Ready
2022-04-06 08:36:57 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bc0a9148 is in desired state: Ready
2022-04-06 08:36:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-bc0a9148 in namespace namespace-116
2022-04-06 08:36:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-116
2022-04-06 08:36:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-bc0a9148 will have desired state: Ready
2022-04-06 08:38:08 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-bc0a9148 is in desired state: Ready
2022-04-06 08:38:08 [main] [32mINFO [m [ConnectIsolatedST:891] Scaling KafkaConnect down to zero
2022-04-06 08:38:08 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-bc0a9148 will have desired state: Ready
2022-04-06 08:38:08 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-bc0a9148 is in desired state: Ready
2022-04-06 08:38:17 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:38:17 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectWithoutConnectorToZero
2022-04-06 08:38:17 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-bc0a9148 in namespace namespace-116
2022-04-06 08:38:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bc0a9148 in namespace namespace-116
2022-04-06 08:38:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:38:27 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-116 for test case:testScaleConnectWithoutConnectorToZero
2022-04-06 08:39:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithoutConnectorToZero-FINISHED
2022-04-06 08:39:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:39:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:39:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithConnectorToZero-STARTED
2022-04-06 08:39:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:39:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-117 for test case:testScaleConnectWithConnectorToZero
2022-04-06 08:39:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-117
2022-04-06 08:39:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-117
2022-04-06 08:39:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-117
2022-04-06 08:39:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-402dc201 in namespace namespace-117
2022-04-06 08:39:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-06 08:39:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-402dc201 will have desired state: Ready
2022-04-06 08:40:21 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-402dc201 is in desired state: Ready
2022-04-06 08:40:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-402dc201 in namespace namespace-117
2022-04-06 08:40:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-06 08:40:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-402dc201 will have desired state: Ready
2022-04-06 08:41:30 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-402dc201 is in desired state: Ready
2022-04-06 08:41:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-402dc201 in namespace namespace-117
2022-04-06 08:41:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-117
2022-04-06 08:41:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-402dc201 will have desired state: Ready
2022-04-06 08:41:31 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-402dc201 is in desired state: Ready
2022-04-06 08:41:31 [main] [32mINFO [m [ConnectIsolatedST:934] Scaling KafkaConnect down to zero
2022-04-06 08:41:31 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-402dc201 will have desired state: Ready
2022-04-06 08:41:31 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-402dc201 is in desired state: Ready
2022-04-06 08:41:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:41:47 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleConnectWithConnectorToZero
2022-04-06 08:41:47 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-402dc201 in namespace namespace-117
2022-04-06 08:41:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-402dc201 in namespace namespace-117
2022-04-06 08:41:47 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-402dc201 in namespace namespace-117
2022-04-06 08:41:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:41:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-117 for test case:testScaleConnectWithConnectorToZero
2022-04-06 08:42:41 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testScaleConnectWithConnectorToZero-FINISHED
2022-04-06 08:42:41 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:42:41 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:42:41 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithPlainAndScramShaAuthentication-STARTED
2022-04-06 08:42:41 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:42:41 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-118 for test case:testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-06 08:42:41 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-118
2022-04-06 08:42:41 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-118
2022-04-06 08:42:41 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-118
2022-04-06 08:42:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-c9f26e8a in namespace namespace-118
2022-04-06 08:42:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 08:42:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-c9f26e8a will have desired state: Ready
2022-04-06 08:43:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-c9f26e8a is in desired state: Ready
2022-04-06 08:43:56 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-c9f26e8a-user in namespace namespace-118
2022-04-06 08:43:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 08:43:56 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-c9f26e8a-user will have desired state: Ready
2022-04-06 08:43:57 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-c9f26e8a-user is in desired state: Ready
2022-04-06 08:43:57 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-241928638-635282106 in namespace namespace-118
2022-04-06 08:43:57 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 08:43:57 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-241928638-635282106 will have desired state: Ready
2022-04-06 08:43:58 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-241928638-635282106 is in desired state: Ready
2022-04-06 08:43:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-c9f26e8a-scraper in namespace namespace-118
2022-04-06 08:43:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 08:43:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-c9f26e8a-scraper will be ready
2022-04-06 08:44:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-c9f26e8a-scraper is ready
2022-04-06 08:44:00 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-c9f26e8a-scraper to be ready
2022-04-06 08:44:10 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-c9f26e8a-scraper is ready
2022-04-06 08:44:10 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-c9f26e8a-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:44:10 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-c9f26e8a-allow in namespace namespace-118
2022-04-06 08:44:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 08:44:10 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:44:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-c9f26e8a in namespace namespace-118
2022-04-06 08:44:10 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 08:44:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-c9f26e8a will have desired state: Ready
2022-04-06 08:45:17 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-c9f26e8a is in desired state: Ready
2022-04-06 08:45:18 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 08:45:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-118 exec my-cluster-c9f26e8a-connect-77dc66bf95-4fc6h -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 08:45:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:45:18 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 08:45:18 [main] [32mINFO [m [ConnectIsolatedST:280] Verifying that KafkaConnect pod logs don't contain ERRORs
2022-04-06 08:45:18 [main] [32mINFO [m [ConnectIsolatedST:283] Creating FileStreamSink connector via pod my-cluster-c9f26e8a-scraper-84978b9bdd-v7gmt with topic my-topic-241928638-635282106
2022-04-06 08:45:18 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-118 exec my-cluster-c9f26e8a-scraper-84978b9bdd-v7gmt -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-241928638-635282106", "file": "/tmp/test-file-sink.txt" } }' http://my-cluster-c9f26e8a-connect-api.namespace-118.svc:8083/connectors
2022-04-06 08:45:18 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:45:18 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 08:45:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-c9f26e8a-hello-world-producer in namespace namespace-118
2022-04-06 08:45:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 08:45:18 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-c9f26e8a-hello-world-consumer in namespace namespace-118
2022-04-06 08:45:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-118
2022-04-06 08:45:18 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-c9f26e8a-hello-world-producer will be in active state
2022-04-06 08:45:18 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-c9f26e8a-hello-world-consumer will be in active state
2022-04-06 08:45:18 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-c9f26e8a-hello-world-producer and consumer my-cluster-c9f26e8a-hello-world-consumer finish
2022-04-06 08:45:36 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-c9f26e8a-connect-77dc66bf95-4fc6h
2022-04-06 08:45:37 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-c9f26e8a-connect-77dc66bf95-4fc6h
2022-04-06 08:45:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:45:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-06 08:45:37 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-c9f26e8a in namespace namespace-118
2022-04-06 08:45:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-241928638-635282106 in namespace namespace-118
2022-04-06 08:45:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-c9f26e8a-hello-world-consumer in namespace namespace-118
2022-04-06 08:45:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-c9f26e8a-user in namespace namespace-118
2022-04-06 08:45:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-c9f26e8a-hello-world-producer in namespace namespace-118
2022-04-06 08:45:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-c9f26e8a-allow in namespace namespace-118
2022-04-06 08:45:37 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-c9f26e8a in namespace namespace-118
2022-04-06 08:45:47 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-c9f26e8a-scraper in namespace namespace-118
2022-04-06 08:46:37 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:46:37 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-118 for test case:testKafkaConnectWithPlainAndScramShaAuthentication
2022-04-06 08:46:42 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testKafkaConnectWithPlainAndScramShaAuthentication-FINISHED
2022-04-06 08:46:42 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:46:42 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:46:42 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-06 08:46:42 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:46:42 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-119 for test case:testCustomAndUpdatedValues
2022-04-06 08:46:42 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-119
2022-04-06 08:46:42 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-119
2022-04-06 08:46:42 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-119
2022-04-06 08:46:42 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-13d099a6 in namespace namespace-119
2022-04-06 08:46:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-119
2022-04-06 08:46:42 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-13d099a6 will have desired state: Ready
2022-04-06 08:48:04 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-13d099a6 is in desired state: Ready
2022-04-06 08:48:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-13d099a6 in namespace namespace-119
2022-04-06 08:48:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-119
2022-04-06 08:48:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-13d099a6 will have desired state: Ready
2022-04-06 08:48:41 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-13d099a6 is in desired state: Ready
2022-04-06 08:48:41 [main] [32mINFO [m [ConnectIsolatedST:629] Verify values before update
2022-04-06 08:48:41 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-13d099a6-connect in pod name
2022-04-06 08:48:41 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-13d099a6-connect
2022-04-06 08:48:41 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-13d099a6-connect
2022-04-06 08:48:41 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-13d099a6-connect
2022-04-06 08:48:41 [main] [32mINFO [m [ConnectIsolatedST:634] Check if actual env variable KAFKA_CONNECT_CONFIGURATION has different value than test.value
2022-04-06 08:48:41 [main] [32mINFO [m [ConnectIsolatedST:640] Updating values in MirrorMaker container
2022-04-06 08:48:41 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-13d099a6-connect rolling update
2022-04-06 08:49:16 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-13d099a6-connect will be ready
2022-04-06 08:49:16 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-13d099a6-connect is ready
2022-04-06 08:49:26 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-13d099a6-connect rolling update finished
2022-04-06 08:49:26 [main] [32mINFO [m [ConnectIsolatedST:657] Verify values after update
2022-04-06 08:49:26 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-13d099a6-connect in pod name
2022-04-06 08:49:26 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-13d099a6-connect
2022-04-06 08:49:26 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-13d099a6-connect
2022-04-06 08:49:26 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-13d099a6-connect
2022-04-06 08:49:26 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-13d099a6-connect
2022-04-06 08:49:26 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-13d099a6-connect
2022-04-06 08:49:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:49:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-06 08:49:26 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-13d099a6 in namespace namespace-119
2022-04-06 08:49:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-13d099a6 in namespace namespace-119
2022-04-06 08:49:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:49:36 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-119 for test case:testCustomAndUpdatedValues
2022-04-06 08:50:03 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-06 08:50:03 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:50:03 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:50:03 [main] [32mINFO [m [ResourceManager:346] In context ConnectIsolatedST is everything deleted.
2022-04-06 08:50:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4,142.999 s - in io.strimzi.systemtest.connect.ConnectIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
2022-04-06 08:50:03 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 08:50:28 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 08:50:28 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 08:50:28 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 08:50:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:50:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 08:50:28 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 08:50:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 08:50:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 08:50:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 08:50:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 08:50:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 08:50:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 08:50:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:50:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 08:50:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:50:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:38 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:50:38 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 08:50:38 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 08:50:38 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 08:50:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:50:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 08:50:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:50:54 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=120000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 08:50:54 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 08:50:54 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 08:50:54 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 08:50:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:50:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 08:50:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 08:50:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 08:50:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 08:50:54 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 08:50:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 08:50:54 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:50:55 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 08:50:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 08:50:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 08:50:55 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 08:50:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:50:55 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 08:50:55 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 08:50:55 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 08:50:55 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 08:50:55 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 08:51:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 08:51:40 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 08:51:50 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 08:51:50 [main] [33mWARN [m [ConnectBuilderIsolatedST:546] For running these tests on K8s you have to have internal registry deployed using `minikube start --insecure-registry '10.0.0.0/24'` and `minikube addons enable registry`
2022-04-06 08:51:50 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka infra-namespace in namespace infra-namespace
2022-04-06 08:51:50 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: infra-namespace will have desired state: Ready
2022-04-06 08:53:11 [main] [32mINFO [m [ResourceManager:444] Kafka: infra-namespace is in desired state: Ready
2022-04-06 08:53:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:53:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildWithJarTgzAndZip-STARTED
2022-04-06 08:53:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:53:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-460380494-956576309 in namespace infra-namespace
2022-04-06 08:53:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-460380494-956576309 will have desired state: Ready
2022-04-06 08:53:13 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-460380494-956576309 is in desired state: Ready
2022-04-06 08:53:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-c30908d3 in namespace infra-namespace
2022-04-06 08:53:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-c30908d3 will have desired state: Ready
2022-04-06 08:55:01 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-c30908d3 is in desired state: Ready
2022-04-06 08:55:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-c30908d3 in namespace infra-namespace
2022-04-06 08:55:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-c30908d3 will have desired state: Ready
2022-04-06 08:55:02 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-c30908d3 is in desired state: Ready
2022-04-06 08:55:02 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 08:55:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-c30908d3-hello-world-producer in namespace infra-namespace
2022-04-06 08:55:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-c30908d3-hello-world-producer will be in active state
2022-04-06 08:55:03 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-c30908d3-hello-world-producer to finished
2022-04-06 08:55:11 [main] [32mINFO [m [PodUtils:186] Waiting for message will be in the log
2022-04-06 08:55:11 [main] [32mINFO [m [PodUtils:189] Message Received message with key 'null' and value '"Hello-world - 99"' found in my-cluster-c30908d3-connect-c8bfd7685-gm74m log
2022-04-06 08:55:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:55:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildWithJarTgzAndZip
2022-04-06 08:55:11 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-c30908d3 in namespace infra-namespace
2022-04-06 08:55:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-c30908d3-hello-world-producer in namespace infra-namespace
2022-04-06 08:55:11 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-c30908d3 in namespace infra-namespace
2022-04-06 08:55:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-460380494-956576309 in namespace infra-namespace
2022-04-06 08:55:21 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:55:21 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildWithJarTgzAndZip-FINISHED
2022-04-06 08:55:21 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:55:21 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:55:21 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildFailsWithWrongChecksumOfArtifact-STARTED
2022-04-06 08:55:21 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:55:21 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-91f165c3-scraper in namespace infra-namespace
2022-04-06 08:55:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-91f165c3-scraper will be ready
2022-04-06 08:55:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-91f165c3-scraper is ready
2022-04-06 08:55:23 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-91f165c3-scraper to be ready
2022-04-06 08:55:33 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-91f165c3-scraper is ready
2022-04-06 08:55:33 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-91f165c3-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-91f165c3-allow in namespace infra-namespace
2022-04-06 08:55:33 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:55:33 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-91f165c3 in namespace infra-namespace
2022-04-06 08:55:33 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-91f165c3 will have desired state: NotReady
2022-04-06 08:55:34 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-91f165c3 is in desired state: NotReady
2022-04-06 08:56:01 [main] [32mINFO [m [ConnectBuilderIsolatedST:186] Checking if KafkaConnect status condition contains message about build failure
2022-04-06 08:56:01 [main] [32mINFO [m [ConnectBuilderIsolatedST:189] Deploying network policies for KafkaConnect
2022-04-06 08:56:01 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-91f165c3-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:56:01 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-91f165c3-allow in namespace infra-namespace
2022-04-06 08:56:01 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:56:01 [main] [32mINFO [m [ConnectBuilderIsolatedST:197] Replacing plugin's checksum with right one
2022-04-06 08:56:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-91f165c3 will have desired state: Ready
2022-04-06 08:58:25 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-91f165c3 is in desired state: Ready
2022-04-06 08:58:25 [main] [32mINFO [m [ConnectBuilderIsolatedST:215] Checking if KafkaConnect API contains EchoSink connector
2022-04-06 08:58:25 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-91f165c3-scraper-5f45fb7f97-kwvxf -- curl -X GET http://my-cluster-91f165c3-connect-api:8083/connector-plugins
2022-04-06 08:58:25 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 08:58:25 [main] [32mINFO [m [ConnectBuilderIsolatedST:220] Checking if KafkaConnect resource contains EchoSink connector in status
2022-04-06 08:58:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 08:58:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildFailsWithWrongChecksumOfArtifact
2022-04-06 08:58:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-91f165c3 in namespace infra-namespace
2022-04-06 08:58:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-91f165c3-allow in namespace infra-namespace
2022-04-06 08:58:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-91f165c3-scraper in namespace infra-namespace
2022-04-06 08:58:25 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-91f165c3-allow in namespace infra-namespace
2022-04-06 08:59:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 08:59:05 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildFailsWithWrongChecksumOfArtifact-FINISHED
2022-04-06 08:59:05 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 08:59:05 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 08:59:05 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildOtherPluginTypeWithAndWithoutFileName-STARTED
2022-04-06 08:59:05 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 08:59:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1524794804-172122816 in namespace infra-namespace
2022-04-06 08:59:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1524794804-172122816 will have desired state: Ready
2022-04-06 08:59:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1524794804-172122816 is in desired state: Ready
2022-04-06 08:59:06 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f986d4ac-scraper in namespace infra-namespace
2022-04-06 08:59:06 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f986d4ac-scraper will be ready
2022-04-06 08:59:08 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f986d4ac-scraper is ready
2022-04-06 08:59:08 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-f986d4ac-scraper to be ready
2022-04-06 08:59:18 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-f986d4ac-scraper is ready
2022-04-06 08:59:18 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-f986d4ac-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 08:59:18 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-f986d4ac-allow in namespace infra-namespace
2022-04-06 08:59:18 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 08:59:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-f986d4ac in namespace infra-namespace
2022-04-06 08:59:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-f986d4ac will have desired state: Ready
2022-04-06 09:00:55 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-f986d4ac is in desired state: Ready
2022-04-06 09:00:55 [main] [32mINFO [m [ConnectBuilderIsolatedST:448] Checking that plugin has correct file name: echo-sink-test.jar
2022-04-06 09:00:55 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-f986d4ac-connect-8598d5bb4-fvqxz -- /bin/bash -c ls plugins/plugin-with-other-type/*
2022-04-06 09:00:55 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:00:55 [main] [32mINFO [m [ConnectBuilderIsolatedST:461] Removing file name from the plugin, hash should be used
2022-04-06 09:00:55 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-f986d4ac-connect rolling update
2022-04-06 09:02:40 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-f986d4ac-connect will be ready
2022-04-06 09:02:40 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-f986d4ac-connect is ready
2022-04-06 09:02:50 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-f986d4ac-connect rolling update finished
2022-04-06 09:02:50 [main] [32mINFO [m [ConnectBuilderIsolatedST:468] Checking that plugin has different name than before
2022-04-06 09:02:50 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-f986d4ac-connect-744db67f64-4h5f4 -- /bin/bash -c ls plugins/plugin-with-other-type/*
2022-04-06 09:02:50 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:02:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:02:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildOtherPluginTypeWithAndWithoutFileName
2022-04-06 09:02:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f986d4ac-scraper in namespace infra-namespace
2022-04-06 09:02:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1524794804-172122816 in namespace infra-namespace
2022-04-06 09:02:50 [main] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-f986d4ac-allow in namespace infra-namespace
2022-04-06 09:02:50 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-f986d4ac in namespace infra-namespace
2022-04-06 09:03:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:03:30 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildOtherPluginTypeWithAndWithoutFileName-FINISHED
2022-04-06 09:03:30 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:03:30 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:03:30 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testUpdateConnectWithAnotherPlugin-STARTED
2022-04-06 09:03:30 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:03:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1496915449-1698051497 in namespace infra-namespace
2022-04-06 09:03:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1496915449-1698051497 will have desired state: Ready
2022-04-06 09:03:32 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1496915449-1698051497 is in desired state: Ready
2022-04-06 09:03:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-be692a98-scraper in namespace infra-namespace
2022-04-06 09:03:32 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-be692a98-scraper will be ready
2022-04-06 09:03:33 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-be692a98-scraper is ready
2022-04-06 09:03:33 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-be692a98-scraper to be ready
2022-04-06 09:03:43 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-be692a98-scraper is ready
2022-04-06 09:03:43 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-be692a98-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 09:03:43 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-be692a98-allow in namespace infra-namespace
2022-04-06 09:03:43 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 09:03:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-be692a98 in namespace infra-namespace
2022-04-06 09:03:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-be692a98 will have desired state: Ready
2022-04-06 09:05:26 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-be692a98 is in desired state: Ready
2022-04-06 09:05:26 [main] [32mINFO [m [ConnectBuilderIsolatedST:370] Creating EchoSink connector
2022-04-06 09:05:26 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector echo-sink-connector in namespace infra-namespace
2022-04-06 09:05:26 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: echo-sink-connector will have desired state: Ready
2022-04-06 09:05:27 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: echo-sink-connector is in desired state: Ready
2022-04-06 09:05:27 [main] [32mINFO [m [ConnectBuilderIsolatedST:382] Checking that KafkaConnect API contains EchoSink connector and not Camel-Telegram Connector class name
2022-04-06 09:05:27 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-be692a98-scraper-899496b-pm4k6 -- curl -X GET http://my-cluster-be692a98-connect-api:8083/connector-plugins
2022-04-06 09:05:27 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:05:27 [main] [32mINFO [m [ConnectBuilderIsolatedST:388] Adding one more connector to the KafkaConnect
2022-04-06 09:05:27 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-be692a98-connect rolling update
2022-04-06 09:07:07 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-be692a98-connect will be ready
2022-04-06 09:07:07 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-be692a98-connect is ready
2022-04-06 09:07:18 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-be692a98-connect rolling update finished
2022-04-06 09:07:18 [main] [32mINFO [m [ConnectBuilderIsolatedST:399] Creating Camel-HTTP-Sink connector
2022-04-06 09:07:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector camel-http-connector in namespace infra-namespace
2022-04-06 09:07:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: camel-http-connector will have desired state: Ready
2022-04-06 09:07:19 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: camel-http-connector is in desired state: Ready
2022-04-06 09:07:19 [main] [32mINFO [m [ConnectBuilderIsolatedST:409] Checking if both Connectors were created and Connect contains both plugins
2022-04-06 09:07:19 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:07:19 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testUpdateConnectWithAnotherPlugin
2022-04-06 09:07:19 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-be692a98 in namespace infra-namespace
2022-04-06 09:07:19 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-be692a98-scraper in namespace infra-namespace
2022-04-06 09:07:19 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1496915449-1698051497 in namespace infra-namespace
2022-04-06 09:07:19 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector camel-http-connector in namespace infra-namespace
2022-04-06 09:07:29 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector echo-sink-connector in namespace infra-namespace
2022-04-06 09:07:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-be692a98-allow in namespace infra-namespace
2022-04-06 09:07:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:07:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testUpdateConnectWithAnotherPlugin-FINISHED
2022-04-06 09:07:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:07:59 [main] [32mINFO [m [OpenShiftOnlyCondition:25] testPushIntoImageStream is @OpenShiftOnly, but the running cluster is not OpenShift: Ignoring testPushIntoImageStream
2022-04-06 09:07:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:07:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts-STARTED
2022-04-06 09:07:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:07:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-923463336-392239177 in namespace infra-namespace
2022-04-06 09:07:59 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-460f9c06 in namespace infra-namespace
2022-04-06 09:07:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-923463336-392239177 will have desired state: Ready
2022-04-06 09:08:00 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-923463336-392239177 is in desired state: Ready
2022-04-06 09:08:00 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-460f9c06 will have desired state: Ready
2022-04-06 09:10:19 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-460f9c06 is in desired state: Ready
2022-04-06 09:10:19 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnector my-cluster-460f9c06-camel-connector in namespace infra-namespace
2022-04-06 09:10:19 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnector: my-cluster-460f9c06-camel-connector will have desired state: Ready
2022-04-06 09:10:20 [main] [32mINFO [m [ResourceManager:444] KafkaConnector: my-cluster-460f9c06-camel-connector is in desired state: Ready
2022-04-06 09:10:20 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 09:10:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-460f9c06-hello-world-consumer in namespace infra-namespace
2022-04-06 09:10:20 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-460f9c06-hello-world-consumer will be in active state
2022-04-06 09:10:21 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-460f9c06-hello-world-consumer to finished
2022-04-06 09:11:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:11:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testBuildPluginUsingMavenCoordinatesArtifacts
2022-04-06 09:11:16 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaConnector my-cluster-460f9c06-camel-connector in namespace infra-namespace
2022-04-06 09:11:16 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-460f9c06-hello-world-consumer in namespace infra-namespace
2022-04-06 09:11:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-460f9c06 in namespace infra-namespace
2022-04-06 09:11:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-923463336-392239177 in namespace infra-namespace
2022-04-06 09:11:26 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:11:26 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.connect.ConnectBuilderIsolatedST.testBuildPluginUsingMavenCoordinatesArtifacts-FINISHED
2022-04-06 09:11:26 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:11:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:11:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for ConnectBuilderIsolatedST
2022-04-06 09:11:26 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka infra-namespace in namespace infra-namespace
2022-04-06 09:11:36 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 6, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 1,293.494 s - in io.strimzi.systemtest.connect.ConnectBuilderIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
2022-04-06 09:11:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 09:12:01 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 09:12:01 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 09:12:01 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 09:12:01 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:12:01 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 09:12:01 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:01 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:12:01 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:12:01 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:01 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:12:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:12:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:12:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:12:02 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:12:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:12:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:12:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:12:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:11 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:11 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:12:11 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:12 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:12 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:12:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:12 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:12 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:22 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:12:28 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 09:12:28 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 09:12:28 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 09:12:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:28 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:29 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:12:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:29 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 09:12:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:12:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:12:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 09:12:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:12:29 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 09:12:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:12:29 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:12:29 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:29 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 09:12:29 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:12:29 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:12:29 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:12:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:12:29 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:12:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:12:29 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 09:13:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 09:13:00 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 09:13:10 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 09:13:10 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:13:10 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-STARTED
2022-04-06 09:13:10 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:13:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-2b8cea1e in namespace infra-namespace
2022-04-06 09:13:10 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2b8cea1e will have desired state: Ready
2022-04-06 09:14:29 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2b8cea1e is in desired state: Ready
2022-04-06 09:14:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-2b8cea1e-producer in namespace infra-namespace
2022-04-06 09:14:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-2b8cea1e-consumer in namespace infra-namespace
2022-04-06 09:14:29 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-2b8cea1e-producer will be in active state
2022-04-06 09:14:29 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-2b8cea1e-consumer will be in active state
2022-04-06 09:14:29 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-2b8cea1e-producer and consumer my-cluster-2b8cea1e-consumer finish
2022-04-06 09:14:49 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-2b8cea1e-kafka-0 -- /opt/kafka/bin/kafka-consumer-groups.sh --describe --bootstrap-server localhost:9092 --group my-group
2022-04-06 09:14:49 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:14:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-2b8cea1e-producer in namespace infra-namespace
2022-04-06 09:14:49 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-2b8cea1e-producer will be in active state
2022-04-06 09:14:50 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-2b8cea1e-producer to finished
2022-04-06 09:14:58 [main] [32mINFO [m [ColdBackupScriptIsolatedST:95] Running backup procedure for infra-namespace/my-cluster-2b8cea1e
2022-04-06 09:16:46 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh backup -n infra-namespace -c my-cluster-2b8cea1e -t /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-2b8cea1e.tgz -y
2022-04-06 09:16:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:16:46 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 09:16:46 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 09:16:46 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 09:16:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:16:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 09:16:46 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:16:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:16:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:16:46 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:16:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:16:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:16:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:16:56 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:16:56 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:16:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:16:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:17:06 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:06 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:17:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:17:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:17:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:17:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:17:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:17:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:17:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:17:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:17:07 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:17 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:17:37 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 09:17:37 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 09:17:37 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 09:17:37 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 09:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:17:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:17:38 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 09:17:38 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:17:38 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:17:38 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:17:38 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:17:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:17:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 09:18:04 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 09:18:04 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 09:18:14 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 09:18:14 [main] [32mINFO [m [ColdBackupScriptIsolatedST:109] Running restore procedure for infra-namespace/my-cluster-2b8cea1e
2022-04-06 09:19:51 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/cold-backup/run.sh restore -n infra-namespace -c my-cluster-2b8cea1e -s /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-2b8cea1e.tgz -y
2022-04-06 09:19:51 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:19:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-2b8cea1e will have desired state: Ready
2022-04-06 09:20:31 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-2b8cea1e is in desired state: Ready
2022-04-06 09:20:34 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-2b8cea1e-kafka-0 -- /opt/kafka/bin/kafka-consumer-groups.sh --describe --bootstrap-server localhost:9092 --group my-group
2022-04-06 09:20:34 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 09:20:34 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-2b8cea1e-consumer in namespace infra-namespace
2022-04-06 09:20:34 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-2b8cea1e-consumer will be in active state
2022-04-06 09:20:35 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-2b8cea1e-consumer to finished
2022-04-06 09:20:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-2b8cea1e-consumer in namespace infra-namespace
2022-04-06 09:20:46 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-2b8cea1e-consumer will be in active state
2022-04-06 09:20:47 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:my-cluster-2b8cea1e-consumer to finished
2022-04-06 09:20:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:20:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for backupAndRestore
2022-04-06 09:20:58 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-2b8cea1e-producer in namespace infra-namespace
2022-04-06 09:20:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-2b8cea1e-consumer in namespace infra-namespace
2022-04-06 09:20:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-2b8cea1e-producer in namespace infra-namespace
2022-04-06 09:20:58 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-2b8cea1e in namespace infra-namespace
2022-04-06 09:20:58 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-2b8cea1e-consumer in namespace infra-namespace
2022-04-06 09:20:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-2b8cea1e-consumer in namespace infra-namespace
2022-04-06 09:21:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:21:08 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST.backupAndRestore-FINISHED
2022-04-06 09:21:08 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:21:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:21:08 [main] [32mINFO [m [ResourceManager:346] In context ColdBackupScriptIsolatedST is everything deleted.
2022-04-06 09:21:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 571.476 s - in io.strimzi.systemtest.backup.ColdBackupScriptIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
2022-04-06 09:21:08 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 09:21:33 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 09:21:33 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 09:21:33 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 09:21:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:21:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 09:21:33 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:21:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:21:43 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:21:43 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:21:43 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:21:43 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:21:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:21:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:21:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:21:53 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:21:53 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:22:03 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:22:09 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 09:22:09 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 09:22:09 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 09:22:09 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:22:09 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 09:22:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 09:22:09 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 09:22:09 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 09:22:10 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 09:22:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 09:22:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 09:22:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:22:10 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 09:22:10 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 09:22:10 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:22:10 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 09:22:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 09:22:10 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 09:22:10 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 09:22:10 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 09:22:49 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 09:22:49 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 09:22:59 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 09:22:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:22:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup-STARTED
2022-04-06 09:22:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:22:59 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-120 for test case:testRestoreOffsetsInConsumerGroup
2022-04-06 09:22:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-120
2022-04-06 09:22:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-120
2022-04-06 09:22:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-120
2022-04-06 09:22:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9d799507-source in namespace namespace-120
2022-04-06 09:22:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:22:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9d799507-target in namespace namespace-120
2022-04-06 09:22:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:22:59 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9d799507-source will have desired state: Ready
2022-04-06 09:24:24 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9d799507-source is in desired state: Ready
2022-04-06 09:24:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9d799507-target will have desired state: Ready
2022-04-06 09:24:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9d799507-target is in desired state: Ready
2022-04-06 09:24:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-9d799507-trg-src in namespace namespace-120
2022-04-06 09:24:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:24:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-9d799507-src-trg in namespace namespace-120
2022-04-06 09:24:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:24:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic test-sync-offset-1254700194 in namespace namespace-120
2022-04-06 09:24:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:24:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-9d799507-trg-src will have desired state: Ready
2022-04-06 09:25:59 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-9d799507-trg-src is in desired state: Ready
2022-04-06 09:25:59 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-9d799507-src-trg will have desired state: Ready
2022-04-06 09:26:01 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-9d799507-src-trg is in desired state: Ready
2022-04-06 09:26:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: test-sync-offset-1254700194 will have desired state: Ready
2022-04-06 09:26:01 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: test-sync-offset-1254700194 is in desired state: Ready
2022-04-06 09:26:01 [main] [32mINFO [m [MirrorMaker2IsolatedST:1090] Send & receive 100 messages to/from Source cluster.
2022-04-06 09:26:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-1780740017 in namespace namespace-120
2022-04-06 09:26:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:26:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-972055884 in namespace namespace-120
2022-04-06 09:26:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:26:01 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-1780740017 will be in active state
2022-04-06 09:26:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-972055884 will be in active state
2022-04-06 09:26:02 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-1780740017 to finished
2022-04-06 09:26:12 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-972055884 to finished
2022-04-06 09:26:17 [main] [32mINFO [m [MirrorMaker2IsolatedST:1098] Send 100 messages to Source cluster.
2022-04-06 09:26:17 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-1780740017 in namespace namespace-120
2022-04-06 09:26:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:26:17 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-1780740017 will be in active state
2022-04-06 09:26:18 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-1780740017 to finished
2022-04-06 09:26:27 [main] [32mINFO [m [MirrorMaker2IsolatedST:1105] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-06 09:26:27 [main] [32mINFO [m [MirrorMaker2IsolatedST:1107] Receive 100 messages from mirrored topic on Target cluster.
2022-04-06 09:26:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-1452961927 in namespace namespace-120
2022-04-06 09:26:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:26:27 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-1452961927 will be in active state
2022-04-06 09:26:28 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-1452961927 to finished
2022-04-06 09:26:38 [main] [32mINFO [m [MirrorMaker2IsolatedST:1112] Send 50 messages to Source cluster
2022-04-06 09:26:38 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-producer-source-my-consumer-group-1780740017 in namespace namespace-120
2022-04-06 09:26:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:26:38 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-producer-source-my-consumer-group-1780740017 will be in active state
2022-04-06 09:26:39 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-producer-source-my-consumer-group-1780740017 to finished
2022-04-06 09:26:47 [main] [32mINFO [m [MirrorMaker2IsolatedST:1118] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-06 09:26:47 [main] [32mINFO [m [MirrorMaker2IsolatedST:1119] Receive 10 msgs from source cluster
2022-04-06 09:26:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-972055884 in namespace namespace-120
2022-04-06 09:26:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:26:47 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-972055884 will be in active state
2022-04-06 09:26:48 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-972055884 to finished
2022-04-06 09:26:59 [main] [32mINFO [m [MirrorMaker2IsolatedST:1125] Wait 1 second as 'sync.group.offsets.interval.seconds=1'. As this is insignificant wait, we're skipping it
2022-04-06 09:26:59 [main] [32mINFO [m [MirrorMaker2IsolatedST:1127] Receive 40 msgs from mirrored topic on Target cluster
2022-04-06 09:26:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-1452961927 in namespace namespace-120
2022-04-06 09:26:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:26:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-1452961927 will be in active state
2022-04-06 09:27:00 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-1452961927 to finished
2022-04-06 09:27:24 [main] [32mINFO [m [MirrorMaker2IsolatedST:1133] There should be no more messages to read. Try to consume at least 1 message. This client job should fail on timeout.
2022-04-06 09:27:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-target-my-consumer-group-1452961927 in namespace namespace-120
2022-04-06 09:27:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:27:24 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-target-my-consumer-group-1452961927 will be in active state
2022-04-06 09:27:25 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:mm2-consumer-target-my-consumer-group-1452961927 to finish with failure.
2022-04-06 09:29:26 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 121000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.lambda$testRestoreOffsetsInConsumerGroup$13(MirrorMaker2IsolatedST.java:1137)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup(MirrorMaker2IsolatedST.java:1137)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 09:29:26 [main] [32mINFO [m [ClientUtils:100] Client job 'mm2-consumer-target-my-consumer-group-1452961927' finished with expected timeout.
2022-04-06 09:29:26 [main] [32mINFO [m [MirrorMaker2IsolatedST:1139] As it's Active-Active MM2 mode, there should be no more messages to read from Source cluster topic. This client job should fail on timeout.
2022-04-06 09:29:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Job mm2-consumer-source-my-consumer-group-972055884 in namespace namespace-120
2022-04-06 09:29:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-120
2022-04-06 09:29:26 [main] [32mINFO [m [JobUtils:81] Waiting for job: mm2-consumer-source-my-consumer-group-972055884 will be in active state
2022-04-06 09:29:27 [main] [32mINFO [m [ClientUtils:89] Waiting for producer/consumer:mm2-consumer-source-my-consumer-group-972055884 to finish with failure.
2022-04-06 09:31:28 [main] [1;31mERROR[m [TestUtils:162] Exception waiting for Job did not finish within time limit (as expected)., null
io.strimzi.test.WaitException: Timeout after 121000 ms waiting for Job did not finish within time limit (as expected).
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:170)
	at io.strimzi.test.TestUtils.waitFor(TestUtils.java:121)
	at io.strimzi.systemtest.utils.ClientUtils.waitForClientTimeout(ClientUtils.java:91)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.lambda$testRestoreOffsetsInConsumerGroup$14(MirrorMaker2IsolatedST.java:1143)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
	at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
	at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
	at io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup(MirrorMaker2IsolatedST.java:1143)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:128)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.maven.surefire.api.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:167)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:161)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:84)
	at org.apache.maven.plugin.surefire.InPluginVMSurefireStarter.runSuitesInProcess(InPluginVMSurefireStarter.java:87)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1295)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1159)
	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:932)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)
	at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:301)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:211)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:165)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:157)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:121)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:127)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:960)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:196)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347)
2022-04-06 09:31:28 [main] [32mINFO [m [ClientUtils:100] Client job 'mm2-consumer-source-my-consumer-group-972055884' finished with expected timeout.
2022-04-06 09:31:28 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:31:28 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testRestoreOffsetsInConsumerGroup
2022-04-06 09:31:28 [main] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-1452961927 in namespace namespace-120
2022-04-06 09:31:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-1452961927 in namespace namespace-120
2022-04-06 09:31:28 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic test-sync-offset-1254700194 in namespace namespace-120
2022-04-06 09:31:28 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9d799507-target in namespace namespace-120
2022-04-06 09:31:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-972055884 in namespace namespace-120
2022-04-06 09:31:28 [main] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-1780740017 in namespace namespace-120
2022-04-06 09:31:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-target-my-consumer-group-1452961927 in namespace namespace-120
2022-04-06 09:31:28 [main] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-1780740017 in namespace namespace-120
2022-04-06 09:31:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-972055884 in namespace namespace-120
2022-04-06 09:31:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job mm2-consumer-source-my-consumer-group-972055884 in namespace namespace-120
2022-04-06 09:31:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job mm2-producer-source-my-consumer-group-1780740017 in namespace namespace-120
2022-04-06 09:31:28 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-9d799507-src-trg in namespace namespace-120
2022-04-06 09:31:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-9d799507-trg-src in namespace namespace-120
2022-04-06 09:31:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9d799507-source in namespace namespace-120
2022-04-06 09:31:49 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:31:49 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-120 for test case:testRestoreOffsetsInConsumerGroup
2022-04-06 09:32:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testRestoreOffsetsInConsumerGroup-FINISHED
2022-04-06 09:32:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:32:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:32:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2-STARTED
2022-04-06 09:32:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:32:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-121 for test case:testMirrorMaker2
2022-04-06 09:32:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-121
2022-04-06 09:32:00 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-121
2022-04-06 09:32:00 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-121
2022-04-06 09:32:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-afc17b09-source in namespace namespace-121
2022-04-06 09:32:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-06 09:32:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-afc17b09-source will have desired state: Ready
2022-04-06 09:33:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-afc17b09-source is in desired state: Ready
2022-04-06 09:33:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-afc17b09-target in namespace namespace-121
2022-04-06 09:33:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-06 09:33:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-afc17b09-target will have desired state: Ready
2022-04-06 09:34:18 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-afc17b09-target is in desired state: Ready
2022-04-06 09:34:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-2086367116 in namespace namespace-121
2022-04-06 09:34:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-06 09:34:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-2086367116 will have desired state: Ready
2022-04-06 09:34:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-2086367116 is in desired state: Ready
2022-04-06 09:34:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-afc17b09-kafka-clients in namespace namespace-121
2022-04-06 09:34:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-06 09:34:29 [main] [32mINFO [m [MirrorMaker2IsolatedST:155] Sending messages to - topic availability-topic-source-my-topic-1210124322-934201735, cluster my-cluster-afc17b09-source and message count of 100
2022-04-06 09:34:29 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7d354cdb, messages=[], arguments=[--bootstrap-server, my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092, --max-messages, 100, --topic, availability-topic-source-my-topic-1210124322-934201735], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt', podNamespace='namespace-121', bootstrapServer='my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-source-my-topic-1210124322-934201735', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@58702163}
2022-04-06 09:34:29 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092:availability-topic-source-my-topic-1210124322-934201735 from pod my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt
2022-04-06 09:34:29 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt -n namespace-121 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092 --max-messages 100 --topic availability-topic-source-my-topic-1210124322-934201735
2022-04-06 09:34:33 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 09:34:33 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 09:34:33 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7de5f6be, messages=[], arguments=[--group-id, my-consumer-group-2066646751, --bootstrap-server, my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092, --group-instance-id, instance258731383, --max-messages, 100, --topic, availability-topic-source-my-topic-1210124322-934201735], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt', podNamespace='namespace-121', bootstrapServer='my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-source-my-topic-1210124322-934201735', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-2066646751', consumerInstanceId='instance258731383', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@24c7b07c}
2022-04-06 09:34:33 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092#availability-topic-source-my-topic-1210124322-934201735 from pod my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt
2022-04-06 09:34:33 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt -n namespace-121 -- /opt/kafka/consumer.sh --group-id my-consumer-group-2066646751 --bootstrap-server my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092 --group-instance-id instance258731383 --max-messages 100 --topic availability-topic-source-my-topic-1210124322-934201735
2022-04-06 09:34:38 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 09:34:38 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 09:34:38 [main] [32mINFO [m [MirrorMaker2IsolatedST:160] Setting topic to availability-topic-target-my-topic-1210124322-934201735, cluster to my-cluster-afc17b09-target and changing consumer group
2022-04-06 09:34:38 [main] [32mINFO [m [MirrorMaker2IsolatedST:168] Sending messages to - topic availability-topic-target-my-topic-1210124322-934201735, cluster my-cluster-afc17b09-target and message count of 100
2022-04-06 09:34:38 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2d3c98f1, messages=[], arguments=[--bootstrap-server, my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092, --max-messages, 100, --topic, availability-topic-target-my-topic-1210124322-934201735], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt', podNamespace='namespace-121', bootstrapServer='my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-target-my-topic-1210124322-934201735', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2ae13e4d}
2022-04-06 09:34:38 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092:availability-topic-target-my-topic-1210124322-934201735 from pod my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt
2022-04-06 09:34:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt -n namespace-121 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092 --max-messages 100 --topic availability-topic-target-my-topic-1210124322-934201735
2022-04-06 09:34:41 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 09:34:41 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 09:34:41 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6663d94e, messages=[], arguments=[--group-id, my-consumer-group-257966381, --bootstrap-server, my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092, --group-instance-id, instance288091295, --max-messages, 100, --topic, availability-topic-target-my-topic-1210124322-934201735], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt', podNamespace='namespace-121', bootstrapServer='my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092', topicName='availability-topic-target-my-topic-1210124322-934201735', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-257966381', consumerInstanceId='instance288091295', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3461897a}
2022-04-06 09:34:41 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092#availability-topic-target-my-topic-1210124322-934201735 from pod my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt
2022-04-06 09:34:41 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt -n namespace-121 -- /opt/kafka/consumer.sh --group-id my-consumer-group-257966381 --bootstrap-server my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092 --group-instance-id instance288091295 --max-messages 100 --topic availability-topic-target-my-topic-1210124322-934201735
2022-04-06 09:34:47 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 09:34:47 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 09:34:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-afc17b09 in namespace namespace-121
2022-04-06 09:34:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-121
2022-04-06 09:34:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-afc17b09 will have desired state: Ready
2022-04-06 09:35:52 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-afc17b09 is in desired state: Ready
2022-04-06 09:35:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:183] Looks like the mirrormaker2 cluster my-cluster deployed OK
2022-04-06 09:35:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:640] Verifying docker image names
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:172] strimzi-cluster-operator
2022-04-06 09:35:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:653] Docker images verified
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type mirrormaker2
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-afc17b09-mirrormaker2-788d6b9b47-cr82x
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:362] Verifying labels for service my-cluster-afc17b09-mirrormaker2-api
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-afc17b09-mirrormaker2-config
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-afc17b09-source-entity-topic-operator-config
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:407] CM my-cluster-afc17b09-source-entity-topic-operator-config is not related to current test
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-afc17b09-source-entity-user-operator-config
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:407] CM my-cluster-afc17b09-source-entity-user-operator-config is not related to current test
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-afc17b09-source-kafka-config
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-afc17b09-source-zookeeper-config
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:407] CM my-cluster-afc17b09-source-zookeeper-config is not related to current test
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-afc17b09-target-entity-topic-operator-config
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:407] CM my-cluster-afc17b09-target-entity-topic-operator-config is not related to current test
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-afc17b09-target-entity-user-operator-config
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:407] CM my-cluster-afc17b09-target-entity-user-operator-config is not related to current test
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-afc17b09-target-kafka-config
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-afc17b09-target-zookeeper-config
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:407] CM my-cluster-afc17b09-target-zookeeper-config is not related to current test
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-afc17b09-source-entity-operator
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-afc17b09-source-kafka
2022-04-06 09:35:52 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-afc17b09-source-zookeeper
2022-04-06 09:35:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:198] Setting topic to mirrormaker2-topic-example-2086367116, cluster to my-cluster-afc17b09-source and changing consumer group
2022-04-06 09:35:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:206] Sending messages to - topic mirrormaker2-topic-example-2086367116, cluster my-cluster-afc17b09-source and message count of 100
2022-04-06 09:35:52 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@9e319f4, messages=[], arguments=[--bootstrap-server, my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092, --max-messages, 100, --topic, mirrormaker2-topic-example-2086367116], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt', podNamespace='namespace-121', bootstrapServer='my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092', topicName='mirrormaker2-topic-example-2086367116', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4d18fced}
2022-04-06 09:35:52 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092:mirrormaker2-topic-example-2086367116 from pod my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt
2022-04-06 09:35:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt -n namespace-121 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092 --max-messages 100 --topic mirrormaker2-topic-example-2086367116
2022-04-06 09:35:55 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 09:35:55 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 09:35:55 [main] [32mINFO [m [MirrorMaker2IsolatedST:210] Consumer in source cluster and topic should receive 100 messages
2022-04-06 09:35:55 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@855506b, messages=[], arguments=[--group-id, my-consumer-group-65801473, --bootstrap-server, my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092, --group-instance-id, instance451384674, --max-messages, 100, --topic, mirrormaker2-topic-example-2086367116], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt', podNamespace='namespace-121', bootstrapServer='my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092', topicName='mirrormaker2-topic-example-2086367116', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-65801473', consumerInstanceId='instance451384674', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1968c60b}
2022-04-06 09:35:55 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092#mirrormaker2-topic-example-2086367116 from pod my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt
2022-04-06 09:35:55 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt -n namespace-121 -- /opt/kafka/consumer.sh --group-id my-consumer-group-65801473 --bootstrap-server my-cluster-afc17b09-source-kafka-bootstrap.namespace-121.svc:9092 --group-instance-id instance451384674 --max-messages 100 --topic mirrormaker2-topic-example-2086367116
2022-04-06 09:36:01 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 09:36:01 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 09:36:01 [main] [32mINFO [m [MirrorMaker2IsolatedST:214] Now setting topic to my-cluster-afc17b09-source.mirrormaker2-topic-example-2086367116 and cluster to my-cluster-afc17b09-target - the messages should be mirrored
2022-04-06 09:36:01 [main] [32mINFO [m [MirrorMaker2IsolatedST:222] Consumer in target cluster and topic should receive 100 messages
2022-04-06 09:36:01 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@612dac5c, messages=[], arguments=[--group-id, my-consumer-group-572917976, --bootstrap-server, my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092, --group-instance-id, instance1131036302, --max-messages, 100, --topic, my-cluster-afc17b09-source.mirrormaker2-topic-example-2086367116], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt', podNamespace='namespace-121', bootstrapServer='my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092', topicName='my-cluster-afc17b09-source.mirrormaker2-topic-example-2086367116', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-572917976', consumerInstanceId='instance1131036302', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1f36fd1c}
2022-04-06 09:36:01 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092#my-cluster-afc17b09-source.mirrormaker2-topic-example-2086367116 from pod my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt
2022-04-06 09:36:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt -n namespace-121 -- /opt/kafka/consumer.sh --group-id my-consumer-group-572917976 --bootstrap-server my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092 --group-instance-id instance1131036302 --max-messages 100 --topic my-cluster-afc17b09-source.mirrormaker2-topic-example-2086367116
2022-04-06 09:36:06 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 09:36:06 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 09:36:06 [main] [32mINFO [m [MirrorMaker2IsolatedST:227] Changing topic to my-cluster-afc17b09-source.availability-topic-source-my-topic-1210124322-934201735
2022-04-06 09:36:06 [main] [32mINFO [m [MirrorMaker2IsolatedST:233] Check if mm2 mirror automatically created topic
2022-04-06 09:36:06 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1c5ebf4a, messages=[], arguments=[--group-id, my-consumer-group-44518129, --bootstrap-server, my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092, --group-instance-id, instance1713439143, --max-messages, 100, --topic, my-cluster-afc17b09-source.availability-topic-source-my-topic-1210124322-934201735], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt', podNamespace='namespace-121', bootstrapServer='my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092', topicName='my-cluster-afc17b09-source.availability-topic-source-my-topic-1210124322-934201735', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-44518129', consumerInstanceId='instance1713439143', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3e2a66ec}
2022-04-06 09:36:06 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092#my-cluster-afc17b09-source.availability-topic-source-my-topic-1210124322-934201735 from pod my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt
2022-04-06 09:36:06 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-afc17b09-kafka-clients-84bbb64969-mgmzt -n namespace-121 -- /opt/kafka/consumer.sh --group-id my-consumer-group-44518129 --bootstrap-server my-cluster-afc17b09-target-kafka-bootstrap.namespace-121.svc:9092 --group-instance-id instance1713439143 --max-messages 100 --topic my-cluster-afc17b09-source.availability-topic-source-my-topic-1210124322-934201735
2022-04-06 09:36:12 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 09:36:12 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 09:36:12 [main] [32mINFO [m [MirrorMaker2IsolatedST:236] Mirrored successful
2022-04-06 09:36:12 [main] [32mINFO [m [KafkaTopicUtils:124] Waiting for KafkaTopic change my-cluster-afc17b09-source.mirrormaker2-topic-example-2086367116
2022-04-06 09:36:52 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:36:52 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2
2022-04-06 09:36:52 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-2086367116 in namespace namespace-121
2022-04-06 09:36:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-afc17b09-target in namespace namespace-121
2022-04-06 09:36:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-afc17b09-source in namespace namespace-121
2022-04-06 09:36:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-afc17b09 in namespace namespace-121
2022-04-06 09:37:02 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-afc17b09-kafka-clients in namespace namespace-121
2022-04-06 09:37:42 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:37:42 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-121 for test case:testMirrorMaker2
2022-04-06 09:37:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2-FINISHED
2022-04-06 09:37:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:37:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:37:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKafkaMirrorMaker2ReflectsConnectorsState-STARTED
2022-04-06 09:37:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:37:48 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-122 for test case:testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-06 09:37:48 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-122
2022-04-06 09:37:48 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-122
2022-04-06 09:37:48 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-122
2022-04-06 09:37:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-379bf40d-source in namespace namespace-122
2022-04-06 09:37:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-06 09:37:48 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-379bf40d-target in namespace namespace-122
2022-04-06 09:37:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-06 09:37:48 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-379bf40d-source will have desired state: Ready
2022-04-06 09:38:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-379bf40d-source is in desired state: Ready
2022-04-06 09:38:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-379bf40d-target will have desired state: Ready
2022-04-06 09:38:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-379bf40d-target is in desired state: Ready
2022-04-06 09:38:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-379bf40d in namespace namespace-122
2022-04-06 09:38:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-122
2022-04-06 09:38:58 [main] [32mINFO [m [ResourceManager:481] Wait for KafkaMirrorMaker2: my-cluster-379bf40d will contain desired status message: One or more connectors are in FAILED state
2022-04-06 09:40:17 [main] [32mINFO [m [ResourceManager:492] KafkaMirrorMaker2: my-cluster-379bf40d contains desired message in status: One or more connectors are in FAILED state
2022-04-06 09:40:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-379bf40d will have desired state: Ready
2022-04-06 09:40:18 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-379bf40d is in desired state: Ready
2022-04-06 09:40:18 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 09:40:18 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-06 09:40:18 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-379bf40d-target in namespace namespace-122
2022-04-06 09:40:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-379bf40d in namespace namespace-122
2022-04-06 09:40:18 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-379bf40d-source in namespace namespace-122
2022-04-06 09:40:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 09:40:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-122 for test case:testKafkaMirrorMaker2ReflectsConnectorsState
2022-04-06 09:40:49 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKafkaMirrorMaker2ReflectsConnectorsState-FINISHED
2022-04-06 09:40:49 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 09:40:49 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 09:40:49 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateTLS-STARTED
2022-04-06 09:40:49 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 09:40:49 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-123 for test case:testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-06 09:40:49 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-123
2022-04-06 09:40:49 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-123
2022-04-06 09:40:49 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-123
2022-04-06 09:40:49 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-dd807b45-source in namespace namespace-123
2022-04-06 09:40:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 09:40:49 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-dd807b45-source will have desired state: Ready
2022-04-06 09:42:05 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-dd807b45-source is in desired state: Ready
2022-04-06 09:42:05 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-dd807b45-target in namespace namespace-123
2022-04-06 09:42:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 09:42:05 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-dd807b45-target will have desired state: Ready
2022-04-06 09:43:22 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-dd807b45-target is in desired state: Ready
2022-04-06 09:43:22 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-a-1749118359 in namespace namespace-123
2022-04-06 09:43:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 09:43:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-a-1749118359 will have desired state: Ready
2022-04-06 09:43:23 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-a-1749118359 is in desired state: Ready
2022-04-06 09:43:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-b-361086272 in namespace namespace-123
2022-04-06 09:43:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 09:43:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-b-361086272 will have desired state: Ready
2022-04-06 09:43:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-b-361086272 is in desired state: Ready
2022-04-06 09:43:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-dd807b45-my-user-source in namespace namespace-123
2022-04-06 09:43:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 09:43:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-dd807b45-my-user-source will have desired state: Ready
2022-04-06 09:43:25 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-dd807b45-my-user-source is in desired state: Ready
2022-04-06 09:43:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-dd807b45-my-user-target in namespace namespace-123
2022-04-06 09:43:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 09:43:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-dd807b45-my-user-target will have desired state: Ready
2022-04-06 09:43:26 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-dd807b45-my-user-target is in desired state: Ready
2022-04-06 09:43:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5db08bca-kafka-clients in namespace namespace-123
2022-04-06 09:43:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 09:43:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2113593103-229598269-test-1 in namespace namespace-123
2022-04-06 09:43:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 09:43:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2113593103-229598269-test-1 will have desired state: Ready
2022-04-06 09:43:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2113593103-229598269-test-1 is in desired state: Ready
2022-04-06 09:43:37 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2113593103-229598269-test-2 in namespace namespace-123
2022-04-06 09:43:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 09:43:37 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2113593103-229598269-test-2 will have desired state: Ready
2022-04-06 09:43:38 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2113593103-229598269-test-2 is in desired state: Ready
2022-04-06 09:43:38 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 09:43:38 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6d33d7a2, messages=[], arguments=[USER=my_cluster_dd807b45_my_user_target, --bootstrap-server, my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093, --max-messages, 200, --topic, my-topic-2113593103-229598269-test-2], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9', podNamespace='namespace-123', bootstrapServer='my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-topic-2113593103-229598269-test-2', maxMessages=200, kafkaUsername='my-cluster-dd807b45-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@53aa34c4}
2022-04-06 09:43:38 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093:my-topic-2113593103-229598269-test-2 from pod my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9
2022-04-06 09:43:38 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9 -n namespace-123 -- /opt/kafka/producer.sh USER=my_cluster_dd807b45_my_user_target --bootstrap-server my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093 --max-messages 200 --topic my-topic-2113593103-229598269-test-2
2022-04-06 09:43:42 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 09:43:42 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 09:43:42 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@132df74c, messages=[], arguments=[USER=my_cluster_dd807b45_my_user_target, --group-id, my-consumer-group-125080930, --bootstrap-server, my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093, --group-instance-id, instance2055432772, --max-messages, 200, --topic, my-topic-2113593103-229598269-test-2], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9', podNamespace='namespace-123', bootstrapServer='my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-topic-2113593103-229598269-test-2', maxMessages=200, kafkaUsername='my-cluster-dd807b45-my-user-target', consumerGroupName='my-consumer-group-125080930', consumerInstanceId='instance2055432772', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1123edb8}
2022-04-06 09:43:42 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093:my-topic-2113593103-229598269-test-2 from pod my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9
2022-04-06 09:43:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9 -n namespace-123 -- /opt/kafka/consumer.sh USER=my_cluster_dd807b45_my_user_target --group-id my-consumer-group-125080930 --bootstrap-server my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093 --group-instance-id instance2055432772 --max-messages 200 --topic my-topic-2113593103-229598269-test-2
2022-04-06 09:43:50 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 09:43:50 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 09:43:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-dd807b45 in namespace namespace-123
2022-04-06 09:43:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-123
2022-04-06 09:43:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-dd807b45 will have desired state: Ready
2022-04-06 09:44:58 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-dd807b45 is in desired state: Ready
2022-04-06 09:44:58 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@255fe52b, messages=[], arguments=[USER=my_cluster_dd807b45_my_user_source, --bootstrap-server, my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093, --max-messages, 200, --topic, mirrormaker2-topic-example-a-1749118359], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9', podNamespace='namespace-123', bootstrapServer='my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-1749118359', maxMessages=200, kafkaUsername='my-cluster-dd807b45-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3c1d4c38}
2022-04-06 09:44:58 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-1749118359 from pod my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9
2022-04-06 09:44:58 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9 -n namespace-123 -- /opt/kafka/producer.sh USER=my_cluster_dd807b45_my_user_source --bootstrap-server my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093 --max-messages 200 --topic mirrormaker2-topic-example-a-1749118359
2022-04-06 09:45:02 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 09:45:02 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 09:45:02 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3b82d680, messages=[], arguments=[USER=my_cluster_dd807b45_my_user_source, --group-id, my-consumer-group-125080930, --bootstrap-server, my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093, --group-instance-id, instance1850031945, --max-messages, 200, --topic, mirrormaker2-topic-example-a-1749118359], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9', podNamespace='namespace-123', bootstrapServer='my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-1749118359', maxMessages=200, kafkaUsername='my-cluster-dd807b45-my-user-source', consumerGroupName='my-consumer-group-125080930', consumerInstanceId='instance1850031945', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6d282b91}
2022-04-06 09:45:02 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-1749118359 from pod my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9
2022-04-06 09:45:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9 -n namespace-123 -- /opt/kafka/consumer.sh USER=my_cluster_dd807b45_my_user_source --group-id my-consumer-group-125080930 --bootstrap-server my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093 --group-instance-id instance1850031945 --max-messages 200 --topic mirrormaker2-topic-example-a-1749118359
2022-04-06 09:45:09 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 09:45:09 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 09:45:09 [main] [32mINFO [m [MirrorMaker2IsolatedST:1551] Consumer in target cluster and topic should receive 200 messages
2022-04-06 09:45:09 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@8d9c89e, messages=[], arguments=[USER=my_cluster_dd807b45_my_user_target, --group-id, my-consumer-group-125080930, --bootstrap-server, my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093, --group-instance-id, instance1625833190, --max-messages, 200, --topic, my-cluster-dd807b45-source.mirrormaker2-topic-example-a-1749118359], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9', podNamespace='namespace-123', bootstrapServer='my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-dd807b45-source.mirrormaker2-topic-example-a-1749118359', maxMessages=200, kafkaUsername='my-cluster-dd807b45-my-user-target', consumerGroupName='my-consumer-group-125080930', consumerInstanceId='instance1625833190', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@61ae0a66}
2022-04-06 09:45:09 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-dd807b45-source.mirrormaker2-topic-example-a-1749118359 from pod my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9
2022-04-06 09:45:09 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9 -n namespace-123 -- /opt/kafka/consumer.sh USER=my_cluster_dd807b45_my_user_target --group-id my-consumer-group-125080930 --bootstrap-server my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093 --group-instance-id instance1625833190 --max-messages 200 --topic my-cluster-dd807b45-source.mirrormaker2-topic-example-a-1749118359
2022-04-06 09:45:17 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 09:45:17 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 09:45:17 [main] [32mINFO [m [MirrorMaker2IsolatedST:1553] Messages successfully mirrored
2022-04-06 09:45:17 [main] [32mINFO [m [MirrorMaker2IsolatedST:1567] Renew Clients CA secret for Source cluster via annotation
2022-04-06 09:45:17 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-dd807b45-source-clients-ca-cert with annotation strimzi.io/force-renew=true
2022-04-06 09:45:17 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-dd807b45-source-kafka rolling update
2022-04-06 09:46:57 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-dd807b45-source-kafka has been successfully rolled
2022-04-06 09:46:57 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-dd807b45-source-kafka to be ready
2022-04-06 09:47:27 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-dd807b45-mirrormaker2 rolling update
2022-04-06 09:47:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-dd807b45-mirrormaker2 will be ready
2022-04-06 09:47:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-dd807b45-mirrormaker2 is ready
2022-04-06 09:47:37 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-dd807b45-mirrormaker2 rolling update finished
2022-04-06 09:47:37 [main] [32mINFO [m [MirrorMaker2IsolatedST:1573] Renew Clients CA secret for Target cluster via annotation
2022-04-06 09:47:37 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-dd807b45-target-clients-ca-cert with annotation strimzi.io/force-renew=true
2022-04-06 09:47:37 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-dd807b45-target-kafka rolling update
2022-04-06 09:48:47 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-dd807b45-target-kafka has been successfully rolled
2022-04-06 09:48:47 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-dd807b45-target-kafka to be ready
2022-04-06 09:49:17 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-dd807b45-mirrormaker2 rolling update
2022-04-06 09:50:38 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-dd807b45-mirrormaker2 will be ready
2022-04-06 09:50:38 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-dd807b45-mirrormaker2 is ready
2022-04-06 09:50:48 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-dd807b45-mirrormaker2 rolling update finished
2022-04-06 09:50:48 [main] [32mINFO [m [MirrorMaker2IsolatedST:1579] Send and receive messages after clients certs were removed
2022-04-06 09:50:48 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6f629402, messages=[], arguments=[USER=my_cluster_dd807b45_my_user_source, --bootstrap-server, my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093, --max-messages, 200, --topic, mirrormaker2-topic-example-a-1749118359], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9', podNamespace='namespace-123', bootstrapServer='my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-a-1749118359', maxMessages=200, kafkaUsername='my-cluster-dd807b45-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6402362d}
2022-04-06 09:50:48 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-a-1749118359 from pod my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9
2022-04-06 09:50:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9 -n namespace-123 -- /opt/kafka/producer.sh USER=my_cluster_dd807b45_my_user_source --bootstrap-server my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093 --max-messages 200 --topic mirrormaker2-topic-example-a-1749118359
2022-04-06 09:50:52 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 09:50:52 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 09:50:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:1595] Consumer in target cluster and topic should receive 200 messages
2022-04-06 09:50:52 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@78135402, messages=[], arguments=[USER=my_cluster_dd807b45_my_user_target, --group-id, my-consumer-group-225832478, --bootstrap-server, my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093, --group-instance-id, instance1771218822, --max-messages, 200, --topic, my-cluster-dd807b45-source.mirrormaker2-topic-example-a-1749118359], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9', podNamespace='namespace-123', bootstrapServer='my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-dd807b45-source.mirrormaker2-topic-example-a-1749118359', maxMessages=200, kafkaUsername='my-cluster-dd807b45-my-user-target', consumerGroupName='my-consumer-group-225832478', consumerInstanceId='instance1771218822', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@dd5b8cb}
2022-04-06 09:50:52 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-dd807b45-source.mirrormaker2-topic-example-a-1749118359 from pod my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9
2022-04-06 09:50:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9 -n namespace-123 -- /opt/kafka/consumer.sh USER=my_cluster_dd807b45_my_user_target --group-id my-consumer-group-225832478 --bootstrap-server my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093 --group-instance-id instance1771218822 --max-messages 200 --topic my-cluster-dd807b45-source.mirrormaker2-topic-example-a-1749118359
2022-04-06 09:50:59 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 09:50:59 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 09:50:59 [main] [32mINFO [m [MirrorMaker2IsolatedST:1597] Messages successfully mirrored
2022-04-06 09:50:59 [main] [32mINFO [m [MirrorMaker2IsolatedST:1599] Renew Cluster CA secret for Source clusters via annotation
2022-04-06 09:50:59 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-dd807b45-source-cluster-ca-cert with annotation strimzi.io/force-renew=true
2022-04-06 09:50:59 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-dd807b45-source-zookeeper rolling update
2022-04-06 09:52:29 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-dd807b45-source-zookeeper has been successfully rolled
2022-04-06 09:52:29 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-dd807b45-source-zookeeper to be ready
2022-04-06 09:53:00 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-dd807b45-source-kafka rolling update
2022-04-06 09:54:05 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-dd807b45-source-kafka has been successfully rolled
2022-04-06 09:54:05 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-dd807b45-source-kafka to be ready
2022-04-06 09:54:32 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-dd807b45-source-entity-operator rolling update
2022-04-06 09:54:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-dd807b45-source-entity-operator will be ready
2022-04-06 09:55:17 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-dd807b45-source-entity-operator is ready
2022-04-06 09:55:27 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-dd807b45-source-entity-operator rolling update finished
2022-04-06 09:55:27 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-dd807b45-mirrormaker2 rolling update
2022-04-06 09:55:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-dd807b45-mirrormaker2 will be ready
2022-04-06 09:55:27 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-dd807b45-mirrormaker2 is ready
2022-04-06 09:55:37 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-dd807b45-mirrormaker2 rolling update finished
2022-04-06 09:55:37 [main] [32mINFO [m [MirrorMaker2IsolatedST:1607] Renew Cluster CA secret for Target clusters via annotation
2022-04-06 09:55:37 [main] [32mINFO [m [SecretUtils:178] Annotating Secret:my-cluster-dd807b45-target-cluster-ca-cert with annotation strimzi.io/force-renew=true
2022-04-06 09:55:38 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-dd807b45-target-zookeeper rolling update
2022-04-06 09:56:48 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-dd807b45-target-zookeeper has been successfully rolled
2022-04-06 09:56:48 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-dd807b45-target-zookeeper to be ready
2022-04-06 09:57:21 [main] [32mINFO [m [RollingUpdateUtils:73] Waiting for component with name: my-cluster-dd807b45-target-kafka rolling update
2022-04-06 09:58:31 [main] [32mINFO [m [RollingUpdateUtils:86] Component with name: my-cluster-dd807b45-target-kafka has been successfully rolled
2022-04-06 09:58:31 [main] [32mINFO [m [RollingUpdateUtils:101] Waiting for 3 Pod(s) of my-cluster-dd807b45-target-kafka to be ready
2022-04-06 09:58:56 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-dd807b45-target-entity-operator rolling update
2022-04-06 09:59:01 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-dd807b45-target-entity-operator will be ready
2022-04-06 10:01:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-dd807b45-target-entity-operator is ready
2022-04-06 10:01:11 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-dd807b45-target-entity-operator rolling update finished
2022-04-06 10:01:11 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-dd807b45-mirrormaker2 rolling update
2022-04-06 10:01:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-dd807b45-mirrormaker2 will be ready
2022-04-06 10:01:11 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-dd807b45-mirrormaker2 is ready
2022-04-06 10:01:21 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-dd807b45-mirrormaker2 rolling update finished
2022-04-06 10:01:21 [main] [32mINFO [m [MirrorMaker2IsolatedST:1615] Send and receive messages after clients certs were removed
2022-04-06 10:01:21 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@1cd11d55, messages=[], arguments=[USER=my_cluster_dd807b45_my_user_source, --bootstrap-server, my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093, --max-messages, 200, --topic, mirrormaker2-topic-example-b-361086272], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9', podNamespace='namespace-123', bootstrapServer='my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093', topicName='mirrormaker2-topic-example-b-361086272', maxMessages=200, kafkaUsername='my-cluster-dd807b45-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4c5463ac}
2022-04-06 10:01:21 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093:mirrormaker2-topic-example-b-361086272 from pod my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9
2022-04-06 10:01:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9 -n namespace-123 -- /opt/kafka/producer.sh USER=my_cluster_dd807b45_my_user_source --bootstrap-server my-cluster-dd807b45-source-kafka-bootstrap.namespace-123.svc:9093 --max-messages 200 --topic mirrormaker2-topic-example-b-361086272
2022-04-06 10:01:25 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:01:25 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:01:25 [main] [32mINFO [m [MirrorMaker2IsolatedST:1631] Consumer in target cluster and topic should receive 200 messages
2022-04-06 10:01:25 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@134790e3, messages=[], arguments=[USER=my_cluster_dd807b45_my_user_target, --group-id, my-consumer-group-1217007045, --bootstrap-server, my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093, --group-instance-id, instance870046064, --max-messages, 200, --topic, my-cluster-dd807b45-source.mirrormaker2-topic-example-b-361086272], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9', podNamespace='namespace-123', bootstrapServer='my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093', topicName='my-cluster-dd807b45-source.mirrormaker2-topic-example-b-361086272', maxMessages=200, kafkaUsername='my-cluster-dd807b45-my-user-target', consumerGroupName='my-consumer-group-1217007045', consumerInstanceId='instance870046064', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7ce1c5d0}
2022-04-06 10:01:25 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093:my-cluster-dd807b45-source.mirrormaker2-topic-example-b-361086272 from pod my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9
2022-04-06 10:01:25 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5db08bca-kafka-clients-6f94bd7697-6psd9 -n namespace-123 -- /opt/kafka/consumer.sh USER=my_cluster_dd807b45_my_user_target --group-id my-consumer-group-1217007045 --bootstrap-server my-cluster-dd807b45-target-kafka-bootstrap.namespace-123.svc:9093 --group-instance-id instance870046064 --max-messages 200 --topic my-cluster-dd807b45-source.mirrormaker2-topic-example-b-361086272
2022-04-06 10:01:32 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:01:32 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:01:32 [main] [32mINFO [m [MirrorMaker2IsolatedST:1633] Messages successfully mirrored
2022-04-06 10:01:32 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:01:32 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-06 10:01:32 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5db08bca-kafka-clients in namespace namespace-123
2022-04-06 10:01:32 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2113593103-229598269-test-2 in namespace namespace-123
2022-04-06 10:01:32 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-a-1749118359 in namespace namespace-123
2022-04-06 10:01:32 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-dd807b45-target in namespace namespace-123
2022-04-06 10:01:42 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-dd807b45-source in namespace namespace-123
2022-04-06 10:01:42 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-dd807b45 in namespace namespace-123
2022-04-06 10:01:52 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-dd807b45-my-user-source in namespace namespace-123
2022-04-06 10:01:52 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-dd807b45-my-user-target in namespace namespace-123
2022-04-06 10:01:52 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2113593103-229598269-test-1 in namespace namespace-123
2022-04-06 10:02:02 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-b-361086272 in namespace namespace-123
2022-04-06 10:02:12 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:02:12 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-123 for test case:testKMM2RollAfterSecretsCertsUpdateTLS
2022-04-06 10:02:40 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateTLS-FINISHED
2022-04-06 10:02:40 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:02:40 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:02:40 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testStrimziIdentityReplicationPolicy-STARTED
2022-04-06 10:02:40 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:02:40 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-124 for test case:testStrimziIdentityReplicationPolicy
2022-04-06 10:02:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-124
2022-04-06 10:02:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-124
2022-04-06 10:02:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-124
2022-04-06 10:02:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f62ace6b-source in namespace namespace-124
2022-04-06 10:02:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-06 10:02:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f62ace6b-source will have desired state: Ready
2022-04-06 10:03:43 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f62ace6b-source is in desired state: Ready
2022-04-06 10:03:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-f62ace6b-target in namespace namespace-124
2022-04-06 10:03:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-06 10:03:43 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-f62ace6b-target will have desired state: Ready
2022-04-06 10:04:58 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-f62ace6b-target is in desired state: Ready
2022-04-06 10:04:58 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-f62ace6b in namespace namespace-124
2022-04-06 10:04:58 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-06 10:04:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-f62ace6b will have desired state: Ready
2022-04-06 10:04:59 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-f62ace6b is in desired state: Ready
2022-04-06 10:04:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-f62ace6b-kafka-clients in namespace namespace-124
2022-04-06 10:04:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-06 10:05:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-f62ace6b in namespace namespace-124
2022-04-06 10:05:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-124
2022-04-06 10:05:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-f62ace6b will have desired state: Ready
2022-04-06 10:06:18 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-f62ace6b is in desired state: Ready
2022-04-06 10:06:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:902] Sending and receiving messages via my-cluster-f62ace6b-source
2022-04-06 10:06:18 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 10:06:18 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@2d564259, messages=[], arguments=[--bootstrap-server, my-cluster-f62ace6b-source-kafka-bootstrap.namespace-124.svc:9092, --max-messages, 100, --topic, my-cluster-f62ace6b], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-f62ace6b-kafka-clients-7b9dfd5576-28msn', podNamespace='namespace-124', bootstrapServer='my-cluster-f62ace6b-source-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-f62ace6b', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@46fad687}
2022-04-06 10:06:18 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-f62ace6b-source-kafka-bootstrap.namespace-124.svc:9092:my-cluster-f62ace6b from pod my-cluster-f62ace6b-kafka-clients-7b9dfd5576-28msn
2022-04-06 10:06:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f62ace6b-kafka-clients-7b9dfd5576-28msn -n namespace-124 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-f62ace6b-source-kafka-bootstrap.namespace-124.svc:9092 --max-messages 100 --topic my-cluster-f62ace6b
2022-04-06 10:06:21 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 10:06:21 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 10:06:21 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5966c73, messages=[], arguments=[--group-id, my-consumer-group-469967981, --bootstrap-server, my-cluster-f62ace6b-source-kafka-bootstrap.namespace-124.svc:9092, --group-instance-id, instance836177471, --max-messages, 100, --topic, my-cluster-f62ace6b], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f62ace6b-kafka-clients-7b9dfd5576-28msn', podNamespace='namespace-124', bootstrapServer='my-cluster-f62ace6b-source-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-f62ace6b', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-469967981', consumerInstanceId='instance836177471', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@15c8cea3}
2022-04-06 10:06:21 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-f62ace6b-source-kafka-bootstrap.namespace-124.svc:9092#my-cluster-f62ace6b from pod my-cluster-f62ace6b-kafka-clients-7b9dfd5576-28msn
2022-04-06 10:06:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f62ace6b-kafka-clients-7b9dfd5576-28msn -n namespace-124 -- /opt/kafka/consumer.sh --group-id my-consumer-group-469967981 --bootstrap-server my-cluster-f62ace6b-source-kafka-bootstrap.namespace-124.svc:9092 --group-instance-id instance836177471 --max-messages 100 --topic my-cluster-f62ace6b
2022-04-06 10:06:27 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 10:06:27 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 10:06:27 [main] [32mINFO [m [MirrorMaker2IsolatedST:917] Changing to my-cluster-f62ace6b-target and will try to receive messages
2022-04-06 10:06:27 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1b767a7b, messages=[], arguments=[--group-id, my-consumer-group-469967981, --bootstrap-server, my-cluster-f62ace6b-target-kafka-bootstrap.namespace-124.svc:9092, --group-instance-id, instance1602959449, --max-messages, 100, --topic, my-cluster-f62ace6b], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-f62ace6b-kafka-clients-7b9dfd5576-28msn', podNamespace='namespace-124', bootstrapServer='my-cluster-f62ace6b-target-kafka-bootstrap.namespace-124.svc:9092', topicName='my-cluster-f62ace6b', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-469967981', consumerInstanceId='instance1602959449', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1a4da212}
2022-04-06 10:06:27 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-f62ace6b-target-kafka-bootstrap.namespace-124.svc:9092#my-cluster-f62ace6b from pod my-cluster-f62ace6b-kafka-clients-7b9dfd5576-28msn
2022-04-06 10:06:27 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-f62ace6b-kafka-clients-7b9dfd5576-28msn -n namespace-124 -- /opt/kafka/consumer.sh --group-id my-consumer-group-469967981 --bootstrap-server my-cluster-f62ace6b-target-kafka-bootstrap.namespace-124.svc:9092 --group-instance-id instance1602959449 --max-messages 100 --topic my-cluster-f62ace6b
2022-04-06 10:06:32 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 10:06:32 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 10:06:32 [main] [32mINFO [m [MirrorMaker2IsolatedST:925] Checking if the mirrored topic name is same as the original one
2022-04-06 10:06:35 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-124 exec my-cluster-f62ace6b-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-06 10:06:35 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 10:06:38 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-124 exec my-cluster-f62ace6b-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-cluster-f62ace6b
2022-04-06 10:06:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 10:06:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:06:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testStrimziIdentityReplicationPolicy
2022-04-06 10:06:38 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-f62ace6b in namespace namespace-124
2022-04-06 10:06:38 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f62ace6b-target in namespace namespace-124
2022-04-06 10:06:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-f62ace6b in namespace namespace-124
2022-04-06 10:06:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-f62ace6b-source in namespace namespace-124
2022-04-06 10:06:48 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-f62ace6b-kafka-clients in namespace namespace-124
2022-04-06 10:07:38 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:07:38 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-124 for test case:testStrimziIdentityReplicationPolicy
2022-04-06 10:07:44 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testStrimziIdentityReplicationPolicy-FINISHED
2022-04-06 10:07:44 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:07:44 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:07:44 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2Subresource-STARTED
2022-04-06 10:07:44 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:07:44 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-125 for test case:testScaleMirrorMaker2Subresource
2022-04-06 10:07:44 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-125
2022-04-06 10:07:44 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-125
2022-04-06 10:07:44 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-125
2022-04-06 10:07:44 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ca5417a9-source in namespace namespace-125
2022-04-06 10:07:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-06 10:07:44 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ca5417a9-source will have desired state: Ready
2022-04-06 10:08:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ca5417a9-source is in desired state: Ready
2022-04-06 10:08:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-ca5417a9-target in namespace namespace-125
2022-04-06 10:08:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-06 10:08:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-ca5417a9-target will have desired state: Ready
2022-04-06 10:10:01 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-ca5417a9-target is in desired state: Ready
2022-04-06 10:10:01 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-ca5417a9 in namespace namespace-125
2022-04-06 10:10:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-125
2022-04-06 10:10:01 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-ca5417a9 will have desired state: Ready
2022-04-06 10:11:18 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-ca5417a9 is in desired state: Ready
2022-04-06 10:11:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:675] -------> Scaling KafkaMirrorMaker2 subresource <-------
2022-04-06 10:11:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:676] Scaling subresource replicas to 4
2022-04-06 10:11:18 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-ca5417a9-mirrormaker2 will be ready
2022-04-06 10:11:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-ca5417a9-mirrormaker2 is ready
2022-04-06 10:11:18 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-ca5417a9-mirrormaker2 to be ready
2022-04-06 10:12:38 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-ca5417a9-mirrormaker2 is ready
2022-04-06 10:12:38 [main] [32mINFO [m [MirrorMaker2IsolatedST:680] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-06 10:12:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:12:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMaker2Subresource
2022-04-06 10:12:38 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ca5417a9-target in namespace namespace-125
2022-04-06 10:12:38 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-ca5417a9-source in namespace namespace-125
2022-04-06 10:12:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-ca5417a9 in namespace namespace-125
2022-04-06 10:12:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:12:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-125 for test case:testScaleMirrorMaker2Subresource
2022-04-06 10:13:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2Subresource-FINISHED
2022-04-06 10:13:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:13:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:13:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testIdentityReplicationPolicy-STARTED
2022-04-06 10:13:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:13:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-126 for test case:testIdentityReplicationPolicy
2022-04-06 10:13:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-126
2022-04-06 10:13:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-126
2022-04-06 10:13:25 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-126
2022-04-06 10:13:25 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bc075166-source in namespace namespace-126
2022-04-06 10:13:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-06 10:13:25 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bc075166-source will have desired state: Ready
2022-04-06 10:14:30 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bc075166-source is in desired state: Ready
2022-04-06 10:14:30 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-bc075166-target in namespace namespace-126
2022-04-06 10:14:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-06 10:14:30 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-bc075166-target will have desired state: Ready
2022-04-06 10:15:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-bc075166-target is in desired state: Ready
2022-04-06 10:15:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-bc075166 in namespace namespace-126
2022-04-06 10:15:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-06 10:15:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-bc075166 will have desired state: Ready
2022-04-06 10:15:37 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-bc075166 is in desired state: Ready
2022-04-06 10:15:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-bc075166-kafka-clients in namespace namespace-126
2022-04-06 10:15:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-06 10:15:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-bc075166 in namespace namespace-126
2022-04-06 10:15:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-126
2022-04-06 10:15:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-bc075166 will have desired state: Ready
2022-04-06 10:16:56 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-bc075166 is in desired state: Ready
2022-04-06 10:16:56 [main] [32mINFO [m [MirrorMaker2IsolatedST:833] Sending and receiving messages via my-cluster-bc075166-source
2022-04-06 10:16:56 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 10:16:56 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@78a82b19, messages=[], arguments=[--bootstrap-server, my-cluster-bc075166-source-kafka-bootstrap.namespace-126.svc:9092, --max-messages, 100, --topic, my-cluster-bc075166], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-bc075166-kafka-clients-79f66bc9f4-cz7mp', podNamespace='namespace-126', bootstrapServer='my-cluster-bc075166-source-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-bc075166', maxMessages=100, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@788218f1}
2022-04-06 10:16:56 [main] [32mINFO [m [InternalKafkaClient:94] Producing 100 messages to my-cluster-bc075166-source-kafka-bootstrap.namespace-126.svc:9092:my-cluster-bc075166 from pod my-cluster-bc075166-kafka-clients-79f66bc9f4-cz7mp
2022-04-06 10:16:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-bc075166-kafka-clients-79f66bc9f4-cz7mp -n namespace-126 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-bc075166-source-kafka-bootstrap.namespace-126.svc:9092 --max-messages 100 --topic my-cluster-bc075166
2022-04-06 10:16:59 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 10:16:59 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 100 messages
2022-04-06 10:16:59 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2139c35c, messages=[], arguments=[--group-id, my-consumer-group-856200253, --bootstrap-server, my-cluster-bc075166-source-kafka-bootstrap.namespace-126.svc:9092, --group-instance-id, instance573474140, --max-messages, 100, --topic, my-cluster-bc075166], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-bc075166-kafka-clients-79f66bc9f4-cz7mp', podNamespace='namespace-126', bootstrapServer='my-cluster-bc075166-source-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-bc075166', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-856200253', consumerInstanceId='instance573474140', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@49941f0f}
2022-04-06 10:16:59 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-bc075166-source-kafka-bootstrap.namespace-126.svc:9092#my-cluster-bc075166 from pod my-cluster-bc075166-kafka-clients-79f66bc9f4-cz7mp
2022-04-06 10:16:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-bc075166-kafka-clients-79f66bc9f4-cz7mp -n namespace-126 -- /opt/kafka/consumer.sh --group-id my-consumer-group-856200253 --bootstrap-server my-cluster-bc075166-source-kafka-bootstrap.namespace-126.svc:9092 --group-instance-id instance573474140 --max-messages 100 --topic my-cluster-bc075166
2022-04-06 10:17:04 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 10:17:04 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 10:17:04 [main] [32mINFO [m [MirrorMaker2IsolatedST:848] Changing to my-cluster-bc075166-target and will try to receive messages
2022-04-06 10:17:04 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6b48a5b2, messages=[], arguments=[--group-id, my-consumer-group-856200253, --bootstrap-server, my-cluster-bc075166-target-kafka-bootstrap.namespace-126.svc:9092, --group-instance-id, instance1913880725, --max-messages, 100, --topic, my-cluster-bc075166], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-bc075166-kafka-clients-79f66bc9f4-cz7mp', podNamespace='namespace-126', bootstrapServer='my-cluster-bc075166-target-kafka-bootstrap.namespace-126.svc:9092', topicName='my-cluster-bc075166', maxMessages=100, kafkaUsername='null', consumerGroupName='my-consumer-group-856200253', consumerInstanceId='instance1913880725', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1870c481}
2022-04-06 10:17:04 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 100 messages from my-cluster-bc075166-target-kafka-bootstrap.namespace-126.svc:9092#my-cluster-bc075166 from pod my-cluster-bc075166-kafka-clients-79f66bc9f4-cz7mp
2022-04-06 10:17:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-bc075166-kafka-clients-79f66bc9f4-cz7mp -n namespace-126 -- /opt/kafka/consumer.sh --group-id my-consumer-group-856200253 --bootstrap-server my-cluster-bc075166-target-kafka-bootstrap.namespace-126.svc:9092 --group-instance-id instance1913880725 --max-messages 100 --topic my-cluster-bc075166
2022-04-06 10:17:10 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 10:17:10 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 100 messages
2022-04-06 10:17:10 [main] [32mINFO [m [MirrorMaker2IsolatedST:856] Checking if the mirrored topic name is same as the original one
2022-04-06 10:17:13 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-126 exec my-cluster-bc075166-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --list --bootstrap-server localhost:9092
2022-04-06 10:17:13 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 10:17:16 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-126 exec my-cluster-bc075166-target-kafka-0 -- /bin/bash -c bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-cluster-bc075166
2022-04-06 10:17:16 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 10:17:16 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:17:16 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIdentityReplicationPolicy
2022-04-06 10:17:16 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-bc075166 in namespace namespace-126
2022-04-06 10:17:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-bc075166 in namespace namespace-126
2022-04-06 10:17:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bc075166-target in namespace namespace-126
2022-04-06 10:17:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-bc075166-source in namespace namespace-126
2022-04-06 10:17:26 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-bc075166-kafka-clients in namespace namespace-126
2022-04-06 10:18:06 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:18:06 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-126 for test case:testIdentityReplicationPolicy
2022-04-06 10:18:11 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testIdentityReplicationPolicy-FINISHED
2022-04-06 10:18:11 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:18:11 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:18:11 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateScramsha-STARTED
2022-04-06 10:18:11 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:18:11 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-127 for test case:testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-06 10:18:11 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-127
2022-04-06 10:18:11 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-127
2022-04-06 10:18:11 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-127
2022-04-06 10:18:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7aeaf28e-source in namespace namespace-127
2022-04-06 10:18:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:18:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7aeaf28e-source will have desired state: Ready
2022-04-06 10:19:16 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7aeaf28e-source is in desired state: Ready
2022-04-06 10:19:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7aeaf28e-target in namespace namespace-127
2022-04-06 10:19:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:19:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7aeaf28e-target will have desired state: Ready
2022-04-06 10:20:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7aeaf28e-target is in desired state: Ready
2022-04-06 10:20:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-a-495892235 in namespace namespace-127
2022-04-06 10:20:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:20:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-b-2028928705 in namespace namespace-127
2022-04-06 10:20:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:20:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-a-495892235 will have desired state: Ready
2022-04-06 10:20:21 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-a-495892235 is in desired state: Ready
2022-04-06 10:20:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-b-2028928705 will have desired state: Ready
2022-04-06 10:20:21 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-b-2028928705 is in desired state: Ready
2022-04-06 10:20:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-7aeaf28e-my-user-source in namespace namespace-127
2022-04-06 10:20:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:20:21 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-7aeaf28e-my-user-target in namespace namespace-127
2022-04-06 10:20:21 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:20:21 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-7aeaf28e-my-user-source will have desired state: Ready
2022-04-06 10:20:22 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-7aeaf28e-my-user-source is in desired state: Ready
2022-04-06 10:20:22 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-7aeaf28e-my-user-target will have desired state: Ready
2022-04-06 10:20:22 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-7aeaf28e-my-user-target is in desired state: Ready
2022-04-06 10:20:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7aeaf28e-kafka-clients in namespace namespace-127
2022-04-06 10:20:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:20:22 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7aeaf28e-kafka-clients will be ready
2022-04-06 10:20:24 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7aeaf28e-kafka-clients is ready
2022-04-06 10:20:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-7aeaf28e in namespace namespace-127
2022-04-06 10:20:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:20:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-7aeaf28e will have desired state: Ready
2022-04-06 10:21:32 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-7aeaf28e is in desired state: Ready
2022-04-06 10:21:32 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 10:21:32 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@44c60f1a, messages=[], arguments=[USER=my_cluster_7aeaf28e_my_user_source, --bootstrap-server, my-cluster-7aeaf28e-source-kafka-bootstrap.namespace-127.svc:9093, --max-messages, 200, --topic, mirrormaker2-topic-example-a-495892235], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7aeaf28e-kafka-clients-6b49878766-bpdls', podNamespace='namespace-127', bootstrapServer='my-cluster-7aeaf28e-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-a-495892235', maxMessages=200, kafkaUsername='my-cluster-7aeaf28e-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3e9f9ac}
2022-04-06 10:21:32 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-7aeaf28e-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-a-495892235 from pod my-cluster-7aeaf28e-kafka-clients-6b49878766-bpdls
2022-04-06 10:21:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7aeaf28e-kafka-clients-6b49878766-bpdls -n namespace-127 -- /opt/kafka/producer.sh USER=my_cluster_7aeaf28e_my_user_source --bootstrap-server my-cluster-7aeaf28e-source-kafka-bootstrap.namespace-127.svc:9093 --max-messages 200 --topic mirrormaker2-topic-example-a-495892235
2022-04-06 10:21:36 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:21:36 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:21:36 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7b4a7f9d, messages=[], arguments=[USER=my_cluster_7aeaf28e_my_user_source, --group-id, my-consumer-group-181086769, --bootstrap-server, my-cluster-7aeaf28e-source-kafka-bootstrap.namespace-127.svc:9093, --group-instance-id, instance1858191199, --max-messages, 200, --topic, mirrormaker2-topic-example-a-495892235], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7aeaf28e-kafka-clients-6b49878766-bpdls', podNamespace='namespace-127', bootstrapServer='my-cluster-7aeaf28e-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-a-495892235', maxMessages=200, kafkaUsername='my-cluster-7aeaf28e-my-user-source', consumerGroupName='my-consumer-group-181086769', consumerInstanceId='instance1858191199', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3722d44c}
2022-04-06 10:21:36 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-7aeaf28e-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-a-495892235 from pod my-cluster-7aeaf28e-kafka-clients-6b49878766-bpdls
2022-04-06 10:21:36 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7aeaf28e-kafka-clients-6b49878766-bpdls -n namespace-127 -- /opt/kafka/consumer.sh USER=my_cluster_7aeaf28e_my_user_source --group-id my-consumer-group-181086769 --bootstrap-server my-cluster-7aeaf28e-source-kafka-bootstrap.namespace-127.svc:9093 --group-instance-id instance1858191199 --max-messages 200 --topic mirrormaker2-topic-example-a-495892235
2022-04-06 10:21:43 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:21:43 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:21:43 [main] [32mINFO [m [MirrorMaker2IsolatedST:1338] Now messages should be mirrored to target topic and cluster
2022-04-06 10:21:43 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2ebb65fb, messages=[], arguments=[USER=my_cluster_7aeaf28e_my_user_target, --group-id, my-consumer-group-19435741, --bootstrap-server, my-cluster-7aeaf28e-target-kafka-bootstrap.namespace-127.svc:9093, --group-instance-id, instance172766824, --max-messages, 200, --topic, my-cluster-7aeaf28e-source.mirrormaker2-topic-example-a-495892235], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7aeaf28e-kafka-clients-6b49878766-bpdls', podNamespace='namespace-127', bootstrapServer='my-cluster-7aeaf28e-target-kafka-bootstrap.namespace-127.svc:9093', topicName='my-cluster-7aeaf28e-source.mirrormaker2-topic-example-a-495892235', maxMessages=200, kafkaUsername='my-cluster-7aeaf28e-my-user-target', consumerGroupName='my-consumer-group-19435741', consumerInstanceId='instance172766824', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@f800131}
2022-04-06 10:21:43 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-7aeaf28e-target-kafka-bootstrap.namespace-127.svc:9093:my-cluster-7aeaf28e-source.mirrormaker2-topic-example-a-495892235 from pod my-cluster-7aeaf28e-kafka-clients-6b49878766-bpdls
2022-04-06 10:21:43 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7aeaf28e-kafka-clients-6b49878766-bpdls -n namespace-127 -- /opt/kafka/consumer.sh USER=my_cluster_7aeaf28e_my_user_target --group-id my-consumer-group-19435741 --bootstrap-server my-cluster-7aeaf28e-target-kafka-bootstrap.namespace-127.svc:9093 --group-instance-id instance172766824 --max-messages 200 --topic my-cluster-7aeaf28e-source.mirrormaker2-topic-example-a-495892235
2022-04-06 10:21:51 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:21:51 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:21:51 [main] [32mINFO [m [MirrorMaker2IsolatedST:1340] Messages successfully mirrored
2022-04-06 10:21:51 [main] [32mINFO [m [MirrorMaker2IsolatedST:1344] Changing KafkaUser sha-password on KMM2 Source and make sure it rolled
2022-04-06 10:21:51 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7aeaf28e-mirrormaker2 rolling update
2022-04-06 10:23:26 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7aeaf28e-mirrormaker2 will be ready
2022-04-06 10:23:26 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7aeaf28e-mirrormaker2 is ready
2022-04-06 10:23:36 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7aeaf28e-mirrormaker2 rolling update finished
2022-04-06 10:23:36 [main] [32mINFO [m [MirrorMaker2IsolatedST:1354] Changing KafkaUser sha-password on KMM2 Target
2022-04-06 10:23:36 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-7aeaf28e-mirrormaker2 rolling update
2022-04-06 10:25:21 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7aeaf28e-mirrormaker2 will be ready
2022-04-06 10:25:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7aeaf28e-mirrormaker2 is ready
2022-04-06 10:25:31 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-7aeaf28e-mirrormaker2 rolling update finished
2022-04-06 10:25:31 [main] [32mINFO [m [MirrorMaker2IsolatedST:1364] Recreate kafkaClients pod with new passwords.
2022-04-06 10:25:31 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7aeaf28e-kafka-clients in namespace namespace-127
2022-04-06 10:26:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7aeaf28e-kafka-clients in namespace namespace-127
2022-04-06 10:26:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-127
2022-04-06 10:26:11 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7aeaf28e-kafka-clients will be ready
2022-04-06 10:26:13 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7aeaf28e-kafka-clients is ready
2022-04-06 10:26:13 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@28d9be6f, messages=[], arguments=[USER=my_cluster_7aeaf28e_my_user_source, --bootstrap-server, my-cluster-7aeaf28e-source-kafka-bootstrap.namespace-127.svc:9093, --max-messages, 200, --topic, mirrormaker2-topic-example-b-2028928705], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7aeaf28e-kafka-clients-578698f94-mdthx', podNamespace='namespace-127', bootstrapServer='my-cluster-7aeaf28e-source-kafka-bootstrap.namespace-127.svc:9093', topicName='mirrormaker2-topic-example-b-2028928705', maxMessages=200, kafkaUsername='my-cluster-7aeaf28e-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1b0e6208}
2022-04-06 10:26:13 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-7aeaf28e-source-kafka-bootstrap.namespace-127.svc:9093:mirrormaker2-topic-example-b-2028928705 from pod my-cluster-7aeaf28e-kafka-clients-578698f94-mdthx
2022-04-06 10:26:13 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7aeaf28e-kafka-clients-578698f94-mdthx -n namespace-127 -- /opt/kafka/producer.sh USER=my_cluster_7aeaf28e_my_user_source --bootstrap-server my-cluster-7aeaf28e-source-kafka-bootstrap.namespace-127.svc:9093 --max-messages 200 --topic mirrormaker2-topic-example-b-2028928705
2022-04-06 10:26:18 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:26:18 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:26:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:1385] Now messages should be mirrored to target topic and cluster
2022-04-06 10:26:18 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@32045afa, messages=[], arguments=[USER=my_cluster_7aeaf28e_my_user_target, --group-id, my-consumer-group-441012065, --bootstrap-server, my-cluster-7aeaf28e-target-kafka-bootstrap.namespace-127.svc:9093, --group-instance-id, instance147061571, --max-messages, 200, --topic, my-cluster-7aeaf28e-source.mirrormaker2-topic-example-b-2028928705], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7aeaf28e-kafka-clients-578698f94-mdthx', podNamespace='namespace-127', bootstrapServer='my-cluster-7aeaf28e-target-kafka-bootstrap.namespace-127.svc:9093', topicName='my-cluster-7aeaf28e-source.mirrormaker2-topic-example-b-2028928705', maxMessages=200, kafkaUsername='my-cluster-7aeaf28e-my-user-target', consumerGroupName='my-consumer-group-441012065', consumerInstanceId='instance147061571', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@5a726d9e}
2022-04-06 10:26:18 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-7aeaf28e-target-kafka-bootstrap.namespace-127.svc:9093:my-cluster-7aeaf28e-source.mirrormaker2-topic-example-b-2028928705 from pod my-cluster-7aeaf28e-kafka-clients-578698f94-mdthx
2022-04-06 10:26:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7aeaf28e-kafka-clients-578698f94-mdthx -n namespace-127 -- /opt/kafka/consumer.sh USER=my_cluster_7aeaf28e_my_user_target --group-id my-consumer-group-441012065 --bootstrap-server my-cluster-7aeaf28e-target-kafka-bootstrap.namespace-127.svc:9093 --group-instance-id instance147061571 --max-messages 200 --topic my-cluster-7aeaf28e-source.mirrormaker2-topic-example-b-2028928705
2022-04-06 10:26:25 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:26:25 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:26:25 [main] [32mINFO [m [MirrorMaker2IsolatedST:1387] Messages successfully mirrored
2022-04-06 10:26:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:26:25 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-06 10:26:25 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-7aeaf28e-my-user-target in namespace namespace-127
2022-04-06 10:26:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-a-495892235 in namespace namespace-127
2022-04-06 10:26:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-7aeaf28e in namespace namespace-127
2022-04-06 10:26:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7aeaf28e-kafka-clients in namespace namespace-127
2022-04-06 10:26:35 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-7aeaf28e-my-user-source in namespace namespace-127
2022-04-06 10:26:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7aeaf28e-kafka-clients in namespace namespace-127
2022-04-06 10:26:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-b-2028928705 in namespace namespace-127
2022-04-06 10:26:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7aeaf28e-target in namespace namespace-127
2022-04-06 10:26:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7aeaf28e-source in namespace namespace-127
2022-04-06 10:27:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:27:05 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-127 for test case:testKMM2RollAfterSecretsCertsUpdateScramsha
2022-04-06 10:27:33 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testKMM2RollAfterSecretsCertsUpdateScramsha-FINISHED
2022-04-06 10:27:33 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:27:33 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:27:33 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndTlsClientAuth-STARTED
2022-04-06 10:27:33 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:27:33 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-128 for test case:testMirrorMaker2TlsAndTlsClientAuth
2022-04-06 10:27:33 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-128
2022-04-06 10:27:33 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-128
2022-04-06 10:27:33 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-128
2022-04-06 10:27:33 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-08649465-source in namespace namespace-128
2022-04-06 10:27:33 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:27:33 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-08649465-source will have desired state: Ready
2022-04-06 10:28:46 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-08649465-source is in desired state: Ready
2022-04-06 10:28:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-08649465-target in namespace namespace-128
2022-04-06 10:28:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:28:46 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-08649465-target will have desired state: Ready
2022-04-06 10:29:51 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-08649465-target is in desired state: Ready
2022-04-06 10:29:51 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-969353732 in namespace namespace-128
2022-04-06 10:29:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:29:51 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-969353732 will have desired state: Ready
2022-04-06 10:29:52 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-969353732 is in desired state: Ready
2022-04-06 10:29:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-08649465-my-user-source in namespace namespace-128
2022-04-06 10:29:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:29:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-08649465-my-user-source will have desired state: Ready
2022-04-06 10:29:53 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-08649465-my-user-source is in desired state: Ready
2022-04-06 10:29:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-08649465-my-user-target in namespace namespace-128
2022-04-06 10:29:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:29:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-08649465-my-user-target will have desired state: Ready
2022-04-06 10:29:54 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-08649465-my-user-target is in desired state: Ready
2022-04-06 10:29:54 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-08649465-kafka-clients in namespace namespace-128
2022-04-06 10:29:54 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:30:04 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1739926636-280160256-test-1 in namespace namespace-128
2022-04-06 10:30:04 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:30:04 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1739926636-280160256-test-1 will have desired state: Ready
2022-04-06 10:30:05 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1739926636-280160256-test-1 is in desired state: Ready
2022-04-06 10:30:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1739926636-280160256-test-2 in namespace namespace-128
2022-04-06 10:30:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:30:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1739926636-280160256-test-2 will have desired state: Ready
2022-04-06 10:30:06 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1739926636-280160256-test-2 is in desired state: Ready
2022-04-06 10:30:06 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 10:30:06 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2041716290-1394676426 in namespace namespace-128
2022-04-06 10:30:06 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:30:06 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2041716290-1394676426 will have desired state: Ready
2022-04-06 10:30:07 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2041716290-1394676426 is in desired state: Ready
2022-04-06 10:30:07 [main] [32mINFO [m [ClientUtils:127] Sending messages to - topic my-topic-1739926636-280160256-test-1, cluster my-cluster-08649465-source and message count of 200
2022-04-06 10:30:07 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@71db1032, messages=[], arguments=[USER=my_cluster_08649465_my_user_source, --bootstrap-server, my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093, --max-messages, 200, --topic, my-topic-2041716290-1394676426], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44', podNamespace='namespace-128', bootstrapServer='my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-2041716290-1394676426', maxMessages=200, kafkaUsername='my-cluster-08649465-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@79050518}
2022-04-06 10:30:07 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093:my-topic-2041716290-1394676426 from pod my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44
2022-04-06 10:30:07 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44 -n namespace-128 -- /opt/kafka/producer.sh USER=my_cluster_08649465_my_user_source --bootstrap-server my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093 --max-messages 200 --topic my-topic-2041716290-1394676426
2022-04-06 10:30:11 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:30:11 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:30:11 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@190d4ebf, messages=[], arguments=[USER=my_cluster_08649465_my_user_source, --group-id, my-consumer-group-132243294, --bootstrap-server, my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093, --group-instance-id, instance1944508981, --max-messages, 200, --topic, my-topic-2041716290-1394676426], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44', podNamespace='namespace-128', bootstrapServer='my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-2041716290-1394676426', maxMessages=200, kafkaUsername='my-cluster-08649465-my-user-source', consumerGroupName='my-consumer-group-132243294', consumerInstanceId='instance1944508981', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4871af6c}
2022-04-06 10:30:11 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093:my-topic-2041716290-1394676426 from pod my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44
2022-04-06 10:30:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44 -n namespace-128 -- /opt/kafka/consumer.sh USER=my_cluster_08649465_my_user_source --group-id my-consumer-group-132243294 --bootstrap-server my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093 --group-instance-id instance1944508981 --max-messages 200 --topic my-topic-2041716290-1394676426
2022-04-06 10:30:18 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:30:18 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:30:18 [main] [32mINFO [m [ClientUtils:133] Sent 200 and received 200
2022-04-06 10:30:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:328] Setting topic to my-topic-1739926636-280160256-test-2, cluster to my-cluster-08649465-target and changing user to my-cluster-08649465-my-user-target
2022-04-06 10:30:18 [main] [32mINFO [m [MirrorMaker2IsolatedST:337] Sending messages to - topic my-topic-1739926636-280160256-test-2, cluster my-cluster-08649465-target and message count of 200
2022-04-06 10:30:18 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@8cff40a, messages=[], arguments=[USER=my_cluster_08649465_my_user_target, --bootstrap-server, my-cluster-08649465-target-kafka-bootstrap.namespace-128.svc:9093, --max-messages, 200, --topic, my-topic-1739926636-280160256-test-2], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44', podNamespace='namespace-128', bootstrapServer='my-cluster-08649465-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-1739926636-280160256-test-2', maxMessages=200, kafkaUsername='my-cluster-08649465-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@307e972c}
2022-04-06 10:30:18 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-08649465-target-kafka-bootstrap.namespace-128.svc:9093:my-topic-1739926636-280160256-test-2 from pod my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44
2022-04-06 10:30:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44 -n namespace-128 -- /opt/kafka/producer.sh USER=my_cluster_08649465_my_user_target --bootstrap-server my-cluster-08649465-target-kafka-bootstrap.namespace-128.svc:9093 --max-messages 200 --topic my-topic-1739926636-280160256-test-2
2022-04-06 10:30:22 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:30:22 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:30:22 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3e0be719, messages=[], arguments=[USER=my_cluster_08649465_my_user_target, --group-id, my-consumer-group-1967511194, --bootstrap-server, my-cluster-08649465-target-kafka-bootstrap.namespace-128.svc:9093, --group-instance-id, instance1837994246, --max-messages, 200, --topic, my-topic-1739926636-280160256-test-2], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44', podNamespace='namespace-128', bootstrapServer='my-cluster-08649465-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-topic-1739926636-280160256-test-2', maxMessages=200, kafkaUsername='my-cluster-08649465-my-user-target', consumerGroupName='my-consumer-group-1967511194', consumerInstanceId='instance1837994246', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@4d0020b0}
2022-04-06 10:30:22 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-08649465-target-kafka-bootstrap.namespace-128.svc:9093:my-topic-1739926636-280160256-test-2 from pod my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44
2022-04-06 10:30:22 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44 -n namespace-128 -- /opt/kafka/consumer.sh USER=my_cluster_08649465_my_user_target --group-id my-consumer-group-1967511194 --bootstrap-server my-cluster-08649465-target-kafka-bootstrap.namespace-128.svc:9093 --group-instance-id instance1837994246 --max-messages 200 --topic my-topic-1739926636-280160256-test-2
2022-04-06 10:30:29 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:30:29 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:30:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-08649465 in namespace namespace-128
2022-04-06 10:30:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-128
2022-04-06 10:30:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-08649465 will have desired state: Ready
2022-04-06 10:31:49 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-08649465 is in desired state: Ready
2022-04-06 10:31:49 [main] [32mINFO [m [MirrorMaker2IsolatedST:397] Setting topic to mirrormaker2-topic-example-969353732, cluster to my-cluster-08649465-source and changing user to my-cluster-08649465-my-user-source
2022-04-06 10:31:49 [main] [32mINFO [m [MirrorMaker2IsolatedST:407] Sending messages to - topic mirrormaker2-topic-example-969353732, cluster my-cluster-08649465-source and message count of 200
2022-04-06 10:31:49 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@208bb443, messages=[], arguments=[USER=my_cluster_08649465_my_user_source, --bootstrap-server, my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093, --max-messages, 200, --topic, mirrormaker2-topic-example-969353732], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44', podNamespace='namespace-128', bootstrapServer='my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093', topicName='mirrormaker2-topic-example-969353732', maxMessages=200, kafkaUsername='my-cluster-08649465-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@41d9a04e}
2022-04-06 10:31:49 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093:mirrormaker2-topic-example-969353732 from pod my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44
2022-04-06 10:31:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44 -n namespace-128 -- /opt/kafka/producer.sh USER=my_cluster_08649465_my_user_source --bootstrap-server my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093 --max-messages 200 --topic mirrormaker2-topic-example-969353732
2022-04-06 10:31:53 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:31:53 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:31:53 [main] [32mINFO [m [MirrorMaker2IsolatedST:411] Receiving messages from - topic mirrormaker2-topic-example-969353732, cluster my-cluster-08649465-source and message count of 200
2022-04-06 10:31:53 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1dd23928, messages=[], arguments=[USER=my_cluster_08649465_my_user_source, --group-id, my-consumer-group-1967511194, --bootstrap-server, my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093, --group-instance-id, instance1366052877, --max-messages, 200, --topic, mirrormaker2-topic-example-969353732], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44', podNamespace='namespace-128', bootstrapServer='my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093', topicName='mirrormaker2-topic-example-969353732', maxMessages=200, kafkaUsername='my-cluster-08649465-my-user-source', consumerGroupName='my-consumer-group-1967511194', consumerInstanceId='instance1366052877', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@11853086}
2022-04-06 10:31:53 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093:mirrormaker2-topic-example-969353732 from pod my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44
2022-04-06 10:31:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44 -n namespace-128 -- /opt/kafka/consumer.sh USER=my_cluster_08649465_my_user_source --group-id my-consumer-group-1967511194 --bootstrap-server my-cluster-08649465-source-kafka-bootstrap.namespace-128.svc:9093 --group-instance-id instance1366052877 --max-messages 200 --topic mirrormaker2-topic-example-969353732
2022-04-06 10:32:00 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:32:00 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:32:00 [main] [32mINFO [m [MirrorMaker2IsolatedST:418] Now setting topic to my-cluster-08649465-source.mirrormaker2-topic-example-969353732, cluster to my-cluster-08649465-target and user to my-cluster-08649465-my-user-target - the messages should be mirrored
2022-04-06 10:32:00 [main] [32mINFO [m [MirrorMaker2IsolatedST:427] Consumer in target cluster and topic should receive 200 messages
2022-04-06 10:32:00 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3deb0cc, messages=[], arguments=[USER=my_cluster_08649465_my_user_target, --group-id, my-consumer-group-1967511194, --bootstrap-server, my-cluster-08649465-target-kafka-bootstrap.namespace-128.svc:9093, --group-instance-id, instance1005254735, --max-messages, 200, --topic, my-cluster-08649465-source.mirrormaker2-topic-example-969353732], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44', podNamespace='namespace-128', bootstrapServer='my-cluster-08649465-target-kafka-bootstrap.namespace-128.svc:9093', topicName='my-cluster-08649465-source.mirrormaker2-topic-example-969353732', maxMessages=200, kafkaUsername='my-cluster-08649465-my-user-target', consumerGroupName='my-consumer-group-1967511194', consumerInstanceId='instance1005254735', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6086af7d}
2022-04-06 10:32:00 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-08649465-target-kafka-bootstrap.namespace-128.svc:9093:my-cluster-08649465-source.mirrormaker2-topic-example-969353732 from pod my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44
2022-04-06 10:32:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-08649465-kafka-clients-5ddd68d6b6-45c44 -n namespace-128 -- /opt/kafka/consumer.sh USER=my_cluster_08649465_my_user_target --group-id my-consumer-group-1967511194 --bootstrap-server my-cluster-08649465-target-kafka-bootstrap.namespace-128.svc:9093 --group-instance-id instance1005254735 --max-messages 200 --topic my-cluster-08649465-source.mirrormaker2-topic-example-969353732
2022-04-06 10:32:06 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:32:06 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:32:06 [main] [32mINFO [m [MirrorMaker2IsolatedST:432] Messages successfully mirrored
2022-04-06 10:32:06 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:32:06 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2TlsAndTlsClientAuth
2022-04-06 10:32:06 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1739926636-280160256-test-1 in namespace namespace-128
2022-04-06 10:32:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-969353732 in namespace namespace-128
2022-04-06 10:32:06 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2041716290-1394676426 in namespace namespace-128
2022-04-06 10:32:06 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-08649465-kafka-clients in namespace namespace-128
2022-04-06 10:32:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-08649465 in namespace namespace-128
2022-04-06 10:32:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-08649465-my-user-target in namespace namespace-128
2022-04-06 10:32:27 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1739926636-280160256-test-2 in namespace namespace-128
2022-04-06 10:32:37 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-08649465-my-user-source in namespace namespace-128
2022-04-06 10:32:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-08649465-target in namespace namespace-128
2022-04-06 10:32:47 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-08649465-source in namespace namespace-128
2022-04-06 10:32:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:32:57 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-128 for test case:testMirrorMaker2TlsAndTlsClientAuth
2022-04-06 10:33:24 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndTlsClientAuth-FINISHED
2022-04-06 10:33:24 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:33:24 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:33:24 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-06 10:33:24 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:33:24 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-129 for test case:testConfigureDeploymentStrategy
2022-04-06 10:33:24 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-129
2022-04-06 10:33:24 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-129
2022-04-06 10:33:24 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-129
2022-04-06 10:33:24 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-730eb552-source in namespace namespace-129
2022-04-06 10:33:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-06 10:33:24 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-730eb552-source will have desired state: Ready
2022-04-06 10:34:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-730eb552-source is in desired state: Ready
2022-04-06 10:34:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-730eb552-target in namespace namespace-129
2022-04-06 10:34:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-06 10:34:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-730eb552-target will have desired state: Ready
2022-04-06 10:35:49 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-730eb552-target is in desired state: Ready
2022-04-06 10:35:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-730eb552 in namespace namespace-129
2022-04-06 10:35:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-129
2022-04-06 10:35:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-730eb552 will have desired state: Ready
2022-04-06 10:37:00 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-730eb552 is in desired state: Ready
2022-04-06 10:37:00 [main] [32mINFO [m [MirrorMaker2IsolatedST:959] Adding label to MirrorMaker2 resource, the CR should be recreated
2022-04-06 10:37:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-730eb552-mirrormaker2 will be ready
2022-04-06 10:37:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-730eb552-mirrormaker2 is ready
2022-04-06 10:37:00 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-730eb552-mirrormaker2 to be ready
2022-04-06 10:38:23 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-730eb552-mirrormaker2 is ready
2022-04-06 10:38:23 [main] [32mINFO [m [MirrorMaker2IsolatedST:966] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-06 10:38:23 [main] [32mINFO [m [MirrorMaker2IsolatedST:971] Changing deployment strategy to ROLLING_UPDATE
2022-04-06 10:38:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-730eb552 will have desired state: Ready
2022-04-06 10:38:23 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-730eb552 is in desired state: Ready
2022-04-06 10:38:23 [main] [32mINFO [m [MirrorMaker2IsolatedST:976] Adding another label to MirrorMaker2 resource, pods should be rolled
2022-04-06 10:38:23 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-730eb552-mirrormaker2 will be ready
2022-04-06 10:38:23 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-730eb552-mirrormaker2 is ready
2022-04-06 10:38:23 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-730eb552-mirrormaker2 to be ready
2022-04-06 10:39:38 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-730eb552-mirrormaker2 is ready
2022-04-06 10:39:38 [main] [32mINFO [m [MirrorMaker2IsolatedST:980] Checking that observed gen. higher (rolling update) and label is changed
2022-04-06 10:39:38 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:39:38 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-06 10:39:38 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-730eb552-target in namespace namespace-129
2022-04-06 10:39:38 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-730eb552-source in namespace namespace-129
2022-04-06 10:39:38 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-730eb552 in namespace namespace-129
2022-04-06 10:39:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:39:58 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-129 for test case:testConfigureDeploymentStrategy
2022-04-06 10:40:25 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-06 10:40:25 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:40:25 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:40:25 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2CorrectlyMirrorsHeaders-STARTED
2022-04-06 10:40:25 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:40:25 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-130 for test case:testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-06 10:40:25 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-130
2022-04-06 10:40:26 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-130
2022-04-06 10:40:26 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-130
2022-04-06 10:40:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3fa5c594-source in namespace namespace-130
2022-04-06 10:40:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-06 10:40:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3fa5c594-source will have desired state: Ready
2022-04-06 10:41:41 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3fa5c594-source is in desired state: Ready
2022-04-06 10:41:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-3fa5c594-target in namespace namespace-130
2022-04-06 10:41:41 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-06 10:41:41 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-3fa5c594-target will have desired state: Ready
2022-04-06 10:42:52 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-3fa5c594-target is in desired state: Ready
2022-04-06 10:42:52 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-cluster-3fa5c594-source-example-topic in namespace namespace-130
2022-04-06 10:42:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-06 10:42:52 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-cluster-3fa5c594-source-example-topic will have desired state: Ready
2022-04-06 10:42:53 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-cluster-3fa5c594-source-example-topic is in desired state: Ready
2022-04-06 10:42:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-3fa5c594 in namespace namespace-130
2022-04-06 10:42:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-06 10:42:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-3fa5c594 will have desired state: Ready
2022-04-06 10:43:59 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-3fa5c594 is in desired state: Ready
2022-04-06 10:43:59 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 10:43:59 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-3fa5c594-target-consumer in namespace namespace-130
2022-04-06 10:43:59 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-06 10:43:59 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-3fa5c594-target-consumer will be in active state
2022-04-06 10:44:00 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 10:44:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-3fa5c594-source-producer in namespace namespace-130
2022-04-06 10:44:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-130
2022-04-06 10:44:00 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-3fa5c594-source-producer will be in active state
2022-04-06 10:44:01 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-3fa5c594-source-producer and consumer my-cluster-3fa5c594-target-consumer finish
2022-04-06 10:45:45 [main] [32mINFO [m [MirrorMaker2IsolatedST:753] Checking log of my-cluster-3fa5c594-target-consumer job if the headers are correct
2022-04-06 10:45:45 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:45:45 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-06 10:45:45 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-3fa5c594 in namespace namespace-130
2022-04-06 10:45:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-3fa5c594-source-producer in namespace namespace-130
2022-04-06 10:45:45 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3fa5c594-target in namespace namespace-130
2022-04-06 10:45:45 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-3fa5c594-source in namespace namespace-130
2022-04-06 10:45:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-3fa5c594-target-consumer in namespace namespace-130
2022-04-06 10:45:45 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-cluster-3fa5c594-source-example-topic in namespace namespace-130
2022-04-06 10:46:05 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:46:05 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-130 for test case:testMirrorMaker2CorrectlyMirrorsHeaders
2022-04-06 10:46:32 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2CorrectlyMirrorsHeaders-FINISHED
2022-04-06 10:46:32 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:46:32 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:46:32 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndScramSha512Auth-STARTED
2022-04-06 10:46:32 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:46:32 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-131 for test case:testMirrorMaker2TlsAndScramSha512Auth
2022-04-06 10:46:32 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-131
2022-04-06 10:46:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-131
2022-04-06 10:46:32 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-131
2022-04-06 10:46:32 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7dee4d13-source in namespace namespace-131
2022-04-06 10:46:32 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 10:46:32 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7dee4d13-source will have desired state: Ready
2022-04-06 10:47:39 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7dee4d13-source is in desired state: Ready
2022-04-06 10:47:39 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7dee4d13-target in namespace namespace-131
2022-04-06 10:47:39 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 10:47:39 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7dee4d13-target will have desired state: Ready
2022-04-06 10:48:48 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7dee4d13-target is in desired state: Ready
2022-04-06 10:48:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic mirrormaker2-topic-example-1810284381 in namespace namespace-131
2022-04-06 10:48:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 10:48:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: mirrormaker2-topic-example-1810284381 will have desired state: Ready
2022-04-06 10:48:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: mirrormaker2-topic-example-1810284381 is in desired state: Ready
2022-04-06 10:48:49 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-7dee4d13-my-user-source in namespace namespace-131
2022-04-06 10:48:49 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 10:48:49 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-7dee4d13-my-user-source will have desired state: Ready
2022-04-06 10:48:50 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-7dee4d13-my-user-source is in desired state: Ready
2022-04-06 10:48:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-7dee4d13-my-user-target in namespace namespace-131
2022-04-06 10:48:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 10:48:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-7dee4d13-my-user-target will have desired state: Ready
2022-04-06 10:48:51 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-7dee4d13-my-user-target is in desired state: Ready
2022-04-06 10:48:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-7dee4d13-kafka-clients in namespace namespace-131
2022-04-06 10:48:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 10:48:51 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-7dee4d13-kafka-clients will be ready
2022-04-06 10:48:52 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-7dee4d13-kafka-clients is ready
2022-04-06 10:48:52 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 10:48:52 [main] [32mINFO [m [MirrorMaker2IsolatedST:536] Sending messages to - topic availability-topic-source-my-topic-1315757923-1050236255, cluster my-cluster-7dee4d13-source and message count of 200
2022-04-06 10:48:52 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@18d55aeb, messages=[], arguments=[USER=my_cluster_7dee4d13_my_user_source, --bootstrap-server, my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093, --max-messages, 200, --topic, availability-topic-source-my-topic-1315757923-1050236255], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb', podNamespace='namespace-131', bootstrapServer='my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-source-my-topic-1315757923-1050236255', maxMessages=200, kafkaUsername='my-cluster-7dee4d13-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@29c46fc6}
2022-04-06 10:48:52 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093:availability-topic-source-my-topic-1315757923-1050236255 from pod my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb
2022-04-06 10:48:52 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb -n namespace-131 -- /opt/kafka/producer.sh USER=my_cluster_7dee4d13_my_user_source --bootstrap-server my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093 --max-messages 200 --topic availability-topic-source-my-topic-1315757923-1050236255
2022-04-06 10:48:56 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:48:56 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:48:56 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@14b0c593, messages=[], arguments=[USER=my_cluster_7dee4d13_my_user_source, --group-id, my-consumer-group-1980889189, --bootstrap-server, my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093, --group-instance-id, instance428728413, --max-messages, 200, --topic, availability-topic-source-my-topic-1315757923-1050236255], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb', podNamespace='namespace-131', bootstrapServer='my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-source-my-topic-1315757923-1050236255', maxMessages=200, kafkaUsername='my-cluster-7dee4d13-my-user-source', consumerGroupName='my-consumer-group-1980889189', consumerInstanceId='instance428728413', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1e0023ca}
2022-04-06 10:48:56 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093:availability-topic-source-my-topic-1315757923-1050236255 from pod my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb
2022-04-06 10:48:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb -n namespace-131 -- /opt/kafka/consumer.sh USER=my_cluster_7dee4d13_my_user_source --group-id my-consumer-group-1980889189 --bootstrap-server my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093 --group-instance-id instance428728413 --max-messages 200 --topic availability-topic-source-my-topic-1315757923-1050236255
2022-04-06 10:49:03 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:49:03 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:49:03 [main] [32mINFO [m [MirrorMaker2IsolatedST:544] Setting topic to availability-topic-target-my-topic-1315757923-1050236255, cluster to my-cluster-7dee4d13-target and changing user to my-cluster-7dee4d13-my-user-target
2022-04-06 10:49:03 [main] [32mINFO [m [MirrorMaker2IsolatedST:553] Sending messages to - topic availability-topic-target-my-topic-1315757923-1050236255, cluster my-cluster-7dee4d13-target and message count of 200
2022-04-06 10:49:03 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@7e712b87, messages=[], arguments=[USER=my_cluster_7dee4d13_my_user_target, --bootstrap-server, my-cluster-7dee4d13-target-kafka-bootstrap.namespace-131.svc:9093, --max-messages, 200, --topic, availability-topic-target-my-topic-1315757923-1050236255], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb', podNamespace='namespace-131', bootstrapServer='my-cluster-7dee4d13-target-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-target-my-topic-1315757923-1050236255', maxMessages=200, kafkaUsername='my-cluster-7dee4d13-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2600c7ec}
2022-04-06 10:49:03 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-7dee4d13-target-kafka-bootstrap.namespace-131.svc:9093:availability-topic-target-my-topic-1315757923-1050236255 from pod my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb
2022-04-06 10:49:03 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb -n namespace-131 -- /opt/kafka/producer.sh USER=my_cluster_7dee4d13_my_user_target --bootstrap-server my-cluster-7dee4d13-target-kafka-bootstrap.namespace-131.svc:9093 --max-messages 200 --topic availability-topic-target-my-topic-1315757923-1050236255
2022-04-06 10:49:08 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:49:08 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:49:08 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@737e8410, messages=[], arguments=[USER=my_cluster_7dee4d13_my_user_target, --group-id, my-consumer-group-1980889189, --bootstrap-server, my-cluster-7dee4d13-target-kafka-bootstrap.namespace-131.svc:9093, --group-instance-id, instance1986462148, --max-messages, 200, --topic, availability-topic-target-my-topic-1315757923-1050236255], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb', podNamespace='namespace-131', bootstrapServer='my-cluster-7dee4d13-target-kafka-bootstrap.namespace-131.svc:9093', topicName='availability-topic-target-my-topic-1315757923-1050236255', maxMessages=200, kafkaUsername='my-cluster-7dee4d13-my-user-target', consumerGroupName='my-consumer-group-1980889189', consumerInstanceId='instance1986462148', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@617059f0}
2022-04-06 10:49:08 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-7dee4d13-target-kafka-bootstrap.namespace-131.svc:9093:availability-topic-target-my-topic-1315757923-1050236255 from pod my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb
2022-04-06 10:49:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb -n namespace-131 -- /opt/kafka/consumer.sh USER=my_cluster_7dee4d13_my_user_target --group-id my-consumer-group-1980889189 --bootstrap-server my-cluster-7dee4d13-target-kafka-bootstrap.namespace-131.svc:9093 --group-instance-id instance1986462148 --max-messages 200 --topic availability-topic-target-my-topic-1315757923-1050236255
2022-04-06 10:49:15 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:49:15 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:49:15 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-7dee4d13 in namespace namespace-131
2022-04-06 10:49:15 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-131
2022-04-06 10:49:15 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-7dee4d13 will have desired state: Ready
2022-04-06 10:50:28 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-7dee4d13 is in desired state: Ready
2022-04-06 10:50:28 [main] [32mINFO [m [MirrorMaker2IsolatedST:597] Setting topic to mirrormaker2-topic-example-1810284381, cluster to my-cluster-7dee4d13-source and changing user to my-cluster-7dee4d13-my-user-source
2022-04-06 10:50:28 [main] [32mINFO [m [MirrorMaker2IsolatedST:606] Sending messages to - topic mirrormaker2-topic-example-1810284381, cluster my-cluster-7dee4d13-source and message count of 200
2022-04-06 10:50:28 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3ec61082, messages=[], arguments=[USER=my_cluster_7dee4d13_my_user_source, --bootstrap-server, my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093, --max-messages, 200, --topic, mirrormaker2-topic-example-1810284381], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb', podNamespace='namespace-131', bootstrapServer='my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093', topicName='mirrormaker2-topic-example-1810284381', maxMessages=200, kafkaUsername='my-cluster-7dee4d13-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1998a08d}
2022-04-06 10:50:28 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093:mirrormaker2-topic-example-1810284381 from pod my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb
2022-04-06 10:50:28 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb -n namespace-131 -- /opt/kafka/producer.sh USER=my_cluster_7dee4d13_my_user_source --bootstrap-server my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093 --max-messages 200 --topic mirrormaker2-topic-example-1810284381
2022-04-06 10:50:32 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 10:50:32 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 10:50:32 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6801be1f, messages=[], arguments=[USER=my_cluster_7dee4d13_my_user_source, --group-id, my-consumer-group-1980889189, --bootstrap-server, my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093, --group-instance-id, instance883646664, --max-messages, 200, --topic, mirrormaker2-topic-example-1810284381], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb', podNamespace='namespace-131', bootstrapServer='my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093', topicName='mirrormaker2-topic-example-1810284381', maxMessages=200, kafkaUsername='my-cluster-7dee4d13-my-user-source', consumerGroupName='my-consumer-group-1980889189', consumerInstanceId='instance883646664', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@34c1ecc2}
2022-04-06 10:50:32 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093:mirrormaker2-topic-example-1810284381 from pod my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb
2022-04-06 10:50:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb -n namespace-131 -- /opt/kafka/consumer.sh USER=my_cluster_7dee4d13_my_user_source --group-id my-consumer-group-1980889189 --bootstrap-server my-cluster-7dee4d13-source-kafka-bootstrap.namespace-131.svc:9093 --group-instance-id instance883646664 --max-messages 200 --topic mirrormaker2-topic-example-1810284381
2022-04-06 10:50:39 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:50:39 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:50:39 [main] [32mINFO [m [MirrorMaker2IsolatedST:615] Changing to target - topic my-cluster-7dee4d13-source.mirrormaker2-topic-example-1810284381, cluster my-cluster-7dee4d13-target, user my-cluster-7dee4d13-my-user-target
2022-04-06 10:50:39 [main] [32mINFO [m [MirrorMaker2IsolatedST:623] Now messages should be mirrored to target topic and cluster
2022-04-06 10:50:39 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5946fe6b, messages=[], arguments=[USER=my_cluster_7dee4d13_my_user_target, --group-id, my-consumer-group-1980889189, --bootstrap-server, my-cluster-7dee4d13-target-kafka-bootstrap.namespace-131.svc:9093, --group-instance-id, instance617070536, --max-messages, 200, --topic, my-cluster-7dee4d13-source.mirrormaker2-topic-example-1810284381], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb', podNamespace='namespace-131', bootstrapServer='my-cluster-7dee4d13-target-kafka-bootstrap.namespace-131.svc:9093', topicName='my-cluster-7dee4d13-source.mirrormaker2-topic-example-1810284381', maxMessages=200, kafkaUsername='my-cluster-7dee4d13-my-user-target', consumerGroupName='my-consumer-group-1980889189', consumerInstanceId='instance617070536', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@66cdf19d}
2022-04-06 10:50:39 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-7dee4d13-target-kafka-bootstrap.namespace-131.svc:9093:my-cluster-7dee4d13-source.mirrormaker2-topic-example-1810284381 from pod my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb
2022-04-06 10:50:39 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-7dee4d13-kafka-clients-64b79867f6-qvqnb -n namespace-131 -- /opt/kafka/consumer.sh USER=my_cluster_7dee4d13_my_user_target --group-id my-consumer-group-1980889189 --bootstrap-server my-cluster-7dee4d13-target-kafka-bootstrap.namespace-131.svc:9093 --group-instance-id instance617070536 --max-messages 200 --topic my-cluster-7dee4d13-source.mirrormaker2-topic-example-1810284381
2022-04-06 10:50:46 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 10:50:46 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 10:50:46 [main] [32mINFO [m [MirrorMaker2IsolatedST:628] Messages successfully mirrored
2022-04-06 10:50:46 [main] [32mINFO [m [KafkaTopicUtils:78] Waiting for KafkaTopic my-cluster-7dee4d13-source.mirrormaker2-topic-example-1810284381 creation 
2022-04-06 10:50:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:50:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker2TlsAndScramSha512Auth
2022-04-06 10:50:46 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-7dee4d13-my-user-target in namespace namespace-131
2022-04-06 10:50:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-7dee4d13 in namespace namespace-131
2022-04-06 10:50:46 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7dee4d13-target in namespace namespace-131
2022-04-06 10:50:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7dee4d13-source in namespace namespace-131
2022-04-06 10:50:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic mirrormaker2-topic-example-1810284381 in namespace namespace-131
2022-04-06 10:50:56 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-7dee4d13-my-user-source in namespace namespace-131
2022-04-06 10:51:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-7dee4d13-kafka-clients in namespace namespace-131
2022-04-06 10:51:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:51:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-131 for test case:testMirrorMaker2TlsAndScramSha512Auth
2022-04-06 10:51:52 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testMirrorMaker2TlsAndScramSha512Auth-FINISHED
2022-04-06 10:51:52 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:51:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:51:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2ToZero-STARTED
2022-04-06 10:51:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:51:52 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-132 for test case:testScaleMirrorMaker2ToZero
2022-04-06 10:51:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-132
2022-04-06 10:51:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-132
2022-04-06 10:51:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-132
2022-04-06 10:51:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7e641d1f-source in namespace namespace-132
2022-04-06 10:51:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-06 10:51:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7e641d1f-source will have desired state: Ready
2022-04-06 10:53:02 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7e641d1f-source is in desired state: Ready
2022-04-06 10:53:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-7e641d1f-target in namespace namespace-132
2022-04-06 10:53:02 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-06 10:53:02 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-7e641d1f-target will have desired state: Ready
2022-04-06 10:54:09 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-7e641d1f-target is in desired state: Ready
2022-04-06 10:54:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 my-cluster-7e641d1f in namespace namespace-132
2022-04-06 10:54:09 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-132
2022-04-06 10:54:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: my-cluster-7e641d1f will have desired state: Ready
2022-04-06 10:55:19 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: my-cluster-7e641d1f is in desired state: Ready
2022-04-06 10:55:19 [main] [32mINFO [m [MirrorMaker2IsolatedST:781] Scaling MirrorMaker2 to zero
2022-04-06 10:55:27 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:55:27 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMaker2ToZero
2022-04-06 10:55:27 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7e641d1f-target in namespace namespace-132
2022-04-06 10:55:27 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-7e641d1f-source in namespace namespace-132
2022-04-06 10:55:27 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 my-cluster-7e641d1f in namespace namespace-132
2022-04-06 10:55:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:55:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-132 for test case:testScaleMirrorMaker2ToZero
2022-04-06 10:55:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST.testScaleMirrorMaker2ToZero-FINISHED
2022-04-06 10:55:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 10:55:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:55:58 [main] [32mINFO [m [ResourceManager:346] In context MirrorMaker2IsolatedST is everything deleted.
2022-04-06 10:55:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5,689.909 s - in io.strimzi.systemtest.mirrormaker.MirrorMaker2IsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
2022-04-06 10:55:58 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 10:56:23 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 10:56:23 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 10:56:23 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 10:56:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 10:56:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 10:56:23 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:23 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:23 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 10:56:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 10:56:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 10:56:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 10:56:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:33 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 10:56:33 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 10:56:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 10:56:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 10:56:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 10:56:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 10:56:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 10:56:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 10:56:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 10:56:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 10:56:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 10:56:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 10:56:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:53 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:53 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 10:56:59 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=120000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 10:56:59 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 10:56:59 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 10:56:59 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 10:56:59 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 10:56:59 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 10:56:59 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 10:57:00 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 10:57:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 10:57:00 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 10:57:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 10:57:00 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 10:57:00 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 10:57:00 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 10:57:00 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 10:57:00 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 10:57:00 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 10:57:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 10:57:00 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 10:57:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 10:57:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 10:57:42 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 10:57:42 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 10:57:52 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 10:57:52 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 10:57:52 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsAuthenticated-STARTED
2022-04-06 10:57:52 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 10:57:52 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-133 for test case:testMirrorMakerTlsAuthenticated
2022-04-06 10:57:52 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-133
2022-04-06 10:57:52 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-133
2022-04-06 10:57:52 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-133
2022-04-06 10:57:52 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b0cf8615-source in namespace namespace-133
2022-04-06 10:57:52 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 10:57:52 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b0cf8615-source will have desired state: Ready
2022-04-06 10:59:11 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b0cf8615-source is in desired state: Ready
2022-04-06 10:59:11 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-b0cf8615-target in namespace namespace-133
2022-04-06 10:59:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 10:59:11 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-b0cf8615-target will have desired state: Ready
2022-04-06 11:00:23 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-b0cf8615-target is in desired state: Ready
2022-04-06 11:00:23 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-609391865-1811347379-source-1472674002 in namespace namespace-133
2022-04-06 11:00:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:00:23 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-609391865-1811347379-source-1472674002 will have desired state: Ready
2022-04-06 11:00:24 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-609391865-1811347379-source-1472674002 is in desired state: Ready
2022-04-06 11:00:24 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-b0cf8615-my-user-source in namespace namespace-133
2022-04-06 11:00:24 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:00:24 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-b0cf8615-my-user-source will have desired state: Ready
2022-04-06 11:00:25 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-b0cf8615-my-user-source is in desired state: Ready
2022-04-06 11:00:25 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-b0cf8615-my-user-target in namespace namespace-133
2022-04-06 11:00:25 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:00:25 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-b0cf8615-my-user-target will have desired state: Ready
2022-04-06 11:00:26 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-b0cf8615-my-user-target is in desired state: Ready
2022-04-06 11:00:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-b0cf8615-kafka-clients in namespace namespace-133
2022-04-06 11:00:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:00:27 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-b0cf8615-kafka-clients will be ready
2022-04-06 11:00:29 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-b0cf8615-kafka-clients is ready
2022-04-06 11:00:29 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-417377503-587035333-test-1 in namespace namespace-133
2022-04-06 11:00:29 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:00:29 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-417377503-587035333-test-1 will have desired state: Ready
2022-04-06 11:00:30 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-417377503-587035333-test-1 is in desired state: Ready
2022-04-06 11:00:30 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-417377503-587035333-test-2 in namespace namespace-133
2022-04-06 11:00:30 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:00:30 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-417377503-587035333-test-2 will have desired state: Ready
2022-04-06 11:00:31 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-417377503-587035333-test-2 is in desired state: Ready
2022-04-06 11:00:31 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 11:00:31 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@af58538, messages=[], arguments=[USER=my_cluster_b0cf8615_my_user_source, --bootstrap-server, my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093, --max-messages, 200, --topic, my-topic-417377503-587035333-test-1], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9', podNamespace='namespace-133', bootstrapServer='my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-417377503-587035333-test-1', maxMessages=200, kafkaUsername='my-cluster-b0cf8615-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7840b252}
2022-04-06 11:00:31 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-417377503-587035333-test-1 from pod my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9
2022-04-06 11:00:31 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9 -n namespace-133 -- /opt/kafka/producer.sh USER=my_cluster_b0cf8615_my_user_source --bootstrap-server my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093 --max-messages 200 --topic my-topic-417377503-587035333-test-1
2022-04-06 11:00:34 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:00:34 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:00:34 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@63d7d55a, messages=[], arguments=[USER=my_cluster_b0cf8615_my_user_source, --group-id, my-consumer-group-1142100521, --bootstrap-server, my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093, --group-instance-id, instance69752258, --max-messages, 200, --topic, my-topic-417377503-587035333-test-1], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9', podNamespace='namespace-133', bootstrapServer='my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-417377503-587035333-test-1', maxMessages=200, kafkaUsername='my-cluster-b0cf8615-my-user-source', consumerGroupName='my-consumer-group-1142100521', consumerInstanceId='instance69752258', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1ef826f5}
2022-04-06 11:00:34 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-417377503-587035333-test-1 from pod my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9
2022-04-06 11:00:34 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9 -n namespace-133 -- /opt/kafka/consumer.sh USER=my_cluster_b0cf8615_my_user_source --group-id my-consumer-group-1142100521 --bootstrap-server my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093 --group-instance-id instance69752258 --max-messages 200 --topic my-topic-417377503-587035333-test-1
2022-04-06 11:00:42 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:00:42 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:00:42 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6b7f922, messages=[], arguments=[USER=my_cluster_b0cf8615_my_user_target, --bootstrap-server, my-cluster-b0cf8615-target-kafka-bootstrap.namespace-133.svc:9093, --max-messages, 200, --topic, my-topic-417377503-587035333-test-2], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9', podNamespace='namespace-133', bootstrapServer='my-cluster-b0cf8615-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-417377503-587035333-test-2', maxMessages=200, kafkaUsername='my-cluster-b0cf8615-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@45ad505d}
2022-04-06 11:00:42 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-b0cf8615-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-417377503-587035333-test-2 from pod my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9
2022-04-06 11:00:42 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9 -n namespace-133 -- /opt/kafka/producer.sh USER=my_cluster_b0cf8615_my_user_target --bootstrap-server my-cluster-b0cf8615-target-kafka-bootstrap.namespace-133.svc:9093 --max-messages 200 --topic my-topic-417377503-587035333-test-2
2022-04-06 11:00:45 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:00:45 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:00:45 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@487dbe4, messages=[], arguments=[USER=my_cluster_b0cf8615_my_user_target, --group-id, my-consumer-group-1311094770, --bootstrap-server, my-cluster-b0cf8615-target-kafka-bootstrap.namespace-133.svc:9093, --group-instance-id, instance1809796204, --max-messages, 200, --topic, my-topic-417377503-587035333-test-2], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9', podNamespace='namespace-133', bootstrapServer='my-cluster-b0cf8615-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-417377503-587035333-test-2', maxMessages=200, kafkaUsername='my-cluster-b0cf8615-my-user-target', consumerGroupName='my-consumer-group-1311094770', consumerInstanceId='instance1809796204', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@59a7a88f}
2022-04-06 11:00:45 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-b0cf8615-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-417377503-587035333-test-2 from pod my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9
2022-04-06 11:00:45 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9 -n namespace-133 -- /opt/kafka/consumer.sh USER=my_cluster_b0cf8615_my_user_target --group-id my-consumer-group-1311094770 --bootstrap-server my-cluster-b0cf8615-target-kafka-bootstrap.namespace-133.svc:9093 --group-instance-id instance1809796204 --max-messages 200 --topic my-topic-417377503-587035333-test-2
2022-04-06 11:00:53 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:00:53 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:00:53 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-b0cf8615 in namespace namespace-133
2022-04-06 11:00:53 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-133
2022-04-06 11:00:53 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-b0cf8615 will have desired state: Ready
2022-04-06 11:01:57 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-b0cf8615 is in desired state: Ready
2022-04-06 11:01:57 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@5f6d1549, messages=[], arguments=[USER=my_cluster_b0cf8615_my_user_source, --bootstrap-server, my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093, --max-messages, 200, --topic, my-topic-609391865-1811347379-source-1472674002], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9', podNamespace='namespace-133', bootstrapServer='my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-609391865-1811347379-source-1472674002', maxMessages=200, kafkaUsername='my-cluster-b0cf8615-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@81461c}
2022-04-06 11:01:57 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-609391865-1811347379-source-1472674002 from pod my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9
2022-04-06 11:01:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9 -n namespace-133 -- /opt/kafka/producer.sh USER=my_cluster_b0cf8615_my_user_source --bootstrap-server my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093 --max-messages 200 --topic my-topic-609391865-1811347379-source-1472674002
2022-04-06 11:02:01 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:02:01 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:02:01 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@16c22309, messages=[], arguments=[USER=my_cluster_b0cf8615_my_user_source, --group-id, my-consumer-group-130539432, --bootstrap-server, my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093, --group-instance-id, instance323815495, --max-messages, 200, --topic, my-topic-609391865-1811347379-source-1472674002], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9', podNamespace='namespace-133', bootstrapServer='my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-609391865-1811347379-source-1472674002', maxMessages=200, kafkaUsername='my-cluster-b0cf8615-my-user-source', consumerGroupName='my-consumer-group-130539432', consumerInstanceId='instance323815495', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1cf9272c}
2022-04-06 11:02:01 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093:my-topic-609391865-1811347379-source-1472674002 from pod my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9
2022-04-06 11:02:01 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9 -n namespace-133 -- /opt/kafka/consumer.sh USER=my_cluster_b0cf8615_my_user_source --group-id my-consumer-group-130539432 --bootstrap-server my-cluster-b0cf8615-source-kafka-bootstrap.namespace-133.svc:9093 --group-instance-id instance323815495 --max-messages 200 --topic my-topic-609391865-1811347379-source-1472674002
2022-04-06 11:02:08 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:02:08 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:02:08 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@60065c10, messages=[], arguments=[USER=my_cluster_b0cf8615_my_user_target, --group-id, my-consumer-group-92494623, --bootstrap-server, my-cluster-b0cf8615-target-kafka-bootstrap.namespace-133.svc:9093, --group-instance-id, instance597065874, --max-messages, 200, --topic, my-topic-609391865-1811347379-source-1472674002], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9', podNamespace='namespace-133', bootstrapServer='my-cluster-b0cf8615-target-kafka-bootstrap.namespace-133.svc:9093', topicName='my-topic-609391865-1811347379-source-1472674002', maxMessages=200, kafkaUsername='my-cluster-b0cf8615-my-user-target', consumerGroupName='my-consumer-group-92494623', consumerInstanceId='instance597065874', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2132bbc5}
2022-04-06 11:02:08 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-b0cf8615-target-kafka-bootstrap.namespace-133.svc:9093:my-topic-609391865-1811347379-source-1472674002 from pod my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9
2022-04-06 11:02:08 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-b0cf8615-kafka-clients-85bb964754-n8xd9 -n namespace-133 -- /opt/kafka/consumer.sh USER=my_cluster_b0cf8615_my_user_target --group-id my-consumer-group-92494623 --bootstrap-server my-cluster-b0cf8615-target-kafka-bootstrap.namespace-133.svc:9093 --group-instance-id instance597065874 --max-messages 200 --topic my-topic-609391865-1811347379-source-1472674002
2022-04-06 11:02:15 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:02:15 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:02:15 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:02:15 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerTlsAuthenticated
2022-04-06 11:02:15 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-b0cf8615-kafka-clients in namespace namespace-133
2022-04-06 11:02:15 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-417377503-587035333-test-2 in namespace namespace-133
2022-04-06 11:02:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-609391865-1811347379-source-1472674002 in namespace namespace-133
2022-04-06 11:02:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-417377503-587035333-test-1 in namespace namespace-133
2022-04-06 11:02:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-b0cf8615-my-user-source in namespace namespace-133
2022-04-06 11:02:25 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-b0cf8615 in namespace namespace-133
2022-04-06 11:02:25 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-b0cf8615-my-user-target in namespace namespace-133
2022-04-06 11:02:35 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b0cf8615-target in namespace namespace-133
2022-04-06 11:02:35 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-b0cf8615-source in namespace namespace-133
2022-04-06 11:02:55 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:02:55 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-133 for test case:testMirrorMakerTlsAuthenticated
2022-04-06 11:03:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsAuthenticated-FINISHED
2022-04-06 11:03:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:03:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:03:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsScramSha-STARTED
2022-04-06 11:03:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:03:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-134 for test case:testMirrorMakerTlsScramSha
2022-04-06 11:03:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-134
2022-04-06 11:03:23 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-134
2022-04-06 11:03:23 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-134
2022-04-06 11:03:23 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-566d05ca-source in namespace namespace-134
2022-04-06 11:03:23 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:03:23 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-566d05ca-source will have desired state: Ready
2022-04-06 11:04:26 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-566d05ca-source is in desired state: Ready
2022-04-06 11:04:26 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-566d05ca-target in namespace namespace-134
2022-04-06 11:04:26 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:04:26 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-566d05ca-target will have desired state: Ready
2022-04-06 11:05:42 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-566d05ca-target is in desired state: Ready
2022-04-06 11:05:42 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-469274240-1855352213 in namespace namespace-134
2022-04-06 11:05:42 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:05:42 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-469274240-1855352213 will have desired state: Ready
2022-04-06 11:05:43 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-469274240-1855352213 is in desired state: Ready
2022-04-06 11:05:43 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-566d05ca-my-user-source in namespace namespace-134
2022-04-06 11:05:43 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:05:43 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-566d05ca-my-user-source will have desired state: Ready
2022-04-06 11:05:44 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-566d05ca-my-user-source is in desired state: Ready
2022-04-06 11:05:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-cluster-566d05ca-my-user-target in namespace namespace-134
2022-04-06 11:05:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:05:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-cluster-566d05ca-my-user-target will have desired state: Ready
2022-04-06 11:05:45 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-cluster-566d05ca-my-user-target is in desired state: Ready
2022-04-06 11:05:45 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-566d05ca-kafka-clients in namespace namespace-134
2022-04-06 11:05:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:05:45 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-566d05ca-kafka-clients will be ready
2022-04-06 11:05:47 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-566d05ca-kafka-clients is ready
2022-04-06 11:05:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-469274240-1855352213-test-1 in namespace namespace-134
2022-04-06 11:05:47 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:05:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-469274240-1855352213-test-1 will have desired state: Ready
2022-04-06 11:05:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-469274240-1855352213-test-1 is in desired state: Ready
2022-04-06 11:05:48 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-469274240-1855352213-test-2 in namespace namespace-134
2022-04-06 11:05:48 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:05:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-469274240-1855352213-test-2 will have desired state: Ready
2022-04-06 11:05:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-469274240-1855352213-test-2 is in desired state: Ready
2022-04-06 11:05:49 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 11:05:49 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@588d8d63, messages=[], arguments=[USER=my_cluster_566d05ca_my_user_source, --bootstrap-server, my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093, --max-messages, 200, --topic, my-topic-469274240-1855352213-test-1], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp', podNamespace='namespace-134', bootstrapServer='my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-469274240-1855352213-test-1', maxMessages=200, kafkaUsername='my-cluster-566d05ca-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@10b7c0ce}
2022-04-06 11:05:49 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-469274240-1855352213-test-1 from pod my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp
2022-04-06 11:05:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp -n namespace-134 -- /opt/kafka/producer.sh USER=my_cluster_566d05ca_my_user_source --bootstrap-server my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093 --max-messages 200 --topic my-topic-469274240-1855352213-test-1
2022-04-06 11:05:53 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:05:53 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:05:53 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2ea453, messages=[], arguments=[USER=my_cluster_566d05ca_my_user_source, --group-id, my-consumer-group-369524074, --bootstrap-server, my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093, --group-instance-id, instance25642614, --max-messages, 200, --topic, my-topic-469274240-1855352213-test-1], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp', podNamespace='namespace-134', bootstrapServer='my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-469274240-1855352213-test-1', maxMessages=200, kafkaUsername='my-cluster-566d05ca-my-user-source', consumerGroupName='my-consumer-group-369524074', consumerInstanceId='instance25642614', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2eb1b0fb}
2022-04-06 11:05:53 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-469274240-1855352213-test-1 from pod my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp
2022-04-06 11:05:53 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp -n namespace-134 -- /opt/kafka/consumer.sh USER=my_cluster_566d05ca_my_user_source --group-id my-consumer-group-369524074 --bootstrap-server my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093 --group-instance-id instance25642614 --max-messages 200 --topic my-topic-469274240-1855352213-test-1
2022-04-06 11:06:00 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:06:00 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:06:00 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3b3f71e7, messages=[], arguments=[USER=my_cluster_566d05ca_my_user_target, --bootstrap-server, my-cluster-566d05ca-target-kafka-bootstrap.namespace-134.svc:9093, --max-messages, 200, --topic, my-topic-469274240-1855352213-test-2], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp', podNamespace='namespace-134', bootstrapServer='my-cluster-566d05ca-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-469274240-1855352213-test-2', maxMessages=200, kafkaUsername='my-cluster-566d05ca-my-user-target', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@34fcc7a0}
2022-04-06 11:06:00 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-566d05ca-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-469274240-1855352213-test-2 from pod my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp
2022-04-06 11:06:00 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp -n namespace-134 -- /opt/kafka/producer.sh USER=my_cluster_566d05ca_my_user_target --bootstrap-server my-cluster-566d05ca-target-kafka-bootstrap.namespace-134.svc:9093 --max-messages 200 --topic my-topic-469274240-1855352213-test-2
2022-04-06 11:06:04 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:06:04 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:06:04 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@6dd31b79, messages=[], arguments=[USER=my_cluster_566d05ca_my_user_target, --group-id, my-consumer-group-366218090, --bootstrap-server, my-cluster-566d05ca-target-kafka-bootstrap.namespace-134.svc:9093, --group-instance-id, instance819417931, --max-messages, 200, --topic, my-topic-469274240-1855352213-test-2], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp', podNamespace='namespace-134', bootstrapServer='my-cluster-566d05ca-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-469274240-1855352213-test-2', maxMessages=200, kafkaUsername='my-cluster-566d05ca-my-user-target', consumerGroupName='my-consumer-group-366218090', consumerInstanceId='instance819417931', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@182a2813}
2022-04-06 11:06:04 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-566d05ca-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-469274240-1855352213-test-2 from pod my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp
2022-04-06 11:06:04 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp -n namespace-134 -- /opt/kafka/consumer.sh USER=my_cluster_566d05ca_my_user_target --group-id my-consumer-group-366218090 --bootstrap-server my-cluster-566d05ca-target-kafka-bootstrap.namespace-134.svc:9093 --group-instance-id instance819417931 --max-messages 200 --topic my-topic-469274240-1855352213-test-2
2022-04-06 11:06:11 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:06:11 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:06:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-566d05ca in namespace namespace-134
2022-04-06 11:06:11 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-134
2022-04-06 11:06:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-566d05ca will have desired state: Ready
2022-04-06 11:07:15 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-566d05ca is in desired state: Ready
2022-04-06 11:07:15 [main] [32mINFO [m [InternalKafkaClient:123] Starting verifiableClient tls producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@42b2da8, messages=[], arguments=[USER=my_cluster_566d05ca_my_user_source, --bootstrap-server, my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093, --max-messages, 200, --topic, my-topic-469274240-1855352213], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp', podNamespace='namespace-134', bootstrapServer='my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-469274240-1855352213', maxMessages=200, kafkaUsername='my-cluster-566d05ca-my-user-source', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@7c948b26}
2022-04-06 11:07:15 [main] [32mINFO [m [InternalKafkaClient:124] Producing 200 messages to my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-469274240-1855352213 from pod my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp
2022-04-06 11:07:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp -n namespace-134 -- /opt/kafka/producer.sh USER=my_cluster_566d05ca_my_user_source --bootstrap-server my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093 --max-messages 200 --topic my-topic-469274240-1855352213
2022-04-06 11:07:19 [main] [32mINFO [m [InternalKafkaClient:127] Producer finished correctly: true
2022-04-06 11:07:19 [main] [32mINFO [m [InternalKafkaClient:131] Producer produced 200 messages
2022-04-06 11:07:19 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@47b356c8, messages=[], arguments=[USER=my_cluster_566d05ca_my_user_source, --group-id, my-consumer-group-2119494569, --bootstrap-server, my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093, --group-instance-id, instance1317386929, --max-messages, 200, --topic, my-topic-469274240-1855352213], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp', podNamespace='namespace-134', bootstrapServer='my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-469274240-1855352213', maxMessages=200, kafkaUsername='my-cluster-566d05ca-my-user-source', consumerGroupName='my-consumer-group-2119494569', consumerInstanceId='instance1317386929', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1f2633b1}
2022-04-06 11:07:19 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093:my-topic-469274240-1855352213 from pod my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp
2022-04-06 11:07:19 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp -n namespace-134 -- /opt/kafka/consumer.sh USER=my_cluster_566d05ca_my_user_source --group-id my-consumer-group-2119494569 --bootstrap-server my-cluster-566d05ca-source-kafka-bootstrap.namespace-134.svc:9093 --group-instance-id instance1317386929 --max-messages 200 --topic my-topic-469274240-1855352213
2022-04-06 11:07:26 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:07:26 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:07:26 [main] [32mINFO [m [InternalKafkaClient:191] Starting verifiableClient tls consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@661a908f, messages=[], arguments=[USER=my_cluster_566d05ca_my_user_target, --group-id, my-consumer-group-635022487, --bootstrap-server, my-cluster-566d05ca-target-kafka-bootstrap.namespace-134.svc:9093, --group-instance-id, instance1693827246, --max-messages, 200, --topic, my-topic-469274240-1855352213], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp', podNamespace='namespace-134', bootstrapServer='my-cluster-566d05ca-target-kafka-bootstrap.namespace-134.svc:9093', topicName='my-topic-469274240-1855352213', maxMessages=200, kafkaUsername='my-cluster-566d05ca-my-user-target', consumerGroupName='my-consumer-group-635022487', consumerInstanceId='instance1693827246', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1aa865fb}
2022-04-06 11:07:26 [main] [32mINFO [m [InternalKafkaClient:192] Consuming 200 messages from my-cluster-566d05ca-target-kafka-bootstrap.namespace-134.svc:9093:my-topic-469274240-1855352213 from pod my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp
2022-04-06 11:07:26 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-566d05ca-kafka-clients-9cfd94f89-cngcp -n namespace-134 -- /opt/kafka/consumer.sh USER=my_cluster_566d05ca_my_user_target --group-id my-consumer-group-635022487 --bootstrap-server my-cluster-566d05ca-target-kafka-bootstrap.namespace-134.svc:9093 --group-instance-id instance1693827246 --max-messages 200 --topic my-topic-469274240-1855352213
2022-04-06 11:07:33 [main] [32mINFO [m [InternalKafkaClient:195] Consumer finished correctly: true
2022-04-06 11:07:33 [main] [32mINFO [m [InternalKafkaClient:198] Consumer consumed 200 messages
2022-04-06 11:07:33 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:07:33 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMakerTlsScramSha
2022-04-06 11:07:33 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-566d05ca-kafka-clients in namespace namespace-134
2022-04-06 11:07:33 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-469274240-1855352213 in namespace namespace-134
2022-04-06 11:07:33 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-469274240-1855352213-test-2 in namespace namespace-134
2022-04-06 11:07:33 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-566d05ca-my-user-target in namespace namespace-134
2022-04-06 11:07:43 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-cluster-566d05ca-my-user-source in namespace namespace-134
2022-04-06 11:07:43 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-566d05ca in namespace namespace-134
2022-04-06 11:07:43 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-566d05ca-target in namespace namespace-134
2022-04-06 11:07:53 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-469274240-1855352213-test-1 in namespace namespace-134
2022-04-06 11:07:53 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-566d05ca-source in namespace namespace-134
2022-04-06 11:08:13 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:08:13 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-134 for test case:testMirrorMakerTlsScramSha
2022-04-06 11:08:40 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMakerTlsScramSha-FINISHED
2022-04-06 11:08:40 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:08:40 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:08:40 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testIncludeList-STARTED
2022-04-06 11:08:40 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:08:40 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-135 for test case:testIncludeList
2022-04-06 11:08:40 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-135
2022-04-06 11:08:40 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-135
2022-04-06 11:08:40 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-135
2022-04-06 11:08:40 [main] [32mINFO [m [MirrorMakerIsolatedST:471] Creating kafka source cluster my-cluster-9fedf48b-source
2022-04-06 11:08:40 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9fedf48b-source in namespace namespace-135
2022-04-06 11:08:40 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-06 11:08:40 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9fedf48b-source will have desired state: Ready
2022-04-06 11:09:56 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9fedf48b-source is in desired state: Ready
2022-04-06 11:09:56 [main] [32mINFO [m [MirrorMakerIsolatedST:473] Creating kafka target cluster my-cluster-9fedf48b-target
2022-04-06 11:09:56 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-9fedf48b-target in namespace namespace-135
2022-04-06 11:09:56 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-06 11:09:56 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-9fedf48b-target will have desired state: Ready
2022-04-06 11:11:17 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-9fedf48b-target is in desired state: Ready
2022-04-06 11:11:17 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic included-topic in namespace namespace-135
2022-04-06 11:11:17 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-06 11:11:17 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: included-topic will have desired state: Ready
2022-04-06 11:11:18 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: included-topic is in desired state: Ready
2022-04-06 11:11:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic not-included-topic in namespace namespace-135
2022-04-06 11:11:18 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-06 11:11:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: not-included-topic will have desired state: Ready
2022-04-06 11:11:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: not-included-topic is in desired state: Ready
2022-04-06 11:11:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-9fedf48b-kafka-clients in namespace namespace-135
2022-04-06 11:11:19 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-06 11:11:19 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-9fedf48b-kafka-clients will be ready
2022-04-06 11:11:21 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-9fedf48b-kafka-clients is ready
2022-04-06 11:11:21 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3965bede, messages=[], arguments=[--bootstrap-server, my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092, --max-messages, 200, --topic, topic-example-10], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-9fedf48b-kafka-clients-979698588-jt4f7', podNamespace='namespace-135', bootstrapServer='my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-10', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@668ffdcc}
2022-04-06 11:11:21 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092:topic-example-10 from pod my-cluster-9fedf48b-kafka-clients-979698588-jt4f7
2022-04-06 11:11:21 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9fedf48b-kafka-clients-979698588-jt4f7 -n namespace-135 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092 --max-messages 200 --topic topic-example-10
2022-04-06 11:11:24 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:11:24 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:11:24 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3ddcbafe, messages=[], arguments=[--group-id, my-consumer-group-1034863410, --bootstrap-server, my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092, --group-instance-id, instance290167367, --max-messages, 200, --topic, topic-example-10], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-9fedf48b-kafka-clients-979698588-jt4f7', podNamespace='namespace-135', bootstrapServer='my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-10', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1034863410', consumerInstanceId='instance290167367', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@24a4523b}
2022-04-06 11:11:24 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092#topic-example-10 from pod my-cluster-9fedf48b-kafka-clients-979698588-jt4f7
2022-04-06 11:11:24 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9fedf48b-kafka-clients-979698588-jt4f7 -n namespace-135 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1034863410 --bootstrap-server my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092 --group-instance-id instance290167367 --max-messages 200 --topic topic-example-10
2022-04-06 11:11:30 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:11:30 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:11:30 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3a0f5243, messages=[], arguments=[--bootstrap-server, my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092, --max-messages, 200, --topic, topic-example-11], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-9fedf48b-kafka-clients-979698588-jt4f7', podNamespace='namespace-135', bootstrapServer='my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-11', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@29db70d5}
2022-04-06 11:11:30 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092:topic-example-11 from pod my-cluster-9fedf48b-kafka-clients-979698588-jt4f7
2022-04-06 11:11:30 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9fedf48b-kafka-clients-979698588-jt4f7 -n namespace-135 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092 --max-messages 200 --topic topic-example-11
2022-04-06 11:11:32 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:11:32 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:11:32 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@64efbc90, messages=[], arguments=[--group-id, my-consumer-group-596389181, --bootstrap-server, my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092, --group-instance-id, instance1157155957, --max-messages, 200, --topic, topic-example-11], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-9fedf48b-kafka-clients-979698588-jt4f7', podNamespace='namespace-135', bootstrapServer='my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092', topicName='topic-example-11', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-596389181', consumerInstanceId='instance1157155957', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3cbceab3}
2022-04-06 11:11:32 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092#topic-example-11 from pod my-cluster-9fedf48b-kafka-clients-979698588-jt4f7
2022-04-06 11:11:32 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9fedf48b-kafka-clients-979698588-jt4f7 -n namespace-135 -- /opt/kafka/consumer.sh --group-id my-consumer-group-596389181 --bootstrap-server my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092 --group-instance-id instance1157155957 --max-messages 200 --topic topic-example-11
2022-04-06 11:11:38 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:11:38 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:11:38 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-9fedf48b in namespace namespace-135
2022-04-06 11:11:38 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-135
2022-04-06 11:11:38 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-9fedf48b will have desired state: Ready
2022-04-06 11:12:48 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-9fedf48b is in desired state: Ready
2022-04-06 11:12:48 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@569df0c1, messages=[], arguments=[--bootstrap-server, my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092, --max-messages, 200, --topic, included-topic], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-9fedf48b-kafka-clients-979698588-jt4f7', podNamespace='namespace-135', bootstrapServer='my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@16402500}
2022-04-06 11:12:48 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092:included-topic from pod my-cluster-9fedf48b-kafka-clients-979698588-jt4f7
2022-04-06 11:12:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9fedf48b-kafka-clients-979698588-jt4f7 -n namespace-135 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092 --max-messages 200 --topic included-topic
2022-04-06 11:12:51 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:12:51 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:12:51 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@3c20868, messages=[], arguments=[--group-id, my-consumer-group-1481336378, --bootstrap-server, my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092, --group-instance-id, instance1048333199, --max-messages, 200, --topic, included-topic], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-9fedf48b-kafka-clients-979698588-jt4f7', podNamespace='namespace-135', bootstrapServer='my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1481336378', consumerInstanceId='instance1048333199', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@14bd57da}
2022-04-06 11:12:51 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092#included-topic from pod my-cluster-9fedf48b-kafka-clients-979698588-jt4f7
2022-04-06 11:12:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9fedf48b-kafka-clients-979698588-jt4f7 -n namespace-135 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1481336378 --bootstrap-server my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092 --group-instance-id instance1048333199 --max-messages 200 --topic included-topic
2022-04-06 11:12:56 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:12:56 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:12:56 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@4c37244f, messages=[], arguments=[--group-id, my-consumer-group-148158541, --bootstrap-server, my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092, --group-instance-id, instance303349465, --max-messages, 200, --topic, included-topic], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-9fedf48b-kafka-clients-979698588-jt4f7', podNamespace='namespace-135', bootstrapServer='my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092', topicName='included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-148158541', consumerInstanceId='instance303349465', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@3a60fb29}
2022-04-06 11:12:56 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092#included-topic from pod my-cluster-9fedf48b-kafka-clients-979698588-jt4f7
2022-04-06 11:12:56 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9fedf48b-kafka-clients-979698588-jt4f7 -n namespace-135 -- /opt/kafka/consumer.sh --group-id my-consumer-group-148158541 --bootstrap-server my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092 --group-instance-id instance303349465 --max-messages 200 --topic included-topic
2022-04-06 11:13:02 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:13:02 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:13:02 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@215866fd, messages=[], arguments=[--bootstrap-server, my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092, --max-messages, 200, --topic, not-included-topic], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-9fedf48b-kafka-clients-979698588-jt4f7', podNamespace='namespace-135', bootstrapServer='my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@324aa994}
2022-04-06 11:13:02 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092:not-included-topic from pod my-cluster-9fedf48b-kafka-clients-979698588-jt4f7
2022-04-06 11:13:02 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9fedf48b-kafka-clients-979698588-jt4f7 -n namespace-135 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092 --max-messages 200 --topic not-included-topic
2022-04-06 11:13:05 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:13:05 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:13:05 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@693c22c4, messages=[], arguments=[--group-id, my-consumer-group-1665357097, --bootstrap-server, my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092, --group-instance-id, instance297087669, --max-messages, 200, --topic, not-included-topic], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-9fedf48b-kafka-clients-979698588-jt4f7', podNamespace='namespace-135', bootstrapServer='my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1665357097', consumerInstanceId='instance297087669', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1cdc784c}
2022-04-06 11:13:05 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092#not-included-topic from pod my-cluster-9fedf48b-kafka-clients-979698588-jt4f7
2022-04-06 11:13:05 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9fedf48b-kafka-clients-979698588-jt4f7 -n namespace-135 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1665357097 --bootstrap-server my-cluster-9fedf48b-source-kafka-bootstrap.namespace-135.svc:9092 --group-instance-id instance297087669 --max-messages 200 --topic not-included-topic
2022-04-06 11:13:11 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:13:11 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:13:11 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@1e52819e, messages=[], arguments=[--group-id, my-consumer-group-1665357097, --bootstrap-server, my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092, --group-instance-id, instance1548525882, --max-messages, 200, --topic, not-included-topic], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-9fedf48b-kafka-clients-979698588-jt4f7', podNamespace='namespace-135', bootstrapServer='my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092', topicName='not-included-topic', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1665357097', consumerInstanceId='instance1548525882', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6de9d}
2022-04-06 11:13:11 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092#not-included-topic from pod my-cluster-9fedf48b-kafka-clients-979698588-jt4f7
2022-04-06 11:13:11 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-9fedf48b-kafka-clients-979698588-jt4f7 -n namespace-135 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1665357097 --bootstrap-server my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092 --group-instance-id instance1548525882 --max-messages 200 --topic not-included-topic
2022-04-06 11:15:11 [main] [32mINFO [m [VerifiableClient:199] CLI_KAFKA_VERIFIABLE_CONSUMER RETURN code: 1
2022-04-06 11:15:11 [main] [32mINFO [m [VerifiableClient:201] ======STDOUT START=======
2022-04-06 11:15:11 [main] [33mWARN [m [Exec:358] Executor log is too long. Going to strip it and print only first 20000 characters
2022-04-06 11:15:11 [main] [32mINFO [m [VerifiableClient:202] /tmp/.properties
Starting Consumer with configuration:

[2022-04-06 11:13:12,633] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-consumer-group-1665357097-instance1548525882
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-consumer-group-1665357097
	group.instance.id = instance1548525882
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (ConsumerConfig:376)
[2022-04-06 11:13:12,638] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Initializing the Kafka consumer (KafkaConsumer:695)
[2022-04-06 11:13:12,741] INFO Kafka version: 3.1.0 (AppInfoParser:119)
[2022-04-06 11:13:12,742] INFO Kafka commitId: 37edeed0777bacb3 (AppInfoParser:120)
[2022-04-06 11:13:12,742] INFO Kafka startTimeMs: 1649243592738 (AppInfoParser:121)
[2022-04-06 11:13:12,745] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Kafka consumer initialized (KafkaConsumer:815)
{"timestamp":1649243592897,"name":"startup_complete"}
[2022-04-06 11:13:12,938] INFO [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Subscribed to topic(s): not-included-topic (KafkaConsumer:966)
[2022-04-06 11:13:12,939] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Sending FindCoordinator request to broker my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) (ConsumerCoordinator:821)
[2022-04-06 11:13:13,173] DEBUG Resolved host my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc as 10.97.165.238 (ClientUtils:113)
[2022-04-06 11:13:13,174] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Initiating connection to node my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) using address my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc/10.97.165.238 (NetworkClient:985)
[2022-04-06 11:13:13,187] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1 (Selector:531)
[2022-04-06 11:13:13,188] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Completed connection to node -1. Fetching API versions. (NetworkClient:952)
[2022-04-06 11:13:13,189] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Initiating API versions fetch from node -1. (NetworkClient:966)
[2022-04-06 11:13:13,191] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-1665357097-instance1548525882, correlationId=1) and timeout 30000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.1.0') (NetworkClient:521)
[2022-04-06 11:13:13,229] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-my-consumer-group-1665357097-instance1548525882, correlationId=1): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=9), ApiVersion(apiKey=1, minVersion=0, maxVersion=13), ApiVersion(apiKey=2, minVersion=0, maxVersion=7), ApiVersion(apiKey=3, minVersion=0, maxVersion=12), ApiVersion(apiKey=4, minVersion=0, maxVersion=5), ApiVersion(apiKey=5, minVersion=0, maxVersion=3), ApiVersion(apiKey=6, minVersion=0, maxVersion=7), ApiVersion(apiKey=7, minVersion=0, maxVersion=3), ApiVersion(apiKey=8, minVersion=0, maxVersion=8), ApiVersion(apiKey=9, minVersion=0, maxVersion=8), ApiVersion(apiKey=10, minVersion=0, maxVersion=4), ApiVersion(apiKey=11, minVersion=0, maxVersion=7), ApiVersion(apiKey=12, minVersion=0, maxVersion=4), ApiVersion(apiKey=13, minVersion=0, maxVersion=4), ApiVersion(apiKey=14, minVersion=0, maxVersion=5), ApiVersion(apiKey=15, minVersion=0, maxVersion=5), ApiVersion(apiKey=16, minVersion=0, maxVersion=4), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=3), ApiVersion(apiKey=19, minVersion=0, maxVersion=7), ApiVersion(apiKey=20, minVersion=0, maxVersion=6), ApiVersion(apiKey=21, minVersion=0, maxVersion=2), ApiVersion(apiKey=22, minVersion=0, maxVersion=4), ApiVersion(apiKey=23, minVersion=0, maxVersion=4), ApiVersion(apiKey=24, minVersion=0, maxVersion=3), ApiVersion(apiKey=25, minVersion=0, maxVersion=3), ApiVersion(apiKey=26, minVersion=0, maxVersion=3), ApiVersion(apiKey=27, minVersion=0, maxVersion=1), ApiVersion(apiKey=28, minVersion=0, maxVersion=3), ApiVersion(apiKey=29, minVersion=0, maxVersion=2), ApiVersion(apiKey=30, minVersion=0, maxVersion=2), ApiVersion(apiKey=31, minVersion=0, maxVersion=2), ApiVersion(apiKey=32, minVersion=0, maxVersion=4), ApiVersion(apiKey=33, minVersion=0, maxVersion=2), ApiVersion(apiKey=34, minVersion=0, maxVersion=2), ApiVersion(apiKey=35, minVersion=0, maxVersion=2), ApiVersion(apiKey=36, minVersion=0, maxVersion=2), ApiVersion(apiKey=37, minVersion=0, maxVersion=3), ApiVersion(apiKey=38, minVersion=0, maxVersion=2), ApiVersion(apiKey=39, minVersion=0, maxVersion=2), ApiVersion(apiKey=40, minVersion=0, maxVersion=2), ApiVersion(apiKey=41, minVersion=0, maxVersion=2), ApiVersion(apiKey=42, minVersion=0, maxVersion=2), ApiVersion(apiKey=43, minVersion=0, maxVersion=2), ApiVersion(apiKey=44, minVersion=0, maxVersion=1), ApiVersion(apiKey=45, minVersion=0, maxVersion=0), ApiVersion(apiKey=46, minVersion=0, maxVersion=0), ApiVersion(apiKey=47, minVersion=0, maxVersion=0), ApiVersion(apiKey=48, minVersion=0, maxVersion=1), ApiVersion(apiKey=49, minVersion=0, maxVersion=1), ApiVersion(apiKey=50, minVersion=0, maxVersion=0), ApiVersion(apiKey=51, minVersion=0, maxVersion=0), ApiVersion(apiKey=56, minVersion=0, maxVersion=0), ApiVersion(apiKey=57, minVersion=0, maxVersion=0), ApiVersion(apiKey=60, minVersion=0, maxVersion=0), ApiVersion(apiKey=61, minVersion=0, maxVersion=0), ApiVersion(apiKey=65, minVersion=0, maxVersion=0), ApiVersion(apiKey=66, minVersion=0, maxVersion=0), ApiVersion(apiKey=67, minVersion=0, maxVersion=0)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=0, finalizedFeatures=[]) (NetworkClient:879)
[2022-04-06 11:13:13,290] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Node -1 has finalized features epoch: 0, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 9 [usable: 9], Fetch(1): 0 to 13 [usable: 13], ListOffsets(2): 0 to 7 [usable: 7], Metadata(3): 0 to 12 [usable: 12], LeaderAndIsr(4): 0 to 5 [usable: 5], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 7 [usable: 7], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 8 [usable: 8], FindCoordinator(10): 0 to 4 [usable: 4], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 7 [usable: 7], DeleteTopics(20): 0 to 6 [usable: 6], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 4 [usable: 4], AddPartitionsToTxn(24): 0 to 3 [usable: 3], AddOffsetsToTxn(25): 0 to 3 [usable: 3], EndTxn(26): 0 to 3 [usable: 3], WriteTxnMarkers(27): 0 to 1 [usable: 1], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 4 [usable: 4], AlterConfigs(33): 0 to 2 [usable: 2], AlterReplicaLogDirs(34): 0 to 2 [usable: 2], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 to 1 [usable: 1], AlterClientQuotas(49): 0 to 1 [usable: 1], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0], DescribeCluster(60): 0 [usable: 0], DescribeProducers(61): 0 [usable: 0], DescribeTransactions(65): 0 [usable: 0], ListTransactions(66): 0 [usable: 0], AllocateProducerIds(67): 0 [usable: 0]). (NetworkClient:921)
[2022-04-06 11:13:13,293] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='not-included-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node my-cluster-9fedf48b-target-kafka-bootstrap.namespace-135.svc:9092 (id: -1 rack: null) (NetworkClient:1139)
[2022-04-06 11:13:13,294] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=consumer-my-consumer-group-1665357097-instance1548525882, correlationId=2) and timeout 30000 to node -1: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='not-included-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) (NetworkClient:521)
[2022-04-06 11:13:13,295] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-1665357097-instance1548525882, correlationId=0) and timeout 30000 to node -1: FindCoordinatorRequestData(key='', keyType=0, coordinatorKeys=[my-consumer-group-1665357097]) (NetworkClient:521)
[2022-04-06 11:13:13,330] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Received METADATA response from node -1 for request with header RequestHeader(apiKey=METADATA, apiVersion=12, clientId=consumer-my-consumer-group-1665357097-instance1548525882, correlationId=2): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=0, host='my-cluster-9fedf48b-target-kafka-0.my-cluster-9fedf48b-target-kafka-brokers.namespace-135.svc', port=9092, rack=null)], clusterId='Zc-_rVJFQQeal2OYgdWKAA', controllerId=0, topics=[MetadataResponseTopic(errorCode=5, name='not-included-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648) (NetworkClient:879)
[2022-04-06 11:13:13,338] WARN [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Error while fetching metadata with correlation id 2 : {not-included-topic=LEADER_NOT_AVAILABLE} (NetworkClient:1099)
[2022-04-06 11:13:13,338] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Requesting metadata update for topic not-included-topic due to error LEADER_NOT_AVAILABLE (Metadata:363)
[2022-04-06 11:13:13,340] INFO [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Cluster ID: Zc-_rVJFQQeal2OYgdWKAA (Metadata:287)
[2022-04-06 11:13:13,347] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='Zc-_rVJFQQeal2OYgdWKAA', nodes={0=my-cluster-9fedf48b-target-kafka-0.my-cluster-9fedf48b-target-kafka-brokers.namespace-135.svc:9092 (id: 0 rack: null)}, partitions=[], controller=my-cluster-9fedf48b-target-kafka-0.my-cluster-9fedf48b-target-kafka-brokers.namespace-135.svc:9092 (id: 0 rack: null)} (Metadata:291)
[2022-04-06 11:13:13,348] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Received FIND_COORDINATOR response from node -1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-1665357097-instance1548525882, correlationId=0): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='', nodeId=0, host='', port=0, coordinators=[Coordinator(key='my-consumer-group-1665357097', nodeId=0, host='my-cluster-9fedf48b-target-kafka-0.my-cluster-9fedf48b-target-kafka-brokers.namespace-135.svc', port=9092, errorCode=0, errorMessage='')]) (NetworkClient:879)
[2022-04-06 11:13:13,349] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Received FindCoordinator response ClientResponse(receivedTimeMs=1649243593348, latencyMs=182, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=4, clientId=consumer-my-consumer-group-1665357097-instance1548525882, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='', nodeId=0, host='', port=0, coordinators=[Coordinator(key='my-consumer-group-1665357097', nodeId=0, host='my-cluster-9fedf48b-target-kafka-0.my-cluster-9fedf48b-target-kafka-brokers.namespace-135.svc', port=9092, errorCode=0, errorMessage='')])) (ConsumerCoordinator:834)
[2022-04-06 11:13:13,349] INFO [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Discovered group coordinator my-cluster-9fedf48b-target-kafka-0.my-cluster-9fedf48b-target-kafka-brokers.namespace-135.svc:9092 (id: 2147483647 rack: null) (ConsumerCoordinator:853)
[2022-04-06 11:13:13,352] DEBUG Resolved host my-cluster-9fedf48b-target-kafka-0.my-cluster-9fedf48b-target-kafka-brokers.namespace-135.svc as 172.17.0.11 (ClientUtils:113)
[2022-04-06 11:13:13,352] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Initiating connection to node my-cluster-9fedf48b-target-kafka-0.my-cluster-9fedf48b-target-kafka-brokers.namespace-135.svc:9092 (id: 2147483647 rack: null) using address my-cluster-9fedf48b-target-kafka-0.my-cluster-9fedf48b-target-kafka-brokers.namespace-135.svc/172.17.0.11 (NetworkClient:985)
[2022-04-06 11:13:13,357] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Executing onJoinPrepare with generation -1 and memberId  (ConsumerCoordinator:700)
[2022-04-06 11:13:13,358] INFO [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] (Re-)joining group (ConsumerCoordinator:535)
[2022-04-06 11:13:13,358] DEBUG [Consumer instanceId=instance1548525882, clientId=consumer-my-consumer-group-1665357097-instance1548525882, groupId=my-consumer-group-1665357097] Joining group with current subscription: [not-included-topic] (Consum
2022-04-06 11:15:11 [main] [32mINFO [m [VerifiableClient:203] ======STDOUT END======
2022-04-06 11:15:11 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: false
2022-04-06 11:15:11 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 0 messages
2022-04-06 11:15:11 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:15:11 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testIncludeList
2022-04-06 11:15:11 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic not-included-topic in namespace namespace-135
2022-04-06 11:15:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9fedf48b-target in namespace namespace-135
2022-04-06 11:15:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-9fedf48b-source in namespace namespace-135
2022-04-06 11:15:11 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic included-topic in namespace namespace-135
2022-04-06 11:15:21 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-9fedf48b in namespace namespace-135
2022-04-06 11:15:21 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-9fedf48b-kafka-clients in namespace namespace-135
2022-04-06 11:16:11 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:16:11 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-135 for test case:testIncludeList
2022-04-06 11:16:16 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testIncludeList-FINISHED
2022-04-06 11:16:16 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:16:16 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:16:16 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testConfigureDeploymentStrategy-STARTED
2022-04-06 11:16:16 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:16:16 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-136 for test case:testConfigureDeploymentStrategy
2022-04-06 11:16:16 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-136
2022-04-06 11:16:16 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-136
2022-04-06 11:16:16 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-136
2022-04-06 11:16:16 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-67e45546-source in namespace namespace-136
2022-04-06 11:16:16 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-06 11:16:16 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-67e45546-source will have desired state: Ready
2022-04-06 11:17:27 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-67e45546-source is in desired state: Ready
2022-04-06 11:17:27 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-67e45546-target in namespace namespace-136
2022-04-06 11:17:27 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-06 11:17:27 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-67e45546-target will have desired state: Ready
2022-04-06 11:18:35 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-67e45546-target is in desired state: Ready
2022-04-06 11:18:35 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-67e45546 in namespace namespace-136
2022-04-06 11:18:35 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-136
2022-04-06 11:18:35 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-67e45546 will have desired state: Ready
2022-04-06 11:19:39 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-67e45546 is in desired state: Ready
2022-04-06 11:19:39 [main] [32mINFO [m [MirrorMakerIsolatedST:763] Adding label to MirrorMaker resource, the CR should be recreateAndWaitForReadinessd
2022-04-06 11:19:39 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-67e45546-mirror-maker will be ready
2022-04-06 11:19:39 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-67e45546-mirror-maker is ready
2022-04-06 11:19:39 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-67e45546-mirror-maker to be ready
2022-04-06 11:20:58 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-67e45546-mirror-maker is ready
2022-04-06 11:20:58 [main] [32mINFO [m [MirrorMakerIsolatedST:770] Checking that observed gen. is still on 1 (recreation) and new label is present
2022-04-06 11:20:58 [main] [32mINFO [m [MirrorMakerIsolatedST:775] Changing deployment strategy to ROLLING_UPDATE
2022-04-06 11:20:58 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-67e45546 will have desired state: Ready
2022-04-06 11:20:58 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-67e45546 is in desired state: Ready
2022-04-06 11:20:58 [main] [32mINFO [m [MirrorMakerIsolatedST:780] Adding another label to MirrorMaker resource, pods should be rolled
2022-04-06 11:20:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-67e45546-mirror-maker will be ready
2022-04-06 11:20:58 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-67e45546-mirror-maker is ready
2022-04-06 11:20:58 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-67e45546-mirror-maker to be ready
2022-04-06 11:22:26 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-67e45546-mirror-maker is ready
2022-04-06 11:22:26 [main] [32mINFO [m [MirrorMakerIsolatedST:784] Checking that observed gen. higher (rolling update) and label is changed
2022-04-06 11:22:26 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:22:26 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testConfigureDeploymentStrategy
2022-04-06 11:22:26 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-67e45546-target in namespace namespace-136
2022-04-06 11:22:26 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-67e45546-source in namespace namespace-136
2022-04-06 11:22:26 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-67e45546 in namespace namespace-136
2022-04-06 11:22:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:22:46 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-136 for test case:testConfigureDeploymentStrategy
2022-04-06 11:22:51 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testConfigureDeploymentStrategy-FINISHED
2022-04-06 11:22:51 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:22:51 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:22:51 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerToZero-STARTED
2022-04-06 11:22:51 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:22:51 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-137 for test case:testScaleMirrorMakerToZero
2022-04-06 11:22:51 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-137
2022-04-06 11:22:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-137
2022-04-06 11:22:51 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-137
2022-04-06 11:22:51 [main] [32mINFO [m [MirrorMakerIsolatedST:713] Creating kafka source cluster my-cluster-e8b93be6-source
2022-04-06 11:22:51 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e8b93be6-source in namespace namespace-137
2022-04-06 11:22:51 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-06 11:22:51 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e8b93be6-source will have desired state: Ready
2022-04-06 11:24:00 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e8b93be6-source is in desired state: Ready
2022-04-06 11:24:00 [main] [32mINFO [m [MirrorMakerIsolatedST:715] Creating kafka target cluster my-cluster-e8b93be6-target
2022-04-06 11:24:00 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-e8b93be6-target in namespace namespace-137
2022-04-06 11:24:00 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-06 11:24:00 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-e8b93be6-target will have desired state: Ready
2022-04-06 11:25:20 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-e8b93be6-target is in desired state: Ready
2022-04-06 11:25:20 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-e8b93be6 in namespace namespace-137
2022-04-06 11:25:20 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-137
2022-04-06 11:25:20 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-e8b93be6 will have desired state: Ready
2022-04-06 11:26:30 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-e8b93be6 is in desired state: Ready
2022-04-06 11:26:30 [main] [32mINFO [m [MirrorMakerIsolatedST:725] Scaling MirrorMaker to zero
2022-04-06 11:26:37 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:26:37 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMakerToZero
2022-04-06 11:26:37 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e8b93be6-target in namespace namespace-137
2022-04-06 11:26:37 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-e8b93be6 in namespace namespace-137
2022-04-06 11:26:37 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-e8b93be6-source in namespace namespace-137
2022-04-06 11:26:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:26:47 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-137 for test case:testScaleMirrorMakerToZero
2022-04-06 11:27:22 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerToZero-FINISHED
2022-04-06 11:27:22 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:27:22 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:27:22 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerSubresource-STARTED
2022-04-06 11:27:22 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:27:22 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-138 for test case:testScaleMirrorMakerSubresource
2022-04-06 11:27:22 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-138
2022-04-06 11:27:22 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-138
2022-04-06 11:27:22 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-138
2022-04-06 11:27:22 [main] [32mINFO [m [MirrorMakerIsolatedST:674] Creating kafka source cluster my-cluster-5a997736-source
2022-04-06 11:27:22 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5a997736-source in namespace namespace-138
2022-04-06 11:27:22 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-06 11:27:22 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5a997736-source will have desired state: Ready
2022-04-06 11:28:36 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5a997736-source is in desired state: Ready
2022-04-06 11:28:36 [main] [32mINFO [m [MirrorMakerIsolatedST:676] Creating kafka target cluster my-cluster-5a997736-target
2022-04-06 11:28:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5a997736-target in namespace namespace-138
2022-04-06 11:28:36 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-06 11:28:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5a997736-target will have desired state: Ready
2022-04-06 11:29:50 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5a997736-target is in desired state: Ready
2022-04-06 11:29:50 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-5a997736 in namespace namespace-138
2022-04-06 11:29:50 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-138
2022-04-06 11:29:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-5a997736 will have desired state: Ready
2022-04-06 11:31:02 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-5a997736 is in desired state: Ready
2022-04-06 11:31:02 [main] [32mINFO [m [MirrorMakerIsolatedST:685] -------> Scaling KafkaMirrorMaker subresource <-------
2022-04-06 11:31:02 [main] [32mINFO [m [MirrorMakerIsolatedST:686] Scaling subresource replicas to 4
2022-04-06 11:31:02 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5a997736-mirror-maker will be ready
2022-04-06 11:31:02 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5a997736-mirror-maker is ready
2022-04-06 11:31:02 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 4 Pod(s) of Deployment my-cluster-5a997736-mirror-maker to be ready
2022-04-06 11:32:23 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-5a997736-mirror-maker is ready
2022-04-06 11:32:23 [main] [32mINFO [m [MirrorMakerIsolatedST:690] Check if replicas is set to 4, naming prefix should be same and observed generation higher
2022-04-06 11:32:23 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:32:23 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testScaleMirrorMakerSubresource
2022-04-06 11:32:23 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5a997736-target in namespace namespace-138
2022-04-06 11:32:23 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-5a997736 in namespace namespace-138
2022-04-06 11:32:23 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5a997736-source in namespace namespace-138
2022-04-06 11:32:33 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:32:33 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-138 for test case:testScaleMirrorMakerSubresource
2022-04-06 11:33:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testScaleMirrorMakerSubresource-FINISHED
2022-04-06 11:33:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:33:00 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:33:00 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testCustomAndUpdatedValues-STARTED
2022-04-06 11:33:00 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:33:00 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-139 for test case:testCustomAndUpdatedValues
2022-04-06 11:33:00 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-139
2022-04-06 11:33:01 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-139
2022-04-06 11:33:01 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-139
2022-04-06 11:33:01 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5f441d62 in namespace namespace-139
2022-04-06 11:33:01 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-139
2022-04-06 11:33:01 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5f441d62 will have desired state: Ready
2022-04-06 11:33:44 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5f441d62 is in desired state: Ready
2022-04-06 11:33:44 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-5f441d62 in namespace namespace-139
2022-04-06 11:33:44 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-139
2022-04-06 11:33:44 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-5f441d62 will have desired state: Ready
2022-04-06 11:34:20 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-5f441d62 is in desired state: Ready
2022-04-06 11:34:20 [main] [32mINFO [m [MirrorMakerIsolatedST:622] Verify values before update
2022-04-06 11:34:20 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-5f441d62-mirror-maker in pod name
2022-04-06 11:34:20 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-5f441d62-mirror-maker
2022-04-06 11:34:20 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-5f441d62-mirror-maker
2022-04-06 11:34:20 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-5f441d62-mirror-maker
2022-04-06 11:34:20 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-5f441d62-mirror-maker
2022-04-06 11:34:20 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-5f441d62-mirror-maker
2022-04-06 11:34:20 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-5f441d62-mirror-maker
2022-04-06 11:34:20 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-5f441d62-mirror-maker
2022-04-06 11:34:20 [main] [32mINFO [m [MirrorMakerIsolatedST:633] Check if actual env variable KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER has different value than test.value
2022-04-06 11:34:20 [main] [32mINFO [m [MirrorMakerIsolatedST:637] Updating values in MirrorMaker container
2022-04-06 11:34:20 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment my-cluster-5f441d62-mirror-maker rolling update
2022-04-06 11:35:00 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5f441d62-mirror-maker will be ready
2022-04-06 11:35:00 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5f441d62-mirror-maker is ready
2022-04-06 11:35:10 [main] [32mINFO [m [DeploymentUtils:141] Deployment my-cluster-5f441d62-mirror-maker rolling update finished
2022-04-06 11:35:10 [main] [32mINFO [m [MirrorMakerIsolatedST:654] Verify values after update
2022-04-06 11:35:10 [main] [32mINFO [m [AbstractST:255] Getting pods by prefix my-cluster-5f441d62-mirror-maker in pod name
2022-04-06 11:35:10 [main] [32mINFO [m [AbstractST:259] Testing Readiness and Liveness configuration for container my-cluster-5f441d62-mirror-maker
2022-04-06 11:35:10 [main] [32mINFO [m [AbstractST:221] Getting pods by prefix in name my-cluster-5f441d62-mirror-maker
2022-04-06 11:35:10 [main] [32mINFO [m [AbstractST:225] Testing EnvVars configuration for container my-cluster-5f441d62-mirror-maker
2022-04-06 11:35:10 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-5f441d62-mirror-maker
2022-04-06 11:35:10 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-5f441d62-mirror-maker
2022-04-06 11:35:10 [main] [32mINFO [m [AbstractST:190] Getting pods by prefix in name my-cluster-5f441d62-mirror-maker
2022-04-06 11:35:10 [main] [32mINFO [m [AbstractST:194] Testing configuration for container my-cluster-5f441d62-mirror-maker
2022-04-06 11:35:10 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:35:10 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testCustomAndUpdatedValues
2022-04-06 11:35:10 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-5f441d62 in namespace namespace-139
2022-04-06 11:35:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5f441d62 in namespace namespace-139
2022-04-06 11:35:20 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:35:20 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-139 for test case:testCustomAndUpdatedValues
2022-04-06 11:35:31 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testCustomAndUpdatedValues-FINISHED
2022-04-06 11:35:31 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:35:31 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:35:31 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMaker-STARTED
2022-04-06 11:35:31 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:35:31 [main] [32mINFO [m [TestSuiteNamespaceManager:163] Creating namespace:namespace-140 for test case:testMirrorMaker
2022-04-06 11:35:31 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: namespace-140
2022-04-06 11:35:31 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: namespace-140
2022-04-06 11:35:31 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: namespace-140
2022-04-06 11:35:31 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5bce1aa7-source in namespace namespace-140
2022-04-06 11:35:31 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-06 11:35:31 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5bce1aa7-source will have desired state: Ready
2022-04-06 11:36:37 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5bce1aa7-source is in desired state: Ready
2022-04-06 11:36:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-5bce1aa7-target in namespace namespace-140
2022-04-06 11:36:37 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-06 11:36:37 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-5bce1aa7-target will have desired state: Ready
2022-04-06 11:37:45 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-5bce1aa7-target is in desired state: Ready
2022-04-06 11:37:45 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-609391865-1811347379-source-91060041 in namespace namespace-140
2022-04-06 11:37:45 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-06 11:37:45 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-609391865-1811347379-source-91060041 will have desired state: Ready
2022-04-06 11:37:46 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-609391865-1811347379-source-91060041 is in desired state: Ready
2022-04-06 11:37:46 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-5bce1aa7-kafka-clients in namespace namespace-140
2022-04-06 11:37:46 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-06 11:37:46 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-5bce1aa7-kafka-clients will be ready
2022-04-06 11:37:48 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-5bce1aa7-kafka-clients is ready
2022-04-06 11:37:49 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 11:37:49 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@777a4d17, messages=[], arguments=[--bootstrap-server, my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092, --max-messages, 200, --topic, topic-for-test-broker-1], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd', podNamespace='namespace-140', bootstrapServer='my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-1', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1d52d7ec}
2022-04-06 11:37:49 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092:topic-for-test-broker-1 from pod my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd
2022-04-06 11:37:49 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd -n namespace-140 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092 --max-messages 200 --topic topic-for-test-broker-1
2022-04-06 11:37:51 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:37:51 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:37:51 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@2e0f7d87, messages=[], arguments=[--group-id, my-consumer-group-1179038728, --bootstrap-server, my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092, --group-instance-id, instance807992663, --max-messages, 200, --topic, topic-for-test-broker-1], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd', podNamespace='namespace-140', bootstrapServer='my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-1', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1179038728', consumerInstanceId='instance807992663', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@25692371}
2022-04-06 11:37:51 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092#topic-for-test-broker-1 from pod my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd
2022-04-06 11:37:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd -n namespace-140 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1179038728 --bootstrap-server my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092 --group-instance-id instance807992663 --max-messages 200 --topic topic-for-test-broker-1
2022-04-06 11:37:57 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:37:57 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:37:57 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@42f8aff9, messages=[], arguments=[--bootstrap-server, my-cluster-5bce1aa7-target-kafka-bootstrap.namespace-140.svc:9092, --max-messages, 200, --topic, topic-for-test-broker-2], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd', podNamespace='namespace-140', bootstrapServer='my-cluster-5bce1aa7-target-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-2', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@b388fa4}
2022-04-06 11:37:57 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-5bce1aa7-target-kafka-bootstrap.namespace-140.svc:9092:topic-for-test-broker-2 from pod my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd
2022-04-06 11:37:57 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd -n namespace-140 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-5bce1aa7-target-kafka-bootstrap.namespace-140.svc:9092 --max-messages 200 --topic topic-for-test-broker-2
2022-04-06 11:37:59 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:37:59 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:37:59 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7bd0dd62, messages=[], arguments=[--group-id, my-consumer-group-763970292, --bootstrap-server, my-cluster-5bce1aa7-target-kafka-bootstrap.namespace-140.svc:9092, --group-instance-id, instance1339755602, --max-messages, 200, --topic, topic-for-test-broker-2], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd', podNamespace='namespace-140', bootstrapServer='my-cluster-5bce1aa7-target-kafka-bootstrap.namespace-140.svc:9092', topicName='topic-for-test-broker-2', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-763970292', consumerInstanceId='instance1339755602', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@2ee67e7c}
2022-04-06 11:37:59 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-5bce1aa7-target-kafka-bootstrap.namespace-140.svc:9092#topic-for-test-broker-2 from pod my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd
2022-04-06 11:37:59 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd -n namespace-140 -- /opt/kafka/consumer.sh --group-id my-consumer-group-763970292 --bootstrap-server my-cluster-5bce1aa7-target-kafka-bootstrap.namespace-140.svc:9092 --group-instance-id instance1339755602 --max-messages 200 --topic topic-for-test-broker-2
2022-04-06 11:38:05 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:38:05 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:38:05 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker my-cluster-5bce1aa7 in namespace namespace-140
2022-04-06 11:38:05 [main] [32mINFO [m [ResourceManager:164] Using Namespace: namespace-140
2022-04-06 11:38:05 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker: my-cluster-5bce1aa7 will have desired state: Ready
2022-04-06 11:39:15 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker: my-cluster-5bce1aa7 is in desired state: Ready
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:311] Verifying labels on pod type mirror-maker
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:315] Verifying labels for pod: my-cluster-5bce1aa7-mirror-maker-6fdbff9b74-g4g2z
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:356] Verifying labels for Kafka Connect Services
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:384] Verifying labels for Config maps
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-5bce1aa7-mirror-maker-config
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-5bce1aa7-source-entity-topic-operator-config
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:407] CM my-cluster-5bce1aa7-source-entity-topic-operator-config is not related to current test
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-5bce1aa7-source-entity-user-operator-config
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:407] CM my-cluster-5bce1aa7-source-entity-user-operator-config is not related to current test
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-5bce1aa7-source-kafka-config
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-5bce1aa7-source-zookeeper-config
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:407] CM my-cluster-5bce1aa7-source-zookeeper-config is not related to current test
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-5bce1aa7-target-entity-topic-operator-config
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:407] CM my-cluster-5bce1aa7-target-entity-topic-operator-config is not related to current test
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-5bce1aa7-target-entity-user-operator-config
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:407] CM my-cluster-5bce1aa7-target-entity-user-operator-config is not related to current test
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-5bce1aa7-target-kafka-config
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:388] Verifying labels for CM my-cluster-5bce1aa7-target-zookeeper-config
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:407] CM my-cluster-5bce1aa7-target-zookeeper-config is not related to current test
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:414] Verifying labels for Service Accounts
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-5bce1aa7-source-entity-operator
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-5bce1aa7-source-kafka
2022-04-06 11:39:15 [main] [32mINFO [m [AbstractST:427] Verifying labels for service account my-cluster-5bce1aa7-source-zookeeper
2022-04-06 11:39:15 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace namespace-140 exec my-cluster-5bce1aa7-mirror-maker-6fdbff9b74-g4g2z -c my-cluster-5bce1aa7-mirror-maker -- /bin/bash -c for proc in $(ls -1 /proc/ | grep [0-9]); do if echo "$(ls -lh /proc/$proc/exe 2>/dev/null || true)" | grep -q java; then cat /proc/$proc/cmdline; fi; done
2022-04-06 11:39:15 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 11:39:15 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@6f56bd4e, messages=[], arguments=[--bootstrap-server, my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092, --max-messages, 200, --topic, my-topic-609391865-1811347379-source-91060041], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd', podNamespace='namespace-140', bootstrapServer='my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-609391865-1811347379-source-91060041', maxMessages=200, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@53a4c29e}
2022-04-06 11:39:15 [main] [32mINFO [m [InternalKafkaClient:94] Producing 200 messages to my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092:my-topic-609391865-1811347379-source-91060041 from pod my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd
2022-04-06 11:39:15 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd -n namespace-140 -- /opt/kafka/producer.sh --bootstrap-server my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092 --max-messages 200 --topic my-topic-609391865-1811347379-source-91060041
2022-04-06 11:39:18 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:39:18 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 200 messages
2022-04-06 11:39:18 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@7333f2fb, messages=[], arguments=[--group-id, my-consumer-group-1670554715, --bootstrap-server, my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092, --group-instance-id, instance1920708237, --max-messages, 200, --topic, my-topic-609391865-1811347379-source-91060041], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd', podNamespace='namespace-140', bootstrapServer='my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-609391865-1811347379-source-91060041', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1670554715', consumerInstanceId='instance1920708237', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1933532e}
2022-04-06 11:39:18 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092#my-topic-609391865-1811347379-source-91060041 from pod my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd
2022-04-06 11:39:18 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd -n namespace-140 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1670554715 --bootstrap-server my-cluster-5bce1aa7-source-kafka-bootstrap.namespace-140.svc:9092 --group-instance-id instance1920708237 --max-messages 200 --topic my-topic-609391865-1811347379-source-91060041
2022-04-06 11:39:23 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:39:23 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:39:23 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@5c101f7c, messages=[], arguments=[--group-id, my-consumer-group-1644964027, --bootstrap-server, my-cluster-5bce1aa7-target-kafka-bootstrap.namespace-140.svc:9092, --group-instance-id, instance591041208, --max-messages, 200, --topic, my-topic-609391865-1811347379-source-91060041], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd', podNamespace='namespace-140', bootstrapServer='my-cluster-5bce1aa7-target-kafka-bootstrap.namespace-140.svc:9092', topicName='my-topic-609391865-1811347379-source-91060041', maxMessages=200, kafkaUsername='null', consumerGroupName='my-consumer-group-1644964027', consumerInstanceId='instance591041208', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6766e31}
2022-04-06 11:39:23 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 200 messages from my-cluster-5bce1aa7-target-kafka-bootstrap.namespace-140.svc:9092#my-topic-609391865-1811347379-source-91060041 from pod my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd
2022-04-06 11:39:23 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec my-cluster-5bce1aa7-kafka-clients-6c4cb457b7-987qd -n namespace-140 -- /opt/kafka/consumer.sh --group-id my-consumer-group-1644964027 --bootstrap-server my-cluster-5bce1aa7-target-kafka-bootstrap.namespace-140.svc:9092 --group-instance-id instance591041208 --max-messages 200 --topic my-topic-609391865-1811347379-source-91060041
2022-04-06 11:39:29 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:39:29 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 200 messages
2022-04-06 11:39:29 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:39:29 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testMirrorMaker
2022-04-06 11:39:29 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-609391865-1811347379-source-91060041 in namespace namespace-140
2022-04-06 11:39:29 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker my-cluster-5bce1aa7 in namespace namespace-140
2022-04-06 11:39:29 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5bce1aa7-target in namespace namespace-140
2022-04-06 11:39:29 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-5bce1aa7-source in namespace namespace-140
2022-04-06 11:39:39 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-5bce1aa7-kafka-clients in namespace namespace-140
2022-04-06 11:40:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:40:29 [main] [32mINFO [m [TestSuiteNamespaceManager:200] Deleting namespace:namespace-140 for test case:testMirrorMaker
2022-04-06 11:40:35 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST.testMirrorMaker-FINISHED
2022-04-06 11:40:35 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:40:35 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:40:35 [main] [32mINFO [m [ResourceManager:346] In context MirrorMakerIsolatedST is everything deleted.
2022-04-06 11:40:35 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2,676.852 s - in io.strimzi.systemtest.mirrormaker.MirrorMakerIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.metrics.MetricsIsolatedST
2022-04-06 11:40:35 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 11:41:00 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 11:41:00 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 11:41:00 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 11:41:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:41:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 11:41:00 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:41:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:10 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:41:10 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 11:41:10 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 11:41:10 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:10 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:20 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:41:35 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=infra-namespace,second-metrics-cluster-test
bindingsNamespaces=[infra-namespace, second-metrics-cluster-test]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 11:41:35 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 11:41:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 11:41:35 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: second-metrics-cluster-test
2022-04-06 11:41:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: second-metrics-cluster-test
2022-04-06 11:41:36 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 11:41:36 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace second-metrics-cluster-test
2022-04-06 11:41:36 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-metrics-cluster-test
2022-04-06 11:41:36 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:41:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 11:42:18 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 11:42:18 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 11:42:28 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 11:42:28 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 11:42:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka metrics-cluster-name in namespace infra-namespace
2022-04-06 11:42:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka second-kafka-cluster in namespace second-metrics-cluster-test
2022-04-06 11:42:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment infra-namespace-kafka-clients in namespace infra-namespace
2022-04-06 11:42:28 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment second-metrics-cluster-test-kafka-clients in namespace second-metrics-cluster-test
2022-04-06 11:42:28 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: metrics-cluster-name will have desired state: Ready
2022-04-06 11:45:36 [main] [32mINFO [m [ResourceManager:444] Kafka: metrics-cluster-name is in desired state: Ready
2022-04-06 11:45:36 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: second-kafka-cluster will have desired state: Ready
2022-04-06 11:45:36 [main] [32mINFO [m [ResourceManager:444] Kafka: second-kafka-cluster is in desired state: Ready
2022-04-06 11:45:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: infra-namespace-kafka-clients will be ready
2022-04-06 11:45:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: infra-namespace-kafka-clients is ready
2022-04-06 11:45:36 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: second-metrics-cluster-test-kafka-clients will be ready
2022-04-06 11:45:36 [main] [32mINFO [m [DeploymentUtils:168] Deployment: second-metrics-cluster-test-kafka-clients is ready
2022-04-06 11:45:36 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaBridge my-bridge in namespace infra-namespace
2022-04-06 11:45:36 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaBridge: my-bridge will have desired state: Ready
2022-04-06 11:46:02 [main] [32mINFO [m [ResourceManager:444] KafkaBridge: my-bridge is in desired state: Ready
2022-04-06 11:46:02 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaMirrorMaker2 mm2-cluster in namespace infra-namespace
2022-04-06 11:46:02 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaMirrorMaker2: mm2-cluster will have desired state: Ready
2022-04-06 11:47:07 [main] [32mINFO [m [ResourceManager:444] KafkaMirrorMaker2: mm2-cluster is in desired state: Ready
2022-04-06 11:47:07 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1340026128-1658645739 in namespace infra-namespace
2022-04-06 11:47:07 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1340026128-1658645739 will have desired state: Ready
2022-04-06 11:47:09 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1340026128-1658645739 is in desired state: Ready
2022-04-06 11:47:09 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-538067116-1396354649 in namespace infra-namespace
2022-04-06 11:47:09 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-538067116-1396354649 will have desired state: Ready
2022-04-06 11:47:10 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-538067116-1396354649 is in desired state: Ready
2022-04-06 11:47:10 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-750392639-2065076382 in namespace infra-namespace
2022-04-06 11:47:10 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-750392639-2065076382 will have desired state: Ready
2022-04-06 11:47:11 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-750392639-2065076382 is in desired state: Ready
2022-04-06 11:47:11 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-950948744-1235734862 in namespace infra-namespace
2022-04-06 11:47:11 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-950948744-1235734862 will have desired state: Ready
2022-04-06 11:47:12 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-950948744-1235734862 is in desired state: Ready
2022-04-06 11:47:12 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaUser my-user-1705135816-702044698 in namespace infra-namespace
2022-04-06 11:47:12 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaUser: my-user-1705135816-702044698 will have desired state: Ready
2022-04-06 11:47:13 [main] [32mINFO [m [ResourceManager:444] KafkaUser: my-user-1705135816-702044698 is in desired state: Ready
2022-04-06 11:47:13 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect metrics-cluster-name in namespace infra-namespace
2022-04-06 11:47:13 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: metrics-cluster-name will have desired state: Ready
2022-04-06 11:48:15 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: metrics-cluster-name is in desired state: Ready
2022-04-06 11:48:15 [main] [32mINFO [m [NetworkPolicyResource:72] Apply NetworkPolicy access to cluster-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-06 11:48:15 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy cluster-operator-allow in namespace infra-namespace
2022-04-06 11:48:15 [main] [32mINFO [m [NetworkPolicyResource:90] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-06 11:48:15 [main] [32mINFO [m [NetworkPolicyResource:104] Apply NetworkPolicy access to metrics-cluster-name-entity-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-06 11:48:15 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy metrics-cluster-name-entity-operator-allow in namespace infra-namespace
2022-04-06 11:48:15 [main] [32mINFO [m [NetworkPolicyResource:128] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-06 11:48:15 [main] [32mINFO [m [NetworkPolicyResource:104] Apply NetworkPolicy access to second-kafka-cluster-entity-operator from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-06 11:48:15 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy second-kafka-cluster-entity-operator-allow in namespace second-metrics-cluster-test
2022-04-06 11:48:15 [main] [32mINFO [m [NetworkPolicyResource:128] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-06 11:48:15 [main] [32mINFO [m [NetworkPolicyResource:141] Apply NetworkPolicy access to metrics-cluster-name-kafka-exporter from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-06 11:48:15 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy metrics-cluster-name-kafka-exporter-allow in namespace infra-namespace
2022-04-06 11:48:15 [main] [32mINFO [m [NetworkPolicyResource:161] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-06 11:48:15 [main] [32mINFO [m [NetworkPolicyResource:141] Apply NetworkPolicy access to second-kafka-cluster-kafka-exporter from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={})
2022-04-06 11:48:15 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy second-kafka-cluster-kafka-exporter-allow in namespace second-metrics-cluster-test
2022-04-06 11:48:15 [main] [32mINFO [m [NetworkPolicyResource:161] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=kafka-clients}, additionalProperties={}) successfully created
2022-04-06 11:49:38 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.15 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:49:40 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.16 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:49:42 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.17 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:49:43 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.10 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:49:43 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.9 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:49:44 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.11 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:49:45 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:49:46 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.21 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:49:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:49:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testUserOperatorMetrics-STARTED
2022-04-06 11:49:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:49:46 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.19 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:49:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:49:46 [main] [32mINFO [m [ResourceManager:346] In context testUserOperatorMetrics is everything deleted.
2022-04-06 11:49:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:49:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testUserOperatorMetrics-FINISHED
2022-04-06 11:49:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:49:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:49:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperWatchersCount-STARTED
2022-04-06 11:49:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:49:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:49:46 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperWatchersCount is everything deleted.
2022-04-06 11:49:46 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:49:46 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperWatchersCount-FINISHED
2022-04-06 11:49:46 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:49:46 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:49:46 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectIoNetwork-STARTED
2022-04-06 11:49:46 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:49:47 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectIoNetwork is everything deleted.
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectIoNetwork-FINISHED
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBrokersCount-STARTED
2022-04-06 11:49:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:346] In context testKafkaBrokersCount is everything deleted.
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBrokersCount-FINISHED
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaActiveControllers-STARTED
2022-04-06 11:49:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:346] In context testKafkaActiveControllers is everything deleted.
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaActiveControllers-FINISHED
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicUnderReplicatedPartitions-STARTED
2022-04-06 11:49:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:346] In context testKafkaTopicUnderReplicatedPartitions is everything deleted.
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicUnderReplicatedPartitions-FINISHED
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperQuorumSize-STARTED
2022-04-06 11:49:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperQuorumSize is everything deleted.
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperQuorumSize-FINISHED
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperAliveConnections-STARTED
2022-04-06 11:49:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:346] In context testZookeeperAliveConnections is everything deleted.
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testZookeeperAliveConnections-FINISHED
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicPartitions-STARTED
2022-04-06 11:49:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:346] In context testKafkaTopicPartitions is everything deleted.
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaTopicPartitions-FINISHED
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:49:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testReconcileStateMetricInTopicOperator-STARTED
2022-04-06 11:49:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:49:47 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: second-metrics-cluster-test
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-1275084607-348085858 in namespace second-metrics-cluster-test
2022-04-06 11:49:47 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1275084607-348085858 will have desired state: Ready
2022-04-06 11:49:48 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1275084607-348085858 is in desired state: Ready
2022-04-06 11:49:48 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-7bcbt finished with return code: 0
2022-04-06 11:49:48 [main] [32mINFO [m [MetricsIsolatedST:555] Checking if resource state metric reason message is "none" and KafkaTopic is ready
2022-04-06 11:49:48 [main] [32mINFO [m [MetricsIsolatedST:558] Changing topic name in spec.topicName
2022-04-06 11:49:48 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1275084607-348085858 will have desired state: NotReady
2022-04-06 11:49:49 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1275084607-348085858 is in desired state: NotReady
2022-04-06 11:49:49 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-7bcbt finished with return code: 0
2022-04-06 11:49:49 [main] [32mINFO [m [MetricsIsolatedST:566] Changing back to it's original name and scaling replicas to be higher number
2022-04-06 11:49:49 [main] [32mINFO [m [KafkaTopicUtils:132] Waiting for KafkaTopic change my-topic-1275084607-348085858
2022-04-06 11:49:49 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-7bcbt finished with return code: 0
2022-04-06 11:49:49 [main] [32mINFO [m [MetricsIsolatedST:578] Scaling replicas to be higher than before
2022-04-06 11:49:49 [main] [32mINFO [m [KafkaTopicUtils:132] Waiting for KafkaTopic change my-topic-1275084607-348085858
2022-04-06 11:49:50 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-7bcbt finished with return code: 0
2022-04-06 11:49:50 [main] [32mINFO [m [MetricsIsolatedST:586] Changing KafkaTopic's spec to correct state
2022-04-06 11:49:50 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-1275084607-348085858 will have desired state: Ready
2022-04-06 11:49:51 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-1275084607-348085858 is in desired state: Ready
2022-04-06 11:49:51 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.14 from Pod second-metrics-cluster-test-kafka-clients-6c57d6898-7bcbt finished with return code: 0
2022-04-06 11:49:51 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 11:49:51 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:49:51 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testReconcileStateMetricInTopicOperator
2022-04-06 11:49:51 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1275084607-348085858 in namespace second-metrics-cluster-test
2022-04-06 11:50:01 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:50:01 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testReconcileStateMetricInTopicOperator-FINISHED
2022-04-06 11:50:01 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:50:01 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:50:01 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testMirrorMaker2Metrics-STARTED
2022-04-06 11:50:01 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:50:02 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.23 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:50:02 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:50:02 [main] [32mINFO [m [ResourceManager:346] In context testMirrorMaker2Metrics is everything deleted.
2022-04-06 11:50:02 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:50:02 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testMirrorMaker2Metrics-FINISHED
2022-04-06 11:50:02 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:50:02 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:50:02 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBridgeMetrics-STARTED
2022-04-06 11:50:02 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:50:02 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 11:50:02 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-producer in namespace infra-namespace
2022-04-06 11:50:02 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-producer will be in active state
2022-04-06 11:50:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Job bridge-consumer in namespace infra-namespace
2022-04-06 11:50:03 [main] [32mINFO [m [JobUtils:81] Waiting for job: bridge-consumer will be in active state
2022-04-06 11:50:04 [main] [32mINFO [m [MetricsIsolatedST:422] Looking for 'strimzi_bridge_kafka_producer_count' in bridge metrics
2022-04-06 11:50:05 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:50:06 [main] [32mINFO [m [MetricsIsolatedST:422] Looking for 'strimzi_bridge_kafka_producer_count' in bridge metrics
2022-04-06 11:50:06 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:50:06 [main] [32mINFO [m [MetricsIsolatedST:430] Looking for 'strimzi_bridge_kafka_consumer_connection_count' in bridge metrics
2022-04-06 11:50:07 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.22 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:50:07 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:50:07 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testKafkaBridgeMetrics
2022-04-06 11:50:07 [main] [32mINFO [m [ResourceManager:241] Delete of Job bridge-consumer in namespace infra-namespace
2022-04-06 11:50:07 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job bridge-producer in namespace infra-namespace
2022-04-06 11:50:07 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:50:07 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaBridgeMetrics-FINISHED
2022-04-06 11:50:07 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:50:07 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:50:07 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaMetricsSettings-STARTED
2022-04-06 11:50:07 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:50:07 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: second-kafka-cluster are stable
2022-04-06 11:50:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 11:50:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 11:50:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 11:50:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 11:50:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 11:50:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 11:50:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 11:50:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 11:50:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 11:50:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 11:50:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 11:50:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 11:50:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 11:50:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 11:50:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 11:50:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 11:50:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 11:50:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 11:50:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 11:50:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 11:50:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 11:50:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 11:50:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 11:50:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 11:50:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 11:50:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 11:50:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 11:50:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 11:50:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 11:50:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 11:50:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 11:50:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 11:50:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 11:50:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 11:50:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 11:50:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 11:50:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 11:50:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 11:50:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 11:50:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 11:50:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 11:50:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 11:50:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 11:50:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 11:50:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 11:50:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 11:50:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 11:50:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 11:50:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 11:50:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 11:50:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 11:50:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 11:50:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 11:50:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 11:50:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 11:50:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 11:50:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 11:50:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 11:50:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 11:50:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 11:50:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 11:50:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 11:50:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 11:50:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 11:50:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 11:50:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 11:50:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 11:50:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 11:50:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 11:50:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 11:50:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 11:50:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 11:50:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 11:50:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 11:50:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 11:50:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 11:50:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 11:50:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 11:50:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 11:50:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 11:50:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 11:50:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 11:50:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 11:50:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 11:50:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 11:50:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 11:50:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 11:50:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 11:50:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 11:50:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 11:50:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 11:50:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 11:50:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 11:50:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 11:50:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 11:50:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 11:50:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 11:50:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 11:50:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 11:50:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 11:50:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 11:50:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 11:50:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 11:50:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 11:50:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 11:50:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 11:50:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 11:50:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 11:50:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 11:50:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 11:50:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 11:50:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 11:50:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 11:50:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 11:50:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 11:50:35 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 11:50:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 11:50:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 11:50:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 11:50:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 11:50:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 11:50:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 11:50:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 11:50:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 11:50:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 11:50:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 11:50:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 11:50:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 11:50:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 11:50:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 11:50:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 11:50:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 11:50:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 11:50:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 11:50:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 11:50:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 11:50:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 11:50:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 11:50:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 11:50:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 11:50:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 11:50:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 11:50:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 11:50:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 11:50:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 11:50:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 11:50:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 11:50:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 11:50:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 11:50:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 11:50:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 11:50:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 11:50:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 11:50:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 11:50:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 11:50:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 11:50:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 11:50:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 11:50:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 11:50:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 11:50:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 11:50:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 11:50:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 11:50:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 11:50:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 11:50:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 11:50:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 11:50:48 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 11:50:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 11:50:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 11:50:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 11:50:49 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 11:50:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 11:50:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 11:50:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 11:50:50 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 11:50:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 11:50:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 11:50:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 11:50:52 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 11:50:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 11:50:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 11:50:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 11:50:53 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 11:50:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 11:50:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 11:50:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 11:50:54 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 11:50:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 11:50:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 11:50:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 11:50:55 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 11:50:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 11:50:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 11:50:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 11:50:56 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 11:50:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 11:50:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 11:50:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 11:50:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 11:50:57 [main] [32mINFO [m [PodUtils:335] All pods are stable second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn ,second-kafka-cluster-kafka-0 ,second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l ,second-kafka-cluster-zookeeper-0
2022-04-06 11:50:57 [main] [32mINFO [m [PodUtils:296] Verify that all pods with prefix: second-kafka-cluster are stable
2022-04-06 11:50:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 11:50:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 11:50:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 11:50:57 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 50
2022-04-06 11:50:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 11:50:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 11:50:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 11:50:58 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 49
2022-04-06 11:50:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 11:50:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 11:50:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 11:50:59 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 48
2022-04-06 11:51:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 11:51:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 11:51:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 11:51:00 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 47
2022-04-06 11:51:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 11:51:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 11:51:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 11:51:01 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 46
2022-04-06 11:51:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 11:51:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 11:51:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 11:51:02 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 45
2022-04-06 11:51:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 11:51:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 11:51:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 11:51:03 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 44
2022-04-06 11:51:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 11:51:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 11:51:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 11:51:04 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 43
2022-04-06 11:51:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 11:51:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 11:51:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 11:51:05 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 42
2022-04-06 11:51:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 11:51:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 11:51:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 11:51:06 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 41
2022-04-06 11:51:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 11:51:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 11:51:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 11:51:07 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 40
2022-04-06 11:51:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 11:51:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 11:51:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 11:51:08 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 39
2022-04-06 11:51:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 11:51:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 11:51:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 11:51:09 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 38
2022-04-06 11:51:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 11:51:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 11:51:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 11:51:10 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 37
2022-04-06 11:51:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 11:51:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 11:51:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 11:51:11 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 36
2022-04-06 11:51:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 11:51:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 11:51:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 11:51:12 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 35
2022-04-06 11:51:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 11:51:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 11:51:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 11:51:13 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 34
2022-04-06 11:51:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 11:51:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 11:51:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 11:51:14 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 33
2022-04-06 11:51:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 11:51:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 11:51:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 11:51:15 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 32
2022-04-06 11:51:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 11:51:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 11:51:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 11:51:16 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 31
2022-04-06 11:51:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 11:51:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 11:51:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 11:51:17 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 30
2022-04-06 11:51:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 11:51:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 11:51:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 11:51:18 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 29
2022-04-06 11:51:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 11:51:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 11:51:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 11:51:19 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 28
2022-04-06 11:51:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 11:51:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 11:51:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 11:51:20 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 27
2022-04-06 11:51:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 11:51:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 11:51:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 11:51:21 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 26
2022-04-06 11:51:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 11:51:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 11:51:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 11:51:22 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 25
2022-04-06 11:51:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 11:51:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 11:51:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 11:51:23 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 24
2022-04-06 11:51:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 11:51:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 11:51:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 11:51:24 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 23
2022-04-06 11:51:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 11:51:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 11:51:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 11:51:25 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 22
2022-04-06 11:51:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 11:51:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 11:51:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 11:51:26 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 21
2022-04-06 11:51:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 11:51:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 11:51:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 11:51:27 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 20
2022-04-06 11:51:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 11:51:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 11:51:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 11:51:28 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 19
2022-04-06 11:51:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 11:51:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 11:51:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 11:51:29 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 18
2022-04-06 11:51:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 11:51:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 11:51:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 11:51:30 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 17
2022-04-06 11:51:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 11:51:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 11:51:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 11:51:31 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 16
2022-04-06 11:51:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 11:51:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 11:51:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 11:51:32 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 15
2022-04-06 11:51:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 11:51:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 11:51:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 11:51:33 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 14
2022-04-06 11:51:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 11:51:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 11:51:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 11:51:34 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 13
2022-04-06 11:51:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 11:51:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 11:51:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 11:51:36 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 12
2022-04-06 11:51:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 11:51:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 11:51:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 11:51:37 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 11
2022-04-06 11:51:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 11:51:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 11:51:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 11:51:38 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 10
2022-04-06 11:51:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 11:51:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 11:51:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 11:51:39 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 9
2022-04-06 11:51:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 11:51:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 11:51:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 11:51:40 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 8
2022-04-06 11:51:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 11:51:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 11:51:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 11:51:41 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 7
2022-04-06 11:51:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 11:51:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 11:51:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 11:51:42 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 6
2022-04-06 11:51:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 11:51:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 11:51:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 11:51:43 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 5
2022-04-06 11:51:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 11:51:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 11:51:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 11:51:44 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 4
2022-04-06 11:51:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 11:51:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 11:51:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 11:51:45 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 3
2022-04-06 11:51:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 11:51:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 11:51:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 11:51:46 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 2
2022-04-06 11:51:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 11:51:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 11:51:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 11:51:47 [main] [32mINFO [m [PodUtils:322] Pod second-kafka-cluster-zookeeper-0 is in the Running state. Remaining seconds pod to be stable 1
2022-04-06 11:51:47 [main] [32mINFO [m [PodUtils:335] All pods are stable second-kafka-cluster-entity-operator-5f8949dc9c-5nqkn ,second-kafka-cluster-kafka-0 ,second-kafka-cluster-kafka-exporter-6dfb7ccc69-gwz4l ,second-kafka-cluster-zookeeper-0
2022-04-06 11:51:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:51:47 [main] [32mINFO [m [ResourceManager:346] In context testKafkaMetricsSettings is everything deleted.
2022-04-06 11:51:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:51:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaMetricsSettings-FINISHED
2022-04-06 11:51:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:51:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:51:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testClusterOperatorMetrics-STARTED
2022-04-06 11:51:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:51:47 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.5 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:51:47 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:51:47 [main] [32mINFO [m [ResourceManager:346] In context testClusterOperatorMetrics is everything deleted.
2022-04-06 11:51:47 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:51:47 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testClusterOperatorMetrics-FINISHED
2022-04-06 11:51:47 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:51:47 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:51:47 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testCruiseControlMetrics-STARTED
2022-04-06 11:51:47 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:51:48 [main] [32mINFO [m [MetricsIsolatedST:452] Verifying that we have more than 0 groups
2022-04-06 11:51:48 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:51:48 [main] [32mINFO [m [ResourceManager:346] In context testCruiseControlMetrics is everything deleted.
2022-04-06 11:51:48 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:51:48 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testCruiseControlMetrics-FINISHED
2022-04-06 11:51:48 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:51:48 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:51:48 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDataAfterExchange-STARTED
2022-04-06 11:51:48 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:51:48 [main] [32mINFO [m [AbstractKafkaClient:188] Consumer group were not specified going to create the random one.
2022-04-06 11:51:48 [main] [32mINFO [m [InternalKafkaClient:93] Starting verifiableClient plain producer with the following configuration: VerifiableClient{allowedArguments=[TOPIC, BOOTSTRAP_SERVER, BROKER_LIST, MAX_MESSAGES, THROUGHPUT, ACKS, PRODUCER_CONFIG, MESSAGE_CREATE_TIME, VALUE_PREFIX, REPEATING_KEYS, USER], lock=java.lang.Object@3121bd65, messages=[], arguments=[--bootstrap-server, metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092, --max-messages, 5000, --topic, my-topic-538067116-1396354649], executable='/opt/kafka/producer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_PRODUCER, podName='infra-namespace-kafka-clients-748578f786-b46n4', podNamespace='infra-namespace', bootstrapServer='metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-538067116-1396354649', maxMessages=5000, kafkaUsername='null', consumerGroupName='null', consumerInstanceId='null', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@1c5c1dec}
2022-04-06 11:51:48 [main] [32mINFO [m [InternalKafkaClient:94] Producing 5000 messages to metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092:my-topic-538067116-1396354649 from pod infra-namespace-kafka-clients-748578f786-b46n4
2022-04-06 11:51:48 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec infra-namespace-kafka-clients-748578f786-b46n4 -n infra-namespace -- /opt/kafka/producer.sh --bootstrap-server metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092 --max-messages 5000 --topic my-topic-538067116-1396354649
2022-04-06 11:51:51 [main] [32mINFO [m [InternalKafkaClient:97] Producer finished correctly: true
2022-04-06 11:51:51 [main] [32mINFO [m [InternalKafkaClient:101] Producer produced 5000 messages
2022-04-06 11:51:51 [main] [32mINFO [m [InternalKafkaClient:156] Starting verifiableClient plain consumer with the following configuration: VerifiableClient{allowedArguments=[BOOTSTRAP_SERVER, BROKER_LIST, TOPIC, GROUP_ID, MAX_MESSAGES, SESSION_TIMEOUT, VERBOSE, ENABLE_AUTOCOMMIT, RESET_POLICY, ASSIGMENT_STRATEGY, CONSUMER_CONFIG, USER, GROUP_INSTANCE_ID], lock=java.lang.Object@99e884e, messages=[], arguments=[--group-id, my-consumer-group-745810895, --bootstrap-server, metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092, --group-instance-id, instance1503772567, --max-messages, 5000, --topic, my-topic-538067116-1396354649], executable='/opt/kafka/consumer.sh', executor=null, clientType=CLI_KAFKA_VERIFIABLE_CONSUMER, podName='infra-namespace-kafka-clients-748578f786-b46n4', podNamespace='infra-namespace', bootstrapServer='metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092', topicName='my-topic-538067116-1396354649', maxMessages=5000, kafkaUsername='null', consumerGroupName='my-consumer-group-745810895', consumerInstanceId='instance1503772567', clientArgumentMap=io.strimzi.systemtest.kafkaclients.clients.ClientArgumentMap@6ae1e4b7}
2022-04-06 11:51:51 [main] [32mINFO [m [InternalKafkaClient:157] Consuming 5000 messages from metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092#my-topic-538067116-1396354649 from pod infra-namespace-kafka-clients-748578f786-b46n4
2022-04-06 11:51:51 [main] [32mINFO [m [VerifiableClient:192] Client command: kubectl exec infra-namespace-kafka-clients-748578f786-b46n4 -n infra-namespace -- /opt/kafka/consumer.sh --group-id my-consumer-group-745810895 --bootstrap-server metrics-cluster-name-kafka-bootstrap.infra-namespace.svc:9092 --group-instance-id instance1503772567 --max-messages 5000 --topic my-topic-538067116-1396354649
2022-04-06 11:51:57 [main] [32mINFO [m [InternalKafkaClient:160] Consumer finished correctly: true
2022-04-06 11:51:57 [main] [32mINFO [m [InternalKafkaClient:163] Consumer consumed 5000 messages
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.21 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:51:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:51:58 [main] [32mINFO [m [ResourceManager:346] In context testKafkaExporterDataAfterExchange is everything deleted.
2022-04-06 11:51:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:51:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDataAfterExchange-FINISHED
2022-04-06 11:51:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:51:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:51:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testTopicOperatorMetrics-STARTED
2022-04-06 11:51:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.19 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: consumer-offsets---84e7a678d08f4bd226872e5cdd4eb527fadc1c6a
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: heartbeats
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-config
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-offsets
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: metrics-cluster-name-connect-status
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-configs
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-offsets
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: mirrormaker2-cluster-status
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-1340026128-1658645739
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-538067116-1396354649
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: my-topic-750392639-2065076382
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: second-kafka-cluster.checkpoints.internal
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi-store-topic---effb8e3e057afce1ecf67c3f5d8e4e3ff177fc55
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi-topic-operator-kstreams-topic-store-changelog---b75e702040b99be8a9263134de3507fc0cc4017b
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.metrics
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.modeltrainingsamples
2022-04-06 11:51:58 [main] [32mINFO [m [MetricsIsolatedST:370] KafkaTopic: strimzi.cruisecontrol.partitionmetricsamples
2022-04-06 11:51:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:51:58 [main] [32mINFO [m [ResourceManager:346] In context testTopicOperatorMetrics is everything deleted.
2022-04-06 11:51:58 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:51:58 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testTopicOperatorMetrics-FINISHED
2022-04-06 11:51:58 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:51:58 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:51:58 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectRequests-STARTED
2022-04-06 11:51:58 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:51:59 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:51:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:51:59 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectRequests is everything deleted.
2022-04-06 11:51:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:51:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectRequests-FINISHED
2022-04-06 11:51:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:51:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:51:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectResponse-STARTED
2022-04-06 11:51:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:51:59 [main] [32mINFO [m [MetricsCollector:239] Metrics collection for PodIp 172.17.0.24 from Pod infra-namespace-kafka-clients-748578f786-b46n4 finished with return code: 0
2022-04-06 11:51:59 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:51:59 [main] [32mINFO [m [ResourceManager:346] In context testKafkaConnectResponse is everything deleted.
2022-04-06 11:51:59 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:51:59 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaConnectResponse-FINISHED
2022-04-06 11:51:59 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:51:59 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:51:59 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDifferentSetting-STARTED
2022-04-06 11:51:59 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:51:59 [main] [32mINFO [m [MetricsIsolatedST:610] Metrics collection for pod metrics-cluster-name-kafka-exporter-8454677f49-mh2g6 return code - 0
2022-04-06 11:51:59 [main] [32mINFO [m [DeploymentUtils:136] Waiting for Deployment metrics-cluster-name-kafka-exporter rolling update
2022-04-06 11:52:50 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: metrics-cluster-name-kafka-exporter will be ready
2022-04-06 11:52:50 [main] [32mINFO [m [DeploymentUtils:168] Deployment: metrics-cluster-name-kafka-exporter is ready
2022-04-06 11:53:00 [main] [32mINFO [m [DeploymentUtils:141] Deployment metrics-cluster-name-kafka-exporter rolling update finished
2022-04-06 11:53:00 [main] [32mINFO [m [MetricsIsolatedST:610] Metrics collection for pod metrics-cluster-name-kafka-exporter-5856df4b7d-dzgs5 return code - 0
2022-04-06 11:53:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:53:00 [main] [32mINFO [m [ResourceManager:346] In context testKafkaExporterDifferentSetting is everything deleted.
2022-04-06 11:53:00 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:53:00 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.metrics.MetricsIsolatedST.testKafkaExporterDifferentSetting-FINISHED
2022-04-06 11:53:00 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:53:00 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:53:00 [main] [32mINFO [m [ResourceManager:348] Delete all resources for MetricsIsolatedST
2022-04-06 11:53:00 [main] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-1705135816-702044698 in namespace infra-namespace
2022-04-06 11:53:00 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaMirrorMaker2 mm2-cluster in namespace infra-namespace
2022-04-06 11:53:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy second-kafka-cluster-entity-operator-allow in namespace second-metrics-cluster-test
2022-04-06 11:53:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaUser my-user-950948744-1235734862 in namespace infra-namespace
2022-04-06 11:53:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy second-kafka-cluster-kafka-exporter-allow in namespace second-metrics-cluster-test
2022-04-06 11:53:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy metrics-cluster-name-kafka-exporter-allow in namespace infra-namespace
2022-04-06 11:53:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy metrics-cluster-name-entity-operator-allow in namespace infra-namespace
2022-04-06 11:53:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy cluster-operator-allow in namespace infra-namespace
2022-04-06 11:53:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect metrics-cluster-name in namespace infra-namespace
2022-04-06 11:53:10 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaBridge my-bridge in namespace infra-namespace
2022-04-06 11:53:10 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-750392639-2065076382 in namespace infra-namespace
2022-04-06 11:53:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment infra-namespace-kafka-clients in namespace infra-namespace
2022-04-06 11:53:20 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-538067116-1396354649 in namespace infra-namespace
2022-04-06 11:53:20 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-1340026128-1658645739 in namespace infra-namespace
2022-04-06 11:53:30 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Kafka second-kafka-cluster in namespace second-metrics-cluster-test
2022-04-06 11:53:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Kafka metrics-cluster-name in namespace infra-namespace
2022-04-06 11:53:30 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [KafkaResource:64] Explicit deletion of KafkaTopics in namespace infra-namespace, for cruise control Kafka cluster metrics-cluster-name
2022-04-06 11:53:40 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment second-metrics-cluster-test-kafka-clients in namespace second-metrics-cluster-test
2022-04-06 11:54:30 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 835.22 s - in io.strimzi.systemtest.metrics.MetricsIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.metrics.JmxIsolatedST
2022-04-06 11:54:30 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 11:54:55 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 11:54:55 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 11:54:55 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 11:54:55 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:54:55 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 11:54:55 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 11:54:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 11:54:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 11:54:55 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 11:54:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace second-metrics-cluster-test
2022-04-06 11:54:55 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 11:54:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 11:54:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace second-metrics-cluster-test
2022-04-06 11:54:55 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 11:54:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 11:54:55 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:54:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 11:54:55 [main] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:54:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 11:54:55 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 11:54:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 11:54:55 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:05 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:05 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:55:05 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:55:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 11:55:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:55:05 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:06 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:15 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:15 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:25 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:55:46 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=30000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 11:55:46 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 11:55:46 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 11:55:46 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 11:55:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:55:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:55:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 11:55:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 11:55:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 11:55:46 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 11:55:46 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:46 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:55:47 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 11:55:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:55:47 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 11:55:47 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 11:55:47 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 11:55:47 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:55:47 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 11:56:15 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 11:56:15 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 11:56:25 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 11:56:25 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:56:25 [main] [32mINFO [m [ResourceManager:346] In context JmxIsolatedST is everything deleted.
2022-04-06 11:56:25 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;33mWARNING[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 115.302 s - in io.strimzi.systemtest.metrics.JmxIsolatedST
[[1;34mINFO[m] Running io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-06 11:56:25 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 11:56:50 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 11:56:50 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 11:56:50 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 11:56:50 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:56:50 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 11:56:50 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 11:56:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 11:56:50 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 11:56:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 11:56:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:56:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:56:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 11:56:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 11:56:50 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:56:50 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:00 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:57:00 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 11:57:00 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 11:57:00 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:00 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:10 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 11:57:11 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 11:57:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 11:57:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:57:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 11:57:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:57:11 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:21 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:31 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:57:36 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@191cc566
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 11:57:36 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 11:57:36 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 11:57:36 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:36 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:37 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 11:57:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:57:37 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 11:57:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 11:57:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 11:57:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 11:57:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 11:57:37 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 11:57:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 11:57:37 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 11:57:37 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:57:37 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 11:57:37 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 11:57:37 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 11:57:37 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 11:57:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:57:37 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 11:57:37 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:57:37 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 11:57:53 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 11:57:53 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 11:58:03 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 11:58:03 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 11:58:03 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-STARTED
2022-04-06 11:58:03 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 11:58:03 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka my-cluster-35d856f9 in namespace infra-namespace
2022-04-06 11:58:03 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: my-cluster-35d856f9 will have desired state: Ready
2022-04-06 11:59:19 [main] [32mINFO [m [ResourceManager:444] Kafka: my-cluster-35d856f9 is in desired state: Ready
2022-04-06 11:59:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-35d856f9-hello-world-producer in namespace infra-namespace
2022-04-06 11:59:20 [main] [32mINFO [m [ResourceManager:155] Create/Update Job my-cluster-35d856f9-hello-world-consumer in namespace infra-namespace
2022-04-06 11:59:20 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-35d856f9-hello-world-producer will be in active state
2022-04-06 11:59:21 [main] [32mINFO [m [JobUtils:81] Waiting for job: my-cluster-35d856f9-hello-world-consumer will be in active state
2022-04-06 11:59:21 [main] [32mINFO [m [ClientUtils:61] Waiting till producer my-cluster-35d856f9-hello-world-producer and consumer my-cluster-35d856f9-hello-world-consumer finish
2022-04-06 11:59:38 [main] [32mINFO [m [LogDumpScriptIsolatedST:78] Print partition segments from cluster infra-namespace/my-cluster-35d856f9
2022-04-06 11:59:38 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-35d856f9 --topic my-topic-2004225973-1061307864 --partition 0 --dry-run
2022-04-06 11:59:38 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 11:59:38 [main] [32mINFO [m [LogDumpScriptIsolatedST:87] Dump topic partition from cluster infra-namespace/my-cluster-35d856f9
2022-04-06 11:59:41 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh partition --namespace infra-namespace --cluster my-cluster-35d856f9 --topic my-topic-2004225973-1061307864 --partition 0 --out-path /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-35d856f9
2022-04-06 11:59:41 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 11:59:41 [main] [32mINFO [m [LogDumpScriptIsolatedST:99] Dump consumer offsets partition from cluster infra-namespace/my-cluster-35d856f9
2022-04-06 11:59:46 [main] [32mINFO [m [Exec:417] Command: /home/ec2-user/strimzi-kafka-operator/systemtest/../tools/log-dump/run.sh cg_offsets --namespace infra-namespace --cluster my-cluster-35d856f9 --group-id my-group --out-path /home/ec2-user/strimzi-kafka-operator/systemtest/target/my-cluster-35d856f9
2022-04-06 11:59:46 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 11:59:46 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:59:46 [main] [32mINFO [m [ResourceManager:348] Delete all resources for dumpPartitions
2022-04-06 11:59:46 [main] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-35d856f9-hello-world-producer in namespace infra-namespace
2022-04-06 11:59:46 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Kafka my-cluster-35d856f9 in namespace infra-namespace
2022-04-06 11:59:46 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Job my-cluster-35d856f9-hello-world-consumer in namespace infra-namespace
2022-04-06 11:59:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 11:59:56 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.dump.LogDumpScriptIsolatedST.dumpPartitions-FINISHED
2022-04-06 11:59:56 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 11:59:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:59:56 [main] [32mINFO [m [ResourceManager:346] In context LogDumpScriptIsolatedST is everything deleted.
2022-04-06 11:59:56 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 210.717 s - in io.strimzi.systemtest.dump.LogDumpScriptIsolatedST
2022-04-06 11:59:56 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 11:59:56 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 11:59:56 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 11:59:56 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 11:59:56 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 11:59:56 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 11:59:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 11:59:56 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 11:59:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 11:59:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 11:59:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 11:59:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 11:59:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 11:59:56 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 11:59:56 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:06 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:06 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:00:06 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:00:06 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:16 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:00:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:00:16 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:00:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:00:16 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:00:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:17 [ForkJoinPool.commonPool-worker-7] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:26 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:27 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:29] =======================================================================
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:30] =======================================================================
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:31]                         Test run started
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:32] =======================================================================
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:33] =======================================================================
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:48] Following testclasses are selected for run:
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:51] -> io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:52] =======================================================================
2022-04-06 12:00:32 [main] [32mINFO [m [TestExecutionListener:53] =======================================================================
[[1;34mINFO[m] Running io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-06 12:00:32 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:00:57 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 12:00:57 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 12:00:57 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:346] In context JUnit Jupiter is everything deleted.
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:00:57 [main] [32mINFO [m [SetupClusterOperator:197] Cluster operator installation configuration:
extensionContext=org.junit.jupiter.engine.descriptor.JupiterEngineExtensionContext@51e23cfb
clusterOperatorName=strimzi-cluster-operator
namespaceInstallTo=infra-namespace
namespaceToWatch=*
bindingsNamespaces=[infra-namespace]
operationTimeout=300000
reconciliationInterval=30000
clusterOperatorRBACType=CLUSTER
2022-04-06 12:00:57 [main] [32mINFO [m [SetupClusterOperator:248] Install ClusterOperator via Yaml bundle
2022-04-06 12:00:57 [main] [32mINFO [m [KubeClusterResource:156] Creating Namespace: infra-namespace
2022-04-06 12:00:57 [main] [32mINFO [m [KubeClusterResource:82] Client use Namespace: infra-namespace
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:57 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:58 [main] [32mINFO [m [NetworkPolicyResource:239] NetworkPolicy successfully set to: true for namespace: infra-namespace
2022-04-06 12:00:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/021-ClusterRoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:00:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml in namespace infra-namespace
2022-04-06 12:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:00:58 [main] [32mINFO [m [ClusterRoleBindingResource:48] Creating ClusterRoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml in namespace infra-namespace
2022-04-06 12:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:00:58 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml in namespace infra-namespace
2022-04-06 12:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:58 [main] [32mINFO [m [RoleBindingResource:43] Creating RoleBinding in test case JUnit Jupiter from /home/ec2-user/strimzi-kafka-operator/systemtest/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml in namespace infra-namespace
2022-04-06 12:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 12:00:58 [main] [32mINFO [m [ClusterRoleBindingTemplates:21] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 12:00:58 [main] [32mINFO [m [ClusterRoleBindingTemplates:26] Creating ClusterRoleBinding that grant cluster-wide access to all OpenShift projects
2022-04-06 12:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 12:00:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:00:58 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: strimzi-cluster-operator will be ready
2022-04-06 12:01:19 [main] [32mINFO [m [DeploymentUtils:168] Deployment: strimzi-cluster-operator is ready
2022-04-06 12:01:19 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment strimzi-cluster-operator to be ready
2022-04-06 12:01:29 [main] [32mINFO [m [DeploymentUtils:197] Deployment strimzi-cluster-operator is ready
2022-04-06 12:01:29 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 12:01:29 [main] [32mINFO [m [OauthAbstractST:125] Deploying keycloak...
2022-04-06 12:01:29 [main] [32mINFO [m [KeycloakUtils:35] Prepare Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 12:02:58 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/prepare_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 12:02:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:02:58 [main] [32mINFO [m [KeycloakUtils:48] Keycloak in namespace infra-namespace is ready
2022-04-06 12:02:58 [main] [32mINFO [m [SecretUtils:46] Waiting for Secret credential-example-keycloak
2022-04-06 12:02:58 [main] [32mINFO [m [SecretUtils:50] Secret credential-example-keycloak created
2022-04-06 12:02:58 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-producer-secret
2022-04-06 12:02:58 [main] [32mINFO [m [SecretUtils:70] Creating secret hello-world-consumer-secret
2022-04-06 12:02:58 [main] [32mINFO [m [SecretUtils:70] Creating secret team-a-client-secret
2022-04-06 12:02:58 [main] [32mINFO [m [SecretUtils:70] Creating secret team-b-client-secret
2022-04-06 12:02:58 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-broker-secret
2022-04-06 12:02:58 [main] [32mINFO [m [SecretUtils:70] Creating secret my-connect-oauth
2022-04-06 12:02:58 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-oauth
2022-04-06 12:02:58 [main] [32mINFO [m [SecretUtils:70] Creating secret my-mirror-maker-2-oauth
2022-04-06 12:02:58 [main] [32mINFO [m [SecretUtils:70] Creating secret my-bridge-oauth
2022-04-06 12:02:58 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-audience-secret
2022-04-06 12:02:58 [main] [32mINFO [m [SecretUtils:70] Creating secret kafka-client-secret
2022-04-06 12:02:58 [main] [32mINFO [m [KeycloakInstance:50] Replacing validIssuerUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal to pointing to internal realm
2022-04-06 12:02:58 [main] [32mINFO [m [KeycloakInstance:51] Replacing jwksEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/certs to pointing to internal realm
2022-04-06 12:02:58 [main] [32mINFO [m [KeycloakInstance:52] Replacing oauthTokenEndpointUri: https://keycloak.infra-namespace.svc.cluster.local:8443/auth/realms/internal/protocol/openid-connect/token to pointing to internal realm
2022-04-06 12:02:58 [main] [32mINFO [m [KeycloakInstance:60] Using HTTP endpoints
2022-04-06 12:02:58 [main] [32mINFO [m [ResourceManager:155] Create/Update Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 12:02:58 [main] [32mINFO [m [ResourceManager:433] Wait for Kafka: oauth-cluster-plain-name will have desired state: Ready
2022-04-06 12:04:18 [main] [32mINFO [m [ResourceManager:444] Kafka: oauth-cluster-plain-name is in desired state: Ready
2022-04-06 12:04:18 [main] [32mINFO [m [TestSeparator:23] ############################################################################
2022-04-06 12:04:18 [main] [32mINFO [m [TestSeparator:24] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-STARTED
2022-04-06 12:04:18 [main] [32mINFO [m [AbstractST:597] Not first test we are gonna generate cluster name
2022-04-06 12:04:18 [main] [32mINFO [m [KafkaClients:87] Consumer group were not specified going to create the random one.
2022-04-06 12:04:18 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaTopic my-topic-2051515924-1826991959 in namespace infra-namespace
2022-04-06 12:04:18 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaTopic: my-topic-2051515924-1826991959 will have desired state: Ready
2022-04-06 12:04:19 [main] [32mINFO [m [ResourceManager:444] KafkaTopic: my-topic-2051515924-1826991959 is in desired state: Ready
2022-04-06 12:04:19 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-producer-my-cluster-3e0bcd3d in namespace infra-namespace
2022-04-06 12:04:19 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-producer-my-cluster-3e0bcd3d will be in active state
2022-04-06 12:04:21 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-producer-my-cluster-3e0bcd3d to finished
2022-04-06 12:04:29 [main] [32mINFO [m [ResourceManager:155] Create/Update Job oauth-consumer-my-cluster-3e0bcd3d in namespace infra-namespace
2022-04-06 12:04:29 [main] [32mINFO [m [JobUtils:81] Waiting for job: oauth-consumer-my-cluster-3e0bcd3d will be in active state
2022-04-06 12:04:30 [main] [32mINFO [m [ClientUtils:76] Waiting for producer/consumer:oauth-consumer-my-cluster-3e0bcd3d to finished
2022-04-06 12:04:41 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3e0bcd3d-kafka-clients in namespace infra-namespace
2022-04-06 12:04:41 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3e0bcd3d-kafka-clients will be ready
2022-04-06 12:04:43 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3e0bcd3d-kafka-clients is ready
2022-04-06 12:04:43 [main] [32mINFO [m [ResourceManager:155] Create/Update Deployment my-cluster-3e0bcd3d-scraper in namespace infra-namespace
2022-04-06 12:04:43 [main] [32mINFO [m [DeploymentUtils:161] Wait for Deployment: my-cluster-3e0bcd3d-scraper will be ready
2022-04-06 12:04:45 [main] [32mINFO [m [DeploymentUtils:168] Deployment: my-cluster-3e0bcd3d-scraper is ready
2022-04-06 12:04:45 [main] [32mINFO [m [DeploymentUtils:194] Waiting for 1 Pod(s) of Deployment my-cluster-3e0bcd3d-scraper to be ready
2022-04-06 12:04:55 [main] [32mINFO [m [DeploymentUtils:197] Deployment my-cluster-3e0bcd3d-scraper is ready
2022-04-06 12:04:55 [main] [32mINFO [m [NetworkPolicyResource:187] Apply NetworkPolicy access to my-cluster-3e0bcd3d-connect from pods with LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={})
2022-04-06 12:04:55 [main] [32mINFO [m [ResourceManager:155] Create/Update NetworkPolicy my-cluster-3e0bcd3d-allow in namespace infra-namespace
2022-04-06 12:04:55 [main] [32mINFO [m [NetworkPolicyResource:229] Network policy for LabelSelector LabelSelector(matchExpressions=[], matchLabels={user-test-app=scraper}, additionalProperties={}) successfully created
2022-04-06 12:04:55 [main] [32mINFO [m [ResourceManager:155] Create/Update KafkaConnect my-cluster-3e0bcd3d in namespace infra-namespace
2022-04-06 12:04:55 [main] [32mINFO [m [ResourceManager:433] Wait for KafkaConnect: my-cluster-3e0bcd3d will have desired state: Ready
2022-04-06 12:05:59 [main] [32mINFO [m [ResourceManager:444] KafkaConnect: my-cluster-3e0bcd3d is in desired state: Ready
2022-04-06 12:05:59 [main] [32mINFO [m [KafkaConnectUtils:63] Waiting until KafkaConnect API is available
2022-04-06 12:05:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-3e0bcd3d-connect-84475465cb-hhqrb -- /bin/bash -c curl -I http://localhost:8083/connectors
2022-04-06 12:05:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:05:59 [main] [32mINFO [m [KafkaConnectUtils:66] KafkaConnect API is available
2022-04-06 12:05:59 [main] [32mINFO [m [Exec:417] Command: kubectl --namespace infra-namespace exec my-cluster-3e0bcd3d-connect-84475465cb-hhqrb -- /bin/bash -c curl -X POST -H "Content-Type: application/json" --data '{ "name": "sink-test", "config": { "connector.class": "FileStreamSink", "tasks.max": "1", "topics": "my-topic-2051515924-1826991959", "file": "/tmp/test-file-sink.txt" } }' http://localhost:8083/connectors
2022-04-06 12:05:59 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:05:59 [main] [32mINFO [m [KafkaConnectUtils:74] Waiting for messages in file sink on my-cluster-3e0bcd3d-connect-84475465cb-hhqrb
2022-04-06 12:06:03 [main] [32mINFO [m [KafkaConnectUtils:77] Expected messages are in file sink on my-cluster-3e0bcd3d-connect-84475465cb-hhqrb
2022-04-06 12:06:04 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:06:04 [main] [32mINFO [m [ResourceManager:348] Delete all resources for testProducerConsumerConnect
2022-04-06 12:06:04 [main] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3e0bcd3d-scraper in namespace infra-namespace
2022-04-06 12:06:04 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of KafkaConnect my-cluster-3e0bcd3d in namespace infra-namespace
2022-04-06 12:06:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-producer-my-cluster-3e0bcd3d in namespace infra-namespace
2022-04-06 12:06:04 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of Deployment my-cluster-3e0bcd3d-kafka-clients in namespace infra-namespace
2022-04-06 12:06:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of Job oauth-consumer-my-cluster-3e0bcd3d in namespace infra-namespace
2022-04-06 12:06:04 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of KafkaTopic my-topic-2051515924-1826991959 in namespace infra-namespace
2022-04-06 12:06:14 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy my-cluster-3e0bcd3d-allow in namespace infra-namespace
2022-04-06 12:06:54 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:06:54 [main] [32mINFO [m [TestSeparator:29] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect-FINISHED
2022-04-06 12:06:54 [main] [32mINFO [m [TestSeparator:30] ############################################################################
2022-04-06 12:06:54 [main] [32mINFO [m [KeycloakUtils:52] Teardown Keycloak Operator in namespace: infra-namespace with watching namespace: infra-namespace
2022-04-06 12:06:58 [main] [32mINFO [m [Exec:417] Command: /bin/bash ../systemtest/src/test/resources/oauth2/teardown_keycloak_operator.sh infra-namespace 11.0.1 infra-namespace
2022-04-06 12:06:58 [main] [32mINFO [m [Exec:417] Return code: 0
2022-04-06 12:06:58 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:06:58 [main] [32mINFO [m [ResourceManager:348] Delete all resources for OauthPlainIsolatedST
2022-04-06 12:06:58 [main] [32mINFO [m [ResourceManager:241] Delete of Kafka oauth-cluster-plain-name in namespace infra-namespace
2022-04-06 12:06:58 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of NetworkPolicy global-network-policy in namespace infra-namespace
2022-04-06 12:07:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:07:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:07:08 [main] [32mINFO [m [ResourceManager:346] In context OauthPlainIsolatedST is everything deleted.
2022-04-06 12:07:08 [main] [32mINFO [m [ResourceManager:369] ############################################################################
[[1;34mINFO[m] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 396.047 s - in io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST
2022-04-06 12:07:08 [main] [32mINFO [m [SetupClusterOperator:618] ============================================================================
2022-04-06 12:07:08 [main] [32mINFO [m [SetupClusterOperator:619] Un-installing cluster operator from infra-namespace namespace
2022-04-06 12:07:08 [main] [32mINFO [m [SetupClusterOperator:620] ============================================================================
2022-04-06 12:07:08 [main] [32mINFO [m [ResourceManager:344] ############################################################################
2022-04-06 12:07:08 [main] [32mINFO [m [ResourceManager:348] Delete all resources for JUnit Jupiter
2022-04-06 12:07:08 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkarebalances.kafka.strimzi.io in namespace (not set)
2022-04-06 12:07:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-broker in namespace (not set)
2022-04-06 12:07:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator-entity-operator-delegation in namespace infra-namespace
2022-04-06 12:07:08 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnects.kafka.strimzi.io in namespace (not set)
2022-04-06 12:07:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-entity-operator in namespace (not set)
2022-04-06 12:07:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:07:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-entity-operator in namespace (not set)
2022-04-06 12:07:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-kafka-client in namespace (not set)
2022-04-06 12:07:08 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of Deployment strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:07:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-namespaced in namespace (not set)
2022-04-06 12:07:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ClusterRole strimzi-cluster-operator-global in namespace (not set)
2022-04-06 12:07:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of ServiceAccount strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:07:08 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkausers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:07:18 [main] [32mINFO [m [ResourceManager:241] Delete of ConfigMap strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:07:18 [main] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator in namespace (not set)
2022-04-06 12:07:18 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkaconnectors.kafka.strimzi.io in namespace (not set)
2022-04-06 12:07:18 [ForkJoinPool.commonPool-worker-5] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition strimzipodsets.core.strimzi.io in namespace (not set)
2022-04-06 12:07:18 [main] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormaker2s.kafka.strimzi.io in namespace (not set)
2022-04-06 12:07:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-client-delegation in namespace (not set)
2022-04-06 12:07:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of RoleBinding strimzi-cluster-operator in namespace infra-namespace
2022-04-06 12:07:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of ClusterRoleBinding strimzi-cluster-operator-kafka-broker-delegation in namespace (not set)
2022-04-06 12:07:18 [ForkJoinPool.commonPool-worker-3] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkabridges.kafka.strimzi.io in namespace (not set)
2022-04-06 12:07:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkamirrormakers.kafka.strimzi.io in namespace (not set)
2022-04-06 12:07:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkatopics.kafka.strimzi.io in namespace (not set)
2022-04-06 12:07:18 [ForkJoinPool.commonPool-worker-1] [32mINFO [m [ResourceManager:241] Delete of CustomResourceDefinition kafkas.kafka.strimzi.io in namespace (not set)
2022-04-06 12:07:29 [main] [32mINFO [m [ResourceManager:369] ############################################################################
2022-04-06 12:07:34 [main] [32mINFO [m [TestExecutionListener:40] =======================================================================
2022-04-06 12:07:34 [main] [32mINFO [m [TestExecutionListener:41] =======================================================================
2022-04-06 12:07:34 [main] [32mINFO [m [TestExecutionListener:42]                         Test run finished
2022-04-06 12:07:34 [main] [32mINFO [m [TestExecutionListener:43] =======================================================================
2022-04-06 12:07:34 [main] [32mINFO [m [TestExecutionListener:44] =======================================================================
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;33mWARNING[m] Flakes: 
[[1;33mWARNING[m] io.strimzi.systemtest.security.oauth.OauthPlainIsolatedST.testProducerConsumerConnect(ExtensionContext)
[[1;31mERROR[m]   Run 1: OauthPlainIsolatedST.testProducerConsumerConnect:287 ? Wait Timeout after 6000...
[[1;34mINFO[m]   Run 2: PASS
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;33mWARNING[m] Tests run: 304, Failures: 0, Errors: 0, Skipped: 13, Flakes: 1
[[1;34mINFO[m] 
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-failsafe-plugin:3.0.0-M5:verify[m [1m(default)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-dependency-plugin:3.1.1:analyze-only[m [1m(analyze)[m @ [36msystemtest[0;1m ---[m
[[1;34mINFO[m] No dependency problems found
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mReactor Summary for Strimzi - Apache Kafka on Kubernetes and OpenShift 0.29.0-SNAPSHOT:[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Strimzi - Apache Kafka on Kubernetes and OpenShift . [1;32mSUCCESS[m [  2.729 s]
[[1;34mINFO[m] test ............................................... [1;32mSUCCESS[m [  1.092 s]
[[1;34mINFO[m] crd-annotations .................................... [1;32mSUCCESS[m [  1.112 s]
[[1;34mINFO[m] crd-generator ...................................... [1;32mSUCCESS[m [  2.572 s]
[[1;34mINFO[m] api ................................................ [1;32mSUCCESS[m [  6.799 s]
[[1;34mINFO[m] mockkube ........................................... [1;32mSUCCESS[m [  1.030 s]
[[1;34mINFO[m] config-model ....................................... [1;32mSUCCESS[m [  0.783 s]
[[1;34mINFO[m] certificate-manager ................................ [1;32mSUCCESS[m [  0.909 s]
[[1;34mINFO[m] operator-common .................................... [1;32mSUCCESS[m [  1.900 s]
[[1;34mINFO[m] systemtest ......................................... [1;32mSUCCESS[m [  20:33 h]
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1;32mBUILD SUCCESS[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] Total time:  20:34 h
[[1;34mINFO[m] Finished at: 2022-04-06T12:07:35Z
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
